{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "333b98b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from pure_ldp.frequency_oracles.local_hashing import LHClient, LHServer\n",
    "# Load data\n",
    "data_path = '../data/raw/bank-full.csv'\n",
    "df = pd.read_csv(data_path, sep=';')\n",
    "df['y'] = df['y'].map({'no': 0, 'yes': 1})\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Best parameters for RandomForestClassifier\n",
    "best_params_rf = {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "\n",
    "# Create directories for figures and results\n",
    "figures_base = 'figures'\n",
    "results_base = 'results'\n",
    "os.makedirs(figures_base, exist_ok=True)\n",
    "os.makedirs(results_base, exist_ok=True)\n",
    "method = 'OLH'\n",
    "method_path = os.path.join(figures_base, method)\n",
    "os.makedirs(method_path, exist_ok=True)\n",
    "subfolders = ['Original'] + [f'eps_{eps}' for eps in [5, 1, 0.1]]\n",
    "for subfolder in subfolders:\n",
    "    os.makedirs(os.path.join(method_path, subfolder), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a19dd0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         job  marital education default  balance housing loan  contact  \\\n",
       "0   58  management  married  tertiary      no     2143     yes   no  unknown   \n",
       "\n",
       "   day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0    5   may       261         1     -1         0  unknown  0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fila = df.head(1)\n",
    "fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c60eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to map binary categorical variables and months\n",
    "def map_binary_columns(df):\n",
    "    df['default'] = df['default'].map({'no': 0, 'yes': 1})\n",
    "    df['housing'] = df['housing'].map({'no': 0, 'yes': 1})\n",
    "    df['loan'] = df['loan'].map({'no': 0, 'yes': 1})\n",
    "    df['month'] = df['month'].map({\n",
    "        'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4,\n",
    "        'may': 5, 'jun': 6, 'jul': 7, 'aug': 8,\n",
    "        'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Function to convert numerical variables to categorical\n",
    "def convert_numerics_to_categories(df):\n",
    "    bins_age = [18, 30, 40, 50, 60, 95]\n",
    "    labels_age = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
    "    df['age'] = pd.cut(df['age'], bins=bins_age, labels=labels_age, include_lowest=True)\n",
    "\n",
    "    bins_balance = [-8019, 0, 72, 448, 1428, 102127]\n",
    "    labels_balance = ['negative', '0-72', '73-448', '449-1428', '1429+']\n",
    "    df['balance'] = pd.cut(df['balance'], bins=bins_balance, labels=labels_balance, include_lowest=True)\n",
    "\n",
    "    bins_day = [1, 7, 14, 21, 31]\n",
    "    labels_day = ['1-7', '8-14', '15-21', '22-31']\n",
    "    df['day'] = pd.cut(df['day'], bins=bins_day, labels=labels_day, include_lowest=True)\n",
    "\n",
    "    bins_duration = [0, 103, 180, 319, 4918]\n",
    "    labels_duration = ['0-103', '104-180', '181-319', '320+']\n",
    "    df['duration'] = pd.cut(df['duration'], bins=bins_duration, labels=labels_duration, include_lowest=True)\n",
    "\n",
    "    bins_campaign = [1, 2, 3, 10, 63]\n",
    "    labels_campaign = ['1', '2-3', '4-10', '11+']\n",
    "    df['campaign'] = pd.cut(df['campaign'], bins=bins_campaign, labels=labels_campaign, include_lowest=True)\n",
    "\n",
    "    bins_pdays = [-1, 0, 30, 90, 871]\n",
    "    labels_pdays = ['no_contact', '0-30', '31-90', '91+']\n",
    "    df['pdays'] = pd.cut(df['pdays'], bins=bins_pdays, labels=labels_pdays, include_lowest=True)\n",
    "\n",
    "    bins_previous = [0, 1, 2, 5, 275]\n",
    "    labels_previous = ['0', '1-2', '3-5', '6+']\n",
    "    df['previous'] = pd.cut(df['previous'], bins=bins_previous, labels=labels_previous, include_lowest=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to map categorical variables to numerical indices\n",
    "def map_categorical_columns(df, categorical_columns):\n",
    "    mappings = {}\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].astype(str).replace('nan', pd.NA)\n",
    "        unique_values = sorted(df[col].dropna().unique())\n",
    "        mappings[col] = {value: idx for idx, value in enumerate(unique_values)}\n",
    "        df[col] = df[col].map(mappings[col])\n",
    "    return df, mappings\n",
    "\n",
    "def apply_olh(df, epsilon, categorical_columns, cat_mappings):\n",
    "    df_olh = df.copy()\n",
    "    fila = df.head(1)\n",
    "    n_samples = len(df)\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        # Domain size of each column\n",
    "        d = len(cat_mappings[col])\n",
    "        print(f\"Column {col}, epsilon={epsilon}, d={d}\")\n",
    "\n",
    "        # Initialize OLH client and server\n",
    "        client = LHClient(epsilon=epsilon, d=d, use_olh=True)\n",
    "        server = LHServer(epsilon=epsilon, d=d, use_olh=True)\n",
    "\n",
    "        # Privatize each data point\n",
    "        for idx in fila.index:\n",
    "            value = fila.at[idx, col]\n",
    "            perturbed_value = client.privatise(int(value))\n",
    "            server.aggregate(perturbed_value)\n",
    "        \n",
    "        # Estimate frequencies for each category\n",
    "        freqs = np.zeros(d)\n",
    "        for i in range(d):\n",
    "            freqs[i] = server.estimate(i)\n",
    "        print(f\"Estimated frequencies for column {col}: {freqs}\")\n",
    "\n",
    "    return freqs\n",
    "\n",
    "# Function to generate count matrices (heatmaps) of feature vs target\n",
    "def plot_feature_target_count_matrices(X_original, X_privatized, y, categorical_columns, cat_mappings, method, model_name):\n",
    "    df_privatized = X_privatized.copy()\n",
    "    df_privatized['y'] = y.reset_index(drop=True)\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        if df_privatized[col].isna().all():\n",
    "            print(f\"Skipping {col}: all values are NaN\")\n",
    "            continue\n",
    "\n",
    "        reverse_mapping = {idx: cat for cat, idx in cat_mappings[col].items()}\n",
    "        df_privatized[col] = df_privatized[col].map(reverse_mapping)\n",
    "        \n",
    "        if df_privatized[col].isna().any():\n",
    "            print(f\"Warning: NaN values found in {col} after mapping. Filling with 'Unknown'\")\n",
    "            df_privatized[col] = df_privatized[col].fillna('Unknown')\n",
    "\n",
    "        count_matrix = pd.crosstab(df_privatized['y'], df_privatized[col])\n",
    "        if count_matrix.empty:\n",
    "            print(f\"Skipping {col}: count matrix is empty\")\n",
    "            continue\n",
    "\n",
    "        categories = list(cat_mappings[col].keys())\n",
    "        if 'Unknown' in df_privatized[col].values:\n",
    "            categories = categories + ['Unknown']\n",
    "        count_matrix = count_matrix.reindex(columns=categories, fill_value=0)\n",
    "        \n",
    "        if len(count_matrix) == 1:\n",
    "            if 0 in count_matrix.index:\n",
    "                count_matrix.loc[1] = 0\n",
    "            else:\n",
    "                count_matrix.loc[0] = 0\n",
    "            count_matrix = count_matrix.sort_index()\n",
    "        count_matrix.index = ['y=0', 'y=1']\n",
    "\n",
    "        plt.figure(figsize=(max(6, len(categories) * 0.5), 3))\n",
    "        sns.heatmap(count_matrix, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Count'})\n",
    "        plt.title(f'Count Matrix: {col} vs Target ({method}, {model_name})')\n",
    "        plt.xlabel(f'{col} Categories')\n",
    "        plt.ylabel('Target (y)')\n",
    "        plt.tight_layout()\n",
    "        filepath = os.path.join('figures', method, model_name, f'count_matrix_{col}.png')\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Complete data processing\n",
    "def process_data(X, y, categorical_columns, cat_mappings, apply_olh_flag=False, epsilon=None):\n",
    "    x = X.copy()\n",
    "    if apply_olh_flag and epsilon:\n",
    "        x = apply_olh(x, epsilon, categorical_columns, cat_mappings)\n",
    "\n",
    "    x = pd.get_dummies(x, columns=categorical_columns, drop_first=True, dtype='int64')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "    rf = RandomForestClassifier(**best_params_rf, random_state=42)\n",
    "    boruta = BorutaPy(rf, n_estimators='auto', verbose=0)\n",
    "    boruta.fit(X_train_resampled.values, y_train_resampled.values)\n",
    "    selected_features = X_train_resampled.columns[boruta.support_].tolist()\n",
    "    return X_train_resampled[selected_features], X_test[selected_features], y_train_resampled, y_test\n",
    "\n",
    "# Train and evaluate model\n",
    "def evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    model = RandomForestClassifier(**best_params_rf, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    actual_negatives, actual_positives = conf_matrix[0].sum(), conf_matrix[1].sum()\n",
    "    false_positive_pct = conf_matrix[0][1] / actual_negatives if actual_negatives > 0 else 0\n",
    "    false_negative_pct = conf_matrix[1][0] / actual_positives if actual_positives > 0 else 0\n",
    "    return {\n",
    "        'ROC AUC': roc_auc_score(y_test, y_prob),\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'Type I Error': false_positive_pct,\n",
    "        'Type II Error': false_negative_pct\n",
    "    }\n",
    "\n",
    "# Function to run iterations and collect results\n",
    "def run_iterations(X, y, X_original, categorical_columns, cat_mappings, method='none', epsilon=None, n_iterations=5):\n",
    "    results = []\n",
    "    for i in range(n_iterations):\n",
    "        print(f\"Iteration {i+1}/{n_iterations} for method={method}, epsilon={epsilon}\")\n",
    "        if method == 'olh':\n",
    "            X_iter = apply_olh(X.copy(), epsilon, categorical_columns, cat_mappings)\n",
    "        else:\n",
    "            X_iter = X.copy()\n",
    "            \n",
    "        if i == 0:\n",
    "            model_name = f'eps_{epsilon}' if method == 'olh' else 'Original'\n",
    "            print(f\"Generating count matrices for {model_name}...\")\n",
    "            plot_feature_target_count_matrices(X_original, X_iter, y, categorical_columns, cat_mappings, 'OLH', model_name)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = process_data(X_iter, y, categorical_columns, cat_mappings)\n",
    "        metrics = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        results.append(metrics)\n",
    "    return results\n",
    "\n",
    "# Function to compute statistics (mean, min, max) of the results\n",
    "def compute_statistics(results):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return {\n",
    "        'mean': results_df.mean().to_dict(),\n",
    "        'min': results_df.min().to_dict(),\n",
    "        'max': results_df.max().to_dict()\n",
    "    }\n",
    "\n",
    "# Function to save results to CSV\n",
    "def save_results_to_csv(stats_dict, method_name):\n",
    "    data = {}\n",
    "    for model, stats in stats_dict.items():\n",
    "        data[f'{model} (mean)'] = stats['mean']\n",
    "        data[f'{model} (min)'] = stats['min']\n",
    "        data[f'{model} (max)'] = stats['max']\n",
    "    df = pd.DataFrame(data).round(4)\n",
    "    df.to_csv(f'results/{method_name}_results.csv')\n",
    "    return df\n",
    "\n",
    "# Function to plot results with vertical whiskers (metrics on x-axis, models in legend)\n",
    "def plot_results_with_whiskers(stats_dict, title, colors):\n",
    "    metrics = list(stats_dict['Original']['mean'].keys())\n",
    "    models = list(stats_dict.keys())\n",
    "    n_metrics = len(metrics)\n",
    "    n_models = len(models)\n",
    "    \n",
    "    plt.figure(figsize=(11, 6))\n",
    "    x_positions = np.arange(n_metrics) * 1.3\n",
    "    \n",
    "    for model_idx, model in enumerate(models):\n",
    "        means = []\n",
    "        mins = []\n",
    "        maxs = []\n",
    "        for metric in metrics:\n",
    "            means.append(stats_dict[model]['mean'][metric])\n",
    "            mins.append(stats_dict[model]['min'][metric])\n",
    "            maxs.append(stats_dict[model]['max'][metric])\n",
    "        \n",
    "        plt.scatter(x_positions + (model_idx - (n_models-1)/2) * 0.15, means, \n",
    "                    color=colors[model_idx], label=model, s=85) \n",
    "        for metric_idx in range(n_metrics):\n",
    "            plt.vlines(x_positions[metric_idx] + (model_idx - (n_models-1)/2) * 0.15, \n",
    "                       mins[metric_idx], maxs[metric_idx], \n",
    "                       color=colors[model_idx], linestyle='-', linewidth=1)\n",
    "    \n",
    "    plt.xticks(x_positions, metrics, rotation=45, fontdict={'fontsize': 11})\n",
    "    plt.yticks(fontsize=11)\n",
    "    plt.title(title, fontdict={'fontsize': 16, 'weight': 'bold'})\n",
    "    plt.xlabel('Metrics', fontdict={'fontsize': 13})\n",
    "    plt.ylabel('Value', fontdict={'fontsize': 13})\n",
    "    plt.legend(title='Models', bbox_to_anchor=(1, 1), loc='upper left', fontsize=11, title_fontsize=13)  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# All columns are now categorical\n",
    "all_categorical_columns = ['default', 'housing', 'loan', 'job', 'marital', 'education', 'contact', 'poutcome',\n",
    "                           'age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Epsilons and results\n",
    "epsilons = [5, 0.1]\n",
    "results_olh_stats = {}\n",
    "n_iterations = 1\n",
    "\n",
    "# Preprocess original data\n",
    "X_original = X.copy()\n",
    "X = map_binary_columns(X)\n",
    "X = convert_numerics_to_categories(X)\n",
    "X, cat_mappings = map_categorical_columns(X, all_categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4fce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iterations for Original...\n",
      "Iteration 1/1 for method=none, epsilon=None\n",
      "Generating count matrices for Original...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model without privacy (Original)\n",
    "print(\"Running iterations for Original...\")\n",
    "results_original = run_iterations(\n",
    "    X, y, X_original, all_categorical_columns, cat_mappings, method='none', epsilon=None, n_iterations=n_iterations\n",
    ")\n",
    "results_olh_stats['Original'] = compute_statistics(results_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18ba04ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running iterations for OLH (ε=5)...\n",
      "Iteration 1/1 for method=olh, epsilon=5\n",
      "Column default, epsilon=5, d=2\n",
      "Estimated frequencies for column default: [-0.01358625 -0.01358625]\n",
      "Column housing, epsilon=5, d=2\n",
      "Estimated frequencies for column housing: [-0.01358625 -0.01358625]\n",
      "Column loan, epsilon=5, d=2\n",
      "Estimated frequencies for column loan: [-0.01358625 -0.01358625]\n",
      "Column job, epsilon=5, d=12\n",
      "Estimated frequencies for column job: [-0.01358625 -0.01358625 -0.01358625 -0.01358625  2.01076458 -0.01358625\n",
      " -0.01358625 -0.01358625 -0.01358625  2.01076458 -0.01358625 -0.01358625]\n",
      "Column marital, epsilon=5, d=3\n",
      "Estimated frequencies for column marital: [-0.01358625 -0.01358625 -0.01358625]\n",
      "Column education, epsilon=5, d=4\n",
      "Estimated frequencies for column education: [-0.01358625 -0.01358625  2.01076458 -0.01358625]\n",
      "Column contact, epsilon=5, d=3\n",
      "Estimated frequencies for column contact: [-0.01358625 -0.01358625 -0.01358625]\n",
      "Column poutcome, epsilon=5, d=4\n",
      "Estimated frequencies for column poutcome: [-0.01358625 -0.01358625 -0.01358625 -0.01358625]\n",
      "Column age, epsilon=5, d=5\n",
      "Estimated frequencies for column age: [-0.01358625 -0.01358625 -0.01358625  2.01076458 -0.01358625]\n",
      "Column balance, epsilon=5, d=5\n",
      "Estimated frequencies for column balance: [-0.01358625 -0.01358625 -0.01358625 -0.01358625 -0.01358625]\n",
      "Column day, epsilon=5, d=4\n",
      "Estimated frequencies for column day: [-0.01358625 -0.01358625 -0.01358625  2.01076458]\n",
      "Column duration, epsilon=5, d=4\n",
      "Estimated frequencies for column duration: [-0.01358625 -0.01358625  2.01076458 -0.01358625]\n",
      "Column campaign, epsilon=5, d=4\n",
      "Estimated frequencies for column campaign: [-0.01358625 -0.01358625 -0.01358625 -0.01358625]\n",
      "Column pdays, epsilon=5, d=4\n",
      "Estimated frequencies for column pdays: [-0.01358625 -0.01358625 -0.01358625  2.01076458]\n",
      "Column previous, epsilon=5, d=4\n",
      "Estimated frequencies for column previous: [-0.01358625 -0.01358625 -0.01358625 -0.01358625]\n",
      "Generating count matrices for eps_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\.venv\\Lib\\site-packages\\pure_ldp\\core\\_freq_oracle_server.py:73: RuntimeWarning: LHServer has only aggregated small amounts of data (n=1) estimations may be highly inaccurate\n",
      "  warnings.warn(self.name + \" has only aggregated small amounts of data (n=\" + str(self.n) +\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epsilon \u001b[38;5;129;01min\u001b[39;00m epsilons:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning iterations for OLH (ε=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     results_olh \u001b[38;5;241m=\u001b[39m \u001b[43mrun_iterations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_categorical_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_mappings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43molh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iterations\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     results_olh_stats[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mε=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m compute_statistics(results_olh)\n",
      "Cell \u001b[1;32mIn[40], line 179\u001b[0m, in \u001b[0;36mrun_iterations\u001b[1;34m(X, y, X_original, categorical_columns, cat_mappings, method, epsilon, n_iterations)\u001b[0m\n\u001b[0;32m    177\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124molh\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating count matrices for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 179\u001b[0m     \u001b[43mplot_feature_target_count_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_mappings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOLH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m process_data(X_iter, y, categorical_columns, cat_mappings)\n\u001b[0;32m    182\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluate_model(X_train, y_train, X_test, y_test)\n",
      "Cell \u001b[1;32mIn[40], line 86\u001b[0m, in \u001b[0;36mplot_feature_target_count_matrices\u001b[1;34m(X_original, X_privatized, y, categorical_columns, cat_mappings, method, model_name)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_feature_target_count_matrices\u001b[39m(X_original, X_privatized, y, categorical_columns, cat_mappings, method, model_name):\n\u001b[0;32m     85\u001b[0m     df_privatized \u001b[38;5;241m=\u001b[39m X_privatized\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mdf_privatized\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_columns:\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m df_privatized[col]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Models with OLH\n",
    "for epsilon in epsilons:\n",
    "    print(f\"\\nRunning iterations for OLH (ε={epsilon})...\")\n",
    "    results_olh = run_iterations(\n",
    "        X, y, X_original, all_categorical_columns, cat_mappings, method='olh', epsilon=epsilon, n_iterations=n_iterations\n",
    "    )\n",
    "    results_olh_stats[f'ε={epsilon}'] = compute_statistics(results_olh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "735c5d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to CSVs...\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSVs\n",
    "print(\"Saving results to CSVs...\")\n",
    "results_olh_df = save_results_to_csv(results_olh_stats, 'OLH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f8d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors for the models (Original, ε=5, ε=3, ε=1, ε=0.5, ε=0.1)\n",
    "colors = ['#0d4e9e', '#ffc520', '#7b9ca0', '#242624', '#cc7b4f', '#7764B4']\n",
    "\n",
    "# Plot results with vertical whiskers\n",
    "plot_results_with_whiskers(results_olh_stats, 'Comparison of Metrics for Different $\\epsilon$ Values in OLH', colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
