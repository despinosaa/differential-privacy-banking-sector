{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 33)\n"
     ]
    }
   ],
   "source": [
    "# Crear carpetas para resultados y figuras\n",
    "import os\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "data_path = 'C:/Users/danie/OneDrive/Documentos/1 UNIANDES/10 semestre/Tesis/differential-privacy-banking-sector/data/processed/bank-processed.csv'\n",
    "data = pd.read_csv(data_path, sep=',')\n",
    "print(data.shape)\n",
    "\n",
    "# Separar características y variable objetivo\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y']\n",
    "\n",
    "# Definir columnas numéricas\n",
    "numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Escalar columnas numéricas\n",
    "scale = MinMaxScaler()\n",
    "X[numeric_cols] = scale.fit_transform(X[numeric_cols])\n",
    "\n",
    "# Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTEENN para balancear clases\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_resample, y_resample = smoteenn.fit_resample(X_train, y_train)\n",
    "X_resample = pd.DataFrame(X_resample, columns=X.columns)\n",
    "y_resample = pd.Series(y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 26\n"
     ]
    }
   ],
   "source": [
    "# Selección de características con BorutaPy\n",
    "rf = xgb.XGBClassifier(eval_metric='logloss')\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
    "feat_selector.fit(X_resample.values, y_resample.values.ravel())\n",
    "X_filtered = X.columns[feat_selector.support_].tolist()\n",
    "print(f\"Selected features: {len(X_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar datos con las características seleccionadas\n",
    "X_train_filtered = X_resample[X_filtered].values\n",
    "X_test_filtered = X_test[X_filtered].values\n",
    "y_train_filtered = y_resample.values\n",
    "y_test_filtered = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Presupuesto de privacidad: ε=1.06, δ=1e-05\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la red neuronal\n",
    "input_size = len(X_filtered)\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n",
    "\n",
    "batch_size = 32\n",
    "# TODO: Modificar uno a la vez\n",
    "num_microbatches = 32 # Probar otros valores\n",
    "l2_norm_clip = 1.0 # Probar otros valores\n",
    "noise_multiplier = 1.1 # Aumentarlo\n",
    "n_iterations = 5\n",
    "\n",
    "# Calcular el presupuesto de privacidad (ε, δ)\n",
    "n = len(X_train_filtered)\n",
    "delta = 1e-5\n",
    "try:\n",
    "    # En tensorflow-privacy 0.5.0, compute_dp_sgd_privacy tiene un argumento diferente\n",
    "    eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "        n=n,\n",
    "        batch_size=batch_size,\n",
    "        noise_multiplier=noise_multiplier,\n",
    "        epochs=epochs,\n",
    "        delta=delta\n",
    "    )[0]  # Retorna una tupla (eps, optimal_alpha), tomamos eps\n",
    "    print(f\"Presupuesto de privacidad: ε={eps:.2f}, δ={delta}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al calcular el presupuesto de privacidad: {e}\")\n",
    "    eps = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la red neuronal con tf.keras\n",
    "def create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=False):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation='relu', input_shape=(input_size,)))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    if use_dp:\n",
    "        optimizer = DPKerasSGDOptimizer(\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "            num_microbatches=num_microbatches,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Función para entrenar el modelo\n",
    "def train_model(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=False):\n",
    "    model = create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=use_dp)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_prob_test = model.predict(X_test, batch_size=batch_size).flatten()\n",
    "    y_pred_test = (y_pred_prob_test > 0.4).astype(int)\n",
    "    \n",
    "    return y_pred_prob_test, y_pred_test\n",
    "\n",
    "# Función para evaluar el modelo\n",
    "def evaluate_model(y_true, y_pred, y_pred_prob):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    actual_negatives, actual_positives = conf_matrix[0].sum(), conf_matrix[1].sum()\n",
    "    false_positive_rate = conf_matrix[0][1] / actual_negatives if actual_negatives > 0 else 0\n",
    "    false_negative_rate = conf_matrix[1][0] / actual_positives if actual_positives > 0 else 0\n",
    "    return {\n",
    "        'ROC AUC': roc_auc_score(y_true, y_pred_prob),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Type I Error': false_positive_rate,\n",
    "        'Type II Error': false_negative_rate\n",
    "    }\n",
    "\n",
    "# Función para ejecutar múltiples iteraciones y calcular estadísticas\n",
    "def run_iterations(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp, n_iterations):\n",
    "    results = []\n",
    "    for _ in range(n_iterations):\n",
    "        y_pred_prob_test, y_pred_test = train_model(\n",
    "            X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=use_dp\n",
    "        )\n",
    "        result = evaluate_model(y_test, y_pred_test, y_pred_prob_test)\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Función para calcular estadísticas (promedio, mínimo, máximo)\n",
    "def compute_statistics(df):\n",
    "    stats = {\n",
    "        'mean': df.mean(),\n",
    "        'min': df.min(),\n",
    "        'max': df.max()\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo sin DP...\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.5824 - accuracy: 0.6913 - val_loss: 0.5829 - val_accuracy: 0.6835\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.4615 - accuracy: 0.7842 - val_loss: 0.5246 - val_accuracy: 0.7441\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.3784 - accuracy: 0.8395 - val_loss: 0.5178 - val_accuracy: 0.7806\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.3210 - accuracy: 0.8750 - val_loss: 0.4562 - val_accuracy: 0.8280\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.2895 - accuracy: 0.8903 - val_loss: 0.4550 - val_accuracy: 0.8304\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.2736 - accuracy: 0.8971 - val_loss: 0.4654 - val_accuracy: 0.8280\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.2655 - accuracy: 0.8994 - val_loss: 0.4736 - val_accuracy: 0.8235\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.2601 - accuracy: 0.9018 - val_loss: 0.4869 - val_accuracy: 0.8163\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.2543 - accuracy: 0.9040 - val_loss: 0.4355 - val_accuracy: 0.8352\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.2509 - accuracy: 0.9051 - val_loss: 0.4527 - val_accuracy: 0.8273\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.2474 - accuracy: 0.9064 - val_loss: 0.4420 - val_accuracy: 0.8311\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.2457 - accuracy: 0.9081 - val_loss: 0.4702 - val_accuracy: 0.8213\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.2424 - accuracy: 0.9089 - val_loss: 0.4876 - val_accuracy: 0.8123\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.2401 - accuracy: 0.9095 - val_loss: 0.4742 - val_accuracy: 0.8188\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.2373 - accuracy: 0.9107 - val_loss: 0.4290 - val_accuracy: 0.8346\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.2351 - accuracy: 0.9112 - val_loss: 0.4424 - val_accuracy: 0.8310\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.2342 - accuracy: 0.9113 - val_loss: 0.4873 - val_accuracy: 0.8120\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.2321 - accuracy: 0.9124 - val_loss: 0.4645 - val_accuracy: 0.8204\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.2300 - accuracy: 0.9127 - val_loss: 0.4588 - val_accuracy: 0.8238\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.2283 - accuracy: 0.9135 - val_loss: 0.4917 - val_accuracy: 0.8112\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.2270 - accuracy: 0.9137 - val_loss: 0.4841 - val_accuracy: 0.8130\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.2248 - accuracy: 0.9151 - val_loss: 0.4403 - val_accuracy: 0.8316\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.2237 - accuracy: 0.9156 - val_loss: 0.4412 - val_accuracy: 0.8309\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.2219 - accuracy: 0.9161 - val_loss: 0.4442 - val_accuracy: 0.8298\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.2206 - accuracy: 0.9165 - val_loss: 0.5053 - val_accuracy: 0.8058\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.2202 - accuracy: 0.9166 - val_loss: 0.5150 - val_accuracy: 0.7983\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.2176 - accuracy: 0.9169 - val_loss: 0.4492 - val_accuracy: 0.8272\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.2171 - accuracy: 0.9179 - val_loss: 0.4528 - val_accuracy: 0.8254\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2158 - accuracy: 0.9187 - val_loss: 0.4861 - val_accuracy: 0.8123\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.2150 - accuracy: 0.9185 - val_loss: 0.4078 - val_accuracy: 0.8446\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.2134 - accuracy: 0.9187 - val_loss: 0.4647 - val_accuracy: 0.8180\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.2128 - accuracy: 0.9190 - val_loss: 0.4250 - val_accuracy: 0.8338\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.2126 - accuracy: 0.9201 - val_loss: 0.4694 - val_accuracy: 0.8184\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.2109 - accuracy: 0.9203 - val_loss: 0.4149 - val_accuracy: 0.8374\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.2096 - accuracy: 0.9208 - val_loss: 0.5138 - val_accuracy: 0.8067\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.2087 - accuracy: 0.9205 - val_loss: 0.4529 - val_accuracy: 0.8286\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.2076 - accuracy: 0.9212 - val_loss: 0.4796 - val_accuracy: 0.8154\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.2075 - accuracy: 0.9213 - val_loss: 0.4715 - val_accuracy: 0.8234\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.2063 - accuracy: 0.9224 - val_loss: 0.4734 - val_accuracy: 0.8224\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.2057 - accuracy: 0.9214 - val_loss: 0.4632 - val_accuracy: 0.8243\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2055 - accuracy: 0.9221 - val_loss: 0.4448 - val_accuracy: 0.8289\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2050 - accuracy: 0.9228 - val_loss: 0.4707 - val_accuracy: 0.8216\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2034 - accuracy: 0.9227 - val_loss: 0.4977 - val_accuracy: 0.8122\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.2033 - accuracy: 0.9226 - val_loss: 0.4629 - val_accuracy: 0.8236\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.2029 - accuracy: 0.9225 - val_loss: 0.4593 - val_accuracy: 0.8303\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2021 - accuracy: 0.9225 - val_loss: 0.4594 - val_accuracy: 0.8261\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.2015 - accuracy: 0.9238 - val_loss: 0.4857 - val_accuracy: 0.8202\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.2023 - accuracy: 0.9232 - val_loss: 0.4612 - val_accuracy: 0.8270\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.2012 - accuracy: 0.9232 - val_loss: 0.5017 - val_accuracy: 0.8047\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.2010 - accuracy: 0.9238 - val_loss: 0.4659 - val_accuracy: 0.8232\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5953 - accuracy: 0.6787 - val_loss: 0.6054 - val_accuracy: 0.6566\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.4664 - accuracy: 0.7786 - val_loss: 0.5364 - val_accuracy: 0.7264\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.3891 - accuracy: 0.8286 - val_loss: 0.4718 - val_accuracy: 0.8039\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.3315 - accuracy: 0.8676 - val_loss: 0.5073 - val_accuracy: 0.7941\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.2970 - accuracy: 0.8863 - val_loss: 0.4876 - val_accuracy: 0.8112\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.2798 - accuracy: 0.8936 - val_loss: 0.4791 - val_accuracy: 0.8158\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.2708 - accuracy: 0.8969 - val_loss: 0.4882 - val_accuracy: 0.8122\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2652 - accuracy: 0.8995 - val_loss: 0.4801 - val_accuracy: 0.8134\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.2603 - accuracy: 0.8994 - val_loss: 0.4537 - val_accuracy: 0.8241\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2565 - accuracy: 0.9020 - val_loss: 0.5370 - val_accuracy: 0.7934\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.2538 - accuracy: 0.9029 - val_loss: 0.4451 - val_accuracy: 0.8273\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.2507 - accuracy: 0.9043 - val_loss: 0.4373 - val_accuracy: 0.8268\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2489 - accuracy: 0.9060 - val_loss: 0.4735 - val_accuracy: 0.8169\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.2466 - accuracy: 0.9069 - val_loss: 0.4601 - val_accuracy: 0.8200\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.2440 - accuracy: 0.9078 - val_loss: 0.4547 - val_accuracy: 0.8243\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2419 - accuracy: 0.9090 - val_loss: 0.4644 - val_accuracy: 0.8205\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.2400 - accuracy: 0.9093 - val_loss: 0.4793 - val_accuracy: 0.8176\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.2374 - accuracy: 0.9105 - val_loss: 0.4796 - val_accuracy: 0.8126\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.2360 - accuracy: 0.9108 - val_loss: 0.4522 - val_accuracy: 0.8244\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2347 - accuracy: 0.9115 - val_loss: 0.4897 - val_accuracy: 0.8098\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.2321 - accuracy: 0.9124 - val_loss: 0.4588 - val_accuracy: 0.8196\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.2308 - accuracy: 0.9121 - val_loss: 0.4577 - val_accuracy: 0.8207\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.2288 - accuracy: 0.9131 - val_loss: 0.4437 - val_accuracy: 0.8294\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.2277 - accuracy: 0.9135 - val_loss: 0.4860 - val_accuracy: 0.8155\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.2269 - accuracy: 0.9146 - val_loss: 0.5030 - val_accuracy: 0.8040\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.2259 - accuracy: 0.9142 - val_loss: 0.4277 - val_accuracy: 0.8341\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2242 - accuracy: 0.9156 - val_loss: 0.4575 - val_accuracy: 0.8247\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.2229 - accuracy: 0.9160 - val_loss: 0.4768 - val_accuracy: 0.8183\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.2215 - accuracy: 0.9161 - val_loss: 0.4959 - val_accuracy: 0.8109\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.2210 - accuracy: 0.9167 - val_loss: 0.4722 - val_accuracy: 0.8184\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.2190 - accuracy: 0.9173 - val_loss: 0.4362 - val_accuracy: 0.8293\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.2179 - accuracy: 0.9173 - val_loss: 0.4520 - val_accuracy: 0.8248\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.2173 - accuracy: 0.9174 - val_loss: 0.4335 - val_accuracy: 0.8343\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.2170 - accuracy: 0.9176 - val_loss: 0.4792 - val_accuracy: 0.8160\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.2145 - accuracy: 0.9191 - val_loss: 0.4230 - val_accuracy: 0.8387\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.2146 - accuracy: 0.9184 - val_loss: 0.4841 - val_accuracy: 0.8174\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.2141 - accuracy: 0.9186 - val_loss: 0.4759 - val_accuracy: 0.8201\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.2118 - accuracy: 0.9203 - val_loss: 0.4597 - val_accuracy: 0.8211\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2122 - accuracy: 0.9189 - val_loss: 0.4585 - val_accuracy: 0.8262\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.2115 - accuracy: 0.9198 - val_loss: 0.4640 - val_accuracy: 0.8201\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.2100 - accuracy: 0.9206 - val_loss: 0.4618 - val_accuracy: 0.8243\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.2083 - accuracy: 0.9207 - val_loss: 0.4925 - val_accuracy: 0.8126\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.2091 - accuracy: 0.9206 - val_loss: 0.4578 - val_accuracy: 0.8262\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.2080 - accuracy: 0.9207 - val_loss: 0.4369 - val_accuracy: 0.8330\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2072 - accuracy: 0.9213 - val_loss: 0.4644 - val_accuracy: 0.8210\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.2066 - accuracy: 0.9214 - val_loss: 0.4610 - val_accuracy: 0.8242\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.2054 - accuracy: 0.9221 - val_loss: 0.4584 - val_accuracy: 0.8254\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 878us/step - loss: 0.2046 - accuracy: 0.9223 - val_loss: 0.5045 - val_accuracy: 0.8098\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.2039 - accuracy: 0.9225 - val_loss: 0.4861 - val_accuracy: 0.8159\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.2037 - accuracy: 0.9220 - val_loss: 0.4382 - val_accuracy: 0.8351\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5860 - accuracy: 0.6863 - val_loss: 0.5932 - val_accuracy: 0.6642\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.4520 - accuracy: 0.7902 - val_loss: 0.5428 - val_accuracy: 0.7263\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.3779 - accuracy: 0.8380 - val_loss: 0.5097 - val_accuracy: 0.7810\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.3216 - accuracy: 0.8735 - val_loss: 0.4708 - val_accuracy: 0.8179\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2900 - accuracy: 0.8884 - val_loss: 0.4627 - val_accuracy: 0.8272\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2753 - accuracy: 0.8956 - val_loss: 0.4762 - val_accuracy: 0.8233\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2664 - accuracy: 0.8983 - val_loss: 0.4709 - val_accuracy: 0.8226\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2607 - accuracy: 0.9008 - val_loss: 0.4862 - val_accuracy: 0.8165\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2563 - accuracy: 0.9028 - val_loss: 0.4631 - val_accuracy: 0.8258\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2519 - accuracy: 0.9036 - val_loss: 0.4564 - val_accuracy: 0.8278\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2493 - accuracy: 0.9048 - val_loss: 0.5012 - val_accuracy: 0.8076\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2461 - accuracy: 0.9074 - val_loss: 0.4588 - val_accuracy: 0.8242\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.2433 - accuracy: 0.9074 - val_loss: 0.4563 - val_accuracy: 0.8246\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.2410 - accuracy: 0.9095 - val_loss: 0.4318 - val_accuracy: 0.8328\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.2383 - accuracy: 0.9095 - val_loss: 0.4464 - val_accuracy: 0.8290\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.2365 - accuracy: 0.9104 - val_loss: 0.4666 - val_accuracy: 0.8205\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.2350 - accuracy: 0.9105 - val_loss: 0.4294 - val_accuracy: 0.8350\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.2327 - accuracy: 0.9107 - val_loss: 0.4618 - val_accuracy: 0.8190\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.2311 - accuracy: 0.9122 - val_loss: 0.4567 - val_accuracy: 0.8223\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.2297 - accuracy: 0.9130 - val_loss: 0.4949 - val_accuracy: 0.8046\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.2276 - accuracy: 0.9134 - val_loss: 0.4582 - val_accuracy: 0.8205\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.2253 - accuracy: 0.9144 - val_loss: 0.4520 - val_accuracy: 0.8200\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.2241 - accuracy: 0.9150 - val_loss: 0.4746 - val_accuracy: 0.8151\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.2234 - accuracy: 0.9151 - val_loss: 0.4579 - val_accuracy: 0.8196\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.2209 - accuracy: 0.9154 - val_loss: 0.4522 - val_accuracy: 0.8252\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.2198 - accuracy: 0.9158 - val_loss: 0.4557 - val_accuracy: 0.8233\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.2189 - accuracy: 0.9157 - val_loss: 0.4610 - val_accuracy: 0.8189\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.2175 - accuracy: 0.9169 - val_loss: 0.4343 - val_accuracy: 0.8289\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.2166 - accuracy: 0.9175 - val_loss: 0.4280 - val_accuracy: 0.8303\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.2149 - accuracy: 0.9172 - val_loss: 0.4851 - val_accuracy: 0.8098\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2144 - accuracy: 0.9179 - val_loss: 0.4089 - val_accuracy: 0.8449\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.2137 - accuracy: 0.9187 - val_loss: 0.4490 - val_accuracy: 0.8242\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.2122 - accuracy: 0.9185 - val_loss: 0.4342 - val_accuracy: 0.8304\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.2117 - accuracy: 0.9194 - val_loss: 0.4401 - val_accuracy: 0.8293\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.2098 - accuracy: 0.9193 - val_loss: 0.4672 - val_accuracy: 0.8170\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.2093 - accuracy: 0.9204 - val_loss: 0.4063 - val_accuracy: 0.8432\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2084 - accuracy: 0.9205 - val_loss: 0.4469 - val_accuracy: 0.8280\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.2076 - accuracy: 0.9202 - val_loss: 0.4231 - val_accuracy: 0.8360\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.2070 - accuracy: 0.9198 - val_loss: 0.5036 - val_accuracy: 0.8043\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.2062 - accuracy: 0.9215 - val_loss: 0.4531 - val_accuracy: 0.8233\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.2056 - accuracy: 0.9210 - val_loss: 0.4362 - val_accuracy: 0.8325\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.2044 - accuracy: 0.9220 - val_loss: 0.4650 - val_accuracy: 0.8236\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.2030 - accuracy: 0.9219 - val_loss: 0.4456 - val_accuracy: 0.8310\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.2032 - accuracy: 0.9216 - val_loss: 0.4452 - val_accuracy: 0.8278\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.2031 - accuracy: 0.9216 - val_loss: 0.4816 - val_accuracy: 0.8146\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.2022 - accuracy: 0.9221 - val_loss: 0.4709 - val_accuracy: 0.8211\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.2009 - accuracy: 0.9232 - val_loss: 0.4932 - val_accuracy: 0.8120\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2005 - accuracy: 0.9228 - val_loss: 0.5064 - val_accuracy: 0.8075\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2001 - accuracy: 0.9228 - val_loss: 0.4808 - val_accuracy: 0.8189\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.1993 - accuracy: 0.9231 - val_loss: 0.4385 - val_accuracy: 0.8319\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5774 - accuracy: 0.6968 - val_loss: 0.6197 - val_accuracy: 0.6415\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.4479 - accuracy: 0.7941 - val_loss: 0.5208 - val_accuracy: 0.7537\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.3708 - accuracy: 0.8438 - val_loss: 0.4999 - val_accuracy: 0.7980\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.3164 - accuracy: 0.8769 - val_loss: 0.4871 - val_accuracy: 0.8155\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.2875 - accuracy: 0.8899 - val_loss: 0.4938 - val_accuracy: 0.8170\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.2736 - accuracy: 0.8963 - val_loss: 0.5049 - val_accuracy: 0.8095\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2639 - accuracy: 0.8994 - val_loss: 0.4829 - val_accuracy: 0.8178\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.2587 - accuracy: 0.9021 - val_loss: 0.5624 - val_accuracy: 0.7865\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.2542 - accuracy: 0.9037 - val_loss: 0.4584 - val_accuracy: 0.8293\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.2509 - accuracy: 0.9041 - val_loss: 0.4704 - val_accuracy: 0.8225\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.2471 - accuracy: 0.9060 - val_loss: 0.4926 - val_accuracy: 0.8129\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2446 - accuracy: 0.9071 - val_loss: 0.4964 - val_accuracy: 0.8138\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2409 - accuracy: 0.9080 - val_loss: 0.4912 - val_accuracy: 0.8139\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2384 - accuracy: 0.9087 - val_loss: 0.4477 - val_accuracy: 0.8317\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.2357 - accuracy: 0.9108 - val_loss: 0.4971 - val_accuracy: 0.8125\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2327 - accuracy: 0.9106 - val_loss: 0.4713 - val_accuracy: 0.8226\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2310 - accuracy: 0.9123 - val_loss: 0.4284 - val_accuracy: 0.8380\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.2287 - accuracy: 0.9134 - val_loss: 0.4764 - val_accuracy: 0.8224\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2269 - accuracy: 0.9143 - val_loss: 0.5390 - val_accuracy: 0.7949\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.2243 - accuracy: 0.9151 - val_loss: 0.4965 - val_accuracy: 0.8098\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.2222 - accuracy: 0.9157 - val_loss: 0.4503 - val_accuracy: 0.8294\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2206 - accuracy: 0.9156 - val_loss: 0.5129 - val_accuracy: 0.8047\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.2189 - accuracy: 0.9168 - val_loss: 0.4344 - val_accuracy: 0.8348\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2178 - accuracy: 0.9181 - val_loss: 0.4575 - val_accuracy: 0.8293\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.2157 - accuracy: 0.9180 - val_loss: 0.4959 - val_accuracy: 0.8174\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.2146 - accuracy: 0.9192 - val_loss: 0.4616 - val_accuracy: 0.8270\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.2139 - accuracy: 0.9190 - val_loss: 0.4572 - val_accuracy: 0.8299\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2122 - accuracy: 0.9198 - val_loss: 0.4553 - val_accuracy: 0.8282\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.2107 - accuracy: 0.9197 - val_loss: 0.4829 - val_accuracy: 0.8204\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.2091 - accuracy: 0.9208 - val_loss: 0.4635 - val_accuracy: 0.8297\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2083 - accuracy: 0.9214 - val_loss: 0.4762 - val_accuracy: 0.8226\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2078 - accuracy: 0.9206 - val_loss: 0.4725 - val_accuracy: 0.8272\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2069 - accuracy: 0.9223 - val_loss: 0.4838 - val_accuracy: 0.8205\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.2058 - accuracy: 0.9223 - val_loss: 0.4692 - val_accuracy: 0.8258\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2054 - accuracy: 0.9226 - val_loss: 0.4458 - val_accuracy: 0.8324\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2036 - accuracy: 0.9236 - val_loss: 0.4658 - val_accuracy: 0.8246\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2028 - accuracy: 0.9238 - val_loss: 0.4756 - val_accuracy: 0.8243\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2016 - accuracy: 0.9232 - val_loss: 0.4387 - val_accuracy: 0.8380\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2008 - accuracy: 0.9248 - val_loss: 0.4858 - val_accuracy: 0.8213\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.1996 - accuracy: 0.9238 - val_loss: 0.4798 - val_accuracy: 0.8255\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2001 - accuracy: 0.9247 - val_loss: 0.4315 - val_accuracy: 0.8402\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.1988 - accuracy: 0.9240 - val_loss: 0.4351 - val_accuracy: 0.8389\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.1974 - accuracy: 0.9253 - val_loss: 0.4377 - val_accuracy: 0.8373\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.1968 - accuracy: 0.9249 - val_loss: 0.4630 - val_accuracy: 0.8296\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.1966 - accuracy: 0.9254 - val_loss: 0.4621 - val_accuracy: 0.8285\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.1962 - accuracy: 0.9256 - val_loss: 0.4945 - val_accuracy: 0.8167\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.1954 - accuracy: 0.9258 - val_loss: 0.4677 - val_accuracy: 0.8264\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.1945 - accuracy: 0.9257 - val_loss: 0.4462 - val_accuracy: 0.8355\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.1937 - accuracy: 0.9259 - val_loss: 0.4771 - val_accuracy: 0.8236\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.1936 - accuracy: 0.9268 - val_loss: 0.4828 - val_accuracy: 0.8226\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5779 - accuracy: 0.6927 - val_loss: 0.5657 - val_accuracy: 0.7053\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.4436 - accuracy: 0.7961 - val_loss: 0.5740 - val_accuracy: 0.7162\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.3614 - accuracy: 0.8496 - val_loss: 0.4749 - val_accuracy: 0.8112\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.3117 - accuracy: 0.8789 - val_loss: 0.5133 - val_accuracy: 0.8021\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.2884 - accuracy: 0.8900 - val_loss: 0.4379 - val_accuracy: 0.8384\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.2765 - accuracy: 0.8953 - val_loss: 0.4645 - val_accuracy: 0.8289\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.2689 - accuracy: 0.8976 - val_loss: 0.4910 - val_accuracy: 0.8182\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2647 - accuracy: 0.9016 - val_loss: 0.4681 - val_accuracy: 0.8254\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2601 - accuracy: 0.9025 - val_loss: 0.4405 - val_accuracy: 0.8337\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2574 - accuracy: 0.9038 - val_loss: 0.4835 - val_accuracy: 0.8179\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2531 - accuracy: 0.9052 - val_loss: 0.4459 - val_accuracy: 0.8335\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.2496 - accuracy: 0.9064 - val_loss: 0.4943 - val_accuracy: 0.8126\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.2467 - accuracy: 0.9074 - val_loss: 0.4852 - val_accuracy: 0.8172\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.2448 - accuracy: 0.9088 - val_loss: 0.4679 - val_accuracy: 0.8215\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2416 - accuracy: 0.9088 - val_loss: 0.5449 - val_accuracy: 0.7895\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2397 - accuracy: 0.9096 - val_loss: 0.4457 - val_accuracy: 0.8275\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.2366 - accuracy: 0.9102 - val_loss: 0.4640 - val_accuracy: 0.8241\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2345 - accuracy: 0.9112 - val_loss: 0.4941 - val_accuracy: 0.8122\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.2327 - accuracy: 0.9127 - val_loss: 0.4660 - val_accuracy: 0.8215\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.2307 - accuracy: 0.9135 - val_loss: 0.4794 - val_accuracy: 0.8188\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.2286 - accuracy: 0.9136 - val_loss: 0.4646 - val_accuracy: 0.8233\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.2270 - accuracy: 0.9146 - val_loss: 0.4722 - val_accuracy: 0.8209\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.2255 - accuracy: 0.9149 - val_loss: 0.4862 - val_accuracy: 0.8158\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.2238 - accuracy: 0.9153 - val_loss: 0.4366 - val_accuracy: 0.8341\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2222 - accuracy: 0.9162 - val_loss: 0.4929 - val_accuracy: 0.8153\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.2208 - accuracy: 0.9160 - val_loss: 0.4551 - val_accuracy: 0.8265\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.2193 - accuracy: 0.9175 - val_loss: 0.4945 - val_accuracy: 0.8115\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.2181 - accuracy: 0.9173 - val_loss: 0.4824 - val_accuracy: 0.8148\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.2159 - accuracy: 0.9182 - val_loss: 0.4540 - val_accuracy: 0.8266\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.2148 - accuracy: 0.9189 - val_loss: 0.4794 - val_accuracy: 0.8154\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2134 - accuracy: 0.9191 - val_loss: 0.5166 - val_accuracy: 0.8056\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.2126 - accuracy: 0.9193 - val_loss: 0.4605 - val_accuracy: 0.8266\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.2112 - accuracy: 0.9192 - val_loss: 0.4774 - val_accuracy: 0.8201\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2106 - accuracy: 0.9207 - val_loss: 0.4372 - val_accuracy: 0.8336\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.2090 - accuracy: 0.9211 - val_loss: 0.4726 - val_accuracy: 0.8196\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.2086 - accuracy: 0.9195 - val_loss: 0.4635 - val_accuracy: 0.8232\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.2073 - accuracy: 0.9216 - val_loss: 0.4555 - val_accuracy: 0.8283\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.2061 - accuracy: 0.9219 - val_loss: 0.4584 - val_accuracy: 0.8235\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.2050 - accuracy: 0.9225 - val_loss: 0.4784 - val_accuracy: 0.8204\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.2046 - accuracy: 0.9216 - val_loss: 0.4539 - val_accuracy: 0.8230\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.2034 - accuracy: 0.9219 - val_loss: 0.4712 - val_accuracy: 0.8192\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2023 - accuracy: 0.9232 - val_loss: 0.4576 - val_accuracy: 0.8282\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2020 - accuracy: 0.9230 - val_loss: 0.4700 - val_accuracy: 0.8279\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.2023 - accuracy: 0.9230 - val_loss: 0.4722 - val_accuracy: 0.8245\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.2010 - accuracy: 0.9225 - val_loss: 0.4887 - val_accuracy: 0.8194\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.2000 - accuracy: 0.9242 - val_loss: 0.4712 - val_accuracy: 0.8228\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.1989 - accuracy: 0.9245 - val_loss: 0.4704 - val_accuracy: 0.8223\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.1988 - accuracy: 0.9240 - val_loss: 0.4275 - val_accuracy: 0.8407\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.1981 - accuracy: 0.9245 - val_loss: 0.4665 - val_accuracy: 0.8256\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.1974 - accuracy: 0.9252 - val_loss: 0.4716 - val_accuracy: 0.8232\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar iteraciones para cada modelo\n",
    "print(\"Entrenando modelo sin DP...\")\n",
    "results_no_dp = run_iterations(\n",
    "    X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered, \n",
    "    batch_size, epochs, use_dp=False, n_iterations=n_iterations\n",
    ")\n",
    "results_no_dp_stats = compute_statistics(results_no_dp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo con DP...\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.7369 - accuracy: 0.5057 - val_loss: 0.6912 - val_accuracy: 0.5204\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6938 - accuracy: 0.5392 - val_loss: 0.7001 - val_accuracy: 0.4761\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.6845 - accuracy: 0.5610 - val_loss: 0.6947 - val_accuracy: 0.5127\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6793 - accuracy: 0.5724 - val_loss: 0.6891 - val_accuracy: 0.5565\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6737 - accuracy: 0.5858 - val_loss: 0.6877 - val_accuracy: 0.5626\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6690 - accuracy: 0.5955 - val_loss: 0.6820 - val_accuracy: 0.5855\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6642 - accuracy: 0.6053 - val_loss: 0.6782 - val_accuracy: 0.5938\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6618 - accuracy: 0.6123 - val_loss: 0.6731 - val_accuracy: 0.6013\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 408us/step - loss: 0.6580 - accuracy: 0.6189 - val_loss: 0.6735 - val_accuracy: 0.5996\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6536 - accuracy: 0.6279 - val_loss: 0.6679 - val_accuracy: 0.6075\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6514 - accuracy: 0.6319 - val_loss: 0.6651 - val_accuracy: 0.6113\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6460 - accuracy: 0.6411 - val_loss: 0.6620 - val_accuracy: 0.6150\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6434 - accuracy: 0.6418 - val_loss: 0.6581 - val_accuracy: 0.6182\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6408 - accuracy: 0.6459 - val_loss: 0.6571 - val_accuracy: 0.6187\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6364 - accuracy: 0.6540 - val_loss: 0.6552 - val_accuracy: 0.6198\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6343 - accuracy: 0.6540 - val_loss: 0.6501 - val_accuracy: 0.6268\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6316 - accuracy: 0.6576 - val_loss: 0.6534 - val_accuracy: 0.6196\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6291 - accuracy: 0.6621 - val_loss: 0.6460 - val_accuracy: 0.6277\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6263 - accuracy: 0.6624 - val_loss: 0.6435 - val_accuracy: 0.6299\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6238 - accuracy: 0.6656 - val_loss: 0.6438 - val_accuracy: 0.6268\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6205 - accuracy: 0.6686 - val_loss: 0.6406 - val_accuracy: 0.6291\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6178 - accuracy: 0.6727 - val_loss: 0.6336 - val_accuracy: 0.6395\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6162 - accuracy: 0.6707 - val_loss: 0.6329 - val_accuracy: 0.6385\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6136 - accuracy: 0.6772 - val_loss: 0.6316 - val_accuracy: 0.6383\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6107 - accuracy: 0.6763 - val_loss: 0.6347 - val_accuracy: 0.6314\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6091 - accuracy: 0.6812 - val_loss: 0.6324 - val_accuracy: 0.6356\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6069 - accuracy: 0.6803 - val_loss: 0.6317 - val_accuracy: 0.6357\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6050 - accuracy: 0.6832 - val_loss: 0.6278 - val_accuracy: 0.6435\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6026 - accuracy: 0.6852 - val_loss: 0.6311 - val_accuracy: 0.6359\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6005 - accuracy: 0.6866 - val_loss: 0.6182 - val_accuracy: 0.6510\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 400us/step - loss: 0.5986 - accuracy: 0.6893 - val_loss: 0.6190 - val_accuracy: 0.6496\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.5972 - accuracy: 0.6885 - val_loss: 0.6260 - val_accuracy: 0.6434\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.5948 - accuracy: 0.6908 - val_loss: 0.6163 - val_accuracy: 0.6502\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 410us/step - loss: 0.5933 - accuracy: 0.6914 - val_loss: 0.6220 - val_accuracy: 0.6447\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 396us/step - loss: 0.5915 - accuracy: 0.6950 - val_loss: 0.6223 - val_accuracy: 0.6433\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5899 - accuracy: 0.6969 - val_loss: 0.6116 - val_accuracy: 0.6503\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5875 - accuracy: 0.6967 - val_loss: 0.6198 - val_accuracy: 0.6435\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5866 - accuracy: 0.6959 - val_loss: 0.6130 - val_accuracy: 0.6470\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5851 - accuracy: 0.6967 - val_loss: 0.6145 - val_accuracy: 0.6447\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5839 - accuracy: 0.7004 - val_loss: 0.6165 - val_accuracy: 0.6434\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5813 - accuracy: 0.7029 - val_loss: 0.6190 - val_accuracy: 0.6412\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 416us/step - loss: 0.5810 - accuracy: 0.7017 - val_loss: 0.6079 - val_accuracy: 0.6480\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5795 - accuracy: 0.7045 - val_loss: 0.6135 - val_accuracy: 0.6437\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 408us/step - loss: 0.5765 - accuracy: 0.7081 - val_loss: 0.6086 - val_accuracy: 0.6465\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 418us/step - loss: 0.5761 - accuracy: 0.7052 - val_loss: 0.6168 - val_accuracy: 0.6415\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5750 - accuracy: 0.7078 - val_loss: 0.6094 - val_accuracy: 0.6464\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5739 - accuracy: 0.7067 - val_loss: 0.6114 - val_accuracy: 0.6439\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5717 - accuracy: 0.7088 - val_loss: 0.6134 - val_accuracy: 0.6429\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5708 - accuracy: 0.7090 - val_loss: 0.6025 - val_accuracy: 0.6510\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5700 - accuracy: 0.7119 - val_loss: 0.6093 - val_accuracy: 0.6445\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.7068 - accuracy: 0.5373 - val_loss: 0.7487 - val_accuracy: 0.2920\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6815 - accuracy: 0.5644 - val_loss: 0.7079 - val_accuracy: 0.4539\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6725 - accuracy: 0.5878 - val_loss: 0.6964 - val_accuracy: 0.5047\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6674 - accuracy: 0.6032 - val_loss: 0.6908 - val_accuracy: 0.5343\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6616 - accuracy: 0.6152 - val_loss: 0.6822 - val_accuracy: 0.5610\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6573 - accuracy: 0.6260 - val_loss: 0.6765 - val_accuracy: 0.5767\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6525 - accuracy: 0.6362 - val_loss: 0.6774 - val_accuracy: 0.5718\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 406us/step - loss: 0.6470 - accuracy: 0.6461 - val_loss: 0.6734 - val_accuracy: 0.5807\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6436 - accuracy: 0.6497 - val_loss: 0.6652 - val_accuracy: 0.5994\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6394 - accuracy: 0.6536 - val_loss: 0.6634 - val_accuracy: 0.6018\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6365 - accuracy: 0.6591 - val_loss: 0.6629 - val_accuracy: 0.5992\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6323 - accuracy: 0.6639 - val_loss: 0.6580 - val_accuracy: 0.6096\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6296 - accuracy: 0.6661 - val_loss: 0.6607 - val_accuracy: 0.6016\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6268 - accuracy: 0.6708 - val_loss: 0.6529 - val_accuracy: 0.6182\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6247 - accuracy: 0.6693 - val_loss: 0.6507 - val_accuracy: 0.6210\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6217 - accuracy: 0.6725 - val_loss: 0.6464 - val_accuracy: 0.6276\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6185 - accuracy: 0.6781 - val_loss: 0.6451 - val_accuracy: 0.6283\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6169 - accuracy: 0.6771 - val_loss: 0.6472 - val_accuracy: 0.6230\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6143 - accuracy: 0.6794 - val_loss: 0.6424 - val_accuracy: 0.6297\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6123 - accuracy: 0.6808 - val_loss: 0.6341 - val_accuracy: 0.6412\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6097 - accuracy: 0.6836 - val_loss: 0.6373 - val_accuracy: 0.6354\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 414us/step - loss: 0.6084 - accuracy: 0.6839 - val_loss: 0.6330 - val_accuracy: 0.6412\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.6057 - accuracy: 0.6866 - val_loss: 0.6407 - val_accuracy: 0.6319\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 399us/step - loss: 0.6028 - accuracy: 0.6893 - val_loss: 0.6293 - val_accuracy: 0.6445\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6017 - accuracy: 0.6893 - val_loss: 0.6316 - val_accuracy: 0.6414\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6008 - accuracy: 0.6901 - val_loss: 0.6290 - val_accuracy: 0.6455\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5977 - accuracy: 0.6943 - val_loss: 0.6319 - val_accuracy: 0.6422\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5957 - accuracy: 0.6948 - val_loss: 0.6231 - val_accuracy: 0.6525\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5945 - accuracy: 0.6941 - val_loss: 0.6223 - val_accuracy: 0.6541\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5928 - accuracy: 0.6972 - val_loss: 0.6201 - val_accuracy: 0.6571\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5907 - accuracy: 0.6979 - val_loss: 0.6205 - val_accuracy: 0.6562\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5880 - accuracy: 0.7024 - val_loss: 0.6220 - val_accuracy: 0.6547\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5880 - accuracy: 0.7014 - val_loss: 0.6205 - val_accuracy: 0.6558\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5857 - accuracy: 0.7021 - val_loss: 0.6148 - val_accuracy: 0.6616\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5844 - accuracy: 0.7039 - val_loss: 0.6218 - val_accuracy: 0.6539\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5827 - accuracy: 0.7062 - val_loss: 0.6181 - val_accuracy: 0.6581\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5813 - accuracy: 0.7070 - val_loss: 0.6174 - val_accuracy: 0.6581\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5805 - accuracy: 0.7084 - val_loss: 0.6179 - val_accuracy: 0.6574\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5789 - accuracy: 0.7078 - val_loss: 0.6121 - val_accuracy: 0.6631\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5780 - accuracy: 0.7084 - val_loss: 0.6095 - val_accuracy: 0.6646\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5766 - accuracy: 0.7099 - val_loss: 0.6148 - val_accuracy: 0.6605\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5755 - accuracy: 0.7110 - val_loss: 0.6141 - val_accuracy: 0.6606\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5740 - accuracy: 0.7111 - val_loss: 0.6140 - val_accuracy: 0.6600\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5719 - accuracy: 0.7134 - val_loss: 0.6126 - val_accuracy: 0.6614\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 416us/step - loss: 0.5712 - accuracy: 0.7142 - val_loss: 0.6045 - val_accuracy: 0.6664\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 414us/step - loss: 0.5696 - accuracy: 0.7151 - val_loss: 0.6036 - val_accuracy: 0.6667\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 414us/step - loss: 0.5689 - accuracy: 0.7150 - val_loss: 0.6079 - val_accuracy: 0.6643\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 407us/step - loss: 0.5681 - accuracy: 0.7165 - val_loss: 0.6142 - val_accuracy: 0.6593\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.5668 - accuracy: 0.7160 - val_loss: 0.6099 - val_accuracy: 0.6631\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5662 - accuracy: 0.7169 - val_loss: 0.6017 - val_accuracy: 0.6679\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.7950 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0141s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.7141 - accuracy: 0.5001 - val_loss: 0.7288 - val_accuracy: 0.3453\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.7007 - accuracy: 0.5247 - val_loss: 0.7203 - val_accuracy: 0.3844\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6922 - accuracy: 0.5430 - val_loss: 0.7155 - val_accuracy: 0.4158\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6843 - accuracy: 0.5596 - val_loss: 0.7075 - val_accuracy: 0.4593\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6801 - accuracy: 0.5681 - val_loss: 0.7044 - val_accuracy: 0.4757\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6730 - accuracy: 0.5870 - val_loss: 0.6948 - val_accuracy: 0.5156\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6693 - accuracy: 0.5948 - val_loss: 0.6951 - val_accuracy: 0.5169\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6642 - accuracy: 0.6047 - val_loss: 0.6845 - val_accuracy: 0.5566\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6601 - accuracy: 0.6143 - val_loss: 0.6790 - val_accuracy: 0.5713\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6544 - accuracy: 0.6241 - val_loss: 0.6751 - val_accuracy: 0.5766\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6497 - accuracy: 0.6347 - val_loss: 0.6720 - val_accuracy: 0.5817\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 415us/step - loss: 0.6467 - accuracy: 0.6361 - val_loss: 0.6686 - val_accuracy: 0.5885\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 414us/step - loss: 0.6423 - accuracy: 0.6453 - val_loss: 0.6676 - val_accuracy: 0.5907\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 414us/step - loss: 0.6399 - accuracy: 0.6485 - val_loss: 0.6611 - val_accuracy: 0.5998\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 408us/step - loss: 0.6359 - accuracy: 0.6540 - val_loss: 0.6562 - val_accuracy: 0.6082\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6337 - accuracy: 0.6545 - val_loss: 0.6547 - val_accuracy: 0.6086\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6295 - accuracy: 0.6601 - val_loss: 0.6464 - val_accuracy: 0.6174\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6264 - accuracy: 0.6652 - val_loss: 0.6457 - val_accuracy: 0.6175\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6231 - accuracy: 0.6660 - val_loss: 0.6443 - val_accuracy: 0.6192\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6216 - accuracy: 0.6670 - val_loss: 0.6440 - val_accuracy: 0.6188\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6181 - accuracy: 0.6710 - val_loss: 0.6426 - val_accuracy: 0.6188\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6150 - accuracy: 0.6721 - val_loss: 0.6381 - val_accuracy: 0.6226\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6125 - accuracy: 0.6745 - val_loss: 0.6336 - val_accuracy: 0.6272\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6103 - accuracy: 0.6777 - val_loss: 0.6346 - val_accuracy: 0.6245\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6086 - accuracy: 0.6785 - val_loss: 0.6377 - val_accuracy: 0.6174\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6055 - accuracy: 0.6830 - val_loss: 0.6371 - val_accuracy: 0.6172\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6033 - accuracy: 0.6846 - val_loss: 0.6286 - val_accuracy: 0.6280\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6024 - accuracy: 0.6840 - val_loss: 0.6327 - val_accuracy: 0.6211\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5999 - accuracy: 0.6880 - val_loss: 0.6276 - val_accuracy: 0.6287\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5974 - accuracy: 0.6878 - val_loss: 0.6268 - val_accuracy: 0.6295\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.5959 - accuracy: 0.6908 - val_loss: 0.6246 - val_accuracy: 0.6312\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.5955 - accuracy: 0.6890 - val_loss: 0.6292 - val_accuracy: 0.6265\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.5931 - accuracy: 0.6915 - val_loss: 0.6258 - val_accuracy: 0.6300\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.5918 - accuracy: 0.6926 - val_loss: 0.6206 - val_accuracy: 0.6343\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 418us/step - loss: 0.5901 - accuracy: 0.6933 - val_loss: 0.6195 - val_accuracy: 0.6361\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 420us/step - loss: 0.5886 - accuracy: 0.6919 - val_loss: 0.6191 - val_accuracy: 0.6360\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5865 - accuracy: 0.6979 - val_loss: 0.6197 - val_accuracy: 0.6359\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5852 - accuracy: 0.6971 - val_loss: 0.6182 - val_accuracy: 0.6386\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.5846 - accuracy: 0.6974 - val_loss: 0.6220 - val_accuracy: 0.6346\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.5821 - accuracy: 0.6995 - val_loss: 0.6254 - val_accuracy: 0.6292\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5808 - accuracy: 0.7002 - val_loss: 0.6131 - val_accuracy: 0.6431\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5799 - accuracy: 0.7008 - val_loss: 0.6164 - val_accuracy: 0.6413\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5781 - accuracy: 0.7010 - val_loss: 0.6162 - val_accuracy: 0.6416\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.5765 - accuracy: 0.7031 - val_loss: 0.6085 - val_accuracy: 0.6489\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.5758 - accuracy: 0.7037 - val_loss: 0.6142 - val_accuracy: 0.6436\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5745 - accuracy: 0.7057 - val_loss: 0.6156 - val_accuracy: 0.6438\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5735 - accuracy: 0.7046 - val_loss: 0.6159 - val_accuracy: 0.6434\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5722 - accuracy: 0.7077 - val_loss: 0.6063 - val_accuracy: 0.6540\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5701 - accuracy: 0.7090 - val_loss: 0.6055 - val_accuracy: 0.6545\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5693 - accuracy: 0.7092 - val_loss: 0.6132 - val_accuracy: 0.6454\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.7237 - accuracy: 0.4670 - val_loss: 0.7212 - val_accuracy: 0.2741\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.7011 - accuracy: 0.5025 - val_loss: 0.7330 - val_accuracy: 0.2410\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6940 - accuracy: 0.5274 - val_loss: 0.7256 - val_accuracy: 0.2987\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 416us/step - loss: 0.6881 - accuracy: 0.5454 - val_loss: 0.7168 - val_accuracy: 0.3543\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 421us/step - loss: 0.6847 - accuracy: 0.5578 - val_loss: 0.7137 - val_accuracy: 0.3925\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6797 - accuracy: 0.5738 - val_loss: 0.7098 - val_accuracy: 0.4288\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 420us/step - loss: 0.6755 - accuracy: 0.5905 - val_loss: 0.7030 - val_accuracy: 0.4755\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6726 - accuracy: 0.5964 - val_loss: 0.7026 - val_accuracy: 0.4917\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6690 - accuracy: 0.6082 - val_loss: 0.6962 - val_accuracy: 0.5234\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6648 - accuracy: 0.6197 - val_loss: 0.6909 - val_accuracy: 0.5385\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6618 - accuracy: 0.6256 - val_loss: 0.6851 - val_accuracy: 0.5523\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 421us/step - loss: 0.6582 - accuracy: 0.6351 - val_loss: 0.6834 - val_accuracy: 0.5592\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6545 - accuracy: 0.6429 - val_loss: 0.6796 - val_accuracy: 0.5702\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6502 - accuracy: 0.6505 - val_loss: 0.6803 - val_accuracy: 0.5656\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6467 - accuracy: 0.6582 - val_loss: 0.6729 - val_accuracy: 0.5800\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.6430 - accuracy: 0.6635 - val_loss: 0.6672 - val_accuracy: 0.5928\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6409 - accuracy: 0.6639 - val_loss: 0.6667 - val_accuracy: 0.5926\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6383 - accuracy: 0.6672 - val_loss: 0.6636 - val_accuracy: 0.5973\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6348 - accuracy: 0.6730 - val_loss: 0.6632 - val_accuracy: 0.5962\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6329 - accuracy: 0.6752 - val_loss: 0.6596 - val_accuracy: 0.6027\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6305 - accuracy: 0.6789 - val_loss: 0.6591 - val_accuracy: 0.6028\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6280 - accuracy: 0.6804 - val_loss: 0.6554 - val_accuracy: 0.6088\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6251 - accuracy: 0.6853 - val_loss: 0.6525 - val_accuracy: 0.6119\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6232 - accuracy: 0.6838 - val_loss: 0.6480 - val_accuracy: 0.6193\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6204 - accuracy: 0.6854 - val_loss: 0.6490 - val_accuracy: 0.6151\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6180 - accuracy: 0.6870 - val_loss: 0.6430 - val_accuracy: 0.6227\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6145 - accuracy: 0.6916 - val_loss: 0.6417 - val_accuracy: 0.6236\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6127 - accuracy: 0.6924 - val_loss: 0.6424 - val_accuracy: 0.6211\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6103 - accuracy: 0.6925 - val_loss: 0.6398 - val_accuracy: 0.6235\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6083 - accuracy: 0.6940 - val_loss: 0.6351 - val_accuracy: 0.6294\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6060 - accuracy: 0.6964 - val_loss: 0.6373 - val_accuracy: 0.6256\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 418us/step - loss: 0.6033 - accuracy: 0.6965 - val_loss: 0.6334 - val_accuracy: 0.6304\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 420us/step - loss: 0.6006 - accuracy: 0.7000 - val_loss: 0.6300 - val_accuracy: 0.6335\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.5997 - accuracy: 0.6993 - val_loss: 0.6283 - val_accuracy: 0.6349\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5977 - accuracy: 0.6994 - val_loss: 0.6243 - val_accuracy: 0.6395\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5964 - accuracy: 0.7036 - val_loss: 0.6316 - val_accuracy: 0.6289\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5936 - accuracy: 0.7037 - val_loss: 0.6309 - val_accuracy: 0.6294\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.5918 - accuracy: 0.7045 - val_loss: 0.6255 - val_accuracy: 0.6365\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 421us/step - loss: 0.5893 - accuracy: 0.7057 - val_loss: 0.6214 - val_accuracy: 0.6427\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5883 - accuracy: 0.7045 - val_loss: 0.6188 - val_accuracy: 0.6457\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5867 - accuracy: 0.7073 - val_loss: 0.6257 - val_accuracy: 0.6347\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5845 - accuracy: 0.7085 - val_loss: 0.6242 - val_accuracy: 0.6367\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5834 - accuracy: 0.7101 - val_loss: 0.6158 - val_accuracy: 0.6477\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5819 - accuracy: 0.7099 - val_loss: 0.6140 - val_accuracy: 0.6491\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5790 - accuracy: 0.7121 - val_loss: 0.6144 - val_accuracy: 0.6488\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5776 - accuracy: 0.7132 - val_loss: 0.6112 - val_accuracy: 0.6517\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 410us/step - loss: 0.5773 - accuracy: 0.7137 - val_loss: 0.6101 - val_accuracy: 0.6521\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 415us/step - loss: 0.5759 - accuracy: 0.7132 - val_loss: 0.6056 - val_accuracy: 0.6577\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 417us/step - loss: 0.5732 - accuracy: 0.7164 - val_loss: 0.6123 - val_accuracy: 0.6487\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 417us/step - loss: 0.5722 - accuracy: 0.7165 - val_loss: 0.6066 - val_accuracy: 0.6553\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6824 - accuracy: 0.5575 - val_loss: 0.7059 - val_accuracy: 0.4301\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 421us/step - loss: 0.6775 - accuracy: 0.5750 - val_loss: 0.7059 - val_accuracy: 0.4384\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6743 - accuracy: 0.5864 - val_loss: 0.7067 - val_accuracy: 0.4470\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6707 - accuracy: 0.5970 - val_loss: 0.7011 - val_accuracy: 0.4842\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6676 - accuracy: 0.6041 - val_loss: 0.6959 - val_accuracy: 0.5077\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6643 - accuracy: 0.6142 - val_loss: 0.6938 - val_accuracy: 0.5187\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6607 - accuracy: 0.6241 - val_loss: 0.6918 - val_accuracy: 0.5299\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6574 - accuracy: 0.6294 - val_loss: 0.6883 - val_accuracy: 0.5454\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6543 - accuracy: 0.6379 - val_loss: 0.6845 - val_accuracy: 0.5613\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6505 - accuracy: 0.6415 - val_loss: 0.6758 - val_accuracy: 0.5875\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6473 - accuracy: 0.6494 - val_loss: 0.6794 - val_accuracy: 0.5772\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.6457 - accuracy: 0.6479 - val_loss: 0.6714 - val_accuracy: 0.5956\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.6428 - accuracy: 0.6537 - val_loss: 0.6713 - val_accuracy: 0.5994\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.6396 - accuracy: 0.6569 - val_loss: 0.6667 - val_accuracy: 0.6072\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 414us/step - loss: 0.6365 - accuracy: 0.6609 - val_loss: 0.6608 - val_accuracy: 0.6136\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6343 - accuracy: 0.6617 - val_loss: 0.6616 - val_accuracy: 0.6119\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6312 - accuracy: 0.6679 - val_loss: 0.6559 - val_accuracy: 0.6188\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 420us/step - loss: 0.6292 - accuracy: 0.6668 - val_loss: 0.6524 - val_accuracy: 0.6234\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 418us/step - loss: 0.6265 - accuracy: 0.6710 - val_loss: 0.6491 - val_accuracy: 0.6278\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.6239 - accuracy: 0.6743 - val_loss: 0.6456 - val_accuracy: 0.6323\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 420us/step - loss: 0.6217 - accuracy: 0.6741 - val_loss: 0.6471 - val_accuracy: 0.6283\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6187 - accuracy: 0.6767 - val_loss: 0.6448 - val_accuracy: 0.6294\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6177 - accuracy: 0.6778 - val_loss: 0.6452 - val_accuracy: 0.6287\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6144 - accuracy: 0.6801 - val_loss: 0.6369 - val_accuracy: 0.6440\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6132 - accuracy: 0.6825 - val_loss: 0.6383 - val_accuracy: 0.6396\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6106 - accuracy: 0.6836 - val_loss: 0.6338 - val_accuracy: 0.6455\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6086 - accuracy: 0.6863 - val_loss: 0.6338 - val_accuracy: 0.6438\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6071 - accuracy: 0.6843 - val_loss: 0.6325 - val_accuracy: 0.6439\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6051 - accuracy: 0.6867 - val_loss: 0.6272 - val_accuracy: 0.6504\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6024 - accuracy: 0.6901 - val_loss: 0.6248 - val_accuracy: 0.6520\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6005 - accuracy: 0.6919 - val_loss: 0.6321 - val_accuracy: 0.6413\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5987 - accuracy: 0.6922 - val_loss: 0.6263 - val_accuracy: 0.6465\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5960 - accuracy: 0.6934 - val_loss: 0.6229 - val_accuracy: 0.6495\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5948 - accuracy: 0.6964 - val_loss: 0.6254 - val_accuracy: 0.6460\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.5931 - accuracy: 0.6968 - val_loss: 0.6205 - val_accuracy: 0.6506\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5912 - accuracy: 0.6973 - val_loss: 0.6202 - val_accuracy: 0.6499\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5892 - accuracy: 0.7025 - val_loss: 0.6212 - val_accuracy: 0.6465\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5876 - accuracy: 0.6995 - val_loss: 0.6224 - val_accuracy: 0.6429\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5872 - accuracy: 0.7020 - val_loss: 0.6181 - val_accuracy: 0.6465\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5853 - accuracy: 0.7032 - val_loss: 0.6114 - val_accuracy: 0.6528\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5842 - accuracy: 0.7023 - val_loss: 0.6129 - val_accuracy: 0.6501\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 417us/step - loss: 0.5812 - accuracy: 0.7057 - val_loss: 0.6139 - val_accuracy: 0.6481\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5804 - accuracy: 0.7046 - val_loss: 0.6130 - val_accuracy: 0.6488\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.5786 - accuracy: 0.7077 - val_loss: 0.6080 - val_accuracy: 0.6541\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.5770 - accuracy: 0.7087 - val_loss: 0.6087 - val_accuracy: 0.6544\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5766 - accuracy: 0.7085 - val_loss: 0.6082 - val_accuracy: 0.6548\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5753 - accuracy: 0.7091 - val_loss: 0.6116 - val_accuracy: 0.6500\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5740 - accuracy: 0.7096 - val_loss: 0.6116 - val_accuracy: 0.6501\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5720 - accuracy: 0.7122 - val_loss: 0.6076 - val_accuracy: 0.6548\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.5702 - accuracy: 0.7122 - val_loss: 0.6081 - val_accuracy: 0.6542\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEntrenando modelo con DP...\")\n",
    "results_dp = run_iterations(\n",
    "    X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered, \n",
    "    batch_size, epochs, use_dp=True, n_iterations=n_iterations\n",
    ")\n",
    "results_dp_stats = compute_statistics(results_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados guardados en 'results/CDP_results.csv'\n",
      "\n",
      "Resultados (Promedios):\n",
      "                No DP (mean)  DP (ε=1.06) (mean)\n",
      "ROC AUC              0.9009              0.7338\n",
      "Accuracy             0.8099              0.4978\n",
      "Precision            0.3662              0.1689\n",
      "Recall               0.8543              0.8389\n",
      "F1 Score             0.5126              0.2811\n",
      "Type I Error         0.1960              0.5474\n",
      "Type II Error        0.1457              0.1611\n"
     ]
    }
   ],
   "source": [
    "# Guardar resultados en un CSV\n",
    "results_stats = {\n",
    "    'No DP': results_no_dp_stats,\n",
    "    f'DP (ε={eps:.2f})': results_dp_stats\n",
    "}\n",
    "data = {}\n",
    "for model, stats in results_stats.items():\n",
    "    data[f'{model} (mean)'] = stats['mean']\n",
    "    data[f'{model} (min)'] = stats['min']\n",
    "    data[f'{model} (max)'] = stats['max']\n",
    "results_df = pd.DataFrame(data).round(4)\n",
    "results_df.to_csv('results/CDP_results.csv')\n",
    "print(\"\\nResultados guardados en 'results/CDP_results.csv'\")\n",
    "print(\"\\nResultados (Promedios):\\n\", results_df[[col for col in results_df.columns if 'mean' in col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficas\n",
    "def plot_results_with_whiskers(stats_dict, title, colors):\n",
    "    metrics = list(stats_dict['No DP']['mean'].keys())\n",
    "    models = list(stats_dict.keys())\n",
    "    n_metrics = len(metrics)\n",
    "    n_models = len(models)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x_positions = np.arange(n_metrics)\n",
    "    \n",
    "    for model_idx, model in enumerate(models):\n",
    "        means = []\n",
    "        mins = []\n",
    "        maxs = []\n",
    "        for metric in metrics:\n",
    "            means.append(stats_dict[model]['mean'][metric])\n",
    "            mins.append(stats_dict[model]['min'][metric])\n",
    "            maxs.append(stats_dict[model]['max'][metric])\n",
    "        \n",
    "        plt.scatter(x_positions + (model_idx - (n_models-1)/2) * 0.15, means, \n",
    "                    color=colors[model_idx], label=model, s=100)\n",
    "        for metric_idx in range(n_metrics):\n",
    "            plt.vlines(x_positions[metric_idx] + (model_idx - (n_models-1)/2) * 0.15, \n",
    "                       mins[metric_idx], maxs[metric_idx], \n",
    "                       color=colors[model_idx], linestyle='-', linewidth=1)\n",
    "    \n",
    "    plt.xticks(x_positions, metrics, rotation=45)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(title='Models', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/{title.replace(\" \", \"_\").replace(\"=\", \"\")}.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Colores para los modelos\n",
    "colores = ['#0d4e9e', '#ffc520']\n",
    "\n",
    "# Graficar resultados\n",
    "plot_results_with_whiskers(results_stats, f'Comparación de métricas: Sin DP vs DP (ε={eps:.2f})', colores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
