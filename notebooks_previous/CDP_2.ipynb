{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b36324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e24fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 33)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "data_path = 'C:/Users/danie/OneDrive/Documentos/1 UNIANDES/10 semestre/Tesis/differential-privacy-banking-sector/data/processed/bank-processed.csv'\n",
    "data = pd.read_csv(data_path, sep=',')\n",
    "print(data.shape)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y']\n",
    "\n",
    "# Define numeric columns\n",
    "numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Scale numeric columns\n",
    "scale = MinMaxScaler()\n",
    "X[numeric_cols] = scale.fit_transform(X[numeric_cols])\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "752f6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply SMOTEENN for class balancing\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_resample, y_resample = smoteenn.fit_resample(X_train, y_train)\n",
    "X_resample = pd.DataFrame(X_resample, columns=X.columns)\n",
    "y_resample = pd.Series(y_resample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5300aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 26\n"
     ]
    }
   ],
   "source": [
    "# Feature selection with BorutaPy\n",
    "rf = xgb.XGBClassifier(eval_metric='logloss')\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
    "feat_selector.fit(X_resample.values, y_resample.values.ravel())\n",
    "X_filtered = X.columns[feat_selector.support_].tolist()\n",
    "print(f\"Selected features: {len(X_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cacdacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data with selected features\n",
    "X_train_filtered = X_resample[X_filtered].values\n",
    "X_test_filtered = X_test[X_filtered].values\n",
    "y_train_filtered = y_resample.values\n",
    "y_test_filtered = y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e653b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neural network parameters\n",
    "input_size = len(X_filtered)\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.001 # previously 0.0001\n",
    "epochs = 50\n",
    "n_iterations = 3\n",
    "# num_microbatches = batch_size\n",
    "l2_norm_clip = 1.0\n",
    "\n",
    "# Define parameter values to test\n",
    "batch_size_values = [16, 32, 64, 128]\n",
    "sample_size_ratio_values = [1, 0.5, 0.1, 0.05]\n",
    "noise_multiplier_values = [1.1, 1.5, 2.0, 2.5]\n",
    "\n",
    "# Fixed default values\n",
    "default_noise_multiplier = 1.1\n",
    "default_batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9916dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute privacy budget\n",
    "def compute_privacy_budget(n, batch_size, noise_multiplier, epochs, delta=1e-5):\n",
    "    try:\n",
    "        eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "            n=n, batch_size=batch_size, noise_multiplier=noise_multiplier,\n",
    "            epochs=epochs, delta=delta\n",
    "        )[0]\n",
    "        return eps\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing privacy budget: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Define neural network model\n",
    "def create_model(input_size, hidden_units, hidden_layers, dropout_rate, num_microbatches, use_dp=False,\n",
    "                 l2_norm_clip=l2_norm_clip, noise_multiplier=1.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation='relu', input_shape=(input_size,)))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if use_dp:\n",
    "        optimizer = DPKerasSGDOptimizer(\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "            num_microbatches=num_microbatches,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to train model\n",
    "def train_model(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=False,\n",
    "                l2_norm_clip=l2_norm_clip, noise_multiplier=1.1):\n",
    "    model = create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=use_dp, \n",
    "                         num_microbatches=batch_size, l2_norm_clip=l2_norm_clip, noise_multiplier=noise_multiplier)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    \n",
    "    y_pred_prob_test = model.predict(X_test, batch_size=batch_size).flatten()\n",
    "    y_pred_test = (y_pred_prob_test > 0.5).astype(int)\n",
    "    \n",
    "    return y_pred_prob_test, y_pred_test\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(y_true, y_pred, y_pred_prob):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    actual_negatives, actual_positives = conf_matrix[0].sum(), conf_matrix[1].sum()\n",
    "    false_positive_rate = conf_matrix[0][1] / actual_negatives if actual_negatives > 0 else 0\n",
    "    false_negative_rate = conf_matrix[1][0] / actual_positives if actual_positives > 0 else 0\n",
    "    return {\n",
    "        'ROC AUC': roc_auc_score(y_true, y_pred_prob),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Type I Error': false_positive_rate,\n",
    "        'Type II Error': false_negative_rate\n",
    "    }\n",
    "\n",
    "# Function to run multiple iterations\n",
    "def run_iterations(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp, n_iterations, \n",
    "                   l2_norm_clip, noise_multiplier):\n",
    "    results = []\n",
    "    for _ in range(n_iterations):\n",
    "        y_pred_prob_test, y_pred_test = train_model(\n",
    "            X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=use_dp,\n",
    "            l2_norm_clip=l2_norm_clip, noise_multiplier=noise_multiplier\n",
    "        )\n",
    "        result = evaluate_model(y_test, y_pred_test, y_pred_prob_test)\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to compute statistics\n",
    "def compute_statistics(df):\n",
    "    stats = {\n",
    "        'mean': df.mean(),\n",
    "        'min': df.min(),\n",
    "        'max': df.max()\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "# Function to subsample training data\n",
    "def subsample_data(X, y, sample_size_ratio, random_state=42):\n",
    "    if sample_size_ratio >= 1.0:\n",
    "        return X, y\n",
    "    n_samples = int(len(X) * sample_size_ratio)\n",
    "    idx = np.random.choice(len(X), n_samples, replace=False)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1690fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model without DP...\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 3s 836us/step - loss: 0.3240 - accuracy: 0.8624 - val_loss: 0.4212 - val_accuracy: 0.8359\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 703us/step - loss: 0.2438 - accuracy: 0.9059 - val_loss: 0.4857 - val_accuracy: 0.8095\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 694us/step - loss: 0.2269 - accuracy: 0.9109 - val_loss: 0.4242 - val_accuracy: 0.8403\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 686us/step - loss: 0.2159 - accuracy: 0.9158 - val_loss: 0.4312 - val_accuracy: 0.8348\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 698us/step - loss: 0.2081 - accuracy: 0.9188 - val_loss: 0.5144 - val_accuracy: 0.7848\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 675us/step - loss: 0.2010 - accuracy: 0.9227 - val_loss: 0.4209 - val_accuracy: 0.8376\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 689us/step - loss: 0.1972 - accuracy: 0.9235 - val_loss: 0.4657 - val_accuracy: 0.8233\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 674us/step - loss: 0.1915 - accuracy: 0.9274 - val_loss: 0.4243 - val_accuracy: 0.8296\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 672us/step - loss: 0.1867 - accuracy: 0.9282 - val_loss: 0.4571 - val_accuracy: 0.8267\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 3s 784us/step - loss: 0.1844 - accuracy: 0.9279 - val_loss: 0.4331 - val_accuracy: 0.8456\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 685us/step - loss: 0.1820 - accuracy: 0.9310 - val_loss: 0.4163 - val_accuracy: 0.8466\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 675us/step - loss: 0.1790 - accuracy: 0.9319 - val_loss: 0.4952 - val_accuracy: 0.8307\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 725us/step - loss: 0.1763 - accuracy: 0.9331 - val_loss: 0.4911 - val_accuracy: 0.8244\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 702us/step - loss: 0.1742 - accuracy: 0.9334 - val_loss: 0.4732 - val_accuracy: 0.8293\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 698us/step - loss: 0.1713 - accuracy: 0.9356 - val_loss: 0.4729 - val_accuracy: 0.8303\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 680us/step - loss: 0.1685 - accuracy: 0.9359 - val_loss: 0.4692 - val_accuracy: 0.8367\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 694us/step - loss: 0.1665 - accuracy: 0.9366 - val_loss: 0.4858 - val_accuracy: 0.8295\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 727us/step - loss: 0.1646 - accuracy: 0.9389 - val_loss: 0.4670 - val_accuracy: 0.8301\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 678us/step - loss: 0.1630 - accuracy: 0.9378 - val_loss: 0.5325 - val_accuracy: 0.8106\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 702us/step - loss: 0.1617 - accuracy: 0.9397 - val_loss: 0.5284 - val_accuracy: 0.8092\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 697us/step - loss: 0.1608 - accuracy: 0.9390 - val_loss: 0.4953 - val_accuracy: 0.8280\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 3s 753us/step - loss: 0.1587 - accuracy: 0.9394 - val_loss: 0.5461 - val_accuracy: 0.8098\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 3s 752us/step - loss: 0.1581 - accuracy: 0.9408 - val_loss: 0.4784 - val_accuracy: 0.8303\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 677us/step - loss: 0.1553 - accuracy: 0.9411 - val_loss: 0.5173 - val_accuracy: 0.8263\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 714us/step - loss: 0.1539 - accuracy: 0.9425 - val_loss: 0.5999 - val_accuracy: 0.7939\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 731us/step - loss: 0.1517 - accuracy: 0.9430 - val_loss: 0.5151 - val_accuracy: 0.8378\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 714us/step - loss: 0.1520 - accuracy: 0.9430 - val_loss: 0.4675 - val_accuracy: 0.8442\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 720us/step - loss: 0.1504 - accuracy: 0.9436 - val_loss: 0.4564 - val_accuracy: 0.8505\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 699us/step - loss: 0.1506 - accuracy: 0.9428 - val_loss: 0.5219 - val_accuracy: 0.8215\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 743us/step - loss: 0.1492 - accuracy: 0.9440 - val_loss: 0.4845 - val_accuracy: 0.8465\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 703us/step - loss: 0.1492 - accuracy: 0.9435 - val_loss: 0.4917 - val_accuracy: 0.8393\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 724us/step - loss: 0.1466 - accuracy: 0.9451 - val_loss: 0.4563 - val_accuracy: 0.8551\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 708us/step - loss: 0.1455 - accuracy: 0.9452 - val_loss: 0.4147 - val_accuracy: 0.8672\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 671us/step - loss: 0.1436 - accuracy: 0.9468 - val_loss: 0.5223 - val_accuracy: 0.8285\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 659us/step - loss: 0.1428 - accuracy: 0.9464 - val_loss: 0.5531 - val_accuracy: 0.8277\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.1421 - accuracy: 0.9463 - val_loss: 0.5491 - val_accuracy: 0.8309\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 661us/step - loss: 0.1420 - accuracy: 0.9463 - val_loss: 0.5096 - val_accuracy: 0.8381\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.1409 - accuracy: 0.9474 - val_loss: 0.5000 - val_accuracy: 0.8435\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.1404 - accuracy: 0.9460 - val_loss: 0.5746 - val_accuracy: 0.8249\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.1395 - accuracy: 0.9472 - val_loss: 0.4924 - val_accuracy: 0.8473\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.1382 - accuracy: 0.9477 - val_loss: 0.5144 - val_accuracy: 0.8400\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.1362 - accuracy: 0.9487 - val_loss: 0.4767 - val_accuracy: 0.8453\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.1359 - accuracy: 0.9486 - val_loss: 0.5550 - val_accuracy: 0.8253\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.1362 - accuracy: 0.9492 - val_loss: 0.5170 - val_accuracy: 0.8408\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.1355 - accuracy: 0.9495 - val_loss: 0.5333 - val_accuracy: 0.8311\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.1336 - accuracy: 0.9504 - val_loss: 0.5571 - val_accuracy: 0.8261\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.1337 - accuracy: 0.9492 - val_loss: 0.5369 - val_accuracy: 0.8330\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.1342 - accuracy: 0.9492 - val_loss: 0.5458 - val_accuracy: 0.8326\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.1320 - accuracy: 0.9504 - val_loss: 0.5679 - val_accuracy: 0.8223\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.1307 - accuracy: 0.9510 - val_loss: 0.5467 - val_accuracy: 0.8441\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.3258 - accuracy: 0.8621 - val_loss: 0.6469 - val_accuracy: 0.7333\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.2481 - accuracy: 0.9037 - val_loss: 0.5884 - val_accuracy: 0.7637\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.2308 - accuracy: 0.9096 - val_loss: 0.3994 - val_accuracy: 0.8382\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.2192 - accuracy: 0.9146 - val_loss: 0.4123 - val_accuracy: 0.8399\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.2108 - accuracy: 0.9191 - val_loss: 0.4021 - val_accuracy: 0.8460\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.2025 - accuracy: 0.9218 - val_loss: 0.4513 - val_accuracy: 0.8306\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.1982 - accuracy: 0.9240 - val_loss: 0.4638 - val_accuracy: 0.8342\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.1936 - accuracy: 0.9264 - val_loss: 0.4594 - val_accuracy: 0.8328\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.1892 - accuracy: 0.9282 - val_loss: 0.4595 - val_accuracy: 0.8383\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.1852 - accuracy: 0.9297 - val_loss: 0.4871 - val_accuracy: 0.8194\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.1809 - accuracy: 0.9325 - val_loss: 0.4631 - val_accuracy: 0.8450\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.1786 - accuracy: 0.9326 - val_loss: 0.5004 - val_accuracy: 0.8246\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.1769 - accuracy: 0.9339 - val_loss: 0.4744 - val_accuracy: 0.8388\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.1732 - accuracy: 0.9348 - val_loss: 0.4587 - val_accuracy: 0.8470\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.1708 - accuracy: 0.9359 - val_loss: 0.4694 - val_accuracy: 0.8379\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.1694 - accuracy: 0.9358 - val_loss: 0.4378 - val_accuracy: 0.8564\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.1668 - accuracy: 0.9378 - val_loss: 0.4825 - val_accuracy: 0.8326\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.1633 - accuracy: 0.9400 - val_loss: 0.4503 - val_accuracy: 0.8434\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.1623 - accuracy: 0.9394 - val_loss: 0.5105 - val_accuracy: 0.8255\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.1599 - accuracy: 0.9398 - val_loss: 0.5147 - val_accuracy: 0.8305\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.1602 - accuracy: 0.9395 - val_loss: 0.4532 - val_accuracy: 0.8541\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.1585 - accuracy: 0.9399 - val_loss: 0.4828 - val_accuracy: 0.8349\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.1566 - accuracy: 0.9407 - val_loss: 0.4841 - val_accuracy: 0.8410\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.1562 - accuracy: 0.9406 - val_loss: 0.4777 - val_accuracy: 0.8517\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.1550 - accuracy: 0.9414 - val_loss: 0.4934 - val_accuracy: 0.8402\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.1533 - accuracy: 0.9421 - val_loss: 0.4782 - val_accuracy: 0.8415\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.1514 - accuracy: 0.9434 - val_loss: 0.5018 - val_accuracy: 0.8421\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.1504 - accuracy: 0.9428 - val_loss: 0.5875 - val_accuracy: 0.8182\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.1481 - accuracy: 0.9444 - val_loss: 0.5162 - val_accuracy: 0.8362\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.1482 - accuracy: 0.9445 - val_loss: 0.5469 - val_accuracy: 0.8319\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.1463 - accuracy: 0.9450 - val_loss: 0.6465 - val_accuracy: 0.8146\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.1472 - accuracy: 0.9452 - val_loss: 0.5039 - val_accuracy: 0.8455\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.1458 - accuracy: 0.9452 - val_loss: 0.5440 - val_accuracy: 0.8339\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.1437 - accuracy: 0.9461 - val_loss: 0.5525 - val_accuracy: 0.8343\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.1420 - accuracy: 0.9469 - val_loss: 0.5342 - val_accuracy: 0.8252\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 3s 795us/step - loss: 0.1432 - accuracy: 0.9455 - val_loss: 0.5633 - val_accuracy: 0.8199\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 3s 749us/step - loss: 0.1417 - accuracy: 0.9470 - val_loss: 0.6262 - val_accuracy: 0.8068\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 688us/step - loss: 0.1398 - accuracy: 0.9466 - val_loss: 0.5198 - val_accuracy: 0.8388\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 699us/step - loss: 0.1394 - accuracy: 0.9474 - val_loss: 0.5274 - val_accuracy: 0.8475\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 681us/step - loss: 0.1384 - accuracy: 0.9475 - val_loss: 0.5543 - val_accuracy: 0.8350\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 693us/step - loss: 0.1382 - accuracy: 0.9485 - val_loss: 0.6060 - val_accuracy: 0.8355\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 704us/step - loss: 0.1381 - accuracy: 0.9472 - val_loss: 0.5728 - val_accuracy: 0.8369\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 674us/step - loss: 0.1356 - accuracy: 0.9487 - val_loss: 0.5509 - val_accuracy: 0.8419\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 711us/step - loss: 0.1350 - accuracy: 0.9493 - val_loss: 0.5685 - val_accuracy: 0.8401\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 683us/step - loss: 0.1364 - accuracy: 0.9498 - val_loss: 0.5739 - val_accuracy: 0.8430\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 690us/step - loss: 0.1347 - accuracy: 0.9498 - val_loss: 0.5358 - val_accuracy: 0.8558\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 690us/step - loss: 0.1339 - accuracy: 0.9498 - val_loss: 0.6186 - val_accuracy: 0.8297\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 673us/step - loss: 0.1332 - accuracy: 0.9499 - val_loss: 0.5745 - val_accuracy: 0.8509\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 703us/step - loss: 0.1330 - accuracy: 0.9507 - val_loss: 0.6037 - val_accuracy: 0.8315\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 682us/step - loss: 0.1317 - accuracy: 0.9507 - val_loss: 0.5700 - val_accuracy: 0.8415\n",
      "Epoch 1/50\n",
      "3334/3344 [============================>.] - ETA: 0s - loss: 0.3314 - accuracy: 0.8569WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 704us/step - loss: 0.3312 - accuracy: 0.8569 - val_loss: 0.5837 - val_accuracy: 0.7611\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 729us/step - loss: 0.2495 - accuracy: 0.9025 - val_loss: 0.4241 - val_accuracy: 0.8305\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 699us/step - loss: 0.2322 - accuracy: 0.9086 - val_loss: 0.4822 - val_accuracy: 0.8191\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 719us/step - loss: 0.2206 - accuracy: 0.9137 - val_loss: 0.4980 - val_accuracy: 0.8038\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 703us/step - loss: 0.2134 - accuracy: 0.9165 - val_loss: 0.4719 - val_accuracy: 0.8129\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 703us/step - loss: 0.2076 - accuracy: 0.9187 - val_loss: 0.4709 - val_accuracy: 0.8154\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 689us/step - loss: 0.2009 - accuracy: 0.9219 - val_loss: 0.5209 - val_accuracy: 0.8098\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 698us/step - loss: 0.1957 - accuracy: 0.9242 - val_loss: 0.5138 - val_accuracy: 0.8116\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 720us/step - loss: 0.1917 - accuracy: 0.9264 - val_loss: 0.4904 - val_accuracy: 0.8214\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 718us/step - loss: 0.1877 - accuracy: 0.9284 - val_loss: 0.4537 - val_accuracy: 0.8325\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 709us/step - loss: 0.1832 - accuracy: 0.9301 - val_loss: 0.4352 - val_accuracy: 0.8309\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 709us/step - loss: 0.1801 - accuracy: 0.9316 - val_loss: 0.4248 - val_accuracy: 0.8564\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 682us/step - loss: 0.1784 - accuracy: 0.9316 - val_loss: 0.4476 - val_accuracy: 0.8358\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 723us/step - loss: 0.1751 - accuracy: 0.9330 - val_loss: 0.4260 - val_accuracy: 0.8440\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 715us/step - loss: 0.1730 - accuracy: 0.9344 - val_loss: 0.4437 - val_accuracy: 0.8464\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 727us/step - loss: 0.1700 - accuracy: 0.9366 - val_loss: 0.4362 - val_accuracy: 0.8432\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 696us/step - loss: 0.1680 - accuracy: 0.9363 - val_loss: 0.4699 - val_accuracy: 0.8388\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 680us/step - loss: 0.1657 - accuracy: 0.9380 - val_loss: 0.4976 - val_accuracy: 0.8355\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 673us/step - loss: 0.1654 - accuracy: 0.9374 - val_loss: 0.4377 - val_accuracy: 0.8508\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 653us/step - loss: 0.1629 - accuracy: 0.9386 - val_loss: 0.4369 - val_accuracy: 0.8436\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 704us/step - loss: 0.1615 - accuracy: 0.9384 - val_loss: 0.4762 - val_accuracy: 0.8326\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 723us/step - loss: 0.1587 - accuracy: 0.9404 - val_loss: 0.5284 - val_accuracy: 0.8170\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 698us/step - loss: 0.1580 - accuracy: 0.9418 - val_loss: 0.4967 - val_accuracy: 0.8262\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.1561 - accuracy: 0.9421 - val_loss: 0.4889 - val_accuracy: 0.8405\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.1560 - accuracy: 0.9411 - val_loss: 0.4168 - val_accuracy: 0.8496\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.1543 - accuracy: 0.9417 - val_loss: 0.4907 - val_accuracy: 0.8369\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.1538 - accuracy: 0.9423 - val_loss: 0.4874 - val_accuracy: 0.8383\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.1507 - accuracy: 0.9437 - val_loss: 0.5020 - val_accuracy: 0.8336\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.1509 - accuracy: 0.9436 - val_loss: 0.4642 - val_accuracy: 0.8486\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.1487 - accuracy: 0.9445 - val_loss: 0.5905 - val_accuracy: 0.8176\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.1498 - accuracy: 0.9437 - val_loss: 0.5043 - val_accuracy: 0.8336\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.1486 - accuracy: 0.9442 - val_loss: 0.5289 - val_accuracy: 0.8377\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.1462 - accuracy: 0.9448 - val_loss: 0.5239 - val_accuracy: 0.8286\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.1465 - accuracy: 0.9449 - val_loss: 0.5603 - val_accuracy: 0.8099\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 601us/step - loss: 0.1436 - accuracy: 0.9465 - val_loss: 0.5231 - val_accuracy: 0.8340\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.1434 - accuracy: 0.9462 - val_loss: 0.5443 - val_accuracy: 0.8347\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.1428 - accuracy: 0.9464 - val_loss: 0.5003 - val_accuracy: 0.8337\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.1417 - accuracy: 0.9466 - val_loss: 0.4975 - val_accuracy: 0.8423\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.1411 - accuracy: 0.9464 - val_loss: 0.5701 - val_accuracy: 0.8253\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.1406 - accuracy: 0.9467 - val_loss: 0.5181 - val_accuracy: 0.8468\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.1408 - accuracy: 0.9484 - val_loss: 0.5955 - val_accuracy: 0.8171\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.1382 - accuracy: 0.9480 - val_loss: 0.5027 - val_accuracy: 0.8519\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.1384 - accuracy: 0.9486 - val_loss: 0.6380 - val_accuracy: 0.8131\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.1381 - accuracy: 0.9483 - val_loss: 0.5317 - val_accuracy: 0.8516\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.1360 - accuracy: 0.9494 - val_loss: 0.4909 - val_accuracy: 0.8431\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.1367 - accuracy: 0.9482 - val_loss: 0.5018 - val_accuracy: 0.8474\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.1336 - accuracy: 0.9499 - val_loss: 0.5422 - val_accuracy: 0.8387\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.1339 - accuracy: 0.9494 - val_loss: 0.4861 - val_accuracy: 0.8467\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.1339 - accuracy: 0.9494 - val_loss: 0.5249 - val_accuracy: 0.8430\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 601us/step - loss: 0.1332 - accuracy: 0.9504 - val_loss: 0.5840 - val_accuracy: 0.8317\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.3264 - accuracy: 0.8607 - val_loss: 0.4571 - val_accuracy: 0.8232\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.2507 - accuracy: 0.9017 - val_loss: 0.4414 - val_accuracy: 0.8258\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.2347 - accuracy: 0.9084 - val_loss: 0.3745 - val_accuracy: 0.8591\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.2238 - accuracy: 0.9119 - val_loss: 0.4424 - val_accuracy: 0.8385\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.2138 - accuracy: 0.9164 - val_loss: 0.5350 - val_accuracy: 0.8032\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.2064 - accuracy: 0.9203 - val_loss: 0.4430 - val_accuracy: 0.8338\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.2002 - accuracy: 0.9219 - val_loss: 0.4870 - val_accuracy: 0.8185\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 635us/step - loss: 0.1948 - accuracy: 0.9248 - val_loss: 0.4522 - val_accuracy: 0.8313\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.1896 - accuracy: 0.9275 - val_loss: 0.4591 - val_accuracy: 0.8290\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.1857 - accuracy: 0.9296 - val_loss: 0.5340 - val_accuracy: 0.8096\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.1818 - accuracy: 0.9305 - val_loss: 0.4432 - val_accuracy: 0.8331\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 595us/step - loss: 0.1797 - accuracy: 0.9324 - val_loss: 0.5003 - val_accuracy: 0.8191\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.1758 - accuracy: 0.9338 - val_loss: 0.4450 - val_accuracy: 0.8510\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.1727 - accuracy: 0.9355 - val_loss: 0.5311 - val_accuracy: 0.8110\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.1705 - accuracy: 0.9357 - val_loss: 0.5575 - val_accuracy: 0.7962\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.1685 - accuracy: 0.9361 - val_loss: 0.4897 - val_accuracy: 0.8326\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 650us/step - loss: 0.1672 - accuracy: 0.9369 - val_loss: 0.4970 - val_accuracy: 0.8296\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 644us/step - loss: 0.1640 - accuracy: 0.9376 - val_loss: 0.4778 - val_accuracy: 0.8331\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 680us/step - loss: 0.1639 - accuracy: 0.9382 - val_loss: 0.4955 - val_accuracy: 0.8338\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 3s 836us/step - loss: 0.1604 - accuracy: 0.9402 - val_loss: 0.5436 - val_accuracy: 0.8184\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 712us/step - loss: 0.1590 - accuracy: 0.9397 - val_loss: 0.4852 - val_accuracy: 0.8442\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 726us/step - loss: 0.1575 - accuracy: 0.9409 - val_loss: 0.5216 - val_accuracy: 0.8279\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 731us/step - loss: 0.1572 - accuracy: 0.9409 - val_loss: 0.4887 - val_accuracy: 0.8379\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 3s 752us/step - loss: 0.1535 - accuracy: 0.9417 - val_loss: 0.4498 - val_accuracy: 0.8579\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 714us/step - loss: 0.1532 - accuracy: 0.9428 - val_loss: 0.4784 - val_accuracy: 0.8356\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 722us/step - loss: 0.1515 - accuracy: 0.9432 - val_loss: 0.5264 - val_accuracy: 0.8255\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 710us/step - loss: 0.1520 - accuracy: 0.9428 - val_loss: 0.4710 - val_accuracy: 0.8479\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 729us/step - loss: 0.1491 - accuracy: 0.9436 - val_loss: 0.4643 - val_accuracy: 0.8485\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 691us/step - loss: 0.1472 - accuracy: 0.9447 - val_loss: 0.4763 - val_accuracy: 0.8446\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.1456 - accuracy: 0.9452 - val_loss: 0.5236 - val_accuracy: 0.8388\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 3s 782us/step - loss: 0.1459 - accuracy: 0.9454 - val_loss: 0.4877 - val_accuracy: 0.8456\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 702us/step - loss: 0.1446 - accuracy: 0.9457 - val_loss: 0.5672 - val_accuracy: 0.8213\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 733us/step - loss: 0.1429 - accuracy: 0.9469 - val_loss: 0.5329 - val_accuracy: 0.8351\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 711us/step - loss: 0.1426 - accuracy: 0.9453 - val_loss: 0.5203 - val_accuracy: 0.8441\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 725us/step - loss: 0.1410 - accuracy: 0.9469 - val_loss: 0.4777 - val_accuracy: 0.8536\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 739us/step - loss: 0.1409 - accuracy: 0.9477 - val_loss: 0.5066 - val_accuracy: 0.8482\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 674us/step - loss: 0.1401 - accuracy: 0.9478 - val_loss: 0.5340 - val_accuracy: 0.8392\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 718us/step - loss: 0.1392 - accuracy: 0.9469 - val_loss: 0.6021 - val_accuracy: 0.8314\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 697us/step - loss: 0.1380 - accuracy: 0.9485 - val_loss: 0.5453 - val_accuracy: 0.8387\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 707us/step - loss: 0.1373 - accuracy: 0.9492 - val_loss: 0.4813 - val_accuracy: 0.8525\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 723us/step - loss: 0.1365 - accuracy: 0.9479 - val_loss: 0.5146 - val_accuracy: 0.8539\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 3s 786us/step - loss: 0.1355 - accuracy: 0.9497 - val_loss: 0.5754 - val_accuracy: 0.8381\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.1334 - accuracy: 0.9506 - val_loss: 0.5514 - val_accuracy: 0.8413\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 717us/step - loss: 0.1340 - accuracy: 0.9505 - val_loss: 0.5792 - val_accuracy: 0.8338\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 730us/step - loss: 0.1349 - accuracy: 0.9491 - val_loss: 0.5186 - val_accuracy: 0.8558\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 729us/step - loss: 0.1325 - accuracy: 0.9502 - val_loss: 0.5816 - val_accuracy: 0.8311\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 715us/step - loss: 0.1314 - accuracy: 0.9499 - val_loss: 0.5659 - val_accuracy: 0.8385\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 712us/step - loss: 0.1312 - accuracy: 0.9517 - val_loss: 0.5289 - val_accuracy: 0.8509\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 718us/step - loss: 0.1294 - accuracy: 0.9518 - val_loss: 0.5276 - val_accuracy: 0.8487\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 720us/step - loss: 0.1296 - accuracy: 0.9519 - val_loss: 0.5705 - val_accuracy: 0.8367\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 3s 750us/step - loss: 0.3276 - accuracy: 0.8596 - val_loss: 0.4918 - val_accuracy: 0.8134\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 681us/step - loss: 0.2532 - accuracy: 0.9010 - val_loss: 0.5478 - val_accuracy: 0.7755\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 694us/step - loss: 0.2358 - accuracy: 0.9072 - val_loss: 0.3951 - val_accuracy: 0.8510\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 677us/step - loss: 0.2232 - accuracy: 0.9115 - val_loss: 0.3798 - val_accuracy: 0.8478\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 715us/step - loss: 0.2125 - accuracy: 0.9172 - val_loss: 0.4203 - val_accuracy: 0.8433\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 683us/step - loss: 0.2072 - accuracy: 0.9201 - val_loss: 0.4059 - val_accuracy: 0.8372\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.2022 - accuracy: 0.9209 - val_loss: 0.4343 - val_accuracy: 0.8206\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.1966 - accuracy: 0.9234 - val_loss: 0.4251 - val_accuracy: 0.8349\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.1912 - accuracy: 0.9268 - val_loss: 0.4773 - val_accuracy: 0.8174\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.1890 - accuracy: 0.9272 - val_loss: 0.4656 - val_accuracy: 0.8257\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.1845 - accuracy: 0.9297 - val_loss: 0.4677 - val_accuracy: 0.8272\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.1802 - accuracy: 0.9310 - val_loss: 0.4482 - val_accuracy: 0.8335\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.1777 - accuracy: 0.9325 - val_loss: 0.4746 - val_accuracy: 0.8372\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.1758 - accuracy: 0.9333 - val_loss: 0.4652 - val_accuracy: 0.8258\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.1746 - accuracy: 0.9329 - val_loss: 0.4607 - val_accuracy: 0.8237\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.1712 - accuracy: 0.9355 - val_loss: 0.4268 - val_accuracy: 0.8440\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 615us/step - loss: 0.1703 - accuracy: 0.9355 - val_loss: 0.4987 - val_accuracy: 0.8198\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.1674 - accuracy: 0.9368 - val_loss: 0.4811 - val_accuracy: 0.8241\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 633us/step - loss: 0.1670 - accuracy: 0.9374 - val_loss: 0.4174 - val_accuracy: 0.8551\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.1658 - accuracy: 0.9371 - val_loss: 0.3972 - val_accuracy: 0.8555\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 610us/step - loss: 0.1624 - accuracy: 0.9385 - val_loss: 0.5112 - val_accuracy: 0.8274\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.1613 - accuracy: 0.9394 - val_loss: 0.4911 - val_accuracy: 0.8286\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.1605 - accuracy: 0.9391 - val_loss: 0.4884 - val_accuracy: 0.8346\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.1579 - accuracy: 0.9410 - val_loss: 0.4673 - val_accuracy: 0.8352\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.1573 - accuracy: 0.9403 - val_loss: 0.4499 - val_accuracy: 0.8453\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 626us/step - loss: 0.1555 - accuracy: 0.9414 - val_loss: 0.4517 - val_accuracy: 0.8444\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.1545 - accuracy: 0.9414 - val_loss: 0.5501 - val_accuracy: 0.8227\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.1553 - accuracy: 0.9409 - val_loss: 0.5688 - val_accuracy: 0.7937\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 637us/step - loss: 0.1538 - accuracy: 0.9420 - val_loss: 0.4401 - val_accuracy: 0.8522\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.1514 - accuracy: 0.9425 - val_loss: 0.5078 - val_accuracy: 0.8358\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 635us/step - loss: 0.1529 - accuracy: 0.9424 - val_loss: 0.4607 - val_accuracy: 0.8454\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.1500 - accuracy: 0.9423 - val_loss: 0.5454 - val_accuracy: 0.8238\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.1495 - accuracy: 0.9443 - val_loss: 0.4863 - val_accuracy: 0.8373\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.1491 - accuracy: 0.9431 - val_loss: 0.4864 - val_accuracy: 0.8390\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.1483 - accuracy: 0.9436 - val_loss: 0.4679 - val_accuracy: 0.8385\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.1477 - accuracy: 0.9443 - val_loss: 0.5609 - val_accuracy: 0.8170\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.1459 - accuracy: 0.9452 - val_loss: 0.5474 - val_accuracy: 0.8169\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.1443 - accuracy: 0.9461 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.1449 - accuracy: 0.9447 - val_loss: 0.5663 - val_accuracy: 0.8139\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.1439 - accuracy: 0.9463 - val_loss: 0.4729 - val_accuracy: 0.8514\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.1424 - accuracy: 0.9458 - val_loss: 0.4740 - val_accuracy: 0.8509\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 637us/step - loss: 0.1418 - accuracy: 0.9467 - val_loss: 0.4704 - val_accuracy: 0.8503\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.1415 - accuracy: 0.9465 - val_loss: 0.5037 - val_accuracy: 0.8381\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.1408 - accuracy: 0.9464 - val_loss: 0.5504 - val_accuracy: 0.8190\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.1393 - accuracy: 0.9481 - val_loss: 0.5311 - val_accuracy: 0.8336\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.1392 - accuracy: 0.9473 - val_loss: 0.5799 - val_accuracy: 0.8202\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.1398 - accuracy: 0.9475 - val_loss: 0.4944 - val_accuracy: 0.8422\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.1381 - accuracy: 0.9491 - val_loss: 0.5159 - val_accuracy: 0.8265\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 654us/step - loss: 0.1372 - accuracy: 0.9475 - val_loss: 0.5712 - val_accuracy: 0.8182\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 728us/step - loss: 0.1368 - accuracy: 0.9481 - val_loss: 0.5220 - val_accuracy: 0.8434\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 3s 892us/step - loss: 0.3277 - accuracy: 0.8583 - val_loss: 0.4450 - val_accuracy: 0.8293\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 3s 794us/step - loss: 0.2491 - accuracy: 0.9018 - val_loss: 0.4786 - val_accuracy: 0.8063\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 3s 753us/step - loss: 0.2336 - accuracy: 0.9082 - val_loss: 0.4436 - val_accuracy: 0.8326\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 730us/step - loss: 0.2225 - accuracy: 0.9125 - val_loss: 0.4866 - val_accuracy: 0.8160\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 3s 814us/step - loss: 0.2140 - accuracy: 0.9164 - val_loss: 0.5437 - val_accuracy: 0.7938\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 3s 756us/step - loss: 0.2062 - accuracy: 0.9201 - val_loss: 0.4690 - val_accuracy: 0.8295\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 3s 787us/step - loss: 0.2005 - accuracy: 0.9234 - val_loss: 0.5212 - val_accuracy: 0.8068\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 745us/step - loss: 0.1936 - accuracy: 0.9262 - val_loss: 0.4390 - val_accuracy: 0.8328\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 717us/step - loss: 0.1894 - accuracy: 0.9279 - val_loss: 0.4527 - val_accuracy: 0.8373\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 3s 753us/step - loss: 0.1849 - accuracy: 0.9302 - val_loss: 0.4475 - val_accuracy: 0.8307\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 723us/step - loss: 0.1823 - accuracy: 0.9315 - val_loss: 0.4577 - val_accuracy: 0.8219\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 742us/step - loss: 0.1799 - accuracy: 0.9314 - val_loss: 0.4561 - val_accuracy: 0.8374\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 719us/step - loss: 0.1769 - accuracy: 0.9331 - val_loss: 0.5018 - val_accuracy: 0.8245\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 740us/step - loss: 0.1737 - accuracy: 0.9335 - val_loss: 0.4302 - val_accuracy: 0.8483\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 740us/step - loss: 0.1709 - accuracy: 0.9356 - val_loss: 0.5680 - val_accuracy: 0.8042\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 737us/step - loss: 0.1678 - accuracy: 0.9362 - val_loss: 0.5107 - val_accuracy: 0.8235\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 710us/step - loss: 0.1660 - accuracy: 0.9376 - val_loss: 0.4982 - val_accuracy: 0.8237\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 737us/step - loss: 0.1638 - accuracy: 0.9396 - val_loss: 0.5399 - val_accuracy: 0.8171\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 728us/step - loss: 0.1608 - accuracy: 0.9393 - val_loss: 0.4021 - val_accuracy: 0.8528\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 745us/step - loss: 0.1603 - accuracy: 0.9408 - val_loss: 0.5626 - val_accuracy: 0.8158\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 3s 755us/step - loss: 0.1587 - accuracy: 0.9403 - val_loss: 0.5621 - val_accuracy: 0.8195\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 3s 754us/step - loss: 0.1579 - accuracy: 0.9409 - val_loss: 0.5038 - val_accuracy: 0.8300\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 3s 753us/step - loss: 0.1545 - accuracy: 0.9418 - val_loss: 0.4915 - val_accuracy: 0.8426\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 3s 758us/step - loss: 0.1557 - accuracy: 0.9410 - val_loss: 0.5307 - val_accuracy: 0.8313\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 737us/step - loss: 0.1546 - accuracy: 0.9424 - val_loss: 0.5085 - val_accuracy: 0.8300\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 730us/step - loss: 0.1515 - accuracy: 0.9434 - val_loss: 0.5230 - val_accuracy: 0.8266\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 715us/step - loss: 0.1516 - accuracy: 0.9438 - val_loss: 0.5246 - val_accuracy: 0.8171\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 736us/step - loss: 0.1508 - accuracy: 0.9440 - val_loss: 0.4623 - val_accuracy: 0.8479\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 737us/step - loss: 0.1496 - accuracy: 0.9440 - val_loss: 0.4574 - val_accuracy: 0.8520\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 730us/step - loss: 0.1484 - accuracy: 0.9452 - val_loss: 0.5286 - val_accuracy: 0.8385\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 736us/step - loss: 0.1460 - accuracy: 0.9451 - val_loss: 0.4989 - val_accuracy: 0.8461\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 708us/step - loss: 0.1452 - accuracy: 0.9460 - val_loss: 0.5028 - val_accuracy: 0.8391\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 725us/step - loss: 0.1437 - accuracy: 0.9465 - val_loss: 0.5612 - val_accuracy: 0.8270\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 3s 874us/step - loss: 0.1451 - accuracy: 0.9460 - val_loss: 0.5084 - val_accuracy: 0.8495\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 3s 748us/step - loss: 0.1432 - accuracy: 0.9458 - val_loss: 0.5122 - val_accuracy: 0.8439\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 727us/step - loss: 0.1417 - accuracy: 0.9481 - val_loss: 0.5301 - val_accuracy: 0.8316\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.1398 - accuracy: 0.9481 - val_loss: 0.5485 - val_accuracy: 0.8363\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.1411 - accuracy: 0.9481 - val_loss: 0.4979 - val_accuracy: 0.8442\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.1406 - accuracy: 0.9464 - val_loss: 0.5965 - val_accuracy: 0.8138\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 620us/step - loss: 0.1398 - accuracy: 0.9468 - val_loss: 0.5433 - val_accuracy: 0.8358\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.1379 - accuracy: 0.9480 - val_loss: 0.5599 - val_accuracy: 0.8308\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.1383 - accuracy: 0.9486 - val_loss: 0.5291 - val_accuracy: 0.8461\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.1363 - accuracy: 0.9498 - val_loss: 0.5501 - val_accuracy: 0.8380\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.1355 - accuracy: 0.9491 - val_loss: 0.5023 - val_accuracy: 0.8434\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.1348 - accuracy: 0.9493 - val_loss: 0.5637 - val_accuracy: 0.8313\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.1350 - accuracy: 0.9492 - val_loss: 0.5274 - val_accuracy: 0.8451\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.1338 - accuracy: 0.9505 - val_loss: 0.6118 - val_accuracy: 0.8304\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.1340 - accuracy: 0.9485 - val_loss: 0.5925 - val_accuracy: 0.8256\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.1334 - accuracy: 0.9501 - val_loss: 0.6094 - val_accuracy: 0.8308\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.1326 - accuracy: 0.9497 - val_loss: 0.5195 - val_accuracy: 0.8504\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 624us/step - loss: 0.3233 - accuracy: 0.8622 - val_loss: 0.5968 - val_accuracy: 0.7625\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 705us/step - loss: 0.2451 - accuracy: 0.9039 - val_loss: 0.4927 - val_accuracy: 0.8097\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 610us/step - loss: 0.2301 - accuracy: 0.9101 - val_loss: 0.5065 - val_accuracy: 0.7952\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.2185 - accuracy: 0.9140 - val_loss: 0.4647 - val_accuracy: 0.8131\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 658us/step - loss: 0.2102 - accuracy: 0.9183 - val_loss: 0.4238 - val_accuracy: 0.8403\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.2047 - accuracy: 0.9197 - val_loss: 0.4267 - val_accuracy: 0.8367\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.1985 - accuracy: 0.9228 - val_loss: 0.4678 - val_accuracy: 0.8278\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 610us/step - loss: 0.1936 - accuracy: 0.9258 - val_loss: 0.4406 - val_accuracy: 0.8356\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.1892 - accuracy: 0.9268 - val_loss: 0.4435 - val_accuracy: 0.8297\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.1846 - accuracy: 0.9285 - val_loss: 0.4323 - val_accuracy: 0.8449\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.1815 - accuracy: 0.9298 - val_loss: 0.5059 - val_accuracy: 0.8220\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.1798 - accuracy: 0.9322 - val_loss: 0.4787 - val_accuracy: 0.8244\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.1766 - accuracy: 0.9332 - val_loss: 0.4414 - val_accuracy: 0.8548\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.1730 - accuracy: 0.9339 - val_loss: 0.4485 - val_accuracy: 0.8338\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.1717 - accuracy: 0.9348 - val_loss: 0.4331 - val_accuracy: 0.8497\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.1687 - accuracy: 0.9362 - val_loss: 0.5526 - val_accuracy: 0.8089\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.1655 - accuracy: 0.9365 - val_loss: 0.5000 - val_accuracy: 0.8266\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.1635 - accuracy: 0.9381 - val_loss: 0.4607 - val_accuracy: 0.8314\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.1610 - accuracy: 0.9387 - val_loss: 0.5035 - val_accuracy: 0.8219\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 639us/step - loss: 0.1603 - accuracy: 0.9399 - val_loss: 0.5018 - val_accuracy: 0.8237\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.1589 - accuracy: 0.9402 - val_loss: 0.5245 - val_accuracy: 0.8198\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.1561 - accuracy: 0.9406 - val_loss: 0.4763 - val_accuracy: 0.8380\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.1537 - accuracy: 0.9408 - val_loss: 0.5603 - val_accuracy: 0.8192\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 620us/step - loss: 0.1538 - accuracy: 0.9415 - val_loss: 0.5741 - val_accuracy: 0.8007\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.1521 - accuracy: 0.9421 - val_loss: 0.5482 - val_accuracy: 0.8276\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 648us/step - loss: 0.1509 - accuracy: 0.9433 - val_loss: 0.4996 - val_accuracy: 0.8337\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 633us/step - loss: 0.1501 - accuracy: 0.9432 - val_loss: 0.4873 - val_accuracy: 0.8412\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.1497 - accuracy: 0.9430 - val_loss: 0.4998 - val_accuracy: 0.8345\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.1479 - accuracy: 0.9445 - val_loss: 0.5648 - val_accuracy: 0.8164\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 3s 779us/step - loss: 0.1454 - accuracy: 0.9457 - val_loss: 0.4955 - val_accuracy: 0.8410\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 3s 813us/step - loss: 0.1447 - accuracy: 0.9457 - val_loss: 0.4832 - val_accuracy: 0.8416\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 716us/step - loss: 0.1432 - accuracy: 0.9456 - val_loss: 0.5224 - val_accuracy: 0.8349\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 730us/step - loss: 0.1423 - accuracy: 0.9474 - val_loss: 0.5345 - val_accuracy: 0.8285\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 3s 756us/step - loss: 0.1409 - accuracy: 0.9466 - val_loss: 0.5877 - val_accuracy: 0.8113\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 731us/step - loss: 0.1401 - accuracy: 0.9472 - val_loss: 0.5399 - val_accuracy: 0.8291\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 735us/step - loss: 0.1388 - accuracy: 0.9477 - val_loss: 0.5255 - val_accuracy: 0.8341\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 723us/step - loss: 0.1374 - accuracy: 0.9476 - val_loss: 0.5387 - val_accuracy: 0.8324\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 725us/step - loss: 0.1374 - accuracy: 0.9480 - val_loss: 0.5222 - val_accuracy: 0.8437\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.1378 - accuracy: 0.9487 - val_loss: 0.5788 - val_accuracy: 0.8262\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 705us/step - loss: 0.1358 - accuracy: 0.9488 - val_loss: 0.5240 - val_accuracy: 0.8428\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 729us/step - loss: 0.1362 - accuracy: 0.9482 - val_loss: 0.4668 - val_accuracy: 0.8656\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 3s 753us/step - loss: 0.1330 - accuracy: 0.9493 - val_loss: 0.5548 - val_accuracy: 0.8387\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 747us/step - loss: 0.1325 - accuracy: 0.9501 - val_loss: 0.5833 - val_accuracy: 0.8404\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 733us/step - loss: 0.1326 - accuracy: 0.9498 - val_loss: 0.5589 - val_accuracy: 0.8387\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 732us/step - loss: 0.1333 - accuracy: 0.9506 - val_loss: 0.5703 - val_accuracy: 0.8387\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 737us/step - loss: 0.1316 - accuracy: 0.9515 - val_loss: 0.5467 - val_accuracy: 0.8471\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 725us/step - loss: 0.1298 - accuracy: 0.9510 - val_loss: 0.5532 - val_accuracy: 0.8414\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 747us/step - loss: 0.1309 - accuracy: 0.9511 - val_loss: 0.6556 - val_accuracy: 0.8173\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 3s 797us/step - loss: 0.1287 - accuracy: 0.9518 - val_loss: 0.6182 - val_accuracy: 0.8308\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 745us/step - loss: 0.1296 - accuracy: 0.9511 - val_loss: 0.6154 - val_accuracy: 0.8343\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 745us/step - loss: 0.3344 - accuracy: 0.8542 - val_loss: 0.5781 - val_accuracy: 0.7732\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 710us/step - loss: 0.2476 - accuracy: 0.9042 - val_loss: 0.4344 - val_accuracy: 0.8288\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 3s 760us/step - loss: 0.2320 - accuracy: 0.9102 - val_loss: 0.5505 - val_accuracy: 0.7876\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 3s 753us/step - loss: 0.2211 - accuracy: 0.9139 - val_loss: 0.4445 - val_accuracy: 0.8256\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 732us/step - loss: 0.2138 - accuracy: 0.9182 - val_loss: 0.4521 - val_accuracy: 0.8389\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 3s 748us/step - loss: 0.2074 - accuracy: 0.9194 - val_loss: 0.4388 - val_accuracy: 0.8215\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 733us/step - loss: 0.2022 - accuracy: 0.9229 - val_loss: 0.4294 - val_accuracy: 0.8345\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 3s 749us/step - loss: 0.1965 - accuracy: 0.9242 - val_loss: 0.4883 - val_accuracy: 0.8206\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 742us/step - loss: 0.1921 - accuracy: 0.9264 - val_loss: 0.5374 - val_accuracy: 0.8038\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 746us/step - loss: 0.1880 - accuracy: 0.9286 - val_loss: 0.4821 - val_accuracy: 0.8210\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 747us/step - loss: 0.1833 - accuracy: 0.9303 - val_loss: 0.4441 - val_accuracy: 0.8384\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 723us/step - loss: 0.1806 - accuracy: 0.9318 - val_loss: 0.4628 - val_accuracy: 0.8299\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 718us/step - loss: 0.1785 - accuracy: 0.9325 - val_loss: 0.6082 - val_accuracy: 0.7729\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 726us/step - loss: 0.1744 - accuracy: 0.9340 - val_loss: 0.5810 - val_accuracy: 0.8045\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 723us/step - loss: 0.1748 - accuracy: 0.9351 - val_loss: 0.5063 - val_accuracy: 0.8210\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.1720 - accuracy: 0.9352 - val_loss: 0.4939 - val_accuracy: 0.8403\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.1698 - accuracy: 0.9364 - val_loss: 0.5351 - val_accuracy: 0.8191\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.1679 - accuracy: 0.9379 - val_loss: 0.5114 - val_accuracy: 0.8340\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.1663 - accuracy: 0.9387 - val_loss: 0.5690 - val_accuracy: 0.8054\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.1650 - accuracy: 0.9389 - val_loss: 0.4815 - val_accuracy: 0.8338\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.1628 - accuracy: 0.9388 - val_loss: 0.5475 - val_accuracy: 0.8215\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.1616 - accuracy: 0.9398 - val_loss: 0.4500 - val_accuracy: 0.8447\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.1604 - accuracy: 0.9402 - val_loss: 0.4773 - val_accuracy: 0.8462\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.1588 - accuracy: 0.9405 - val_loss: 0.4944 - val_accuracy: 0.8367\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 646us/step - loss: 0.1570 - accuracy: 0.9413 - val_loss: 0.4826 - val_accuracy: 0.8379\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.1566 - accuracy: 0.9415 - val_loss: 0.4572 - val_accuracy: 0.8441\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.1548 - accuracy: 0.9435 - val_loss: 0.5939 - val_accuracy: 0.8164\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.1540 - accuracy: 0.9418 - val_loss: 0.4614 - val_accuracy: 0.8485\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 635us/step - loss: 0.1540 - accuracy: 0.9425 - val_loss: 0.4856 - val_accuracy: 0.8434\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 647us/step - loss: 0.1518 - accuracy: 0.9439 - val_loss: 0.4814 - val_accuracy: 0.8403\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 610us/step - loss: 0.1508 - accuracy: 0.9432 - val_loss: 0.5082 - val_accuracy: 0.8374\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.1490 - accuracy: 0.9444 - val_loss: 0.5095 - val_accuracy: 0.8377\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 633us/step - loss: 0.1494 - accuracy: 0.9436 - val_loss: 0.5102 - val_accuracy: 0.8408\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.1483 - accuracy: 0.9449 - val_loss: 0.5215 - val_accuracy: 0.8473\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.1473 - accuracy: 0.9460 - val_loss: 0.6007 - val_accuracy: 0.8107\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 646us/step - loss: 0.1456 - accuracy: 0.9462 - val_loss: 0.5935 - val_accuracy: 0.8192\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.1454 - accuracy: 0.9454 - val_loss: 0.4892 - val_accuracy: 0.8379\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 625us/step - loss: 0.1449 - accuracy: 0.9454 - val_loss: 0.4920 - val_accuracy: 0.8426\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.1444 - accuracy: 0.9464 - val_loss: 0.6301 - val_accuracy: 0.7966\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 639us/step - loss: 0.1445 - accuracy: 0.9460 - val_loss: 0.5174 - val_accuracy: 0.8475\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.1428 - accuracy: 0.9471 - val_loss: 0.5559 - val_accuracy: 0.8308\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.1400 - accuracy: 0.9477 - val_loss: 0.6346 - val_accuracy: 0.8130\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.1417 - accuracy: 0.9472 - val_loss: 0.5141 - val_accuracy: 0.8361\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 637us/step - loss: 0.1404 - accuracy: 0.9473 - val_loss: 0.5481 - val_accuracy: 0.8442\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 648us/step - loss: 0.1420 - accuracy: 0.9477 - val_loss: 0.5784 - val_accuracy: 0.8288\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.1391 - accuracy: 0.9480 - val_loss: 0.5741 - val_accuracy: 0.8300\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 654us/step - loss: 0.1379 - accuracy: 0.9485 - val_loss: 0.5145 - val_accuracy: 0.8496\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 626us/step - loss: 0.1388 - accuracy: 0.9484 - val_loss: 0.5441 - val_accuracy: 0.8454\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.1384 - accuracy: 0.9486 - val_loss: 0.5717 - val_accuracy: 0.8331\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 647us/step - loss: 0.1361 - accuracy: 0.9508 - val_loss: 0.5843 - val_accuracy: 0.8324\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 610us/step - loss: 0.3201 - accuracy: 0.8636 - val_loss: 0.4020 - val_accuracy: 0.8482\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.2438 - accuracy: 0.9042 - val_loss: 0.4146 - val_accuracy: 0.8418\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.2287 - accuracy: 0.9108 - val_loss: 0.4698 - val_accuracy: 0.8242\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.2180 - accuracy: 0.9151 - val_loss: 0.4773 - val_accuracy: 0.8104\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.2085 - accuracy: 0.9185 - val_loss: 0.4706 - val_accuracy: 0.8303\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 642us/step - loss: 0.2014 - accuracy: 0.9215 - val_loss: 0.4604 - val_accuracy: 0.8220\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 615us/step - loss: 0.1949 - accuracy: 0.9252 - val_loss: 0.4683 - val_accuracy: 0.8223\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 626us/step - loss: 0.1900 - accuracy: 0.9270 - val_loss: 0.4975 - val_accuracy: 0.8297\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.1859 - accuracy: 0.9289 - val_loss: 0.4852 - val_accuracy: 0.8261\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 3s 861us/step - loss: 0.1836 - accuracy: 0.9303 - val_loss: 0.4933 - val_accuracy: 0.8224\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 3s 822us/step - loss: 0.1787 - accuracy: 0.9318 - val_loss: 0.6219 - val_accuracy: 0.7838\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 3s 769us/step - loss: 0.1768 - accuracy: 0.9335 - val_loss: 0.4539 - val_accuracy: 0.8398\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 3s 757us/step - loss: 0.1733 - accuracy: 0.9353 - val_loss: 0.4591 - val_accuracy: 0.8428\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 3s 754us/step - loss: 0.1718 - accuracy: 0.9355 - val_loss: 0.5165 - val_accuracy: 0.8230\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 3s 761us/step - loss: 0.1698 - accuracy: 0.9349 - val_loss: 0.4580 - val_accuracy: 0.8423\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 3s 754us/step - loss: 0.1685 - accuracy: 0.9361 - val_loss: 0.5023 - val_accuracy: 0.8348\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 3s 750us/step - loss: 0.1651 - accuracy: 0.9380 - val_loss: 0.5344 - val_accuracy: 0.8174\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 3s 779us/step - loss: 0.1637 - accuracy: 0.9377 - val_loss: 0.4981 - val_accuracy: 0.8324\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 3s 760us/step - loss: 0.1624 - accuracy: 0.9391 - val_loss: 0.4826 - val_accuracy: 0.8411\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 3s 759us/step - loss: 0.1602 - accuracy: 0.9402 - val_loss: 0.4743 - val_accuracy: 0.8339\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 3s 806us/step - loss: 0.1586 - accuracy: 0.9407 - val_loss: 0.4572 - val_accuracy: 0.8468\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 3s 768us/step - loss: 0.1563 - accuracy: 0.9410 - val_loss: 0.5153 - val_accuracy: 0.8285\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 3s 771us/step - loss: 0.1558 - accuracy: 0.9408 - val_loss: 0.5122 - val_accuracy: 0.8352\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.1547 - accuracy: 0.9426 - val_loss: 0.5263 - val_accuracy: 0.8248\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 3s 748us/step - loss: 0.1523 - accuracy: 0.9432 - val_loss: 0.4582 - val_accuracy: 0.8529\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 3s 758us/step - loss: 0.1522 - accuracy: 0.9434 - val_loss: 0.4660 - val_accuracy: 0.8380\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 3s 773us/step - loss: 0.1508 - accuracy: 0.9439 - val_loss: 0.6067 - val_accuracy: 0.8099\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 3s 754us/step - loss: 0.1498 - accuracy: 0.9434 - val_loss: 0.4814 - val_accuracy: 0.8447\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 3s 793us/step - loss: 0.1463 - accuracy: 0.9447 - val_loss: 0.5014 - val_accuracy: 0.8415\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 3s 757us/step - loss: 0.1463 - accuracy: 0.9450 - val_loss: 0.4533 - val_accuracy: 0.8451\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 3s 756us/step - loss: 0.1457 - accuracy: 0.9454 - val_loss: 0.5568 - val_accuracy: 0.8280\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 3s 762us/step - loss: 0.1461 - accuracy: 0.9446 - val_loss: 0.5459 - val_accuracy: 0.8280\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 3s 760us/step - loss: 0.1439 - accuracy: 0.9463 - val_loss: 0.5686 - val_accuracy: 0.8278\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 3s 765us/step - loss: 0.1442 - accuracy: 0.9453 - val_loss: 0.4934 - val_accuracy: 0.8505\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 3s 755us/step - loss: 0.1422 - accuracy: 0.9462 - val_loss: 0.5263 - val_accuracy: 0.8362\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 3s 795us/step - loss: 0.1415 - accuracy: 0.9471 - val_loss: 0.5834 - val_accuracy: 0.8185\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 3s 760us/step - loss: 0.1412 - accuracy: 0.9473 - val_loss: 0.5158 - val_accuracy: 0.8454\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 3s 773us/step - loss: 0.1397 - accuracy: 0.9482 - val_loss: 0.5188 - val_accuracy: 0.8411\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 3s 748us/step - loss: 0.1379 - accuracy: 0.9488 - val_loss: 0.5830 - val_accuracy: 0.8221\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 3s 762us/step - loss: 0.1379 - accuracy: 0.9480 - val_loss: 0.4872 - val_accuracy: 0.8461\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.1371 - accuracy: 0.9482 - val_loss: 0.6083 - val_accuracy: 0.8146\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 735us/step - loss: 0.1364 - accuracy: 0.9482 - val_loss: 0.5806 - val_accuracy: 0.8328\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 738us/step - loss: 0.1346 - accuracy: 0.9496 - val_loss: 0.5039 - val_accuracy: 0.8529\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 733us/step - loss: 0.1340 - accuracy: 0.9498 - val_loss: 0.5234 - val_accuracy: 0.8423\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 3s 770us/step - loss: 0.1340 - accuracy: 0.9494 - val_loss: 0.6567 - val_accuracy: 0.8100\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 670us/step - loss: 0.1329 - accuracy: 0.9501 - val_loss: 0.6071 - val_accuracy: 0.8252\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 645us/step - loss: 0.1315 - accuracy: 0.9503 - val_loss: 0.5868 - val_accuracy: 0.8362\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.1319 - accuracy: 0.9505 - val_loss: 0.5873 - val_accuracy: 0.8331\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 646us/step - loss: 0.1315 - accuracy: 0.9508 - val_loss: 0.6125 - val_accuracy: 0.8219\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.1302 - accuracy: 0.9513 - val_loss: 0.5808 - val_accuracy: 0.8373\n",
      "Epoch 1/50\n",
      "3313/3344 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.8647WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 644us/step - loss: 0.3215 - accuracy: 0.8650 - val_loss: 0.4165 - val_accuracy: 0.8329\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.2497 - accuracy: 0.9033 - val_loss: 0.3860 - val_accuracy: 0.8600\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.2318 - accuracy: 0.9091 - val_loss: 0.4343 - val_accuracy: 0.8359\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 633us/step - loss: 0.2199 - accuracy: 0.9142 - val_loss: 0.4792 - val_accuracy: 0.8160\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 641us/step - loss: 0.2113 - accuracy: 0.9182 - val_loss: 0.4790 - val_accuracy: 0.8112\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.2055 - accuracy: 0.9212 - val_loss: 0.5958 - val_accuracy: 0.7700\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 648us/step - loss: 0.1997 - accuracy: 0.9227 - val_loss: 0.4733 - val_accuracy: 0.8183\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 625us/step - loss: 0.1967 - accuracy: 0.9239 - val_loss: 0.4532 - val_accuracy: 0.8319\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.1922 - accuracy: 0.9255 - val_loss: 0.4165 - val_accuracy: 0.8328\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 655us/step - loss: 0.1879 - accuracy: 0.9277 - val_loss: 0.4966 - val_accuracy: 0.8084\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.1848 - accuracy: 0.9287 - val_loss: 0.5019 - val_accuracy: 0.8174\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 647us/step - loss: 0.1809 - accuracy: 0.9314 - val_loss: 0.4408 - val_accuracy: 0.8360\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.1782 - accuracy: 0.9316 - val_loss: 0.4365 - val_accuracy: 0.8361\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 672us/step - loss: 0.1761 - accuracy: 0.9343 - val_loss: 0.4893 - val_accuracy: 0.8252\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.1735 - accuracy: 0.9340 - val_loss: 0.4390 - val_accuracy: 0.8391\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 648us/step - loss: 0.1708 - accuracy: 0.9349 - val_loss: 0.5517 - val_accuracy: 0.8031\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.1694 - accuracy: 0.9359 - val_loss: 0.5108 - val_accuracy: 0.8139\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.1676 - accuracy: 0.9365 - val_loss: 0.4698 - val_accuracy: 0.8325\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 644us/step - loss: 0.1659 - accuracy: 0.9365 - val_loss: 0.4556 - val_accuracy: 0.8369\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.1635 - accuracy: 0.9379 - val_loss: 0.4538 - val_accuracy: 0.8378\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 641us/step - loss: 0.1612 - accuracy: 0.9382 - val_loss: 0.5014 - val_accuracy: 0.8244\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 637us/step - loss: 0.1602 - accuracy: 0.9389 - val_loss: 0.4972 - val_accuracy: 0.8213\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 662us/step - loss: 0.1592 - accuracy: 0.9393 - val_loss: 0.4554 - val_accuracy: 0.8452\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.1566 - accuracy: 0.9407 - val_loss: 0.5470 - val_accuracy: 0.8211\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 624us/step - loss: 0.1558 - accuracy: 0.9418 - val_loss: 0.5215 - val_accuracy: 0.8303\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 652us/step - loss: 0.1555 - accuracy: 0.9414 - val_loss: 0.5175 - val_accuracy: 0.8301\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.1537 - accuracy: 0.9418 - val_loss: 0.4612 - val_accuracy: 0.8483\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 653us/step - loss: 0.1516 - accuracy: 0.9430 - val_loss: 0.4935 - val_accuracy: 0.8442\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 672us/step - loss: 0.1503 - accuracy: 0.9440 - val_loss: 0.4831 - val_accuracy: 0.8383\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.1491 - accuracy: 0.9427 - val_loss: 0.5053 - val_accuracy: 0.8547\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 692us/step - loss: 0.1489 - accuracy: 0.9425 - val_loss: 0.5248 - val_accuracy: 0.8330\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 664us/step - loss: 0.1472 - accuracy: 0.9444 - val_loss: 0.4689 - val_accuracy: 0.8443\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 641us/step - loss: 0.1467 - accuracy: 0.9444 - val_loss: 0.5530 - val_accuracy: 0.8307\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 654us/step - loss: 0.1453 - accuracy: 0.9450 - val_loss: 0.5521 - val_accuracy: 0.8169\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 651us/step - loss: 0.1449 - accuracy: 0.9453 - val_loss: 0.4893 - val_accuracy: 0.8392\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 667us/step - loss: 0.1437 - accuracy: 0.9450 - val_loss: 0.5659 - val_accuracy: 0.8226\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 3s 798us/step - loss: 0.1425 - accuracy: 0.9453 - val_loss: 0.5227 - val_accuracy: 0.8428\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 3s 824us/step - loss: 0.1431 - accuracy: 0.9460 - val_loss: 0.4836 - val_accuracy: 0.8516\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 3s 770us/step - loss: 0.1426 - accuracy: 0.9459 - val_loss: 0.5534 - val_accuracy: 0.8380\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 739us/step - loss: 0.1415 - accuracy: 0.9466 - val_loss: 0.5342 - val_accuracy: 0.8400\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 3s 760us/step - loss: 0.1402 - accuracy: 0.9476 - val_loss: 0.5058 - val_accuracy: 0.8402\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 744us/step - loss: 0.1407 - accuracy: 0.9471 - val_loss: 0.4783 - val_accuracy: 0.8491\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 3s 748us/step - loss: 0.1390 - accuracy: 0.9469 - val_loss: 0.5118 - val_accuracy: 0.8429\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 3s 752us/step - loss: 0.1380 - accuracy: 0.9475 - val_loss: 0.5348 - val_accuracy: 0.8442\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 3s 763us/step - loss: 0.1373 - accuracy: 0.9471 - val_loss: 0.5652 - val_accuracy: 0.8363\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 742us/step - loss: 0.1368 - accuracy: 0.9473 - val_loss: 0.5624 - val_accuracy: 0.8299\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 734us/step - loss: 0.1358 - accuracy: 0.9477 - val_loss: 0.5034 - val_accuracy: 0.8479\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 3s 778us/step - loss: 0.1342 - accuracy: 0.9498 - val_loss: 0.6026 - val_accuracy: 0.8327\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 3s 750us/step - loss: 0.1353 - accuracy: 0.9479 - val_loss: 0.5933 - val_accuracy: 0.8339\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 736us/step - loss: 0.1345 - accuracy: 0.9488 - val_loss: 0.5979 - val_accuracy: 0.8252\n"
     ]
    }
   ],
   "source": [
    "# Train model without DP\n",
    "print(\"Training model without DP...\")\n",
    "results_no_dp = run_iterations(\n",
    "    X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "    batch_size=default_batch_size, epochs=epochs, use_dp=False, n_iterations=n_iterations,\n",
    "    l2_norm_clip=None, noise_multiplier=None\n",
    ")\n",
    "results_no_dp_stats = compute_statistics(results_no_dp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ec3c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with batch_size=16...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.1 iterated over 167200 steps satisfies differential privacy with eps = 0.849 and delta = 1e-05.\n",
      "The optimal RDP order is 19.0.\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.6616 - accuracy: 0.6027 - val_loss: 0.6549 - val_accuracy: 0.6156\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.6122 - accuracy: 0.6751 - val_loss: 0.6169 - val_accuracy: 0.6626\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5801 - accuracy: 0.7045 - val_loss: 0.6103 - val_accuracy: 0.6520\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5583 - accuracy: 0.7223 - val_loss: 0.5782 - val_accuracy: 0.6705\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.5415 - accuracy: 0.7308 - val_loss: 0.6077 - val_accuracy: 0.6468\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.5274 - accuracy: 0.7365 - val_loss: 0.6136 - val_accuracy: 0.6407\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.5143 - accuracy: 0.7450 - val_loss: 0.6143 - val_accuracy: 0.6408\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.5028 - accuracy: 0.7518 - val_loss: 0.5616 - val_accuracy: 0.6877\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.4895 - accuracy: 0.7603 - val_loss: 0.6037 - val_accuracy: 0.6542\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.4761 - accuracy: 0.7709 - val_loss: 0.5857 - val_accuracy: 0.6729\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.4612 - accuracy: 0.7816 - val_loss: 0.6181 - val_accuracy: 0.6542\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.4468 - accuracy: 0.7930 - val_loss: 0.5761 - val_accuracy: 0.6934\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.4302 - accuracy: 0.8037 - val_loss: 0.5305 - val_accuracy: 0.7357\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.4134 - accuracy: 0.8169 - val_loss: 0.5785 - val_accuracy: 0.7019\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.3975 - accuracy: 0.8287 - val_loss: 0.5128 - val_accuracy: 0.7629\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.3807 - accuracy: 0.8381 - val_loss: 0.5220 - val_accuracy: 0.7590\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3663 - accuracy: 0.8478 - val_loss: 0.4409 - val_accuracy: 0.8236\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.3524 - accuracy: 0.8561 - val_loss: 0.4692 - val_accuracy: 0.8104\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.3422 - accuracy: 0.8609 - val_loss: 0.5186 - val_accuracy: 0.7763\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.3328 - accuracy: 0.8669 - val_loss: 0.5898 - val_accuracy: 0.7295\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.3233 - accuracy: 0.8723 - val_loss: 0.4362 - val_accuracy: 0.8304\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.3165 - accuracy: 0.8756 - val_loss: 0.4218 - val_accuracy: 0.8378\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.3102 - accuracy: 0.8790 - val_loss: 0.4470 - val_accuracy: 0.8264\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.3057 - accuracy: 0.8794 - val_loss: 0.4867 - val_accuracy: 0.8107\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.3018 - accuracy: 0.8808 - val_loss: 0.5795 - val_accuracy: 0.7584\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2991 - accuracy: 0.8840 - val_loss: 0.4242 - val_accuracy: 0.8379\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2936 - accuracy: 0.8860 - val_loss: 0.5322 - val_accuracy: 0.7893\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2920 - accuracy: 0.8861 - val_loss: 0.4541 - val_accuracy: 0.8261\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2904 - accuracy: 0.8861 - val_loss: 0.5056 - val_accuracy: 0.8034\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2873 - accuracy: 0.8883 - val_loss: 0.7783 - val_accuracy: 0.6646\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.2843 - accuracy: 0.8891 - val_loss: 0.5261 - val_accuracy: 0.7938\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2836 - accuracy: 0.8890 - val_loss: 0.4885 - val_accuracy: 0.8134\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2821 - accuracy: 0.8894 - val_loss: 0.3900 - val_accuracy: 0.8517\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2810 - accuracy: 0.8905 - val_loss: 0.5484 - val_accuracy: 0.7867\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2797 - accuracy: 0.8908 - val_loss: 0.5220 - val_accuracy: 0.7976\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2784 - accuracy: 0.8905 - val_loss: 0.5735 - val_accuracy: 0.7700\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2768 - accuracy: 0.8925 - val_loss: 0.5092 - val_accuracy: 0.8014\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2746 - accuracy: 0.8936 - val_loss: 0.4816 - val_accuracy: 0.8148\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 417us/step - loss: 0.2742 - accuracy: 0.8931 - val_loss: 0.4487 - val_accuracy: 0.8259\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.2726 - accuracy: 0.8940 - val_loss: 0.4241 - val_accuracy: 0.8364\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.2726 - accuracy: 0.8951 - val_loss: 0.5442 - val_accuracy: 0.7857\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2710 - accuracy: 0.8937 - val_loss: 0.4488 - val_accuracy: 0.8269\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2695 - accuracy: 0.8940 - val_loss: 0.4573 - val_accuracy: 0.8216\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2680 - accuracy: 0.8946 - val_loss: 0.4000 - val_accuracy: 0.8458\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 417us/step - loss: 0.2685 - accuracy: 0.8947 - val_loss: 0.5505 - val_accuracy: 0.7807\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2682 - accuracy: 0.8943 - val_loss: 0.3598 - val_accuracy: 0.8620\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2671 - accuracy: 0.8960 - val_loss: 0.5176 - val_accuracy: 0.7980\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 417us/step - loss: 0.2669 - accuracy: 0.8945 - val_loss: 0.4045 - val_accuracy: 0.8455\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.2654 - accuracy: 0.8963 - val_loss: 0.6081 - val_accuracy: 0.7533\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.2649 - accuracy: 0.8970 - val_loss: 0.4834 - val_accuracy: 0.8123\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.6602 - accuracy: 0.6038 - val_loss: 0.6264 - val_accuracy: 0.6882\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.6163 - accuracy: 0.6634 - val_loss: 0.6411 - val_accuracy: 0.6146\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.5854 - accuracy: 0.6934 - val_loss: 0.5948 - val_accuracy: 0.6600\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.5620 - accuracy: 0.7142 - val_loss: 0.6592 - val_accuracy: 0.6049\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.5443 - accuracy: 0.7232 - val_loss: 0.6339 - val_accuracy: 0.6280\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5298 - accuracy: 0.7330 - val_loss: 0.5933 - val_accuracy: 0.6602\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5179 - accuracy: 0.7394 - val_loss: 0.5911 - val_accuracy: 0.6629\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.5061 - accuracy: 0.7491 - val_loss: 0.5584 - val_accuracy: 0.6900\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.4945 - accuracy: 0.7552 - val_loss: 0.5937 - val_accuracy: 0.6619\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.4828 - accuracy: 0.7649 - val_loss: 0.6229 - val_accuracy: 0.6423\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.4694 - accuracy: 0.7740 - val_loss: 0.5891 - val_accuracy: 0.6773\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.4557 - accuracy: 0.7846 - val_loss: 0.5317 - val_accuracy: 0.7313\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.4424 - accuracy: 0.7941 - val_loss: 0.5142 - val_accuracy: 0.7516\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.4272 - accuracy: 0.8044 - val_loss: 0.6566 - val_accuracy: 0.6455\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.4119 - accuracy: 0.8157 - val_loss: 0.4750 - val_accuracy: 0.7934\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.3950 - accuracy: 0.8272 - val_loss: 0.4931 - val_accuracy: 0.7820\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.3800 - accuracy: 0.8368 - val_loss: 0.4352 - val_accuracy: 0.8231\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.3659 - accuracy: 0.8467 - val_loss: 0.4609 - val_accuracy: 0.8105\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.3533 - accuracy: 0.8542 - val_loss: 0.5305 - val_accuracy: 0.7627\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.3426 - accuracy: 0.8618 - val_loss: 0.4642 - val_accuracy: 0.8107\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.3303 - accuracy: 0.8675 - val_loss: 0.4517 - val_accuracy: 0.8186\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.3235 - accuracy: 0.8702 - val_loss: 0.4602 - val_accuracy: 0.8152\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.3149 - accuracy: 0.8753 - val_loss: 0.4014 - val_accuracy: 0.8402\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.3083 - accuracy: 0.8777 - val_loss: 0.4324 - val_accuracy: 0.8315\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.3028 - accuracy: 0.8812 - val_loss: 0.5488 - val_accuracy: 0.7722\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2992 - accuracy: 0.8819 - val_loss: 0.4311 - val_accuracy: 0.8314\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2956 - accuracy: 0.8836 - val_loss: 0.4485 - val_accuracy: 0.8228\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2915 - accuracy: 0.8851 - val_loss: 0.5120 - val_accuracy: 0.7954\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2884 - accuracy: 0.8874 - val_loss: 0.4750 - val_accuracy: 0.8122\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2850 - accuracy: 0.8894 - val_loss: 0.5491 - val_accuracy: 0.7758\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2836 - accuracy: 0.8888 - val_loss: 0.4722 - val_accuracy: 0.8161\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2811 - accuracy: 0.8897 - val_loss: 0.6093 - val_accuracy: 0.7465\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2802 - accuracy: 0.8897 - val_loss: 0.3784 - val_accuracy: 0.8527\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2781 - accuracy: 0.8903 - val_loss: 0.4768 - val_accuracy: 0.8137\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2750 - accuracy: 0.8917 - val_loss: 0.4275 - val_accuracy: 0.8334\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2740 - accuracy: 0.8915 - val_loss: 0.4173 - val_accuracy: 0.8393\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2732 - accuracy: 0.8918 - val_loss: 0.4199 - val_accuracy: 0.8353\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2715 - accuracy: 0.8934 - val_loss: 0.4628 - val_accuracy: 0.8189\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2705 - accuracy: 0.8932 - val_loss: 0.5315 - val_accuracy: 0.7909\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2697 - accuracy: 0.8951 - val_loss: 0.3934 - val_accuracy: 0.8487\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2677 - accuracy: 0.8947 - val_loss: 0.6127 - val_accuracy: 0.7470\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2675 - accuracy: 0.8951 - val_loss: 0.5281 - val_accuracy: 0.7877\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2672 - accuracy: 0.8955 - val_loss: 0.5508 - val_accuracy: 0.7777\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2665 - accuracy: 0.8951 - val_loss: 0.4590 - val_accuracy: 0.8190\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2631 - accuracy: 0.8957 - val_loss: 0.3738 - val_accuracy: 0.8572\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.2633 - accuracy: 0.8972 - val_loss: 0.4437 - val_accuracy: 0.8273\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.2624 - accuracy: 0.8976 - val_loss: 0.4507 - val_accuracy: 0.8213\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2621 - accuracy: 0.8964 - val_loss: 0.4249 - val_accuracy: 0.8334\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2611 - accuracy: 0.8984 - val_loss: 0.5336 - val_accuracy: 0.7864\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2600 - accuracy: 0.8984 - val_loss: 0.4779 - val_accuracy: 0.8161\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.6494 - accuracy: 0.6214 - val_loss: 0.6336 - val_accuracy: 0.6279\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.5903 - accuracy: 0.6952 - val_loss: 0.6364 - val_accuracy: 0.6214\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.5621 - accuracy: 0.7171 - val_loss: 0.5807 - val_accuracy: 0.6653\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5432 - accuracy: 0.7283 - val_loss: 0.5735 - val_accuracy: 0.6695\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.5274 - accuracy: 0.7379 - val_loss: 0.6270 - val_accuracy: 0.6269\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.5129 - accuracy: 0.7471 - val_loss: 0.6048 - val_accuracy: 0.6467\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.4998 - accuracy: 0.7541 - val_loss: 0.5383 - val_accuracy: 0.7052\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.4862 - accuracy: 0.7643 - val_loss: 0.5413 - val_accuracy: 0.7065\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.4725 - accuracy: 0.7741 - val_loss: 0.5308 - val_accuracy: 0.7206\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.4567 - accuracy: 0.7839 - val_loss: 0.5483 - val_accuracy: 0.7066\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.4392 - accuracy: 0.7976 - val_loss: 0.5126 - val_accuracy: 0.7465\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.4234 - accuracy: 0.8094 - val_loss: 0.5762 - val_accuracy: 0.6970\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.4066 - accuracy: 0.8191 - val_loss: 0.4498 - val_accuracy: 0.8031\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.3905 - accuracy: 0.8303 - val_loss: 0.5195 - val_accuracy: 0.7525\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.3724 - accuracy: 0.8405 - val_loss: 0.4595 - val_accuracy: 0.8069\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.3599 - accuracy: 0.8498 - val_loss: 0.4905 - val_accuracy: 0.7859\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.3473 - accuracy: 0.8570 - val_loss: 0.4633 - val_accuracy: 0.8084\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.3364 - accuracy: 0.8633 - val_loss: 0.4779 - val_accuracy: 0.8043\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.3265 - accuracy: 0.8702 - val_loss: 0.4227 - val_accuracy: 0.8318\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.3192 - accuracy: 0.8729 - val_loss: 0.5837 - val_accuracy: 0.7395\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.3110 - accuracy: 0.8755 - val_loss: 0.4182 - val_accuracy: 0.8356\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3070 - accuracy: 0.8781 - val_loss: 0.5028 - val_accuracy: 0.7972\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.3020 - accuracy: 0.8798 - val_loss: 0.3866 - val_accuracy: 0.8510\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2979 - accuracy: 0.8823 - val_loss: 0.4791 - val_accuracy: 0.8111\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.2955 - accuracy: 0.8826 - val_loss: 0.4673 - val_accuracy: 0.8180\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.2921 - accuracy: 0.8858 - val_loss: 0.3876 - val_accuracy: 0.8505\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2903 - accuracy: 0.8857 - val_loss: 0.5493 - val_accuracy: 0.7777\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.2878 - accuracy: 0.8868 - val_loss: 0.6233 - val_accuracy: 0.7352\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.2848 - accuracy: 0.8874 - val_loss: 0.5725 - val_accuracy: 0.7631\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2850 - accuracy: 0.8880 - val_loss: 0.5700 - val_accuracy: 0.7682\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.2820 - accuracy: 0.8892 - val_loss: 0.4860 - val_accuracy: 0.8069\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.2800 - accuracy: 0.8901 - val_loss: 0.4058 - val_accuracy: 0.8420\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2791 - accuracy: 0.8895 - val_loss: 0.4653 - val_accuracy: 0.8193\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2769 - accuracy: 0.8920 - val_loss: 0.5363 - val_accuracy: 0.7835\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2774 - accuracy: 0.8917 - val_loss: 0.5652 - val_accuracy: 0.7709\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2745 - accuracy: 0.8929 - val_loss: 0.4359 - val_accuracy: 0.8289\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2745 - accuracy: 0.8918 - val_loss: 0.4112 - val_accuracy: 0.8399\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2733 - accuracy: 0.8918 - val_loss: 0.4578 - val_accuracy: 0.8203\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.2714 - accuracy: 0.8941 - val_loss: 0.5619 - val_accuracy: 0.7710\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.2703 - accuracy: 0.8935 - val_loss: 0.5046 - val_accuracy: 0.8044\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2708 - accuracy: 0.8945 - val_loss: 0.4713 - val_accuracy: 0.8126\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2698 - accuracy: 0.8946 - val_loss: 0.4019 - val_accuracy: 0.8442\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2682 - accuracy: 0.8948 - val_loss: 0.5431 - val_accuracy: 0.7820\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2678 - accuracy: 0.8958 - val_loss: 0.3928 - val_accuracy: 0.8476\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2663 - accuracy: 0.8957 - val_loss: 0.7862 - val_accuracy: 0.6648\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2678 - accuracy: 0.8959 - val_loss: 0.5087 - val_accuracy: 0.7997\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2651 - accuracy: 0.8966 - val_loss: 0.3648 - val_accuracy: 0.8600\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2645 - accuracy: 0.8969 - val_loss: 0.4593 - val_accuracy: 0.8169\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2630 - accuracy: 0.8970 - val_loss: 0.4125 - val_accuracy: 0.8367\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2640 - accuracy: 0.8966 - val_loss: 0.4158 - val_accuracy: 0.8349\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.6508 - accuracy: 0.6176 - val_loss: 0.6170 - val_accuracy: 0.6753\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5959 - accuracy: 0.6869 - val_loss: 0.6444 - val_accuracy: 0.6162\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.5678 - accuracy: 0.7096 - val_loss: 0.5893 - val_accuracy: 0.6653\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.5460 - accuracy: 0.7266 - val_loss: 0.5786 - val_accuracy: 0.6728\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.5304 - accuracy: 0.7359 - val_loss: 0.5560 - val_accuracy: 0.6918\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.5169 - accuracy: 0.7416 - val_loss: 0.5896 - val_accuracy: 0.6631\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.5056 - accuracy: 0.7516 - val_loss: 0.5835 - val_accuracy: 0.6707\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.4940 - accuracy: 0.7589 - val_loss: 0.5797 - val_accuracy: 0.6733\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.4821 - accuracy: 0.7676 - val_loss: 0.5197 - val_accuracy: 0.7306\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.5762 - val_accuracy: 0.6814\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.4548 - accuracy: 0.7864 - val_loss: 0.6245 - val_accuracy: 0.6508\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.4411 - accuracy: 0.7958 - val_loss: 0.5818 - val_accuracy: 0.6876\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.4262 - accuracy: 0.8082 - val_loss: 0.4731 - val_accuracy: 0.7805\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.4118 - accuracy: 0.8166 - val_loss: 0.5575 - val_accuracy: 0.7152\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.3948 - accuracy: 0.8297 - val_loss: 0.5842 - val_accuracy: 0.6970\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.3797 - accuracy: 0.8383 - val_loss: 0.5072 - val_accuracy: 0.7638\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.3671 - accuracy: 0.8465 - val_loss: 0.4373 - val_accuracy: 0.8215\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.3526 - accuracy: 0.8541 - val_loss: 0.4863 - val_accuracy: 0.7897\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.3420 - accuracy: 0.8619 - val_loss: 0.4619 - val_accuracy: 0.8113\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.3319 - accuracy: 0.8655 - val_loss: 0.6084 - val_accuracy: 0.7102\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.3240 - accuracy: 0.8717 - val_loss: 0.4665 - val_accuracy: 0.8127\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.3168 - accuracy: 0.8730 - val_loss: 0.4666 - val_accuracy: 0.8147\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.3116 - accuracy: 0.8774 - val_loss: 0.4720 - val_accuracy: 0.8129\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.3071 - accuracy: 0.8790 - val_loss: 0.3808 - val_accuracy: 0.8513\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.3023 - accuracy: 0.8811 - val_loss: 0.4256 - val_accuracy: 0.8351\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2983 - accuracy: 0.8820 - val_loss: 0.4901 - val_accuracy: 0.8035\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2959 - accuracy: 0.8827 - val_loss: 0.4252 - val_accuracy: 0.8338\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2932 - accuracy: 0.8854 - val_loss: 0.4581 - val_accuracy: 0.8211\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2904 - accuracy: 0.8854 - val_loss: 0.4722 - val_accuracy: 0.8142\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.2883 - accuracy: 0.8869 - val_loss: 0.4990 - val_accuracy: 0.8012\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2868 - accuracy: 0.8883 - val_loss: 0.5466 - val_accuracy: 0.7746\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2847 - accuracy: 0.8876 - val_loss: 0.4527 - val_accuracy: 0.8237\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2822 - accuracy: 0.8899 - val_loss: 0.5263 - val_accuracy: 0.7860\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2799 - accuracy: 0.8904 - val_loss: 0.4071 - val_accuracy: 0.8418\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.2781 - accuracy: 0.8914 - val_loss: 0.5656 - val_accuracy: 0.7686\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.2769 - accuracy: 0.8907 - val_loss: 0.4450 - val_accuracy: 0.8257\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2758 - accuracy: 0.8919 - val_loss: 0.4888 - val_accuracy: 0.8028\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.2733 - accuracy: 0.8932 - val_loss: 0.5373 - val_accuracy: 0.7830\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2717 - accuracy: 0.8944 - val_loss: 0.4694 - val_accuracy: 0.8157\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.2690 - accuracy: 0.8945 - val_loss: 0.4438 - val_accuracy: 0.8236\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2705 - accuracy: 0.8944 - val_loss: 0.4114 - val_accuracy: 0.8369\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2685 - accuracy: 0.8945 - val_loss: 0.5861 - val_accuracy: 0.7561\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2669 - accuracy: 0.8958 - val_loss: 0.4009 - val_accuracy: 0.8422\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.2665 - accuracy: 0.8953 - val_loss: 0.5052 - val_accuracy: 0.7983\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2642 - accuracy: 0.8963 - val_loss: 0.4319 - val_accuracy: 0.8278\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2633 - accuracy: 0.8964 - val_loss: 0.4932 - val_accuracy: 0.8026\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2632 - accuracy: 0.8971 - val_loss: 0.5134 - val_accuracy: 0.7946\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2620 - accuracy: 0.8968 - val_loss: 0.5233 - val_accuracy: 0.7901\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2612 - accuracy: 0.8974 - val_loss: 0.4746 - val_accuracy: 0.8136\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2605 - accuracy: 0.8977 - val_loss: 0.3827 - val_accuracy: 0.8449\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.6636 - accuracy: 0.5857 - val_loss: 0.6202 - val_accuracy: 0.6368\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.6035 - accuracy: 0.6765 - val_loss: 0.5952 - val_accuracy: 0.6637\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.5713 - accuracy: 0.7118 - val_loss: 0.5715 - val_accuracy: 0.6883\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.5498 - accuracy: 0.7265 - val_loss: 0.5930 - val_accuracy: 0.6692\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.5325 - accuracy: 0.7371 - val_loss: 0.6289 - val_accuracy: 0.6308\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.5198 - accuracy: 0.7440 - val_loss: 0.5975 - val_accuracy: 0.6614\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.5083 - accuracy: 0.7507 - val_loss: 0.5946 - val_accuracy: 0.6686\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.4957 - accuracy: 0.7594 - val_loss: 0.5836 - val_accuracy: 0.6802\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.4837 - accuracy: 0.7664 - val_loss: 0.5568 - val_accuracy: 0.7014\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.4711 - accuracy: 0.7753 - val_loss: 0.5630 - val_accuracy: 0.6997\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.4576 - accuracy: 0.7853 - val_loss: 0.5663 - val_accuracy: 0.6995\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.4439 - accuracy: 0.7927 - val_loss: 0.5063 - val_accuracy: 0.7536\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.4293 - accuracy: 0.8037 - val_loss: 0.5501 - val_accuracy: 0.7221\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.4132 - accuracy: 0.8159 - val_loss: 0.5409 - val_accuracy: 0.7343\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.3983 - accuracy: 0.8260 - val_loss: 0.4943 - val_accuracy: 0.7783\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.3815 - accuracy: 0.8378 - val_loss: 0.4998 - val_accuracy: 0.7779\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.3661 - accuracy: 0.8469 - val_loss: 0.4840 - val_accuracy: 0.7937\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.3521 - accuracy: 0.8562 - val_loss: 0.4662 - val_accuracy: 0.8110\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.3410 - accuracy: 0.8638 - val_loss: 0.4307 - val_accuracy: 0.8319\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.3307 - accuracy: 0.8687 - val_loss: 0.5563 - val_accuracy: 0.7541\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.3226 - accuracy: 0.8739 - val_loss: 0.4428 - val_accuracy: 0.8267\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.3159 - accuracy: 0.8764 - val_loss: 0.4373 - val_accuracy: 0.8313\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.3106 - accuracy: 0.8774 - val_loss: 0.4260 - val_accuracy: 0.8353\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.3045 - accuracy: 0.8809 - val_loss: 0.4133 - val_accuracy: 0.8404\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.3018 - accuracy: 0.8816 - val_loss: 0.6298 - val_accuracy: 0.7227\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.2992 - accuracy: 0.8825 - val_loss: 0.5493 - val_accuracy: 0.7796\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2942 - accuracy: 0.8855 - val_loss: 0.6148 - val_accuracy: 0.7415\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2926 - accuracy: 0.8864 - val_loss: 0.4441 - val_accuracy: 0.8310\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.2901 - accuracy: 0.8875 - val_loss: 0.4522 - val_accuracy: 0.8267\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.2876 - accuracy: 0.8868 - val_loss: 0.4486 - val_accuracy: 0.8293\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.2866 - accuracy: 0.8865 - val_loss: 0.4722 - val_accuracy: 0.8189\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2852 - accuracy: 0.8888 - val_loss: 0.5285 - val_accuracy: 0.7925\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2836 - accuracy: 0.8884 - val_loss: 0.9083 - val_accuracy: 0.6109\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.2817 - accuracy: 0.8906 - val_loss: 0.4444 - val_accuracy: 0.8286\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.2809 - accuracy: 0.8908 - val_loss: 0.4411 - val_accuracy: 0.8305\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2793 - accuracy: 0.8907 - val_loss: 0.4785 - val_accuracy: 0.8161\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2768 - accuracy: 0.8903 - val_loss: 0.4155 - val_accuracy: 0.8401\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2769 - accuracy: 0.8917 - val_loss: 0.4888 - val_accuracy: 0.8082\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2763 - accuracy: 0.8925 - val_loss: 0.4697 - val_accuracy: 0.8195\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2736 - accuracy: 0.8940 - val_loss: 0.4650 - val_accuracy: 0.8226\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2737 - accuracy: 0.8927 - val_loss: 0.4105 - val_accuracy: 0.8425\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.2727 - accuracy: 0.8932 - val_loss: 0.6887 - val_accuracy: 0.7136\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.2709 - accuracy: 0.8946 - val_loss: 0.4337 - val_accuracy: 0.8328\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2712 - accuracy: 0.8957 - val_loss: 0.4087 - val_accuracy: 0.8426\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2702 - accuracy: 0.8944 - val_loss: 0.4317 - val_accuracy: 0.8313\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.2687 - accuracy: 0.8953 - val_loss: 0.5777 - val_accuracy: 0.7676\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.2680 - accuracy: 0.8956 - val_loss: 0.3934 - val_accuracy: 0.8452\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2675 - accuracy: 0.8958 - val_loss: 0.5894 - val_accuracy: 0.7619\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.2663 - accuracy: 0.8960 - val_loss: 0.4824 - val_accuracy: 0.8087\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2652 - accuracy: 0.8964 - val_loss: 0.4513 - val_accuracy: 0.8211\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.6519 - accuracy: 0.6177 - val_loss: 0.6234 - val_accuracy: 0.6598\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.5882 - accuracy: 0.6968 - val_loss: 0.6239 - val_accuracy: 0.6335\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.5555 - accuracy: 0.7188 - val_loss: 0.5743 - val_accuracy: 0.6747\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.5371 - accuracy: 0.7299 - val_loss: 0.6007 - val_accuracy: 0.6512\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.5235 - accuracy: 0.7381 - val_loss: 0.6100 - val_accuracy: 0.6449\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.5117 - accuracy: 0.7446 - val_loss: 0.5932 - val_accuracy: 0.6659\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5008 - accuracy: 0.7498 - val_loss: 0.6299 - val_accuracy: 0.6412\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.4915 - accuracy: 0.7568 - val_loss: 0.5990 - val_accuracy: 0.6707\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.4818 - accuracy: 0.7646 - val_loss: 0.5829 - val_accuracy: 0.6851\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.4708 - accuracy: 0.7731 - val_loss: 0.5434 - val_accuracy: 0.7207\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.4586 - accuracy: 0.7819 - val_loss: 0.5758 - val_accuracy: 0.7016\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.4453 - accuracy: 0.7926 - val_loss: 0.6054 - val_accuracy: 0.6862\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.4325 - accuracy: 0.8028 - val_loss: 0.6159 - val_accuracy: 0.6796\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.4177 - accuracy: 0.8128 - val_loss: 0.4959 - val_accuracy: 0.7761\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.4024 - accuracy: 0.8241 - val_loss: 0.4593 - val_accuracy: 0.8077\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.3873 - accuracy: 0.8342 - val_loss: 0.4830 - val_accuracy: 0.7934\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.3713 - accuracy: 0.8433 - val_loss: 0.5351 - val_accuracy: 0.7587\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.3584 - accuracy: 0.8521 - val_loss: 0.4682 - val_accuracy: 0.8116\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.3474 - accuracy: 0.8584 - val_loss: 0.4949 - val_accuracy: 0.7973\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.3373 - accuracy: 0.8640 - val_loss: 0.4647 - val_accuracy: 0.8203\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.3295 - accuracy: 0.8689 - val_loss: 0.4765 - val_accuracy: 0.8141\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.3227 - accuracy: 0.8714 - val_loss: 0.5225 - val_accuracy: 0.7864\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3167 - accuracy: 0.8749 - val_loss: 0.4274 - val_accuracy: 0.8382\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.3100 - accuracy: 0.8768 - val_loss: 0.5706 - val_accuracy: 0.7669\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.3072 - accuracy: 0.8797 - val_loss: 0.5206 - val_accuracy: 0.7960\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.3039 - accuracy: 0.8797 - val_loss: 0.4629 - val_accuracy: 0.8245\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.3000 - accuracy: 0.8818 - val_loss: 0.4710 - val_accuracy: 0.8205\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.2970 - accuracy: 0.8839 - val_loss: 0.4793 - val_accuracy: 0.8185\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2943 - accuracy: 0.8837 - val_loss: 0.3753 - val_accuracy: 0.8592\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.2915 - accuracy: 0.8867 - val_loss: 0.4484 - val_accuracy: 0.8305\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.2917 - accuracy: 0.8857 - val_loss: 0.4443 - val_accuracy: 0.8318\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2892 - accuracy: 0.8874 - val_loss: 0.6424 - val_accuracy: 0.7386\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2863 - accuracy: 0.8893 - val_loss: 0.4491 - val_accuracy: 0.8294\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.2859 - accuracy: 0.8877 - val_loss: 0.6357 - val_accuracy: 0.7392\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.2844 - accuracy: 0.8891 - val_loss: 0.5047 - val_accuracy: 0.8075\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2818 - accuracy: 0.8899 - val_loss: 0.5059 - val_accuracy: 0.8045\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.2808 - accuracy: 0.8911 - val_loss: 0.5032 - val_accuracy: 0.8048\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2786 - accuracy: 0.8920 - val_loss: 0.4592 - val_accuracy: 0.8228\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.2782 - accuracy: 0.8926 - val_loss: 0.5155 - val_accuracy: 0.8013\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2776 - accuracy: 0.8920 - val_loss: 0.5222 - val_accuracy: 0.7930\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2749 - accuracy: 0.8934 - val_loss: 0.4820 - val_accuracy: 0.8128\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2751 - accuracy: 0.8933 - val_loss: 0.4200 - val_accuracy: 0.8397\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2742 - accuracy: 0.8932 - val_loss: 0.5425 - val_accuracy: 0.7862\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2723 - accuracy: 0.8942 - val_loss: 0.5032 - val_accuracy: 0.8033\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2710 - accuracy: 0.8952 - val_loss: 0.4100 - val_accuracy: 0.8433\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2693 - accuracy: 0.8954 - val_loss: 0.5135 - val_accuracy: 0.7977\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2698 - accuracy: 0.8954 - val_loss: 0.4771 - val_accuracy: 0.8131\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2689 - accuracy: 0.8960 - val_loss: 0.3782 - val_accuracy: 0.8550\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.2666 - accuracy: 0.8963 - val_loss: 0.4381 - val_accuracy: 0.8304\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2662 - accuracy: 0.8981 - val_loss: 0.4843 - val_accuracy: 0.8100\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.6524 - accuracy: 0.6135 - val_loss: 0.6301 - val_accuracy: 0.6681\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5947 - accuracy: 0.6951 - val_loss: 0.6319 - val_accuracy: 0.6169\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 449us/step - loss: 0.5620 - accuracy: 0.7178 - val_loss: 0.6210 - val_accuracy: 0.6232\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.5405 - accuracy: 0.7308 - val_loss: 0.5696 - val_accuracy: 0.6700\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.5242 - accuracy: 0.7387 - val_loss: 0.5801 - val_accuracy: 0.6605\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.5077 - accuracy: 0.7478 - val_loss: 0.5393 - val_accuracy: 0.7073\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.4938 - accuracy: 0.7570 - val_loss: 0.5798 - val_accuracy: 0.6669\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.4799 - accuracy: 0.7670 - val_loss: 0.5504 - val_accuracy: 0.7009\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.4653 - accuracy: 0.7780 - val_loss: 0.5080 - val_accuracy: 0.7457\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.4493 - accuracy: 0.7886 - val_loss: 0.5005 - val_accuracy: 0.7575\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.4333 - accuracy: 0.8011 - val_loss: 0.5196 - val_accuracy: 0.7434\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.4162 - accuracy: 0.8121 - val_loss: 0.5787 - val_accuracy: 0.6995\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.3998 - accuracy: 0.8250 - val_loss: 0.5486 - val_accuracy: 0.7276\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.3835 - accuracy: 0.8357 - val_loss: 0.6336 - val_accuracy: 0.6746\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.3680 - accuracy: 0.8460 - val_loss: 0.5146 - val_accuracy: 0.7710\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.3553 - accuracy: 0.8532 - val_loss: 0.4459 - val_accuracy: 0.8182\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.3434 - accuracy: 0.8607 - val_loss: 0.4675 - val_accuracy: 0.8087\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.3342 - accuracy: 0.8653 - val_loss: 0.5572 - val_accuracy: 0.7552\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.3256 - accuracy: 0.8689 - val_loss: 0.3872 - val_accuracy: 0.8461\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.3184 - accuracy: 0.8726 - val_loss: 0.5623 - val_accuracy: 0.7608\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.3124 - accuracy: 0.8759 - val_loss: 0.3951 - val_accuracy: 0.8442\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.3077 - accuracy: 0.8781 - val_loss: 0.4918 - val_accuracy: 0.8024\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.3031 - accuracy: 0.8794 - val_loss: 0.5278 - val_accuracy: 0.7871\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.2999 - accuracy: 0.8810 - val_loss: 0.4039 - val_accuracy: 0.8453\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.2974 - accuracy: 0.8834 - val_loss: 0.5774 - val_accuracy: 0.7609\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.2955 - accuracy: 0.8847 - val_loss: 0.4401 - val_accuracy: 0.8294\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2914 - accuracy: 0.8854 - val_loss: 0.3818 - val_accuracy: 0.8515\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2903 - accuracy: 0.8851 - val_loss: 0.4139 - val_accuracy: 0.8410\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2873 - accuracy: 0.8869 - val_loss: 0.3580 - val_accuracy: 0.8621\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2859 - accuracy: 0.8873 - val_loss: 0.3973 - val_accuracy: 0.8473\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.2854 - accuracy: 0.8883 - val_loss: 0.5854 - val_accuracy: 0.7624\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.2819 - accuracy: 0.8895 - val_loss: 0.3950 - val_accuracy: 0.8475\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.2807 - accuracy: 0.8889 - val_loss: 0.5431 - val_accuracy: 0.7829\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2810 - accuracy: 0.8899 - val_loss: 0.3756 - val_accuracy: 0.8537\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2784 - accuracy: 0.8898 - val_loss: 0.4036 - val_accuracy: 0.8451\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2769 - accuracy: 0.8911 - val_loss: 0.4885 - val_accuracy: 0.8075\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2765 - accuracy: 0.8914 - val_loss: 0.4124 - val_accuracy: 0.8395\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.2758 - accuracy: 0.8928 - val_loss: 0.4574 - val_accuracy: 0.8200\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.2746 - accuracy: 0.8923 - val_loss: 0.4710 - val_accuracy: 0.8170\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2720 - accuracy: 0.8936 - val_loss: 0.4731 - val_accuracy: 0.8163\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2726 - accuracy: 0.8930 - val_loss: 0.5875 - val_accuracy: 0.7619\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.2722 - accuracy: 0.8937 - val_loss: 0.5390 - val_accuracy: 0.7815\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.2707 - accuracy: 0.8940 - val_loss: 0.4630 - val_accuracy: 0.8163\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2691 - accuracy: 0.8953 - val_loss: 0.4943 - val_accuracy: 0.8085\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.2680 - accuracy: 0.8954 - val_loss: 0.4102 - val_accuracy: 0.8383\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2671 - accuracy: 0.8957 - val_loss: 0.3996 - val_accuracy: 0.8441\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.2660 - accuracy: 0.8966 - val_loss: 0.3965 - val_accuracy: 0.8450\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2661 - accuracy: 0.8949 - val_loss: 0.4176 - val_accuracy: 0.8331\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2649 - accuracy: 0.8958 - val_loss: 0.4865 - val_accuracy: 0.8063\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2638 - accuracy: 0.8961 - val_loss: 0.3837 - val_accuracy: 0.8476\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.6440 - accuracy: 0.6143 - val_loss: 0.6325 - val_accuracy: 0.6624\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5939 - accuracy: 0.6710 - val_loss: 0.6269 - val_accuracy: 0.6300\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.5639 - accuracy: 0.7068 - val_loss: 0.5702 - val_accuracy: 0.6892\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.5422 - accuracy: 0.7268 - val_loss: 0.6037 - val_accuracy: 0.6489\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.5272 - accuracy: 0.7353 - val_loss: 0.5750 - val_accuracy: 0.6793\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.5147 - accuracy: 0.7416 - val_loss: 0.5968 - val_accuracy: 0.6556\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5025 - accuracy: 0.7504 - val_loss: 0.6061 - val_accuracy: 0.6511\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.4916 - accuracy: 0.7572 - val_loss: 0.5704 - val_accuracy: 0.6872\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.4814 - accuracy: 0.7665 - val_loss: 0.5064 - val_accuracy: 0.7535\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.4679 - accuracy: 0.7734 - val_loss: 0.6003 - val_accuracy: 0.6679\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.4559 - accuracy: 0.7841 - val_loss: 0.6288 - val_accuracy: 0.6456\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.4405 - accuracy: 0.7960 - val_loss: 0.5617 - val_accuracy: 0.7114\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.4254 - accuracy: 0.8053 - val_loss: 0.6020 - val_accuracy: 0.6849\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.4090 - accuracy: 0.8193 - val_loss: 0.5821 - val_accuracy: 0.7072\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.3915 - accuracy: 0.8326 - val_loss: 0.6163 - val_accuracy: 0.6911\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.3754 - accuracy: 0.8420 - val_loss: 0.5658 - val_accuracy: 0.7365\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.3609 - accuracy: 0.8522 - val_loss: 0.5293 - val_accuracy: 0.7676\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3489 - accuracy: 0.8590 - val_loss: 0.4688 - val_accuracy: 0.8130\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.3346 - accuracy: 0.8660 - val_loss: 0.4557 - val_accuracy: 0.8224\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.3265 - accuracy: 0.8709 - val_loss: 0.4460 - val_accuracy: 0.8279\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3172 - accuracy: 0.8752 - val_loss: 0.4541 - val_accuracy: 0.8259\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.3114 - accuracy: 0.8783 - val_loss: 0.5129 - val_accuracy: 0.7954\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.3063 - accuracy: 0.8821 - val_loss: 0.4557 - val_accuracy: 0.8257\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.3008 - accuracy: 0.8832 - val_loss: 0.4769 - val_accuracy: 0.8174\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.2968 - accuracy: 0.8844 - val_loss: 0.4915 - val_accuracy: 0.8106\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2939 - accuracy: 0.8852 - val_loss: 0.5180 - val_accuracy: 0.8001\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.2917 - accuracy: 0.8866 - val_loss: 0.4952 - val_accuracy: 0.8091\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2877 - accuracy: 0.8881 - val_loss: 0.6163 - val_accuracy: 0.7501\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2857 - accuracy: 0.8879 - val_loss: 0.3707 - val_accuracy: 0.8594\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2845 - accuracy: 0.8875 - val_loss: 0.5026 - val_accuracy: 0.8079\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.2827 - accuracy: 0.8906 - val_loss: 0.4148 - val_accuracy: 0.8428\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2817 - accuracy: 0.8905 - val_loss: 0.5499 - val_accuracy: 0.7849\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.2787 - accuracy: 0.8907 - val_loss: 0.4269 - val_accuracy: 0.8381\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2774 - accuracy: 0.8923 - val_loss: 0.4668 - val_accuracy: 0.8215\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2765 - accuracy: 0.8920 - val_loss: 0.7053 - val_accuracy: 0.7125\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2747 - accuracy: 0.8928 - val_loss: 0.4175 - val_accuracy: 0.8415\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2734 - accuracy: 0.8936 - val_loss: 0.4772 - val_accuracy: 0.8183\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2714 - accuracy: 0.8935 - val_loss: 0.4022 - val_accuracy: 0.8465\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2715 - accuracy: 0.8943 - val_loss: 0.5258 - val_accuracy: 0.7984\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2709 - accuracy: 0.8952 - val_loss: 0.5362 - val_accuracy: 0.7878\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2699 - accuracy: 0.8962 - val_loss: 0.3393 - val_accuracy: 0.8682\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2687 - accuracy: 0.8957 - val_loss: 0.6747 - val_accuracy: 0.7259\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.2672 - accuracy: 0.8957 - val_loss: 0.4302 - val_accuracy: 0.8332\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2662 - accuracy: 0.8970 - val_loss: 0.4820 - val_accuracy: 0.8132\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2664 - accuracy: 0.8964 - val_loss: 0.4746 - val_accuracy: 0.8152\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2665 - accuracy: 0.8965 - val_loss: 0.4591 - val_accuracy: 0.8232\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.2666 - accuracy: 0.8971 - val_loss: 0.4526 - val_accuracy: 0.8238\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2643 - accuracy: 0.8980 - val_loss: 0.5281 - val_accuracy: 0.7951\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2646 - accuracy: 0.8982 - val_loss: 0.4398 - val_accuracy: 0.8289\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2635 - accuracy: 0.8977 - val_loss: 0.5425 - val_accuracy: 0.7917\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.6796 - accuracy: 0.5794 - val_loss: 0.6840 - val_accuracy: 0.5632\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.6341 - accuracy: 0.6638 - val_loss: 0.6327 - val_accuracy: 0.6365\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.6020 - accuracy: 0.6897 - val_loss: 0.6290 - val_accuracy: 0.6248\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.5777 - accuracy: 0.7054 - val_loss: 0.6324 - val_accuracy: 0.6185\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.5604 - accuracy: 0.7164 - val_loss: 0.6262 - val_accuracy: 0.6363\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.5465 - accuracy: 0.7246 - val_loss: 0.6355 - val_accuracy: 0.6361\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.5356 - accuracy: 0.7302 - val_loss: 0.6647 - val_accuracy: 0.6138\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5255 - accuracy: 0.7348 - val_loss: 0.6356 - val_accuracy: 0.6374\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.5159 - accuracy: 0.7395 - val_loss: 0.6882 - val_accuracy: 0.6109\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.5077 - accuracy: 0.7452 - val_loss: 0.5844 - val_accuracy: 0.6811\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.4989 - accuracy: 0.7510 - val_loss: 0.5739 - val_accuracy: 0.6899\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.4897 - accuracy: 0.7597 - val_loss: 0.6219 - val_accuracy: 0.6570\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.4807 - accuracy: 0.7636 - val_loss: 0.5798 - val_accuracy: 0.6899\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.4707 - accuracy: 0.7693 - val_loss: 0.5516 - val_accuracy: 0.7120\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.4585 - accuracy: 0.7799 - val_loss: 0.5638 - val_accuracy: 0.7057\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.4459 - accuracy: 0.7888 - val_loss: 0.6943 - val_accuracy: 0.6230\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.4320 - accuracy: 0.8008 - val_loss: 0.5309 - val_accuracy: 0.7399\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.4175 - accuracy: 0.8118 - val_loss: 0.6097 - val_accuracy: 0.6848\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.4012 - accuracy: 0.8218 - val_loss: 0.5612 - val_accuracy: 0.7228\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.3857 - accuracy: 0.8342 - val_loss: 0.5605 - val_accuracy: 0.7304\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.3714 - accuracy: 0.8435 - val_loss: 0.5391 - val_accuracy: 0.7495\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.3566 - accuracy: 0.8538 - val_loss: 0.4360 - val_accuracy: 0.8220\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.3443 - accuracy: 0.8609 - val_loss: 0.4784 - val_accuracy: 0.8018\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.3330 - accuracy: 0.8674 - val_loss: 0.4870 - val_accuracy: 0.8000\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.3252 - accuracy: 0.8712 - val_loss: 0.4989 - val_accuracy: 0.7935\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.3162 - accuracy: 0.8751 - val_loss: 0.4275 - val_accuracy: 0.8321\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.3113 - accuracy: 0.8781 - val_loss: 0.4446 - val_accuracy: 0.8261\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.3039 - accuracy: 0.8817 - val_loss: 0.4517 - val_accuracy: 0.8236\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.3007 - accuracy: 0.8813 - val_loss: 0.5094 - val_accuracy: 0.7955\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.2967 - accuracy: 0.8835 - val_loss: 0.4578 - val_accuracy: 0.8205\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2920 - accuracy: 0.8857 - val_loss: 0.4577 - val_accuracy: 0.8204\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2899 - accuracy: 0.8866 - val_loss: 0.5204 - val_accuracy: 0.7942\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2859 - accuracy: 0.8881 - val_loss: 0.4182 - val_accuracy: 0.8392\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2850 - accuracy: 0.8888 - val_loss: 0.4584 - val_accuracy: 0.8217\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2843 - accuracy: 0.8891 - val_loss: 0.5716 - val_accuracy: 0.7669\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2805 - accuracy: 0.8911 - val_loss: 0.4152 - val_accuracy: 0.8388\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2785 - accuracy: 0.8914 - val_loss: 0.5496 - val_accuracy: 0.7829\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2768 - accuracy: 0.8929 - val_loss: 0.4441 - val_accuracy: 0.8280\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.2760 - accuracy: 0.8915 - val_loss: 0.5016 - val_accuracy: 0.8055\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.2744 - accuracy: 0.8935 - val_loss: 0.4468 - val_accuracy: 0.8226\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2731 - accuracy: 0.8932 - val_loss: 0.5338 - val_accuracy: 0.7925\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.2723 - accuracy: 0.8937 - val_loss: 0.5270 - val_accuracy: 0.7935\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2714 - accuracy: 0.8954 - val_loss: 0.4756 - val_accuracy: 0.8164\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2687 - accuracy: 0.8955 - val_loss: 0.4124 - val_accuracy: 0.8419\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2683 - accuracy: 0.8956 - val_loss: 0.4049 - val_accuracy: 0.8454\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2682 - accuracy: 0.8951 - val_loss: 0.4505 - val_accuracy: 0.8254\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2666 - accuracy: 0.8967 - val_loss: 0.4490 - val_accuracy: 0.8272\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2657 - accuracy: 0.8969 - val_loss: 0.4843 - val_accuracy: 0.8139\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2646 - accuracy: 0.8964 - val_loss: 0.3764 - val_accuracy: 0.8544\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.2643 - accuracy: 0.8972 - val_loss: 0.4135 - val_accuracy: 0.8412\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.6494 - accuracy: 0.6204 - val_loss: 0.6369 - val_accuracy: 0.6092\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5978 - accuracy: 0.6789 - val_loss: 0.6354 - val_accuracy: 0.5938\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.5667 - accuracy: 0.7070 - val_loss: 0.5874 - val_accuracy: 0.6487\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5410 - accuracy: 0.7274 - val_loss: 0.6039 - val_accuracy: 0.6394\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.5228 - accuracy: 0.7394 - val_loss: 0.5669 - val_accuracy: 0.6807\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.5084 - accuracy: 0.7486 - val_loss: 0.6292 - val_accuracy: 0.6222\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.4949 - accuracy: 0.7567 - val_loss: 0.6238 - val_accuracy: 0.6333\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.4822 - accuracy: 0.7652 - val_loss: 0.5201 - val_accuracy: 0.7358\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.4679 - accuracy: 0.7735 - val_loss: 0.5717 - val_accuracy: 0.6899\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.4530 - accuracy: 0.7852 - val_loss: 0.5318 - val_accuracy: 0.7316\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.4376 - accuracy: 0.7982 - val_loss: 0.4698 - val_accuracy: 0.7899\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.4226 - accuracy: 0.8071 - val_loss: 0.5552 - val_accuracy: 0.7232\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.4042 - accuracy: 0.8229 - val_loss: 0.4235 - val_accuracy: 0.8290\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.3877 - accuracy: 0.8330 - val_loss: 0.5917 - val_accuracy: 0.7087\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.3720 - accuracy: 0.8431 - val_loss: 0.5085 - val_accuracy: 0.7734\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.3559 - accuracy: 0.8547 - val_loss: 0.5136 - val_accuracy: 0.7745\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.3438 - accuracy: 0.8633 - val_loss: 0.4017 - val_accuracy: 0.8444\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.3322 - accuracy: 0.8678 - val_loss: 0.5250 - val_accuracy: 0.7743\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.3218 - accuracy: 0.8739 - val_loss: 0.4446 - val_accuracy: 0.8243\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.3138 - accuracy: 0.8773 - val_loss: 0.4278 - val_accuracy: 0.8336\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.3067 - accuracy: 0.8813 - val_loss: 0.4603 - val_accuracy: 0.8202\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.3010 - accuracy: 0.8828 - val_loss: 0.4872 - val_accuracy: 0.8073\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.2963 - accuracy: 0.8835 - val_loss: 0.4489 - val_accuracy: 0.8262\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2930 - accuracy: 0.8855 - val_loss: 0.5189 - val_accuracy: 0.7921\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.2895 - accuracy: 0.8866 - val_loss: 0.5348 - val_accuracy: 0.7883\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.2866 - accuracy: 0.8896 - val_loss: 0.4393 - val_accuracy: 0.8303\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2832 - accuracy: 0.8893 - val_loss: 0.4669 - val_accuracy: 0.8183\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2819 - accuracy: 0.8900 - val_loss: 0.4684 - val_accuracy: 0.8173\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2788 - accuracy: 0.8903 - val_loss: 0.4087 - val_accuracy: 0.8425\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2781 - accuracy: 0.8920 - val_loss: 0.4135 - val_accuracy: 0.8413\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2749 - accuracy: 0.8933 - val_loss: 0.4916 - val_accuracy: 0.8078\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2730 - accuracy: 0.8939 - val_loss: 0.4427 - val_accuracy: 0.8273\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2715 - accuracy: 0.8939 - val_loss: 0.5386 - val_accuracy: 0.7841\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2706 - accuracy: 0.8938 - val_loss: 0.4642 - val_accuracy: 0.8195\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2702 - accuracy: 0.8952 - val_loss: 0.3505 - val_accuracy: 0.8641\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2689 - accuracy: 0.8943 - val_loss: 0.4268 - val_accuracy: 0.8349\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2673 - accuracy: 0.8950 - val_loss: 0.6057 - val_accuracy: 0.7453\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2658 - accuracy: 0.8953 - val_loss: 0.4488 - val_accuracy: 0.8228\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2656 - accuracy: 0.8964 - val_loss: 0.5075 - val_accuracy: 0.7974\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2639 - accuracy: 0.8969 - val_loss: 0.3916 - val_accuracy: 0.8478\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2637 - accuracy: 0.8968 - val_loss: 0.4285 - val_accuracy: 0.8336\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2615 - accuracy: 0.8980 - val_loss: 0.5428 - val_accuracy: 0.7843\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2607 - accuracy: 0.8987 - val_loss: 0.4452 - val_accuracy: 0.8231\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.2604 - accuracy: 0.8987 - val_loss: 0.4423 - val_accuracy: 0.8262\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2603 - accuracy: 0.8987 - val_loss: 0.5563 - val_accuracy: 0.7730\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.2586 - accuracy: 0.8994 - val_loss: 0.4402 - val_accuracy: 0.8279\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2576 - accuracy: 0.8984 - val_loss: 0.4809 - val_accuracy: 0.8110\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2574 - accuracy: 0.8997 - val_loss: 0.4063 - val_accuracy: 0.8428\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2560 - accuracy: 0.8996 - val_loss: 0.4783 - val_accuracy: 0.8102\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2551 - accuracy: 0.9007 - val_loss: 0.4039 - val_accuracy: 0.8392\n",
      "\n",
      "Training model with batch_size=32...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6503 - accuracy: 0.6248 - val_loss: 0.6426 - val_accuracy: 0.6510\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6113 - accuracy: 0.6764 - val_loss: 0.6009 - val_accuracy: 0.6856\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.5887 - accuracy: 0.6986 - val_loss: 0.5873 - val_accuracy: 0.6834\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.5710 - accuracy: 0.7122 - val_loss: 0.6042 - val_accuracy: 0.6615\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5557 - accuracy: 0.7260 - val_loss: 0.5782 - val_accuracy: 0.6739\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5436 - accuracy: 0.7307 - val_loss: 0.5961 - val_accuracy: 0.6571\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5336 - accuracy: 0.7348 - val_loss: 0.5929 - val_accuracy: 0.6584\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.5254 - accuracy: 0.7401 - val_loss: 0.6143 - val_accuracy: 0.6376\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5183 - accuracy: 0.7425 - val_loss: 0.5706 - val_accuracy: 0.6719\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.5115 - accuracy: 0.7470 - val_loss: 0.5988 - val_accuracy: 0.6498\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5027 - accuracy: 0.7521 - val_loss: 0.5842 - val_accuracy: 0.6615\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.4984 - accuracy: 0.7522 - val_loss: 0.5746 - val_accuracy: 0.6698\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.4900 - accuracy: 0.7619 - val_loss: 0.6015 - val_accuracy: 0.6504\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.4829 - accuracy: 0.7643 - val_loss: 0.5852 - val_accuracy: 0.6632\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.4762 - accuracy: 0.7703 - val_loss: 0.5922 - val_accuracy: 0.6618\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.4692 - accuracy: 0.7737 - val_loss: 0.5861 - val_accuracy: 0.6687\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.4620 - accuracy: 0.7803 - val_loss: 0.5314 - val_accuracy: 0.7188\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.4534 - accuracy: 0.7843 - val_loss: 0.6115 - val_accuracy: 0.6543\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.4465 - accuracy: 0.7889 - val_loss: 0.5821 - val_accuracy: 0.6795\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.4374 - accuracy: 0.7968 - val_loss: 0.4914 - val_accuracy: 0.7601\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.4307 - accuracy: 0.8017 - val_loss: 0.6239 - val_accuracy: 0.6552\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.4210 - accuracy: 0.8080 - val_loss: 0.5649 - val_accuracy: 0.7018\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.4137 - accuracy: 0.8125 - val_loss: 0.5304 - val_accuracy: 0.7345\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.4056 - accuracy: 0.8213 - val_loss: 0.4734 - val_accuracy: 0.7826\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.3975 - accuracy: 0.8248 - val_loss: 0.4558 - val_accuracy: 0.8001\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.3877 - accuracy: 0.8325 - val_loss: 0.4500 - val_accuracy: 0.8064\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.3801 - accuracy: 0.8380 - val_loss: 0.4819 - val_accuracy: 0.7827\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.3735 - accuracy: 0.8430 - val_loss: 0.5754 - val_accuracy: 0.7129\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.3660 - accuracy: 0.8458 - val_loss: 0.4585 - val_accuracy: 0.8031\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.3575 - accuracy: 0.8523 - val_loss: 0.5336 - val_accuracy: 0.7524\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.3520 - accuracy: 0.8546 - val_loss: 0.5103 - val_accuracy: 0.7697\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.3451 - accuracy: 0.8609 - val_loss: 0.4990 - val_accuracy: 0.7807\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.3395 - accuracy: 0.8631 - val_loss: 0.4439 - val_accuracy: 0.8174\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.3343 - accuracy: 0.8652 - val_loss: 0.4735 - val_accuracy: 0.8001\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.3290 - accuracy: 0.8680 - val_loss: 0.4553 - val_accuracy: 0.8151\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.3250 - accuracy: 0.8714 - val_loss: 0.5091 - val_accuracy: 0.7816\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.3203 - accuracy: 0.8738 - val_loss: 0.5185 - val_accuracy: 0.7779\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.3163 - accuracy: 0.8753 - val_loss: 0.5015 - val_accuracy: 0.7919\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.3129 - accuracy: 0.8767 - val_loss: 0.4595 - val_accuracy: 0.8144\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.3091 - accuracy: 0.8797 - val_loss: 0.6187 - val_accuracy: 0.7159\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.3067 - accuracy: 0.8803 - val_loss: 0.4507 - val_accuracy: 0.8204\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.3046 - accuracy: 0.8811 - val_loss: 0.5056 - val_accuracy: 0.7940\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.3018 - accuracy: 0.8815 - val_loss: 0.4756 - val_accuracy: 0.8118\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.2998 - accuracy: 0.8831 - val_loss: 0.4766 - val_accuracy: 0.8111\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.2963 - accuracy: 0.8842 - val_loss: 0.4597 - val_accuracy: 0.8202\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.2955 - accuracy: 0.8862 - val_loss: 0.4877 - val_accuracy: 0.8065\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.2944 - accuracy: 0.8849 - val_loss: 0.4975 - val_accuracy: 0.8026\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.2924 - accuracy: 0.8869 - val_loss: 0.4199 - val_accuracy: 0.8372\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.2899 - accuracy: 0.8874 - val_loss: 0.5059 - val_accuracy: 0.7992\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.2885 - accuracy: 0.8882 - val_loss: 0.4513 - val_accuracy: 0.8244\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6722 - accuracy: 0.5817 - val_loss: 0.6646 - val_accuracy: 0.6219\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6412 - accuracy: 0.6418 - val_loss: 0.6479 - val_accuracy: 0.6382\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6160 - accuracy: 0.6686 - val_loss: 0.6419 - val_accuracy: 0.6195\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.5943 - accuracy: 0.6887 - val_loss: 0.6254 - val_accuracy: 0.6365\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5773 - accuracy: 0.7035 - val_loss: 0.6260 - val_accuracy: 0.6307\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.5631 - accuracy: 0.7129 - val_loss: 0.6016 - val_accuracy: 0.6502\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.5527 - accuracy: 0.7184 - val_loss: 0.5853 - val_accuracy: 0.6692\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5434 - accuracy: 0.7270 - val_loss: 0.6059 - val_accuracy: 0.6511\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5364 - accuracy: 0.7291 - val_loss: 0.5954 - val_accuracy: 0.6671\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5285 - accuracy: 0.7349 - val_loss: 0.5772 - val_accuracy: 0.6796\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5223 - accuracy: 0.7377 - val_loss: 0.5999 - val_accuracy: 0.6635\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.5165 - accuracy: 0.7411 - val_loss: 0.5933 - val_accuracy: 0.6715\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5111 - accuracy: 0.7434 - val_loss: 0.5770 - val_accuracy: 0.6811\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.5056 - accuracy: 0.7473 - val_loss: 0.6031 - val_accuracy: 0.6674\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5008 - accuracy: 0.7513 - val_loss: 0.5623 - val_accuracy: 0.6918\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.4948 - accuracy: 0.7538 - val_loss: 0.5891 - val_accuracy: 0.6778\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.4891 - accuracy: 0.7586 - val_loss: 0.6446 - val_accuracy: 0.6347\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.4847 - accuracy: 0.7633 - val_loss: 0.5806 - val_accuracy: 0.6866\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.4790 - accuracy: 0.7673 - val_loss: 0.5806 - val_accuracy: 0.6876\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.4725 - accuracy: 0.7716 - val_loss: 0.5618 - val_accuracy: 0.7020\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.4667 - accuracy: 0.7747 - val_loss: 0.5603 - val_accuracy: 0.7051\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.4618 - accuracy: 0.7777 - val_loss: 0.5995 - val_accuracy: 0.6769\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.4548 - accuracy: 0.7834 - val_loss: 0.5728 - val_accuracy: 0.7002\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.4485 - accuracy: 0.7873 - val_loss: 0.5521 - val_accuracy: 0.7196\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.4404 - accuracy: 0.7938 - val_loss: 0.5869 - val_accuracy: 0.6960\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.4358 - accuracy: 0.7958 - val_loss: 0.5288 - val_accuracy: 0.7423\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.4264 - accuracy: 0.8040 - val_loss: 0.5599 - val_accuracy: 0.7196\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.4212 - accuracy: 0.8079 - val_loss: 0.5389 - val_accuracy: 0.7370\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.4124 - accuracy: 0.8139 - val_loss: 0.5407 - val_accuracy: 0.7381\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.4052 - accuracy: 0.8192 - val_loss: 0.4968 - val_accuracy: 0.7745\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.3973 - accuracy: 0.8255 - val_loss: 0.5120 - val_accuracy: 0.7651\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.3906 - accuracy: 0.8304 - val_loss: 0.5021 - val_accuracy: 0.7744\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.3831 - accuracy: 0.8346 - val_loss: 0.5221 - val_accuracy: 0.7626\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.3744 - accuracy: 0.8413 - val_loss: 0.5399 - val_accuracy: 0.7514\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.3685 - accuracy: 0.8456 - val_loss: 0.4927 - val_accuracy: 0.7900\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.3617 - accuracy: 0.8486 - val_loss: 0.5083 - val_accuracy: 0.7778\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.3543 - accuracy: 0.8534 - val_loss: 0.4906 - val_accuracy: 0.7930\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.3485 - accuracy: 0.8570 - val_loss: 0.4259 - val_accuracy: 0.8327\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.3427 - accuracy: 0.8607 - val_loss: 0.4717 - val_accuracy: 0.8109\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.3393 - accuracy: 0.8634 - val_loss: 0.5174 - val_accuracy: 0.7807\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.3332 - accuracy: 0.8678 - val_loss: 0.4575 - val_accuracy: 0.8209\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.3281 - accuracy: 0.8713 - val_loss: 0.4913 - val_accuracy: 0.8016\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.3242 - accuracy: 0.8716 - val_loss: 0.5263 - val_accuracy: 0.7806\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.3197 - accuracy: 0.8736 - val_loss: 0.5841 - val_accuracy: 0.7482\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.3176 - accuracy: 0.8755 - val_loss: 0.6036 - val_accuracy: 0.7375\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.3139 - accuracy: 0.8766 - val_loss: 0.5190 - val_accuracy: 0.7885\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.3115 - accuracy: 0.8772 - val_loss: 0.4745 - val_accuracy: 0.8182\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.3075 - accuracy: 0.8799 - val_loss: 0.5161 - val_accuracy: 0.7951\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.3049 - accuracy: 0.8820 - val_loss: 0.5084 - val_accuracy: 0.7997\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.3034 - accuracy: 0.8824 - val_loss: 0.4104 - val_accuracy: 0.8456\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6720 - accuracy: 0.5798 - val_loss: 0.6822 - val_accuracy: 0.5802\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6323 - accuracy: 0.6448 - val_loss: 0.6102 - val_accuracy: 0.6980\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6030 - accuracy: 0.6779 - val_loss: 0.6439 - val_accuracy: 0.6263\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5810 - accuracy: 0.7003 - val_loss: 0.6176 - val_accuracy: 0.6448\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5652 - accuracy: 0.7147 - val_loss: 0.5966 - val_accuracy: 0.6587\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5533 - accuracy: 0.7243 - val_loss: 0.5920 - val_accuracy: 0.6592\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5415 - accuracy: 0.7275 - val_loss: 0.5941 - val_accuracy: 0.6589\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5336 - accuracy: 0.7334 - val_loss: 0.5937 - val_accuracy: 0.6568\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5246 - accuracy: 0.7391 - val_loss: 0.5907 - val_accuracy: 0.6585\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5175 - accuracy: 0.7421 - val_loss: 0.5793 - val_accuracy: 0.6671\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.6053 - val_accuracy: 0.6478\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5796 - val_accuracy: 0.6717\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.4963 - accuracy: 0.7572 - val_loss: 0.5536 - val_accuracy: 0.6979\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.4902 - accuracy: 0.7610 - val_loss: 0.5840 - val_accuracy: 0.6717\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.4828 - accuracy: 0.7649 - val_loss: 0.5672 - val_accuracy: 0.6880\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.4771 - accuracy: 0.7698 - val_loss: 0.6064 - val_accuracy: 0.6534\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.4673 - accuracy: 0.7769 - val_loss: 0.5347 - val_accuracy: 0.7235\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.4613 - accuracy: 0.7824 - val_loss: 0.5491 - val_accuracy: 0.7093\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.4541 - accuracy: 0.7864 - val_loss: 0.5479 - val_accuracy: 0.7123\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.4453 - accuracy: 0.7935 - val_loss: 0.5351 - val_accuracy: 0.7269\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.4361 - accuracy: 0.7998 - val_loss: 0.5391 - val_accuracy: 0.7258\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.4282 - accuracy: 0.8056 - val_loss: 0.5122 - val_accuracy: 0.7519\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.4199 - accuracy: 0.8123 - val_loss: 0.5385 - val_accuracy: 0.7310\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.4116 - accuracy: 0.8180 - val_loss: 0.5460 - val_accuracy: 0.7284\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.4008 - accuracy: 0.8237 - val_loss: 0.5360 - val_accuracy: 0.7402\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.3935 - accuracy: 0.8300 - val_loss: 0.5134 - val_accuracy: 0.7617\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.3831 - accuracy: 0.8375 - val_loss: 0.5033 - val_accuracy: 0.7701\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.3757 - accuracy: 0.8416 - val_loss: 0.4901 - val_accuracy: 0.7840\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.3667 - accuracy: 0.8483 - val_loss: 0.5469 - val_accuracy: 0.7447\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.3595 - accuracy: 0.8525 - val_loss: 0.4855 - val_accuracy: 0.7904\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.3525 - accuracy: 0.8577 - val_loss: 0.4942 - val_accuracy: 0.7891\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.3449 - accuracy: 0.8620 - val_loss: 0.4713 - val_accuracy: 0.8019\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.3387 - accuracy: 0.8661 - val_loss: 0.5453 - val_accuracy: 0.7587\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.3323 - accuracy: 0.8697 - val_loss: 0.4390 - val_accuracy: 0.8230\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.3270 - accuracy: 0.8707 - val_loss: 0.5726 - val_accuracy: 0.7447\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.3229 - accuracy: 0.8740 - val_loss: 0.4664 - val_accuracy: 0.8127\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.3168 - accuracy: 0.8759 - val_loss: 0.4690 - val_accuracy: 0.8106\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.3129 - accuracy: 0.8785 - val_loss: 0.4424 - val_accuracy: 0.8249\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.3090 - accuracy: 0.8805 - val_loss: 0.5215 - val_accuracy: 0.7857\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.3061 - accuracy: 0.8824 - val_loss: 0.4305 - val_accuracy: 0.8308\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.3026 - accuracy: 0.8831 - val_loss: 0.4032 - val_accuracy: 0.8416\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.3001 - accuracy: 0.8842 - val_loss: 0.3900 - val_accuracy: 0.8481\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.2978 - accuracy: 0.8844 - val_loss: 0.4775 - val_accuracy: 0.8127\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.2946 - accuracy: 0.8884 - val_loss: 0.5796 - val_accuracy: 0.7583\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2927 - accuracy: 0.8874 - val_loss: 0.4800 - val_accuracy: 0.8130\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.2914 - accuracy: 0.8889 - val_loss: 0.5370 - val_accuracy: 0.7848\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.2890 - accuracy: 0.8877 - val_loss: 0.5078 - val_accuracy: 0.8021\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.2888 - accuracy: 0.8893 - val_loss: 0.4792 - val_accuracy: 0.8151\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.2867 - accuracy: 0.8917 - val_loss: 0.5396 - val_accuracy: 0.7858\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.2856 - accuracy: 0.8903 - val_loss: 0.4905 - val_accuracy: 0.8120\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6867 - accuracy: 0.5645 - val_loss: 0.6558 - val_accuracy: 0.6294\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6381 - accuracy: 0.6382 - val_loss: 0.6301 - val_accuracy: 0.6464\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6153 - accuracy: 0.6641 - val_loss: 0.5994 - val_accuracy: 0.6807\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5990 - accuracy: 0.6763 - val_loss: 0.6123 - val_accuracy: 0.6516\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5858 - accuracy: 0.6904 - val_loss: 0.5984 - val_accuracy: 0.6642\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5744 - accuracy: 0.7020 - val_loss: 0.5905 - val_accuracy: 0.6690\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5657 - accuracy: 0.7076 - val_loss: 0.6075 - val_accuracy: 0.6482\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5562 - accuracy: 0.7163 - val_loss: 0.6063 - val_accuracy: 0.6498\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5479 - accuracy: 0.7218 - val_loss: 0.5877 - val_accuracy: 0.6694\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5419 - accuracy: 0.7263 - val_loss: 0.5860 - val_accuracy: 0.6713\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5350 - accuracy: 0.7299 - val_loss: 0.5726 - val_accuracy: 0.6834\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.5281 - accuracy: 0.7333 - val_loss: 0.5912 - val_accuracy: 0.6612\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5237 - accuracy: 0.7364 - val_loss: 0.5854 - val_accuracy: 0.6675\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5177 - accuracy: 0.7392 - val_loss: 0.6237 - val_accuracy: 0.6315\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5125 - accuracy: 0.7455 - val_loss: 0.5603 - val_accuracy: 0.6907\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5062 - accuracy: 0.7476 - val_loss: 0.5620 - val_accuracy: 0.6889\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5003 - accuracy: 0.7518 - val_loss: 0.5731 - val_accuracy: 0.6806\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.4956 - accuracy: 0.7561 - val_loss: 0.5928 - val_accuracy: 0.6637\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.4898 - accuracy: 0.7594 - val_loss: 0.5986 - val_accuracy: 0.6616\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.4842 - accuracy: 0.7618 - val_loss: 0.5559 - val_accuracy: 0.6942\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.4778 - accuracy: 0.7683 - val_loss: 0.5858 - val_accuracy: 0.6756\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.4711 - accuracy: 0.7718 - val_loss: 0.5493 - val_accuracy: 0.7025\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.4652 - accuracy: 0.7755 - val_loss: 0.6091 - val_accuracy: 0.6628\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.4581 - accuracy: 0.7820 - val_loss: 0.5247 - val_accuracy: 0.7298\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.4520 - accuracy: 0.7861 - val_loss: 0.5916 - val_accuracy: 0.6821\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.4443 - accuracy: 0.7914 - val_loss: 0.5672 - val_accuracy: 0.7003\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.4364 - accuracy: 0.7972 - val_loss: 0.5526 - val_accuracy: 0.7120\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.4294 - accuracy: 0.8022 - val_loss: 0.5623 - val_accuracy: 0.7085\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.4214 - accuracy: 0.8087 - val_loss: 0.4852 - val_accuracy: 0.7728\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.4133 - accuracy: 0.8145 - val_loss: 0.5464 - val_accuracy: 0.7265\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.4055 - accuracy: 0.8197 - val_loss: 0.5362 - val_accuracy: 0.7347\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.3969 - accuracy: 0.8254 - val_loss: 0.5365 - val_accuracy: 0.7385\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.3902 - accuracy: 0.8306 - val_loss: 0.5951 - val_accuracy: 0.7005\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.3818 - accuracy: 0.8364 - val_loss: 0.4473 - val_accuracy: 0.8119\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.3730 - accuracy: 0.8399 - val_loss: 0.4949 - val_accuracy: 0.7802\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.3673 - accuracy: 0.8458 - val_loss: 0.4990 - val_accuracy: 0.7798\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.3590 - accuracy: 0.8497 - val_loss: 0.5206 - val_accuracy: 0.7649\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.3524 - accuracy: 0.8547 - val_loss: 0.5116 - val_accuracy: 0.7733\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.3473 - accuracy: 0.8584 - val_loss: 0.5133 - val_accuracy: 0.7761\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.3411 - accuracy: 0.8611 - val_loss: 0.4814 - val_accuracy: 0.7990\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.3354 - accuracy: 0.8634 - val_loss: 0.4561 - val_accuracy: 0.8162\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.3302 - accuracy: 0.8673 - val_loss: 0.6305 - val_accuracy: 0.7040\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.3252 - accuracy: 0.8700 - val_loss: 0.5973 - val_accuracy: 0.7238\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.3220 - accuracy: 0.8710 - val_loss: 0.5014 - val_accuracy: 0.7917\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.3176 - accuracy: 0.8733 - val_loss: 0.4831 - val_accuracy: 0.8023\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.3137 - accuracy: 0.8759 - val_loss: 0.4975 - val_accuracy: 0.7961\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.3110 - accuracy: 0.8771 - val_loss: 0.4901 - val_accuracy: 0.8015\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.3083 - accuracy: 0.8783 - val_loss: 0.4271 - val_accuracy: 0.8336\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.3030 - accuracy: 0.8808 - val_loss: 0.4334 - val_accuracy: 0.8310\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.3014 - accuracy: 0.8815 - val_loss: 0.4788 - val_accuracy: 0.8107\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6977 - accuracy: 0.5325 - val_loss: 0.7151 - val_accuracy: 0.4330\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6626 - accuracy: 0.6228 - val_loss: 0.6767 - val_accuracy: 0.5923\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6389 - accuracy: 0.6572 - val_loss: 0.6622 - val_accuracy: 0.6039\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6185 - accuracy: 0.6738 - val_loss: 0.6516 - val_accuracy: 0.6086\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5990 - accuracy: 0.6869 - val_loss: 0.6268 - val_accuracy: 0.6329\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5836 - accuracy: 0.7007 - val_loss: 0.6262 - val_accuracy: 0.6351\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.5702 - accuracy: 0.7106 - val_loss: 0.6091 - val_accuracy: 0.6530\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5596 - accuracy: 0.7169 - val_loss: 0.6077 - val_accuracy: 0.6511\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5498 - accuracy: 0.7239 - val_loss: 0.5712 - val_accuracy: 0.6857\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.5409 - accuracy: 0.7287 - val_loss: 0.6142 - val_accuracy: 0.6439\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5334 - accuracy: 0.7341 - val_loss: 0.5981 - val_accuracy: 0.6607\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5264 - accuracy: 0.7384 - val_loss: 0.5990 - val_accuracy: 0.6627\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5197 - accuracy: 0.7410 - val_loss: 0.6088 - val_accuracy: 0.6576\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.5150 - accuracy: 0.7430 - val_loss: 0.6008 - val_accuracy: 0.6625\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.5081 - accuracy: 0.7487 - val_loss: 0.6107 - val_accuracy: 0.6556\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5031 - accuracy: 0.7507 - val_loss: 0.5867 - val_accuracy: 0.6770\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.4968 - accuracy: 0.7558 - val_loss: 0.6029 - val_accuracy: 0.6646\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.4910 - accuracy: 0.7591 - val_loss: 0.5822 - val_accuracy: 0.6843\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.4851 - accuracy: 0.7631 - val_loss: 0.5836 - val_accuracy: 0.6823\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.4786 - accuracy: 0.7679 - val_loss: 0.5774 - val_accuracy: 0.6890\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.4726 - accuracy: 0.7732 - val_loss: 0.5897 - val_accuracy: 0.6833\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.4657 - accuracy: 0.7761 - val_loss: 0.5571 - val_accuracy: 0.7104\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.4593 - accuracy: 0.7819 - val_loss: 0.6011 - val_accuracy: 0.6799\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.4514 - accuracy: 0.7874 - val_loss: 0.6040 - val_accuracy: 0.6794\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.4444 - accuracy: 0.7933 - val_loss: 0.5729 - val_accuracy: 0.7033\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.4370 - accuracy: 0.7968 - val_loss: 0.4803 - val_accuracy: 0.7837\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.4292 - accuracy: 0.8030 - val_loss: 0.5818 - val_accuracy: 0.7018\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.4215 - accuracy: 0.8097 - val_loss: 0.5268 - val_accuracy: 0.7472\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.4132 - accuracy: 0.8146 - val_loss: 0.5642 - val_accuracy: 0.7198\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.4062 - accuracy: 0.8203 - val_loss: 0.5638 - val_accuracy: 0.7214\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.3989 - accuracy: 0.8240 - val_loss: 0.5442 - val_accuracy: 0.7392\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.3899 - accuracy: 0.8310 - val_loss: 0.4554 - val_accuracy: 0.8105\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.3833 - accuracy: 0.8341 - val_loss: 0.5030 - val_accuracy: 0.7784\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.3742 - accuracy: 0.8428 - val_loss: 0.5629 - val_accuracy: 0.7348\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.3678 - accuracy: 0.8454 - val_loss: 0.5724 - val_accuracy: 0.7297\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.3612 - accuracy: 0.8517 - val_loss: 0.4757 - val_accuracy: 0.8008\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.3543 - accuracy: 0.8556 - val_loss: 0.4289 - val_accuracy: 0.8315\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.3480 - accuracy: 0.8578 - val_loss: 0.5277 - val_accuracy: 0.7700\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.3415 - accuracy: 0.8636 - val_loss: 0.5074 - val_accuracy: 0.7868\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.3370 - accuracy: 0.8656 - val_loss: 0.4796 - val_accuracy: 0.8057\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.3320 - accuracy: 0.8675 - val_loss: 0.4320 - val_accuracy: 0.8321\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.3273 - accuracy: 0.8696 - val_loss: 0.4691 - val_accuracy: 0.8158\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.3228 - accuracy: 0.8727 - val_loss: 0.4744 - val_accuracy: 0.8139\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.3201 - accuracy: 0.8735 - val_loss: 0.5003 - val_accuracy: 0.7982\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.3154 - accuracy: 0.8768 - val_loss: 0.4998 - val_accuracy: 0.8012\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.3131 - accuracy: 0.8773 - val_loss: 0.5885 - val_accuracy: 0.7461\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.3107 - accuracy: 0.8781 - val_loss: 0.4748 - val_accuracy: 0.8158\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.3077 - accuracy: 0.8807 - val_loss: 0.4217 - val_accuracy: 0.8392\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.3046 - accuracy: 0.8815 - val_loss: 0.5314 - val_accuracy: 0.7839\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.3022 - accuracy: 0.8830 - val_loss: 0.4778 - val_accuracy: 0.8173\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6661 - accuracy: 0.6018 - val_loss: 0.6466 - val_accuracy: 0.6417\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6203 - accuracy: 0.6714 - val_loss: 0.6337 - val_accuracy: 0.6441\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5973 - accuracy: 0.6912 - val_loss: 0.5889 - val_accuracy: 0.6931\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5806 - accuracy: 0.7044 - val_loss: 0.6110 - val_accuracy: 0.6565\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5692 - accuracy: 0.7148 - val_loss: 0.6036 - val_accuracy: 0.6648\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5579 - accuracy: 0.7204 - val_loss: 0.5698 - val_accuracy: 0.6904\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5457 - accuracy: 0.7253 - val_loss: 0.6124 - val_accuracy: 0.6488\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.5376 - accuracy: 0.7315 - val_loss: 0.5780 - val_accuracy: 0.6722\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5293 - accuracy: 0.7373 - val_loss: 0.5498 - val_accuracy: 0.6974\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.5220 - accuracy: 0.7408 - val_loss: 0.5907 - val_accuracy: 0.6632\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5152 - accuracy: 0.7446 - val_loss: 0.5468 - val_accuracy: 0.6978\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5084 - accuracy: 0.7484 - val_loss: 0.5819 - val_accuracy: 0.6678\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5009 - accuracy: 0.7523 - val_loss: 0.5655 - val_accuracy: 0.6843\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.4955 - accuracy: 0.7560 - val_loss: 0.6117 - val_accuracy: 0.6468\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.4889 - accuracy: 0.7590 - val_loss: 0.5511 - val_accuracy: 0.6938\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.4824 - accuracy: 0.7638 - val_loss: 0.5552 - val_accuracy: 0.6924\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.4759 - accuracy: 0.7683 - val_loss: 0.5646 - val_accuracy: 0.6873\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.4683 - accuracy: 0.7734 - val_loss: 0.5576 - val_accuracy: 0.6951\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.4618 - accuracy: 0.7787 - val_loss: 0.5686 - val_accuracy: 0.6904\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.4554 - accuracy: 0.7840 - val_loss: 0.5870 - val_accuracy: 0.6785\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.4480 - accuracy: 0.7866 - val_loss: 0.5364 - val_accuracy: 0.7238\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.4405 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5541 - val_accuracy: 0.7117\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.4233 - accuracy: 0.8077 - val_loss: 0.5440 - val_accuracy: 0.7237\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.4149 - accuracy: 0.8139 - val_loss: 0.5217 - val_accuracy: 0.7450\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.4068 - accuracy: 0.8195 - val_loss: 0.5451 - val_accuracy: 0.7272\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.3999 - accuracy: 0.8246 - val_loss: 0.4653 - val_accuracy: 0.8022\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.3900 - accuracy: 0.8321 - val_loss: 0.5195 - val_accuracy: 0.7562\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.3820 - accuracy: 0.8375 - val_loss: 0.5121 - val_accuracy: 0.7679\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.3735 - accuracy: 0.8437 - val_loss: 0.4967 - val_accuracy: 0.7820\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.3667 - accuracy: 0.8483 - val_loss: 0.5813 - val_accuracy: 0.7225\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.3606 - accuracy: 0.8520 - val_loss: 0.5470 - val_accuracy: 0.7523\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.3542 - accuracy: 0.8569 - val_loss: 0.5362 - val_accuracy: 0.7631\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.3466 - accuracy: 0.8596 - val_loss: 0.5305 - val_accuracy: 0.7686\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.3417 - accuracy: 0.8640 - val_loss: 0.4849 - val_accuracy: 0.8040\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.3354 - accuracy: 0.8667 - val_loss: 0.6118 - val_accuracy: 0.7201\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.3310 - accuracy: 0.8690 - val_loss: 0.4929 - val_accuracy: 0.8044\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.3259 - accuracy: 0.8715 - val_loss: 0.4592 - val_accuracy: 0.8221\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.3218 - accuracy: 0.8744 - val_loss: 0.4649 - val_accuracy: 0.8205\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.3177 - accuracy: 0.8760 - val_loss: 0.4772 - val_accuracy: 0.8164\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.3136 - accuracy: 0.8782 - val_loss: 0.4505 - val_accuracy: 0.8287\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.3115 - accuracy: 0.8789 - val_loss: 0.5089 - val_accuracy: 0.8027\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.3078 - accuracy: 0.8803 - val_loss: 0.4415 - val_accuracy: 0.8336\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.3062 - accuracy: 0.8813 - val_loss: 0.5099 - val_accuracy: 0.8034\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.3025 - accuracy: 0.8843 - val_loss: 0.4975 - val_accuracy: 0.8109\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.2997 - accuracy: 0.8841 - val_loss: 0.4703 - val_accuracy: 0.8225\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.2980 - accuracy: 0.8843 - val_loss: 0.4704 - val_accuracy: 0.8230\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.2964 - accuracy: 0.8857 - val_loss: 0.5148 - val_accuracy: 0.8039\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.2936 - accuracy: 0.8874 - val_loss: 0.4998 - val_accuracy: 0.8108\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.2928 - accuracy: 0.8879 - val_loss: 0.4481 - val_accuracy: 0.8317\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6864 - accuracy: 0.5490 - val_loss: 0.6831 - val_accuracy: 0.5593\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6422 - accuracy: 0.6389 - val_loss: 0.6450 - val_accuracy: 0.6309\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.6113 - accuracy: 0.6808 - val_loss: 0.6193 - val_accuracy: 0.6456\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.5888 - accuracy: 0.7019 - val_loss: 0.6217 - val_accuracy: 0.6326\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.5730 - accuracy: 0.7131 - val_loss: 0.6274 - val_accuracy: 0.6297\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5601 - accuracy: 0.7230 - val_loss: 0.6256 - val_accuracy: 0.6301\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5473 - accuracy: 0.7308 - val_loss: 0.5951 - val_accuracy: 0.6524\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5384 - accuracy: 0.7354 - val_loss: 0.5744 - val_accuracy: 0.6754\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5284 - accuracy: 0.7396 - val_loss: 0.5662 - val_accuracy: 0.6838\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5224 - accuracy: 0.7437 - val_loss: 0.5922 - val_accuracy: 0.6629\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5155 - accuracy: 0.7455 - val_loss: 0.5920 - val_accuracy: 0.6637\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.5091 - accuracy: 0.7502 - val_loss: 0.6311 - val_accuracy: 0.6360\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5606 - val_accuracy: 0.6872\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.4969 - accuracy: 0.7575 - val_loss: 0.5755 - val_accuracy: 0.6773\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.4902 - accuracy: 0.7615 - val_loss: 0.6007 - val_accuracy: 0.6589\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.4830 - accuracy: 0.7652 - val_loss: 0.5594 - val_accuracy: 0.6946\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.4767 - accuracy: 0.7704 - val_loss: 0.5747 - val_accuracy: 0.6813\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.4700 - accuracy: 0.7735 - val_loss: 0.6146 - val_accuracy: 0.6531\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.4627 - accuracy: 0.7794 - val_loss: 0.5381 - val_accuracy: 0.7199\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.4538 - accuracy: 0.7835 - val_loss: 0.5861 - val_accuracy: 0.6803\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.4484 - accuracy: 0.7901 - val_loss: 0.5884 - val_accuracy: 0.6815\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.4400 - accuracy: 0.7959 - val_loss: 0.5386 - val_accuracy: 0.7246\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.4327 - accuracy: 0.8001 - val_loss: 0.6014 - val_accuracy: 0.6768\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.4232 - accuracy: 0.8071 - val_loss: 0.5327 - val_accuracy: 0.7361\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.4147 - accuracy: 0.8144 - val_loss: 0.6550 - val_accuracy: 0.6480\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.4068 - accuracy: 0.8200 - val_loss: 0.5185 - val_accuracy: 0.7521\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.3980 - accuracy: 0.8256 - val_loss: 0.4902 - val_accuracy: 0.7768\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.3899 - accuracy: 0.8311 - val_loss: 0.5188 - val_accuracy: 0.7573\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.3822 - accuracy: 0.8357 - val_loss: 0.5757 - val_accuracy: 0.7134\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.3741 - accuracy: 0.8423 - val_loss: 0.5781 - val_accuracy: 0.7187\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.3669 - accuracy: 0.8474 - val_loss: 0.4928 - val_accuracy: 0.7873\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.3603 - accuracy: 0.8516 - val_loss: 0.4974 - val_accuracy: 0.7854\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.3532 - accuracy: 0.8549 - val_loss: 0.5132 - val_accuracy: 0.7755\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.3464 - accuracy: 0.8596 - val_loss: 0.4861 - val_accuracy: 0.7976\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.3400 - accuracy: 0.8638 - val_loss: 0.5776 - val_accuracy: 0.7373\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.3358 - accuracy: 0.8660 - val_loss: 0.4874 - val_accuracy: 0.8016\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.3304 - accuracy: 0.8694 - val_loss: 0.4644 - val_accuracy: 0.8127\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.3247 - accuracy: 0.8714 - val_loss: 0.5380 - val_accuracy: 0.7722\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.3217 - accuracy: 0.8731 - val_loss: 0.4756 - val_accuracy: 0.8097\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.3169 - accuracy: 0.8766 - val_loss: 0.5566 - val_accuracy: 0.7646\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.3139 - accuracy: 0.8769 - val_loss: 0.4834 - val_accuracy: 0.8085\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.3108 - accuracy: 0.8796 - val_loss: 0.4579 - val_accuracy: 0.8196\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.3073 - accuracy: 0.8812 - val_loss: 0.4391 - val_accuracy: 0.8276\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.3058 - accuracy: 0.8807 - val_loss: 0.4855 - val_accuracy: 0.8105\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.3009 - accuracy: 0.8826 - val_loss: 0.4900 - val_accuracy: 0.8096\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.2994 - accuracy: 0.8828 - val_loss: 0.4524 - val_accuracy: 0.8237\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2977 - accuracy: 0.8859 - val_loss: 0.4540 - val_accuracy: 0.8242\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.2961 - accuracy: 0.8860 - val_loss: 0.5100 - val_accuracy: 0.8004\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.2933 - accuracy: 0.8865 - val_loss: 0.4682 - val_accuracy: 0.8194\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.2909 - accuracy: 0.8879 - val_loss: 0.4568 - val_accuracy: 0.8237\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.6985 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6805 - accuracy: 0.5851 - val_loss: 0.6596 - val_accuracy: 0.5965\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6319 - accuracy: 0.6603 - val_loss: 0.6355 - val_accuracy: 0.6229\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6089 - accuracy: 0.6845 - val_loss: 0.6214 - val_accuracy: 0.6345\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5925 - accuracy: 0.6984 - val_loss: 0.6110 - val_accuracy: 0.6385\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5799 - accuracy: 0.7074 - val_loss: 0.6254 - val_accuracy: 0.6175\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5710 - accuracy: 0.7105 - val_loss: 0.6014 - val_accuracy: 0.6315\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5614 - accuracy: 0.7146 - val_loss: 0.5965 - val_accuracy: 0.6363\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5510 - accuracy: 0.7204 - val_loss: 0.5916 - val_accuracy: 0.6409\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5446 - accuracy: 0.7246 - val_loss: 0.6179 - val_accuracy: 0.6201\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5388 - accuracy: 0.7279 - val_loss: 0.6316 - val_accuracy: 0.6124\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5314 - accuracy: 0.7322 - val_loss: 0.6183 - val_accuracy: 0.6234\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5259 - accuracy: 0.7356 - val_loss: 0.6291 - val_accuracy: 0.6166\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5207 - accuracy: 0.7390 - val_loss: 0.6313 - val_accuracy: 0.6180\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5150 - accuracy: 0.7418 - val_loss: 0.6143 - val_accuracy: 0.6344\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.5098 - accuracy: 0.7463 - val_loss: 0.6184 - val_accuracy: 0.6337\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5041 - accuracy: 0.7503 - val_loss: 0.5858 - val_accuracy: 0.6615\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.4989 - accuracy: 0.7540 - val_loss: 0.5866 - val_accuracy: 0.6618\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.4935 - accuracy: 0.7581 - val_loss: 0.6094 - val_accuracy: 0.6453\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.4874 - accuracy: 0.7619 - val_loss: 0.5531 - val_accuracy: 0.6979\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.4813 - accuracy: 0.7655 - val_loss: 0.6066 - val_accuracy: 0.6529\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.4764 - accuracy: 0.7690 - val_loss: 0.5566 - val_accuracy: 0.6967\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.4697 - accuracy: 0.7741 - val_loss: 0.5904 - val_accuracy: 0.6692\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.5335 - val_accuracy: 0.7211\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.5326 - val_accuracy: 0.7224\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.4497 - accuracy: 0.7882 - val_loss: 0.5777 - val_accuracy: 0.6851\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.4424 - accuracy: 0.7934 - val_loss: 0.5496 - val_accuracy: 0.7124\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.4343 - accuracy: 0.7985 - val_loss: 0.5366 - val_accuracy: 0.7256\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.4260 - accuracy: 0.8055 - val_loss: 0.5488 - val_accuracy: 0.7174\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.4191 - accuracy: 0.8108 - val_loss: 0.5448 - val_accuracy: 0.7233\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.4097 - accuracy: 0.8172 - val_loss: 0.5252 - val_accuracy: 0.7443\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.4024 - accuracy: 0.8220 - val_loss: 0.4923 - val_accuracy: 0.7716\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.3933 - accuracy: 0.8272 - val_loss: 0.5266 - val_accuracy: 0.7454\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.3851 - accuracy: 0.8356 - val_loss: 0.4801 - val_accuracy: 0.7868\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.3765 - accuracy: 0.8404 - val_loss: 0.4980 - val_accuracy: 0.7755\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.3692 - accuracy: 0.8447 - val_loss: 0.4437 - val_accuracy: 0.8188\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.3620 - accuracy: 0.8488 - val_loss: 0.5368 - val_accuracy: 0.7504\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.3547 - accuracy: 0.8532 - val_loss: 0.4423 - val_accuracy: 0.8220\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.3482 - accuracy: 0.8574 - val_loss: 0.5047 - val_accuracy: 0.7819\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.3416 - accuracy: 0.8610 - val_loss: 0.4983 - val_accuracy: 0.7857\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.3358 - accuracy: 0.8645 - val_loss: 0.4726 - val_accuracy: 0.8035\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.3306 - accuracy: 0.8666 - val_loss: 0.5141 - val_accuracy: 0.7791\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.3259 - accuracy: 0.8692 - val_loss: 0.5687 - val_accuracy: 0.7422\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.3223 - accuracy: 0.8710 - val_loss: 0.4803 - val_accuracy: 0.8038\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.3182 - accuracy: 0.8748 - val_loss: 0.4440 - val_accuracy: 0.8234\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.3144 - accuracy: 0.8751 - val_loss: 0.4977 - val_accuracy: 0.7966\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.3110 - accuracy: 0.8772 - val_loss: 0.4559 - val_accuracy: 0.8202\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.3075 - accuracy: 0.8794 - val_loss: 0.4282 - val_accuracy: 0.8297\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.3058 - accuracy: 0.8799 - val_loss: 0.5030 - val_accuracy: 0.7967\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.3017 - accuracy: 0.8809 - val_loss: 0.6179 - val_accuracy: 0.7324\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.3001 - accuracy: 0.8834 - val_loss: 0.4877 - val_accuracy: 0.8080\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6819 - accuracy: 0.5673 - val_loss: 0.6850 - val_accuracy: 0.5863\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6579 - accuracy: 0.6266 - val_loss: 0.6816 - val_accuracy: 0.5736\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6386 - accuracy: 0.6541 - val_loss: 0.6427 - val_accuracy: 0.6480\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6213 - accuracy: 0.6686 - val_loss: 0.6467 - val_accuracy: 0.6217\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6040 - accuracy: 0.6802 - val_loss: 0.6322 - val_accuracy: 0.6312\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5894 - accuracy: 0.6928 - val_loss: 0.6237 - val_accuracy: 0.6366\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5752 - accuracy: 0.7039 - val_loss: 0.5960 - val_accuracy: 0.6659\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.5635 - accuracy: 0.7116 - val_loss: 0.6005 - val_accuracy: 0.6529\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.5528 - accuracy: 0.7214 - val_loss: 0.6243 - val_accuracy: 0.6278\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.5433 - accuracy: 0.7282 - val_loss: 0.6040 - val_accuracy: 0.6470\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.5339 - accuracy: 0.7346 - val_loss: 0.5966 - val_accuracy: 0.6574\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5258 - accuracy: 0.7386 - val_loss: 0.6141 - val_accuracy: 0.6436\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5200 - accuracy: 0.7407 - val_loss: 0.5908 - val_accuracy: 0.6642\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.5116 - accuracy: 0.7463 - val_loss: 0.5948 - val_accuracy: 0.6616\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5046 - accuracy: 0.7523 - val_loss: 0.5905 - val_accuracy: 0.6677\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.4978 - accuracy: 0.7565 - val_loss: 0.6092 - val_accuracy: 0.6529\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.4909 - accuracy: 0.7597 - val_loss: 0.5505 - val_accuracy: 0.7060\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.4849 - accuracy: 0.7630 - val_loss: 0.5863 - val_accuracy: 0.6740\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.4778 - accuracy: 0.7693 - val_loss: 0.5448 - val_accuracy: 0.7136\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.4703 - accuracy: 0.7732 - val_loss: 0.5807 - val_accuracy: 0.6804\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.4628 - accuracy: 0.7794 - val_loss: 0.5531 - val_accuracy: 0.7070\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.4563 - accuracy: 0.7847 - val_loss: 0.6037 - val_accuracy: 0.6680\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.4485 - accuracy: 0.7888 - val_loss: 0.5626 - val_accuracy: 0.7034\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.4399 - accuracy: 0.7960 - val_loss: 0.5768 - val_accuracy: 0.6948\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.4312 - accuracy: 0.8029 - val_loss: 0.5383 - val_accuracy: 0.7308\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.4234 - accuracy: 0.8088 - val_loss: 0.5435 - val_accuracy: 0.7295\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.4162 - accuracy: 0.8119 - val_loss: 0.5332 - val_accuracy: 0.7407\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.4075 - accuracy: 0.8211 - val_loss: 0.5016 - val_accuracy: 0.7686\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.3988 - accuracy: 0.8257 - val_loss: 0.4860 - val_accuracy: 0.7825\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.3906 - accuracy: 0.8315 - val_loss: 0.5098 - val_accuracy: 0.7666\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.3822 - accuracy: 0.8383 - val_loss: 0.4861 - val_accuracy: 0.7869\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.3745 - accuracy: 0.8435 - val_loss: 0.4706 - val_accuracy: 0.8022\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.3665 - accuracy: 0.8480 - val_loss: 0.4974 - val_accuracy: 0.7809\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.3594 - accuracy: 0.8521 - val_loss: 0.5519 - val_accuracy: 0.7449\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.3531 - accuracy: 0.8560 - val_loss: 0.4948 - val_accuracy: 0.7867\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.3467 - accuracy: 0.8603 - val_loss: 0.4925 - val_accuracy: 0.7931\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.3401 - accuracy: 0.8641 - val_loss: 0.4328 - val_accuracy: 0.8290\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.3351 - accuracy: 0.8677 - val_loss: 0.5291 - val_accuracy: 0.7716\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.3311 - accuracy: 0.8689 - val_loss: 0.5378 - val_accuracy: 0.7688\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.3252 - accuracy: 0.8727 - val_loss: 0.4832 - val_accuracy: 0.8054\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.3206 - accuracy: 0.8744 - val_loss: 0.5205 - val_accuracy: 0.7834\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.3173 - accuracy: 0.8759 - val_loss: 0.4326 - val_accuracy: 0.8309\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.3116 - accuracy: 0.8798 - val_loss: 0.4839 - val_accuracy: 0.8075\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.3103 - accuracy: 0.8786 - val_loss: 0.4597 - val_accuracy: 0.8210\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.3065 - accuracy: 0.8819 - val_loss: 0.4328 - val_accuracy: 0.8311\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.3041 - accuracy: 0.8824 - val_loss: 0.4536 - val_accuracy: 0.8252\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.3020 - accuracy: 0.8823 - val_loss: 0.5502 - val_accuracy: 0.7746\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.2989 - accuracy: 0.8852 - val_loss: 0.5554 - val_accuracy: 0.7718\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.2965 - accuracy: 0.8858 - val_loss: 0.4335 - val_accuracy: 0.8336\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.2956 - accuracy: 0.8863 - val_loss: 0.4991 - val_accuracy: 0.8046\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6770 - accuracy: 0.5849 - val_loss: 0.6679 - val_accuracy: 0.5765\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6326 - accuracy: 0.6634 - val_loss: 0.6490 - val_accuracy: 0.6083\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6038 - accuracy: 0.6869 - val_loss: 0.6290 - val_accuracy: 0.6300\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5858 - accuracy: 0.6982 - val_loss: 0.6123 - val_accuracy: 0.6462\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5713 - accuracy: 0.7099 - val_loss: 0.5805 - val_accuracy: 0.6772\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5591 - accuracy: 0.7164 - val_loss: 0.6242 - val_accuracy: 0.6301\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5493 - accuracy: 0.7230 - val_loss: 0.5946 - val_accuracy: 0.6615\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.5419 - accuracy: 0.7278 - val_loss: 0.6151 - val_accuracy: 0.6402\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5336 - accuracy: 0.7317 - val_loss: 0.6158 - val_accuracy: 0.6434\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.5275 - accuracy: 0.7359 - val_loss: 0.5947 - val_accuracy: 0.6634\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5223 - accuracy: 0.7378 - val_loss: 0.6106 - val_accuracy: 0.6525\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5166 - accuracy: 0.7409 - val_loss: 0.6140 - val_accuracy: 0.6516\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5121 - accuracy: 0.7435 - val_loss: 0.6298 - val_accuracy: 0.6389\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5067 - accuracy: 0.7476 - val_loss: 0.5990 - val_accuracy: 0.6647\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5022 - accuracy: 0.7508 - val_loss: 0.6485 - val_accuracy: 0.6246\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.4979 - accuracy: 0.7531 - val_loss: 0.6159 - val_accuracy: 0.6531\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.4925 - accuracy: 0.7574 - val_loss: 0.5678 - val_accuracy: 0.6952\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.4882 - accuracy: 0.7594 - val_loss: 0.5892 - val_accuracy: 0.6780\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.4826 - accuracy: 0.7641 - val_loss: 0.5840 - val_accuracy: 0.6835\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.4776 - accuracy: 0.7683 - val_loss: 0.5784 - val_accuracy: 0.6905\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.4724 - accuracy: 0.7703 - val_loss: 0.5823 - val_accuracy: 0.6887\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.4666 - accuracy: 0.7759 - val_loss: 0.5953 - val_accuracy: 0.6805\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.4607 - accuracy: 0.7792 - val_loss: 0.5499 - val_accuracy: 0.7216\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.4558 - accuracy: 0.7833 - val_loss: 0.5878 - val_accuracy: 0.6911\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.4483 - accuracy: 0.7895 - val_loss: 0.5548 - val_accuracy: 0.7231\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.4416 - accuracy: 0.7941 - val_loss: 0.6345 - val_accuracy: 0.6606\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.4363 - accuracy: 0.7986 - val_loss: 0.5616 - val_accuracy: 0.7210\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.4283 - accuracy: 0.8030 - val_loss: 0.5688 - val_accuracy: 0.7177\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.4204 - accuracy: 0.8088 - val_loss: 0.6205 - val_accuracy: 0.6781\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.4141 - accuracy: 0.8140 - val_loss: 0.6126 - val_accuracy: 0.6875\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.4064 - accuracy: 0.8200 - val_loss: 0.5912 - val_accuracy: 0.7051\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.3980 - accuracy: 0.8255 - val_loss: 0.5053 - val_accuracy: 0.7730\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.3911 - accuracy: 0.8297 - val_loss: 0.5536 - val_accuracy: 0.7386\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.3842 - accuracy: 0.8343 - val_loss: 0.5226 - val_accuracy: 0.7642\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.3759 - accuracy: 0.8413 - val_loss: 0.5123 - val_accuracy: 0.7733\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.3679 - accuracy: 0.8473 - val_loss: 0.4742 - val_accuracy: 0.8027\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.3618 - accuracy: 0.8507 - val_loss: 0.4607 - val_accuracy: 0.8113\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.3559 - accuracy: 0.8540 - val_loss: 0.4913 - val_accuracy: 0.7935\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.3494 - accuracy: 0.8581 - val_loss: 0.5391 - val_accuracy: 0.7645\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.3432 - accuracy: 0.8614 - val_loss: 0.5456 - val_accuracy: 0.7638\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.3378 - accuracy: 0.8640 - val_loss: 0.5461 - val_accuracy: 0.7659\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.3317 - accuracy: 0.8669 - val_loss: 0.4484 - val_accuracy: 0.8241\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.3266 - accuracy: 0.8705 - val_loss: 0.5390 - val_accuracy: 0.7724\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.3224 - accuracy: 0.8733 - val_loss: 0.4879 - val_accuracy: 0.8038\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.3177 - accuracy: 0.8763 - val_loss: 0.4842 - val_accuracy: 0.8075\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.3158 - accuracy: 0.8756 - val_loss: 0.5431 - val_accuracy: 0.7760\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.3118 - accuracy: 0.8792 - val_loss: 0.4281 - val_accuracy: 0.8345\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.3095 - accuracy: 0.8791 - val_loss: 0.4761 - val_accuracy: 0.8143\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.3050 - accuracy: 0.8813 - val_loss: 0.5392 - val_accuracy: 0.7816\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.3020 - accuracy: 0.8817 - val_loss: 0.4701 - val_accuracy: 0.8184\n",
      "\n",
      "Training model with batch_size=64...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.1 iterated over 41800 steps satisfies differential privacy with eps = 1.42 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 587us/step - loss: 0.6915 - accuracy: 0.5426 - val_loss: 0.6853 - val_accuracy: 0.5145\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 733us/step - loss: 0.6561 - accuracy: 0.6217 - val_loss: 0.6673 - val_accuracy: 0.5657\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6340 - accuracy: 0.6566 - val_loss: 0.6545 - val_accuracy: 0.5851\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.6195 - accuracy: 0.6703 - val_loss: 0.6355 - val_accuracy: 0.6094\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6060 - accuracy: 0.6832 - val_loss: 0.6113 - val_accuracy: 0.6416\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 878us/step - loss: 0.5962 - accuracy: 0.6883 - val_loss: 0.6203 - val_accuracy: 0.6258\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.5859 - accuracy: 0.6995 - val_loss: 0.6067 - val_accuracy: 0.6447\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.5767 - accuracy: 0.7051 - val_loss: 0.6000 - val_accuracy: 0.6503\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 720us/step - loss: 0.5707 - accuracy: 0.7093 - val_loss: 0.5960 - val_accuracy: 0.6502\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.5646 - accuracy: 0.7130 - val_loss: 0.6087 - val_accuracy: 0.6370\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.5585 - accuracy: 0.7173 - val_loss: 0.5966 - val_accuracy: 0.6466\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.5520 - accuracy: 0.7210 - val_loss: 0.5879 - val_accuracy: 0.6585\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 679us/step - loss: 0.5479 - accuracy: 0.7244 - val_loss: 0.5931 - val_accuracy: 0.6551\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.5433 - accuracy: 0.7262 - val_loss: 0.5782 - val_accuracy: 0.6688\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.5393 - accuracy: 0.7286 - val_loss: 0.6035 - val_accuracy: 0.6462\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.5348 - accuracy: 0.7310 - val_loss: 0.5977 - val_accuracy: 0.6496\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 685us/step - loss: 0.5320 - accuracy: 0.7352 - val_loss: 0.5910 - val_accuracy: 0.6570\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.5276 - accuracy: 0.7357 - val_loss: 0.6026 - val_accuracy: 0.6460\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 698us/step - loss: 0.5240 - accuracy: 0.7373 - val_loss: 0.6147 - val_accuracy: 0.6365\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.5204 - accuracy: 0.7414 - val_loss: 0.5692 - val_accuracy: 0.6781\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 681us/step - loss: 0.5180 - accuracy: 0.7405 - val_loss: 0.5994 - val_accuracy: 0.6527\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.5136 - accuracy: 0.7444 - val_loss: 0.6201 - val_accuracy: 0.6342\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 687us/step - loss: 0.5107 - accuracy: 0.7456 - val_loss: 0.5945 - val_accuracy: 0.6576\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.5080 - accuracy: 0.7481 - val_loss: 0.5982 - val_accuracy: 0.6537\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 707us/step - loss: 0.5043 - accuracy: 0.7489 - val_loss: 0.5740 - val_accuracy: 0.6769\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.5027 - accuracy: 0.7511 - val_loss: 0.5874 - val_accuracy: 0.6658\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.4983 - accuracy: 0.7534 - val_loss: 0.5945 - val_accuracy: 0.6595\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 685us/step - loss: 0.4962 - accuracy: 0.7557 - val_loss: 0.5722 - val_accuracy: 0.6782\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 687us/step - loss: 0.4924 - accuracy: 0.7568 - val_loss: 0.5870 - val_accuracy: 0.6657\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.4897 - accuracy: 0.7593 - val_loss: 0.6109 - val_accuracy: 0.6468\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.4856 - accuracy: 0.7613 - val_loss: 0.5950 - val_accuracy: 0.6608\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.4832 - accuracy: 0.7631 - val_loss: 0.5529 - val_accuracy: 0.6927\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.4809 - accuracy: 0.7645 - val_loss: 0.5748 - val_accuracy: 0.6783\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.4767 - accuracy: 0.7672 - val_loss: 0.5966 - val_accuracy: 0.6625\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 667us/step - loss: 0.4740 - accuracy: 0.7695 - val_loss: 0.5827 - val_accuracy: 0.6744\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.4705 - accuracy: 0.7720 - val_loss: 0.5716 - val_accuracy: 0.6836\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.4684 - accuracy: 0.7729 - val_loss: 0.5871 - val_accuracy: 0.6739\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.4648 - accuracy: 0.7768 - val_loss: 0.5749 - val_accuracy: 0.6840\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.4618 - accuracy: 0.7770 - val_loss: 0.5549 - val_accuracy: 0.7014\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.5572 - val_accuracy: 0.7007\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.4538 - accuracy: 0.7838 - val_loss: 0.5746 - val_accuracy: 0.6888\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.4511 - accuracy: 0.7867 - val_loss: 0.5725 - val_accuracy: 0.6898\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.4486 - accuracy: 0.7880 - val_loss: 0.5609 - val_accuracy: 0.6998\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 622us/step - loss: 0.4443 - accuracy: 0.7910 - val_loss: 0.5683 - val_accuracy: 0.6952\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.4405 - accuracy: 0.7943 - val_loss: 0.5494 - val_accuracy: 0.7137\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 678us/step - loss: 0.4361 - accuracy: 0.7973 - val_loss: 0.5546 - val_accuracy: 0.7110\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.4323 - accuracy: 0.8008 - val_loss: 0.5569 - val_accuracy: 0.7110\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 676us/step - loss: 0.4285 - accuracy: 0.8032 - val_loss: 0.5252 - val_accuracy: 0.7400\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.4244 - accuracy: 0.8064 - val_loss: 0.5454 - val_accuracy: 0.7231\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.4211 - accuracy: 0.8089 - val_loss: 0.5264 - val_accuracy: 0.7431\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.6975 - accuracy: 0.5385 - val_loss: 0.7006 - val_accuracy: 0.5358\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.6676 - accuracy: 0.5889 - val_loss: 0.6861 - val_accuracy: 0.5838\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6538 - accuracy: 0.6211 - val_loss: 0.6627 - val_accuracy: 0.6365\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.6418 - accuracy: 0.6413 - val_loss: 0.6556 - val_accuracy: 0.6405\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6302 - accuracy: 0.6552 - val_loss: 0.6566 - val_accuracy: 0.6295\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.6201 - accuracy: 0.6660 - val_loss: 0.6428 - val_accuracy: 0.6459\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6105 - accuracy: 0.6766 - val_loss: 0.6341 - val_accuracy: 0.6513\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 616us/step - loss: 0.6019 - accuracy: 0.6873 - val_loss: 0.6372 - val_accuracy: 0.6384\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.5936 - accuracy: 0.6938 - val_loss: 0.6220 - val_accuracy: 0.6480\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.5857 - accuracy: 0.7017 - val_loss: 0.6199 - val_accuracy: 0.6469\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.5787 - accuracy: 0.7073 - val_loss: 0.6285 - val_accuracy: 0.6356\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.5728 - accuracy: 0.7125 - val_loss: 0.6176 - val_accuracy: 0.6454\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.5660 - accuracy: 0.7173 - val_loss: 0.6079 - val_accuracy: 0.6570\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.5603 - accuracy: 0.7204 - val_loss: 0.6268 - val_accuracy: 0.6395\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.5534 - accuracy: 0.7255 - val_loss: 0.6009 - val_accuracy: 0.6680\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.5478 - accuracy: 0.7283 - val_loss: 0.6101 - val_accuracy: 0.6577\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.5433 - accuracy: 0.7316 - val_loss: 0.6205 - val_accuracy: 0.6453\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 701us/step - loss: 0.5376 - accuracy: 0.7340 - val_loss: 0.6021 - val_accuracy: 0.6617\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.5345 - accuracy: 0.7356 - val_loss: 0.5954 - val_accuracy: 0.6686\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.5305 - accuracy: 0.7371 - val_loss: 0.6118 - val_accuracy: 0.6486\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 701us/step - loss: 0.5260 - accuracy: 0.7400 - val_loss: 0.5925 - val_accuracy: 0.6685\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.5240 - accuracy: 0.7384 - val_loss: 0.6113 - val_accuracy: 0.6462\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.5202 - accuracy: 0.7422 - val_loss: 0.5769 - val_accuracy: 0.6889\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.5173 - accuracy: 0.7443 - val_loss: 0.5978 - val_accuracy: 0.6619\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.5146 - accuracy: 0.7448 - val_loss: 0.6006 - val_accuracy: 0.6610\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 682us/step - loss: 0.5117 - accuracy: 0.7465 - val_loss: 0.5935 - val_accuracy: 0.6681\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.5086 - accuracy: 0.7486 - val_loss: 0.5927 - val_accuracy: 0.6690\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 682us/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5863 - val_accuracy: 0.6761\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5930 - val_accuracy: 0.6706\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 680us/step - loss: 0.5012 - accuracy: 0.7532 - val_loss: 0.6125 - val_accuracy: 0.6555\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.4966 - accuracy: 0.7564 - val_loss: 0.5766 - val_accuracy: 0.6866\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.4944 - accuracy: 0.7560 - val_loss: 0.5603 - val_accuracy: 0.7016\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.4934 - accuracy: 0.7572 - val_loss: 0.6082 - val_accuracy: 0.6611\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.4894 - accuracy: 0.7610 - val_loss: 0.5719 - val_accuracy: 0.6916\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.4865 - accuracy: 0.7623 - val_loss: 0.5750 - val_accuracy: 0.6892\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.4841 - accuracy: 0.7637 - val_loss: 0.5884 - val_accuracy: 0.6802\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.4816 - accuracy: 0.7661 - val_loss: 0.5645 - val_accuracy: 0.7005\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.4789 - accuracy: 0.7659 - val_loss: 0.5967 - val_accuracy: 0.6768\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.4762 - accuracy: 0.7684 - val_loss: 0.5787 - val_accuracy: 0.6909\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 680us/step - loss: 0.4742 - accuracy: 0.7708 - val_loss: 0.5941 - val_accuracy: 0.6796\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.4711 - accuracy: 0.7733 - val_loss: 0.5828 - val_accuracy: 0.6882\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.4680 - accuracy: 0.7765 - val_loss: 0.5930 - val_accuracy: 0.6822\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.4655 - accuracy: 0.7768 - val_loss: 0.5593 - val_accuracy: 0.7085\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 690us/step - loss: 0.4625 - accuracy: 0.7793 - val_loss: 0.5622 - val_accuracy: 0.7064\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.4601 - accuracy: 0.7808 - val_loss: 0.6214 - val_accuracy: 0.6648\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.4563 - accuracy: 0.7835 - val_loss: 0.5700 - val_accuracy: 0.7014\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.4535 - accuracy: 0.7846 - val_loss: 0.5894 - val_accuracy: 0.6884\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.4499 - accuracy: 0.7890 - val_loss: 0.5618 - val_accuracy: 0.7125\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.4462 - accuracy: 0.7903 - val_loss: 0.6067 - val_accuracy: 0.6790\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.4437 - accuracy: 0.7920 - val_loss: 0.5928 - val_accuracy: 0.6887\n",
      "Epoch 1/50\n",
      "  1/836 [..............................] - ETA: 0s - loss: 0.8248 - accuracy: 0.4531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6910 - accuracy: 0.5432 - val_loss: 0.6800 - val_accuracy: 0.5883\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.6659 - accuracy: 0.5948 - val_loss: 0.6724 - val_accuracy: 0.6061\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.6518 - accuracy: 0.6253 - val_loss: 0.6639 - val_accuracy: 0.6159\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6393 - accuracy: 0.6447 - val_loss: 0.6563 - val_accuracy: 0.6229\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6288 - accuracy: 0.6596 - val_loss: 0.6333 - val_accuracy: 0.6506\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 701us/step - loss: 0.6197 - accuracy: 0.6693 - val_loss: 0.6338 - val_accuracy: 0.6388\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6100 - accuracy: 0.6789 - val_loss: 0.6294 - val_accuracy: 0.6402\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 678us/step - loss: 0.6014 - accuracy: 0.6867 - val_loss: 0.6098 - val_accuracy: 0.6615\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.5942 - accuracy: 0.6924 - val_loss: 0.6172 - val_accuracy: 0.6466\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 680us/step - loss: 0.5870 - accuracy: 0.6986 - val_loss: 0.6107 - val_accuracy: 0.6492\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.5815 - accuracy: 0.7028 - val_loss: 0.6081 - val_accuracy: 0.6478\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.5747 - accuracy: 0.7070 - val_loss: 0.6103 - val_accuracy: 0.6401\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 647us/step - loss: 0.5695 - accuracy: 0.7113 - val_loss: 0.6140 - val_accuracy: 0.6356\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.5625 - accuracy: 0.7175 - val_loss: 0.6045 - val_accuracy: 0.6449\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 612us/step - loss: 0.5570 - accuracy: 0.7212 - val_loss: 0.5999 - val_accuracy: 0.6488\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.5534 - accuracy: 0.7229 - val_loss: 0.6082 - val_accuracy: 0.6404\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 674us/step - loss: 0.5474 - accuracy: 0.7249 - val_loss: 0.6110 - val_accuracy: 0.6374\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.5429 - accuracy: 0.7279 - val_loss: 0.5972 - val_accuracy: 0.6509\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 701us/step - loss: 0.5399 - accuracy: 0.7284 - val_loss: 0.5844 - val_accuracy: 0.6643\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 599us/step - loss: 0.5358 - accuracy: 0.7328 - val_loss: 0.5979 - val_accuracy: 0.6538\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.5322 - accuracy: 0.7341 - val_loss: 0.5984 - val_accuracy: 0.6537\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.5282 - accuracy: 0.7381 - val_loss: 0.6057 - val_accuracy: 0.6475\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.5252 - accuracy: 0.7356 - val_loss: 0.6028 - val_accuracy: 0.6495\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 603us/step - loss: 0.5202 - accuracy: 0.7395 - val_loss: 0.5862 - val_accuracy: 0.6647\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.5183 - accuracy: 0.7412 - val_loss: 0.5945 - val_accuracy: 0.6583\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.5156 - accuracy: 0.7436 - val_loss: 0.5967 - val_accuracy: 0.6576\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.5125 - accuracy: 0.7459 - val_loss: 0.5927 - val_accuracy: 0.6611\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 605us/step - loss: 0.5097 - accuracy: 0.7463 - val_loss: 0.5849 - val_accuracy: 0.6688\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 687us/step - loss: 0.5070 - accuracy: 0.7479 - val_loss: 0.5858 - val_accuracy: 0.6689\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.5039 - accuracy: 0.7505 - val_loss: 0.5960 - val_accuracy: 0.6596\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 613us/step - loss: 0.5011 - accuracy: 0.7506 - val_loss: 0.6211 - val_accuracy: 0.6388\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.4973 - accuracy: 0.7535 - val_loss: 0.6008 - val_accuracy: 0.6563\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 784us/step - loss: 0.4944 - accuracy: 0.7549 - val_loss: 0.6073 - val_accuracy: 0.6506\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.4917 - accuracy: 0.7591 - val_loss: 0.6083 - val_accuracy: 0.6504\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 880us/step - loss: 0.4888 - accuracy: 0.7599 - val_loss: 0.5850 - val_accuracy: 0.6709\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.4872 - accuracy: 0.7602 - val_loss: 0.6046 - val_accuracy: 0.6560\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.4820 - accuracy: 0.7650 - val_loss: 0.5984 - val_accuracy: 0.6624\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.4795 - accuracy: 0.7673 - val_loss: 0.5762 - val_accuracy: 0.6792\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.4774 - accuracy: 0.7678 - val_loss: 0.5507 - val_accuracy: 0.7033\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.4726 - accuracy: 0.7728 - val_loss: 0.5882 - val_accuracy: 0.6707\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.4706 - accuracy: 0.7728 - val_loss: 0.5518 - val_accuracy: 0.7013\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 553us/step - loss: 0.4668 - accuracy: 0.7757 - val_loss: 0.5769 - val_accuracy: 0.6804\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.4638 - accuracy: 0.7789 - val_loss: 0.5368 - val_accuracy: 0.7167\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 608us/step - loss: 0.4594 - accuracy: 0.7811 - val_loss: 0.5585 - val_accuracy: 0.6962\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 587us/step - loss: 0.4567 - accuracy: 0.7817 - val_loss: 0.5621 - val_accuracy: 0.6931\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.4520 - accuracy: 0.7874 - val_loss: 0.5753 - val_accuracy: 0.6840\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 560us/step - loss: 0.4488 - accuracy: 0.7881 - val_loss: 0.5573 - val_accuracy: 0.6999\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.4462 - accuracy: 0.7910 - val_loss: 0.5490 - val_accuracy: 0.7089\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.4409 - accuracy: 0.7946 - val_loss: 0.5754 - val_accuracy: 0.6874\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 622us/step - loss: 0.4359 - accuracy: 0.7970 - val_loss: 0.5279 - val_accuracy: 0.7286\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 594us/step - loss: 0.7006 - accuracy: 0.5111 - val_loss: 0.6993 - val_accuracy: 0.4882\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 539us/step - loss: 0.6691 - accuracy: 0.5856 - val_loss: 0.6791 - val_accuracy: 0.5924\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6507 - accuracy: 0.6289 - val_loss: 0.6610 - val_accuracy: 0.6321\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 607us/step - loss: 0.6343 - accuracy: 0.6550 - val_loss: 0.6522 - val_accuracy: 0.6385\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6208 - accuracy: 0.6739 - val_loss: 0.6201 - val_accuracy: 0.6741\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.6093 - accuracy: 0.6848 - val_loss: 0.6183 - val_accuracy: 0.6668\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.5998 - accuracy: 0.6912 - val_loss: 0.6190 - val_accuracy: 0.6580\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.5916 - accuracy: 0.6990 - val_loss: 0.6077 - val_accuracy: 0.6679\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 542us/step - loss: 0.5835 - accuracy: 0.7050 - val_loss: 0.6249 - val_accuracy: 0.6423\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 614us/step - loss: 0.5764 - accuracy: 0.7087 - val_loss: 0.6071 - val_accuracy: 0.6611\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.5690 - accuracy: 0.7161 - val_loss: 0.6100 - val_accuracy: 0.6563\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.5637 - accuracy: 0.7186 - val_loss: 0.6030 - val_accuracy: 0.6587\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.5579 - accuracy: 0.7242 - val_loss: 0.5928 - val_accuracy: 0.6654\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.5530 - accuracy: 0.7241 - val_loss: 0.5903 - val_accuracy: 0.6678\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 555us/step - loss: 0.5476 - accuracy: 0.7275 - val_loss: 0.5886 - val_accuracy: 0.6711\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.5411 - accuracy: 0.7339 - val_loss: 0.5875 - val_accuracy: 0.6729\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 552us/step - loss: 0.5376 - accuracy: 0.7325 - val_loss: 0.6056 - val_accuracy: 0.6531\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.5333 - accuracy: 0.7336 - val_loss: 0.6055 - val_accuracy: 0.6521\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.5293 - accuracy: 0.7364 - val_loss: 0.5813 - val_accuracy: 0.6799\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.5259 - accuracy: 0.7378 - val_loss: 0.6052 - val_accuracy: 0.6537\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 545us/step - loss: 0.5217 - accuracy: 0.7419 - val_loss: 0.6114 - val_accuracy: 0.6470\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.5181 - accuracy: 0.7436 - val_loss: 0.6086 - val_accuracy: 0.6498\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 629us/step - loss: 0.5147 - accuracy: 0.7448 - val_loss: 0.5973 - val_accuracy: 0.6616\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 559us/step - loss: 0.5123 - accuracy: 0.7450 - val_loss: 0.5725 - val_accuracy: 0.6826\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.5099 - accuracy: 0.7470 - val_loss: 0.6022 - val_accuracy: 0.6547\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.5059 - accuracy: 0.7481 - val_loss: 0.5915 - val_accuracy: 0.6665\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.5036 - accuracy: 0.7492 - val_loss: 0.5952 - val_accuracy: 0.6631\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 553us/step - loss: 0.5015 - accuracy: 0.7509 - val_loss: 0.5874 - val_accuracy: 0.6695\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.4969 - accuracy: 0.7550 - val_loss: 0.6092 - val_accuracy: 0.6498\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.4947 - accuracy: 0.7568 - val_loss: 0.5898 - val_accuracy: 0.6677\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 574us/step - loss: 0.4916 - accuracy: 0.7572 - val_loss: 0.5763 - val_accuracy: 0.6785\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.4895 - accuracy: 0.7593 - val_loss: 0.5844 - val_accuracy: 0.6726\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.4865 - accuracy: 0.7615 - val_loss: 0.5781 - val_accuracy: 0.6790\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.4833 - accuracy: 0.7649 - val_loss: 0.5696 - val_accuracy: 0.6875\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.4810 - accuracy: 0.7643 - val_loss: 0.5768 - val_accuracy: 0.6819\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.4773 - accuracy: 0.7672 - val_loss: 0.5607 - val_accuracy: 0.6988\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 556us/step - loss: 0.4742 - accuracy: 0.7697 - val_loss: 0.5807 - val_accuracy: 0.6806\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.4699 - accuracy: 0.7731 - val_loss: 0.5917 - val_accuracy: 0.6737\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 622us/step - loss: 0.4668 - accuracy: 0.7746 - val_loss: 0.5570 - val_accuracy: 0.7042\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 561us/step - loss: 0.4621 - accuracy: 0.7803 - val_loss: 0.5556 - val_accuracy: 0.7054\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 622us/step - loss: 0.4592 - accuracy: 0.7808 - val_loss: 0.5710 - val_accuracy: 0.6917\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 574us/step - loss: 0.4559 - accuracy: 0.7837 - val_loss: 0.5755 - val_accuracy: 0.6901\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.4519 - accuracy: 0.7871 - val_loss: 0.5960 - val_accuracy: 0.6783\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.4478 - accuracy: 0.7902 - val_loss: 0.5878 - val_accuracy: 0.6840\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.4438 - accuracy: 0.7932 - val_loss: 0.5530 - val_accuracy: 0.7146\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 560us/step - loss: 0.4402 - accuracy: 0.7967 - val_loss: 0.5609 - val_accuracy: 0.7092\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.4367 - accuracy: 0.7987 - val_loss: 0.5382 - val_accuracy: 0.7298\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 614us/step - loss: 0.4323 - accuracy: 0.8022 - val_loss: 0.5515 - val_accuracy: 0.7198\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.4284 - accuracy: 0.8063 - val_loss: 0.5556 - val_accuracy: 0.7180\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 602us/step - loss: 0.4246 - accuracy: 0.8080 - val_loss: 0.5486 - val_accuracy: 0.7250\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 592us/step - loss: 0.6746 - accuracy: 0.5837 - val_loss: 0.6939 - val_accuracy: 0.5349\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.6532 - accuracy: 0.6326 - val_loss: 0.6719 - val_accuracy: 0.5926\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6358 - accuracy: 0.6552 - val_loss: 0.6437 - val_accuracy: 0.6477\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6199 - accuracy: 0.6730 - val_loss: 0.6329 - val_accuracy: 0.6562\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6047 - accuracy: 0.6853 - val_loss: 0.6177 - val_accuracy: 0.6690\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 672us/step - loss: 0.5914 - accuracy: 0.6937 - val_loss: 0.5941 - val_accuracy: 0.6940\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 537us/step - loss: 0.5803 - accuracy: 0.7030 - val_loss: 0.5937 - val_accuracy: 0.6798\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.5712 - accuracy: 0.7103 - val_loss: 0.5886 - val_accuracy: 0.6792\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 609us/step - loss: 0.5620 - accuracy: 0.7173 - val_loss: 0.5870 - val_accuracy: 0.6749\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.5547 - accuracy: 0.7238 - val_loss: 0.6236 - val_accuracy: 0.6298\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 612us/step - loss: 0.5488 - accuracy: 0.7273 - val_loss: 0.5785 - val_accuracy: 0.6750\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 559us/step - loss: 0.5428 - accuracy: 0.7332 - val_loss: 0.5959 - val_accuracy: 0.6553\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 617us/step - loss: 0.5364 - accuracy: 0.7357 - val_loss: 0.5770 - val_accuracy: 0.6701\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 561us/step - loss: 0.5315 - accuracy: 0.7397 - val_loss: 0.5601 - val_accuracy: 0.6867\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.5271 - accuracy: 0.7414 - val_loss: 0.6034 - val_accuracy: 0.6433\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 553us/step - loss: 0.5235 - accuracy: 0.7419 - val_loss: 0.5869 - val_accuracy: 0.6552\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.5198 - accuracy: 0.7435 - val_loss: 0.5831 - val_accuracy: 0.6589\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 542us/step - loss: 0.5153 - accuracy: 0.7469 - val_loss: 0.6019 - val_accuracy: 0.6415\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.5119 - accuracy: 0.7492 - val_loss: 0.5953 - val_accuracy: 0.6476\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.5095 - accuracy: 0.7488 - val_loss: 0.5834 - val_accuracy: 0.6579\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5851 - val_accuracy: 0.6574\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.5035 - accuracy: 0.7506 - val_loss: 0.5883 - val_accuracy: 0.6549\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 551us/step - loss: 0.4986 - accuracy: 0.7547 - val_loss: 0.5775 - val_accuracy: 0.6640\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 608us/step - loss: 0.4959 - accuracy: 0.7567 - val_loss: 0.5948 - val_accuracy: 0.6517\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 547us/step - loss: 0.4929 - accuracy: 0.7573 - val_loss: 0.6105 - val_accuracy: 0.6388\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.4898 - accuracy: 0.7599 - val_loss: 0.6126 - val_accuracy: 0.6377\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 545us/step - loss: 0.4873 - accuracy: 0.7613 - val_loss: 0.5878 - val_accuracy: 0.6584\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.4843 - accuracy: 0.7635 - val_loss: 0.5668 - val_accuracy: 0.6740\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 539us/step - loss: 0.4808 - accuracy: 0.7657 - val_loss: 0.5631 - val_accuracy: 0.6773\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.4775 - accuracy: 0.7692 - val_loss: 0.5653 - val_accuracy: 0.6762\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 619us/step - loss: 0.4733 - accuracy: 0.7726 - val_loss: 0.5950 - val_accuracy: 0.6579\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.4699 - accuracy: 0.7737 - val_loss: 0.5444 - val_accuracy: 0.6998\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 530us/step - loss: 0.4662 - accuracy: 0.7773 - val_loss: 0.6177 - val_accuracy: 0.6440\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 621us/step - loss: 0.4629 - accuracy: 0.7783 - val_loss: 0.6100 - val_accuracy: 0.6496\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 542us/step - loss: 0.4583 - accuracy: 0.7823 - val_loss: 0.5461 - val_accuracy: 0.7021\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.4556 - accuracy: 0.7844 - val_loss: 0.5519 - val_accuracy: 0.6972\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 541us/step - loss: 0.4509 - accuracy: 0.7877 - val_loss: 0.5676 - val_accuracy: 0.6863\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.4465 - accuracy: 0.7921 - val_loss: 0.5727 - val_accuracy: 0.6838\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 534us/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.5643 - val_accuracy: 0.6910\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 629us/step - loss: 0.4390 - accuracy: 0.7968 - val_loss: 0.5669 - val_accuracy: 0.6899\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 613us/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.5006 - val_accuracy: 0.7555\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 549us/step - loss: 0.4307 - accuracy: 0.8044 - val_loss: 0.5517 - val_accuracy: 0.7068\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.4271 - accuracy: 0.8064 - val_loss: 0.5629 - val_accuracy: 0.6991\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 559us/step - loss: 0.4223 - accuracy: 0.8081 - val_loss: 0.5591 - val_accuracy: 0.7055\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 602us/step - loss: 0.4175 - accuracy: 0.8114 - val_loss: 0.5393 - val_accuracy: 0.7259\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 551us/step - loss: 0.4135 - accuracy: 0.8173 - val_loss: 0.5241 - val_accuracy: 0.7394\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.4089 - accuracy: 0.8201 - val_loss: 0.4874 - val_accuracy: 0.7763\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 532us/step - loss: 0.4052 - accuracy: 0.8209 - val_loss: 0.5285 - val_accuracy: 0.7386\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 619us/step - loss: 0.4007 - accuracy: 0.8256 - val_loss: 0.5290 - val_accuracy: 0.7392\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 539us/step - loss: 0.3960 - accuracy: 0.8281 - val_loss: 0.4982 - val_accuracy: 0.7683\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.7072 - accuracy: 0.4917 - val_loss: 0.7139 - val_accuracy: 0.4121\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.6770 - accuracy: 0.5682 - val_loss: 0.7049 - val_accuracy: 0.4586\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.6596 - accuracy: 0.6133 - val_loss: 0.6858 - val_accuracy: 0.5229\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 621us/step - loss: 0.6451 - accuracy: 0.6425 - val_loss: 0.6664 - val_accuracy: 0.5716\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 561us/step - loss: 0.6315 - accuracy: 0.6658 - val_loss: 0.6442 - val_accuracy: 0.6210\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 619us/step - loss: 0.6201 - accuracy: 0.6785 - val_loss: 0.6580 - val_accuracy: 0.5875\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 540us/step - loss: 0.6090 - accuracy: 0.6902 - val_loss: 0.6343 - val_accuracy: 0.6231\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 535us/step - loss: 0.5997 - accuracy: 0.6970 - val_loss: 0.6249 - val_accuracy: 0.6298\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.5893 - accuracy: 0.7053 - val_loss: 0.6132 - val_accuracy: 0.6418\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 536us/step - loss: 0.5812 - accuracy: 0.7125 - val_loss: 0.6186 - val_accuracy: 0.6330\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.5738 - accuracy: 0.7161 - val_loss: 0.6141 - val_accuracy: 0.6376\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 534us/step - loss: 0.5674 - accuracy: 0.7201 - val_loss: 0.6067 - val_accuracy: 0.6420\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.5616 - accuracy: 0.7228 - val_loss: 0.6144 - val_accuracy: 0.6325\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.5554 - accuracy: 0.7253 - val_loss: 0.5909 - val_accuracy: 0.6563\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.5495 - accuracy: 0.7281 - val_loss: 0.6072 - val_accuracy: 0.6376\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.5452 - accuracy: 0.7321 - val_loss: 0.6017 - val_accuracy: 0.6406\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 539us/step - loss: 0.5403 - accuracy: 0.7318 - val_loss: 0.5938 - val_accuracy: 0.6490\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.5363 - accuracy: 0.7339 - val_loss: 0.5886 - val_accuracy: 0.6502\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 608us/step - loss: 0.5326 - accuracy: 0.7344 - val_loss: 0.6028 - val_accuracy: 0.6378\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.5281 - accuracy: 0.7367 - val_loss: 0.5869 - val_accuracy: 0.6493\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 601us/step - loss: 0.5248 - accuracy: 0.7384 - val_loss: 0.5909 - val_accuracy: 0.6457\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 556us/step - loss: 0.5213 - accuracy: 0.7405 - val_loss: 0.6030 - val_accuracy: 0.6366\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 606us/step - loss: 0.5175 - accuracy: 0.7409 - val_loss: 0.5863 - val_accuracy: 0.6502\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 556us/step - loss: 0.5149 - accuracy: 0.7437 - val_loss: 0.5696 - val_accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 533us/step - loss: 0.5111 - accuracy: 0.7457 - val_loss: 0.6154 - val_accuracy: 0.6313\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 616us/step - loss: 0.5085 - accuracy: 0.7461 - val_loss: 0.6052 - val_accuracy: 0.6384\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 547us/step - loss: 0.5051 - accuracy: 0.7476 - val_loss: 0.5965 - val_accuracy: 0.6449\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.5024 - accuracy: 0.7493 - val_loss: 0.5981 - val_accuracy: 0.6435\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 540us/step - loss: 0.4999 - accuracy: 0.7513 - val_loss: 0.6025 - val_accuracy: 0.6414\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 622us/step - loss: 0.4953 - accuracy: 0.7543 - val_loss: 0.5698 - val_accuracy: 0.6710\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 540us/step - loss: 0.4935 - accuracy: 0.7555 - val_loss: 0.5633 - val_accuracy: 0.6786\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.4905 - accuracy: 0.7562 - val_loss: 0.5633 - val_accuracy: 0.6792\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 606us/step - loss: 0.4871 - accuracy: 0.7591 - val_loss: 0.5910 - val_accuracy: 0.6543\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.4845 - accuracy: 0.7602 - val_loss: 0.5922 - val_accuracy: 0.6539\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.4803 - accuracy: 0.7638 - val_loss: 0.5933 - val_accuracy: 0.6549\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 545us/step - loss: 0.4765 - accuracy: 0.7657 - val_loss: 0.5890 - val_accuracy: 0.6586\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 537us/step - loss: 0.4734 - accuracy: 0.7673 - val_loss: 0.5755 - val_accuracy: 0.6727\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.4709 - accuracy: 0.7695 - val_loss: 0.5907 - val_accuracy: 0.6616\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.4672 - accuracy: 0.7721 - val_loss: 0.5647 - val_accuracy: 0.6856\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 543us/step - loss: 0.4630 - accuracy: 0.7748 - val_loss: 0.5668 - val_accuracy: 0.6857\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.4605 - accuracy: 0.7773 - val_loss: 0.5952 - val_accuracy: 0.6635\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 560us/step - loss: 0.4560 - accuracy: 0.7805 - val_loss: 0.6210 - val_accuracy: 0.6495\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.4529 - accuracy: 0.7825 - val_loss: 0.5722 - val_accuracy: 0.6869\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 544us/step - loss: 0.4495 - accuracy: 0.7854 - val_loss: 0.5725 - val_accuracy: 0.6884\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 629us/step - loss: 0.4442 - accuracy: 0.7892 - val_loss: 0.5629 - val_accuracy: 0.6983\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 617us/step - loss: 0.4405 - accuracy: 0.7923 - val_loss: 0.5516 - val_accuracy: 0.7078\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.4376 - accuracy: 0.7931 - val_loss: 0.5611 - val_accuracy: 0.7018\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 616us/step - loss: 0.4328 - accuracy: 0.7976 - val_loss: 0.5686 - val_accuracy: 0.6967\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 548us/step - loss: 0.4276 - accuracy: 0.8005 - val_loss: 0.5289 - val_accuracy: 0.7292\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.4248 - accuracy: 0.8038 - val_loss: 0.5295 - val_accuracy: 0.7302\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 586us/step - loss: 0.7040 - accuracy: 0.5222 - val_loss: 0.6808 - val_accuracy: 0.5896\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 610us/step - loss: 0.6613 - accuracy: 0.6077 - val_loss: 0.6502 - val_accuracy: 0.6551\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 553us/step - loss: 0.6386 - accuracy: 0.6476 - val_loss: 0.6385 - val_accuracy: 0.6501\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6232 - accuracy: 0.6663 - val_loss: 0.6318 - val_accuracy: 0.6478\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 553us/step - loss: 0.6101 - accuracy: 0.6774 - val_loss: 0.6158 - val_accuracy: 0.6629\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.5991 - accuracy: 0.6864 - val_loss: 0.6035 - val_accuracy: 0.6751\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.5898 - accuracy: 0.6938 - val_loss: 0.6025 - val_accuracy: 0.6681\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 555us/step - loss: 0.5821 - accuracy: 0.6996 - val_loss: 0.6163 - val_accuracy: 0.6478\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.5749 - accuracy: 0.7054 - val_loss: 0.6106 - val_accuracy: 0.6523\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.5693 - accuracy: 0.7116 - val_loss: 0.6219 - val_accuracy: 0.6393\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 566us/step - loss: 0.5638 - accuracy: 0.7136 - val_loss: 0.5954 - val_accuracy: 0.6669\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.5581 - accuracy: 0.7194 - val_loss: 0.6025 - val_accuracy: 0.6600\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 552us/step - loss: 0.5535 - accuracy: 0.7194 - val_loss: 0.5918 - val_accuracy: 0.6688\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.5492 - accuracy: 0.7236 - val_loss: 0.5977 - val_accuracy: 0.6622\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 545us/step - loss: 0.5450 - accuracy: 0.7249 - val_loss: 0.5818 - val_accuracy: 0.6754\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.5408 - accuracy: 0.7272 - val_loss: 0.6036 - val_accuracy: 0.6573\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.5377 - accuracy: 0.7306 - val_loss: 0.6054 - val_accuracy: 0.6547\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.5334 - accuracy: 0.7316 - val_loss: 0.5913 - val_accuracy: 0.6653\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.5287 - accuracy: 0.7344 - val_loss: 0.5835 - val_accuracy: 0.6702\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 540us/step - loss: 0.5258 - accuracy: 0.7351 - val_loss: 0.6102 - val_accuracy: 0.6497\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.5226 - accuracy: 0.7372 - val_loss: 0.5874 - val_accuracy: 0.6640\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 614us/step - loss: 0.5203 - accuracy: 0.7389 - val_loss: 0.6245 - val_accuracy: 0.6367\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.5173 - accuracy: 0.7409 - val_loss: 0.5998 - val_accuracy: 0.6534\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.5135 - accuracy: 0.7418 - val_loss: 0.6211 - val_accuracy: 0.6396\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 535us/step - loss: 0.5104 - accuracy: 0.7434 - val_loss: 0.6283 - val_accuracy: 0.6354\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 620us/step - loss: 0.5078 - accuracy: 0.7459 - val_loss: 0.6072 - val_accuracy: 0.6508\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 538us/step - loss: 0.5059 - accuracy: 0.7475 - val_loss: 0.6077 - val_accuracy: 0.6503\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 629us/step - loss: 0.5023 - accuracy: 0.7487 - val_loss: 0.5877 - val_accuracy: 0.6658\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 617us/step - loss: 0.4988 - accuracy: 0.7516 - val_loss: 0.6063 - val_accuracy: 0.6528\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 545us/step - loss: 0.4971 - accuracy: 0.7538 - val_loss: 0.5885 - val_accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.4942 - accuracy: 0.7559 - val_loss: 0.5811 - val_accuracy: 0.6738\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 550us/step - loss: 0.4909 - accuracy: 0.7573 - val_loss: 0.5992 - val_accuracy: 0.6595\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.4873 - accuracy: 0.7602 - val_loss: 0.5814 - val_accuracy: 0.6754\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 621us/step - loss: 0.4841 - accuracy: 0.7622 - val_loss: 0.5834 - val_accuracy: 0.6734\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 551us/step - loss: 0.4805 - accuracy: 0.7640 - val_loss: 0.5744 - val_accuracy: 0.6811\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 619us/step - loss: 0.4785 - accuracy: 0.7661 - val_loss: 0.5657 - val_accuracy: 0.6893\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 543us/step - loss: 0.4760 - accuracy: 0.7680 - val_loss: 0.5922 - val_accuracy: 0.6702\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.4724 - accuracy: 0.7715 - val_loss: 0.5679 - val_accuracy: 0.6898\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.4681 - accuracy: 0.7745 - val_loss: 0.5814 - val_accuracy: 0.6810\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.4655 - accuracy: 0.7759 - val_loss: 0.6041 - val_accuracy: 0.6638\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.4613 - accuracy: 0.7790 - val_loss: 0.5972 - val_accuracy: 0.6707\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 548us/step - loss: 0.4576 - accuracy: 0.7813 - val_loss: 0.5653 - val_accuracy: 0.6976\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.4544 - accuracy: 0.7853 - val_loss: 0.5967 - val_accuracy: 0.6743\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 736us/step - loss: 0.4502 - accuracy: 0.7879 - val_loss: 0.5428 - val_accuracy: 0.7183\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 794us/step - loss: 0.4471 - accuracy: 0.7893 - val_loss: 0.5556 - val_accuracy: 0.7058\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 972us/step - loss: 0.4434 - accuracy: 0.7932 - val_loss: 0.5450 - val_accuracy: 0.7171\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.4395 - accuracy: 0.7961 - val_loss: 0.5528 - val_accuracy: 0.7114\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 794us/step - loss: 0.4351 - accuracy: 0.7983 - val_loss: 0.5514 - val_accuracy: 0.7135\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 719us/step - loss: 0.4305 - accuracy: 0.8022 - val_loss: 0.5306 - val_accuracy: 0.7349\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.5491 - val_accuracy: 0.7181\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.6729 - accuracy: 0.5885 - val_loss: 0.6790 - val_accuracy: 0.5941\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6413 - accuracy: 0.6466 - val_loss: 0.6622 - val_accuracy: 0.6216\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6251 - accuracy: 0.6681 - val_loss: 0.6465 - val_accuracy: 0.6449\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6099 - accuracy: 0.6864 - val_loss: 0.6339 - val_accuracy: 0.6516\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.5956 - accuracy: 0.6971 - val_loss: 0.6215 - val_accuracy: 0.6577\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 720us/step - loss: 0.5842 - accuracy: 0.7062 - val_loss: 0.6235 - val_accuracy: 0.6495\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 682us/step - loss: 0.5744 - accuracy: 0.7160 - val_loss: 0.6194 - val_accuracy: 0.6478\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.5659 - accuracy: 0.7215 - val_loss: 0.5975 - val_accuracy: 0.6655\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.5579 - accuracy: 0.7260 - val_loss: 0.5999 - val_accuracy: 0.6605\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.5510 - accuracy: 0.7298 - val_loss: 0.5835 - val_accuracy: 0.6732\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.5450 - accuracy: 0.7333 - val_loss: 0.5912 - val_accuracy: 0.6664\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.5395 - accuracy: 0.7356 - val_loss: 0.6130 - val_accuracy: 0.6471\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 671us/step - loss: 0.5343 - accuracy: 0.7393 - val_loss: 0.5992 - val_accuracy: 0.6573\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 744us/step - loss: 0.5292 - accuracy: 0.7394 - val_loss: 0.6043 - val_accuracy: 0.6530\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.5267 - accuracy: 0.7407 - val_loss: 0.6200 - val_accuracy: 0.6415\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.5228 - accuracy: 0.7421 - val_loss: 0.5761 - val_accuracy: 0.6830\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.5191 - accuracy: 0.7449 - val_loss: 0.5808 - val_accuracy: 0.6774\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.5164 - accuracy: 0.7442 - val_loss: 0.6129 - val_accuracy: 0.6472\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 730us/step - loss: 0.5128 - accuracy: 0.7480 - val_loss: 0.5879 - val_accuracy: 0.6720\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.5095 - accuracy: 0.7493 - val_loss: 0.5627 - val_accuracy: 0.6948\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 733us/step - loss: 0.5070 - accuracy: 0.7513 - val_loss: 0.5949 - val_accuracy: 0.6675\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.5035 - accuracy: 0.7512 - val_loss: 0.6109 - val_accuracy: 0.6522\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.5014 - accuracy: 0.7542 - val_loss: 0.5832 - val_accuracy: 0.6771\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.4989 - accuracy: 0.7543 - val_loss: 0.6026 - val_accuracy: 0.6612\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.4950 - accuracy: 0.7581 - val_loss: 0.5599 - val_accuracy: 0.6970\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.4933 - accuracy: 0.7583 - val_loss: 0.5943 - val_accuracy: 0.6727\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.4893 - accuracy: 0.7619 - val_loss: 0.5768 - val_accuracy: 0.6828\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 711us/step - loss: 0.4871 - accuracy: 0.7637 - val_loss: 0.5928 - val_accuracy: 0.6732\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.4838 - accuracy: 0.7656 - val_loss: 0.5776 - val_accuracy: 0.6856\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.4803 - accuracy: 0.7681 - val_loss: 0.5933 - val_accuracy: 0.6740\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.4787 - accuracy: 0.7677 - val_loss: 0.5597 - val_accuracy: 0.7016\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.4751 - accuracy: 0.7724 - val_loss: 0.5901 - val_accuracy: 0.6783\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.4717 - accuracy: 0.7744 - val_loss: 0.5464 - val_accuracy: 0.7160\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.4693 - accuracy: 0.7757 - val_loss: 0.5679 - val_accuracy: 0.6967\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.4660 - accuracy: 0.7786 - val_loss: 0.5463 - val_accuracy: 0.7162\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.4615 - accuracy: 0.7797 - val_loss: 0.6144 - val_accuracy: 0.6619\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.5587 - val_accuracy: 0.7063\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.4544 - accuracy: 0.7849 - val_loss: 0.5568 - val_accuracy: 0.7082\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.5646 - val_accuracy: 0.7033\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 730us/step - loss: 0.4478 - accuracy: 0.7916 - val_loss: 0.5467 - val_accuracy: 0.7213\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.4436 - accuracy: 0.7943 - val_loss: 0.5759 - val_accuracy: 0.6973\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 672us/step - loss: 0.4405 - accuracy: 0.7949 - val_loss: 0.5455 - val_accuracy: 0.7234\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.4356 - accuracy: 0.7987 - val_loss: 0.5320 - val_accuracy: 0.7390\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.4319 - accuracy: 0.8033 - val_loss: 0.5644 - val_accuracy: 0.7089\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.4298 - accuracy: 0.8040 - val_loss: 0.5421 - val_accuracy: 0.7311\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.4247 - accuracy: 0.8072 - val_loss: 0.5507 - val_accuracy: 0.7234\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.4200 - accuracy: 0.8106 - val_loss: 0.5346 - val_accuracy: 0.7418\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.4165 - accuracy: 0.8130 - val_loss: 0.5611 - val_accuracy: 0.7180\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.4126 - accuracy: 0.8159 - val_loss: 0.5226 - val_accuracy: 0.7538\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 719us/step - loss: 0.4072 - accuracy: 0.8207 - val_loss: 0.5111 - val_accuracy: 0.7626\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6839 - accuracy: 0.5779 - val_loss: 0.7147 - val_accuracy: 0.4290\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6488 - accuracy: 0.6437 - val_loss: 0.6898 - val_accuracy: 0.5328\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 733us/step - loss: 0.6295 - accuracy: 0.6624 - val_loss: 0.6658 - val_accuracy: 0.5879\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 800us/step - loss: 0.6172 - accuracy: 0.6698 - val_loss: 0.6531 - val_accuracy: 0.6062\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6044 - accuracy: 0.6800 - val_loss: 0.6305 - val_accuracy: 0.6329\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 687us/step - loss: 0.5956 - accuracy: 0.6874 - val_loss: 0.6358 - val_accuracy: 0.6260\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.5869 - accuracy: 0.6939 - val_loss: 0.6224 - val_accuracy: 0.6394\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.5796 - accuracy: 0.7004 - val_loss: 0.6121 - val_accuracy: 0.6472\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.5730 - accuracy: 0.7056 - val_loss: 0.6240 - val_accuracy: 0.6370\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.5665 - accuracy: 0.7082 - val_loss: 0.6185 - val_accuracy: 0.6412\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.5615 - accuracy: 0.7124 - val_loss: 0.6019 - val_accuracy: 0.6533\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 667us/step - loss: 0.5576 - accuracy: 0.7157 - val_loss: 0.6219 - val_accuracy: 0.6367\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.5525 - accuracy: 0.7185 - val_loss: 0.6172 - val_accuracy: 0.6396\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.5484 - accuracy: 0.7207 - val_loss: 0.6370 - val_accuracy: 0.6246\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.5448 - accuracy: 0.7235 - val_loss: 0.6387 - val_accuracy: 0.6229\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.5408 - accuracy: 0.7249 - val_loss: 0.6014 - val_accuracy: 0.6503\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.5377 - accuracy: 0.7278 - val_loss: 0.5978 - val_accuracy: 0.6521\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 720us/step - loss: 0.5344 - accuracy: 0.7294 - val_loss: 0.6037 - val_accuracy: 0.6479\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.5310 - accuracy: 0.7315 - val_loss: 0.6302 - val_accuracy: 0.6315\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.5274 - accuracy: 0.7324 - val_loss: 0.6204 - val_accuracy: 0.6381\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.5262 - accuracy: 0.7354 - val_loss: 0.6165 - val_accuracy: 0.6410\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 676us/step - loss: 0.5222 - accuracy: 0.7374 - val_loss: 0.5911 - val_accuracy: 0.6597\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.5201 - accuracy: 0.7399 - val_loss: 0.5987 - val_accuracy: 0.6551\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.5176 - accuracy: 0.7395 - val_loss: 0.6338 - val_accuracy: 0.6335\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.5141 - accuracy: 0.7430 - val_loss: 0.6077 - val_accuracy: 0.6490\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.5110 - accuracy: 0.7441 - val_loss: 0.6189 - val_accuracy: 0.6415\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.5079 - accuracy: 0.7454 - val_loss: 0.6029 - val_accuracy: 0.6562\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.5061 - accuracy: 0.7478 - val_loss: 0.5853 - val_accuracy: 0.6708\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 733us/step - loss: 0.5031 - accuracy: 0.7480 - val_loss: 0.6113 - val_accuracy: 0.6514\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.5007 - accuracy: 0.7504 - val_loss: 0.5877 - val_accuracy: 0.6708\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.4987 - accuracy: 0.7529 - val_loss: 0.5959 - val_accuracy: 0.6652\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.4952 - accuracy: 0.7544 - val_loss: 0.5729 - val_accuracy: 0.6849\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.4926 - accuracy: 0.7565 - val_loss: 0.5762 - val_accuracy: 0.6837\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.4897 - accuracy: 0.7607 - val_loss: 0.5904 - val_accuracy: 0.6716\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.4872 - accuracy: 0.7602 - val_loss: 0.5723 - val_accuracy: 0.6890\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 667us/step - loss: 0.4847 - accuracy: 0.7622 - val_loss: 0.5996 - val_accuracy: 0.6670\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.4798 - accuracy: 0.7663 - val_loss: 0.5658 - val_accuracy: 0.6965\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.4777 - accuracy: 0.7665 - val_loss: 0.6027 - val_accuracy: 0.6653\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 721us/step - loss: 0.4746 - accuracy: 0.7716 - val_loss: 0.6175 - val_accuracy: 0.6555\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.4719 - accuracy: 0.7702 - val_loss: 0.5898 - val_accuracy: 0.6801\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.4685 - accuracy: 0.7742 - val_loss: 0.5935 - val_accuracy: 0.6768\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.4655 - accuracy: 0.7771 - val_loss: 0.5633 - val_accuracy: 0.7052\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.4624 - accuracy: 0.7786 - val_loss: 0.5960 - val_accuracy: 0.6767\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.4587 - accuracy: 0.7817 - val_loss: 0.5633 - val_accuracy: 0.7085\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.4548 - accuracy: 0.7852 - val_loss: 0.5726 - val_accuracy: 0.7023\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 675us/step - loss: 0.4523 - accuracy: 0.7864 - val_loss: 0.5628 - val_accuracy: 0.7130\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.4473 - accuracy: 0.7914 - val_loss: 0.5495 - val_accuracy: 0.7270\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.4438 - accuracy: 0.7935 - val_loss: 0.5656 - val_accuracy: 0.7116\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.4401 - accuracy: 0.7967 - val_loss: 0.5461 - val_accuracy: 0.7331\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.4361 - accuracy: 0.7996 - val_loss: 0.5445 - val_accuracy: 0.7360\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.7305 - accuracy: 0.4806 - val_loss: 0.7038 - val_accuracy: 0.4829\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.6917 - accuracy: 0.5428 - val_loss: 0.7056 - val_accuracy: 0.5055\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 678us/step - loss: 0.6722 - accuracy: 0.5949 - val_loss: 0.6776 - val_accuracy: 0.5919\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 753us/step - loss: 0.6564 - accuracy: 0.6301 - val_loss: 0.6590 - val_accuracy: 0.6204\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6428 - accuracy: 0.6528 - val_loss: 0.6469 - val_accuracy: 0.6315\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6304 - accuracy: 0.6706 - val_loss: 0.6626 - val_accuracy: 0.6077\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 746us/step - loss: 0.6202 - accuracy: 0.6809 - val_loss: 0.6414 - val_accuracy: 0.6277\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.6098 - accuracy: 0.6881 - val_loss: 0.6210 - val_accuracy: 0.6492\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6014 - accuracy: 0.6938 - val_loss: 0.6332 - val_accuracy: 0.6289\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 736us/step - loss: 0.5934 - accuracy: 0.7004 - val_loss: 0.6230 - val_accuracy: 0.6349\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.5861 - accuracy: 0.7074 - val_loss: 0.6403 - val_accuracy: 0.6176\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.5799 - accuracy: 0.7097 - val_loss: 0.6243 - val_accuracy: 0.6342\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.5741 - accuracy: 0.7140 - val_loss: 0.6092 - val_accuracy: 0.6493\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.5694 - accuracy: 0.7149 - val_loss: 0.6051 - val_accuracy: 0.6538\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.5637 - accuracy: 0.7176 - val_loss: 0.6105 - val_accuracy: 0.6470\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.5583 - accuracy: 0.7203 - val_loss: 0.6084 - val_accuracy: 0.6488\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 671us/step - loss: 0.5545 - accuracy: 0.7214 - val_loss: 0.5910 - val_accuracy: 0.6618\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.5498 - accuracy: 0.7250 - val_loss: 0.6072 - val_accuracy: 0.6513\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.5461 - accuracy: 0.7260 - val_loss: 0.5895 - val_accuracy: 0.6632\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.5433 - accuracy: 0.7268 - val_loss: 0.6182 - val_accuracy: 0.6409\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 683us/step - loss: 0.5394 - accuracy: 0.7300 - val_loss: 0.6097 - val_accuracy: 0.6466\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.5356 - accuracy: 0.7301 - val_loss: 0.6026 - val_accuracy: 0.6514\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 804us/step - loss: 0.5324 - accuracy: 0.7330 - val_loss: 0.5887 - val_accuracy: 0.6628\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.5296 - accuracy: 0.7352 - val_loss: 0.5990 - val_accuracy: 0.6555\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.5258 - accuracy: 0.7372 - val_loss: 0.6221 - val_accuracy: 0.6356\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.5238 - accuracy: 0.7371 - val_loss: 0.6164 - val_accuracy: 0.6406\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 588us/step - loss: 0.5199 - accuracy: 0.7406 - val_loss: 0.6111 - val_accuracy: 0.6449\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 681us/step - loss: 0.5165 - accuracy: 0.7431 - val_loss: 0.5958 - val_accuracy: 0.6592\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.5135 - accuracy: 0.7447 - val_loss: 0.5870 - val_accuracy: 0.6635\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 601us/step - loss: 0.5103 - accuracy: 0.7456 - val_loss: 0.5834 - val_accuracy: 0.6659\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.5080 - accuracy: 0.7477 - val_loss: 0.5803 - val_accuracy: 0.6694\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.5060 - accuracy: 0.7477 - val_loss: 0.5892 - val_accuracy: 0.6622\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.5022 - accuracy: 0.7516 - val_loss: 0.5760 - val_accuracy: 0.6750\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.5004 - accuracy: 0.7529 - val_loss: 0.5857 - val_accuracy: 0.6670\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.4972 - accuracy: 0.7550 - val_loss: 0.5948 - val_accuracy: 0.6602\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.4941 - accuracy: 0.7561 - val_loss: 0.5801 - val_accuracy: 0.6711\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.4901 - accuracy: 0.7610 - val_loss: 0.6066 - val_accuracy: 0.6520\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.4885 - accuracy: 0.7608 - val_loss: 0.5759 - val_accuracy: 0.6757\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 574us/step - loss: 0.4835 - accuracy: 0.7639 - val_loss: 0.5976 - val_accuracy: 0.6584\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.4825 - accuracy: 0.7642 - val_loss: 0.5954 - val_accuracy: 0.6617\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.4778 - accuracy: 0.7682 - val_loss: 0.5836 - val_accuracy: 0.6719\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 621us/step - loss: 0.4743 - accuracy: 0.7711 - val_loss: 0.5685 - val_accuracy: 0.6844\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 599us/step - loss: 0.4714 - accuracy: 0.7730 - val_loss: 0.5752 - val_accuracy: 0.6806\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.4694 - accuracy: 0.7757 - val_loss: 0.5967 - val_accuracy: 0.6635\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.4653 - accuracy: 0.7769 - val_loss: 0.5764 - val_accuracy: 0.6824\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.4617 - accuracy: 0.7801 - val_loss: 0.5840 - val_accuracy: 0.6763\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.4589 - accuracy: 0.7819 - val_loss: 0.5817 - val_accuracy: 0.6793\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.4551 - accuracy: 0.7846 - val_loss: 0.5655 - val_accuracy: 0.6930\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.4512 - accuracy: 0.7872 - val_loss: 0.5335 - val_accuracy: 0.7217\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.4479 - accuracy: 0.7901 - val_loss: 0.5427 - val_accuracy: 0.7136\n",
      "\n",
      "Training model with batch_size=128...\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.1 iterated over 20900 steps satisfies differential privacy with eps = 2.01 and delta = 1e-05.\n",
      "The optimal RDP order is 12.0.\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 912us/step - loss: 0.7098 - accuracy: 0.5015 - val_loss: 0.7271 - val_accuracy: 0.3262\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.6926 - accuracy: 0.5361 - val_loss: 0.7071 - val_accuracy: 0.4511\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 763us/step - loss: 0.6795 - accuracy: 0.5644 - val_loss: 0.6990 - val_accuracy: 0.5061\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 829us/step - loss: 0.6671 - accuracy: 0.5924 - val_loss: 0.6977 - val_accuracy: 0.5220\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 786us/step - loss: 0.6599 - accuracy: 0.6087 - val_loss: 0.6743 - val_accuracy: 0.5785\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 739us/step - loss: 0.6506 - accuracy: 0.6231 - val_loss: 0.6824 - val_accuracy: 0.5612\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 892us/step - loss: 0.6437 - accuracy: 0.6355 - val_loss: 0.6695 - val_accuracy: 0.5861\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 737us/step - loss: 0.6368 - accuracy: 0.6487 - val_loss: 0.6736 - val_accuracy: 0.5760\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 893us/step - loss: 0.6297 - accuracy: 0.6559 - val_loss: 0.6617 - val_accuracy: 0.5959\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 735us/step - loss: 0.6249 - accuracy: 0.6616 - val_loss: 0.6535 - val_accuracy: 0.6073\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 887us/step - loss: 0.6179 - accuracy: 0.6685 - val_loss: 0.6476 - val_accuracy: 0.6115\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 744us/step - loss: 0.6114 - accuracy: 0.6741 - val_loss: 0.6379 - val_accuracy: 0.6222\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 892us/step - loss: 0.6058 - accuracy: 0.6804 - val_loss: 0.6401 - val_accuracy: 0.6166\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 734us/step - loss: 0.5990 - accuracy: 0.6843 - val_loss: 0.6399 - val_accuracy: 0.6173\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 881us/step - loss: 0.5945 - accuracy: 0.6879 - val_loss: 0.6331 - val_accuracy: 0.6259\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 736us/step - loss: 0.5889 - accuracy: 0.6918 - val_loss: 0.6419 - val_accuracy: 0.6152\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 873us/step - loss: 0.5843 - accuracy: 0.6966 - val_loss: 0.6488 - val_accuracy: 0.6099\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 746us/step - loss: 0.5801 - accuracy: 0.7004 - val_loss: 0.6355 - val_accuracy: 0.6213\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 884us/step - loss: 0.5752 - accuracy: 0.7035 - val_loss: 0.6391 - val_accuracy: 0.6186\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 745us/step - loss: 0.5728 - accuracy: 0.7060 - val_loss: 0.6057 - val_accuracy: 0.6468\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 810us/step - loss: 0.5690 - accuracy: 0.7077 - val_loss: 0.6249 - val_accuracy: 0.6272\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 788us/step - loss: 0.5653 - accuracy: 0.7102 - val_loss: 0.6252 - val_accuracy: 0.6269\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 726us/step - loss: 0.5629 - accuracy: 0.7108 - val_loss: 0.6253 - val_accuracy: 0.6271\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 889us/step - loss: 0.5587 - accuracy: 0.7149 - val_loss: 0.6127 - val_accuracy: 0.6373\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 862us/step - loss: 0.5570 - accuracy: 0.7149 - val_loss: 0.6214 - val_accuracy: 0.6301\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 758us/step - loss: 0.5540 - accuracy: 0.7185 - val_loss: 0.6255 - val_accuracy: 0.6272\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 729us/step - loss: 0.5518 - accuracy: 0.7164 - val_loss: 0.6034 - val_accuracy: 0.6435\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.7212 - val_loss: 0.6173 - val_accuracy: 0.6340\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 966us/step - loss: 0.5460 - accuracy: 0.7221 - val_loss: 0.6146 - val_accuracy: 0.6362\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 897us/step - loss: 0.5449 - accuracy: 0.7222 - val_loss: 0.6289 - val_accuracy: 0.6286\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 740us/step - loss: 0.5422 - accuracy: 0.7225 - val_loss: 0.6118 - val_accuracy: 0.6404\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 869us/step - loss: 0.5401 - accuracy: 0.7252 - val_loss: 0.6170 - val_accuracy: 0.6380\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 747us/step - loss: 0.5383 - accuracy: 0.7263 - val_loss: 0.6217 - val_accuracy: 0.6349\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 726us/step - loss: 0.5366 - accuracy: 0.7272 - val_loss: 0.6109 - val_accuracy: 0.6427\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.5349 - accuracy: 0.7282 - val_loss: 0.6064 - val_accuracy: 0.6453\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 729us/step - loss: 0.5331 - accuracy: 0.7293 - val_loss: 0.6006 - val_accuracy: 0.6512\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 870us/step - loss: 0.5318 - accuracy: 0.7283 - val_loss: 0.6117 - val_accuracy: 0.6439\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 735us/step - loss: 0.5304 - accuracy: 0.7311 - val_loss: 0.6113 - val_accuracy: 0.6438\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 897us/step - loss: 0.5282 - accuracy: 0.7319 - val_loss: 0.6143 - val_accuracy: 0.6427\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 778us/step - loss: 0.5269 - accuracy: 0.7319 - val_loss: 0.6104 - val_accuracy: 0.6470\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 861us/step - loss: 0.5248 - accuracy: 0.7334 - val_loss: 0.6076 - val_accuracy: 0.6506\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 715us/step - loss: 0.5237 - accuracy: 0.7341 - val_loss: 0.6294 - val_accuracy: 0.6351\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 909us/step - loss: 0.5220 - accuracy: 0.7368 - val_loss: 0.6044 - val_accuracy: 0.6545\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 714us/step - loss: 0.5202 - accuracy: 0.7363 - val_loss: 0.6213 - val_accuracy: 0.6431\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 865us/step - loss: 0.5195 - accuracy: 0.7381 - val_loss: 0.6048 - val_accuracy: 0.6564\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 740us/step - loss: 0.5174 - accuracy: 0.7379 - val_loss: 0.6071 - val_accuracy: 0.6548\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 888us/step - loss: 0.5165 - accuracy: 0.7383 - val_loss: 0.6111 - val_accuracy: 0.6516\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 742us/step - loss: 0.5159 - accuracy: 0.7388 - val_loss: 0.6098 - val_accuracy: 0.6548\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.5139 - accuracy: 0.7408 - val_loss: 0.6046 - val_accuracy: 0.6589\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 811us/step - loss: 0.5129 - accuracy: 0.7410 - val_loss: 0.6148 - val_accuracy: 0.6513\n",
      "Epoch 1/50\n",
      "407/418 [============================>.] - ETA: 0s - loss: 0.6975 - accuracy: 0.5317WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6973 - accuracy: 0.5320 - val_loss: 0.7078 - val_accuracy: 0.4681\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 750us/step - loss: 0.6786 - accuracy: 0.5667 - val_loss: 0.6934 - val_accuracy: 0.5325\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 698us/step - loss: 0.6652 - accuracy: 0.5925 - val_loss: 0.6857 - val_accuracy: 0.5629\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.6537 - accuracy: 0.6163 - val_loss: 0.6700 - val_accuracy: 0.5964\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 759us/step - loss: 0.6443 - accuracy: 0.6322 - val_loss: 0.6624 - val_accuracy: 0.6067\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 885us/step - loss: 0.6350 - accuracy: 0.6486 - val_loss: 0.6447 - val_accuracy: 0.6345\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 746us/step - loss: 0.6274 - accuracy: 0.6581 - val_loss: 0.6507 - val_accuracy: 0.6155\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6207 - accuracy: 0.6648 - val_loss: 0.6453 - val_accuracy: 0.6218\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 761us/step - loss: 0.6135 - accuracy: 0.6728 - val_loss: 0.6338 - val_accuracy: 0.6380\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.6084 - accuracy: 0.6776 - val_loss: 0.6417 - val_accuracy: 0.6229\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 771us/step - loss: 0.6032 - accuracy: 0.6864 - val_loss: 0.6369 - val_accuracy: 0.6268\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 732us/step - loss: 0.5984 - accuracy: 0.6883 - val_loss: 0.6365 - val_accuracy: 0.6219\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 873us/step - loss: 0.5939 - accuracy: 0.6941 - val_loss: 0.6305 - val_accuracy: 0.6268\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 740us/step - loss: 0.5887 - accuracy: 0.6986 - val_loss: 0.6135 - val_accuracy: 0.6478\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 885us/step - loss: 0.5847 - accuracy: 0.7023 - val_loss: 0.6089 - val_accuracy: 0.6487\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 725us/step - loss: 0.5821 - accuracy: 0.7027 - val_loss: 0.6047 - val_accuracy: 0.6511\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 886us/step - loss: 0.5781 - accuracy: 0.7079 - val_loss: 0.6131 - val_accuracy: 0.6377\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 738us/step - loss: 0.5743 - accuracy: 0.7092 - val_loss: 0.6230 - val_accuracy: 0.6250\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 874us/step - loss: 0.5702 - accuracy: 0.7149 - val_loss: 0.6110 - val_accuracy: 0.6362\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 737us/step - loss: 0.5672 - accuracy: 0.7162 - val_loss: 0.6009 - val_accuracy: 0.6469\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 867us/step - loss: 0.5646 - accuracy: 0.7172 - val_loss: 0.6187 - val_accuracy: 0.6263\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 762us/step - loss: 0.5624 - accuracy: 0.7176 - val_loss: 0.6120 - val_accuracy: 0.6325\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 731us/step - loss: 0.5595 - accuracy: 0.7194 - val_loss: 0.5900 - val_accuracy: 0.6613\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 893us/step - loss: 0.5567 - accuracy: 0.7215 - val_loss: 0.6146 - val_accuracy: 0.6287\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 734us/step - loss: 0.5537 - accuracy: 0.7216 - val_loss: 0.6065 - val_accuracy: 0.6384\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 884us/step - loss: 0.5522 - accuracy: 0.7234 - val_loss: 0.5959 - val_accuracy: 0.6506\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 740us/step - loss: 0.5482 - accuracy: 0.7259 - val_loss: 0.6098 - val_accuracy: 0.6332\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 886us/step - loss: 0.5475 - accuracy: 0.7266 - val_loss: 0.6063 - val_accuracy: 0.6386\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 743us/step - loss: 0.5447 - accuracy: 0.7286 - val_loss: 0.6180 - val_accuracy: 0.6257\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 876us/step - loss: 0.5437 - accuracy: 0.7261 - val_loss: 0.6027 - val_accuracy: 0.6436\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 748us/step - loss: 0.5404 - accuracy: 0.7301 - val_loss: 0.6165 - val_accuracy: 0.6294\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.5383 - accuracy: 0.7294 - val_loss: 0.5998 - val_accuracy: 0.6475\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.5369 - accuracy: 0.7306 - val_loss: 0.6198 - val_accuracy: 0.6261\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 915us/step - loss: 0.5358 - accuracy: 0.7312 - val_loss: 0.5861 - val_accuracy: 0.6607\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 748us/step - loss: 0.5334 - accuracy: 0.7314 - val_loss: 0.6138 - val_accuracy: 0.6343\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 892us/step - loss: 0.5317 - accuracy: 0.7320 - val_loss: 0.6067 - val_accuracy: 0.6413\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 743us/step - loss: 0.5306 - accuracy: 0.7336 - val_loss: 0.6098 - val_accuracy: 0.6386\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 995us/step - loss: 0.5295 - accuracy: 0.7333 - val_loss: 0.6044 - val_accuracy: 0.6418\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.5276 - accuracy: 0.7344 - val_loss: 0.6292 - val_accuracy: 0.6200\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 776us/step - loss: 0.5265 - accuracy: 0.7361 - val_loss: 0.6183 - val_accuracy: 0.6304\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 871us/step - loss: 0.5255 - accuracy: 0.7356 - val_loss: 0.6057 - val_accuracy: 0.6405\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 773us/step - loss: 0.5231 - accuracy: 0.7372 - val_loss: 0.6154 - val_accuracy: 0.6328\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 738us/step - loss: 0.5218 - accuracy: 0.7371 - val_loss: 0.5997 - val_accuracy: 0.6464\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.5215 - accuracy: 0.7377 - val_loss: 0.6080 - val_accuracy: 0.6394\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 763us/step - loss: 0.5194 - accuracy: 0.7394 - val_loss: 0.6023 - val_accuracy: 0.6443\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 726us/step - loss: 0.5176 - accuracy: 0.7412 - val_loss: 0.6046 - val_accuracy: 0.6425\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 885us/step - loss: 0.5162 - accuracy: 0.7394 - val_loss: 0.6024 - val_accuracy: 0.6461\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.5146 - accuracy: 0.7422 - val_loss: 0.6000 - val_accuracy: 0.6483\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 785us/step - loss: 0.5135 - accuracy: 0.7433 - val_loss: 0.5980 - val_accuracy: 0.6513\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 740us/step - loss: 0.5127 - accuracy: 0.7431 - val_loss: 0.6016 - val_accuracy: 0.6483\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 865us/step - loss: 0.7249 - accuracy: 0.5175 - val_loss: 0.7190 - val_accuracy: 0.3386\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 802us/step - loss: 0.6829 - accuracy: 0.5587 - val_loss: 0.7089 - val_accuracy: 0.4389\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 795us/step - loss: 0.6671 - accuracy: 0.6011 - val_loss: 0.6983 - val_accuracy: 0.5215\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 841us/step - loss: 0.6565 - accuracy: 0.6265 - val_loss: 0.6890 - val_accuracy: 0.5540\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 788us/step - loss: 0.6476 - accuracy: 0.6439 - val_loss: 0.6778 - val_accuracy: 0.5790\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 876us/step - loss: 0.6417 - accuracy: 0.6522 - val_loss: 0.6664 - val_accuracy: 0.6023\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 774us/step - loss: 0.6337 - accuracy: 0.6637 - val_loss: 0.6689 - val_accuracy: 0.5943\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 756us/step - loss: 0.6281 - accuracy: 0.6688 - val_loss: 0.6573 - val_accuracy: 0.6137\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 895us/step - loss: 0.6214 - accuracy: 0.6763 - val_loss: 0.6537 - val_accuracy: 0.6151\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 751us/step - loss: 0.6158 - accuracy: 0.6805 - val_loss: 0.6518 - val_accuracy: 0.6162\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 870us/step - loss: 0.6111 - accuracy: 0.6833 - val_loss: 0.6433 - val_accuracy: 0.6266\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 756us/step - loss: 0.6064 - accuracy: 0.6853 - val_loss: 0.6417 - val_accuracy: 0.6269\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 857us/step - loss: 0.6008 - accuracy: 0.6933 - val_loss: 0.6396 - val_accuracy: 0.6270\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 787us/step - loss: 0.5966 - accuracy: 0.6957 - val_loss: 0.6249 - val_accuracy: 0.6485\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.5914 - accuracy: 0.7024 - val_loss: 0.6276 - val_accuracy: 0.6424\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 774us/step - loss: 0.5877 - accuracy: 0.7011 - val_loss: 0.6256 - val_accuracy: 0.6462\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 730us/step - loss: 0.5837 - accuracy: 0.7032 - val_loss: 0.6223 - val_accuracy: 0.6498\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 893us/step - loss: 0.5804 - accuracy: 0.7071 - val_loss: 0.6169 - val_accuracy: 0.6552\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 731us/step - loss: 0.5772 - accuracy: 0.7101 - val_loss: 0.6208 - val_accuracy: 0.6509\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 923us/step - loss: 0.5738 - accuracy: 0.7103 - val_loss: 0.6113 - val_accuracy: 0.6600\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 722us/step - loss: 0.5704 - accuracy: 0.7133 - val_loss: 0.6188 - val_accuracy: 0.6530\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 886us/step - loss: 0.5673 - accuracy: 0.7148 - val_loss: 0.6069 - val_accuracy: 0.6640\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 727us/step - loss: 0.5630 - accuracy: 0.7170 - val_loss: 0.6250 - val_accuracy: 0.6480\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 824us/step - loss: 0.5601 - accuracy: 0.7190 - val_loss: 0.6178 - val_accuracy: 0.6543\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 743us/step - loss: 0.5579 - accuracy: 0.7182 - val_loss: 0.6203 - val_accuracy: 0.6527\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 871us/step - loss: 0.5565 - accuracy: 0.7199 - val_loss: 0.6102 - val_accuracy: 0.6627\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 735us/step - loss: 0.5538 - accuracy: 0.7211 - val_loss: 0.6190 - val_accuracy: 0.6530\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 811us/step - loss: 0.5510 - accuracy: 0.7225 - val_loss: 0.6002 - val_accuracy: 0.6722\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 783us/step - loss: 0.5489 - accuracy: 0.7239 - val_loss: 0.6107 - val_accuracy: 0.6617\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.5467 - accuracy: 0.7234 - val_loss: 0.6040 - val_accuracy: 0.6676\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 741us/step - loss: 0.5454 - accuracy: 0.7255 - val_loss: 0.6123 - val_accuracy: 0.6604\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 873us/step - loss: 0.5430 - accuracy: 0.7269 - val_loss: 0.6251 - val_accuracy: 0.6481\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 735us/step - loss: 0.5405 - accuracy: 0.7273 - val_loss: 0.6246 - val_accuracy: 0.6486\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 841us/step - loss: 0.5390 - accuracy: 0.7303 - val_loss: 0.6109 - val_accuracy: 0.6623\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 746us/step - loss: 0.5370 - accuracy: 0.7302 - val_loss: 0.6176 - val_accuracy: 0.6560\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 865us/step - loss: 0.5361 - accuracy: 0.7299 - val_loss: 0.6139 - val_accuracy: 0.6586\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 742us/step - loss: 0.5330 - accuracy: 0.7330 - val_loss: 0.6185 - val_accuracy: 0.6560\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.5313 - accuracy: 0.7330 - val_loss: 0.6068 - val_accuracy: 0.6642\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 748us/step - loss: 0.5293 - accuracy: 0.7320 - val_loss: 0.6097 - val_accuracy: 0.6621\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 869us/step - loss: 0.5275 - accuracy: 0.7349 - val_loss: 0.6096 - val_accuracy: 0.6625\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 742us/step - loss: 0.5264 - accuracy: 0.7359 - val_loss: 0.6037 - val_accuracy: 0.6663\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 869us/step - loss: 0.5251 - accuracy: 0.7356 - val_loss: 0.6282 - val_accuracy: 0.6514\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 740us/step - loss: 0.5232 - accuracy: 0.7376 - val_loss: 0.6172 - val_accuracy: 0.6596\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 896us/step - loss: 0.5220 - accuracy: 0.7364 - val_loss: 0.6046 - val_accuracy: 0.6665\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 994us/step - loss: 0.5208 - accuracy: 0.7381 - val_loss: 0.6107 - val_accuracy: 0.6627\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7382 - val_loss: 0.6149 - val_accuracy: 0.6612\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 776us/step - loss: 0.5182 - accuracy: 0.7405 - val_loss: 0.5942 - val_accuracy: 0.6742\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 721us/step - loss: 0.5165 - accuracy: 0.7423 - val_loss: 0.6211 - val_accuracy: 0.6568\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 880us/step - loss: 0.5157 - accuracy: 0.7422 - val_loss: 0.5945 - val_accuracy: 0.6743\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 733us/step - loss: 0.5139 - accuracy: 0.7434 - val_loss: 0.5902 - val_accuracy: 0.6775\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 814us/step - loss: 0.7111 - accuracy: 0.4945 - val_loss: 0.7074 - val_accuracy: 0.4182\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6881 - accuracy: 0.5386 - val_loss: 0.6943 - val_accuracy: 0.5158\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 717us/step - loss: 0.6771 - accuracy: 0.5709 - val_loss: 0.6855 - val_accuracy: 0.5547\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 869us/step - loss: 0.6666 - accuracy: 0.5953 - val_loss: 0.6804 - val_accuracy: 0.5713\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6586 - accuracy: 0.6103 - val_loss: 0.6677 - val_accuracy: 0.6008\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 740us/step - loss: 0.6512 - accuracy: 0.6222 - val_loss: 0.6564 - val_accuracy: 0.6239\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 798us/step - loss: 0.6433 - accuracy: 0.6318 - val_loss: 0.6423 - val_accuracy: 0.6450\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 770us/step - loss: 0.6377 - accuracy: 0.6405 - val_loss: 0.6442 - val_accuracy: 0.6378\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 704us/step - loss: 0.6318 - accuracy: 0.6443 - val_loss: 0.6410 - val_accuracy: 0.6418\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.6274 - accuracy: 0.6512 - val_loss: 0.6344 - val_accuracy: 0.6483\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 724us/step - loss: 0.6215 - accuracy: 0.6583 - val_loss: 0.6364 - val_accuracy: 0.6428\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 862us/step - loss: 0.6168 - accuracy: 0.6605 - val_loss: 0.6257 - val_accuracy: 0.6530\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 727us/step - loss: 0.6124 - accuracy: 0.6634 - val_loss: 0.6234 - val_accuracy: 0.6525\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.6084 - accuracy: 0.6661 - val_loss: 0.6156 - val_accuracy: 0.6595\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 717us/step - loss: 0.6035 - accuracy: 0.6697 - val_loss: 0.6204 - val_accuracy: 0.6518\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 871us/step - loss: 0.5978 - accuracy: 0.6761 - val_loss: 0.6181 - val_accuracy: 0.6528\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 722us/step - loss: 0.5954 - accuracy: 0.6804 - val_loss: 0.6128 - val_accuracy: 0.6576\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 851us/step - loss: 0.5911 - accuracy: 0.6832 - val_loss: 0.6135 - val_accuracy: 0.6569\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 782us/step - loss: 0.5890 - accuracy: 0.6839 - val_loss: 0.6105 - val_accuracy: 0.6597\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 925us/step - loss: 0.5839 - accuracy: 0.6896 - val_loss: 0.6102 - val_accuracy: 0.6583\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 725us/step - loss: 0.5807 - accuracy: 0.6926 - val_loss: 0.6007 - val_accuracy: 0.6657\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 864us/step - loss: 0.5774 - accuracy: 0.6974 - val_loss: 0.6021 - val_accuracy: 0.6619\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 815us/step - loss: 0.5736 - accuracy: 0.7003 - val_loss: 0.5982 - val_accuracy: 0.6653\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 773us/step - loss: 0.5709 - accuracy: 0.7040 - val_loss: 0.5974 - val_accuracy: 0.6664\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 801us/step - loss: 0.5675 - accuracy: 0.7100 - val_loss: 0.6003 - val_accuracy: 0.6619\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 757us/step - loss: 0.5646 - accuracy: 0.7138 - val_loss: 0.5932 - val_accuracy: 0.6697\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 709us/step - loss: 0.5615 - accuracy: 0.7175 - val_loss: 0.6000 - val_accuracy: 0.6596\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.5579 - accuracy: 0.7201 - val_loss: 0.5995 - val_accuracy: 0.6582\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 726us/step - loss: 0.5559 - accuracy: 0.7217 - val_loss: 0.6013 - val_accuracy: 0.6555\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 703us/step - loss: 0.5522 - accuracy: 0.7269 - val_loss: 0.5873 - val_accuracy: 0.6695\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.5499 - accuracy: 0.7296 - val_loss: 0.5996 - val_accuracy: 0.6554\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 721us/step - loss: 0.5464 - accuracy: 0.7280 - val_loss: 0.5866 - val_accuracy: 0.6696\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.5437 - accuracy: 0.7330 - val_loss: 0.5822 - val_accuracy: 0.6736\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.5419 - accuracy: 0.7337 - val_loss: 0.5904 - val_accuracy: 0.6624\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.5386 - accuracy: 0.7353 - val_loss: 0.5918 - val_accuracy: 0.6593\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 872us/step - loss: 0.5364 - accuracy: 0.7353 - val_loss: 0.5868 - val_accuracy: 0.6639\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 889us/step - loss: 0.5343 - accuracy: 0.7380 - val_loss: 0.5869 - val_accuracy: 0.6623\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 695us/step - loss: 0.5318 - accuracy: 0.7404 - val_loss: 0.5895 - val_accuracy: 0.6597\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.5295 - accuracy: 0.7416 - val_loss: 0.5715 - val_accuracy: 0.6807\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 809us/step - loss: 0.5270 - accuracy: 0.7439 - val_loss: 0.5836 - val_accuracy: 0.6646\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 781us/step - loss: 0.5246 - accuracy: 0.7446 - val_loss: 0.5907 - val_accuracy: 0.6583\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.5230 - accuracy: 0.7448 - val_loss: 0.5800 - val_accuracy: 0.6690\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 724us/step - loss: 0.5223 - accuracy: 0.7443 - val_loss: 0.6026 - val_accuracy: 0.6481\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.5197 - accuracy: 0.7468 - val_loss: 0.5741 - val_accuracy: 0.6751\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 719us/step - loss: 0.5169 - accuracy: 0.7486 - val_loss: 0.5964 - val_accuracy: 0.6531\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.5153 - accuracy: 0.7478 - val_loss: 0.5832 - val_accuracy: 0.6668\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 724us/step - loss: 0.5139 - accuracy: 0.7497 - val_loss: 0.5789 - val_accuracy: 0.6698\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.5127 - accuracy: 0.7507 - val_loss: 0.5752 - val_accuracy: 0.6736\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 725us/step - loss: 0.5098 - accuracy: 0.7521 - val_loss: 0.5926 - val_accuracy: 0.6571\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.5094 - accuracy: 0.7514 - val_loss: 0.5870 - val_accuracy: 0.6622\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 916us/step - loss: 0.6962 - accuracy: 0.5397 - val_loss: 0.6949 - val_accuracy: 0.5179\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 727us/step - loss: 0.6745 - accuracy: 0.5792 - val_loss: 0.6709 - val_accuracy: 0.5986\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 703us/step - loss: 0.6602 - accuracy: 0.6113 - val_loss: 0.6724 - val_accuracy: 0.5806\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.6476 - accuracy: 0.6379 - val_loss: 0.6649 - val_accuracy: 0.6004\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 801us/step - loss: 0.6389 - accuracy: 0.6494 - val_loss: 0.6567 - val_accuracy: 0.6152\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 767us/step - loss: 0.6312 - accuracy: 0.6621 - val_loss: 0.6475 - val_accuracy: 0.6266\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 707us/step - loss: 0.6241 - accuracy: 0.6682 - val_loss: 0.6364 - val_accuracy: 0.6409\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 860us/step - loss: 0.6168 - accuracy: 0.6791 - val_loss: 0.6379 - val_accuracy: 0.6342\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 710us/step - loss: 0.6116 - accuracy: 0.6830 - val_loss: 0.6215 - val_accuracy: 0.6565\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.6068 - accuracy: 0.6893 - val_loss: 0.6223 - val_accuracy: 0.6520\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6023 - accuracy: 0.6922 - val_loss: 0.6270 - val_accuracy: 0.6430\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 729us/step - loss: 0.5984 - accuracy: 0.6926 - val_loss: 0.6185 - val_accuracy: 0.6529\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 841us/step - loss: 0.5943 - accuracy: 0.6989 - val_loss: 0.6236 - val_accuracy: 0.6451\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 720us/step - loss: 0.5896 - accuracy: 0.7034 - val_loss: 0.6209 - val_accuracy: 0.6464\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.5861 - accuracy: 0.7048 - val_loss: 0.6123 - val_accuracy: 0.6549\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 720us/step - loss: 0.5839 - accuracy: 0.7046 - val_loss: 0.6263 - val_accuracy: 0.6399\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 870us/step - loss: 0.5803 - accuracy: 0.7082 - val_loss: 0.5943 - val_accuracy: 0.6684\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 795us/step - loss: 0.5769 - accuracy: 0.7119 - val_loss: 0.6082 - val_accuracy: 0.6568\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 765us/step - loss: 0.5737 - accuracy: 0.7135 - val_loss: 0.6128 - val_accuracy: 0.6511\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 711us/step - loss: 0.5715 - accuracy: 0.7142 - val_loss: 0.6033 - val_accuracy: 0.6561\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.5679 - accuracy: 0.7174 - val_loss: 0.6020 - val_accuracy: 0.6566\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 711us/step - loss: 0.5652 - accuracy: 0.7181 - val_loss: 0.6187 - val_accuracy: 0.6405\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.5626 - accuracy: 0.7193 - val_loss: 0.6158 - val_accuracy: 0.6425\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 708us/step - loss: 0.5611 - accuracy: 0.7202 - val_loss: 0.5958 - val_accuracy: 0.6585\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 864us/step - loss: 0.5574 - accuracy: 0.7221 - val_loss: 0.6054 - val_accuracy: 0.6502\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 715us/step - loss: 0.5556 - accuracy: 0.7224 - val_loss: 0.5955 - val_accuracy: 0.6590\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.5533 - accuracy: 0.7233 - val_loss: 0.5949 - val_accuracy: 0.6585\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.5505 - accuracy: 0.7263 - val_loss: 0.6060 - val_accuracy: 0.6480\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 736us/step - loss: 0.5493 - accuracy: 0.7257 - val_loss: 0.6161 - val_accuracy: 0.6359\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.5476 - accuracy: 0.7264 - val_loss: 0.6016 - val_accuracy: 0.6508\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 720us/step - loss: 0.5450 - accuracy: 0.7287 - val_loss: 0.5986 - val_accuracy: 0.6529\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 851us/step - loss: 0.5434 - accuracy: 0.7284 - val_loss: 0.6091 - val_accuracy: 0.6422\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 722us/step - loss: 0.5414 - accuracy: 0.7299 - val_loss: 0.5975 - val_accuracy: 0.6528\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 843us/step - loss: 0.5401 - accuracy: 0.7324 - val_loss: 0.5887 - val_accuracy: 0.6585\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 707us/step - loss: 0.5374 - accuracy: 0.7336 - val_loss: 0.6049 - val_accuracy: 0.6438\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.5357 - accuracy: 0.7341 - val_loss: 0.5966 - val_accuracy: 0.6503\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 697us/step - loss: 0.5338 - accuracy: 0.7345 - val_loss: 0.6025 - val_accuracy: 0.6443\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.5311 - accuracy: 0.7369 - val_loss: 0.6028 - val_accuracy: 0.6438\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.5306 - accuracy: 0.7372 - val_loss: 0.5912 - val_accuracy: 0.6534\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 734us/step - loss: 0.5282 - accuracy: 0.7376 - val_loss: 0.5953 - val_accuracy: 0.6501\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 707us/step - loss: 0.5270 - accuracy: 0.7386 - val_loss: 0.6040 - val_accuracy: 0.6429\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.5251 - accuracy: 0.7396 - val_loss: 0.5896 - val_accuracy: 0.6541\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 713us/step - loss: 0.5236 - accuracy: 0.7415 - val_loss: 0.6003 - val_accuracy: 0.6464\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.5223 - accuracy: 0.7419 - val_loss: 0.5970 - val_accuracy: 0.6483\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 710us/step - loss: 0.5210 - accuracy: 0.7409 - val_loss: 0.6012 - val_accuracy: 0.6462\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 843us/step - loss: 0.5189 - accuracy: 0.7424 - val_loss: 0.5984 - val_accuracy: 0.6475\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 725us/step - loss: 0.5171 - accuracy: 0.7458 - val_loss: 0.5799 - val_accuracy: 0.6642\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 824us/step - loss: 0.5163 - accuracy: 0.7438 - val_loss: 0.5828 - val_accuracy: 0.6612\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 732us/step - loss: 0.5138 - accuracy: 0.7466 - val_loss: 0.5950 - val_accuracy: 0.6511\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.5135 - accuracy: 0.7453 - val_loss: 0.5758 - val_accuracy: 0.6689\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 794us/step - loss: 0.7182 - accuracy: 0.4842 - val_loss: 0.7186 - val_accuracy: 0.3137\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 823us/step - loss: 0.6958 - accuracy: 0.5353 - val_loss: 0.7133 - val_accuracy: 0.3891\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 800us/step - loss: 0.6800 - accuracy: 0.5698 - val_loss: 0.7045 - val_accuracy: 0.4792\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 750us/step - loss: 0.6669 - accuracy: 0.6058 - val_loss: 0.6890 - val_accuracy: 0.5508\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 711us/step - loss: 0.6579 - accuracy: 0.6223 - val_loss: 0.6788 - val_accuracy: 0.5734\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 861us/step - loss: 0.6500 - accuracy: 0.6370 - val_loss: 0.6645 - val_accuracy: 0.6036\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 783us/step - loss: 0.6424 - accuracy: 0.6485 - val_loss: 0.6686 - val_accuracy: 0.5929\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 993us/step - loss: 0.6347 - accuracy: 0.6557 - val_loss: 0.6583 - val_accuracy: 0.6063\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 910us/step - loss: 0.6283 - accuracy: 0.6640 - val_loss: 0.6467 - val_accuracy: 0.6258\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6229 - accuracy: 0.6695 - val_loss: 0.6481 - val_accuracy: 0.6164\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6175 - accuracy: 0.6745 - val_loss: 0.6427 - val_accuracy: 0.6245\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 962us/step - loss: 0.6115 - accuracy: 0.6770 - val_loss: 0.6363 - val_accuracy: 0.6319\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6070 - accuracy: 0.6803 - val_loss: 0.6303 - val_accuracy: 0.6335\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6025 - accuracy: 0.6863 - val_loss: 0.6346 - val_accuracy: 0.6294\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.6910 - val_loss: 0.6272 - val_accuracy: 0.6330\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 789us/step - loss: 0.5942 - accuracy: 0.6941 - val_loss: 0.6294 - val_accuracy: 0.6284\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 902us/step - loss: 0.5904 - accuracy: 0.6938 - val_loss: 0.6281 - val_accuracy: 0.6273\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.5866 - accuracy: 0.6988 - val_loss: 0.6184 - val_accuracy: 0.6346\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.5827 - accuracy: 0.7019 - val_loss: 0.6158 - val_accuracy: 0.6378\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.5794 - accuracy: 0.7037 - val_loss: 0.6169 - val_accuracy: 0.6372\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 888us/step - loss: 0.5757 - accuracy: 0.7087 - val_loss: 0.6078 - val_accuracy: 0.6459\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.5727 - accuracy: 0.7086 - val_loss: 0.6123 - val_accuracy: 0.6419\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 943us/step - loss: 0.5706 - accuracy: 0.7104 - val_loss: 0.6037 - val_accuracy: 0.6482\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.5677 - accuracy: 0.7121 - val_loss: 0.6120 - val_accuracy: 0.6403\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.5643 - accuracy: 0.7146 - val_loss: 0.6085 - val_accuracy: 0.6426\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 800us/step - loss: 0.5623 - accuracy: 0.7145 - val_loss: 0.6111 - val_accuracy: 0.6406\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 903us/step - loss: 0.5591 - accuracy: 0.7168 - val_loss: 0.6084 - val_accuracy: 0.6444\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 927us/step - loss: 0.5570 - accuracy: 0.7194 - val_loss: 0.6176 - val_accuracy: 0.6354\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.5541 - accuracy: 0.7197 - val_loss: 0.6000 - val_accuracy: 0.6516\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 786us/step - loss: 0.5521 - accuracy: 0.7220 - val_loss: 0.6025 - val_accuracy: 0.6498\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 941us/step - loss: 0.5496 - accuracy: 0.7237 - val_loss: 0.6005 - val_accuracy: 0.6522\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 799us/step - loss: 0.5473 - accuracy: 0.7256 - val_loss: 0.5965 - val_accuracy: 0.6560\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 923us/step - loss: 0.5459 - accuracy: 0.7245 - val_loss: 0.6067 - val_accuracy: 0.6489\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 807us/step - loss: 0.5441 - accuracy: 0.7253 - val_loss: 0.6093 - val_accuracy: 0.6479\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 942us/step - loss: 0.5418 - accuracy: 0.7288 - val_loss: 0.6110 - val_accuracy: 0.6493\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 799us/step - loss: 0.5405 - accuracy: 0.7283 - val_loss: 0.6195 - val_accuracy: 0.6417\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5377 - accuracy: 0.7295 - val_loss: 0.6119 - val_accuracy: 0.6482\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 794us/step - loss: 0.5360 - accuracy: 0.7313 - val_loss: 0.6090 - val_accuracy: 0.6502\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 958us/step - loss: 0.5341 - accuracy: 0.7300 - val_loss: 0.6061 - val_accuracy: 0.6525\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.5322 - accuracy: 0.7311 - val_loss: 0.6039 - val_accuracy: 0.6548\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7328 - val_loss: 0.6032 - val_accuracy: 0.6560\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7356 - val_loss: 0.5992 - val_accuracy: 0.6582\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.7361 - val_loss: 0.6086 - val_accuracy: 0.6511\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 808us/step - loss: 0.5252 - accuracy: 0.7376 - val_loss: 0.5885 - val_accuracy: 0.6639\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 998us/step - loss: 0.5238 - accuracy: 0.7368 - val_loss: 0.5918 - val_accuracy: 0.6622\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 898us/step - loss: 0.5220 - accuracy: 0.7407 - val_loss: 0.6211 - val_accuracy: 0.6417\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 831us/step - loss: 0.5203 - accuracy: 0.7394 - val_loss: 0.6052 - val_accuracy: 0.6532\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 806us/step - loss: 0.5178 - accuracy: 0.7418 - val_loss: 0.5919 - val_accuracy: 0.6617\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.5163 - accuracy: 0.7417 - val_loss: 0.6043 - val_accuracy: 0.6547\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 753us/step - loss: 0.5149 - accuracy: 0.7442 - val_loss: 0.5898 - val_accuracy: 0.6636\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.4816 - val_loss: 0.7198 - val_accuracy: 0.2917\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6908 - accuracy: 0.5341 - val_loss: 0.6931 - val_accuracy: 0.5149\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 939us/step - loss: 0.6745 - accuracy: 0.5823 - val_loss: 0.6793 - val_accuracy: 0.5963\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 810us/step - loss: 0.6631 - accuracy: 0.6129 - val_loss: 0.6762 - val_accuracy: 0.6017\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 939us/step - loss: 0.6533 - accuracy: 0.6344 - val_loss: 0.6656 - val_accuracy: 0.6238\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 925us/step - loss: 0.6453 - accuracy: 0.6476 - val_loss: 0.6572 - val_accuracy: 0.6362\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6378 - accuracy: 0.6576 - val_loss: 0.6568 - val_accuracy: 0.6292\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 919us/step - loss: 0.6304 - accuracy: 0.6637 - val_loss: 0.6454 - val_accuracy: 0.6417\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 792us/step - loss: 0.6242 - accuracy: 0.6700 - val_loss: 0.6443 - val_accuracy: 0.6373\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6169 - accuracy: 0.6778 - val_loss: 0.6315 - val_accuracy: 0.6521\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 801us/step - loss: 0.6123 - accuracy: 0.6793 - val_loss: 0.6414 - val_accuracy: 0.6334\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 967us/step - loss: 0.6069 - accuracy: 0.6865 - val_loss: 0.6371 - val_accuracy: 0.6339\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.6015 - accuracy: 0.6909 - val_loss: 0.6229 - val_accuracy: 0.6518\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.5967 - accuracy: 0.6939 - val_loss: 0.6261 - val_accuracy: 0.6434\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 922us/step - loss: 0.5933 - accuracy: 0.6962 - val_loss: 0.6141 - val_accuracy: 0.6563\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 813us/step - loss: 0.5885 - accuracy: 0.7008 - val_loss: 0.6264 - val_accuracy: 0.6398\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 903us/step - loss: 0.5847 - accuracy: 0.7034 - val_loss: 0.6058 - val_accuracy: 0.6593\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 816us/step - loss: 0.5807 - accuracy: 0.7079 - val_loss: 0.6116 - val_accuracy: 0.6528\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 874us/step - loss: 0.5771 - accuracy: 0.7093 - val_loss: 0.6111 - val_accuracy: 0.6519\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.5729 - accuracy: 0.7133 - val_loss: 0.6196 - val_accuracy: 0.6445\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 941us/step - loss: 0.5704 - accuracy: 0.7137 - val_loss: 0.6090 - val_accuracy: 0.6571\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 918us/step - loss: 0.5678 - accuracy: 0.7163 - val_loss: 0.6180 - val_accuracy: 0.6486\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.5644 - accuracy: 0.7183 - val_loss: 0.5940 - val_accuracy: 0.6702\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 939us/step - loss: 0.5614 - accuracy: 0.7204 - val_loss: 0.6054 - val_accuracy: 0.6602\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 781us/step - loss: 0.5582 - accuracy: 0.7233 - val_loss: 0.6043 - val_accuracy: 0.6600\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 917us/step - loss: 0.5564 - accuracy: 0.7206 - val_loss: 0.6019 - val_accuracy: 0.6621\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 811us/step - loss: 0.5544 - accuracy: 0.7230 - val_loss: 0.6097 - val_accuracy: 0.6544\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 950us/step - loss: 0.5509 - accuracy: 0.7259 - val_loss: 0.6091 - val_accuracy: 0.6549\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 893us/step - loss: 0.5483 - accuracy: 0.7271 - val_loss: 0.5769 - val_accuracy: 0.6827\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.5467 - accuracy: 0.7271 - val_loss: 0.5919 - val_accuracy: 0.6705\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.5440 - accuracy: 0.7290 - val_loss: 0.6047 - val_accuracy: 0.6586\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 968us/step - loss: 0.5412 - accuracy: 0.7301 - val_loss: 0.5985 - val_accuracy: 0.6649\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 798us/step - loss: 0.5382 - accuracy: 0.7324 - val_loss: 0.6188 - val_accuracy: 0.6499\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 920us/step - loss: 0.5374 - accuracy: 0.7336 - val_loss: 0.5865 - val_accuracy: 0.6728\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 942us/step - loss: 0.5354 - accuracy: 0.7347 - val_loss: 0.6065 - val_accuracy: 0.6600\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 813us/step - loss: 0.5329 - accuracy: 0.7352 - val_loss: 0.5923 - val_accuracy: 0.6689\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 926us/step - loss: 0.5313 - accuracy: 0.7372 - val_loss: 0.5994 - val_accuracy: 0.6647\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 806us/step - loss: 0.5291 - accuracy: 0.7375 - val_loss: 0.6021 - val_accuracy: 0.6625\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 982us/step - loss: 0.5270 - accuracy: 0.7381 - val_loss: 0.5742 - val_accuracy: 0.6812\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 858us/step - loss: 0.5236 - accuracy: 0.7410 - val_loss: 0.6016 - val_accuracy: 0.6619\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 946us/step - loss: 0.5219 - accuracy: 0.7408 - val_loss: 0.6089 - val_accuracy: 0.6579\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.5203 - accuracy: 0.7431 - val_loss: 0.5928 - val_accuracy: 0.6686\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.5196 - accuracy: 0.7431 - val_loss: 0.5820 - val_accuracy: 0.6752\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 944us/step - loss: 0.5170 - accuracy: 0.7446 - val_loss: 0.5985 - val_accuracy: 0.6647\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 795us/step - loss: 0.5151 - accuracy: 0.7457 - val_loss: 0.5842 - val_accuracy: 0.6742\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 951us/step - loss: 0.5141 - accuracy: 0.7447 - val_loss: 0.6034 - val_accuracy: 0.6631\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 809us/step - loss: 0.5111 - accuracy: 0.7472 - val_loss: 0.5989 - val_accuracy: 0.6663\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5993 - val_accuracy: 0.6664\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.5072 - accuracy: 0.7514 - val_loss: 0.5901 - val_accuracy: 0.6711\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.5046 - accuracy: 0.7526 - val_loss: 0.5916 - val_accuracy: 0.6704\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7307 - accuracy: 0.5165 - val_loss: 0.7128 - val_accuracy: 0.4358\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 804us/step - loss: 0.6953 - accuracy: 0.5455 - val_loss: 0.6974 - val_accuracy: 0.4870\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 860us/step - loss: 0.6790 - accuracy: 0.5789 - val_loss: 0.6922 - val_accuracy: 0.5058\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6684 - accuracy: 0.5993 - val_loss: 0.6783 - val_accuracy: 0.5456\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.6574 - accuracy: 0.6237 - val_loss: 0.6716 - val_accuracy: 0.5685\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 877us/step - loss: 0.6479 - accuracy: 0.6418 - val_loss: 0.6535 - val_accuracy: 0.6059\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6398 - accuracy: 0.6541 - val_loss: 0.6524 - val_accuracy: 0.6077\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.6326 - accuracy: 0.6653 - val_loss: 0.6462 - val_accuracy: 0.6143\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6262 - accuracy: 0.6702 - val_loss: 0.6395 - val_accuracy: 0.6217\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 802us/step - loss: 0.6193 - accuracy: 0.6785 - val_loss: 0.6431 - val_accuracy: 0.6150\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 958us/step - loss: 0.6126 - accuracy: 0.6840 - val_loss: 0.6301 - val_accuracy: 0.6314\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 914us/step - loss: 0.6079 - accuracy: 0.6882 - val_loss: 0.6241 - val_accuracy: 0.6359\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 887us/step - loss: 0.6025 - accuracy: 0.6925 - val_loss: 0.6389 - val_accuracy: 0.6148\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 816us/step - loss: 0.5978 - accuracy: 0.6975 - val_loss: 0.6168 - val_accuracy: 0.6402\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 990us/step - loss: 0.5930 - accuracy: 0.7012 - val_loss: 0.6205 - val_accuracy: 0.6343\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 813us/step - loss: 0.5895 - accuracy: 0.7028 - val_loss: 0.6045 - val_accuracy: 0.6489\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.7047 - val_loss: 0.6117 - val_accuracy: 0.6402\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 935us/step - loss: 0.5814 - accuracy: 0.7081 - val_loss: 0.6054 - val_accuracy: 0.6459\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.5769 - accuracy: 0.7127 - val_loss: 0.6063 - val_accuracy: 0.6433\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.5735 - accuracy: 0.7128 - val_loss: 0.5952 - val_accuracy: 0.6563\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 942us/step - loss: 0.5697 - accuracy: 0.7163 - val_loss: 0.5933 - val_accuracy: 0.6580\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 827us/step - loss: 0.5664 - accuracy: 0.7184 - val_loss: 0.5979 - val_accuracy: 0.6548\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.5643 - accuracy: 0.7208 - val_loss: 0.6103 - val_accuracy: 0.6424\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.5603 - accuracy: 0.7208 - val_loss: 0.5977 - val_accuracy: 0.6544\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 955us/step - loss: 0.5582 - accuracy: 0.7237 - val_loss: 0.6028 - val_accuracy: 0.6493\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 815us/step - loss: 0.5533 - accuracy: 0.7251 - val_loss: 0.6093 - val_accuracy: 0.6453\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.5513 - accuracy: 0.7256 - val_loss: 0.5938 - val_accuracy: 0.6570\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.5494 - accuracy: 0.7271 - val_loss: 0.6046 - val_accuracy: 0.6487\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.5469 - accuracy: 0.7282 - val_loss: 0.5877 - val_accuracy: 0.6643\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.5435 - accuracy: 0.7297 - val_loss: 0.6063 - val_accuracy: 0.6474\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 976us/step - loss: 0.5411 - accuracy: 0.7309 - val_loss: 0.5870 - val_accuracy: 0.6634\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 808us/step - loss: 0.5396 - accuracy: 0.7304 - val_loss: 0.6019 - val_accuracy: 0.6507\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.5379 - accuracy: 0.7320 - val_loss: 0.5889 - val_accuracy: 0.6612\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 813us/step - loss: 0.5350 - accuracy: 0.7336 - val_loss: 0.5975 - val_accuracy: 0.6532\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 946us/step - loss: 0.5323 - accuracy: 0.7351 - val_loss: 0.5897 - val_accuracy: 0.6598\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 935us/step - loss: 0.5309 - accuracy: 0.7352 - val_loss: 0.5831 - val_accuracy: 0.6654\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.5287 - accuracy: 0.7354 - val_loss: 0.5955 - val_accuracy: 0.6565\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.5272 - accuracy: 0.7355 - val_loss: 0.5944 - val_accuracy: 0.6598\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 884us/step - loss: 0.5244 - accuracy: 0.7393 - val_loss: 0.5974 - val_accuracy: 0.6583\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7383 - val_loss: 0.5944 - val_accuracy: 0.6608\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.7397 - val_loss: 0.6002 - val_accuracy: 0.6579\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 837us/step - loss: 0.5187 - accuracy: 0.7414 - val_loss: 0.5921 - val_accuracy: 0.6645\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.5183 - accuracy: 0.7417 - val_loss: 0.5950 - val_accuracy: 0.6629\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 928us/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5708 - val_accuracy: 0.6803\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 849us/step - loss: 0.5139 - accuracy: 0.7444 - val_loss: 0.5785 - val_accuracy: 0.6758\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 910us/step - loss: 0.5131 - accuracy: 0.7456 - val_loss: 0.5844 - val_accuracy: 0.6721\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 881us/step - loss: 0.5107 - accuracy: 0.7469 - val_loss: 0.5937 - val_accuracy: 0.6646\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 812us/step - loss: 0.5099 - accuracy: 0.7474 - val_loss: 0.5916 - val_accuracy: 0.6657\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 935us/step - loss: 0.5078 - accuracy: 0.7497 - val_loss: 0.5887 - val_accuracy: 0.6681\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 890us/step - loss: 0.5064 - accuracy: 0.7507 - val_loss: 0.5882 - val_accuracy: 0.6686\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 951us/step - loss: 0.7081 - accuracy: 0.5437 - val_loss: 0.6934 - val_accuracy: 0.5445\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.6706 - accuracy: 0.5808 - val_loss: 0.6768 - val_accuracy: 0.5869\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6047 - val_loss: 0.6744 - val_accuracy: 0.5924\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 912us/step - loss: 0.6510 - accuracy: 0.6182 - val_loss: 0.6616 - val_accuracy: 0.6146\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6427 - accuracy: 0.6339 - val_loss: 0.6611 - val_accuracy: 0.6136\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.6372 - accuracy: 0.6408 - val_loss: 0.6496 - val_accuracy: 0.6298\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 986us/step - loss: 0.6305 - accuracy: 0.6496 - val_loss: 0.6472 - val_accuracy: 0.6290\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 944us/step - loss: 0.6253 - accuracy: 0.6536 - val_loss: 0.6459 - val_accuracy: 0.6276\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 919us/step - loss: 0.6199 - accuracy: 0.6606 - val_loss: 0.6398 - val_accuracy: 0.6324\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 925us/step - loss: 0.6155 - accuracy: 0.6646 - val_loss: 0.6339 - val_accuracy: 0.6399\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 866us/step - loss: 0.6119 - accuracy: 0.6698 - val_loss: 0.6391 - val_accuracy: 0.6270\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 980us/step - loss: 0.6075 - accuracy: 0.6731 - val_loss: 0.6316 - val_accuracy: 0.6386\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6030 - accuracy: 0.6800 - val_loss: 0.6325 - val_accuracy: 0.6345\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 996us/step - loss: 0.5986 - accuracy: 0.6853 - val_loss: 0.6243 - val_accuracy: 0.6415\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.5951 - accuracy: 0.6882 - val_loss: 0.6231 - val_accuracy: 0.6409\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 805us/step - loss: 0.5916 - accuracy: 0.6919 - val_loss: 0.6143 - val_accuracy: 0.6502\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 963us/step - loss: 0.5897 - accuracy: 0.6950 - val_loss: 0.6259 - val_accuracy: 0.6303\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 826us/step - loss: 0.5858 - accuracy: 0.6968 - val_loss: 0.6138 - val_accuracy: 0.6460\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 975us/step - loss: 0.5821 - accuracy: 0.7006 - val_loss: 0.6199 - val_accuracy: 0.6363\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.5797 - accuracy: 0.7027 - val_loss: 0.6194 - val_accuracy: 0.6361\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 974us/step - loss: 0.5770 - accuracy: 0.7071 - val_loss: 0.6166 - val_accuracy: 0.6384\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.5752 - accuracy: 0.7082 - val_loss: 0.6120 - val_accuracy: 0.6480\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 977us/step - loss: 0.5708 - accuracy: 0.7119 - val_loss: 0.6127 - val_accuracy: 0.6470\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.5686 - accuracy: 0.7134 - val_loss: 0.6045 - val_accuracy: 0.6532\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 986us/step - loss: 0.5658 - accuracy: 0.7153 - val_loss: 0.6250 - val_accuracy: 0.6359\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 927us/step - loss: 0.5637 - accuracy: 0.7164 - val_loss: 0.6088 - val_accuracy: 0.6490\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 872us/step - loss: 0.5613 - accuracy: 0.7185 - val_loss: 0.6064 - val_accuracy: 0.6511\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 975us/step - loss: 0.5594 - accuracy: 0.7183 - val_loss: 0.6222 - val_accuracy: 0.6371\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.5576 - accuracy: 0.7213 - val_loss: 0.6156 - val_accuracy: 0.6444\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7216 - val_loss: 0.6222 - val_accuracy: 0.6389\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 974us/step - loss: 0.5529 - accuracy: 0.7233 - val_loss: 0.6189 - val_accuracy: 0.6420\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.5512 - accuracy: 0.7245 - val_loss: 0.6183 - val_accuracy: 0.6425\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.5499 - accuracy: 0.7254 - val_loss: 0.6131 - val_accuracy: 0.6479\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 897us/step - loss: 0.5482 - accuracy: 0.7247 - val_loss: 0.6154 - val_accuracy: 0.6460\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 904us/step - loss: 0.5472 - accuracy: 0.7254 - val_loss: 0.6133 - val_accuracy: 0.6469\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.5447 - accuracy: 0.7275 - val_loss: 0.6096 - val_accuracy: 0.6489\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 981us/step - loss: 0.5421 - accuracy: 0.7282 - val_loss: 0.6307 - val_accuracy: 0.6363\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.5416 - accuracy: 0.7282 - val_loss: 0.6180 - val_accuracy: 0.6431\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.5392 - accuracy: 0.7295 - val_loss: 0.6119 - val_accuracy: 0.6480\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.5379 - accuracy: 0.7299 - val_loss: 0.6138 - val_accuracy: 0.6465\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.5361 - accuracy: 0.7312 - val_loss: 0.6257 - val_accuracy: 0.6374\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 958us/step - loss: 0.5343 - accuracy: 0.7327 - val_loss: 0.6113 - val_accuracy: 0.6472\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 874us/step - loss: 0.5331 - accuracy: 0.7334 - val_loss: 0.5986 - val_accuracy: 0.6561\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 967us/step - loss: 0.5311 - accuracy: 0.7342 - val_loss: 0.5921 - val_accuracy: 0.6618\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 816us/step - loss: 0.5290 - accuracy: 0.7349 - val_loss: 0.6002 - val_accuracy: 0.6553\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 963us/step - loss: 0.5282 - accuracy: 0.7342 - val_loss: 0.5977 - val_accuracy: 0.6583\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 951us/step - loss: 0.5268 - accuracy: 0.7368 - val_loss: 0.6129 - val_accuracy: 0.6459\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 809us/step - loss: 0.5257 - accuracy: 0.7369 - val_loss: 0.5907 - val_accuracy: 0.6631\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 948us/step - loss: 0.5243 - accuracy: 0.7371 - val_loss: 0.5952 - val_accuracy: 0.6614\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 904us/step - loss: 0.5230 - accuracy: 0.7373 - val_loss: 0.6083 - val_accuracy: 0.6500\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 898us/step - loss: 0.7129 - accuracy: 0.5242 - val_loss: 0.7134 - val_accuracy: 0.3877\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 806us/step - loss: 0.6885 - accuracy: 0.5625 - val_loss: 0.6942 - val_accuracy: 0.5557\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 987us/step - loss: 0.6744 - accuracy: 0.5861 - val_loss: 0.6862 - val_accuracy: 0.5812\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.6622 - accuracy: 0.6124 - val_loss: 0.6729 - val_accuracy: 0.6028\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 910us/step - loss: 0.6528 - accuracy: 0.6312 - val_loss: 0.6574 - val_accuracy: 0.6208\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.6432 - accuracy: 0.6465 - val_loss: 0.6582 - val_accuracy: 0.6133\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.6592 - val_loss: 0.6591 - val_accuracy: 0.6069\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6663 - val_loss: 0.6390 - val_accuracy: 0.6391\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 780us/step - loss: 0.6224 - accuracy: 0.6714 - val_loss: 0.6430 - val_accuracy: 0.6250\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 931us/step - loss: 0.6154 - accuracy: 0.6774 - val_loss: 0.6387 - val_accuracy: 0.6286\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 887us/step - loss: 0.6091 - accuracy: 0.6850 - val_loss: 0.6216 - val_accuracy: 0.6481\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 735us/step - loss: 0.6049 - accuracy: 0.6893 - val_loss: 0.6174 - val_accuracy: 0.6523\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.6011 - accuracy: 0.6904 - val_loss: 0.6326 - val_accuracy: 0.6282\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 757us/step - loss: 0.5972 - accuracy: 0.6950 - val_loss: 0.6209 - val_accuracy: 0.6430\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 878us/step - loss: 0.5927 - accuracy: 0.6985 - val_loss: 0.6043 - val_accuracy: 0.6619\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 872us/step - loss: 0.5892 - accuracy: 0.7016 - val_loss: 0.6045 - val_accuracy: 0.6608\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 764us/step - loss: 0.5836 - accuracy: 0.7048 - val_loss: 0.6126 - val_accuracy: 0.6509\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 718us/step - loss: 0.5800 - accuracy: 0.7098 - val_loss: 0.6095 - val_accuracy: 0.6525\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 863us/step - loss: 0.5786 - accuracy: 0.7076 - val_loss: 0.6044 - val_accuracy: 0.6572\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 730us/step - loss: 0.5742 - accuracy: 0.7117 - val_loss: 0.5967 - val_accuracy: 0.6635\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 878us/step - loss: 0.5711 - accuracy: 0.7143 - val_loss: 0.5953 - val_accuracy: 0.6646\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 861us/step - loss: 0.5678 - accuracy: 0.7170 - val_loss: 0.6084 - val_accuracy: 0.6508\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 742us/step - loss: 0.5656 - accuracy: 0.7173 - val_loss: 0.6116 - val_accuracy: 0.6475\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.5611 - accuracy: 0.7213 - val_loss: 0.6122 - val_accuracy: 0.6453\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 777us/step - loss: 0.5599 - accuracy: 0.7206 - val_loss: 0.5959 - val_accuracy: 0.6632\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.5574 - accuracy: 0.7225 - val_loss: 0.6075 - val_accuracy: 0.6474\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 788us/step - loss: 0.5540 - accuracy: 0.7271 - val_loss: 0.6093 - val_accuracy: 0.6418\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 873us/step - loss: 0.5521 - accuracy: 0.7255 - val_loss: 0.6059 - val_accuracy: 0.6453\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.5491 - accuracy: 0.7282 - val_loss: 0.6018 - val_accuracy: 0.6468\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 763us/step - loss: 0.5466 - accuracy: 0.7296 - val_loss: 0.6015 - val_accuracy: 0.6466\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 851us/step - loss: 0.5444 - accuracy: 0.7311 - val_loss: 0.6026 - val_accuracy: 0.6461\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 759us/step - loss: 0.5433 - accuracy: 0.7303 - val_loss: 0.6090 - val_accuracy: 0.6406\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 899us/step - loss: 0.5399 - accuracy: 0.7338 - val_loss: 0.6049 - val_accuracy: 0.6444\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 736us/step - loss: 0.5376 - accuracy: 0.7352 - val_loss: 0.5935 - val_accuracy: 0.6541\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.5366 - accuracy: 0.7342 - val_loss: 0.6038 - val_accuracy: 0.6440\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 770us/step - loss: 0.5345 - accuracy: 0.7342 - val_loss: 0.5929 - val_accuracy: 0.6545\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.5324 - accuracy: 0.7378 - val_loss: 0.5959 - val_accuracy: 0.6508\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 766us/step - loss: 0.5302 - accuracy: 0.7371 - val_loss: 0.5849 - val_accuracy: 0.6638\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 884us/step - loss: 0.5291 - accuracy: 0.7391 - val_loss: 0.5990 - val_accuracy: 0.6481\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 739us/step - loss: 0.5276 - accuracy: 0.7413 - val_loss: 0.5987 - val_accuracy: 0.6483\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.5271 - accuracy: 0.7376 - val_loss: 0.5979 - val_accuracy: 0.6502\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 771us/step - loss: 0.5238 - accuracy: 0.7411 - val_loss: 0.5927 - val_accuracy: 0.6563\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 873us/step - loss: 0.5214 - accuracy: 0.7445 - val_loss: 0.5913 - val_accuracy: 0.6575\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 744us/step - loss: 0.5206 - accuracy: 0.7423 - val_loss: 0.5931 - val_accuracy: 0.6562\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.5182 - accuracy: 0.7437 - val_loss: 0.5855 - val_accuracy: 0.6647\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 865us/step - loss: 0.5172 - accuracy: 0.7456 - val_loss: 0.5909 - val_accuracy: 0.6580\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.5149 - accuracy: 0.7453 - val_loss: 0.5880 - val_accuracy: 0.6606\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5137 - accuracy: 0.7477 - val_loss: 0.5914 - val_accuracy: 0.6582\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 792us/step - loss: 0.5135 - accuracy: 0.7484 - val_loss: 0.5960 - val_accuracy: 0.6540\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 861us/step - loss: 0.5113 - accuracy: 0.7483 - val_loss: 0.5861 - val_accuracy: 0.6646\n"
     ]
    }
   ],
   "source": [
    "# Run experiments varying parameters\n",
    "delta = 1e-5\n",
    "\n",
    "# 1. Vary batch_size\n",
    "results_batch_size = {}\n",
    "eps_batch_size = {}\n",
    "for bs in batch_size_values:\n",
    "    print(f\"\\nTraining model with batch_size={bs}...\")\n",
    "    n = len(X_train_filtered)\n",
    "    eps = compute_privacy_budget(n, bs, default_noise_multiplier, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "        batch_size=bs, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        l2_norm_clip=l2_norm_clip, noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_batch_size[bs] = compute_statistics(results)\n",
    "    eps_batch_size[bs] = eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae4efc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with sample_size_ratio=1...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.1 iterated over 167200 steps satisfies differential privacy with eps = 0.849 and delta = 1e-05.\n",
      "The optimal RDP order is 19.0.\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.6795 - accuracy: 0.5789 - val_loss: 0.6872 - val_accuracy: 0.5589\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.6199 - accuracy: 0.6816 - val_loss: 0.6196 - val_accuracy: 0.6579\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.5774 - accuracy: 0.7127 - val_loss: 0.5724 - val_accuracy: 0.6889\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.5475 - accuracy: 0.7281 - val_loss: 0.6247 - val_accuracy: 0.6404\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.5276 - accuracy: 0.7383 - val_loss: 0.5713 - val_accuracy: 0.6822\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.5108 - accuracy: 0.7491 - val_loss: 0.6008 - val_accuracy: 0.6604\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.4989 - accuracy: 0.7545 - val_loss: 0.6214 - val_accuracy: 0.6475\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.4857 - accuracy: 0.7644 - val_loss: 0.5516 - val_accuracy: 0.7060\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.4744 - accuracy: 0.7735 - val_loss: 0.6327 - val_accuracy: 0.6437\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.4621 - accuracy: 0.7794 - val_loss: 0.5814 - val_accuracy: 0.6866\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.4488 - accuracy: 0.7893 - val_loss: 0.5503 - val_accuracy: 0.7172\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.4352 - accuracy: 0.8009 - val_loss: 0.5552 - val_accuracy: 0.7171\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.4178 - accuracy: 0.8135 - val_loss: 0.5500 - val_accuracy: 0.7255\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.4038 - accuracy: 0.8220 - val_loss: 0.5265 - val_accuracy: 0.7489\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.3864 - accuracy: 0.8344 - val_loss: 0.5417 - val_accuracy: 0.7440\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3728 - accuracy: 0.8426 - val_loss: 0.4519 - val_accuracy: 0.8201\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.3593 - accuracy: 0.8511 - val_loss: 0.5392 - val_accuracy: 0.7574\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.3481 - accuracy: 0.8576 - val_loss: 0.4737 - val_accuracy: 0.8078\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.3373 - accuracy: 0.8642 - val_loss: 0.4421 - val_accuracy: 0.8272\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.3289 - accuracy: 0.8687 - val_loss: 0.4564 - val_accuracy: 0.8221\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.3219 - accuracy: 0.8714 - val_loss: 0.4713 - val_accuracy: 0.8183\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.3159 - accuracy: 0.8750 - val_loss: 0.5532 - val_accuracy: 0.7739\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.3106 - accuracy: 0.8776 - val_loss: 0.5077 - val_accuracy: 0.8005\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.3065 - accuracy: 0.8796 - val_loss: 0.4922 - val_accuracy: 0.8094\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.3015 - accuracy: 0.8811 - val_loss: 0.5443 - val_accuracy: 0.7829\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2989 - accuracy: 0.8832 - val_loss: 0.5215 - val_accuracy: 0.7950\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2961 - accuracy: 0.8844 - val_loss: 0.4797 - val_accuracy: 0.8180\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2938 - accuracy: 0.8853 - val_loss: 0.4849 - val_accuracy: 0.8149\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2915 - accuracy: 0.8868 - val_loss: 0.4814 - val_accuracy: 0.8165\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2905 - accuracy: 0.8871 - val_loss: 0.4544 - val_accuracy: 0.8290\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2870 - accuracy: 0.8888 - val_loss: 0.4289 - val_accuracy: 0.8358\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2860 - accuracy: 0.8892 - val_loss: 0.5083 - val_accuracy: 0.8045\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2835 - accuracy: 0.8900 - val_loss: 0.4826 - val_accuracy: 0.8172\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 416us/step - loss: 0.2820 - accuracy: 0.8898 - val_loss: 0.4457 - val_accuracy: 0.8317\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.2813 - accuracy: 0.8900 - val_loss: 0.4640 - val_accuracy: 0.8266\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2805 - accuracy: 0.8916 - val_loss: 0.5629 - val_accuracy: 0.7808\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2799 - accuracy: 0.8920 - val_loss: 0.5387 - val_accuracy: 0.7887\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2781 - accuracy: 0.8930 - val_loss: 0.5252 - val_accuracy: 0.7958\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.2768 - accuracy: 0.8938 - val_loss: 0.4501 - val_accuracy: 0.8288\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.2750 - accuracy: 0.8933 - val_loss: 0.4809 - val_accuracy: 0.8154\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2744 - accuracy: 0.8933 - val_loss: 0.5317 - val_accuracy: 0.7977\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2742 - accuracy: 0.8937 - val_loss: 0.4667 - val_accuracy: 0.8215\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2722 - accuracy: 0.8953 - val_loss: 0.5051 - val_accuracy: 0.8070\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2714 - accuracy: 0.8946 - val_loss: 0.4721 - val_accuracy: 0.8205\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2705 - accuracy: 0.8957 - val_loss: 0.4536 - val_accuracy: 0.8299\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2706 - accuracy: 0.8956 - val_loss: 0.4866 - val_accuracy: 0.8153\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2680 - accuracy: 0.8964 - val_loss: 0.4152 - val_accuracy: 0.8433\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2672 - accuracy: 0.8965 - val_loss: 0.4321 - val_accuracy: 0.8382\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2668 - accuracy: 0.8964 - val_loss: 0.4729 - val_accuracy: 0.8211\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2654 - accuracy: 0.8985 - val_loss: 0.4635 - val_accuracy: 0.8242\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.6629 - accuracy: 0.5954 - val_loss: 0.6687 - val_accuracy: 0.6309\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.6179 - accuracy: 0.6645 - val_loss: 0.6709 - val_accuracy: 0.6030\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.5845 - accuracy: 0.6969 - val_loss: 0.6078 - val_accuracy: 0.6601\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.5594 - accuracy: 0.7178 - val_loss: 0.6314 - val_accuracy: 0.6314\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.5417 - accuracy: 0.7289 - val_loss: 0.6039 - val_accuracy: 0.6533\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.5275 - accuracy: 0.7379 - val_loss: 0.6110 - val_accuracy: 0.6520\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.5154 - accuracy: 0.7446 - val_loss: 0.5785 - val_accuracy: 0.6817\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.5047 - accuracy: 0.7492 - val_loss: 0.5824 - val_accuracy: 0.6773\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.4966 - accuracy: 0.7555 - val_loss: 0.6727 - val_accuracy: 0.6194\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.4864 - accuracy: 0.7624 - val_loss: 0.6314 - val_accuracy: 0.6459\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.4748 - accuracy: 0.7709 - val_loss: 0.5521 - val_accuracy: 0.7102\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.4641 - accuracy: 0.7770 - val_loss: 0.6241 - val_accuracy: 0.6600\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.4505 - accuracy: 0.7885 - val_loss: 0.5346 - val_accuracy: 0.7338\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.4362 - accuracy: 0.7983 - val_loss: 0.5923 - val_accuracy: 0.6905\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.4218 - accuracy: 0.8091 - val_loss: 0.5157 - val_accuracy: 0.7579\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.4053 - accuracy: 0.8202 - val_loss: 0.5547 - val_accuracy: 0.7318\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3900 - accuracy: 0.8307 - val_loss: 0.4720 - val_accuracy: 0.7997\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.3740 - accuracy: 0.8426 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.3603 - accuracy: 0.8505 - val_loss: 0.5087 - val_accuracy: 0.7831\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.3463 - accuracy: 0.8583 - val_loss: 0.4729 - val_accuracy: 0.8092\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.3378 - accuracy: 0.8642 - val_loss: 0.4551 - val_accuracy: 0.8219\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.3289 - accuracy: 0.8680 - val_loss: 0.4938 - val_accuracy: 0.8031\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.3192 - accuracy: 0.8728 - val_loss: 0.4330 - val_accuracy: 0.8347\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3144 - accuracy: 0.8766 - val_loss: 0.5125 - val_accuracy: 0.7966\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.3078 - accuracy: 0.8795 - val_loss: 0.4447 - val_accuracy: 0.8314\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3037 - accuracy: 0.8812 - val_loss: 0.5272 - val_accuracy: 0.7946\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2991 - accuracy: 0.8836 - val_loss: 0.4333 - val_accuracy: 0.8390\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2960 - accuracy: 0.8832 - val_loss: 0.4278 - val_accuracy: 0.8421\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2941 - accuracy: 0.8862 - val_loss: 0.4105 - val_accuracy: 0.8471\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2904 - accuracy: 0.8868 - val_loss: 0.5016 - val_accuracy: 0.8111\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2894 - accuracy: 0.8882 - val_loss: 0.5549 - val_accuracy: 0.7864\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2865 - accuracy: 0.8882 - val_loss: 0.6299 - val_accuracy: 0.7438\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2866 - accuracy: 0.8884 - val_loss: 0.4712 - val_accuracy: 0.8235\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.2832 - accuracy: 0.8900 - val_loss: 0.4086 - val_accuracy: 0.8474\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2813 - accuracy: 0.8915 - val_loss: 0.5007 - val_accuracy: 0.8110\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2806 - accuracy: 0.8897 - val_loss: 0.4740 - val_accuracy: 0.8201\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.2797 - accuracy: 0.8915 - val_loss: 0.4725 - val_accuracy: 0.8209\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.2769 - accuracy: 0.8919 - val_loss: 0.4406 - val_accuracy: 0.8358\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2765 - accuracy: 0.8934 - val_loss: 0.4289 - val_accuracy: 0.8378\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2752 - accuracy: 0.8930 - val_loss: 0.5258 - val_accuracy: 0.7980\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2752 - accuracy: 0.8935 - val_loss: 0.5075 - val_accuracy: 0.8026\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2724 - accuracy: 0.8934 - val_loss: 0.4425 - val_accuracy: 0.8317\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2722 - accuracy: 0.8947 - val_loss: 0.4510 - val_accuracy: 0.8267\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2701 - accuracy: 0.8954 - val_loss: 0.5020 - val_accuracy: 0.8061\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2688 - accuracy: 0.8960 - val_loss: 0.5098 - val_accuracy: 0.8049\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2696 - accuracy: 0.8961 - val_loss: 0.5036 - val_accuracy: 0.8055\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2689 - accuracy: 0.8959 - val_loss: 0.3837 - val_accuracy: 0.8525\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2666 - accuracy: 0.8970 - val_loss: 0.4329 - val_accuracy: 0.8325\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2655 - accuracy: 0.8975 - val_loss: 0.5162 - val_accuracy: 0.7987\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.2650 - accuracy: 0.8974 - val_loss: 0.4330 - val_accuracy: 0.8334\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.6466 - accuracy: 0.6352 - val_loss: 0.6502 - val_accuracy: 0.6302\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.5958 - accuracy: 0.6959 - val_loss: 0.6170 - val_accuracy: 0.6585\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5693 - accuracy: 0.7126 - val_loss: 0.6277 - val_accuracy: 0.6487\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.5494 - accuracy: 0.7247 - val_loss: 0.5599 - val_accuracy: 0.6939\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.5346 - accuracy: 0.7299 - val_loss: 0.6117 - val_accuracy: 0.6604\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5207 - accuracy: 0.7387 - val_loss: 0.5822 - val_accuracy: 0.6810\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.5098 - accuracy: 0.7467 - val_loss: 0.5810 - val_accuracy: 0.6816\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.4980 - accuracy: 0.7536 - val_loss: 0.5922 - val_accuracy: 0.6761\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.4874 - accuracy: 0.7615 - val_loss: 0.5976 - val_accuracy: 0.6726\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.4767 - accuracy: 0.7714 - val_loss: 0.5242 - val_accuracy: 0.7332\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.4640 - accuracy: 0.7790 - val_loss: 0.5561 - val_accuracy: 0.7065\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.4508 - accuracy: 0.7887 - val_loss: 0.5842 - val_accuracy: 0.6890\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.6293 - val_accuracy: 0.6647\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.4224 - accuracy: 0.8079 - val_loss: 0.4945 - val_accuracy: 0.7700\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.4081 - accuracy: 0.8184 - val_loss: 0.4244 - val_accuracy: 0.8272\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.3935 - accuracy: 0.8289 - val_loss: 0.5880 - val_accuracy: 0.7093\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.3794 - accuracy: 0.8370 - val_loss: 0.5614 - val_accuracy: 0.7332\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.3652 - accuracy: 0.8456 - val_loss: 0.5769 - val_accuracy: 0.7235\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.3536 - accuracy: 0.8536 - val_loss: 0.5844 - val_accuracy: 0.7246\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.3441 - accuracy: 0.8591 - val_loss: 0.5750 - val_accuracy: 0.7384\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.3336 - accuracy: 0.8656 - val_loss: 0.5267 - val_accuracy: 0.7747\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.3262 - accuracy: 0.8682 - val_loss: 0.4952 - val_accuracy: 0.7980\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.3214 - accuracy: 0.8710 - val_loss: 0.4839 - val_accuracy: 0.8068\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.3142 - accuracy: 0.8746 - val_loss: 0.5444 - val_accuracy: 0.7712\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.3088 - accuracy: 0.8786 - val_loss: 0.4772 - val_accuracy: 0.8128\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.3045 - accuracy: 0.8798 - val_loss: 0.4605 - val_accuracy: 0.8190\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.3015 - accuracy: 0.8811 - val_loss: 0.6073 - val_accuracy: 0.7410\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2972 - accuracy: 0.8842 - val_loss: 0.4696 - val_accuracy: 0.8179\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2954 - accuracy: 0.8842 - val_loss: 0.5055 - val_accuracy: 0.7997\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2927 - accuracy: 0.8853 - val_loss: 0.4273 - val_accuracy: 0.8326\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2911 - accuracy: 0.8853 - val_loss: 0.4605 - val_accuracy: 0.8185\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2887 - accuracy: 0.8871 - val_loss: 0.5900 - val_accuracy: 0.7574\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2858 - accuracy: 0.8876 - val_loss: 0.5045 - val_accuracy: 0.7986\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2842 - accuracy: 0.8894 - val_loss: 0.5073 - val_accuracy: 0.8002\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2823 - accuracy: 0.8893 - val_loss: 0.4757 - val_accuracy: 0.8138\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2814 - accuracy: 0.8901 - val_loss: 0.4489 - val_accuracy: 0.8251\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.2785 - accuracy: 0.8914 - val_loss: 0.5143 - val_accuracy: 0.7979\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2792 - accuracy: 0.8912 - val_loss: 0.5409 - val_accuracy: 0.7838\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2765 - accuracy: 0.8926 - val_loss: 0.4633 - val_accuracy: 0.8175\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2766 - accuracy: 0.8916 - val_loss: 0.4775 - val_accuracy: 0.8104\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2753 - accuracy: 0.8922 - val_loss: 0.4462 - val_accuracy: 0.8255\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2737 - accuracy: 0.8940 - val_loss: 0.4421 - val_accuracy: 0.8269\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.2716 - accuracy: 0.8945 - val_loss: 0.6023 - val_accuracy: 0.7540\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2711 - accuracy: 0.8944 - val_loss: 0.4594 - val_accuracy: 0.8161\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2706 - accuracy: 0.8949 - val_loss: 0.5225 - val_accuracy: 0.7931\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2697 - accuracy: 0.8950 - val_loss: 0.5923 - val_accuracy: 0.7609\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2683 - accuracy: 0.8957 - val_loss: 0.4132 - val_accuracy: 0.8353\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2666 - accuracy: 0.8960 - val_loss: 0.5168 - val_accuracy: 0.7962\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2681 - accuracy: 0.8959 - val_loss: 0.4041 - val_accuracy: 0.8392\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2664 - accuracy: 0.8960 - val_loss: 0.4810 - val_accuracy: 0.8085\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.6441 - accuracy: 0.6308 - val_loss: 0.6429 - val_accuracy: 0.5978\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.5924 - accuracy: 0.6821 - val_loss: 0.5639 - val_accuracy: 0.6877\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 417us/step - loss: 0.5655 - accuracy: 0.7023 - val_loss: 0.6240 - val_accuracy: 0.6173\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.5463 - accuracy: 0.7182 - val_loss: 0.5980 - val_accuracy: 0.6415\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.5303 - accuracy: 0.7287 - val_loss: 0.6548 - val_accuracy: 0.6157\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5165 - accuracy: 0.7372 - val_loss: 0.6267 - val_accuracy: 0.6362\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5046 - accuracy: 0.7459 - val_loss: 0.6029 - val_accuracy: 0.6555\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.4939 - accuracy: 0.7533 - val_loss: 0.5697 - val_accuracy: 0.6821\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.4808 - accuracy: 0.7637 - val_loss: 0.6575 - val_accuracy: 0.6209\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.4683 - accuracy: 0.7711 - val_loss: 0.5480 - val_accuracy: 0.7049\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.4542 - accuracy: 0.7837 - val_loss: 0.5928 - val_accuracy: 0.6758\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.4406 - accuracy: 0.7926 - val_loss: 0.5460 - val_accuracy: 0.7192\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.4261 - accuracy: 0.8043 - val_loss: 0.4697 - val_accuracy: 0.7907\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.4106 - accuracy: 0.8136 - val_loss: 0.4819 - val_accuracy: 0.7838\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.3961 - accuracy: 0.8255 - val_loss: 0.4497 - val_accuracy: 0.8136\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.3805 - accuracy: 0.8341 - val_loss: 0.4890 - val_accuracy: 0.7848\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.3680 - accuracy: 0.8435 - val_loss: 0.4882 - val_accuracy: 0.7892\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.3551 - accuracy: 0.8513 - val_loss: 0.4575 - val_accuracy: 0.8144\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.3445 - accuracy: 0.8588 - val_loss: 0.5096 - val_accuracy: 0.7803\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.3350 - accuracy: 0.8645 - val_loss: 0.4629 - val_accuracy: 0.8150\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.3266 - accuracy: 0.8690 - val_loss: 0.5344 - val_accuracy: 0.7712\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.3194 - accuracy: 0.8718 - val_loss: 0.4054 - val_accuracy: 0.8456\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.3134 - accuracy: 0.8754 - val_loss: 0.5565 - val_accuracy: 0.7667\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.3089 - accuracy: 0.8792 - val_loss: 0.4997 - val_accuracy: 0.8024\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.3041 - accuracy: 0.8794 - val_loss: 0.4534 - val_accuracy: 0.8254\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2998 - accuracy: 0.8827 - val_loss: 0.4211 - val_accuracy: 0.8387\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2964 - accuracy: 0.8838 - val_loss: 0.6444 - val_accuracy: 0.7200\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.2938 - accuracy: 0.8850 - val_loss: 0.4342 - val_accuracy: 0.8334\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.2916 - accuracy: 0.8855 - val_loss: 0.5289 - val_accuracy: 0.7930\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.2871 - accuracy: 0.8872 - val_loss: 0.5648 - val_accuracy: 0.7731\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2850 - accuracy: 0.8896 - val_loss: 0.5361 - val_accuracy: 0.7897\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.2838 - accuracy: 0.8899 - val_loss: 0.4723 - val_accuracy: 0.8211\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2835 - accuracy: 0.8893 - val_loss: 0.7431 - val_accuracy: 0.6791\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.2800 - accuracy: 0.8909 - val_loss: 0.4620 - val_accuracy: 0.8242\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2775 - accuracy: 0.8919 - val_loss: 0.3681 - val_accuracy: 0.8583\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2765 - accuracy: 0.8936 - val_loss: 0.4441 - val_accuracy: 0.8314\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2759 - accuracy: 0.8935 - val_loss: 0.4021 - val_accuracy: 0.8458\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2725 - accuracy: 0.8938 - val_loss: 0.4244 - val_accuracy: 0.8370\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2723 - accuracy: 0.8937 - val_loss: 0.4168 - val_accuracy: 0.8379\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2713 - accuracy: 0.8948 - val_loss: 0.5244 - val_accuracy: 0.7970\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2713 - accuracy: 0.8955 - val_loss: 0.4814 - val_accuracy: 0.8164\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2697 - accuracy: 0.8963 - val_loss: 0.4791 - val_accuracy: 0.8167\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2678 - accuracy: 0.8971 - val_loss: 0.6218 - val_accuracy: 0.7461\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.2679 - accuracy: 0.8966 - val_loss: 0.5321 - val_accuracy: 0.7922\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2665 - accuracy: 0.8966 - val_loss: 0.5603 - val_accuracy: 0.7826\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2660 - accuracy: 0.8966 - val_loss: 0.4077 - val_accuracy: 0.8443\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2646 - accuracy: 0.8968 - val_loss: 0.5817 - val_accuracy: 0.7668\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2632 - accuracy: 0.8982 - val_loss: 0.4259 - val_accuracy: 0.8368\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2636 - accuracy: 0.8967 - val_loss: 0.3805 - val_accuracy: 0.8522\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2624 - accuracy: 0.8983 - val_loss: 0.4433 - val_accuracy: 0.8290\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.6661 - accuracy: 0.5908 - val_loss: 0.6495 - val_accuracy: 0.6267\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.6060 - accuracy: 0.6843 - val_loss: 0.6219 - val_accuracy: 0.6337\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5751 - accuracy: 0.7077 - val_loss: 0.6384 - val_accuracy: 0.6179\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.5546 - accuracy: 0.7206 - val_loss: 0.6424 - val_accuracy: 0.6197\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.5396 - accuracy: 0.7303 - val_loss: 0.6270 - val_accuracy: 0.6265\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5255 - accuracy: 0.7355 - val_loss: 0.6012 - val_accuracy: 0.6488\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.5149 - accuracy: 0.7418 - val_loss: 0.5671 - val_accuracy: 0.6786\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.5034 - accuracy: 0.7500 - val_loss: 0.5596 - val_accuracy: 0.6863\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.4923 - accuracy: 0.7584 - val_loss: 0.6392 - val_accuracy: 0.6260\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.4811 - accuracy: 0.7652 - val_loss: 0.5671 - val_accuracy: 0.6848\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.4703 - accuracy: 0.7728 - val_loss: 0.5410 - val_accuracy: 0.7138\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.4564 - accuracy: 0.7824 - val_loss: 0.5702 - val_accuracy: 0.6896\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.4434 - accuracy: 0.7919 - val_loss: 0.4772 - val_accuracy: 0.7795\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.4279 - accuracy: 0.8045 - val_loss: 0.5866 - val_accuracy: 0.6871\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.4127 - accuracy: 0.8142 - val_loss: 0.5776 - val_accuracy: 0.6999\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.3975 - accuracy: 0.8255 - val_loss: 0.4843 - val_accuracy: 0.7820\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.3824 - accuracy: 0.8360 - val_loss: 0.4273 - val_accuracy: 0.8279\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.3669 - accuracy: 0.8467 - val_loss: 0.5335 - val_accuracy: 0.7503\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.3546 - accuracy: 0.8547 - val_loss: 0.4567 - val_accuracy: 0.8132\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.3441 - accuracy: 0.8600 - val_loss: 0.4708 - val_accuracy: 0.8042\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.3341 - accuracy: 0.8654 - val_loss: 0.4847 - val_accuracy: 0.8007\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.3255 - accuracy: 0.8708 - val_loss: 0.6247 - val_accuracy: 0.7068\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.3201 - accuracy: 0.8719 - val_loss: 0.4482 - val_accuracy: 0.8238\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3141 - accuracy: 0.8756 - val_loss: 0.4635 - val_accuracy: 0.8160\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.3082 - accuracy: 0.8783 - val_loss: 0.6327 - val_accuracy: 0.7145\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.3060 - accuracy: 0.8793 - val_loss: 0.6733 - val_accuracy: 0.6961\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.3000 - accuracy: 0.8820 - val_loss: 0.4260 - val_accuracy: 0.8325\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2970 - accuracy: 0.8823 - val_loss: 0.4767 - val_accuracy: 0.8143\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2948 - accuracy: 0.8835 - val_loss: 0.4443 - val_accuracy: 0.8252\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2908 - accuracy: 0.8871 - val_loss: 0.4362 - val_accuracy: 0.8286\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2903 - accuracy: 0.8863 - val_loss: 0.4883 - val_accuracy: 0.8086\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.2872 - accuracy: 0.8879 - val_loss: 0.4873 - val_accuracy: 0.8081\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.2858 - accuracy: 0.8877 - val_loss: 0.4437 - val_accuracy: 0.8270\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2831 - accuracy: 0.8904 - val_loss: 0.3982 - val_accuracy: 0.8464\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2824 - accuracy: 0.8888 - val_loss: 0.4906 - val_accuracy: 0.8078\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2817 - accuracy: 0.8907 - val_loss: 0.5691 - val_accuracy: 0.7715\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2801 - accuracy: 0.8915 - val_loss: 0.4682 - val_accuracy: 0.8185\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.2791 - accuracy: 0.8914 - val_loss: 0.5787 - val_accuracy: 0.7621\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2783 - accuracy: 0.8902 - val_loss: 0.4444 - val_accuracy: 0.8275\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.2762 - accuracy: 0.8929 - val_loss: 0.4075 - val_accuracy: 0.8426\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2768 - accuracy: 0.8926 - val_loss: 0.4535 - val_accuracy: 0.8223\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2759 - accuracy: 0.8926 - val_loss: 0.4574 - val_accuracy: 0.8205\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2742 - accuracy: 0.8932 - val_loss: 0.4372 - val_accuracy: 0.8291\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2730 - accuracy: 0.8942 - val_loss: 0.4741 - val_accuracy: 0.8123\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.2729 - accuracy: 0.8945 - val_loss: 0.4521 - val_accuracy: 0.8215\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2719 - accuracy: 0.8945 - val_loss: 0.5378 - val_accuracy: 0.7812\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2708 - accuracy: 0.8943 - val_loss: 0.5165 - val_accuracy: 0.7942\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2687 - accuracy: 0.8957 - val_loss: 0.3740 - val_accuracy: 0.8528\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2702 - accuracy: 0.8949 - val_loss: 0.6414 - val_accuracy: 0.7280\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.2698 - accuracy: 0.8972 - val_loss: 0.5325 - val_accuracy: 0.7879\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.6564 - accuracy: 0.6125 - val_loss: 0.6409 - val_accuracy: 0.6380\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.6036 - accuracy: 0.6838 - val_loss: 0.5944 - val_accuracy: 0.6726\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.5740 - accuracy: 0.7068 - val_loss: 0.6358 - val_accuracy: 0.6194\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.5512 - accuracy: 0.7213 - val_loss: 0.6332 - val_accuracy: 0.6247\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.5353 - accuracy: 0.7323 - val_loss: 0.6166 - val_accuracy: 0.6381\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5205 - accuracy: 0.7384 - val_loss: 0.6182 - val_accuracy: 0.6434\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.5078 - accuracy: 0.7459 - val_loss: 0.6165 - val_accuracy: 0.6479\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.4972 - accuracy: 0.7528 - val_loss: 0.5773 - val_accuracy: 0.6789\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.4849 - accuracy: 0.7610 - val_loss: 0.5697 - val_accuracy: 0.6856\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.4736 - accuracy: 0.7689 - val_loss: 0.5795 - val_accuracy: 0.6812\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.4603 - accuracy: 0.7786 - val_loss: 0.5494 - val_accuracy: 0.7076\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.4469 - accuracy: 0.7880 - val_loss: 0.5484 - val_accuracy: 0.7154\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.4308 - accuracy: 0.7998 - val_loss: 0.5783 - val_accuracy: 0.6987\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.4169 - accuracy: 0.8109 - val_loss: 0.5237 - val_accuracy: 0.7455\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.4001 - accuracy: 0.8227 - val_loss: 0.5176 - val_accuracy: 0.7555\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.3859 - accuracy: 0.8317 - val_loss: 0.4802 - val_accuracy: 0.7923\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.3707 - accuracy: 0.8428 - val_loss: 0.5219 - val_accuracy: 0.7580\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.3565 - accuracy: 0.8510 - val_loss: 0.6027 - val_accuracy: 0.7086\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.3458 - accuracy: 0.8574 - val_loss: 0.4978 - val_accuracy: 0.7918\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.3347 - accuracy: 0.8639 - val_loss: 0.4892 - val_accuracy: 0.8039\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.3275 - accuracy: 0.8683 - val_loss: 0.5275 - val_accuracy: 0.7817\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.3185 - accuracy: 0.8732 - val_loss: 0.5872 - val_accuracy: 0.7408\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.3132 - accuracy: 0.8761 - val_loss: 0.4922 - val_accuracy: 0.8079\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.3076 - accuracy: 0.8777 - val_loss: 0.4886 - val_accuracy: 0.8131\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.3044 - accuracy: 0.8806 - val_loss: 0.5133 - val_accuracy: 0.7951\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2999 - accuracy: 0.8815 - val_loss: 0.4465 - val_accuracy: 0.8311\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2975 - accuracy: 0.8833 - val_loss: 0.5165 - val_accuracy: 0.8029\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2941 - accuracy: 0.8854 - val_loss: 0.4678 - val_accuracy: 0.8232\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2923 - accuracy: 0.8857 - val_loss: 0.4294 - val_accuracy: 0.8369\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2901 - accuracy: 0.8860 - val_loss: 0.4336 - val_accuracy: 0.8363\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2870 - accuracy: 0.8879 - val_loss: 0.4254 - val_accuracy: 0.8393\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2841 - accuracy: 0.8884 - val_loss: 0.6686 - val_accuracy: 0.7186\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2836 - accuracy: 0.8896 - val_loss: 0.5673 - val_accuracy: 0.7750\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2814 - accuracy: 0.8893 - val_loss: 0.5570 - val_accuracy: 0.7838\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2801 - accuracy: 0.8896 - val_loss: 0.5321 - val_accuracy: 0.7923\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2783 - accuracy: 0.8906 - val_loss: 0.4717 - val_accuracy: 0.8217\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2783 - accuracy: 0.8922 - val_loss: 0.4287 - val_accuracy: 0.8370\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2766 - accuracy: 0.8925 - val_loss: 0.5499 - val_accuracy: 0.7825\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2753 - accuracy: 0.8935 - val_loss: 0.5072 - val_accuracy: 0.8043\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2733 - accuracy: 0.8934 - val_loss: 0.5127 - val_accuracy: 0.8034\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 669us/step - loss: 0.2739 - accuracy: 0.8931 - val_loss: 0.4878 - val_accuracy: 0.8116\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.2725 - accuracy: 0.8940 - val_loss: 0.4222 - val_accuracy: 0.8384\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.2714 - accuracy: 0.8935 - val_loss: 0.4402 - val_accuracy: 0.8306\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.2707 - accuracy: 0.8948 - val_loss: 0.4011 - val_accuracy: 0.8450\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.2683 - accuracy: 0.8963 - val_loss: 0.4411 - val_accuracy: 0.8304\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.2681 - accuracy: 0.8955 - val_loss: 0.4403 - val_accuracy: 0.8303\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.2679 - accuracy: 0.8965 - val_loss: 0.4848 - val_accuracy: 0.8091\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.2662 - accuracy: 0.8972 - val_loss: 0.3783 - val_accuracy: 0.8548\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.2660 - accuracy: 0.8970 - val_loss: 0.5580 - val_accuracy: 0.7784\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2646 - accuracy: 0.8976 - val_loss: 0.4315 - val_accuracy: 0.8338\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.6459 - accuracy: 0.6317 - val_loss: 0.6548 - val_accuracy: 0.5954\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.5945 - accuracy: 0.6878 - val_loss: 0.6019 - val_accuracy: 0.6563\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5708 - accuracy: 0.7099 - val_loss: 0.6043 - val_accuracy: 0.6563\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.5561 - accuracy: 0.7186 - val_loss: 0.5947 - val_accuracy: 0.6637\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.5433 - accuracy: 0.7266 - val_loss: 0.6099 - val_accuracy: 0.6583\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.5326 - accuracy: 0.7332 - val_loss: 0.5955 - val_accuracy: 0.6750\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5249 - accuracy: 0.7357 - val_loss: 0.6025 - val_accuracy: 0.6721\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5172 - accuracy: 0.7403 - val_loss: 0.6127 - val_accuracy: 0.6650\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5086 - accuracy: 0.7449 - val_loss: 0.5774 - val_accuracy: 0.6913\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5023 - accuracy: 0.7493 - val_loss: 0.5811 - val_accuracy: 0.6900\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.4942 - accuracy: 0.7572 - val_loss: 0.6228 - val_accuracy: 0.6615\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.4862 - accuracy: 0.7606 - val_loss: 0.5620 - val_accuracy: 0.7045\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.4777 - accuracy: 0.7674 - val_loss: 0.5758 - val_accuracy: 0.6939\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.4684 - accuracy: 0.7739 - val_loss: 0.5605 - val_accuracy: 0.7061\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.4589 - accuracy: 0.7796 - val_loss: 0.5991 - val_accuracy: 0.6824\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.4488 - accuracy: 0.7872 - val_loss: 0.5115 - val_accuracy: 0.7553\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.4372 - accuracy: 0.7949 - val_loss: 0.7180 - val_accuracy: 0.6206\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.4238 - accuracy: 0.8046 - val_loss: 0.5836 - val_accuracy: 0.7041\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.4105 - accuracy: 0.8140 - val_loss: 0.5341 - val_accuracy: 0.7453\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.3967 - accuracy: 0.8244 - val_loss: 0.6029 - val_accuracy: 0.7024\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.3816 - accuracy: 0.8354 - val_loss: 0.5467 - val_accuracy: 0.7444\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.3682 - accuracy: 0.8440 - val_loss: 0.4264 - val_accuracy: 0.8346\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.3562 - accuracy: 0.8511 - val_loss: 0.5037 - val_accuracy: 0.7866\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.3460 - accuracy: 0.8571 - val_loss: 0.5420 - val_accuracy: 0.7656\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.3361 - accuracy: 0.8633 - val_loss: 0.4335 - val_accuracy: 0.8341\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.3286 - accuracy: 0.8688 - val_loss: 0.4645 - val_accuracy: 0.8200\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.3218 - accuracy: 0.8727 - val_loss: 0.3755 - val_accuracy: 0.8598\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.3165 - accuracy: 0.8750 - val_loss: 0.4488 - val_accuracy: 0.8283\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.3110 - accuracy: 0.8775 - val_loss: 0.5985 - val_accuracy: 0.7451\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.3071 - accuracy: 0.8789 - val_loss: 0.5202 - val_accuracy: 0.7927\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.3043 - accuracy: 0.8799 - val_loss: 0.4994 - val_accuracy: 0.8048\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.2994 - accuracy: 0.8823 - val_loss: 0.5397 - val_accuracy: 0.7844\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2979 - accuracy: 0.8831 - val_loss: 0.4775 - val_accuracy: 0.8192\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2953 - accuracy: 0.8828 - val_loss: 0.4702 - val_accuracy: 0.8213\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.2931 - accuracy: 0.8845 - val_loss: 0.3759 - val_accuracy: 0.8597\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.2921 - accuracy: 0.8849 - val_loss: 0.5073 - val_accuracy: 0.8053\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.2901 - accuracy: 0.8857 - val_loss: 0.4990 - val_accuracy: 0.8063\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2884 - accuracy: 0.8870 - val_loss: 0.5324 - val_accuracy: 0.7907\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2857 - accuracy: 0.8887 - val_loss: 0.4480 - val_accuracy: 0.8295\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.2843 - accuracy: 0.8887 - val_loss: 0.5123 - val_accuracy: 0.8015\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2832 - accuracy: 0.8889 - val_loss: 0.5313 - val_accuracy: 0.7897\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2828 - accuracy: 0.8902 - val_loss: 0.4309 - val_accuracy: 0.8362\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2822 - accuracy: 0.8884 - val_loss: 0.3849 - val_accuracy: 0.8554\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.2798 - accuracy: 0.8911 - val_loss: 0.5646 - val_accuracy: 0.7762\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2786 - accuracy: 0.8910 - val_loss: 0.3702 - val_accuracy: 0.8582\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2806 - accuracy: 0.8898 - val_loss: 0.4614 - val_accuracy: 0.8221\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2766 - accuracy: 0.8934 - val_loss: 0.4335 - val_accuracy: 0.8368\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2764 - accuracy: 0.8929 - val_loss: 0.5000 - val_accuracy: 0.8039\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2759 - accuracy: 0.8929 - val_loss: 0.4172 - val_accuracy: 0.8398\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2739 - accuracy: 0.8937 - val_loss: 0.4708 - val_accuracy: 0.8155\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.6288 - accuracy: 0.6680 - val_loss: 0.6547 - val_accuracy: 0.6017\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 417us/step - loss: 0.5747 - accuracy: 0.7179 - val_loss: 0.6139 - val_accuracy: 0.6394\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.5476 - accuracy: 0.7320 - val_loss: 0.5680 - val_accuracy: 0.6824\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.5291 - accuracy: 0.7391 - val_loss: 0.5987 - val_accuracy: 0.6616\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.5150 - accuracy: 0.7464 - val_loss: 0.6211 - val_accuracy: 0.6459\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5015 - accuracy: 0.7543 - val_loss: 0.5546 - val_accuracy: 0.6969\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.4893 - accuracy: 0.7616 - val_loss: 0.6041 - val_accuracy: 0.6631\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.4760 - accuracy: 0.7699 - val_loss: 0.5755 - val_accuracy: 0.6867\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.4636 - accuracy: 0.7796 - val_loss: 0.5927 - val_accuracy: 0.6738\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.4484 - accuracy: 0.7899 - val_loss: 0.5888 - val_accuracy: 0.6851\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.4333 - accuracy: 0.7997 - val_loss: 0.5112 - val_accuracy: 0.7558\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.4169 - accuracy: 0.8113 - val_loss: 0.5489 - val_accuracy: 0.7264\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.4016 - accuracy: 0.8238 - val_loss: 0.4680 - val_accuracy: 0.7974\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.3853 - accuracy: 0.8341 - val_loss: 0.5591 - val_accuracy: 0.7284\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3715 - accuracy: 0.8425 - val_loss: 0.6659 - val_accuracy: 0.6634\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.3575 - accuracy: 0.8514 - val_loss: 0.5561 - val_accuracy: 0.7475\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.3469 - accuracy: 0.8585 - val_loss: 0.4562 - val_accuracy: 0.8171\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.3350 - accuracy: 0.8656 - val_loss: 0.3999 - val_accuracy: 0.8452\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3265 - accuracy: 0.8691 - val_loss: 0.4069 - val_accuracy: 0.8413\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.3209 - accuracy: 0.8736 - val_loss: 0.4986 - val_accuracy: 0.7995\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3146 - accuracy: 0.8764 - val_loss: 0.5510 - val_accuracy: 0.7712\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.3076 - accuracy: 0.8783 - val_loss: 0.5246 - val_accuracy: 0.7881\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.3049 - accuracy: 0.8810 - val_loss: 0.4475 - val_accuracy: 0.8283\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.3008 - accuracy: 0.8815 - val_loss: 0.4680 - val_accuracy: 0.8206\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2989 - accuracy: 0.8834 - val_loss: 0.4408 - val_accuracy: 0.8309\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2959 - accuracy: 0.8851 - val_loss: 0.4011 - val_accuracy: 0.8478\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2936 - accuracy: 0.8864 - val_loss: 0.4245 - val_accuracy: 0.8391\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2919 - accuracy: 0.8864 - val_loss: 0.5117 - val_accuracy: 0.8015\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2892 - accuracy: 0.8875 - val_loss: 0.4359 - val_accuracy: 0.8336\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2874 - accuracy: 0.8878 - val_loss: 0.4655 - val_accuracy: 0.8228\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2866 - accuracy: 0.8879 - val_loss: 0.5239 - val_accuracy: 0.7964\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2859 - accuracy: 0.8888 - val_loss: 0.5089 - val_accuracy: 0.8033\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2834 - accuracy: 0.8901 - val_loss: 0.4995 - val_accuracy: 0.8085\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2827 - accuracy: 0.8888 - val_loss: 0.5374 - val_accuracy: 0.7881\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2821 - accuracy: 0.8918 - val_loss: 0.5179 - val_accuracy: 0.8016\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2801 - accuracy: 0.8918 - val_loss: 0.6199 - val_accuracy: 0.7463\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2799 - accuracy: 0.8920 - val_loss: 0.5754 - val_accuracy: 0.7712\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2784 - accuracy: 0.8918 - val_loss: 0.4881 - val_accuracy: 0.8117\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2775 - accuracy: 0.8933 - val_loss: 0.4962 - val_accuracy: 0.8069\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2756 - accuracy: 0.8937 - val_loss: 0.6019 - val_accuracy: 0.7603\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2761 - accuracy: 0.8932 - val_loss: 0.5228 - val_accuracy: 0.7970\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2739 - accuracy: 0.8953 - val_loss: 0.5427 - val_accuracy: 0.7866\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2738 - accuracy: 0.8936 - val_loss: 0.4414 - val_accuracy: 0.8291\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2735 - accuracy: 0.8959 - val_loss: 0.5023 - val_accuracy: 0.8049\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.2714 - accuracy: 0.8956 - val_loss: 0.4798 - val_accuracy: 0.8161\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2709 - accuracy: 0.8954 - val_loss: 0.5753 - val_accuracy: 0.7700\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2699 - accuracy: 0.8956 - val_loss: 0.5586 - val_accuracy: 0.7787\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2686 - accuracy: 0.8964 - val_loss: 0.4419 - val_accuracy: 0.8254\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2695 - accuracy: 0.8972 - val_loss: 0.4508 - val_accuracy: 0.8235\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.2690 - accuracy: 0.8965 - val_loss: 0.4639 - val_accuracy: 0.8172\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.6800 - accuracy: 0.5593 - val_loss: 0.6628 - val_accuracy: 0.6234\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.6206 - accuracy: 0.6583 - val_loss: 0.6164 - val_accuracy: 0.6708\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5839 - accuracy: 0.6874 - val_loss: 0.5901 - val_accuracy: 0.6809\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5551 - accuracy: 0.7162 - val_loss: 0.5788 - val_accuracy: 0.6821\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.5363 - accuracy: 0.7311 - val_loss: 0.6105 - val_accuracy: 0.6477\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.5211 - accuracy: 0.7406 - val_loss: 0.5614 - val_accuracy: 0.6876\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5088 - accuracy: 0.7484 - val_loss: 0.5878 - val_accuracy: 0.6687\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.4968 - accuracy: 0.7589 - val_loss: 0.6128 - val_accuracy: 0.6553\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.4856 - accuracy: 0.7657 - val_loss: 0.5812 - val_accuracy: 0.6778\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.4733 - accuracy: 0.7736 - val_loss: 0.5986 - val_accuracy: 0.6695\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.4608 - accuracy: 0.7837 - val_loss: 0.5621 - val_accuracy: 0.7020\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.4468 - accuracy: 0.7911 - val_loss: 0.5621 - val_accuracy: 0.7067\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.4331 - accuracy: 0.8023 - val_loss: 0.5550 - val_accuracy: 0.7172\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.4172 - accuracy: 0.8134 - val_loss: 0.4689 - val_accuracy: 0.7960\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.4003 - accuracy: 0.8263 - val_loss: 0.5232 - val_accuracy: 0.7540\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.3862 - accuracy: 0.8357 - val_loss: 0.5267 - val_accuracy: 0.7549\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3718 - accuracy: 0.8426 - val_loss: 0.5752 - val_accuracy: 0.7249\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.3582 - accuracy: 0.8515 - val_loss: 0.5193 - val_accuracy: 0.7704\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.3483 - accuracy: 0.8570 - val_loss: 0.5717 - val_accuracy: 0.7369\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.3383 - accuracy: 0.8631 - val_loss: 0.4237 - val_accuracy: 0.8337\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.3295 - accuracy: 0.8674 - val_loss: 0.5119 - val_accuracy: 0.7873\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.3217 - accuracy: 0.8718 - val_loss: 0.4574 - val_accuracy: 0.8211\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.3161 - accuracy: 0.8741 - val_loss: 0.5293 - val_accuracy: 0.7825\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.3091 - accuracy: 0.8775 - val_loss: 0.4725 - val_accuracy: 0.8165\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.3059 - accuracy: 0.8799 - val_loss: 0.4460 - val_accuracy: 0.8264\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.3028 - accuracy: 0.8788 - val_loss: 0.4660 - val_accuracy: 0.8181\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2993 - accuracy: 0.8826 - val_loss: 0.5535 - val_accuracy: 0.7754\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2959 - accuracy: 0.8833 - val_loss: 0.4556 - val_accuracy: 0.8227\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2922 - accuracy: 0.8863 - val_loss: 0.7407 - val_accuracy: 0.6764\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2917 - accuracy: 0.8855 - val_loss: 0.5656 - val_accuracy: 0.7716\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2880 - accuracy: 0.8868 - val_loss: 0.5157 - val_accuracy: 0.7966\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2849 - accuracy: 0.8882 - val_loss: 0.4396 - val_accuracy: 0.8300\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2837 - accuracy: 0.8899 - val_loss: 0.5135 - val_accuracy: 0.7969\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2823 - accuracy: 0.8899 - val_loss: 0.4079 - val_accuracy: 0.8436\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.2817 - accuracy: 0.8892 - val_loss: 0.4443 - val_accuracy: 0.8270\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2806 - accuracy: 0.8909 - val_loss: 0.4365 - val_accuracy: 0.8283\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.2778 - accuracy: 0.8915 - val_loss: 0.5157 - val_accuracy: 0.7956\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2771 - accuracy: 0.8919 - val_loss: 0.5144 - val_accuracy: 0.7983\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2741 - accuracy: 0.8933 - val_loss: 0.4994 - val_accuracy: 0.8028\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2746 - accuracy: 0.8917 - val_loss: 0.4101 - val_accuracy: 0.8388\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2731 - accuracy: 0.8932 - val_loss: 0.5385 - val_accuracy: 0.7869\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.2725 - accuracy: 0.8931 - val_loss: 0.5098 - val_accuracy: 0.8006\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2705 - accuracy: 0.8947 - val_loss: 0.5843 - val_accuracy: 0.7631\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.2684 - accuracy: 0.8954 - val_loss: 0.4578 - val_accuracy: 0.8213\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2688 - accuracy: 0.8946 - val_loss: 0.4780 - val_accuracy: 0.8104\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2685 - accuracy: 0.8957 - val_loss: 0.4344 - val_accuracy: 0.8280\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.2664 - accuracy: 0.8963 - val_loss: 0.4660 - val_accuracy: 0.8160\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.2661 - accuracy: 0.8961 - val_loss: 0.5702 - val_accuracy: 0.7709\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.2646 - accuracy: 0.8950 - val_loss: 0.4322 - val_accuracy: 0.8279\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2628 - accuracy: 0.8979 - val_loss: 0.4585 - val_accuracy: 0.8183\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.6698 - accuracy: 0.5739 - val_loss: 0.6414 - val_accuracy: 0.6720\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 414us/step - loss: 0.6182 - accuracy: 0.6723 - val_loss: 0.6294 - val_accuracy: 0.6389\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.5784 - accuracy: 0.7132 - val_loss: 0.6228 - val_accuracy: 0.6310\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.5489 - accuracy: 0.7327 - val_loss: 0.5889 - val_accuracy: 0.6605\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.5258 - accuracy: 0.7444 - val_loss: 0.5767 - val_accuracy: 0.6742\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.5072 - accuracy: 0.7538 - val_loss: 0.6010 - val_accuracy: 0.6548\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.4926 - accuracy: 0.7608 - val_loss: 0.5466 - val_accuracy: 0.6994\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.4773 - accuracy: 0.7710 - val_loss: 0.5439 - val_accuracy: 0.7039\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.4612 - accuracy: 0.7814 - val_loss: 0.5762 - val_accuracy: 0.6821\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.4459 - accuracy: 0.7924 - val_loss: 0.5808 - val_accuracy: 0.6824\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.4301 - accuracy: 0.8030 - val_loss: 0.5626 - val_accuracy: 0.6999\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.4148 - accuracy: 0.8151 - val_loss: 0.5264 - val_accuracy: 0.7373\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.3975 - accuracy: 0.8258 - val_loss: 0.5469 - val_accuracy: 0.7230\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.3815 - accuracy: 0.8369 - val_loss: 0.5379 - val_accuracy: 0.7415\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.3668 - accuracy: 0.8470 - val_loss: 0.4386 - val_accuracy: 0.8179\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3550 - accuracy: 0.8534 - val_loss: 0.5975 - val_accuracy: 0.7110\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.3419 - accuracy: 0.8608 - val_loss: 0.3680 - val_accuracy: 0.8570\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.3321 - accuracy: 0.8674 - val_loss: 0.4117 - val_accuracy: 0.8374\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3225 - accuracy: 0.8713 - val_loss: 0.5005 - val_accuracy: 0.7931\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.3155 - accuracy: 0.8749 - val_loss: 0.4750 - val_accuracy: 0.8116\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.3094 - accuracy: 0.8774 - val_loss: 0.3830 - val_accuracy: 0.8520\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.3030 - accuracy: 0.8813 - val_loss: 0.3571 - val_accuracy: 0.8624\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.3007 - accuracy: 0.8818 - val_loss: 0.4575 - val_accuracy: 0.8213\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2956 - accuracy: 0.8855 - val_loss: 0.4698 - val_accuracy: 0.8157\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.2933 - accuracy: 0.8856 - val_loss: 0.5474 - val_accuracy: 0.7786\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2902 - accuracy: 0.8871 - val_loss: 0.4216 - val_accuracy: 0.8363\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.2864 - accuracy: 0.8879 - val_loss: 0.6405 - val_accuracy: 0.7323\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2855 - accuracy: 0.8892 - val_loss: 0.5091 - val_accuracy: 0.8017\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2839 - accuracy: 0.8895 - val_loss: 0.5024 - val_accuracy: 0.8032\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2821 - accuracy: 0.8899 - val_loss: 0.5653 - val_accuracy: 0.7740\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2795 - accuracy: 0.8911 - val_loss: 0.3448 - val_accuracy: 0.8675\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2775 - accuracy: 0.8912 - val_loss: 0.3984 - val_accuracy: 0.8458\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2773 - accuracy: 0.8921 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.2754 - accuracy: 0.8926 - val_loss: 0.4318 - val_accuracy: 0.8315\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2747 - accuracy: 0.8949 - val_loss: 0.5697 - val_accuracy: 0.7741\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2732 - accuracy: 0.8932 - val_loss: 0.5113 - val_accuracy: 0.7966\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2712 - accuracy: 0.8948 - val_loss: 0.4016 - val_accuracy: 0.8439\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2709 - accuracy: 0.8932 - val_loss: 0.5592 - val_accuracy: 0.7774\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2698 - accuracy: 0.8955 - val_loss: 0.5656 - val_accuracy: 0.7697\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2683 - accuracy: 0.8952 - val_loss: 0.4019 - val_accuracy: 0.8416\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2689 - accuracy: 0.8943 - val_loss: 0.4576 - val_accuracy: 0.8194\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.2667 - accuracy: 0.8954 - val_loss: 0.4122 - val_accuracy: 0.8390\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2655 - accuracy: 0.8972 - val_loss: 0.3995 - val_accuracy: 0.8425\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2667 - accuracy: 0.8961 - val_loss: 0.4406 - val_accuracy: 0.8237\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.2653 - accuracy: 0.8959 - val_loss: 0.4416 - val_accuracy: 0.8225\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2641 - accuracy: 0.8959 - val_loss: 0.4057 - val_accuracy: 0.8415\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2637 - accuracy: 0.8967 - val_loss: 0.6486 - val_accuracy: 0.7287\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2633 - accuracy: 0.8975 - val_loss: 0.5246 - val_accuracy: 0.7917\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2623 - accuracy: 0.8982 - val_loss: 0.5242 - val_accuracy: 0.7942\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.2605 - accuracy: 0.8998 - val_loss: 0.3942 - val_accuracy: 0.8451\n",
      "\n",
      "Training model with sample_size_ratio=0.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6784 - accuracy: 0.5738 - val_loss: 0.6905 - val_accuracy: 0.5473\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6437 - accuracy: 0.6413 - val_loss: 0.7120 - val_accuracy: 0.5210\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6177 - accuracy: 0.6673 - val_loss: 0.6471 - val_accuracy: 0.6125\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5954 - accuracy: 0.6874 - val_loss: 0.6104 - val_accuracy: 0.6476\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5782 - accuracy: 0.7023 - val_loss: 0.6418 - val_accuracy: 0.6075\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5632 - accuracy: 0.7132 - val_loss: 0.6269 - val_accuracy: 0.6245\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5503 - accuracy: 0.7204 - val_loss: 0.5661 - val_accuracy: 0.6740\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5399 - accuracy: 0.7297 - val_loss: 0.5889 - val_accuracy: 0.6522\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5321 - accuracy: 0.7347 - val_loss: 0.6232 - val_accuracy: 0.6258\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.5234 - accuracy: 0.7414 - val_loss: 0.5820 - val_accuracy: 0.6613\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5171 - accuracy: 0.7444 - val_loss: 0.6061 - val_accuracy: 0.6399\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5092 - accuracy: 0.7501 - val_loss: 0.6015 - val_accuracy: 0.6461\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5037 - accuracy: 0.7540 - val_loss: 0.5266 - val_accuracy: 0.7177\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.4976 - accuracy: 0.7554 - val_loss: 0.5874 - val_accuracy: 0.6628\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.4899 - accuracy: 0.7618 - val_loss: 0.5969 - val_accuracy: 0.6571\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.4847 - accuracy: 0.7667 - val_loss: 0.6198 - val_accuracy: 0.6422\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.4782 - accuracy: 0.7710 - val_loss: 0.5929 - val_accuracy: 0.6665\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.4725 - accuracy: 0.7753 - val_loss: 0.5818 - val_accuracy: 0.6769\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.4638 - accuracy: 0.7816 - val_loss: 0.5817 - val_accuracy: 0.6778\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.4574 - accuracy: 0.7859 - val_loss: 0.5398 - val_accuracy: 0.7156\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.4516 - accuracy: 0.7898 - val_loss: 0.5669 - val_accuracy: 0.6926\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.4427 - accuracy: 0.7967 - val_loss: 0.5596 - val_accuracy: 0.7051\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.4339 - accuracy: 0.8015 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.4261 - accuracy: 0.8069 - val_loss: 0.5191 - val_accuracy: 0.7455\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.4169 - accuracy: 0.8149 - val_loss: 0.4968 - val_accuracy: 0.7679\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.4082 - accuracy: 0.8214 - val_loss: 0.5548 - val_accuracy: 0.7221\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.4013 - accuracy: 0.8238 - val_loss: 0.5074 - val_accuracy: 0.7609\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.3932 - accuracy: 0.8320 - val_loss: 0.5154 - val_accuracy: 0.7549\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.3843 - accuracy: 0.8360 - val_loss: 0.5229 - val_accuracy: 0.7528\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.3754 - accuracy: 0.8417 - val_loss: 0.4853 - val_accuracy: 0.7861\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.3685 - accuracy: 0.8478 - val_loss: 0.5425 - val_accuracy: 0.7452\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.3605 - accuracy: 0.8516 - val_loss: 0.5266 - val_accuracy: 0.7592\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.3530 - accuracy: 0.8556 - val_loss: 0.5189 - val_accuracy: 0.7681\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.3495 - accuracy: 0.8581 - val_loss: 0.5272 - val_accuracy: 0.7645\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.3410 - accuracy: 0.8641 - val_loss: 0.4447 - val_accuracy: 0.8211\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.3356 - accuracy: 0.8680 - val_loss: 0.4892 - val_accuracy: 0.7935\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.3298 - accuracy: 0.8696 - val_loss: 0.4846 - val_accuracy: 0.7982\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.3266 - accuracy: 0.8710 - val_loss: 0.4681 - val_accuracy: 0.8106\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.3221 - accuracy: 0.8731 - val_loss: 0.4188 - val_accuracy: 0.8336\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.3180 - accuracy: 0.8744 - val_loss: 0.4806 - val_accuracy: 0.8061\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.3147 - accuracy: 0.8756 - val_loss: 0.6044 - val_accuracy: 0.7262\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.3114 - accuracy: 0.8790 - val_loss: 0.4122 - val_accuracy: 0.8372\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.3075 - accuracy: 0.8806 - val_loss: 0.4619 - val_accuracy: 0.8170\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.3054 - accuracy: 0.8809 - val_loss: 0.4157 - val_accuracy: 0.8351\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.3030 - accuracy: 0.8811 - val_loss: 0.5101 - val_accuracy: 0.7908\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.3007 - accuracy: 0.8815 - val_loss: 0.3612 - val_accuracy: 0.8587\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.2977 - accuracy: 0.8845 - val_loss: 0.4973 - val_accuracy: 0.7994\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.2974 - accuracy: 0.8827 - val_loss: 0.5489 - val_accuracy: 0.7722\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.2937 - accuracy: 0.8857 - val_loss: 0.4017 - val_accuracy: 0.8436\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.2925 - accuracy: 0.8855 - val_loss: 0.4207 - val_accuracy: 0.8359\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.6728 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6480 - accuracy: 0.6322 - val_loss: 0.6641 - val_accuracy: 0.6109\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6172 - accuracy: 0.6725 - val_loss: 0.6318 - val_accuracy: 0.6407\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5990 - accuracy: 0.6886 - val_loss: 0.6572 - val_accuracy: 0.6095\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5849 - accuracy: 0.7014 - val_loss: 0.6051 - val_accuracy: 0.6556\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.5709 - accuracy: 0.7118 - val_loss: 0.6054 - val_accuracy: 0.6581\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5606 - accuracy: 0.7173 - val_loss: 0.6182 - val_accuracy: 0.6431\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.5514 - accuracy: 0.7218 - val_loss: 0.6076 - val_accuracy: 0.6566\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5446 - accuracy: 0.7278 - val_loss: 0.5935 - val_accuracy: 0.6706\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5382 - accuracy: 0.7313 - val_loss: 0.6066 - val_accuracy: 0.6530\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5306 - accuracy: 0.7364 - val_loss: 0.5662 - val_accuracy: 0.6916\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5255 - accuracy: 0.7361 - val_loss: 0.5907 - val_accuracy: 0.6701\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5202 - accuracy: 0.7433 - val_loss: 0.5878 - val_accuracy: 0.6721\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5137 - accuracy: 0.7456 - val_loss: 0.6060 - val_accuracy: 0.6569\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5099 - accuracy: 0.7466 - val_loss: 0.5851 - val_accuracy: 0.6738\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5052 - accuracy: 0.7498 - val_loss: 0.5933 - val_accuracy: 0.6683\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5000 - accuracy: 0.7536 - val_loss: 0.5833 - val_accuracy: 0.6768\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.4944 - accuracy: 0.7568 - val_loss: 0.5919 - val_accuracy: 0.6721\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.4903 - accuracy: 0.7595 - val_loss: 0.6046 - val_accuracy: 0.6632\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.4853 - accuracy: 0.7633 - val_loss: 0.5840 - val_accuracy: 0.6813\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.4799 - accuracy: 0.7666 - val_loss: 0.6022 - val_accuracy: 0.6686\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.4752 - accuracy: 0.7676 - val_loss: 0.6047 - val_accuracy: 0.6685\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.4708 - accuracy: 0.7716 - val_loss: 0.5497 - val_accuracy: 0.7136\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.4645 - accuracy: 0.7753 - val_loss: 0.5342 - val_accuracy: 0.7280\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.4569 - accuracy: 0.7826 - val_loss: 0.5993 - val_accuracy: 0.6763\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.4524 - accuracy: 0.7850 - val_loss: 0.5758 - val_accuracy: 0.6963\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.4444 - accuracy: 0.7895 - val_loss: 0.6023 - val_accuracy: 0.6789\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.4383 - accuracy: 0.7952 - val_loss: 0.6086 - val_accuracy: 0.6778\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.4304 - accuracy: 0.7998 - val_loss: 0.5238 - val_accuracy: 0.7423\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.4241 - accuracy: 0.8022 - val_loss: 0.5688 - val_accuracy: 0.7105\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.4166 - accuracy: 0.8097 - val_loss: 0.5562 - val_accuracy: 0.7221\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.4089 - accuracy: 0.8146 - val_loss: 0.5009 - val_accuracy: 0.7678\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.4014 - accuracy: 0.8207 - val_loss: 0.6051 - val_accuracy: 0.6931\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.3935 - accuracy: 0.8258 - val_loss: 0.5803 - val_accuracy: 0.7119\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.3850 - accuracy: 0.8337 - val_loss: 0.5325 - val_accuracy: 0.7489\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.3802 - accuracy: 0.8381 - val_loss: 0.5321 - val_accuracy: 0.7524\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.3710 - accuracy: 0.8431 - val_loss: 0.5062 - val_accuracy: 0.7733\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.3621 - accuracy: 0.8507 - val_loss: 0.5837 - val_accuracy: 0.7213\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.3572 - accuracy: 0.8513 - val_loss: 0.5215 - val_accuracy: 0.7677\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.3507 - accuracy: 0.8556 - val_loss: 0.4690 - val_accuracy: 0.8038\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.3441 - accuracy: 0.8606 - val_loss: 0.4068 - val_accuracy: 0.8384\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.3397 - accuracy: 0.8620 - val_loss: 0.5008 - val_accuracy: 0.7843\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.3344 - accuracy: 0.8649 - val_loss: 0.5436 - val_accuracy: 0.7607\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.3288 - accuracy: 0.8664 - val_loss: 0.4021 - val_accuracy: 0.8426\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.3253 - accuracy: 0.8701 - val_loss: 0.4106 - val_accuracy: 0.8387\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.3216 - accuracy: 0.8724 - val_loss: 0.4609 - val_accuracy: 0.8170\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.3179 - accuracy: 0.8750 - val_loss: 0.4447 - val_accuracy: 0.8248\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.3154 - accuracy: 0.8744 - val_loss: 0.4388 - val_accuracy: 0.8270\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.3115 - accuracy: 0.8782 - val_loss: 0.5711 - val_accuracy: 0.7543\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.3096 - accuracy: 0.8761 - val_loss: 0.4557 - val_accuracy: 0.8215\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.3062 - accuracy: 0.8791 - val_loss: 0.4835 - val_accuracy: 0.8091\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6556 - accuracy: 0.6174 - val_loss: 0.6724 - val_accuracy: 0.5919\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6218 - accuracy: 0.6638 - val_loss: 0.6115 - val_accuracy: 0.6428\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6008 - accuracy: 0.6818 - val_loss: 0.6432 - val_accuracy: 0.6078\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5844 - accuracy: 0.6937 - val_loss: 0.6067 - val_accuracy: 0.6349\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5725 - accuracy: 0.7029 - val_loss: 0.6239 - val_accuracy: 0.6239\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.5623 - accuracy: 0.7101 - val_loss: 0.6077 - val_accuracy: 0.6466\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5498 - accuracy: 0.7183 - val_loss: 0.5459 - val_accuracy: 0.7175\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5440 - accuracy: 0.7220 - val_loss: 0.6152 - val_accuracy: 0.6475\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5354 - accuracy: 0.7282 - val_loss: 0.5852 - val_accuracy: 0.6752\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5280 - accuracy: 0.7349 - val_loss: 0.6009 - val_accuracy: 0.6640\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5242 - accuracy: 0.7327 - val_loss: 0.6427 - val_accuracy: 0.6248\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5166 - accuracy: 0.7407 - val_loss: 0.6320 - val_accuracy: 0.6345\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5110 - accuracy: 0.7467 - val_loss: 0.6264 - val_accuracy: 0.6413\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5040 - accuracy: 0.7489 - val_loss: 0.5770 - val_accuracy: 0.6872\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.4986 - accuracy: 0.7516 - val_loss: 0.6013 - val_accuracy: 0.6643\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.4950 - accuracy: 0.7561 - val_loss: 0.6049 - val_accuracy: 0.6642\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.4880 - accuracy: 0.7617 - val_loss: 0.5943 - val_accuracy: 0.6752\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.4828 - accuracy: 0.7644 - val_loss: 0.6327 - val_accuracy: 0.6424\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.4766 - accuracy: 0.7679 - val_loss: 0.5805 - val_accuracy: 0.6908\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.4721 - accuracy: 0.7699 - val_loss: 0.6165 - val_accuracy: 0.6615\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.4640 - accuracy: 0.7777 - val_loss: 0.6353 - val_accuracy: 0.6506\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.4583 - accuracy: 0.7825 - val_loss: 0.5491 - val_accuracy: 0.7249\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.4521 - accuracy: 0.7885 - val_loss: 0.5904 - val_accuracy: 0.6915\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.4451 - accuracy: 0.7928 - val_loss: 0.5845 - val_accuracy: 0.7001\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.4396 - accuracy: 0.7963 - val_loss: 0.5745 - val_accuracy: 0.7104\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.4325 - accuracy: 0.8009 - val_loss: 0.5783 - val_accuracy: 0.7094\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.4249 - accuracy: 0.8067 - val_loss: 0.5325 - val_accuracy: 0.7477\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.4193 - accuracy: 0.8101 - val_loss: 0.5298 - val_accuracy: 0.7501\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.4112 - accuracy: 0.8158 - val_loss: 0.5543 - val_accuracy: 0.7321\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.4042 - accuracy: 0.8220 - val_loss: 0.5044 - val_accuracy: 0.7739\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.3946 - accuracy: 0.8279 - val_loss: 0.5782 - val_accuracy: 0.7154\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.3886 - accuracy: 0.8316 - val_loss: 0.4422 - val_accuracy: 0.8220\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.3817 - accuracy: 0.8354 - val_loss: 0.4670 - val_accuracy: 0.8068\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.3744 - accuracy: 0.8420 - val_loss: 0.4774 - val_accuracy: 0.8008\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.3665 - accuracy: 0.8474 - val_loss: 0.5001 - val_accuracy: 0.7866\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.3608 - accuracy: 0.8500 - val_loss: 0.5320 - val_accuracy: 0.7652\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.3549 - accuracy: 0.8549 - val_loss: 0.5943 - val_accuracy: 0.7225\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.3473 - accuracy: 0.8589 - val_loss: 0.6185 - val_accuracy: 0.7095\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.3427 - accuracy: 0.8609 - val_loss: 0.4354 - val_accuracy: 0.8285\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.3384 - accuracy: 0.8628 - val_loss: 0.5152 - val_accuracy: 0.7848\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.3330 - accuracy: 0.8670 - val_loss: 0.4722 - val_accuracy: 0.8112\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.3295 - accuracy: 0.8701 - val_loss: 0.4293 - val_accuracy: 0.8299\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.3253 - accuracy: 0.8713 - val_loss: 0.4478 - val_accuracy: 0.8267\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.3199 - accuracy: 0.8743 - val_loss: 0.4879 - val_accuracy: 0.8077\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.3153 - accuracy: 0.8764 - val_loss: 0.4918 - val_accuracy: 0.8050\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.3132 - accuracy: 0.8761 - val_loss: 0.4600 - val_accuracy: 0.8222\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.3104 - accuracy: 0.8789 - val_loss: 0.4072 - val_accuracy: 0.8423\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.3062 - accuracy: 0.8791 - val_loss: 0.4056 - val_accuracy: 0.8437\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.3045 - accuracy: 0.8805 - val_loss: 0.4915 - val_accuracy: 0.8061\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.3029 - accuracy: 0.8814 - val_loss: 0.4595 - val_accuracy: 0.8236\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6581 - accuracy: 0.6074 - val_loss: 0.6464 - val_accuracy: 0.6227\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6192 - accuracy: 0.6651 - val_loss: 0.6465 - val_accuracy: 0.6164\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5943 - accuracy: 0.6952 - val_loss: 0.6060 - val_accuracy: 0.6618\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5781 - accuracy: 0.7050 - val_loss: 0.5688 - val_accuracy: 0.6997\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5625 - accuracy: 0.7196 - val_loss: 0.6029 - val_accuracy: 0.6601\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5501 - accuracy: 0.7265 - val_loss: 0.6035 - val_accuracy: 0.6559\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.5400 - accuracy: 0.7333 - val_loss: 0.6200 - val_accuracy: 0.6464\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5298 - accuracy: 0.7375 - val_loss: 0.5957 - val_accuracy: 0.6629\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5232 - accuracy: 0.7429 - val_loss: 0.5716 - val_accuracy: 0.6817\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5147 - accuracy: 0.7472 - val_loss: 0.6079 - val_accuracy: 0.6524\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5074 - accuracy: 0.7492 - val_loss: 0.5531 - val_accuracy: 0.6929\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5009 - accuracy: 0.7553 - val_loss: 0.5965 - val_accuracy: 0.6656\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.4941 - accuracy: 0.7579 - val_loss: 0.5921 - val_accuracy: 0.6696\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.4882 - accuracy: 0.7613 - val_loss: 0.5662 - val_accuracy: 0.6868\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.4831 - accuracy: 0.7644 - val_loss: 0.5921 - val_accuracy: 0.6723\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.4783 - accuracy: 0.7678 - val_loss: 0.5608 - val_accuracy: 0.6949\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.4700 - accuracy: 0.7731 - val_loss: 0.5432 - val_accuracy: 0.7086\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.4640 - accuracy: 0.7775 - val_loss: 0.4893 - val_accuracy: 0.7615\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.4567 - accuracy: 0.7800 - val_loss: 0.5506 - val_accuracy: 0.7054\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.4510 - accuracy: 0.7848 - val_loss: 0.5652 - val_accuracy: 0.6971\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.4443 - accuracy: 0.7918 - val_loss: 0.5162 - val_accuracy: 0.7390\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.4353 - accuracy: 0.7974 - val_loss: 0.5992 - val_accuracy: 0.6781\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.4286 - accuracy: 0.8007 - val_loss: 0.6007 - val_accuracy: 0.6802\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.4212 - accuracy: 0.8056 - val_loss: 0.5475 - val_accuracy: 0.7213\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.4113 - accuracy: 0.8143 - val_loss: 0.5277 - val_accuracy: 0.7379\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.4057 - accuracy: 0.8168 - val_loss: 0.5144 - val_accuracy: 0.7515\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.3985 - accuracy: 0.8229 - val_loss: 0.5593 - val_accuracy: 0.7203\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.3925 - accuracy: 0.8288 - val_loss: 0.4460 - val_accuracy: 0.8119\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.3829 - accuracy: 0.8336 - val_loss: 0.5715 - val_accuracy: 0.7167\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.3759 - accuracy: 0.8398 - val_loss: 0.5005 - val_accuracy: 0.7715\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.3690 - accuracy: 0.8426 - val_loss: 0.4862 - val_accuracy: 0.7877\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.3648 - accuracy: 0.8475 - val_loss: 0.5214 - val_accuracy: 0.7626\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.3559 - accuracy: 0.8518 - val_loss: 0.4824 - val_accuracy: 0.7943\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.3516 - accuracy: 0.8564 - val_loss: 0.5185 - val_accuracy: 0.7713\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.3469 - accuracy: 0.8569 - val_loss: 0.4966 - val_accuracy: 0.7913\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.3386 - accuracy: 0.8612 - val_loss: 0.4218 - val_accuracy: 0.8370\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.3339 - accuracy: 0.8639 - val_loss: 0.4718 - val_accuracy: 0.8085\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.3315 - accuracy: 0.8669 - val_loss: 0.5123 - val_accuracy: 0.7848\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.3282 - accuracy: 0.8663 - val_loss: 0.6011 - val_accuracy: 0.7264\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.3236 - accuracy: 0.8678 - val_loss: 0.3978 - val_accuracy: 0.8457\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.3181 - accuracy: 0.8756 - val_loss: 0.3764 - val_accuracy: 0.8576\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.3167 - accuracy: 0.8744 - val_loss: 0.4174 - val_accuracy: 0.8394\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.3144 - accuracy: 0.8753 - val_loss: 0.4422 - val_accuracy: 0.8286\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.3105 - accuracy: 0.8765 - val_loss: 0.4396 - val_accuracy: 0.8288\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.3062 - accuracy: 0.8794 - val_loss: 0.4451 - val_accuracy: 0.8293\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.3053 - accuracy: 0.8803 - val_loss: 0.5014 - val_accuracy: 0.8037\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.3034 - accuracy: 0.8818 - val_loss: 0.5609 - val_accuracy: 0.7684\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.3009 - accuracy: 0.8827 - val_loss: 0.5148 - val_accuracy: 0.7952\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.3009 - accuracy: 0.8800 - val_loss: 0.4813 - val_accuracy: 0.8140\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.2982 - accuracy: 0.8817 - val_loss: 0.5267 - val_accuracy: 0.7910\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6675 - accuracy: 0.5986 - val_loss: 0.6666 - val_accuracy: 0.6318\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6375 - accuracy: 0.6491 - val_loss: 0.6580 - val_accuracy: 0.6232\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6114 - accuracy: 0.6774 - val_loss: 0.6112 - val_accuracy: 0.6799\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5934 - accuracy: 0.6872 - val_loss: 0.6241 - val_accuracy: 0.6543\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5770 - accuracy: 0.7047 - val_loss: 0.6340 - val_accuracy: 0.6343\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5622 - accuracy: 0.7179 - val_loss: 0.6138 - val_accuracy: 0.6561\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5498 - accuracy: 0.7257 - val_loss: 0.5996 - val_accuracy: 0.6708\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5385 - accuracy: 0.7317 - val_loss: 0.6241 - val_accuracy: 0.6468\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5294 - accuracy: 0.7368 - val_loss: 0.6104 - val_accuracy: 0.6589\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5222 - accuracy: 0.7414 - val_loss: 0.5472 - val_accuracy: 0.7055\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5149 - accuracy: 0.7467 - val_loss: 0.6099 - val_accuracy: 0.6590\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5078 - accuracy: 0.7517 - val_loss: 0.5899 - val_accuracy: 0.6738\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5920 - val_accuracy: 0.6719\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.4964 - accuracy: 0.7560 - val_loss: 0.6285 - val_accuracy: 0.6470\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.4904 - accuracy: 0.7608 - val_loss: 0.5569 - val_accuracy: 0.6980\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.4848 - accuracy: 0.7632 - val_loss: 0.5729 - val_accuracy: 0.6885\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.4776 - accuracy: 0.7700 - val_loss: 0.6078 - val_accuracy: 0.6654\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.4731 - accuracy: 0.7725 - val_loss: 0.5856 - val_accuracy: 0.6824\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.4653 - accuracy: 0.7761 - val_loss: 0.5999 - val_accuracy: 0.6741\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.4608 - accuracy: 0.7826 - val_loss: 0.6144 - val_accuracy: 0.6663\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.4548 - accuracy: 0.7840 - val_loss: 0.5550 - val_accuracy: 0.7146\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.4480 - accuracy: 0.7909 - val_loss: 0.5168 - val_accuracy: 0.7488\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.4409 - accuracy: 0.7949 - val_loss: 0.5919 - val_accuracy: 0.6898\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.4338 - accuracy: 0.8010 - val_loss: 0.5748 - val_accuracy: 0.7054\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.4243 - accuracy: 0.8064 - val_loss: 0.5584 - val_accuracy: 0.7203\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.4167 - accuracy: 0.8132 - val_loss: 0.4762 - val_accuracy: 0.7882\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.4102 - accuracy: 0.8161 - val_loss: 0.6437 - val_accuracy: 0.6596\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.4034 - accuracy: 0.8209 - val_loss: 0.6309 - val_accuracy: 0.6706\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.3934 - accuracy: 0.8274 - val_loss: 0.5897 - val_accuracy: 0.7015\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.3872 - accuracy: 0.8320 - val_loss: 0.5221 - val_accuracy: 0.7584\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.3778 - accuracy: 0.8393 - val_loss: 0.5158 - val_accuracy: 0.7668\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.3720 - accuracy: 0.8431 - val_loss: 0.5229 - val_accuracy: 0.7618\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.3639 - accuracy: 0.8499 - val_loss: 0.4483 - val_accuracy: 0.8165\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.3583 - accuracy: 0.8527 - val_loss: 0.6447 - val_accuracy: 0.6806\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.3514 - accuracy: 0.8557 - val_loss: 0.4947 - val_accuracy: 0.7868\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.3444 - accuracy: 0.8610 - val_loss: 0.5432 - val_accuracy: 0.7592\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.3398 - accuracy: 0.8632 - val_loss: 0.5245 - val_accuracy: 0.7736\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.3327 - accuracy: 0.8660 - val_loss: 0.4867 - val_accuracy: 0.7983\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.3285 - accuracy: 0.8704 - val_loss: 0.5465 - val_accuracy: 0.7630\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.3248 - accuracy: 0.8704 - val_loss: 0.5041 - val_accuracy: 0.7918\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.3203 - accuracy: 0.8741 - val_loss: 0.6092 - val_accuracy: 0.7261\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.3174 - accuracy: 0.8740 - val_loss: 0.4903 - val_accuracy: 0.8027\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.3142 - accuracy: 0.8772 - val_loss: 0.5450 - val_accuracy: 0.7711\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.3102 - accuracy: 0.8781 - val_loss: 0.4359 - val_accuracy: 0.8291\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.3068 - accuracy: 0.8816 - val_loss: 0.5576 - val_accuracy: 0.7658\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.3056 - accuracy: 0.8815 - val_loss: 0.3941 - val_accuracy: 0.8464\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.3022 - accuracy: 0.8830 - val_loss: 0.6587 - val_accuracy: 0.7074\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.3001 - accuracy: 0.8853 - val_loss: 0.5079 - val_accuracy: 0.7963\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.2974 - accuracy: 0.8835 - val_loss: 0.4708 - val_accuracy: 0.8163\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.2969 - accuracy: 0.8849 - val_loss: 0.5145 - val_accuracy: 0.7955\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6684 - accuracy: 0.5974 - val_loss: 0.6865 - val_accuracy: 0.5462\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6353 - accuracy: 0.6554 - val_loss: 0.6435 - val_accuracy: 0.6148\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6143 - accuracy: 0.6732 - val_loss: 0.6159 - val_accuracy: 0.6415\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5984 - accuracy: 0.6879 - val_loss: 0.6229 - val_accuracy: 0.6277\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5861 - accuracy: 0.6979 - val_loss: 0.6516 - val_accuracy: 0.5945\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.5727 - accuracy: 0.7078 - val_loss: 0.5901 - val_accuracy: 0.6570\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5648 - accuracy: 0.7136 - val_loss: 0.6208 - val_accuracy: 0.6245\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5535 - accuracy: 0.7192 - val_loss: 0.6206 - val_accuracy: 0.6240\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5471 - accuracy: 0.7246 - val_loss: 0.5864 - val_accuracy: 0.6624\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.5411 - accuracy: 0.7266 - val_loss: 0.6468 - val_accuracy: 0.6085\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5326 - accuracy: 0.7318 - val_loss: 0.6075 - val_accuracy: 0.6460\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5278 - accuracy: 0.7370 - val_loss: 0.6002 - val_accuracy: 0.6542\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5220 - accuracy: 0.7394 - val_loss: 0.5970 - val_accuracy: 0.6597\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5140 - accuracy: 0.7450 - val_loss: 0.6157 - val_accuracy: 0.6454\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5098 - accuracy: 0.7485 - val_loss: 0.5884 - val_accuracy: 0.6678\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5035 - accuracy: 0.7531 - val_loss: 0.5855 - val_accuracy: 0.6697\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.4988 - accuracy: 0.7556 - val_loss: 0.6136 - val_accuracy: 0.6480\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.4921 - accuracy: 0.7595 - val_loss: 0.5960 - val_accuracy: 0.6618\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.4866 - accuracy: 0.7652 - val_loss: 0.6209 - val_accuracy: 0.6438\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.4795 - accuracy: 0.7698 - val_loss: 0.5475 - val_accuracy: 0.7078\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.4738 - accuracy: 0.7710 - val_loss: 0.6341 - val_accuracy: 0.6396\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.4677 - accuracy: 0.7759 - val_loss: 0.5765 - val_accuracy: 0.6840\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.4602 - accuracy: 0.7833 - val_loss: 0.6275 - val_accuracy: 0.6483\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.4550 - accuracy: 0.7851 - val_loss: 0.6239 - val_accuracy: 0.6540\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.4471 - accuracy: 0.7906 - val_loss: 0.6255 - val_accuracy: 0.6548\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.4385 - accuracy: 0.7962 - val_loss: 0.6686 - val_accuracy: 0.6299\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.4307 - accuracy: 0.8034 - val_loss: 0.5891 - val_accuracy: 0.6843\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.4235 - accuracy: 0.8103 - val_loss: 0.5395 - val_accuracy: 0.7295\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.4151 - accuracy: 0.8144 - val_loss: 0.5417 - val_accuracy: 0.7287\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.4068 - accuracy: 0.8198 - val_loss: 0.5560 - val_accuracy: 0.7198\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.3993 - accuracy: 0.8258 - val_loss: 0.5647 - val_accuracy: 0.7140\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.3911 - accuracy: 0.8312 - val_loss: 0.4823 - val_accuracy: 0.7818\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.3817 - accuracy: 0.8366 - val_loss: 0.5440 - val_accuracy: 0.7374\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.3745 - accuracy: 0.8427 - val_loss: 0.4784 - val_accuracy: 0.7868\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.3671 - accuracy: 0.8458 - val_loss: 0.5983 - val_accuracy: 0.7040\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.3607 - accuracy: 0.8525 - val_loss: 0.5414 - val_accuracy: 0.7455\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.3539 - accuracy: 0.8561 - val_loss: 0.5587 - val_accuracy: 0.7388\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.3489 - accuracy: 0.8586 - val_loss: 0.5192 - val_accuracy: 0.7661\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.3415 - accuracy: 0.8613 - val_loss: 0.4525 - val_accuracy: 0.8126\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.3364 - accuracy: 0.8666 - val_loss: 0.5172 - val_accuracy: 0.7726\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.3305 - accuracy: 0.8682 - val_loss: 0.5142 - val_accuracy: 0.7784\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.3260 - accuracy: 0.8692 - val_loss: 0.5295 - val_accuracy: 0.7701\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.3213 - accuracy: 0.8709 - val_loss: 0.4485 - val_accuracy: 0.8200\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.3176 - accuracy: 0.8744 - val_loss: 0.4280 - val_accuracy: 0.8278\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.3142 - accuracy: 0.8768 - val_loss: 0.4049 - val_accuracy: 0.8399\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.3110 - accuracy: 0.8774 - val_loss: 0.4858 - val_accuracy: 0.8026\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.3076 - accuracy: 0.8785 - val_loss: 0.5966 - val_accuracy: 0.7346\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.3061 - accuracy: 0.8790 - val_loss: 0.4907 - val_accuracy: 0.8018\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.3013 - accuracy: 0.8818 - val_loss: 0.4421 - val_accuracy: 0.8245\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.3021 - accuracy: 0.8824 - val_loss: 0.5753 - val_accuracy: 0.7530\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6705 - accuracy: 0.5898 - val_loss: 0.6678 - val_accuracy: 0.6209\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6301 - accuracy: 0.6488 - val_loss: 0.6462 - val_accuracy: 0.6396\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6078 - accuracy: 0.6675 - val_loss: 0.6329 - val_accuracy: 0.6468\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5897 - accuracy: 0.6843 - val_loss: 0.6023 - val_accuracy: 0.6758\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5743 - accuracy: 0.6995 - val_loss: 0.6096 - val_accuracy: 0.6573\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5622 - accuracy: 0.7099 - val_loss: 0.5808 - val_accuracy: 0.6836\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5507 - accuracy: 0.7211 - val_loss: 0.5876 - val_accuracy: 0.6671\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5385 - accuracy: 0.7305 - val_loss: 0.5878 - val_accuracy: 0.6617\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5300 - accuracy: 0.7374 - val_loss: 0.5889 - val_accuracy: 0.6595\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5216 - accuracy: 0.7417 - val_loss: 0.6160 - val_accuracy: 0.6260\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5130 - accuracy: 0.7455 - val_loss: 0.5703 - val_accuracy: 0.6733\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5074 - accuracy: 0.7482 - val_loss: 0.5398 - val_accuracy: 0.7050\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5004 - accuracy: 0.7543 - val_loss: 0.5998 - val_accuracy: 0.6467\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.4941 - accuracy: 0.7585 - val_loss: 0.5731 - val_accuracy: 0.6698\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.4860 - accuracy: 0.7620 - val_loss: 0.5874 - val_accuracy: 0.6600\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.4809 - accuracy: 0.7663 - val_loss: 0.5701 - val_accuracy: 0.6783\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.6025 - val_accuracy: 0.6556\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.4680 - accuracy: 0.7756 - val_loss: 0.5236 - val_accuracy: 0.7264\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.4592 - accuracy: 0.7805 - val_loss: 0.5170 - val_accuracy: 0.7318\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.4531 - accuracy: 0.7877 - val_loss: 0.5842 - val_accuracy: 0.6777\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.4466 - accuracy: 0.7915 - val_loss: 0.6349 - val_accuracy: 0.6450\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.4371 - accuracy: 0.7979 - val_loss: 0.5707 - val_accuracy: 0.6956\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.4289 - accuracy: 0.8035 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.4222 - accuracy: 0.8075 - val_loss: 0.5441 - val_accuracy: 0.7180\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.4138 - accuracy: 0.8152 - val_loss: 0.5516 - val_accuracy: 0.7139\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.4049 - accuracy: 0.8218 - val_loss: 0.5457 - val_accuracy: 0.7214\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.3974 - accuracy: 0.8263 - val_loss: 0.4966 - val_accuracy: 0.7662\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.3920 - accuracy: 0.8310 - val_loss: 0.5449 - val_accuracy: 0.7294\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.3819 - accuracy: 0.8366 - val_loss: 0.4897 - val_accuracy: 0.7765\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.3773 - accuracy: 0.8402 - val_loss: 0.5327 - val_accuracy: 0.7451\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.3684 - accuracy: 0.8457 - val_loss: 0.5061 - val_accuracy: 0.7677\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.3607 - accuracy: 0.8522 - val_loss: 0.5345 - val_accuracy: 0.7498\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.3545 - accuracy: 0.8550 - val_loss: 0.4480 - val_accuracy: 0.8164\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.3484 - accuracy: 0.8583 - val_loss: 0.4282 - val_accuracy: 0.8280\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.3440 - accuracy: 0.8603 - val_loss: 0.6200 - val_accuracy: 0.6977\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.3386 - accuracy: 0.8649 - val_loss: 0.5908 - val_accuracy: 0.7208\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.3349 - accuracy: 0.8666 - val_loss: 0.4836 - val_accuracy: 0.7960\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.3295 - accuracy: 0.8690 - val_loss: 0.6176 - val_accuracy: 0.7106\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.3235 - accuracy: 0.8719 - val_loss: 0.4964 - val_accuracy: 0.7919\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.3220 - accuracy: 0.8740 - val_loss: 0.3446 - val_accuracy: 0.8644\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.3185 - accuracy: 0.8745 - val_loss: 0.5011 - val_accuracy: 0.7895\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.3155 - accuracy: 0.8765 - val_loss: 0.5225 - val_accuracy: 0.7775\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.3121 - accuracy: 0.8794 - val_loss: 0.5115 - val_accuracy: 0.7848\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.3087 - accuracy: 0.8808 - val_loss: 0.4496 - val_accuracy: 0.8219\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.3057 - accuracy: 0.8810 - val_loss: 0.4254 - val_accuracy: 0.8338\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.3049 - accuracy: 0.8813 - val_loss: 0.4467 - val_accuracy: 0.8238\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.3020 - accuracy: 0.8831 - val_loss: 0.5632 - val_accuracy: 0.7587\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.3005 - accuracy: 0.8825 - val_loss: 0.3716 - val_accuracy: 0.8571\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.2980 - accuracy: 0.8816 - val_loss: 0.4431 - val_accuracy: 0.8253\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.2977 - accuracy: 0.8840 - val_loss: 0.4806 - val_accuracy: 0.8085\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6871 - accuracy: 0.5478 - val_loss: 0.6930 - val_accuracy: 0.5431\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6434 - accuracy: 0.6442 - val_loss: 0.6323 - val_accuracy: 0.6654\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6192 - accuracy: 0.6719 - val_loss: 0.6289 - val_accuracy: 0.6430\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5997 - accuracy: 0.6892 - val_loss: 0.6194 - val_accuracy: 0.6468\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5824 - accuracy: 0.7047 - val_loss: 0.5896 - val_accuracy: 0.6738\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5677 - accuracy: 0.7137 - val_loss: 0.5835 - val_accuracy: 0.6783\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5566 - accuracy: 0.7220 - val_loss: 0.6250 - val_accuracy: 0.6384\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5458 - accuracy: 0.7270 - val_loss: 0.6194 - val_accuracy: 0.6409\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5366 - accuracy: 0.7336 - val_loss: 0.5879 - val_accuracy: 0.6731\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5298 - accuracy: 0.7351 - val_loss: 0.5869 - val_accuracy: 0.6757\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5204 - accuracy: 0.7439 - val_loss: 0.5498 - val_accuracy: 0.6918\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5152 - accuracy: 0.7451 - val_loss: 0.6267 - val_accuracy: 0.6402\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5082 - accuracy: 0.7507 - val_loss: 0.6242 - val_accuracy: 0.6436\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5010 - accuracy: 0.7556 - val_loss: 0.5849 - val_accuracy: 0.6698\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.4948 - accuracy: 0.7582 - val_loss: 0.6542 - val_accuracy: 0.6197\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.4887 - accuracy: 0.7624 - val_loss: 0.5522 - val_accuracy: 0.6938\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.4835 - accuracy: 0.7636 - val_loss: 0.5462 - val_accuracy: 0.6993\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.4769 - accuracy: 0.7690 - val_loss: 0.5882 - val_accuracy: 0.6710\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.4719 - accuracy: 0.7729 - val_loss: 0.5809 - val_accuracy: 0.6758\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.4652 - accuracy: 0.7786 - val_loss: 0.5283 - val_accuracy: 0.7216\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.4585 - accuracy: 0.7820 - val_loss: 0.6021 - val_accuracy: 0.6647\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.4508 - accuracy: 0.7875 - val_loss: 0.5096 - val_accuracy: 0.7399\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.4433 - accuracy: 0.7940 - val_loss: 0.5277 - val_accuracy: 0.7265\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.4362 - accuracy: 0.7991 - val_loss: 0.5406 - val_accuracy: 0.7195\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.4289 - accuracy: 0.8030 - val_loss: 0.5376 - val_accuracy: 0.7244\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.4221 - accuracy: 0.8112 - val_loss: 0.5602 - val_accuracy: 0.7108\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.4132 - accuracy: 0.8150 - val_loss: 0.5004 - val_accuracy: 0.7556\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.4054 - accuracy: 0.8196 - val_loss: 0.4712 - val_accuracy: 0.7846\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.3984 - accuracy: 0.8261 - val_loss: 0.5215 - val_accuracy: 0.7471\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.3910 - accuracy: 0.8313 - val_loss: 0.5050 - val_accuracy: 0.7626\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.3835 - accuracy: 0.8376 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.3765 - accuracy: 0.8403 - val_loss: 0.5579 - val_accuracy: 0.7272\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.3702 - accuracy: 0.8444 - val_loss: 0.5466 - val_accuracy: 0.7402\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.3640 - accuracy: 0.8499 - val_loss: 0.4836 - val_accuracy: 0.7867\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.3556 - accuracy: 0.8535 - val_loss: 0.4233 - val_accuracy: 0.8282\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.3506 - accuracy: 0.8570 - val_loss: 0.4161 - val_accuracy: 0.8337\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.3459 - accuracy: 0.8596 - val_loss: 0.4926 - val_accuracy: 0.7878\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.3416 - accuracy: 0.8639 - val_loss: 0.4977 - val_accuracy: 0.7846\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.3342 - accuracy: 0.8667 - val_loss: 0.4888 - val_accuracy: 0.7918\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.3301 - accuracy: 0.8668 - val_loss: 0.4173 - val_accuracy: 0.8351\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.3271 - accuracy: 0.8702 - val_loss: 0.5022 - val_accuracy: 0.7876\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.3223 - accuracy: 0.8718 - val_loss: 0.6302 - val_accuracy: 0.7050\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.3208 - accuracy: 0.8741 - val_loss: 0.4489 - val_accuracy: 0.8225\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.3163 - accuracy: 0.8765 - val_loss: 0.4556 - val_accuracy: 0.8186\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.3132 - accuracy: 0.8765 - val_loss: 0.5011 - val_accuracy: 0.7946\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.3102 - accuracy: 0.8782 - val_loss: 0.3985 - val_accuracy: 0.8437\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.3083 - accuracy: 0.8786 - val_loss: 0.5413 - val_accuracy: 0.7702\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.3072 - accuracy: 0.8795 - val_loss: 0.4869 - val_accuracy: 0.8058\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.3055 - accuracy: 0.8820 - val_loss: 0.4460 - val_accuracy: 0.8249\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.3016 - accuracy: 0.8815 - val_loss: 0.5700 - val_accuracy: 0.7589\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6730 - accuracy: 0.5874 - val_loss: 0.6705 - val_accuracy: 0.6013\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6357 - accuracy: 0.6561 - val_loss: 0.6545 - val_accuracy: 0.6123\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6097 - accuracy: 0.6798 - val_loss: 0.6051 - val_accuracy: 0.6749\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5911 - accuracy: 0.6930 - val_loss: 0.6103 - val_accuracy: 0.6553\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5791 - accuracy: 0.6988 - val_loss: 0.5744 - val_accuracy: 0.6900\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5678 - accuracy: 0.7075 - val_loss: 0.6171 - val_accuracy: 0.6404\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5577 - accuracy: 0.7131 - val_loss: 0.5857 - val_accuracy: 0.6696\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5489 - accuracy: 0.7195 - val_loss: 0.6096 - val_accuracy: 0.6477\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5419 - accuracy: 0.7225 - val_loss: 0.5900 - val_accuracy: 0.6655\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5341 - accuracy: 0.7290 - val_loss: 0.5666 - val_accuracy: 0.6872\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5267 - accuracy: 0.7325 - val_loss: 0.5740 - val_accuracy: 0.6802\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5207 - accuracy: 0.7362 - val_loss: 0.6175 - val_accuracy: 0.6456\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5125 - accuracy: 0.7452 - val_loss: 0.5973 - val_accuracy: 0.6625\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5067 - accuracy: 0.7477 - val_loss: 0.5913 - val_accuracy: 0.6662\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5015 - accuracy: 0.7514 - val_loss: 0.5638 - val_accuracy: 0.6949\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.4930 - accuracy: 0.7560 - val_loss: 0.5560 - val_accuracy: 0.7031\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.4873 - accuracy: 0.7620 - val_loss: 0.5703 - val_accuracy: 0.6908\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.4828 - accuracy: 0.7656 - val_loss: 0.5658 - val_accuracy: 0.6962\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.4754 - accuracy: 0.7716 - val_loss: 0.5409 - val_accuracy: 0.7220\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.4683 - accuracy: 0.7726 - val_loss: 0.5807 - val_accuracy: 0.6824\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.4612 - accuracy: 0.7804 - val_loss: 0.5708 - val_accuracy: 0.6960\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.4537 - accuracy: 0.7861 - val_loss: 0.5850 - val_accuracy: 0.6868\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.4469 - accuracy: 0.7887 - val_loss: 0.5659 - val_accuracy: 0.7030\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.4399 - accuracy: 0.7959 - val_loss: 0.5894 - val_accuracy: 0.6877\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.4307 - accuracy: 0.8033 - val_loss: 0.5963 - val_accuracy: 0.6855\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.4225 - accuracy: 0.8108 - val_loss: 0.5354 - val_accuracy: 0.7374\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.4151 - accuracy: 0.8174 - val_loss: 0.6210 - val_accuracy: 0.6713\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.4072 - accuracy: 0.8211 - val_loss: 0.4482 - val_accuracy: 0.8113\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.3967 - accuracy: 0.8285 - val_loss: 0.5714 - val_accuracy: 0.7182\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.3881 - accuracy: 0.8350 - val_loss: 0.6102 - val_accuracy: 0.6922\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.3805 - accuracy: 0.8398 - val_loss: 0.5652 - val_accuracy: 0.7272\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 808us/step - loss: 0.3731 - accuracy: 0.8456 - val_loss: 0.4661 - val_accuracy: 0.8037\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.3664 - accuracy: 0.8482 - val_loss: 0.4662 - val_accuracy: 0.8064\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.3599 - accuracy: 0.8532 - val_loss: 0.4660 - val_accuracy: 0.8073\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.3509 - accuracy: 0.8569 - val_loss: 0.5596 - val_accuracy: 0.7430\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.3464 - accuracy: 0.8598 - val_loss: 0.5112 - val_accuracy: 0.7802\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.3401 - accuracy: 0.8624 - val_loss: 0.5194 - val_accuracy: 0.7782\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.3364 - accuracy: 0.8636 - val_loss: 0.4888 - val_accuracy: 0.8000\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.3324 - accuracy: 0.8660 - val_loss: 0.4202 - val_accuracy: 0.8359\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.3271 - accuracy: 0.8690 - val_loss: 0.5318 - val_accuracy: 0.7784\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.3228 - accuracy: 0.8709 - val_loss: 0.4859 - val_accuracy: 0.8064\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.3201 - accuracy: 0.8730 - val_loss: 0.5013 - val_accuracy: 0.7986\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.3174 - accuracy: 0.8755 - val_loss: 0.4539 - val_accuracy: 0.8235\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.3144 - accuracy: 0.8743 - val_loss: 0.4109 - val_accuracy: 0.8407\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.3108 - accuracy: 0.8783 - val_loss: 0.4024 - val_accuracy: 0.8436\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.3101 - accuracy: 0.8766 - val_loss: 0.6424 - val_accuracy: 0.7115\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.3050 - accuracy: 0.8793 - val_loss: 0.6906 - val_accuracy: 0.6899\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.3049 - accuracy: 0.8788 - val_loss: 0.4059 - val_accuracy: 0.8444\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.3048 - accuracy: 0.8790 - val_loss: 0.5252 - val_accuracy: 0.7909\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.3015 - accuracy: 0.8800 - val_loss: 0.4663 - val_accuracy: 0.8213\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6562 - accuracy: 0.6210 - val_loss: 0.6810 - val_accuracy: 0.5708\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6205 - accuracy: 0.6693 - val_loss: 0.6703 - val_accuracy: 0.5901\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5958 - accuracy: 0.6920 - val_loss: 0.6213 - val_accuracy: 0.6464\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5807 - accuracy: 0.7007 - val_loss: 0.6020 - val_accuracy: 0.6611\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5671 - accuracy: 0.7095 - val_loss: 0.6323 - val_accuracy: 0.6247\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5575 - accuracy: 0.7154 - val_loss: 0.5882 - val_accuracy: 0.6627\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5472 - accuracy: 0.7239 - val_loss: 0.5986 - val_accuracy: 0.6524\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5386 - accuracy: 0.7260 - val_loss: 0.6190 - val_accuracy: 0.6385\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5331 - accuracy: 0.7313 - val_loss: 0.5834 - val_accuracy: 0.6662\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5260 - accuracy: 0.7350 - val_loss: 0.5995 - val_accuracy: 0.6545\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5198 - accuracy: 0.7387 - val_loss: 0.5781 - val_accuracy: 0.6697\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5120 - accuracy: 0.7457 - val_loss: 0.6124 - val_accuracy: 0.6448\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5082 - accuracy: 0.7463 - val_loss: 0.6145 - val_accuracy: 0.6441\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5027 - accuracy: 0.7504 - val_loss: 0.5797 - val_accuracy: 0.6690\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.4950 - accuracy: 0.7589 - val_loss: 0.6127 - val_accuracy: 0.6458\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.4900 - accuracy: 0.7598 - val_loss: 0.5710 - val_accuracy: 0.6828\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.4846 - accuracy: 0.7639 - val_loss: 0.5448 - val_accuracy: 0.7073\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.4768 - accuracy: 0.7706 - val_loss: 0.5929 - val_accuracy: 0.6662\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.4716 - accuracy: 0.7726 - val_loss: 0.5957 - val_accuracy: 0.6687\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.4647 - accuracy: 0.7774 - val_loss: 0.5911 - val_accuracy: 0.6767\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.5679 - val_accuracy: 0.6987\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.4501 - accuracy: 0.7894 - val_loss: 0.5582 - val_accuracy: 0.7085\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.4417 - accuracy: 0.7943 - val_loss: 0.5865 - val_accuracy: 0.6867\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.4343 - accuracy: 0.8012 - val_loss: 0.5317 - val_accuracy: 0.7371\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.4257 - accuracy: 0.8078 - val_loss: 0.5198 - val_accuracy: 0.7530\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.4178 - accuracy: 0.8129 - val_loss: 0.5463 - val_accuracy: 0.7293\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.4108 - accuracy: 0.8192 - val_loss: 0.6069 - val_accuracy: 0.6834\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.4031 - accuracy: 0.8246 - val_loss: 0.5034 - val_accuracy: 0.7704\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.3937 - accuracy: 0.8303 - val_loss: 0.5700 - val_accuracy: 0.7181\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.3863 - accuracy: 0.8339 - val_loss: 0.5820 - val_accuracy: 0.7122\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.3800 - accuracy: 0.8382 - val_loss: 0.5835 - val_accuracy: 0.7108\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.3720 - accuracy: 0.8451 - val_loss: 0.5185 - val_accuracy: 0.7628\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.3661 - accuracy: 0.8475 - val_loss: 0.4720 - val_accuracy: 0.7988\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.3575 - accuracy: 0.8548 - val_loss: 0.4860 - val_accuracy: 0.7918\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.3528 - accuracy: 0.8563 - val_loss: 0.5097 - val_accuracy: 0.7786\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.3448 - accuracy: 0.8603 - val_loss: 0.5831 - val_accuracy: 0.7285\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.3407 - accuracy: 0.8626 - val_loss: 0.4674 - val_accuracy: 0.8125\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.3358 - accuracy: 0.8629 - val_loss: 0.5242 - val_accuracy: 0.7762\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.3320 - accuracy: 0.8690 - val_loss: 0.5423 - val_accuracy: 0.7637\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.3267 - accuracy: 0.8711 - val_loss: 0.4842 - val_accuracy: 0.8054\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.3210 - accuracy: 0.8732 - val_loss: 0.4536 - val_accuracy: 0.8227\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.3197 - accuracy: 0.8731 - val_loss: 0.4556 - val_accuracy: 0.8223\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.3160 - accuracy: 0.8760 - val_loss: 0.4584 - val_accuracy: 0.8205\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.3116 - accuracy: 0.8759 - val_loss: 0.4906 - val_accuracy: 0.8038\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.3106 - accuracy: 0.8768 - val_loss: 0.4819 - val_accuracy: 0.8096\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.3081 - accuracy: 0.8791 - val_loss: 0.5163 - val_accuracy: 0.7918\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.3040 - accuracy: 0.8799 - val_loss: 0.5163 - val_accuracy: 0.7922\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.3037 - accuracy: 0.8799 - val_loss: 0.5139 - val_accuracy: 0.7928\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.3004 - accuracy: 0.8831 - val_loss: 0.4397 - val_accuracy: 0.8296\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.2990 - accuracy: 0.8834 - val_loss: 0.5983 - val_accuracy: 0.7469\n",
      "\n",
      "Training model with sample_size_ratio=0.1...\n",
      "DP-SGD with sampling rate = 0.299% and noise_multiplier = 1.1 iterated over 16719 steps satisfies differential privacy with eps = 2.27 and delta = 1e-05.\n",
      "The optimal RDP order is 11.0.\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.4948 - val_loss: 0.7490 - val_accuracy: 0.2736\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.4953 - val_loss: 0.7458 - val_accuracy: 0.2666\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.5135 - val_loss: 0.7584 - val_accuracy: 0.2250\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5374 - val_loss: 0.7103 - val_accuracy: 0.4191\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5495 - val_loss: 0.7185 - val_accuracy: 0.3927\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5529 - val_loss: 0.7118 - val_accuracy: 0.4504\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6724 - accuracy: 0.5721 - val_loss: 0.7122 - val_accuracy: 0.4641\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.5819 - val_loss: 0.7131 - val_accuracy: 0.4787\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.5955 - val_loss: 0.7177 - val_accuracy: 0.4752\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6049 - val_loss: 0.6802 - val_accuracy: 0.5912\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6228 - val_loss: 0.6882 - val_accuracy: 0.5720\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6310 - val_loss: 0.6902 - val_accuracy: 0.5695\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6366 - val_loss: 0.6819 - val_accuracy: 0.5852\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6389 - val_loss: 0.6801 - val_accuracy: 0.5884\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6346 - accuracy: 0.6464 - val_loss: 0.6469 - val_accuracy: 0.6482\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.6299 - accuracy: 0.6581 - val_loss: 0.6680 - val_accuracy: 0.6112\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 960us/step - loss: 0.6218 - accuracy: 0.6664 - val_loss: 0.6601 - val_accuracy: 0.6227\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.6216 - accuracy: 0.6578 - val_loss: 0.6539 - val_accuracy: 0.6294\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6165 - accuracy: 0.6621 - val_loss: 0.6636 - val_accuracy: 0.6146\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 961us/step - loss: 0.6129 - accuracy: 0.6677 - val_loss: 0.6461 - val_accuracy: 0.6363\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6083 - accuracy: 0.6693 - val_loss: 0.6543 - val_accuracy: 0.6262\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 979us/step - loss: 0.6039 - accuracy: 0.6763 - val_loss: 0.6308 - val_accuracy: 0.6527\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 0s 934us/step - loss: 0.5999 - accuracy: 0.6826 - val_loss: 0.6366 - val_accuracy: 0.6445\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 948us/step - loss: 0.5961 - accuracy: 0.6836 - val_loss: 0.6224 - val_accuracy: 0.6626\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.6841 - val_loss: 0.6275 - val_accuracy: 0.6520\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 960us/step - loss: 0.5878 - accuracy: 0.6884 - val_loss: 0.6096 - val_accuracy: 0.6706\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 946us/step - loss: 0.5854 - accuracy: 0.6908 - val_loss: 0.6146 - val_accuracy: 0.6638\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 946us/step - loss: 0.5802 - accuracy: 0.6983 - val_loss: 0.6367 - val_accuracy: 0.6343\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 969us/step - loss: 0.5786 - accuracy: 0.6979 - val_loss: 0.6288 - val_accuracy: 0.6428\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 941us/step - loss: 0.5735 - accuracy: 0.7015 - val_loss: 0.6349 - val_accuracy: 0.6380\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7060 - val_loss: 0.6217 - val_accuracy: 0.6496\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 981us/step - loss: 0.5681 - accuracy: 0.7075 - val_loss: 0.6441 - val_accuracy: 0.6252\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.5647 - accuracy: 0.7136 - val_loss: 0.6387 - val_accuracy: 0.6309\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 939us/step - loss: 0.5613 - accuracy: 0.7136 - val_loss: 0.6754 - val_accuracy: 0.5950\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 932us/step - loss: 0.5602 - accuracy: 0.7166 - val_loss: 0.5991 - val_accuracy: 0.6645\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7148 - val_loss: 0.6194 - val_accuracy: 0.6458\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 0s 939us/step - loss: 0.5528 - accuracy: 0.7166 - val_loss: 0.6170 - val_accuracy: 0.6479\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 934us/step - loss: 0.5543 - accuracy: 0.7170 - val_loss: 0.6351 - val_accuracy: 0.6302\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 937us/step - loss: 0.5478 - accuracy: 0.7241 - val_loss: 0.5943 - val_accuracy: 0.6654\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 937us/step - loss: 0.5457 - accuracy: 0.7293 - val_loss: 0.6259 - val_accuracy: 0.6374\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 930us/step - loss: 0.5438 - accuracy: 0.7275 - val_loss: 0.5976 - val_accuracy: 0.6591\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 956us/step - loss: 0.5417 - accuracy: 0.7275 - val_loss: 0.6318 - val_accuracy: 0.6323\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.7245 - val_loss: 0.5967 - val_accuracy: 0.6565\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 965us/step - loss: 0.5394 - accuracy: 0.7284 - val_loss: 0.6113 - val_accuracy: 0.6474\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 942us/step - loss: 0.5359 - accuracy: 0.7297 - val_loss: 0.6312 - val_accuracy: 0.6331\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.5318 - accuracy: 0.7348 - val_loss: 0.6314 - val_accuracy: 0.6328\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 940us/step - loss: 0.5300 - accuracy: 0.7325 - val_loss: 0.6344 - val_accuracy: 0.6299\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 980us/step - loss: 0.5301 - accuracy: 0.7361 - val_loss: 0.6509 - val_accuracy: 0.6157\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.7449 - val_loss: 0.5946 - val_accuracy: 0.6583\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 946us/step - loss: 0.5256 - accuracy: 0.7398 - val_loss: 0.6190 - val_accuracy: 0.6413\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.5320 - val_loss: 0.7182 - val_accuracy: 0.4336\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 927us/step - loss: 0.6801 - accuracy: 0.5712 - val_loss: 0.7145 - val_accuracy: 0.4890\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 935us/step - loss: 0.6666 - accuracy: 0.5950 - val_loss: 0.6971 - val_accuracy: 0.5440\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 966us/step - loss: 0.6559 - accuracy: 0.6193 - val_loss: 0.7013 - val_accuracy: 0.5402\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6310 - val_loss: 0.6713 - val_accuracy: 0.5896\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 972us/step - loss: 0.6463 - accuracy: 0.6372 - val_loss: 0.6733 - val_accuracy: 0.5849\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 938us/step - loss: 0.6377 - accuracy: 0.6467 - val_loss: 0.6754 - val_accuracy: 0.5775\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 971us/step - loss: 0.6322 - accuracy: 0.6490 - val_loss: 0.6587 - val_accuracy: 0.6061\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 939us/step - loss: 0.6258 - accuracy: 0.6611 - val_loss: 0.6535 - val_accuracy: 0.6102\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 933us/step - loss: 0.6183 - accuracy: 0.6735 - val_loss: 0.6591 - val_accuracy: 0.5996\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6164 - accuracy: 0.6677 - val_loss: 0.6679 - val_accuracy: 0.5866\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 960us/step - loss: 0.6126 - accuracy: 0.6682 - val_loss: 0.6510 - val_accuracy: 0.6109\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 0s 946us/step - loss: 0.6076 - accuracy: 0.6785 - val_loss: 0.6389 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 930us/step - loss: 0.6021 - accuracy: 0.6836 - val_loss: 0.6407 - val_accuracy: 0.6278\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 0s 937us/step - loss: 0.5999 - accuracy: 0.6864 - val_loss: 0.6405 - val_accuracy: 0.6272\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 0s 922us/step - loss: 0.5943 - accuracy: 0.6963 - val_loss: 0.6608 - val_accuracy: 0.6043\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.6972 - val_loss: 0.6128 - val_accuracy: 0.6664\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 0s 951us/step - loss: 0.5853 - accuracy: 0.7000 - val_loss: 0.6232 - val_accuracy: 0.6495\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 0s 942us/step - loss: 0.5845 - accuracy: 0.6959 - val_loss: 0.6372 - val_accuracy: 0.6330\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 934us/step - loss: 0.5801 - accuracy: 0.7032 - val_loss: 0.6146 - val_accuracy: 0.6585\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 932us/step - loss: 0.5789 - accuracy: 0.7024 - val_loss: 0.6676 - val_accuracy: 0.6031\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 937us/step - loss: 0.5754 - accuracy: 0.7069 - val_loss: 0.6759 - val_accuracy: 0.5968\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7060 - val_loss: 0.6204 - val_accuracy: 0.6466\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 946us/step - loss: 0.5734 - accuracy: 0.7088 - val_loss: 0.6641 - val_accuracy: 0.6057\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 968us/step - loss: 0.5703 - accuracy: 0.7075 - val_loss: 0.6000 - val_accuracy: 0.6648\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 936us/step - loss: 0.5679 - accuracy: 0.7088 - val_loss: 0.6365 - val_accuracy: 0.6322\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.5631 - accuracy: 0.7121 - val_loss: 0.6688 - val_accuracy: 0.6037\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 942us/step - loss: 0.5621 - accuracy: 0.7121 - val_loss: 0.6077 - val_accuracy: 0.6569\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7164 - val_loss: 0.6318 - val_accuracy: 0.6376\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 925us/step - loss: 0.5589 - accuracy: 0.7118 - val_loss: 0.5905 - val_accuracy: 0.6720\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 935us/step - loss: 0.5565 - accuracy: 0.7215 - val_loss: 0.6157 - val_accuracy: 0.6486\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 925us/step - loss: 0.5546 - accuracy: 0.7226 - val_loss: 0.6048 - val_accuracy: 0.6556\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 926us/step - loss: 0.5531 - accuracy: 0.7239 - val_loss: 0.6413 - val_accuracy: 0.6283\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 935us/step - loss: 0.5518 - accuracy: 0.7217 - val_loss: 0.6434 - val_accuracy: 0.6256\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.7202 - val_loss: 0.6157 - val_accuracy: 0.6467\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 946us/step - loss: 0.5495 - accuracy: 0.7250 - val_loss: 0.6109 - val_accuracy: 0.6497\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 0s 944us/step - loss: 0.5459 - accuracy: 0.7269 - val_loss: 0.6512 - val_accuracy: 0.6187\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 938us/step - loss: 0.5458 - accuracy: 0.7219 - val_loss: 0.5672 - val_accuracy: 0.6952\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.5418 - accuracy: 0.7234 - val_loss: 0.6310 - val_accuracy: 0.6331\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 935us/step - loss: 0.5410 - accuracy: 0.7250 - val_loss: 0.6206 - val_accuracy: 0.6398\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.7264 - val_loss: 0.5879 - val_accuracy: 0.6697\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 959us/step - loss: 0.5388 - accuracy: 0.7293 - val_loss: 0.5873 - val_accuracy: 0.6701\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 953us/step - loss: 0.5320 - accuracy: 0.7350 - val_loss: 0.6240 - val_accuracy: 0.6367\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 940us/step - loss: 0.5374 - accuracy: 0.7249 - val_loss: 0.6328 - val_accuracy: 0.6302\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 932us/step - loss: 0.5354 - accuracy: 0.7316 - val_loss: 0.6260 - val_accuracy: 0.6362\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.7370 - val_loss: 0.6128 - val_accuracy: 0.6444\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 966us/step - loss: 0.5333 - accuracy: 0.7357 - val_loss: 0.6293 - val_accuracy: 0.6331\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 950us/step - loss: 0.5286 - accuracy: 0.7310 - val_loss: 0.6058 - val_accuracy: 0.6521\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.5301 - accuracy: 0.7320 - val_loss: 0.6370 - val_accuracy: 0.6284\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.5263 - accuracy: 0.7370 - val_loss: 0.6567 - val_accuracy: 0.6146\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5697 - val_loss: 0.7071 - val_accuracy: 0.5114\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 942us/step - loss: 0.6686 - accuracy: 0.5916 - val_loss: 0.6828 - val_accuracy: 0.5716\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6133 - val_loss: 0.6766 - val_accuracy: 0.5905\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 991us/step - loss: 0.6552 - accuracy: 0.6213 - val_loss: 0.6686 - val_accuracy: 0.6067\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 959us/step - loss: 0.6455 - accuracy: 0.6419 - val_loss: 0.6718 - val_accuracy: 0.5966\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 947us/step - loss: 0.6360 - accuracy: 0.6520 - val_loss: 0.6712 - val_accuracy: 0.5947\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.6378 - accuracy: 0.6467 - val_loss: 0.6614 - val_accuracy: 0.6115\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6347 - accuracy: 0.6505 - val_loss: 0.6870 - val_accuracy: 0.5730\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 965us/step - loss: 0.6299 - accuracy: 0.6572 - val_loss: 0.6601 - val_accuracy: 0.6102\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 947us/step - loss: 0.6232 - accuracy: 0.6624 - val_loss: 0.6477 - val_accuracy: 0.6244\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 947us/step - loss: 0.6187 - accuracy: 0.6723 - val_loss: 0.6568 - val_accuracy: 0.6163\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 939us/step - loss: 0.6145 - accuracy: 0.6735 - val_loss: 0.6469 - val_accuracy: 0.6211\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 0s 929us/step - loss: 0.6132 - accuracy: 0.6731 - val_loss: 0.6265 - val_accuracy: 0.6430\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6074 - accuracy: 0.6796 - val_loss: 0.6290 - val_accuracy: 0.6394\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 0s 959us/step - loss: 0.6049 - accuracy: 0.6864 - val_loss: 0.6186 - val_accuracy: 0.6530\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 0s 964us/step - loss: 0.6001 - accuracy: 0.6964 - val_loss: 0.6635 - val_accuracy: 0.6071\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.6004 - accuracy: 0.6888 - val_loss: 0.6638 - val_accuracy: 0.6068\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 0s 945us/step - loss: 0.5984 - accuracy: 0.6940 - val_loss: 0.6565 - val_accuracy: 0.6145\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 0s 961us/step - loss: 0.5916 - accuracy: 0.6940 - val_loss: 0.6568 - val_accuracy: 0.6134\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 944us/step - loss: 0.5913 - accuracy: 0.6901 - val_loss: 0.6239 - val_accuracy: 0.6427\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5896 - accuracy: 0.6996 - val_loss: 0.6196 - val_accuracy: 0.6459\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.5832 - accuracy: 0.7030 - val_loss: 0.6247 - val_accuracy: 0.6408\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 0s 938us/step - loss: 0.5812 - accuracy: 0.7090 - val_loss: 0.6456 - val_accuracy: 0.6224\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.5804 - accuracy: 0.7050 - val_loss: 0.6653 - val_accuracy: 0.6106\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.5747 - accuracy: 0.7028 - val_loss: 0.6327 - val_accuracy: 0.6315\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.7095 - val_loss: 0.6244 - val_accuracy: 0.6443\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 972us/step - loss: 0.5736 - accuracy: 0.7069 - val_loss: 0.6131 - val_accuracy: 0.6550\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 975us/step - loss: 0.5707 - accuracy: 0.7084 - val_loss: 0.6131 - val_accuracy: 0.6541\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7095 - val_loss: 0.6272 - val_accuracy: 0.6419\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.7077 - val_loss: 0.6174 - val_accuracy: 0.6512\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7191 - val_loss: 0.6545 - val_accuracy: 0.6180\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7185 - val_loss: 0.6225 - val_accuracy: 0.6481\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7172 - val_loss: 0.6140 - val_accuracy: 0.6535\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 988us/step - loss: 0.5556 - accuracy: 0.7204 - val_loss: 0.6560 - val_accuracy: 0.6205\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 953us/step - loss: 0.5574 - accuracy: 0.7166 - val_loss: 0.6318 - val_accuracy: 0.6407\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.7245 - val_loss: 0.5787 - val_accuracy: 0.6845\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.5477 - accuracy: 0.7265 - val_loss: 0.6553 - val_accuracy: 0.6207\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7234 - val_loss: 0.6115 - val_accuracy: 0.6574\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7303 - val_loss: 0.6455 - val_accuracy: 0.6289\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.7219 - val_loss: 0.5973 - val_accuracy: 0.6727\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5447 - accuracy: 0.7303 - val_loss: 0.6348 - val_accuracy: 0.6393\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.7211 - val_loss: 0.6311 - val_accuracy: 0.6427\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7318 - val_loss: 0.6149 - val_accuracy: 0.6591\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7297 - val_loss: 0.6462 - val_accuracy: 0.6281\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.7293 - val_loss: 0.6172 - val_accuracy: 0.6574\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7325 - val_loss: 0.6185 - val_accuracy: 0.6556\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.7280 - val_loss: 0.5898 - val_accuracy: 0.6770\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7308 - val_loss: 0.6224 - val_accuracy: 0.6532\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.7318 - val_loss: 0.6051 - val_accuracy: 0.6664\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7368 - val_loss: 0.6490 - val_accuracy: 0.6246\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.5243 - val_loss: 0.7197 - val_accuracy: 0.4532\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 912us/step - loss: 0.6874 - accuracy: 0.5488 - val_loss: 0.7007 - val_accuracy: 0.5277\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 970us/step - loss: 0.6794 - accuracy: 0.5821 - val_loss: 0.7005 - val_accuracy: 0.5301\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 986us/step - loss: 0.6622 - accuracy: 0.6064 - val_loss: 0.7143 - val_accuracy: 0.5007\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6093 - val_loss: 0.6826 - val_accuracy: 0.5827\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 990us/step - loss: 0.6523 - accuracy: 0.6217 - val_loss: 0.6909 - val_accuracy: 0.5719\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 963us/step - loss: 0.6430 - accuracy: 0.6406 - val_loss: 0.6749 - val_accuracy: 0.6011\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 954us/step - loss: 0.6351 - accuracy: 0.6527 - val_loss: 0.6598 - val_accuracy: 0.6226\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 946us/step - loss: 0.6317 - accuracy: 0.6598 - val_loss: 0.6754 - val_accuracy: 0.5984\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 943us/step - loss: 0.6252 - accuracy: 0.6680 - val_loss: 0.6639 - val_accuracy: 0.6128\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.6662 - val_loss: 0.6598 - val_accuracy: 0.6169\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 999us/step - loss: 0.6156 - accuracy: 0.6692 - val_loss: 0.6439 - val_accuracy: 0.6370\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 0s 947us/step - loss: 0.6149 - accuracy: 0.6764 - val_loss: 0.6614 - val_accuracy: 0.6071\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 936us/step - loss: 0.6095 - accuracy: 0.6746 - val_loss: 0.6576 - val_accuracy: 0.6136\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 0s 935us/step - loss: 0.6098 - accuracy: 0.6830 - val_loss: 0.6293 - val_accuracy: 0.6456\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 0s 938us/step - loss: 0.6031 - accuracy: 0.6880 - val_loss: 0.6509 - val_accuracy: 0.6187\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.6961 - val_loss: 0.6519 - val_accuracy: 0.6168\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.6946 - val_loss: 0.6615 - val_accuracy: 0.6050\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.5951 - accuracy: 0.6899 - val_loss: 0.6481 - val_accuracy: 0.6173\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 997us/step - loss: 0.5928 - accuracy: 0.6946 - val_loss: 0.6330 - val_accuracy: 0.6401\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 961us/step - loss: 0.5856 - accuracy: 0.7009 - val_loss: 0.6418 - val_accuracy: 0.6276\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 965us/step - loss: 0.5820 - accuracy: 0.7086 - val_loss: 0.6452 - val_accuracy: 0.6240\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.7036 - val_loss: 0.5866 - val_accuracy: 0.6782\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 971us/step - loss: 0.5792 - accuracy: 0.7050 - val_loss: 0.6138 - val_accuracy: 0.6551\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 943us/step - loss: 0.5767 - accuracy: 0.7101 - val_loss: 0.6738 - val_accuracy: 0.5959\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 969us/step - loss: 0.5749 - accuracy: 0.7086 - val_loss: 0.6579 - val_accuracy: 0.6110\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.7118 - val_loss: 0.6153 - val_accuracy: 0.6547\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 983us/step - loss: 0.5671 - accuracy: 0.7123 - val_loss: 0.6223 - val_accuracy: 0.6462\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 950us/step - loss: 0.5673 - accuracy: 0.7125 - val_loss: 0.6375 - val_accuracy: 0.6311\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7157 - val_loss: 0.6410 - val_accuracy: 0.6284\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 958us/step - loss: 0.5624 - accuracy: 0.7138 - val_loss: 0.6029 - val_accuracy: 0.6605\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.7198 - val_loss: 0.6401 - val_accuracy: 0.6278\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 988us/step - loss: 0.5577 - accuracy: 0.7155 - val_loss: 0.6151 - val_accuracy: 0.6537\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 945us/step - loss: 0.5551 - accuracy: 0.7206 - val_loss: 0.6556 - val_accuracy: 0.6133\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 994us/step - loss: 0.5585 - accuracy: 0.7140 - val_loss: 0.6101 - val_accuracy: 0.6569\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7178 - val_loss: 0.6379 - val_accuracy: 0.6269\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 0s 990us/step - loss: 0.5527 - accuracy: 0.7221 - val_loss: 0.6404 - val_accuracy: 0.6231\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 941us/step - loss: 0.5519 - accuracy: 0.7185 - val_loss: 0.6836 - val_accuracy: 0.5943\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 983us/step - loss: 0.5489 - accuracy: 0.7269 - val_loss: 0.6576 - val_accuracy: 0.6109\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 956us/step - loss: 0.5453 - accuracy: 0.7250 - val_loss: 0.6053 - val_accuracy: 0.6584\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 930us/step - loss: 0.5449 - accuracy: 0.7275 - val_loss: 0.6823 - val_accuracy: 0.5994\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7252 - val_loss: 0.6541 - val_accuracy: 0.6140\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 983us/step - loss: 0.5378 - accuracy: 0.7258 - val_loss: 0.6673 - val_accuracy: 0.6085\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 950us/step - loss: 0.5395 - accuracy: 0.7260 - val_loss: 0.5914 - val_accuracy: 0.6653\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 964us/step - loss: 0.5382 - accuracy: 0.7273 - val_loss: 0.6161 - val_accuracy: 0.6471\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 982us/step - loss: 0.5399 - accuracy: 0.7284 - val_loss: 0.6389 - val_accuracy: 0.6269\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.7331 - val_loss: 0.5983 - val_accuracy: 0.6579\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5352 - accuracy: 0.7350 - val_loss: 0.6286 - val_accuracy: 0.6357\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 985us/step - loss: 0.5345 - accuracy: 0.7247 - val_loss: 0.5793 - val_accuracy: 0.6720\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 966us/step - loss: 0.5326 - accuracy: 0.7301 - val_loss: 0.6189 - val_accuracy: 0.6450\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5164 - val_loss: 0.7422 - val_accuracy: 0.2592\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 979us/step - loss: 0.6850 - accuracy: 0.5525 - val_loss: 0.7383 - val_accuracy: 0.3289\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5723 - val_loss: 0.7055 - val_accuracy: 0.4701\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 989us/step - loss: 0.6733 - accuracy: 0.5961 - val_loss: 0.7125 - val_accuracy: 0.4542\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.6034 - val_loss: 0.7104 - val_accuracy: 0.4734\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.6185 - val_loss: 0.6953 - val_accuracy: 0.5225\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 989us/step - loss: 0.6488 - accuracy: 0.6301 - val_loss: 0.6941 - val_accuracy: 0.5304\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 989us/step - loss: 0.6431 - accuracy: 0.6441 - val_loss: 0.6752 - val_accuracy: 0.5707\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6557 - val_loss: 0.6886 - val_accuracy: 0.5485\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6606 - val_loss: 0.6591 - val_accuracy: 0.6060\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.6637 - val_loss: 0.6799 - val_accuracy: 0.5629\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6682 - val_loss: 0.6759 - val_accuracy: 0.5696\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 0s 992us/step - loss: 0.6168 - accuracy: 0.6742 - val_loss: 0.6377 - val_accuracy: 0.6362\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6757 - val_loss: 0.6861 - val_accuracy: 0.5590\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6071 - accuracy: 0.6802 - val_loss: 0.6636 - val_accuracy: 0.5947\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 0s 994us/step - loss: 0.6036 - accuracy: 0.6858 - val_loss: 0.6636 - val_accuracy: 0.5956\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5982 - accuracy: 0.6877 - val_loss: 0.6694 - val_accuracy: 0.5866\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.6813 - val_loss: 0.6416 - val_accuracy: 0.6203\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.6875 - val_loss: 0.6487 - val_accuracy: 0.6134\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5908 - accuracy: 0.6931 - val_loss: 0.6378 - val_accuracy: 0.6248\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.6907 - val_loss: 0.6318 - val_accuracy: 0.6322\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 981us/step - loss: 0.5862 - accuracy: 0.6964 - val_loss: 0.6689 - val_accuracy: 0.5916\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.6929 - val_loss: 0.6514 - val_accuracy: 0.6090\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 996us/step - loss: 0.5797 - accuracy: 0.6970 - val_loss: 0.6495 - val_accuracy: 0.6104\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 972us/step - loss: 0.5792 - accuracy: 0.7032 - val_loss: 0.6094 - val_accuracy: 0.6568\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5781 - accuracy: 0.7004 - val_loss: 0.6354 - val_accuracy: 0.6269\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7013 - val_loss: 0.6608 - val_accuracy: 0.6000\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 982us/step - loss: 0.5694 - accuracy: 0.7034 - val_loss: 0.6517 - val_accuracy: 0.6082\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7021 - val_loss: 0.5873 - val_accuracy: 0.6753\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 993us/step - loss: 0.5649 - accuracy: 0.7129 - val_loss: 0.5992 - val_accuracy: 0.6602\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.7032 - val_loss: 0.6517 - val_accuracy: 0.6086\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7140 - val_loss: 0.6721 - val_accuracy: 0.5881\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 987us/step - loss: 0.5610 - accuracy: 0.7069 - val_loss: 0.6385 - val_accuracy: 0.6241\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 992us/step - loss: 0.5547 - accuracy: 0.7179 - val_loss: 0.6315 - val_accuracy: 0.6322\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.7179 - val_loss: 0.6141 - val_accuracy: 0.6456\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 993us/step - loss: 0.5549 - accuracy: 0.7174 - val_loss: 0.6223 - val_accuracy: 0.6404\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 0s 978us/step - loss: 0.5498 - accuracy: 0.7163 - val_loss: 0.6473 - val_accuracy: 0.6166\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 985us/step - loss: 0.5517 - accuracy: 0.7138 - val_loss: 0.7063 - val_accuracy: 0.5682\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.7185 - val_loss: 0.6314 - val_accuracy: 0.6325\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.7166 - val_loss: 0.6052 - val_accuracy: 0.6508\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 997us/step - loss: 0.5466 - accuracy: 0.7198 - val_loss: 0.6213 - val_accuracy: 0.6404\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 972us/step - loss: 0.5457 - accuracy: 0.7185 - val_loss: 0.5847 - val_accuracy: 0.6670\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.7209 - val_loss: 0.6217 - val_accuracy: 0.6387\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 994us/step - loss: 0.5404 - accuracy: 0.7206 - val_loss: 0.5975 - val_accuracy: 0.6564\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 997us/step - loss: 0.5378 - accuracy: 0.7194 - val_loss: 0.6133 - val_accuracy: 0.6445\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7179 - val_loss: 0.6179 - val_accuracy: 0.6426\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.7252 - val_loss: 0.6124 - val_accuracy: 0.6453\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 987us/step - loss: 0.5345 - accuracy: 0.7307 - val_loss: 0.5794 - val_accuracy: 0.6698\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7247 - val_loss: 0.6361 - val_accuracy: 0.6270\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 970us/step - loss: 0.5320 - accuracy: 0.7288 - val_loss: 0.6207 - val_accuracy: 0.6402\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5733 - val_loss: 0.7424 - val_accuracy: 0.2621\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 954us/step - loss: 0.6727 - accuracy: 0.5890 - val_loss: 0.7103 - val_accuracy: 0.4757\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 942us/step - loss: 0.6596 - accuracy: 0.6176 - val_loss: 0.6853 - val_accuracy: 0.5719\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 935us/step - loss: 0.6479 - accuracy: 0.6327 - val_loss: 0.6937 - val_accuracy: 0.5569\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6411 - accuracy: 0.6518 - val_loss: 0.6768 - val_accuracy: 0.5924\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 974us/step - loss: 0.6379 - accuracy: 0.6479 - val_loss: 0.6750 - val_accuracy: 0.5953\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.6641 - val_loss: 0.6677 - val_accuracy: 0.6105\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 965us/step - loss: 0.6245 - accuracy: 0.6656 - val_loss: 0.6693 - val_accuracy: 0.6071\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 954us/step - loss: 0.6188 - accuracy: 0.6725 - val_loss: 0.6684 - val_accuracy: 0.6072\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6667 - val_loss: 0.6755 - val_accuracy: 0.5890\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 967us/step - loss: 0.6132 - accuracy: 0.6740 - val_loss: 0.6709 - val_accuracy: 0.5998\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 947us/step - loss: 0.6104 - accuracy: 0.6821 - val_loss: 0.6342 - val_accuracy: 0.6498\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 0s 944us/step - loss: 0.6032 - accuracy: 0.6815 - val_loss: 0.6373 - val_accuracy: 0.6431\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6014 - accuracy: 0.6867 - val_loss: 0.6517 - val_accuracy: 0.6242\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 0s 979us/step - loss: 0.5946 - accuracy: 0.6925 - val_loss: 0.6191 - val_accuracy: 0.6621\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 0s 957us/step - loss: 0.5942 - accuracy: 0.6905 - val_loss: 0.6222 - val_accuracy: 0.6575\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 960us/step - loss: 0.5912 - accuracy: 0.6933 - val_loss: 0.6493 - val_accuracy: 0.6257\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 0s 951us/step - loss: 0.5844 - accuracy: 0.7015 - val_loss: 0.6356 - val_accuracy: 0.6364\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.7043 - val_loss: 0.6016 - val_accuracy: 0.6761\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 965us/step - loss: 0.5814 - accuracy: 0.7002 - val_loss: 0.6217 - val_accuracy: 0.6478\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 956us/step - loss: 0.5791 - accuracy: 0.7000 - val_loss: 0.6105 - val_accuracy: 0.6605\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 957us/step - loss: 0.5739 - accuracy: 0.7090 - val_loss: 0.6423 - val_accuracy: 0.6262\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7110 - val_loss: 0.6313 - val_accuracy: 0.6339\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 973us/step - loss: 0.5712 - accuracy: 0.7116 - val_loss: 0.6306 - val_accuracy: 0.6342\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 946us/step - loss: 0.5655 - accuracy: 0.7118 - val_loss: 0.6125 - val_accuracy: 0.6549\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 943us/step - loss: 0.5629 - accuracy: 0.7144 - val_loss: 0.6151 - val_accuracy: 0.6532\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.7193 - val_loss: 0.5647 - val_accuracy: 0.6987\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5576 - accuracy: 0.7191 - val_loss: 0.6372 - val_accuracy: 0.6339\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7193 - val_loss: 0.6246 - val_accuracy: 0.6476\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 975us/step - loss: 0.5517 - accuracy: 0.7262 - val_loss: 0.6199 - val_accuracy: 0.6516\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 957us/step - loss: 0.5510 - accuracy: 0.7222 - val_loss: 0.5990 - val_accuracy: 0.6702\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7239 - val_loss: 0.6091 - val_accuracy: 0.6632\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 971us/step - loss: 0.5479 - accuracy: 0.7273 - val_loss: 0.6292 - val_accuracy: 0.6453\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 957us/step - loss: 0.5443 - accuracy: 0.7277 - val_loss: 0.5890 - val_accuracy: 0.6800\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 945us/step - loss: 0.5411 - accuracy: 0.7320 - val_loss: 0.6314 - val_accuracy: 0.6423\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.7247 - val_loss: 0.6109 - val_accuracy: 0.6605\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 0s 979us/step - loss: 0.5410 - accuracy: 0.7308 - val_loss: 0.5911 - val_accuracy: 0.6774\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 944us/step - loss: 0.5386 - accuracy: 0.7307 - val_loss: 0.6393 - val_accuracy: 0.6357\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.5333 - accuracy: 0.7303 - val_loss: 0.5754 - val_accuracy: 0.6874\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 941us/step - loss: 0.5347 - accuracy: 0.7342 - val_loss: 0.6193 - val_accuracy: 0.6524\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7351 - val_loss: 0.6533 - val_accuracy: 0.6229\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 961us/step - loss: 0.5315 - accuracy: 0.7344 - val_loss: 0.6238 - val_accuracy: 0.6487\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7316 - val_loss: 0.5753 - val_accuracy: 0.6861\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 952us/step - loss: 0.5276 - accuracy: 0.7368 - val_loss: 0.5997 - val_accuracy: 0.6702\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7407 - val_loss: 0.6304 - val_accuracy: 0.6408\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 972us/step - loss: 0.5248 - accuracy: 0.7398 - val_loss: 0.5985 - val_accuracy: 0.6707\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 956us/step - loss: 0.5236 - accuracy: 0.7391 - val_loss: 0.6243 - val_accuracy: 0.6460\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 966us/step - loss: 0.5234 - accuracy: 0.7381 - val_loss: 0.6045 - val_accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 950us/step - loss: 0.5222 - accuracy: 0.7391 - val_loss: 0.6168 - val_accuracy: 0.6531\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7385 - val_loss: 0.5863 - val_accuracy: 0.6778\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.4895 - val_loss: 0.7362 - val_accuracy: 0.3227\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 935us/step - loss: 0.6907 - accuracy: 0.5383 - val_loss: 0.7285 - val_accuracy: 0.4026\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 937us/step - loss: 0.6833 - accuracy: 0.5587 - val_loss: 0.7326 - val_accuracy: 0.4125\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.5879 - val_loss: 0.6931 - val_accuracy: 0.5398\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6677 - accuracy: 0.6019 - val_loss: 0.7018 - val_accuracy: 0.5058\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.6136 - val_loss: 0.7166 - val_accuracy: 0.4743\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 930us/step - loss: 0.6550 - accuracy: 0.6264 - val_loss: 0.6959 - val_accuracy: 0.5297\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.6499 - accuracy: 0.6368 - val_loss: 0.6914 - val_accuracy: 0.5482\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.6422 - val_loss: 0.6861 - val_accuracy: 0.5636\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 979us/step - loss: 0.6394 - accuracy: 0.6497 - val_loss: 0.6750 - val_accuracy: 0.5925\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 986us/step - loss: 0.6352 - accuracy: 0.6488 - val_loss: 0.6982 - val_accuracy: 0.5399\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.6607 - val_loss: 0.6795 - val_accuracy: 0.5751\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6559 - val_loss: 0.6675 - val_accuracy: 0.6026\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6245 - accuracy: 0.6632 - val_loss: 0.6638 - val_accuracy: 0.6072\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.6205 - accuracy: 0.6671 - val_loss: 0.6411 - val_accuracy: 0.6458\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.6157 - accuracy: 0.6718 - val_loss: 0.6637 - val_accuracy: 0.6019\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.6705 - val_loss: 0.6433 - val_accuracy: 0.6378\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.6785 - val_loss: 0.6318 - val_accuracy: 0.6537\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.6763 - val_loss: 0.6545 - val_accuracy: 0.6114\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.6821 - val_loss: 0.6710 - val_accuracy: 0.5823\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.6879 - val_loss: 0.6277 - val_accuracy: 0.6482\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5945 - accuracy: 0.6886 - val_loss: 0.6648 - val_accuracy: 0.5895\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.6914 - val_loss: 0.6190 - val_accuracy: 0.6558\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.6912 - val_loss: 0.6539 - val_accuracy: 0.6017\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.7011 - val_loss: 0.6162 - val_accuracy: 0.6568\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.6948 - val_loss: 0.6372 - val_accuracy: 0.6224\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5767 - accuracy: 0.7043 - val_loss: 0.6517 - val_accuracy: 0.6032\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6950 - val_loss: 0.5844 - val_accuracy: 0.6915\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.6998 - val_loss: 0.5880 - val_accuracy: 0.6847\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.6998 - val_loss: 0.6283 - val_accuracy: 0.6310\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7017 - val_loss: 0.5983 - val_accuracy: 0.6704\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7073 - val_loss: 0.6136 - val_accuracy: 0.6456\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7092 - val_loss: 0.6129 - val_accuracy: 0.6449\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7144 - val_loss: 0.6109 - val_accuracy: 0.6475\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5585 - accuracy: 0.7140 - val_loss: 0.6235 - val_accuracy: 0.6349\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5544 - accuracy: 0.7114 - val_loss: 0.6222 - val_accuracy: 0.6356\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.7159 - val_loss: 0.6562 - val_accuracy: 0.6035\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7116 - val_loss: 0.6617 - val_accuracy: 0.5973\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.7189 - val_loss: 0.6260 - val_accuracy: 0.6316\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7127 - val_loss: 0.6044 - val_accuracy: 0.6532\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.7200 - val_loss: 0.5901 - val_accuracy: 0.6699\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7258 - val_loss: 0.6114 - val_accuracy: 0.6462\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5437 - accuracy: 0.7243 - val_loss: 0.6317 - val_accuracy: 0.6249\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7250 - val_loss: 0.6104 - val_accuracy: 0.6470\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7245 - val_loss: 0.7160 - val_accuracy: 0.5552\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7299 - val_loss: 0.6365 - val_accuracy: 0.6220\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7269 - val_loss: 0.5842 - val_accuracy: 0.6729\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.7277 - val_loss: 0.6535 - val_accuracy: 0.6061\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.7275 - val_loss: 0.6425 - val_accuracy: 0.6174\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7301 - val_loss: 0.6225 - val_accuracy: 0.6366\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.7355 - accuracy: 0.5121 - val_loss: 0.7262 - val_accuracy: 0.3721\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5729 - val_loss: 0.6964 - val_accuracy: 0.5269\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6121 - val_loss: 0.6899 - val_accuracy: 0.5529\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6308 - val_loss: 0.6850 - val_accuracy: 0.5701\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6393 - val_loss: 0.6780 - val_accuracy: 0.5816\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6551 - val_loss: 0.6606 - val_accuracy: 0.6113\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.6587 - val_loss: 0.6743 - val_accuracy: 0.5859\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.6637 - val_loss: 0.6792 - val_accuracy: 0.5811\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.6751 - val_loss: 0.6453 - val_accuracy: 0.6244\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6159 - accuracy: 0.6733 - val_loss: 0.6456 - val_accuracy: 0.6226\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6705 - val_loss: 0.6552 - val_accuracy: 0.6105\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6100 - accuracy: 0.6804 - val_loss: 0.6326 - val_accuracy: 0.6326\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.6028 - accuracy: 0.6880 - val_loss: 0.6392 - val_accuracy: 0.6235\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.6884 - val_loss: 0.6228 - val_accuracy: 0.6447\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5974 - accuracy: 0.6908 - val_loss: 0.6409 - val_accuracy: 0.6205\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.6935 - val_loss: 0.6432 - val_accuracy: 0.6178\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.6946 - val_loss: 0.6432 - val_accuracy: 0.6175\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6966 - val_loss: 0.6408 - val_accuracy: 0.6185\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5902 - accuracy: 0.6968 - val_loss: 0.6470 - val_accuracy: 0.6120\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.7024 - val_loss: 0.6405 - val_accuracy: 0.6157\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7022 - val_loss: 0.6788 - val_accuracy: 0.5859\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7065 - val_loss: 0.6263 - val_accuracy: 0.6312\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7095 - val_loss: 0.6334 - val_accuracy: 0.6238\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7065 - val_loss: 0.6895 - val_accuracy: 0.5729\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.7058 - val_loss: 0.6490 - val_accuracy: 0.6082\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7138 - val_loss: 0.6318 - val_accuracy: 0.6244\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7153 - val_loss: 0.6053 - val_accuracy: 0.6530\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7125 - val_loss: 0.6310 - val_accuracy: 0.6263\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7176 - val_loss: 0.6610 - val_accuracy: 0.5949\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.7221 - val_loss: 0.6172 - val_accuracy: 0.6399\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7213 - val_loss: 0.6462 - val_accuracy: 0.6104\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.7163 - val_loss: 0.6394 - val_accuracy: 0.6180\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.7204 - val_loss: 0.6345 - val_accuracy: 0.6228\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7164 - val_loss: 0.6272 - val_accuracy: 0.6280\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7221 - val_loss: 0.6828 - val_accuracy: 0.5765\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.7196 - val_loss: 0.6049 - val_accuracy: 0.6507\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7249 - val_loss: 0.6523 - val_accuracy: 0.6029\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7321 - val_loss: 0.5940 - val_accuracy: 0.6583\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.7237 - val_loss: 0.6203 - val_accuracy: 0.6331\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5467 - accuracy: 0.7252 - val_loss: 0.6061 - val_accuracy: 0.6475\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.7262 - val_loss: 0.5714 - val_accuracy: 0.6817\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.7277 - val_loss: 0.6755 - val_accuracy: 0.5875\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7245 - val_loss: 0.6027 - val_accuracy: 0.6509\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7284 - val_loss: 0.6503 - val_accuracy: 0.6060\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7269 - val_loss: 0.6559 - val_accuracy: 0.6032\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7320 - val_loss: 0.6571 - val_accuracy: 0.6026\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7284 - val_loss: 0.6689 - val_accuracy: 0.5932\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7301 - val_loss: 0.6395 - val_accuracy: 0.6161\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.7316 - val_loss: 0.5994 - val_accuracy: 0.6562\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7310 - val_loss: 0.6159 - val_accuracy: 0.6363\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5707 - val_loss: 0.7174 - val_accuracy: 0.4221\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.6017 - val_loss: 0.6921 - val_accuracy: 0.5134\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6237 - val_loss: 0.7053 - val_accuracy: 0.4809\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6379 - val_loss: 0.6729 - val_accuracy: 0.5558\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6452 - accuracy: 0.6467 - val_loss: 0.6975 - val_accuracy: 0.5083\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6600 - val_loss: 0.6777 - val_accuracy: 0.5461\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.6680 - val_loss: 0.6452 - val_accuracy: 0.6026\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.6723 - val_loss: 0.6604 - val_accuracy: 0.5728\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6757 - val_loss: 0.6578 - val_accuracy: 0.5802\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6744 - val_loss: 0.6562 - val_accuracy: 0.5839\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6133 - accuracy: 0.6875 - val_loss: 0.6532 - val_accuracy: 0.5893\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6865 - val_loss: 0.6549 - val_accuracy: 0.5893\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.6864 - val_loss: 0.6328 - val_accuracy: 0.6203\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.6981 - val_loss: 0.6533 - val_accuracy: 0.5911\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5962 - accuracy: 0.6987 - val_loss: 0.6267 - val_accuracy: 0.6282\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.6950 - val_loss: 0.6354 - val_accuracy: 0.6128\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.6998 - val_loss: 0.6454 - val_accuracy: 0.6011\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5869 - accuracy: 0.7058 - val_loss: 0.6453 - val_accuracy: 0.6010\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.7019 - val_loss: 0.6385 - val_accuracy: 0.6105\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5834 - accuracy: 0.7075 - val_loss: 0.6428 - val_accuracy: 0.6071\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.7146 - val_loss: 0.6208 - val_accuracy: 0.6291\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.7107 - val_loss: 0.6033 - val_accuracy: 0.6525\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.7121 - val_loss: 0.5944 - val_accuracy: 0.6618\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7174 - val_loss: 0.6180 - val_accuracy: 0.6326\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7174 - val_loss: 0.6222 - val_accuracy: 0.6271\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7217 - val_loss: 0.6034 - val_accuracy: 0.6470\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.7172 - val_loss: 0.5959 - val_accuracy: 0.6602\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.7193 - val_loss: 0.6273 - val_accuracy: 0.6235\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7234 - val_loss: 0.6371 - val_accuracy: 0.6173\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7264 - val_loss: 0.6211 - val_accuracy: 0.6300\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.7241 - val_loss: 0.6395 - val_accuracy: 0.6172\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7237 - val_loss: 0.6012 - val_accuracy: 0.6527\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.7260 - val_loss: 0.6107 - val_accuracy: 0.6397\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7258 - val_loss: 0.6208 - val_accuracy: 0.6304\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5424 - accuracy: 0.7357 - val_loss: 0.5985 - val_accuracy: 0.6541\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5417 - accuracy: 0.7308 - val_loss: 0.5939 - val_accuracy: 0.6589\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7333 - val_loss: 0.6529 - val_accuracy: 0.6061\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.7323 - val_loss: 0.6210 - val_accuracy: 0.6294\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5343 - accuracy: 0.7368 - val_loss: 0.6066 - val_accuracy: 0.6436\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7364 - val_loss: 0.6093 - val_accuracy: 0.6402\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.7385 - val_loss: 0.6072 - val_accuracy: 0.6446\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7400 - val_loss: 0.6230 - val_accuracy: 0.6267\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7340 - val_loss: 0.5864 - val_accuracy: 0.6635\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.7393 - val_loss: 0.5784 - val_accuracy: 0.6692\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.7344 - val_loss: 0.6350 - val_accuracy: 0.6190\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7465 - val_loss: 0.6355 - val_accuracy: 0.6185\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7391 - val_loss: 0.6447 - val_accuracy: 0.6132\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7381 - val_loss: 0.6376 - val_accuracy: 0.6189\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.7424 - val_loss: 0.5842 - val_accuracy: 0.6624\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7437 - val_loss: 0.6162 - val_accuracy: 0.6403\n",
      "Epoch 1/50\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.7522 - accuracy: 0.5236 - val_loss: 0.7749 - val_accuracy: 0.1226\n",
      "Epoch 2/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.5260 - val_loss: 0.7668 - val_accuracy: 0.1295\n",
      "Epoch 3/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5561 - val_loss: 0.7380 - val_accuracy: 0.2357\n",
      "Epoch 4/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5768 - val_loss: 0.7554 - val_accuracy: 0.2625\n",
      "Epoch 5/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.5998 - val_loss: 0.7242 - val_accuracy: 0.4152\n",
      "Epoch 6/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6256 - val_loss: 0.7194 - val_accuracy: 0.4514\n",
      "Epoch 7/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6387 - val_loss: 0.7333 - val_accuracy: 0.4396\n",
      "Epoch 8/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6501 - val_loss: 0.6900 - val_accuracy: 0.5570\n",
      "Epoch 9/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6542 - val_loss: 0.7027 - val_accuracy: 0.5291\n",
      "Epoch 10/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.6578 - val_loss: 0.6964 - val_accuracy: 0.5464\n",
      "Epoch 11/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.6710 - val_loss: 0.6967 - val_accuracy: 0.5495\n",
      "Epoch 12/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.6811 - val_loss: 0.6699 - val_accuracy: 0.5976\n",
      "Epoch 13/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6205 - accuracy: 0.6794 - val_loss: 0.6483 - val_accuracy: 0.6353\n",
      "Epoch 14/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6152 - accuracy: 0.6856 - val_loss: 0.6821 - val_accuracy: 0.5777\n",
      "Epoch 15/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6114 - accuracy: 0.6886 - val_loss: 0.6482 - val_accuracy: 0.6303\n",
      "Epoch 16/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.6882 - val_loss: 0.6318 - val_accuracy: 0.6496\n",
      "Epoch 17/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.6023 - accuracy: 0.6912 - val_loss: 0.6717 - val_accuracy: 0.5967\n",
      "Epoch 18/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5962 - accuracy: 0.7017 - val_loss: 0.6185 - val_accuracy: 0.6623\n",
      "Epoch 19/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.6978 - val_loss: 0.6672 - val_accuracy: 0.6022\n",
      "Epoch 20/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5921 - accuracy: 0.7006 - val_loss: 0.6541 - val_accuracy: 0.6144\n",
      "Epoch 21/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.7047 - val_loss: 0.6421 - val_accuracy: 0.6267\n",
      "Epoch 22/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.7099 - val_loss: 0.6672 - val_accuracy: 0.5981\n",
      "Epoch 23/50\n",
      "335/335 [==============================] - 1s 1ms/step - loss: 0.5835 - accuracy: 0.7080 - val_loss: 0.6470 - val_accuracy: 0.6161\n",
      "Epoch 24/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.7166 - val_loss: 0.6472 - val_accuracy: 0.6142\n",
      "Epoch 25/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.7107 - val_loss: 0.6213 - val_accuracy: 0.6431\n",
      "Epoch 26/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.7131 - val_loss: 0.6537 - val_accuracy: 0.6074\n",
      "Epoch 27/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7166 - val_loss: 0.6342 - val_accuracy: 0.6273\n",
      "Epoch 28/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.7185 - val_loss: 0.6380 - val_accuracy: 0.6221\n",
      "Epoch 29/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7185 - val_loss: 0.7028 - val_accuracy: 0.5631\n",
      "Epoch 30/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7249 - val_loss: 0.6400 - val_accuracy: 0.6205\n",
      "Epoch 31/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7264 - val_loss: 0.6215 - val_accuracy: 0.6378\n",
      "Epoch 32/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7273 - val_loss: 0.6458 - val_accuracy: 0.6145\n",
      "Epoch 33/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.7308 - val_loss: 0.6468 - val_accuracy: 0.6137\n",
      "Epoch 34/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7258 - val_loss: 0.6420 - val_accuracy: 0.6186\n",
      "Epoch 35/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5458 - accuracy: 0.7277 - val_loss: 0.5806 - val_accuracy: 0.6790\n",
      "Epoch 36/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.7308 - val_loss: 0.6577 - val_accuracy: 0.6062\n",
      "Epoch 37/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.7331 - val_loss: 0.6656 - val_accuracy: 0.6002\n",
      "Epoch 38/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7316 - val_loss: 0.6336 - val_accuracy: 0.6269\n",
      "Epoch 39/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7316 - val_loss: 0.6385 - val_accuracy: 0.6244\n",
      "Epoch 40/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.7350 - val_loss: 0.5979 - val_accuracy: 0.6585\n",
      "Epoch 41/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.7396 - val_loss: 0.6154 - val_accuracy: 0.6449\n",
      "Epoch 42/50\n",
      "335/335 [==============================] - 0s 964us/step - loss: 0.5302 - accuracy: 0.7402 - val_loss: 0.6084 - val_accuracy: 0.6504\n",
      "Epoch 43/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.7378 - val_loss: 0.6367 - val_accuracy: 0.6263\n",
      "Epoch 44/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7387 - val_loss: 0.6890 - val_accuracy: 0.5912\n",
      "Epoch 45/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7422 - val_loss: 0.6488 - val_accuracy: 0.6185\n",
      "Epoch 46/50\n",
      "335/335 [==============================] - 0s 943us/step - loss: 0.5243 - accuracy: 0.7422 - val_loss: 0.5988 - val_accuracy: 0.6592\n",
      "Epoch 47/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7437 - val_loss: 0.6280 - val_accuracy: 0.6356\n",
      "Epoch 48/50\n",
      "335/335 [==============================] - 0s 987us/step - loss: 0.5237 - accuracy: 0.7421 - val_loss: 0.6122 - val_accuracy: 0.6471\n",
      "Epoch 49/50\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7411 - val_loss: 0.6088 - val_accuracy: 0.6506\n",
      "Epoch 50/50\n",
      "335/335 [==============================] - 0s 969us/step - loss: 0.5148 - accuracy: 0.7454 - val_loss: 0.6833 - val_accuracy: 0.6001\n",
      "\n",
      "Training model with sample_size_ratio=0.05...\n",
      "DP-SGD with sampling rate = 0.598% and noise_multiplier = 1.1 iterated over 8360 steps satisfies differential privacy with eps = 3.3 and delta = 1e-05.\n",
      "The optimal RDP order is 8.0.\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5679 - val_loss: 0.6840 - val_accuracy: 0.5873\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5761 - val_loss: 0.6757 - val_accuracy: 0.6106\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5798 - val_loss: 0.7041 - val_accuracy: 0.5035\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.5817 - val_loss: 0.6568 - val_accuracy: 0.6584\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6321 - val_loss: 0.6613 - val_accuracy: 0.6272\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6030 - val_loss: 0.6557 - val_accuracy: 0.6320\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6292 - val_loss: 0.6464 - val_accuracy: 0.6459\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6370 - val_loss: 0.6544 - val_accuracy: 0.6200\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6393 - val_loss: 0.6515 - val_accuracy: 0.6220\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6568 - val_loss: 0.6338 - val_accuracy: 0.6539\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6490 - val_loss: 0.6364 - val_accuracy: 0.6438\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.6594 - val_loss: 0.6428 - val_accuracy: 0.6278\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6572 - val_loss: 0.6289 - val_accuracy: 0.6517\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6636 - val_loss: 0.6659 - val_accuracy: 0.5874\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6692 - val_loss: 0.6156 - val_accuracy: 0.6689\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6650 - val_loss: 0.6249 - val_accuracy: 0.6477\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6141 - accuracy: 0.6774 - val_loss: 0.6065 - val_accuracy: 0.6786\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 0.6751 - val_loss: 0.6048 - val_accuracy: 0.6786\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6811 - val_loss: 0.6304 - val_accuracy: 0.6357\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6766 - val_loss: 0.6153 - val_accuracy: 0.6594\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6759 - val_loss: 0.6376 - val_accuracy: 0.6240\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.6733 - val_loss: 0.6745 - val_accuracy: 0.5751\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.6905 - val_loss: 0.6252 - val_accuracy: 0.6391\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6841 - val_loss: 0.6300 - val_accuracy: 0.6325\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6875 - val_loss: 0.6129 - val_accuracy: 0.6556\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5961 - accuracy: 0.6826 - val_loss: 0.6227 - val_accuracy: 0.6399\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.6916 - val_loss: 0.6448 - val_accuracy: 0.6119\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.6964 - val_loss: 0.5954 - val_accuracy: 0.6731\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6938 - val_loss: 0.6135 - val_accuracy: 0.6529\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7006 - val_loss: 0.6595 - val_accuracy: 0.5969\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.7002 - val_loss: 0.5800 - val_accuracy: 0.6920\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.7028 - val_loss: 0.5896 - val_accuracy: 0.6786\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.6976 - val_loss: 0.6324 - val_accuracy: 0.6261\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7054 - val_loss: 0.6169 - val_accuracy: 0.6466\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7069 - val_loss: 0.5964 - val_accuracy: 0.6702\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7062 - val_loss: 0.6569 - val_accuracy: 0.6030\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.6979 - val_loss: 0.6217 - val_accuracy: 0.6389\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7032 - val_loss: 0.6165 - val_accuracy: 0.6447\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7054 - val_loss: 0.6191 - val_accuracy: 0.6393\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7136 - val_loss: 0.5803 - val_accuracy: 0.6841\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7047 - val_loss: 0.6162 - val_accuracy: 0.6424\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7077 - val_loss: 0.6436 - val_accuracy: 0.6126\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7133 - val_loss: 0.6101 - val_accuracy: 0.6522\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7163 - val_loss: 0.6276 - val_accuracy: 0.6301\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7036 - val_loss: 0.5807 - val_accuracy: 0.6773\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7200 - val_loss: 0.5942 - val_accuracy: 0.6662\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7151 - val_loss: 0.5869 - val_accuracy: 0.6704\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7133 - val_loss: 0.5819 - val_accuracy: 0.6743\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7118 - val_loss: 0.6326 - val_accuracy: 0.6231\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7092 - val_loss: 0.5902 - val_accuracy: 0.6675\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.4673 - val_loss: 0.7721 - val_accuracy: 0.2423\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.4729 - val_loss: 0.7270 - val_accuracy: 0.3591\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.4550 - val_loss: 0.7257 - val_accuracy: 0.3526\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.4793 - val_loss: 0.7102 - val_accuracy: 0.3804\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.4804 - val_loss: 0.7011 - val_accuracy: 0.4108\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.4964 - val_loss: 0.6864 - val_accuracy: 0.5301\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.5021 - val_loss: 0.6837 - val_accuracy: 0.5892\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5305 - val_loss: 0.6891 - val_accuracy: 0.5453\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5630 - val_loss: 0.6844 - val_accuracy: 0.5659\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5679 - val_loss: 0.6774 - val_accuracy: 0.6040\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.5817 - val_loss: 0.6782 - val_accuracy: 0.5964\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.5910 - val_loss: 0.6634 - val_accuracy: 0.6514\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.5918 - val_loss: 0.6681 - val_accuracy: 0.6247\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6049 - val_loss: 0.6767 - val_accuracy: 0.5958\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6146 - val_loss: 0.6562 - val_accuracy: 0.6503\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.6187 - val_loss: 0.6591 - val_accuracy: 0.6365\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6321 - val_loss: 0.6537 - val_accuracy: 0.6455\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6419 - val_loss: 0.6526 - val_accuracy: 0.6430\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6370 - val_loss: 0.6564 - val_accuracy: 0.6304\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6437 - val_loss: 0.6445 - val_accuracy: 0.6498\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6452 - accuracy: 0.6464 - val_loss: 0.6521 - val_accuracy: 0.6314\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6553 - val_loss: 0.6497 - val_accuracy: 0.6326\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6377 - accuracy: 0.6531 - val_loss: 0.6384 - val_accuracy: 0.6528\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6587 - val_loss: 0.6261 - val_accuracy: 0.6723\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6520 - val_loss: 0.6410 - val_accuracy: 0.6391\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.6564 - val_loss: 0.6368 - val_accuracy: 0.6436\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.6583 - val_loss: 0.6327 - val_accuracy: 0.6513\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6550 - val_loss: 0.6387 - val_accuracy: 0.6378\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.6643 - val_loss: 0.6280 - val_accuracy: 0.6555\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6632 - val_loss: 0.6126 - val_accuracy: 0.6739\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.6695 - val_loss: 0.6297 - val_accuracy: 0.6470\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.6763 - val_loss: 0.6309 - val_accuracy: 0.6417\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6721 - val_loss: 0.6272 - val_accuracy: 0.6481\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6789 - val_loss: 0.5992 - val_accuracy: 0.6825\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6695 - val_loss: 0.6268 - val_accuracy: 0.6474\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6736 - val_loss: 0.6182 - val_accuracy: 0.6594\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6834 - val_loss: 0.6118 - val_accuracy: 0.6655\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6114 - accuracy: 0.6628 - val_loss: 0.6106 - val_accuracy: 0.6660\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6111 - accuracy: 0.6800 - val_loss: 0.6145 - val_accuracy: 0.6607\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.6699 - val_loss: 0.6098 - val_accuracy: 0.6658\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6864 - val_loss: 0.6012 - val_accuracy: 0.6721\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6856 - val_loss: 0.6095 - val_accuracy: 0.6654\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.6837 - val_loss: 0.6263 - val_accuracy: 0.6465\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6029 - accuracy: 0.6864 - val_loss: 0.6007 - val_accuracy: 0.6710\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6871 - val_loss: 0.5816 - val_accuracy: 0.6908\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6871 - val_loss: 0.5965 - val_accuracy: 0.6737\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6879 - val_loss: 0.6015 - val_accuracy: 0.6685\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6927 - val_loss: 0.6142 - val_accuracy: 0.6569\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6867 - val_loss: 0.6047 - val_accuracy: 0.6640\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.6983 - val_loss: 0.6114 - val_accuracy: 0.6582\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.5260 - val_loss: 0.6899 - val_accuracy: 0.4907\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.5241 - val_loss: 0.6914 - val_accuracy: 0.5231\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5626 - val_loss: 0.6814 - val_accuracy: 0.5817\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5682 - val_loss: 0.6988 - val_accuracy: 0.5257\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5772 - val_loss: 0.6896 - val_accuracy: 0.5615\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.5989 - val_loss: 0.6878 - val_accuracy: 0.5647\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6041 - val_loss: 0.6550 - val_accuracy: 0.6514\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6015 - val_loss: 0.6698 - val_accuracy: 0.6047\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6202 - val_loss: 0.6530 - val_accuracy: 0.6482\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6097 - val_loss: 0.6673 - val_accuracy: 0.6065\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6280 - val_loss: 0.6235 - val_accuracy: 0.6969\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6262 - val_loss: 0.6518 - val_accuracy: 0.6396\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6318 - val_loss: 0.6524 - val_accuracy: 0.6337\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6303 - val_loss: 0.6497 - val_accuracy: 0.6372\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.6378 - val_loss: 0.6353 - val_accuracy: 0.6594\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6407 - val_loss: 0.6633 - val_accuracy: 0.6078\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6452 - val_loss: 0.6611 - val_accuracy: 0.6109\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6479 - val_loss: 0.6527 - val_accuracy: 0.6259\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6505 - val_loss: 0.6159 - val_accuracy: 0.6823\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6434 - val_loss: 0.6565 - val_accuracy: 0.6185\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6437 - val_loss: 0.6219 - val_accuracy: 0.6671\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6512 - val_loss: 0.6423 - val_accuracy: 0.6387\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6464 - val_loss: 0.5973 - val_accuracy: 0.7042\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6482 - val_loss: 0.6315 - val_accuracy: 0.6469\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6512 - val_loss: 0.6035 - val_accuracy: 0.6901\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.6636 - val_loss: 0.6296 - val_accuracy: 0.6492\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6512 - val_loss: 0.6456 - val_accuracy: 0.6323\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.6505 - val_loss: 0.6405 - val_accuracy: 0.6372\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6643 - val_loss: 0.6261 - val_accuracy: 0.6538\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6591 - val_loss: 0.6290 - val_accuracy: 0.6503\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6561 - val_loss: 0.6177 - val_accuracy: 0.6652\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6613 - val_loss: 0.6092 - val_accuracy: 0.6722\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6744 - val_loss: 0.6244 - val_accuracy: 0.6540\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6609 - val_loss: 0.6154 - val_accuracy: 0.6659\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6665 - val_loss: 0.6277 - val_accuracy: 0.6495\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6650 - val_loss: 0.6033 - val_accuracy: 0.6765\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6699 - val_loss: 0.6055 - val_accuracy: 0.6742\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6796 - val_loss: 0.6084 - val_accuracy: 0.6700\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.6680 - val_loss: 0.6272 - val_accuracy: 0.6513\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6740 - val_loss: 0.6102 - val_accuracy: 0.6659\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6707 - val_loss: 0.6333 - val_accuracy: 0.6425\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6744 - val_loss: 0.6076 - val_accuracy: 0.6686\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6748 - val_loss: 0.6236 - val_accuracy: 0.6525\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.6815 - val_loss: 0.5859 - val_accuracy: 0.6869\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6748 - val_loss: 0.6465 - val_accuracy: 0.6213\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6804 - val_loss: 0.6010 - val_accuracy: 0.6701\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6834 - val_loss: 0.6168 - val_accuracy: 0.6568\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6841 - val_loss: 0.6214 - val_accuracy: 0.6512\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.6916 - val_loss: 0.5989 - val_accuracy: 0.6688\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6796 - val_loss: 0.6124 - val_accuracy: 0.6558\n",
      "Epoch 1/50\n",
      " 93/168 [===============>..............] - ETA: 0s - loss: 0.7408 - accuracy: 0.4556WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7250 - accuracy: 0.4770 - val_loss: 0.6910 - val_accuracy: 0.5289\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.5021 - val_loss: 0.6558 - val_accuracy: 0.6823\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.5166 - val_loss: 0.6955 - val_accuracy: 0.5151\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5327 - val_loss: 0.6719 - val_accuracy: 0.5863\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5305 - val_loss: 0.6895 - val_accuracy: 0.5321\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5566 - val_loss: 0.6724 - val_accuracy: 0.5762\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5660 - val_loss: 0.6617 - val_accuracy: 0.6056\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5697 - val_loss: 0.6860 - val_accuracy: 0.5364\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5753 - val_loss: 0.6781 - val_accuracy: 0.5603\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.5809 - val_loss: 0.6680 - val_accuracy: 0.5880\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.6052 - val_loss: 0.6495 - val_accuracy: 0.6341\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6026 - val_loss: 0.6348 - val_accuracy: 0.6660\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6000 - val_loss: 0.6517 - val_accuracy: 0.6251\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6127 - val_loss: 0.6550 - val_accuracy: 0.6171\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6265 - val_loss: 0.6476 - val_accuracy: 0.6299\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6232 - val_loss: 0.6348 - val_accuracy: 0.6523\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6232 - val_loss: 0.6360 - val_accuracy: 0.6457\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6206 - val_loss: 0.6313 - val_accuracy: 0.6533\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6239 - val_loss: 0.6338 - val_accuracy: 0.6441\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6277 - val_loss: 0.6488 - val_accuracy: 0.6188\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6187 - val_loss: 0.6554 - val_accuracy: 0.6099\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6381 - val_loss: 0.6305 - val_accuracy: 0.6450\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.6430 - val_loss: 0.6281 - val_accuracy: 0.6468\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6449 - val_loss: 0.6393 - val_accuracy: 0.6246\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6520 - val_loss: 0.6562 - val_accuracy: 0.6054\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6456 - val_loss: 0.6234 - val_accuracy: 0.6489\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6456 - val_loss: 0.6440 - val_accuracy: 0.6176\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6426 - val_loss: 0.6133 - val_accuracy: 0.6603\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6456 - val_loss: 0.6448 - val_accuracy: 0.6172\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6561 - val_loss: 0.6021 - val_accuracy: 0.6757\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6576 - val_loss: 0.6316 - val_accuracy: 0.6301\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6501 - val_loss: 0.6257 - val_accuracy: 0.6385\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6647 - val_loss: 0.6420 - val_accuracy: 0.6148\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6145 - accuracy: 0.6710 - val_loss: 0.6292 - val_accuracy: 0.6305\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6553 - val_loss: 0.6268 - val_accuracy: 0.6341\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6684 - val_loss: 0.6119 - val_accuracy: 0.6558\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6695 - val_loss: 0.6213 - val_accuracy: 0.6415\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6145 - accuracy: 0.6710 - val_loss: 0.6265 - val_accuracy: 0.6313\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6707 - val_loss: 0.6533 - val_accuracy: 0.6004\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6721 - val_loss: 0.6371 - val_accuracy: 0.6154\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6778 - val_loss: 0.6025 - val_accuracy: 0.6632\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6736 - val_loss: 0.6119 - val_accuracy: 0.6511\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6684 - val_loss: 0.6112 - val_accuracy: 0.6516\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6070 - accuracy: 0.6721 - val_loss: 0.6011 - val_accuracy: 0.6642\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6077 - accuracy: 0.6774 - val_loss: 0.6093 - val_accuracy: 0.6525\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6047 - accuracy: 0.6800 - val_loss: 0.6122 - val_accuracy: 0.6479\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6864 - val_loss: 0.6421 - val_accuracy: 0.6068\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6822 - val_loss: 0.5982 - val_accuracy: 0.6662\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5958 - accuracy: 0.6931 - val_loss: 0.6105 - val_accuracy: 0.6469\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.6916 - val_loss: 0.6198 - val_accuracy: 0.6374\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.5181 - val_loss: 0.7346 - val_accuracy: 0.4012\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5525 - val_loss: 0.6998 - val_accuracy: 0.5162\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.5682 - val_loss: 0.6955 - val_accuracy: 0.5412\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5817 - val_loss: 0.6890 - val_accuracy: 0.5615\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.6034 - val_loss: 0.6894 - val_accuracy: 0.5633\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.6157 - val_loss: 0.6640 - val_accuracy: 0.6192\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6224 - val_loss: 0.6650 - val_accuracy: 0.6123\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6258 - val_loss: 0.6643 - val_accuracy: 0.6117\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6336 - val_loss: 0.6773 - val_accuracy: 0.5834\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6393 - val_loss: 0.6608 - val_accuracy: 0.6171\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6465 - accuracy: 0.6437 - val_loss: 0.6689 - val_accuracy: 0.6021\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.6493 - val_loss: 0.6740 - val_accuracy: 0.5922\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6201\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6482 - val_loss: 0.6784 - val_accuracy: 0.5838\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6594 - val_loss: 0.6426 - val_accuracy: 0.6428\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6579 - val_loss: 0.6572 - val_accuracy: 0.6178\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6688 - val_loss: 0.6461 - val_accuracy: 0.6337\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6598 - val_loss: 0.6625 - val_accuracy: 0.6122\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6751 - val_loss: 0.6377 - val_accuracy: 0.6439\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6279 - accuracy: 0.6639 - val_loss: 0.6318 - val_accuracy: 0.6561\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.6669 - val_loss: 0.6408 - val_accuracy: 0.6365\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6804 - val_loss: 0.6308 - val_accuracy: 0.6533\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6770 - val_loss: 0.6363 - val_accuracy: 0.6418\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6770 - val_loss: 0.6534 - val_accuracy: 0.6147\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.6807 - val_loss: 0.6401 - val_accuracy: 0.6326\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6186 - accuracy: 0.6789 - val_loss: 0.6466 - val_accuracy: 0.6220\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6837 - val_loss: 0.6174 - val_accuracy: 0.6623\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6964 - val_loss: 0.6418 - val_accuracy: 0.6294\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.6845 - val_loss: 0.6464 - val_accuracy: 0.6229\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6077 - accuracy: 0.6931 - val_loss: 0.6139 - val_accuracy: 0.6631\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6088 - accuracy: 0.6819 - val_loss: 0.6226 - val_accuracy: 0.6573\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6826 - val_loss: 0.6510 - val_accuracy: 0.6184\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6890 - val_loss: 0.6166 - val_accuracy: 0.6612\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.7032 - val_loss: 0.6099 - val_accuracy: 0.6649\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.7017 - val_loss: 0.6224 - val_accuracy: 0.6572\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5969 - accuracy: 0.6972 - val_loss: 0.6229 - val_accuracy: 0.6570\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6916 - val_loss: 0.6292 - val_accuracy: 0.6529\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.6920 - val_loss: 0.6308 - val_accuracy: 0.6519\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.7006 - val_loss: 0.6178 - val_accuracy: 0.6610\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.7043 - val_loss: 0.6206 - val_accuracy: 0.6597\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.6957 - val_loss: 0.5986 - val_accuracy: 0.6701\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.7054 - val_loss: 0.6359 - val_accuracy: 0.6457\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.7032 - val_loss: 0.6226 - val_accuracy: 0.6571\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5901 - accuracy: 0.7039 - val_loss: 0.6253 - val_accuracy: 0.6545\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.7032 - val_loss: 0.6443 - val_accuracy: 0.6368\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7110 - val_loss: 0.5909 - val_accuracy: 0.6741\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7021 - val_loss: 0.6300 - val_accuracy: 0.6485\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7110 - val_loss: 0.5853 - val_accuracy: 0.6805\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.7050 - val_loss: 0.6069 - val_accuracy: 0.6639\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.7069 - val_loss: 0.5766 - val_accuracy: 0.6894\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.5368 - val_loss: 0.6746 - val_accuracy: 0.5977\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5764 - val_loss: 0.6919 - val_accuracy: 0.5239\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.5978 - val_loss: 0.6805 - val_accuracy: 0.5562\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5996 - val_loss: 0.6483 - val_accuracy: 0.6575\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6056 - val_loss: 0.6698 - val_accuracy: 0.5697\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6243 - val_loss: 0.6501 - val_accuracy: 0.6246\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6236 - val_loss: 0.6921 - val_accuracy: 0.5269\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6325 - val_loss: 0.6535 - val_accuracy: 0.6023\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6482 - val_loss: 0.6509 - val_accuracy: 0.6050\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6445 - val_loss: 0.6558 - val_accuracy: 0.5944\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.6647 - val_loss: 0.6882 - val_accuracy: 0.5375\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.6688 - val_loss: 0.6708 - val_accuracy: 0.5620\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6669 - val_loss: 0.6480 - val_accuracy: 0.6021\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6647 - val_loss: 0.6326 - val_accuracy: 0.6253\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6639 - val_loss: 0.6172 - val_accuracy: 0.6509\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6744 - val_loss: 0.6329 - val_accuracy: 0.6206\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6183 - accuracy: 0.6916 - val_loss: 0.6383 - val_accuracy: 0.6113\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6759 - val_loss: 0.6246 - val_accuracy: 0.6299\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6186 - accuracy: 0.6875 - val_loss: 0.6513 - val_accuracy: 0.5896\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6774 - val_loss: 0.6216 - val_accuracy: 0.6313\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6819 - val_loss: 0.6133 - val_accuracy: 0.6431\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6882 - val_loss: 0.6465 - val_accuracy: 0.5963\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.6826 - val_loss: 0.6263 - val_accuracy: 0.6208\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.6972 - val_loss: 0.5960 - val_accuracy: 0.6647\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6849 - val_loss: 0.6387 - val_accuracy: 0.6058\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.6845 - val_loss: 0.6127 - val_accuracy: 0.6364\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.6867 - val_loss: 0.6047 - val_accuracy: 0.6479\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.6998 - val_loss: 0.6149 - val_accuracy: 0.6324\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.7039 - val_loss: 0.6027 - val_accuracy: 0.6491\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.7032 - val_loss: 0.6420 - val_accuracy: 0.5996\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6998 - val_loss: 0.6116 - val_accuracy: 0.6357\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.7148 - val_loss: 0.5778 - val_accuracy: 0.6752\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.7103 - val_loss: 0.5741 - val_accuracy: 0.6783\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7095 - val_loss: 0.6620 - val_accuracy: 0.5801\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7028 - val_loss: 0.6017 - val_accuracy: 0.6486\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.7050 - val_loss: 0.6071 - val_accuracy: 0.6412\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7099 - val_loss: 0.6260 - val_accuracy: 0.6178\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.7092 - val_loss: 0.6096 - val_accuracy: 0.6384\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7159 - val_loss: 0.6210 - val_accuracy: 0.6242\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7136 - val_loss: 0.6153 - val_accuracy: 0.6315\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7099 - val_loss: 0.6193 - val_accuracy: 0.6277\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.7129 - val_loss: 0.5703 - val_accuracy: 0.6739\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.7118 - val_loss: 0.5855 - val_accuracy: 0.6607\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7151 - val_loss: 0.6185 - val_accuracy: 0.6302\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7230 - val_loss: 0.6081 - val_accuracy: 0.6418\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7178 - val_loss: 0.5902 - val_accuracy: 0.6571\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7163 - val_loss: 0.5855 - val_accuracy: 0.6603\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7200 - val_loss: 0.5942 - val_accuracy: 0.6539\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7178 - val_loss: 0.5895 - val_accuracy: 0.6576\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7215 - val_loss: 0.5868 - val_accuracy: 0.6607\n",
      "Epoch 1/50\n",
      "  1/168 [..............................] - ETA: 0s - loss: 0.4940 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0012s). Check your callbacks.\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5686 - val_loss: 0.6947 - val_accuracy: 0.5150\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6700 - accuracy: 0.5903 - val_loss: 0.6651 - val_accuracy: 0.6148\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6105 - val_loss: 0.6776 - val_accuracy: 0.5640\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6067 - val_loss: 0.6592 - val_accuracy: 0.6260\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6221 - val_loss: 0.6505 - val_accuracy: 0.6467\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6415 - val_loss: 0.6414 - val_accuracy: 0.6633\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6434 - val_loss: 0.6331 - val_accuracy: 0.6782\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6475 - val_loss: 0.6426 - val_accuracy: 0.6502\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6407 - val_loss: 0.6170 - val_accuracy: 0.6963\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6665 - val_loss: 0.6137 - val_accuracy: 0.6965\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6628 - val_loss: 0.6302 - val_accuracy: 0.6663\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.6639 - val_loss: 0.6189 - val_accuracy: 0.6832\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6557 - val_loss: 0.6283 - val_accuracy: 0.6604\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6733 - val_loss: 0.6027 - val_accuracy: 0.7011\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6167 - accuracy: 0.6755 - val_loss: 0.6154 - val_accuracy: 0.6800\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.6796 - val_loss: 0.5999 - val_accuracy: 0.6987\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6729 - val_loss: 0.6214 - val_accuracy: 0.6631\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6793 - val_loss: 0.6077 - val_accuracy: 0.6823\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.6879 - val_loss: 0.6085 - val_accuracy: 0.6795\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6051 - accuracy: 0.6864 - val_loss: 0.6278 - val_accuracy: 0.6514\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.6916 - val_loss: 0.6210 - val_accuracy: 0.6602\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.6920 - val_loss: 0.6121 - val_accuracy: 0.6674\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6927 - val_loss: 0.6252 - val_accuracy: 0.6497\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.7009 - val_loss: 0.6012 - val_accuracy: 0.6794\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.6994 - val_loss: 0.6276 - val_accuracy: 0.6457\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7036 - val_loss: 0.5877 - val_accuracy: 0.6935\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7103 - val_loss: 0.5884 - val_accuracy: 0.6905\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.7028 - val_loss: 0.6140 - val_accuracy: 0.6569\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.7050 - val_loss: 0.5833 - val_accuracy: 0.6955\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7095 - val_loss: 0.6200 - val_accuracy: 0.6492\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.7107 - val_loss: 0.5646 - val_accuracy: 0.7095\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.7080 - val_loss: 0.5950 - val_accuracy: 0.6765\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7163 - val_loss: 0.6005 - val_accuracy: 0.6656\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7155 - val_loss: 0.5757 - val_accuracy: 0.6966\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7069 - val_loss: 0.5885 - val_accuracy: 0.6825\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7207 - val_loss: 0.5841 - val_accuracy: 0.6862\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7207 - val_loss: 0.5730 - val_accuracy: 0.6969\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7178 - val_loss: 0.5966 - val_accuracy: 0.6715\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7189 - val_loss: 0.5817 - val_accuracy: 0.6862\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7200 - val_loss: 0.5772 - val_accuracy: 0.6901\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7140 - val_loss: 0.6056 - val_accuracy: 0.6587\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7163 - val_loss: 0.6019 - val_accuracy: 0.6647\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7133 - val_loss: 0.5953 - val_accuracy: 0.6729\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7166 - val_loss: 0.5947 - val_accuracy: 0.6730\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7189 - val_loss: 0.5420 - val_accuracy: 0.7181\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7245 - val_loss: 0.6203 - val_accuracy: 0.6445\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7264 - val_loss: 0.6081 - val_accuracy: 0.6591\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7297 - val_loss: 0.5912 - val_accuracy: 0.6739\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7286 - val_loss: 0.6029 - val_accuracy: 0.6643\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7234 - val_loss: 0.6016 - val_accuracy: 0.6647\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7122 - accuracy: 0.5084 - val_loss: 0.6719 - val_accuracy: 0.5946\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.5338 - val_loss: 0.6857 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5398 - val_loss: 0.6673 - val_accuracy: 0.6018\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5585 - val_loss: 0.6892 - val_accuracy: 0.5403\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.5757 - val_loss: 0.6608 - val_accuracy: 0.6073\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.5776 - val_loss: 0.6494 - val_accuracy: 0.6346\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.5951 - val_loss: 0.6400 - val_accuracy: 0.6532\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.5993 - val_loss: 0.6481 - val_accuracy: 0.6386\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.5989 - val_loss: 0.6429 - val_accuracy: 0.6466\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.6176 - val_loss: 0.6509 - val_accuracy: 0.6309\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6265 - val_loss: 0.6329 - val_accuracy: 0.6583\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6146 - val_loss: 0.6596 - val_accuracy: 0.6111\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6288 - val_loss: 0.6759 - val_accuracy: 0.5865\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6318 - val_loss: 0.6312 - val_accuracy: 0.6563\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6527 - val_loss: 0.6469 - val_accuracy: 0.6305\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6456 - val_loss: 0.6584 - val_accuracy: 0.6148\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6546 - val_loss: 0.6094 - val_accuracy: 0.6810\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6587 - val_loss: 0.6167 - val_accuracy: 0.6690\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6632 - val_loss: 0.6246 - val_accuracy: 0.6582\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6598 - val_loss: 0.6311 - val_accuracy: 0.6514\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6665 - val_loss: 0.6250 - val_accuracy: 0.6565\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6699 - val_loss: 0.6255 - val_accuracy: 0.6547\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6695 - val_loss: 0.6124 - val_accuracy: 0.6656\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6815 - val_loss: 0.6380 - val_accuracy: 0.6326\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6763 - val_loss: 0.6184 - val_accuracy: 0.6569\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6770 - val_loss: 0.6153 - val_accuracy: 0.6590\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6796 - val_loss: 0.6217 - val_accuracy: 0.6512\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6815 - val_loss: 0.6062 - val_accuracy: 0.6664\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6815 - val_loss: 0.6123 - val_accuracy: 0.6574\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6964 - val_loss: 0.6089 - val_accuracy: 0.6600\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.6931 - val_loss: 0.6120 - val_accuracy: 0.6550\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.6931 - val_loss: 0.6082 - val_accuracy: 0.6576\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6942 - val_loss: 0.5718 - val_accuracy: 0.6974\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6923 - val_loss: 0.6105 - val_accuracy: 0.6522\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7028 - val_loss: 0.5827 - val_accuracy: 0.6851\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6905 - val_loss: 0.6099 - val_accuracy: 0.6520\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6964 - val_loss: 0.5653 - val_accuracy: 0.6994\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7021 - val_loss: 0.5910 - val_accuracy: 0.6712\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.7107 - val_loss: 0.5604 - val_accuracy: 0.7012\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7028 - val_loss: 0.6443 - val_accuracy: 0.6175\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7021 - val_loss: 0.5930 - val_accuracy: 0.6659\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6979 - val_loss: 0.6177 - val_accuracy: 0.6418\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7013 - val_loss: 0.6039 - val_accuracy: 0.6539\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7103 - val_loss: 0.5597 - val_accuracy: 0.6929\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7080 - val_loss: 0.5749 - val_accuracy: 0.6775\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7099 - val_loss: 0.5559 - val_accuracy: 0.6927\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7009 - val_loss: 0.5776 - val_accuracy: 0.6726\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7129 - val_loss: 0.6078 - val_accuracy: 0.6481\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7058 - val_loss: 0.6474 - val_accuracy: 0.6127\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7088 - val_loss: 0.5875 - val_accuracy: 0.6664\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.4987 - val_loss: 0.6543 - val_accuracy: 0.8289\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5480 - val_loss: 0.6769 - val_accuracy: 0.6542\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5536 - val_loss: 0.6868 - val_accuracy: 0.5473\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5862 - val_loss: 0.6835 - val_accuracy: 0.5728\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5959 - val_loss: 0.6818 - val_accuracy: 0.5820\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.5966 - val_loss: 0.6832 - val_accuracy: 0.5823\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.6228 - val_loss: 0.6925 - val_accuracy: 0.5249\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6449 - val_loss: 0.6948 - val_accuracy: 0.5192\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.6351 - val_loss: 0.6862 - val_accuracy: 0.5587\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.6546 - val_loss: 0.6813 - val_accuracy: 0.5793\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.6621 - val_loss: 0.6753 - val_accuracy: 0.6047\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6520 - val_loss: 0.6669 - val_accuracy: 0.6278\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6516 - val_loss: 0.6517 - val_accuracy: 0.6674\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6606 - val_loss: 0.6639 - val_accuracy: 0.6252\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6658 - val_loss: 0.6709 - val_accuracy: 0.6077\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6550 - val_loss: 0.6582 - val_accuracy: 0.6279\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6643 - val_loss: 0.6620 - val_accuracy: 0.6165\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6837 - val_loss: 0.6531 - val_accuracy: 0.6346\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6707 - val_loss: 0.6530 - val_accuracy: 0.6301\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6755 - val_loss: 0.6506 - val_accuracy: 0.6330\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6804 - val_loss: 0.6451 - val_accuracy: 0.6457\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6763 - val_loss: 0.6336 - val_accuracy: 0.6680\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6703 - val_loss: 0.6497 - val_accuracy: 0.6297\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6781 - val_loss: 0.6240 - val_accuracy: 0.6792\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6860 - val_loss: 0.6404 - val_accuracy: 0.6450\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6916 - val_loss: 0.6612 - val_accuracy: 0.6094\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6852 - val_loss: 0.6228 - val_accuracy: 0.6709\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.6815 - val_loss: 0.6306 - val_accuracy: 0.6566\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6860 - val_loss: 0.6257 - val_accuracy: 0.6629\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6785 - val_loss: 0.6296 - val_accuracy: 0.6543\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.6927 - val_loss: 0.6400 - val_accuracy: 0.6404\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6822 - val_loss: 0.6287 - val_accuracy: 0.6516\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6905 - val_loss: 0.6107 - val_accuracy: 0.6723\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.6908 - val_loss: 0.6163 - val_accuracy: 0.6637\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6886 - val_loss: 0.6220 - val_accuracy: 0.6554\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6991 - val_loss: 0.6253 - val_accuracy: 0.6499\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.7058 - val_loss: 0.6379 - val_accuracy: 0.6370\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6987 - val_loss: 0.6035 - val_accuracy: 0.6704\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.7047 - val_loss: 0.6121 - val_accuracy: 0.6605\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7002 - val_loss: 0.6272 - val_accuracy: 0.6447\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6994 - val_loss: 0.6020 - val_accuracy: 0.6681\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7028 - val_loss: 0.6342 - val_accuracy: 0.6341\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.7114 - val_loss: 0.6150 - val_accuracy: 0.6551\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.7017 - val_loss: 0.6423 - val_accuracy: 0.6247\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7032 - val_loss: 0.5897 - val_accuracy: 0.6774\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7032 - val_loss: 0.6222 - val_accuracy: 0.6428\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7095 - val_loss: 0.6245 - val_accuracy: 0.6398\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7088 - val_loss: 0.6215 - val_accuracy: 0.6420\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7092 - val_loss: 0.5909 - val_accuracy: 0.6712\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7099 - val_loss: 0.6228 - val_accuracy: 0.6410\n",
      "Epoch 1/50\n",
      " 96/168 [================>.............] - ETA: 0s - loss: 0.8070 - accuracy: 0.4818WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0011s). Check your callbacks.\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7756 - accuracy: 0.4677 - val_loss: 0.7030 - val_accuracy: 0.4597\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.4837 - val_loss: 0.7144 - val_accuracy: 0.4098\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.4849 - val_loss: 0.6809 - val_accuracy: 0.5757\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.5249 - val_loss: 0.6714 - val_accuracy: 0.6203\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5619 - val_loss: 0.6843 - val_accuracy: 0.5626\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5563 - val_loss: 0.6723 - val_accuracy: 0.6072\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5641 - val_loss: 0.6607 - val_accuracy: 0.6418\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5746 - val_loss: 0.6640 - val_accuracy: 0.6166\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.6064 - val_loss: 0.6558 - val_accuracy: 0.6380\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.5989 - val_loss: 0.6649 - val_accuracy: 0.6054\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6168 - val_loss: 0.6693 - val_accuracy: 0.5966\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6206 - val_loss: 0.6449 - val_accuracy: 0.6493\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6232 - val_loss: 0.6294 - val_accuracy: 0.6771\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6236 - val_loss: 0.6539 - val_accuracy: 0.6258\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6239 - val_loss: 0.6319 - val_accuracy: 0.6627\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6430 - val_loss: 0.6518 - val_accuracy: 0.6265\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6479 - val_loss: 0.6365 - val_accuracy: 0.6498\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.6355 - val_loss: 0.6157 - val_accuracy: 0.6823\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6381 - val_loss: 0.6205 - val_accuracy: 0.6669\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6535 - val_loss: 0.6560 - val_accuracy: 0.6114\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6508 - val_loss: 0.6327 - val_accuracy: 0.6490\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6576 - val_loss: 0.6462 - val_accuracy: 0.6258\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6718 - val_loss: 0.6300 - val_accuracy: 0.6507\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6568 - val_loss: 0.6349 - val_accuracy: 0.6450\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6699 - val_loss: 0.6348 - val_accuracy: 0.6437\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6606 - val_loss: 0.6088 - val_accuracy: 0.6739\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.6677 - val_loss: 0.6407 - val_accuracy: 0.6250\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6725 - val_loss: 0.6316 - val_accuracy: 0.6387\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6864 - val_loss: 0.5972 - val_accuracy: 0.6810\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6804 - val_loss: 0.6142 - val_accuracy: 0.6642\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6852 - val_loss: 0.5901 - val_accuracy: 0.6867\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6770 - val_loss: 0.6167 - val_accuracy: 0.6539\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.6849 - val_loss: 0.6381 - val_accuracy: 0.6220\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.6826 - val_loss: 0.5953 - val_accuracy: 0.6759\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6927 - val_loss: 0.5824 - val_accuracy: 0.6876\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6864 - val_loss: 0.6159 - val_accuracy: 0.6532\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7017 - val_loss: 0.5983 - val_accuracy: 0.6685\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6979 - val_loss: 0.6071 - val_accuracy: 0.6602\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6983 - val_loss: 0.5829 - val_accuracy: 0.6794\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6983 - val_loss: 0.6001 - val_accuracy: 0.6632\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7013 - val_loss: 0.6097 - val_accuracy: 0.6560\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6946 - val_loss: 0.5898 - val_accuracy: 0.6716\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.7121 - val_loss: 0.6187 - val_accuracy: 0.6476\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7009 - val_loss: 0.6182 - val_accuracy: 0.6479\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7058 - val_loss: 0.6026 - val_accuracy: 0.6600\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7073 - val_loss: 0.6128 - val_accuracy: 0.6500\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7047 - val_loss: 0.6067 - val_accuracy: 0.6553\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7114 - val_loss: 0.5918 - val_accuracy: 0.6656\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.6991 - val_loss: 0.5655 - val_accuracy: 0.6875\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7058 - val_loss: 0.5791 - val_accuracy: 0.6726\n"
     ]
    }
   ],
   "source": [
    "# 2. Vary sample_size_ratio\n",
    "results_sample_size = {}\n",
    "eps_sample_size = {}\n",
    "for ssr in sample_size_ratio_values:\n",
    "    print(f\"\\nTraining model with sample_size_ratio={ssr}...\")\n",
    "    X_sub, y_sub = subsample_data(X_train_filtered, y_train_filtered, ssr)\n",
    "    n = len(X_sub)\n",
    "    eps = compute_privacy_budget(n, default_batch_size, default_noise_multiplier, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_sub, y_sub, X_test_filtered, y_test_filtered,\n",
    "        batch_size=default_batch_size, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_sample_size[ssr] = compute_statistics(results)\n",
    "    eps_sample_size[ssr] = eps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7f3f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with noise_multiplier=1.1...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.1 iterated over 167200 steps satisfies differential privacy with eps = 0.849 and delta = 1e-05.\n",
      "The optimal RDP order is 19.0.\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.6577 - accuracy: 0.6059 - val_loss: 0.6420 - val_accuracy: 0.6337\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.5997 - accuracy: 0.6869 - val_loss: 0.5902 - val_accuracy: 0.6676\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.5651 - accuracy: 0.7163 - val_loss: 0.6184 - val_accuracy: 0.6266\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5436 - accuracy: 0.7294 - val_loss: 0.6041 - val_accuracy: 0.6365\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.5289 - accuracy: 0.7369 - val_loss: 0.6066 - val_accuracy: 0.6399\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.5158 - accuracy: 0.7450 - val_loss: 0.6319 - val_accuracy: 0.6222\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5049 - accuracy: 0.7506 - val_loss: 0.6103 - val_accuracy: 0.6440\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.4932 - accuracy: 0.7596 - val_loss: 0.5551 - val_accuracy: 0.6883\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.4819 - accuracy: 0.7667 - val_loss: 0.5888 - val_accuracy: 0.6668\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.5658 - val_accuracy: 0.6890\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.4579 - accuracy: 0.7831 - val_loss: 0.6135 - val_accuracy: 0.6604\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.4437 - accuracy: 0.7924 - val_loss: 0.6080 - val_accuracy: 0.6678\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.4291 - accuracy: 0.8020 - val_loss: 0.5528 - val_accuracy: 0.7124\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.4137 - accuracy: 0.8141 - val_loss: 0.5161 - val_accuracy: 0.7482\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.3984 - accuracy: 0.8244 - val_loss: 0.4526 - val_accuracy: 0.8044\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.3830 - accuracy: 0.8352 - val_loss: 0.4899 - val_accuracy: 0.7772\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.3688 - accuracy: 0.8448 - val_loss: 0.4825 - val_accuracy: 0.7860\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.3555 - accuracy: 0.8531 - val_loss: 0.5163 - val_accuracy: 0.7670\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.3436 - accuracy: 0.8587 - val_loss: 0.5252 - val_accuracy: 0.7674\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.3342 - accuracy: 0.8657 - val_loss: 0.4527 - val_accuracy: 0.8172\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.3271 - accuracy: 0.8700 - val_loss: 0.4443 - val_accuracy: 0.8234\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.3184 - accuracy: 0.8730 - val_loss: 0.5084 - val_accuracy: 0.7889\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.3129 - accuracy: 0.8754 - val_loss: 0.5212 - val_accuracy: 0.7864\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.3085 - accuracy: 0.8782 - val_loss: 0.5625 - val_accuracy: 0.7619\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.3039 - accuracy: 0.8788 - val_loss: 0.6206 - val_accuracy: 0.7310\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.3002 - accuracy: 0.8816 - val_loss: 0.4938 - val_accuracy: 0.8044\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2972 - accuracy: 0.8836 - val_loss: 0.5338 - val_accuracy: 0.7835\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2948 - accuracy: 0.8844 - val_loss: 0.5094 - val_accuracy: 0.7987\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2924 - accuracy: 0.8854 - val_loss: 0.6514 - val_accuracy: 0.7203\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2905 - accuracy: 0.8844 - val_loss: 0.5233 - val_accuracy: 0.7944\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2877 - accuracy: 0.8873 - val_loss: 0.5649 - val_accuracy: 0.7690\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2872 - accuracy: 0.8870 - val_loss: 0.4448 - val_accuracy: 0.8274\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2845 - accuracy: 0.8894 - val_loss: 0.4317 - val_accuracy: 0.8352\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2839 - accuracy: 0.8879 - val_loss: 0.5472 - val_accuracy: 0.7845\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2819 - accuracy: 0.8904 - val_loss: 0.4508 - val_accuracy: 0.8235\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.2798 - accuracy: 0.8910 - val_loss: 0.4341 - val_accuracy: 0.8319\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.2791 - accuracy: 0.8906 - val_loss: 0.5098 - val_accuracy: 0.7972\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2772 - accuracy: 0.8922 - val_loss: 0.4846 - val_accuracy: 0.8095\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2766 - accuracy: 0.8923 - val_loss: 0.4828 - val_accuracy: 0.8109\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.2760 - accuracy: 0.8922 - val_loss: 0.4733 - val_accuracy: 0.8159\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2753 - accuracy: 0.8926 - val_loss: 0.3927 - val_accuracy: 0.8483\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2727 - accuracy: 0.8936 - val_loss: 0.5514 - val_accuracy: 0.7761\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2745 - accuracy: 0.8932 - val_loss: 0.3940 - val_accuracy: 0.8483\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2724 - accuracy: 0.8922 - val_loss: 0.4080 - val_accuracy: 0.8424\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2710 - accuracy: 0.8945 - val_loss: 0.4278 - val_accuracy: 0.8332\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2711 - accuracy: 0.8940 - val_loss: 0.3907 - val_accuracy: 0.8477\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.2710 - accuracy: 0.8944 - val_loss: 0.4451 - val_accuracy: 0.8244\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.2693 - accuracy: 0.8958 - val_loss: 0.5308 - val_accuracy: 0.7872\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2680 - accuracy: 0.8959 - val_loss: 0.4762 - val_accuracy: 0.8104\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2685 - accuracy: 0.8960 - val_loss: 0.5003 - val_accuracy: 0.8018\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.6502 - accuracy: 0.6237 - val_loss: 0.6571 - val_accuracy: 0.6232\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.6027 - accuracy: 0.6839 - val_loss: 0.6472 - val_accuracy: 0.6226\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 415us/step - loss: 0.5760 - accuracy: 0.7042 - val_loss: 0.5806 - val_accuracy: 0.6807\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.5588 - accuracy: 0.7171 - val_loss: 0.6041 - val_accuracy: 0.6597\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.5443 - accuracy: 0.7253 - val_loss: 0.5823 - val_accuracy: 0.6816\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.5331 - accuracy: 0.7308 - val_loss: 0.5976 - val_accuracy: 0.6752\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.5236 - accuracy: 0.7378 - val_loss: 0.6211 - val_accuracy: 0.6580\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5164 - accuracy: 0.7398 - val_loss: 0.6069 - val_accuracy: 0.6711\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.5071 - accuracy: 0.7459 - val_loss: 0.5546 - val_accuracy: 0.7082\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.4980 - accuracy: 0.7536 - val_loss: 0.5717 - val_accuracy: 0.7003\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.4888 - accuracy: 0.7607 - val_loss: 0.6082 - val_accuracy: 0.6715\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.4798 - accuracy: 0.7664 - val_loss: 0.6045 - val_accuracy: 0.6756\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.4700 - accuracy: 0.7739 - val_loss: 0.5810 - val_accuracy: 0.6948\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 417us/step - loss: 0.4584 - accuracy: 0.7815 - val_loss: 0.5844 - val_accuracy: 0.6953\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.4460 - accuracy: 0.7900 - val_loss: 0.5563 - val_accuracy: 0.7175\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.4330 - accuracy: 0.7978 - val_loss: 0.5235 - val_accuracy: 0.7503\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.4186 - accuracy: 0.8102 - val_loss: 0.4901 - val_accuracy: 0.7785\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.4044 - accuracy: 0.8199 - val_loss: 0.5304 - val_accuracy: 0.7522\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.3891 - accuracy: 0.8295 - val_loss: 0.4875 - val_accuracy: 0.7937\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.3755 - accuracy: 0.8395 - val_loss: 0.4737 - val_accuracy: 0.8049\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.3605 - accuracy: 0.8497 - val_loss: 0.4658 - val_accuracy: 0.8134\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.3490 - accuracy: 0.8598 - val_loss: 0.5384 - val_accuracy: 0.7682\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.3378 - accuracy: 0.8632 - val_loss: 0.4908 - val_accuracy: 0.8045\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.3287 - accuracy: 0.8703 - val_loss: 0.4833 - val_accuracy: 0.8082\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.3190 - accuracy: 0.8742 - val_loss: 0.4704 - val_accuracy: 0.8183\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.3147 - accuracy: 0.8757 - val_loss: 0.4942 - val_accuracy: 0.8064\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.3083 - accuracy: 0.8795 - val_loss: 0.3675 - val_accuracy: 0.8599\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.3042 - accuracy: 0.8814 - val_loss: 0.3778 - val_accuracy: 0.8569\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.3012 - accuracy: 0.8826 - val_loss: 0.4435 - val_accuracy: 0.8319\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2971 - accuracy: 0.8845 - val_loss: 0.4778 - val_accuracy: 0.8175\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2949 - accuracy: 0.8854 - val_loss: 0.5050 - val_accuracy: 0.8070\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.2939 - accuracy: 0.8857 - val_loss: 0.7034 - val_accuracy: 0.6971\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2898 - accuracy: 0.8865 - val_loss: 0.4208 - val_accuracy: 0.8398\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2888 - accuracy: 0.8871 - val_loss: 0.4560 - val_accuracy: 0.8261\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.2873 - accuracy: 0.8873 - val_loss: 0.5577 - val_accuracy: 0.7788\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2864 - accuracy: 0.8884 - val_loss: 0.5256 - val_accuracy: 0.7975\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2840 - accuracy: 0.8911 - val_loss: 0.4155 - val_accuracy: 0.8405\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.2817 - accuracy: 0.8912 - val_loss: 0.4502 - val_accuracy: 0.8272\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.2817 - accuracy: 0.8910 - val_loss: 0.4512 - val_accuracy: 0.8279\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.2807 - accuracy: 0.8907 - val_loss: 0.5213 - val_accuracy: 0.7993\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2788 - accuracy: 0.8923 - val_loss: 0.4792 - val_accuracy: 0.8170\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2777 - accuracy: 0.8923 - val_loss: 0.4617 - val_accuracy: 0.8222\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 633us/step - loss: 0.2778 - accuracy: 0.8928 - val_loss: 0.4506 - val_accuracy: 0.8279\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.2747 - accuracy: 0.8931 - val_loss: 0.3682 - val_accuracy: 0.8593\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2763 - accuracy: 0.8930 - val_loss: 0.4832 - val_accuracy: 0.8141\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2740 - accuracy: 0.8939 - val_loss: 0.4747 - val_accuracy: 0.8171\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2733 - accuracy: 0.8953 - val_loss: 0.3867 - val_accuracy: 0.8531\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2720 - accuracy: 0.8941 - val_loss: 0.6177 - val_accuracy: 0.7519\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2718 - accuracy: 0.8950 - val_loss: 0.5264 - val_accuracy: 0.7953\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2698 - accuracy: 0.8950 - val_loss: 0.4591 - val_accuracy: 0.8231\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.6738 - accuracy: 0.5737 - val_loss: 0.6610 - val_accuracy: 0.5992\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.6265 - accuracy: 0.6555 - val_loss: 0.6105 - val_accuracy: 0.6514\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5940 - accuracy: 0.6891 - val_loss: 0.6137 - val_accuracy: 0.6281\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.5687 - accuracy: 0.7104 - val_loss: 0.5758 - val_accuracy: 0.6619\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.5488 - accuracy: 0.7228 - val_loss: 0.6301 - val_accuracy: 0.6141\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.5340 - accuracy: 0.7318 - val_loss: 0.6078 - val_accuracy: 0.6344\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5212 - accuracy: 0.7370 - val_loss: 0.5896 - val_accuracy: 0.6525\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.5108 - accuracy: 0.7423 - val_loss: 0.6143 - val_accuracy: 0.6368\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.5004 - accuracy: 0.7490 - val_loss: 0.5852 - val_accuracy: 0.6634\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.4889 - accuracy: 0.7598 - val_loss: 0.5907 - val_accuracy: 0.6629\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.4782 - accuracy: 0.7647 - val_loss: 0.5435 - val_accuracy: 0.7028\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.4663 - accuracy: 0.7734 - val_loss: 0.6076 - val_accuracy: 0.6602\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.4545 - accuracy: 0.7823 - val_loss: 0.6005 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.4403 - accuracy: 0.7913 - val_loss: 0.5353 - val_accuracy: 0.7270\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.4258 - accuracy: 0.8029 - val_loss: 0.5248 - val_accuracy: 0.7397\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.4109 - accuracy: 0.8124 - val_loss: 0.5682 - val_accuracy: 0.7084\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.3967 - accuracy: 0.8234 - val_loss: 0.5412 - val_accuracy: 0.7360\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.3804 - accuracy: 0.8360 - val_loss: 0.4882 - val_accuracy: 0.7859\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.3670 - accuracy: 0.8449 - val_loss: 0.4659 - val_accuracy: 0.8045\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.3535 - accuracy: 0.8543 - val_loss: 0.4066 - val_accuracy: 0.8385\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3419 - accuracy: 0.8614 - val_loss: 0.4724 - val_accuracy: 0.8069\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.3316 - accuracy: 0.8675 - val_loss: 0.4371 - val_accuracy: 0.8255\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.3223 - accuracy: 0.8717 - val_loss: 0.4832 - val_accuracy: 0.8065\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3140 - accuracy: 0.8754 - val_loss: 0.4034 - val_accuracy: 0.8426\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.3080 - accuracy: 0.8793 - val_loss: 0.5138 - val_accuracy: 0.7899\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.3029 - accuracy: 0.8818 - val_loss: 0.4616 - val_accuracy: 0.8172\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2992 - accuracy: 0.8835 - val_loss: 0.4101 - val_accuracy: 0.8398\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2936 - accuracy: 0.8847 - val_loss: 0.4217 - val_accuracy: 0.8352\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.2917 - accuracy: 0.8869 - val_loss: 0.5004 - val_accuracy: 0.8038\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.2871 - accuracy: 0.8878 - val_loss: 0.5582 - val_accuracy: 0.7739\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2869 - accuracy: 0.8883 - val_loss: 0.4436 - val_accuracy: 0.8270\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2839 - accuracy: 0.8886 - val_loss: 0.6264 - val_accuracy: 0.7376\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.2819 - accuracy: 0.8905 - val_loss: 0.5935 - val_accuracy: 0.7565\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2800 - accuracy: 0.8914 - val_loss: 0.6302 - val_accuracy: 0.7379\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2789 - accuracy: 0.8906 - val_loss: 0.5055 - val_accuracy: 0.8032\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.2768 - accuracy: 0.8915 - val_loss: 0.4268 - val_accuracy: 0.8336\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2756 - accuracy: 0.8913 - val_loss: 0.4381 - val_accuracy: 0.8298\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2746 - accuracy: 0.8930 - val_loss: 0.4020 - val_accuracy: 0.8455\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2717 - accuracy: 0.8936 - val_loss: 0.4556 - val_accuracy: 0.8209\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.2702 - accuracy: 0.8951 - val_loss: 0.3814 - val_accuracy: 0.8508\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2710 - accuracy: 0.8952 - val_loss: 0.4456 - val_accuracy: 0.8255\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2689 - accuracy: 0.8947 - val_loss: 0.4419 - val_accuracy: 0.8289\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2675 - accuracy: 0.8959 - val_loss: 0.4935 - val_accuracy: 0.8058\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2679 - accuracy: 0.8965 - val_loss: 0.3732 - val_accuracy: 0.8554\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2661 - accuracy: 0.8965 - val_loss: 0.3895 - val_accuracy: 0.8479\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2655 - accuracy: 0.8966 - val_loss: 0.5374 - val_accuracy: 0.7876\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2652 - accuracy: 0.8958 - val_loss: 0.4492 - val_accuracy: 0.8228\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2640 - accuracy: 0.8969 - val_loss: 0.4643 - val_accuracy: 0.8185\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2623 - accuracy: 0.8967 - val_loss: 0.6233 - val_accuracy: 0.7438\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2624 - accuracy: 0.8982 - val_loss: 0.3871 - val_accuracy: 0.8493\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.6696 - accuracy: 0.6006 - val_loss: 0.6392 - val_accuracy: 0.6640\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 414us/step - loss: 0.6260 - accuracy: 0.6626 - val_loss: 0.6688 - val_accuracy: 0.6017\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.5947 - accuracy: 0.6907 - val_loss: 0.6407 - val_accuracy: 0.6284\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.5693 - accuracy: 0.7096 - val_loss: 0.6702 - val_accuracy: 0.6040\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.5477 - accuracy: 0.7265 - val_loss: 0.5681 - val_accuracy: 0.6983\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.5327 - accuracy: 0.7340 - val_loss: 0.5861 - val_accuracy: 0.6835\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.5186 - accuracy: 0.7422 - val_loss: 0.6411 - val_accuracy: 0.6340\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.5061 - accuracy: 0.7507 - val_loss: 0.6132 - val_accuracy: 0.6583\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.4938 - accuracy: 0.7574 - val_loss: 0.6274 - val_accuracy: 0.6504\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.4821 - accuracy: 0.7656 - val_loss: 0.6216 - val_accuracy: 0.6610\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.4695 - accuracy: 0.7738 - val_loss: 0.5562 - val_accuracy: 0.7071\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.4561 - accuracy: 0.7835 - val_loss: 0.5560 - val_accuracy: 0.7118\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.4430 - accuracy: 0.7925 - val_loss: 0.6105 - val_accuracy: 0.6807\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.4276 - accuracy: 0.8051 - val_loss: 0.5960 - val_accuracy: 0.6930\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.4133 - accuracy: 0.8135 - val_loss: 0.4506 - val_accuracy: 0.8110\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 411us/step - loss: 0.3988 - accuracy: 0.8256 - val_loss: 0.5259 - val_accuracy: 0.7509\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.3835 - accuracy: 0.8349 - val_loss: 0.5222 - val_accuracy: 0.7572\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.3691 - accuracy: 0.8449 - val_loss: 0.4852 - val_accuracy: 0.7919\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.3571 - accuracy: 0.8530 - val_loss: 0.4552 - val_accuracy: 0.8162\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.3465 - accuracy: 0.8586 - val_loss: 0.4068 - val_accuracy: 0.8433\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3362 - accuracy: 0.8641 - val_loss: 0.4873 - val_accuracy: 0.8018\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.3274 - accuracy: 0.8685 - val_loss: 0.4431 - val_accuracy: 0.8273\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.3206 - accuracy: 0.8718 - val_loss: 0.5247 - val_accuracy: 0.7828\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3142 - accuracy: 0.8762 - val_loss: 0.4765 - val_accuracy: 0.8140\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.3096 - accuracy: 0.8785 - val_loss: 0.3989 - val_accuracy: 0.8483\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.3056 - accuracy: 0.8802 - val_loss: 0.5402 - val_accuracy: 0.7848\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.3019 - accuracy: 0.8817 - val_loss: 0.4404 - val_accuracy: 0.8327\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.2990 - accuracy: 0.8831 - val_loss: 0.4966 - val_accuracy: 0.8076\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2953 - accuracy: 0.8829 - val_loss: 0.3987 - val_accuracy: 0.8502\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2930 - accuracy: 0.8867 - val_loss: 0.4472 - val_accuracy: 0.8284\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.2899 - accuracy: 0.8867 - val_loss: 0.5936 - val_accuracy: 0.7598\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.2878 - accuracy: 0.8875 - val_loss: 0.3986 - val_accuracy: 0.8484\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 416us/step - loss: 0.2848 - accuracy: 0.8881 - val_loss: 0.5379 - val_accuracy: 0.7897\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2866 - accuracy: 0.8875 - val_loss: 0.4147 - val_accuracy: 0.8420\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2834 - accuracy: 0.8892 - val_loss: 0.4899 - val_accuracy: 0.8128\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2822 - accuracy: 0.8902 - val_loss: 0.5637 - val_accuracy: 0.7760\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2814 - accuracy: 0.8906 - val_loss: 0.4145 - val_accuracy: 0.8428\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.2797 - accuracy: 0.8911 - val_loss: 0.4689 - val_accuracy: 0.8214\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2788 - accuracy: 0.8902 - val_loss: 0.5358 - val_accuracy: 0.7906\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.2780 - accuracy: 0.8922 - val_loss: 0.4553 - val_accuracy: 0.8243\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.2765 - accuracy: 0.8925 - val_loss: 0.3587 - val_accuracy: 0.8635\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.2761 - accuracy: 0.8920 - val_loss: 0.4640 - val_accuracy: 0.8201\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.2734 - accuracy: 0.8933 - val_loss: 0.4517 - val_accuracy: 0.8267\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.2738 - accuracy: 0.8929 - val_loss: 0.5141 - val_accuracy: 0.8007\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 417us/step - loss: 0.2732 - accuracy: 0.8938 - val_loss: 0.5477 - val_accuracy: 0.7844\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.2709 - accuracy: 0.8955 - val_loss: 0.4982 - val_accuracy: 0.8070\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.2711 - accuracy: 0.8946 - val_loss: 0.4905 - val_accuracy: 0.8112\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.2695 - accuracy: 0.8952 - val_loss: 0.4250 - val_accuracy: 0.8362\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2701 - accuracy: 0.8950 - val_loss: 0.4394 - val_accuracy: 0.8316\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2685 - accuracy: 0.8952 - val_loss: 0.6174 - val_accuracy: 0.7543\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.6763 - accuracy: 0.5762 - val_loss: 0.6400 - val_accuracy: 0.6772\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.6237 - accuracy: 0.6641 - val_loss: 0.6177 - val_accuracy: 0.6525\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.5870 - accuracy: 0.6926 - val_loss: 0.6035 - val_accuracy: 0.6469\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.5601 - accuracy: 0.7180 - val_loss: 0.6375 - val_accuracy: 0.6052\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.5426 - accuracy: 0.7272 - val_loss: 0.5681 - val_accuracy: 0.6698\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.5289 - accuracy: 0.7340 - val_loss: 0.5757 - val_accuracy: 0.6615\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.5178 - accuracy: 0.7407 - val_loss: 0.6614 - val_accuracy: 0.5975\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5078 - accuracy: 0.7473 - val_loss: 0.6315 - val_accuracy: 0.6232\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.4965 - accuracy: 0.7542 - val_loss: 0.5949 - val_accuracy: 0.6600\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.4864 - accuracy: 0.7610 - val_loss: 0.5796 - val_accuracy: 0.6759\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.4764 - accuracy: 0.7687 - val_loss: 0.5882 - val_accuracy: 0.6739\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.4645 - accuracy: 0.7768 - val_loss: 0.5444 - val_accuracy: 0.7211\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.4537 - accuracy: 0.7869 - val_loss: 0.5792 - val_accuracy: 0.6924\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.4394 - accuracy: 0.7967 - val_loss: 0.5750 - val_accuracy: 0.7013\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.4253 - accuracy: 0.8054 - val_loss: 0.6365 - val_accuracy: 0.6619\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.4107 - accuracy: 0.8171 - val_loss: 0.5618 - val_accuracy: 0.7238\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.3946 - accuracy: 0.8285 - val_loss: 0.5762 - val_accuracy: 0.7139\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.3794 - accuracy: 0.8382 - val_loss: 0.4626 - val_accuracy: 0.8100\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.3638 - accuracy: 0.8496 - val_loss: 0.5330 - val_accuracy: 0.7614\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.3512 - accuracy: 0.8569 - val_loss: 0.5495 - val_accuracy: 0.7562\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.3382 - accuracy: 0.8643 - val_loss: 0.4744 - val_accuracy: 0.8080\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.3272 - accuracy: 0.8703 - val_loss: 0.5720 - val_accuracy: 0.7480\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.3188 - accuracy: 0.8745 - val_loss: 0.5245 - val_accuracy: 0.7805\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.3112 - accuracy: 0.8779 - val_loss: 0.5003 - val_accuracy: 0.7977\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.3061 - accuracy: 0.8797 - val_loss: 0.3838 - val_accuracy: 0.8516\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2994 - accuracy: 0.8826 - val_loss: 0.4901 - val_accuracy: 0.8091\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2958 - accuracy: 0.8843 - val_loss: 0.6180 - val_accuracy: 0.7336\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.2925 - accuracy: 0.8851 - val_loss: 0.4737 - val_accuracy: 0.8123\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2897 - accuracy: 0.8864 - val_loss: 0.4785 - val_accuracy: 0.8134\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2854 - accuracy: 0.8888 - val_loss: 0.4807 - val_accuracy: 0.8126\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2843 - accuracy: 0.8900 - val_loss: 0.4511 - val_accuracy: 0.8232\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2817 - accuracy: 0.8895 - val_loss: 0.4446 - val_accuracy: 0.8298\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.2798 - accuracy: 0.8907 - val_loss: 0.4915 - val_accuracy: 0.8069\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2758 - accuracy: 0.8928 - val_loss: 0.5338 - val_accuracy: 0.7914\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.2772 - accuracy: 0.8919 - val_loss: 0.4586 - val_accuracy: 0.8231\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.2753 - accuracy: 0.8931 - val_loss: 0.5356 - val_accuracy: 0.7867\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.2730 - accuracy: 0.8934 - val_loss: 0.6017 - val_accuracy: 0.7526\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.2723 - accuracy: 0.8943 - val_loss: 0.4561 - val_accuracy: 0.8234\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.2712 - accuracy: 0.8934 - val_loss: 0.7238 - val_accuracy: 0.6861\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2691 - accuracy: 0.8951 - val_loss: 0.4560 - val_accuracy: 0.8245\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2687 - accuracy: 0.8952 - val_loss: 0.5338 - val_accuracy: 0.7866\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2680 - accuracy: 0.8951 - val_loss: 0.4739 - val_accuracy: 0.8130\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2663 - accuracy: 0.8967 - val_loss: 0.3390 - val_accuracy: 0.8698\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2653 - accuracy: 0.8983 - val_loss: 0.4715 - val_accuracy: 0.8143\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2650 - accuracy: 0.8966 - val_loss: 0.5208 - val_accuracy: 0.7897\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2647 - accuracy: 0.8966 - val_loss: 0.4408 - val_accuracy: 0.8277\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2638 - accuracy: 0.8976 - val_loss: 0.4560 - val_accuracy: 0.8234\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2612 - accuracy: 0.8988 - val_loss: 0.5019 - val_accuracy: 0.8029\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2612 - accuracy: 0.8984 - val_loss: 0.5579 - val_accuracy: 0.7749\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.2615 - accuracy: 0.8985 - val_loss: 0.4636 - val_accuracy: 0.8193\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.6555 - accuracy: 0.6110 - val_loss: 0.6307 - val_accuracy: 0.6570\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.6064 - accuracy: 0.6735 - val_loss: 0.6321 - val_accuracy: 0.6354\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5755 - accuracy: 0.7036 - val_loss: 0.5873 - val_accuracy: 0.6701\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.5544 - accuracy: 0.7223 - val_loss: 0.6299 - val_accuracy: 0.6316\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5384 - accuracy: 0.7304 - val_loss: 0.6144 - val_accuracy: 0.6403\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.5245 - accuracy: 0.7390 - val_loss: 0.6147 - val_accuracy: 0.6425\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.5133 - accuracy: 0.7444 - val_loss: 0.6154 - val_accuracy: 0.6444\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.5023 - accuracy: 0.7507 - val_loss: 0.5466 - val_accuracy: 0.7061\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.4922 - accuracy: 0.7578 - val_loss: 0.6001 - val_accuracy: 0.6600\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.4814 - accuracy: 0.7660 - val_loss: 0.5940 - val_accuracy: 0.6702\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.5982 - val_accuracy: 0.6718\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.4573 - accuracy: 0.7840 - val_loss: 0.6187 - val_accuracy: 0.6633\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.4426 - accuracy: 0.7936 - val_loss: 0.5647 - val_accuracy: 0.7083\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.4266 - accuracy: 0.8057 - val_loss: 0.5728 - val_accuracy: 0.7049\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.4113 - accuracy: 0.8178 - val_loss: 0.5357 - val_accuracy: 0.7421\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.3963 - accuracy: 0.8294 - val_loss: 0.4906 - val_accuracy: 0.7813\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.3807 - accuracy: 0.8402 - val_loss: 0.5756 - val_accuracy: 0.7210\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.3667 - accuracy: 0.8464 - val_loss: 0.5526 - val_accuracy: 0.7431\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.3533 - accuracy: 0.8563 - val_loss: 0.5485 - val_accuracy: 0.7547\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.3411 - accuracy: 0.8629 - val_loss: 0.6394 - val_accuracy: 0.6958\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.3326 - accuracy: 0.8666 - val_loss: 0.4489 - val_accuracy: 0.8264\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.3234 - accuracy: 0.8733 - val_loss: 0.4826 - val_accuracy: 0.8092\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.3160 - accuracy: 0.8744 - val_loss: 0.5101 - val_accuracy: 0.7960\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.3108 - accuracy: 0.8777 - val_loss: 0.4199 - val_accuracy: 0.8397\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.3063 - accuracy: 0.8811 - val_loss: 0.5790 - val_accuracy: 0.7626\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.3016 - accuracy: 0.8824 - val_loss: 0.4746 - val_accuracy: 0.8203\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.2992 - accuracy: 0.8850 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.2954 - accuracy: 0.8854 - val_loss: 0.4377 - val_accuracy: 0.8371\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2937 - accuracy: 0.8859 - val_loss: 0.4490 - val_accuracy: 0.8319\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2903 - accuracy: 0.8868 - val_loss: 0.4514 - val_accuracy: 0.8296\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2890 - accuracy: 0.8878 - val_loss: 0.4790 - val_accuracy: 0.8223\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2871 - accuracy: 0.8884 - val_loss: 0.5414 - val_accuracy: 0.7878\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2859 - accuracy: 0.8887 - val_loss: 0.5694 - val_accuracy: 0.7774\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2841 - accuracy: 0.8900 - val_loss: 0.6992 - val_accuracy: 0.7071\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2824 - accuracy: 0.8904 - val_loss: 0.4077 - val_accuracy: 0.8476\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2816 - accuracy: 0.8894 - val_loss: 0.5971 - val_accuracy: 0.7627\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2798 - accuracy: 0.8918 - val_loss: 0.5455 - val_accuracy: 0.7886\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2787 - accuracy: 0.8911 - val_loss: 0.5783 - val_accuracy: 0.7714\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2776 - accuracy: 0.8924 - val_loss: 0.5071 - val_accuracy: 0.8048\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.2761 - accuracy: 0.8935 - val_loss: 0.6642 - val_accuracy: 0.7310\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.2743 - accuracy: 0.8943 - val_loss: 0.6096 - val_accuracy: 0.7557\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2740 - accuracy: 0.8936 - val_loss: 0.5243 - val_accuracy: 0.7983\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.2732 - accuracy: 0.8946 - val_loss: 0.5933 - val_accuracy: 0.7600\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2730 - accuracy: 0.8950 - val_loss: 0.4690 - val_accuracy: 0.8217\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2717 - accuracy: 0.8947 - val_loss: 0.4554 - val_accuracy: 0.8257\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2709 - accuracy: 0.8947 - val_loss: 0.4769 - val_accuracy: 0.8137\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2684 - accuracy: 0.8959 - val_loss: 0.5445 - val_accuracy: 0.7888\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2698 - accuracy: 0.8944 - val_loss: 0.4465 - val_accuracy: 0.8284\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.2673 - accuracy: 0.8952 - val_loss: 0.3620 - val_accuracy: 0.8607\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2674 - accuracy: 0.8967 - val_loss: 0.6013 - val_accuracy: 0.7576\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.6748 - accuracy: 0.5737 - val_loss: 0.6748 - val_accuracy: 0.6089\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.6203 - accuracy: 0.6691 - val_loss: 0.6153 - val_accuracy: 0.6809\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.5797 - accuracy: 0.7049 - val_loss: 0.6152 - val_accuracy: 0.6550\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.5502 - accuracy: 0.7281 - val_loss: 0.5691 - val_accuracy: 0.6879\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.5309 - accuracy: 0.7400 - val_loss: 0.5739 - val_accuracy: 0.6804\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.5162 - accuracy: 0.7466 - val_loss: 0.6292 - val_accuracy: 0.6365\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5030 - accuracy: 0.7541 - val_loss: 0.6434 - val_accuracy: 0.6272\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.4910 - accuracy: 0.7595 - val_loss: 0.5623 - val_accuracy: 0.6929\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.4799 - accuracy: 0.7690 - val_loss: 0.5772 - val_accuracy: 0.6845\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.4671 - accuracy: 0.7744 - val_loss: 0.5208 - val_accuracy: 0.7379\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.4536 - accuracy: 0.7846 - val_loss: 0.5993 - val_accuracy: 0.6740\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.4396 - accuracy: 0.7941 - val_loss: 0.5397 - val_accuracy: 0.7258\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.4257 - accuracy: 0.8051 - val_loss: 0.5953 - val_accuracy: 0.6854\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.4090 - accuracy: 0.8155 - val_loss: 0.5981 - val_accuracy: 0.6928\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.3953 - accuracy: 0.8257 - val_loss: 0.5322 - val_accuracy: 0.7525\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.3792 - accuracy: 0.8379 - val_loss: 0.4882 - val_accuracy: 0.7912\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.3648 - accuracy: 0.8476 - val_loss: 0.5787 - val_accuracy: 0.7281\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.3528 - accuracy: 0.8541 - val_loss: 0.4872 - val_accuracy: 0.8029\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.3406 - accuracy: 0.8629 - val_loss: 0.4510 - val_accuracy: 0.8232\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.3313 - accuracy: 0.8660 - val_loss: 0.5310 - val_accuracy: 0.7804\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.3216 - accuracy: 0.8723 - val_loss: 0.5657 - val_accuracy: 0.7566\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.3149 - accuracy: 0.8746 - val_loss: 0.5007 - val_accuracy: 0.8007\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.3081 - accuracy: 0.8782 - val_loss: 0.4219 - val_accuracy: 0.8405\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.3028 - accuracy: 0.8821 - val_loss: 0.5835 - val_accuracy: 0.7575\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.3000 - accuracy: 0.8827 - val_loss: 0.4031 - val_accuracy: 0.8485\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.2966 - accuracy: 0.8847 - val_loss: 0.4998 - val_accuracy: 0.8058\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.2924 - accuracy: 0.8858 - val_loss: 0.4577 - val_accuracy: 0.8253\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2901 - accuracy: 0.8863 - val_loss: 0.3915 - val_accuracy: 0.8528\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2868 - accuracy: 0.8869 - val_loss: 0.4507 - val_accuracy: 0.8289\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2862 - accuracy: 0.8889 - val_loss: 0.4537 - val_accuracy: 0.8262\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2831 - accuracy: 0.8891 - val_loss: 0.5127 - val_accuracy: 0.8027\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.2812 - accuracy: 0.8903 - val_loss: 0.4116 - val_accuracy: 0.8424\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2792 - accuracy: 0.8906 - val_loss: 0.4583 - val_accuracy: 0.8240\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2773 - accuracy: 0.8922 - val_loss: 0.4664 - val_accuracy: 0.8188\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2767 - accuracy: 0.8918 - val_loss: 0.4230 - val_accuracy: 0.8370\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2747 - accuracy: 0.8931 - val_loss: 0.4507 - val_accuracy: 0.8247\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2742 - accuracy: 0.8919 - val_loss: 0.3770 - val_accuracy: 0.8573\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2712 - accuracy: 0.8940 - val_loss: 0.4082 - val_accuracy: 0.8442\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2714 - accuracy: 0.8946 - val_loss: 0.5812 - val_accuracy: 0.7699\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2708 - accuracy: 0.8940 - val_loss: 0.4104 - val_accuracy: 0.8395\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2684 - accuracy: 0.8954 - val_loss: 0.4628 - val_accuracy: 0.8217\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2678 - accuracy: 0.8960 - val_loss: 0.4134 - val_accuracy: 0.8418\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2669 - accuracy: 0.8979 - val_loss: 0.4673 - val_accuracy: 0.8194\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2663 - accuracy: 0.8958 - val_loss: 0.5211 - val_accuracy: 0.7986\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2663 - accuracy: 0.8974 - val_loss: 0.6254 - val_accuracy: 0.7532\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2637 - accuracy: 0.8972 - val_loss: 0.5182 - val_accuracy: 0.8005\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.2642 - accuracy: 0.8969 - val_loss: 0.4282 - val_accuracy: 0.8341\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.2625 - accuracy: 0.8980 - val_loss: 0.6155 - val_accuracy: 0.7516\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2621 - accuracy: 0.8991 - val_loss: 0.5655 - val_accuracy: 0.7747\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.2611 - accuracy: 0.8994 - val_loss: 0.6475 - val_accuracy: 0.7447\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.6526 - accuracy: 0.6174 - val_loss: 0.6762 - val_accuracy: 0.5589\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.5969 - accuracy: 0.6824 - val_loss: 0.6352 - val_accuracy: 0.6164\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.5670 - accuracy: 0.7086 - val_loss: 0.6586 - val_accuracy: 0.5955\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5472 - accuracy: 0.7223 - val_loss: 0.6192 - val_accuracy: 0.6362\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5308 - accuracy: 0.7334 - val_loss: 0.5858 - val_accuracy: 0.6691\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.5191 - accuracy: 0.7389 - val_loss: 0.5902 - val_accuracy: 0.6677\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.5081 - accuracy: 0.7459 - val_loss: 0.5922 - val_accuracy: 0.6670\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.4969 - accuracy: 0.7555 - val_loss: 0.5531 - val_accuracy: 0.6984\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.4862 - accuracy: 0.7621 - val_loss: 0.5789 - val_accuracy: 0.6840\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.4752 - accuracy: 0.7702 - val_loss: 0.5840 - val_accuracy: 0.6830\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.4631 - accuracy: 0.7793 - val_loss: 0.5455 - val_accuracy: 0.7134\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.4509 - accuracy: 0.7879 - val_loss: 0.5511 - val_accuracy: 0.7137\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.4379 - accuracy: 0.7967 - val_loss: 0.5891 - val_accuracy: 0.6900\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.4244 - accuracy: 0.8061 - val_loss: 0.5138 - val_accuracy: 0.7521\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.4083 - accuracy: 0.8173 - val_loss: 0.6537 - val_accuracy: 0.6548\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.3922 - accuracy: 0.8271 - val_loss: 0.4849 - val_accuracy: 0.7840\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3778 - accuracy: 0.8367 - val_loss: 0.4286 - val_accuracy: 0.8288\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3636 - accuracy: 0.8482 - val_loss: 0.5502 - val_accuracy: 0.7392\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.3519 - accuracy: 0.8532 - val_loss: 0.4733 - val_accuracy: 0.8048\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.3419 - accuracy: 0.8607 - val_loss: 0.5728 - val_accuracy: 0.7339\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.3316 - accuracy: 0.8657 - val_loss: 0.5109 - val_accuracy: 0.7862\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.3240 - accuracy: 0.8701 - val_loss: 0.5514 - val_accuracy: 0.7618\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.3163 - accuracy: 0.8740 - val_loss: 0.3827 - val_accuracy: 0.8535\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.3108 - accuracy: 0.8760 - val_loss: 0.5823 - val_accuracy: 0.7504\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3058 - accuracy: 0.8788 - val_loss: 0.4428 - val_accuracy: 0.8304\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.3024 - accuracy: 0.8786 - val_loss: 0.5105 - val_accuracy: 0.7973\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.2991 - accuracy: 0.8813 - val_loss: 0.5521 - val_accuracy: 0.7746\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2958 - accuracy: 0.8834 - val_loss: 0.4452 - val_accuracy: 0.8282\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.2914 - accuracy: 0.8850 - val_loss: 0.4724 - val_accuracy: 0.8185\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2900 - accuracy: 0.8848 - val_loss: 0.5490 - val_accuracy: 0.7812\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2877 - accuracy: 0.8872 - val_loss: 0.4247 - val_accuracy: 0.8360\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.2859 - accuracy: 0.8884 - val_loss: 0.3642 - val_accuracy: 0.8602\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.2854 - accuracy: 0.8879 - val_loss: 0.4343 - val_accuracy: 0.8315\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.2842 - accuracy: 0.8880 - val_loss: 0.4991 - val_accuracy: 0.8050\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.2822 - accuracy: 0.8901 - val_loss: 0.5028 - val_accuracy: 0.8017\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2797 - accuracy: 0.8910 - val_loss: 0.4994 - val_accuracy: 0.8066\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.2781 - accuracy: 0.8907 - val_loss: 0.6264 - val_accuracy: 0.7426\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.2790 - accuracy: 0.8909 - val_loss: 0.3592 - val_accuracy: 0.8613\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2755 - accuracy: 0.8910 - val_loss: 0.5793 - val_accuracy: 0.7635\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2756 - accuracy: 0.8915 - val_loss: 0.5089 - val_accuracy: 0.8028\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.2752 - accuracy: 0.8920 - val_loss: 0.4818 - val_accuracy: 0.8113\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2742 - accuracy: 0.8924 - val_loss: 0.4769 - val_accuracy: 0.8126\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2725 - accuracy: 0.8931 - val_loss: 0.4164 - val_accuracy: 0.8362\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2713 - accuracy: 0.8933 - val_loss: 0.4860 - val_accuracy: 0.8107\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2715 - accuracy: 0.8928 - val_loss: 0.5849 - val_accuracy: 0.7547\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.2709 - accuracy: 0.8920 - val_loss: 0.4641 - val_accuracy: 0.8140\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2693 - accuracy: 0.8944 - val_loss: 0.4573 - val_accuracy: 0.8195\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2683 - accuracy: 0.8943 - val_loss: 0.5151 - val_accuracy: 0.7996\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.2676 - accuracy: 0.8942 - val_loss: 0.4473 - val_accuracy: 0.8265\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2670 - accuracy: 0.8955 - val_loss: 0.4633 - val_accuracy: 0.8190\n",
      "Epoch 1/50\n",
      "3314/3344 [============================>.] - ETA: 0s - loss: 0.6609 - accuracy: 0.6080WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.6606 - accuracy: 0.6085 - val_loss: 0.6710 - val_accuracy: 0.5876\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.6024 - accuracy: 0.6888 - val_loss: 0.6471 - val_accuracy: 0.6155\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5737 - accuracy: 0.7109 - val_loss: 0.5944 - val_accuracy: 0.6646\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.5529 - accuracy: 0.7210 - val_loss: 0.6488 - val_accuracy: 0.6263\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.5367 - accuracy: 0.7317 - val_loss: 0.5887 - val_accuracy: 0.6706\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.5230 - accuracy: 0.7392 - val_loss: 0.5537 - val_accuracy: 0.6984\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.5107 - accuracy: 0.7456 - val_loss: 0.6033 - val_accuracy: 0.6656\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.4987 - accuracy: 0.7537 - val_loss: 0.6050 - val_accuracy: 0.6658\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.4887 - accuracy: 0.7595 - val_loss: 0.5813 - val_accuracy: 0.6846\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.4768 - accuracy: 0.7699 - val_loss: 0.5923 - val_accuracy: 0.6790\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.4662 - accuracy: 0.7756 - val_loss: 0.6550 - val_accuracy: 0.6412\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.4535 - accuracy: 0.7862 - val_loss: 0.4807 - val_accuracy: 0.7810\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.4400 - accuracy: 0.7943 - val_loss: 0.5243 - val_accuracy: 0.7429\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.4258 - accuracy: 0.8051 - val_loss: 0.4674 - val_accuracy: 0.7924\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.4108 - accuracy: 0.8153 - val_loss: 0.4632 - val_accuracy: 0.7977\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.3945 - accuracy: 0.8262 - val_loss: 0.4768 - val_accuracy: 0.7912\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.3801 - accuracy: 0.8376 - val_loss: 0.5289 - val_accuracy: 0.7557\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.3667 - accuracy: 0.8447 - val_loss: 0.5117 - val_accuracy: 0.7735\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.3532 - accuracy: 0.8560 - val_loss: 0.5350 - val_accuracy: 0.7651\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3407 - accuracy: 0.8620 - val_loss: 0.5207 - val_accuracy: 0.7792\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.3323 - accuracy: 0.8668 - val_loss: 0.4267 - val_accuracy: 0.8351\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.3229 - accuracy: 0.8724 - val_loss: 0.7066 - val_accuracy: 0.6732\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.3157 - accuracy: 0.8765 - val_loss: 0.3886 - val_accuracy: 0.8520\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.3100 - accuracy: 0.8783 - val_loss: 0.5788 - val_accuracy: 0.7556\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.3054 - accuracy: 0.8803 - val_loss: 0.5104 - val_accuracy: 0.8001\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.2991 - accuracy: 0.8845 - val_loss: 0.5410 - val_accuracy: 0.7829\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2953 - accuracy: 0.8853 - val_loss: 0.5604 - val_accuracy: 0.7760\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.2924 - accuracy: 0.8862 - val_loss: 0.4371 - val_accuracy: 0.8320\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.2892 - accuracy: 0.8883 - val_loss: 0.5069 - val_accuracy: 0.8043\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2861 - accuracy: 0.8894 - val_loss: 0.5237 - val_accuracy: 0.7974\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2836 - accuracy: 0.8900 - val_loss: 0.5725 - val_accuracy: 0.7707\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2819 - accuracy: 0.8904 - val_loss: 0.5649 - val_accuracy: 0.7786\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2793 - accuracy: 0.8903 - val_loss: 0.6601 - val_accuracy: 0.7267\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.2779 - accuracy: 0.8919 - val_loss: 0.4852 - val_accuracy: 0.8134\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.2757 - accuracy: 0.8927 - val_loss: 0.4503 - val_accuracy: 0.8301\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 433us/step - loss: 0.2740 - accuracy: 0.8930 - val_loss: 0.5878 - val_accuracy: 0.7621\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2721 - accuracy: 0.8934 - val_loss: 0.4790 - val_accuracy: 0.8171\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.2694 - accuracy: 0.8955 - val_loss: 0.5413 - val_accuracy: 0.7878\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2691 - accuracy: 0.8953 - val_loss: 0.5228 - val_accuracy: 0.7971\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2684 - accuracy: 0.8956 - val_loss: 0.4313 - val_accuracy: 0.8324\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.2668 - accuracy: 0.8967 - val_loss: 0.4708 - val_accuracy: 0.8173\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2659 - accuracy: 0.8970 - val_loss: 0.4109 - val_accuracy: 0.8409\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2643 - accuracy: 0.8974 - val_loss: 0.5243 - val_accuracy: 0.7925\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.2643 - accuracy: 0.8977 - val_loss: 0.5627 - val_accuracy: 0.7726\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2635 - accuracy: 0.8971 - val_loss: 0.5641 - val_accuracy: 0.7732\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.2609 - accuracy: 0.8982 - val_loss: 0.4829 - val_accuracy: 0.8154\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2610 - accuracy: 0.8984 - val_loss: 0.4219 - val_accuracy: 0.8345\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2588 - accuracy: 0.8991 - val_loss: 0.4510 - val_accuracy: 0.8251\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2581 - accuracy: 0.8995 - val_loss: 0.4123 - val_accuracy: 0.8390\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2574 - accuracy: 0.9001 - val_loss: 0.5781 - val_accuracy: 0.7705\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.6415 - accuracy: 0.6367 - val_loss: 0.6374 - val_accuracy: 0.6217\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5961 - accuracy: 0.6929 - val_loss: 0.6178 - val_accuracy: 0.6314\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.5684 - accuracy: 0.7155 - val_loss: 0.6011 - val_accuracy: 0.6458\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5451 - accuracy: 0.7311 - val_loss: 0.6001 - val_accuracy: 0.6477\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5287 - accuracy: 0.7390 - val_loss: 0.6078 - val_accuracy: 0.6436\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.5147 - accuracy: 0.7429 - val_loss: 0.5532 - val_accuracy: 0.6982\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5027 - accuracy: 0.7530 - val_loss: 0.5665 - val_accuracy: 0.6856\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.4902 - accuracy: 0.7600 - val_loss: 0.5514 - val_accuracy: 0.7015\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.4762 - accuracy: 0.7697 - val_loss: 0.5831 - val_accuracy: 0.6771\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.4642 - accuracy: 0.7802 - val_loss: 0.5745 - val_accuracy: 0.6877\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.4495 - accuracy: 0.7909 - val_loss: 0.5334 - val_accuracy: 0.7282\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.4343 - accuracy: 0.7992 - val_loss: 0.6043 - val_accuracy: 0.6806\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.4198 - accuracy: 0.8078 - val_loss: 0.5962 - val_accuracy: 0.6893\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.4031 - accuracy: 0.8218 - val_loss: 0.5120 - val_accuracy: 0.7599\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.3884 - accuracy: 0.8313 - val_loss: 0.6289 - val_accuracy: 0.6763\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3733 - accuracy: 0.8423 - val_loss: 0.4344 - val_accuracy: 0.8249\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.3593 - accuracy: 0.8514 - val_loss: 0.4679 - val_accuracy: 0.8081\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.3456 - accuracy: 0.8598 - val_loss: 0.3930 - val_accuracy: 0.8453\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.3344 - accuracy: 0.8661 - val_loss: 0.5023 - val_accuracy: 0.7898\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.3251 - accuracy: 0.8728 - val_loss: 0.4817 - val_accuracy: 0.8021\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.3167 - accuracy: 0.8754 - val_loss: 0.4085 - val_accuracy: 0.8400\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.3089 - accuracy: 0.8800 - val_loss: 0.5138 - val_accuracy: 0.7912\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.3040 - accuracy: 0.8821 - val_loss: 0.3551 - val_accuracy: 0.8617\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.3005 - accuracy: 0.8830 - val_loss: 0.5574 - val_accuracy: 0.7697\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.2958 - accuracy: 0.8854 - val_loss: 0.4812 - val_accuracy: 0.8096\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.2926 - accuracy: 0.8878 - val_loss: 0.4090 - val_accuracy: 0.8397\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.2886 - accuracy: 0.8889 - val_loss: 0.5501 - val_accuracy: 0.7760\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2879 - accuracy: 0.8887 - val_loss: 0.4041 - val_accuracy: 0.8428\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.2840 - accuracy: 0.8893 - val_loss: 0.4334 - val_accuracy: 0.8294\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2822 - accuracy: 0.8899 - val_loss: 0.4076 - val_accuracy: 0.8424\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2800 - accuracy: 0.8923 - val_loss: 0.4633 - val_accuracy: 0.8171\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.2786 - accuracy: 0.8926 - val_loss: 0.4413 - val_accuracy: 0.8257\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2778 - accuracy: 0.8920 - val_loss: 0.4988 - val_accuracy: 0.8021\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2771 - accuracy: 0.8934 - val_loss: 0.5091 - val_accuracy: 0.7993\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.2755 - accuracy: 0.8935 - val_loss: 0.4479 - val_accuracy: 0.8215\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.2731 - accuracy: 0.8947 - val_loss: 0.4292 - val_accuracy: 0.8329\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.2724 - accuracy: 0.8941 - val_loss: 0.4064 - val_accuracy: 0.8428\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2732 - accuracy: 0.8933 - val_loss: 0.4006 - val_accuracy: 0.8463\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2700 - accuracy: 0.8960 - val_loss: 0.6158 - val_accuracy: 0.7503\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2700 - accuracy: 0.8946 - val_loss: 0.4947 - val_accuracy: 0.8048\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2679 - accuracy: 0.8963 - val_loss: 0.5321 - val_accuracy: 0.7852\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2674 - accuracy: 0.8961 - val_loss: 0.4827 - val_accuracy: 0.8067\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.2656 - accuracy: 0.8970 - val_loss: 0.4649 - val_accuracy: 0.8171\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.2644 - accuracy: 0.8977 - val_loss: 0.5359 - val_accuracy: 0.7847\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.2643 - accuracy: 0.8984 - val_loss: 0.6077 - val_accuracy: 0.7543\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2638 - accuracy: 0.8977 - val_loss: 0.4434 - val_accuracy: 0.8232\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.2628 - accuracy: 0.8982 - val_loss: 0.5590 - val_accuracy: 0.7761\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.2624 - accuracy: 0.8993 - val_loss: 0.4704 - val_accuracy: 0.8121\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2606 - accuracy: 0.8997 - val_loss: 0.4449 - val_accuracy: 0.8244\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.2599 - accuracy: 0.8988 - val_loss: 0.5373 - val_accuracy: 0.7824\n",
      "\n",
      "Training model with noise_multiplier=1.5...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.5 iterated over 167200 steps satisfies differential privacy with eps = 0.486 and delta = 1e-05.\n",
      "The optimal RDP order is 35.0.\n",
      "Epoch 1/50\n",
      "3320/3344 [============================>.] - ETA: 0s - loss: 0.6727 - accuracy: 0.5720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.6725 - accuracy: 0.5724 - val_loss: 0.6605 - val_accuracy: 0.6060\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.6133 - accuracy: 0.6699 - val_loss: 0.6017 - val_accuracy: 0.6702\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.5767 - accuracy: 0.7073 - val_loss: 0.6083 - val_accuracy: 0.6561\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.5509 - accuracy: 0.7258 - val_loss: 0.5879 - val_accuracy: 0.6702\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.5332 - accuracy: 0.7352 - val_loss: 0.6006 - val_accuracy: 0.6623\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.5189 - accuracy: 0.7450 - val_loss: 0.5774 - val_accuracy: 0.6786\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.5064 - accuracy: 0.7504 - val_loss: 0.5594 - val_accuracy: 0.6942\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.4961 - accuracy: 0.7571 - val_loss: 0.6050 - val_accuracy: 0.6594\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.4851 - accuracy: 0.7628 - val_loss: 0.5787 - val_accuracy: 0.6841\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.4740 - accuracy: 0.7718 - val_loss: 0.5657 - val_accuracy: 0.6942\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.4610 - accuracy: 0.7803 - val_loss: 0.5922 - val_accuracy: 0.6783\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.4470 - accuracy: 0.7897 - val_loss: 0.5441 - val_accuracy: 0.7212\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.4334 - accuracy: 0.7992 - val_loss: 0.6264 - val_accuracy: 0.6643\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.4185 - accuracy: 0.8098 - val_loss: 0.6203 - val_accuracy: 0.6720\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.4021 - accuracy: 0.8212 - val_loss: 0.5002 - val_accuracy: 0.7734\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.3848 - accuracy: 0.8346 - val_loss: 0.4799 - val_accuracy: 0.7949\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.3702 - accuracy: 0.8464 - val_loss: 0.4535 - val_accuracy: 0.8167\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.3550 - accuracy: 0.8548 - val_loss: 0.4236 - val_accuracy: 0.8343\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.3439 - accuracy: 0.8622 - val_loss: 0.5457 - val_accuracy: 0.7578\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.3342 - accuracy: 0.8667 - val_loss: 0.5043 - val_accuracy: 0.7928\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.3246 - accuracy: 0.8723 - val_loss: 0.4982 - val_accuracy: 0.7981\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.3171 - accuracy: 0.8756 - val_loss: 0.4003 - val_accuracy: 0.8466\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.3119 - accuracy: 0.8784 - val_loss: 0.5055 - val_accuracy: 0.8007\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.3055 - accuracy: 0.8803 - val_loss: 0.5059 - val_accuracy: 0.8017\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.3019 - accuracy: 0.8826 - val_loss: 0.6772 - val_accuracy: 0.7013\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2992 - accuracy: 0.8834 - val_loss: 0.5447 - val_accuracy: 0.7804\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2957 - accuracy: 0.8845 - val_loss: 0.4626 - val_accuracy: 0.8241\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2917 - accuracy: 0.8868 - val_loss: 0.4392 - val_accuracy: 0.8335\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.2892 - accuracy: 0.8865 - val_loss: 0.5471 - val_accuracy: 0.7839\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2878 - accuracy: 0.8883 - val_loss: 0.5955 - val_accuracy: 0.7590\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.2848 - accuracy: 0.8877 - val_loss: 0.4875 - val_accuracy: 0.8149\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2848 - accuracy: 0.8885 - val_loss: 0.5151 - val_accuracy: 0.8028\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2813 - accuracy: 0.8903 - val_loss: 0.4449 - val_accuracy: 0.8325\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.2818 - accuracy: 0.8906 - val_loss: 0.4313 - val_accuracy: 0.8362\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2799 - accuracy: 0.8914 - val_loss: 0.4621 - val_accuracy: 0.8274\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2789 - accuracy: 0.8927 - val_loss: 0.4842 - val_accuracy: 0.8162\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.2783 - accuracy: 0.8921 - val_loss: 0.4700 - val_accuracy: 0.8231\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2753 - accuracy: 0.8941 - val_loss: 0.7343 - val_accuracy: 0.6906\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2749 - accuracy: 0.8945 - val_loss: 0.5022 - val_accuracy: 0.8101\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2737 - accuracy: 0.8944 - val_loss: 0.4944 - val_accuracy: 0.8129\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.2709 - accuracy: 0.8961 - val_loss: 0.6276 - val_accuracy: 0.7474\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.2706 - accuracy: 0.8954 - val_loss: 0.4608 - val_accuracy: 0.8266\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2713 - accuracy: 0.8958 - val_loss: 0.4606 - val_accuracy: 0.8263\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.2696 - accuracy: 0.8968 - val_loss: 0.4912 - val_accuracy: 0.8141\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2682 - accuracy: 0.8957 - val_loss: 0.4373 - val_accuracy: 0.8346\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2687 - accuracy: 0.8962 - val_loss: 0.4456 - val_accuracy: 0.8296\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2667 - accuracy: 0.8973 - val_loss: 0.4404 - val_accuracy: 0.8318\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2657 - accuracy: 0.8973 - val_loss: 0.4433 - val_accuracy: 0.8308\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2662 - accuracy: 0.8968 - val_loss: 0.4223 - val_accuracy: 0.8382\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2632 - accuracy: 0.8980 - val_loss: 0.4428 - val_accuracy: 0.8328\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.6885 - accuracy: 0.5459 - val_loss: 0.6682 - val_accuracy: 0.6036\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.6409 - accuracy: 0.6394 - val_loss: 0.6507 - val_accuracy: 0.6007\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.6036 - accuracy: 0.6806 - val_loss: 0.6193 - val_accuracy: 0.6229\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.5748 - accuracy: 0.7062 - val_loss: 0.6071 - val_accuracy: 0.6300\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5536 - accuracy: 0.7226 - val_loss: 0.6095 - val_accuracy: 0.6248\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5381 - accuracy: 0.7287 - val_loss: 0.5863 - val_accuracy: 0.6592\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5235 - accuracy: 0.7382 - val_loss: 0.6490 - val_accuracy: 0.6092\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.5109 - accuracy: 0.7458 - val_loss: 0.6667 - val_accuracy: 0.6052\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5003 - accuracy: 0.7520 - val_loss: 0.6251 - val_accuracy: 0.6357\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.4903 - accuracy: 0.7598 - val_loss: 0.5974 - val_accuracy: 0.6619\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.4786 - accuracy: 0.7676 - val_loss: 0.6199 - val_accuracy: 0.6491\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.4660 - accuracy: 0.7765 - val_loss: 0.5936 - val_accuracy: 0.6750\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.4525 - accuracy: 0.7870 - val_loss: 0.6037 - val_accuracy: 0.6708\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.4399 - accuracy: 0.7959 - val_loss: 0.5603 - val_accuracy: 0.7119\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.4241 - accuracy: 0.8086 - val_loss: 0.5411 - val_accuracy: 0.7342\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.4091 - accuracy: 0.8187 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.3929 - accuracy: 0.8289 - val_loss: 0.5363 - val_accuracy: 0.7470\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3775 - accuracy: 0.8406 - val_loss: 0.5458 - val_accuracy: 0.7440\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.3632 - accuracy: 0.8491 - val_loss: 0.4493 - val_accuracy: 0.8203\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.3511 - accuracy: 0.8553 - val_loss: 0.5649 - val_accuracy: 0.7426\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.3397 - accuracy: 0.8625 - val_loss: 0.5388 - val_accuracy: 0.7670\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3306 - accuracy: 0.8674 - val_loss: 0.6454 - val_accuracy: 0.7015\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.3220 - accuracy: 0.8711 - val_loss: 0.4352 - val_accuracy: 0.8297\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.3172 - accuracy: 0.8742 - val_loss: 0.4634 - val_accuracy: 0.8193\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.3109 - accuracy: 0.8761 - val_loss: 0.4399 - val_accuracy: 0.8308\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.3060 - accuracy: 0.8788 - val_loss: 0.4807 - val_accuracy: 0.8113\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.3019 - accuracy: 0.8809 - val_loss: 0.4595 - val_accuracy: 0.8219\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.2992 - accuracy: 0.8816 - val_loss: 0.5496 - val_accuracy: 0.7788\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.2972 - accuracy: 0.8847 - val_loss: 0.4301 - val_accuracy: 0.8361\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2944 - accuracy: 0.8831 - val_loss: 0.5579 - val_accuracy: 0.7749\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2918 - accuracy: 0.8862 - val_loss: 0.4961 - val_accuracy: 0.8080\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2896 - accuracy: 0.8865 - val_loss: 0.4523 - val_accuracy: 0.8261\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2883 - accuracy: 0.8864 - val_loss: 0.4365 - val_accuracy: 0.8345\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.2862 - accuracy: 0.8879 - val_loss: 0.5331 - val_accuracy: 0.7898\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.2857 - accuracy: 0.8890 - val_loss: 0.4770 - val_accuracy: 0.8171\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.2845 - accuracy: 0.8905 - val_loss: 0.4476 - val_accuracy: 0.8310\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.2825 - accuracy: 0.8888 - val_loss: 0.4653 - val_accuracy: 0.8213\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.2801 - accuracy: 0.8917 - val_loss: 0.3618 - val_accuracy: 0.8640\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.2796 - accuracy: 0.8908 - val_loss: 0.4167 - val_accuracy: 0.8405\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.2780 - accuracy: 0.8908 - val_loss: 0.4447 - val_accuracy: 0.8291\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2770 - accuracy: 0.8921 - val_loss: 0.6568 - val_accuracy: 0.7265\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2755 - accuracy: 0.8940 - val_loss: 0.5832 - val_accuracy: 0.7632\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.2739 - accuracy: 0.8936 - val_loss: 0.5682 - val_accuracy: 0.7674\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.2739 - accuracy: 0.8937 - val_loss: 0.4163 - val_accuracy: 0.8400\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2727 - accuracy: 0.8948 - val_loss: 0.4108 - val_accuracy: 0.8430\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.2724 - accuracy: 0.8939 - val_loss: 0.5129 - val_accuracy: 0.7941\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2708 - accuracy: 0.8957 - val_loss: 0.4837 - val_accuracy: 0.8116\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2705 - accuracy: 0.8938 - val_loss: 0.4761 - val_accuracy: 0.8136\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2682 - accuracy: 0.8959 - val_loss: 0.5002 - val_accuracy: 0.8040\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.2672 - accuracy: 0.8964 - val_loss: 0.4519 - val_accuracy: 0.8223\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.6566 - accuracy: 0.6059 - val_loss: 0.6747 - val_accuracy: 0.5957\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.6048 - accuracy: 0.6785 - val_loss: 0.6132 - val_accuracy: 0.6704\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.5714 - accuracy: 0.7080 - val_loss: 0.5960 - val_accuracy: 0.6719\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.5486 - accuracy: 0.7254 - val_loss: 0.6039 - val_accuracy: 0.6614\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.5303 - accuracy: 0.7347 - val_loss: 0.5816 - val_accuracy: 0.6748\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.5160 - accuracy: 0.7415 - val_loss: 0.5924 - val_accuracy: 0.6675\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.5027 - accuracy: 0.7502 - val_loss: 0.5933 - val_accuracy: 0.6647\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.4912 - accuracy: 0.7566 - val_loss: 0.6498 - val_accuracy: 0.6219\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.4785 - accuracy: 0.7660 - val_loss: 0.5970 - val_accuracy: 0.6614\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.4645 - accuracy: 0.7763 - val_loss: 0.5515 - val_accuracy: 0.7043\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.4500 - accuracy: 0.7861 - val_loss: 0.5753 - val_accuracy: 0.6894\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.4347 - accuracy: 0.7985 - val_loss: 0.4682 - val_accuracy: 0.7925\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.4188 - accuracy: 0.8118 - val_loss: 0.5107 - val_accuracy: 0.7579\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5831 - val_accuracy: 0.7063\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.3867 - accuracy: 0.8337 - val_loss: 0.5003 - val_accuracy: 0.7779\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3721 - accuracy: 0.8436 - val_loss: 0.5700 - val_accuracy: 0.7277\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.3595 - accuracy: 0.8538 - val_loss: 0.4438 - val_accuracy: 0.8217\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.3481 - accuracy: 0.8581 - val_loss: 0.5353 - val_accuracy: 0.7652\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.3368 - accuracy: 0.8667 - val_loss: 0.5388 - val_accuracy: 0.7645\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.3290 - accuracy: 0.8690 - val_loss: 0.4161 - val_accuracy: 0.8364\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.3210 - accuracy: 0.8730 - val_loss: 0.5726 - val_accuracy: 0.7532\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 446us/step - loss: 0.3144 - accuracy: 0.8777 - val_loss: 0.5390 - val_accuracy: 0.7765\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.3092 - accuracy: 0.8789 - val_loss: 0.4849 - val_accuracy: 0.8099\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.3062 - accuracy: 0.8803 - val_loss: 0.4463 - val_accuracy: 0.8267\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.3022 - accuracy: 0.8816 - val_loss: 0.5131 - val_accuracy: 0.7955\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.2992 - accuracy: 0.8838 - val_loss: 0.5069 - val_accuracy: 0.7998\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.2959 - accuracy: 0.8857 - val_loss: 0.5763 - val_accuracy: 0.7657\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.2932 - accuracy: 0.8848 - val_loss: 0.5706 - val_accuracy: 0.7669\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.2919 - accuracy: 0.8856 - val_loss: 0.5177 - val_accuracy: 0.7934\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2902 - accuracy: 0.8875 - val_loss: 0.6028 - val_accuracy: 0.7555\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2885 - accuracy: 0.8877 - val_loss: 0.3616 - val_accuracy: 0.8600\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.2865 - accuracy: 0.8884 - val_loss: 0.4353 - val_accuracy: 0.8306\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2836 - accuracy: 0.8896 - val_loss: 0.4420 - val_accuracy: 0.8286\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2822 - accuracy: 0.8895 - val_loss: 0.5426 - val_accuracy: 0.7855\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2831 - accuracy: 0.8906 - val_loss: 0.4080 - val_accuracy: 0.8433\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2793 - accuracy: 0.8909 - val_loss: 0.3955 - val_accuracy: 0.8483\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2799 - accuracy: 0.8909 - val_loss: 0.3917 - val_accuracy: 0.8488\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2774 - accuracy: 0.8925 - val_loss: 0.5165 - val_accuracy: 0.7950\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.2776 - accuracy: 0.8917 - val_loss: 0.4400 - val_accuracy: 0.8280\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2768 - accuracy: 0.8941 - val_loss: 0.4915 - val_accuracy: 0.8056\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.2756 - accuracy: 0.8935 - val_loss: 0.4395 - val_accuracy: 0.8256\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2748 - accuracy: 0.8937 - val_loss: 0.4142 - val_accuracy: 0.8372\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2736 - accuracy: 0.8942 - val_loss: 0.3814 - val_accuracy: 0.8504\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2717 - accuracy: 0.8943 - val_loss: 0.4610 - val_accuracy: 0.8175\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.2724 - accuracy: 0.8953 - val_loss: 0.5476 - val_accuracy: 0.7819\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2698 - accuracy: 0.8945 - val_loss: 0.4566 - val_accuracy: 0.8190\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2696 - accuracy: 0.8959 - val_loss: 0.4222 - val_accuracy: 0.8349\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2684 - accuracy: 0.8957 - val_loss: 0.5543 - val_accuracy: 0.7768\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2684 - accuracy: 0.8969 - val_loss: 0.4458 - val_accuracy: 0.8268\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2675 - accuracy: 0.8964 - val_loss: 0.5043 - val_accuracy: 0.8010\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.6537 - accuracy: 0.6121 - val_loss: 0.6306 - val_accuracy: 0.6378\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.6029 - accuracy: 0.6792 - val_loss: 0.6033 - val_accuracy: 0.6570\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.5729 - accuracy: 0.7051 - val_loss: 0.6106 - val_accuracy: 0.6434\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.5507 - accuracy: 0.7194 - val_loss: 0.6052 - val_accuracy: 0.6388\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.5326 - accuracy: 0.7332 - val_loss: 0.5594 - val_accuracy: 0.6796\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 442us/step - loss: 0.5198 - accuracy: 0.7392 - val_loss: 0.6112 - val_accuracy: 0.6402\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.5069 - accuracy: 0.7483 - val_loss: 0.5846 - val_accuracy: 0.6617\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.4936 - accuracy: 0.7557 - val_loss: 0.5614 - val_accuracy: 0.6835\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.4810 - accuracy: 0.7622 - val_loss: 0.5462 - val_accuracy: 0.7014\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.4667 - accuracy: 0.7747 - val_loss: 0.5729 - val_accuracy: 0.6838\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.4526 - accuracy: 0.7854 - val_loss: 0.5328 - val_accuracy: 0.7248\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.4377 - accuracy: 0.7958 - val_loss: 0.5049 - val_accuracy: 0.7533\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.4222 - accuracy: 0.8078 - val_loss: 0.5983 - val_accuracy: 0.6866\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.4061 - accuracy: 0.8204 - val_loss: 0.5530 - val_accuracy: 0.7208\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.3906 - accuracy: 0.8293 - val_loss: 0.5291 - val_accuracy: 0.7474\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.3746 - accuracy: 0.8416 - val_loss: 0.5691 - val_accuracy: 0.7237\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3603 - accuracy: 0.8488 - val_loss: 0.5370 - val_accuracy: 0.7528\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3488 - accuracy: 0.8571 - val_loss: 0.4959 - val_accuracy: 0.7855\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.3372 - accuracy: 0.8638 - val_loss: 0.5012 - val_accuracy: 0.7870\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.3285 - accuracy: 0.8678 - val_loss: 0.4445 - val_accuracy: 0.8241\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.3201 - accuracy: 0.8727 - val_loss: 0.5232 - val_accuracy: 0.7778\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.3129 - accuracy: 0.8758 - val_loss: 0.4223 - val_accuracy: 0.8345\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.3074 - accuracy: 0.8796 - val_loss: 0.5232 - val_accuracy: 0.7817\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.3017 - accuracy: 0.8806 - val_loss: 0.5637 - val_accuracy: 0.7621\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2981 - accuracy: 0.8833 - val_loss: 0.4402 - val_accuracy: 0.8282\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.2945 - accuracy: 0.8848 - val_loss: 0.5985 - val_accuracy: 0.7440\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.2913 - accuracy: 0.8857 - val_loss: 0.4422 - val_accuracy: 0.8288\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2883 - accuracy: 0.8868 - val_loss: 0.4742 - val_accuracy: 0.8138\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.2861 - accuracy: 0.8876 - val_loss: 0.4603 - val_accuracy: 0.8212\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.2840 - accuracy: 0.8892 - val_loss: 0.4527 - val_accuracy: 0.8237\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.2836 - accuracy: 0.8886 - val_loss: 0.4780 - val_accuracy: 0.8121\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2805 - accuracy: 0.8892 - val_loss: 0.4134 - val_accuracy: 0.8392\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 610us/step - loss: 0.2782 - accuracy: 0.8912 - val_loss: 0.5234 - val_accuracy: 0.7910\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2773 - accuracy: 0.8910 - val_loss: 0.5997 - val_accuracy: 0.7515\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.2759 - accuracy: 0.8909 - val_loss: 0.4061 - val_accuracy: 0.8420\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2753 - accuracy: 0.8916 - val_loss: 0.3845 - val_accuracy: 0.8519\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2732 - accuracy: 0.8936 - val_loss: 0.4378 - val_accuracy: 0.8311\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2727 - accuracy: 0.8935 - val_loss: 0.5726 - val_accuracy: 0.7643\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2720 - accuracy: 0.8937 - val_loss: 0.5098 - val_accuracy: 0.7992\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2713 - accuracy: 0.8944 - val_loss: 0.5120 - val_accuracy: 0.7993\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2702 - accuracy: 0.8945 - val_loss: 0.3690 - val_accuracy: 0.8558\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.2699 - accuracy: 0.8942 - val_loss: 0.4068 - val_accuracy: 0.8405\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.2690 - accuracy: 0.8954 - val_loss: 0.5397 - val_accuracy: 0.7860\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2678 - accuracy: 0.8961 - val_loss: 0.4794 - val_accuracy: 0.8126\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2662 - accuracy: 0.8954 - val_loss: 0.4621 - val_accuracy: 0.8181\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2659 - accuracy: 0.8972 - val_loss: 0.4409 - val_accuracy: 0.8253\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.2645 - accuracy: 0.8967 - val_loss: 0.3849 - val_accuracy: 0.8505\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2645 - accuracy: 0.8973 - val_loss: 0.4349 - val_accuracy: 0.8266\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.2630 - accuracy: 0.8982 - val_loss: 0.4151 - val_accuracy: 0.8373\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2617 - accuracy: 0.8975 - val_loss: 0.5137 - val_accuracy: 0.7925\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.6526 - accuracy: 0.6290 - val_loss: 0.6409 - val_accuracy: 0.6300\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.5919 - accuracy: 0.7036 - val_loss: 0.5979 - val_accuracy: 0.6561\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.5601 - accuracy: 0.7243 - val_loss: 0.6049 - val_accuracy: 0.6417\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5382 - accuracy: 0.7372 - val_loss: 0.5968 - val_accuracy: 0.6506\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.5221 - accuracy: 0.7427 - val_loss: 0.5457 - val_accuracy: 0.6962\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.5066 - accuracy: 0.7512 - val_loss: 0.6284 - val_accuracy: 0.6335\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.4928 - accuracy: 0.7598 - val_loss: 0.5337 - val_accuracy: 0.7124\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.4801 - accuracy: 0.7673 - val_loss: 0.5972 - val_accuracy: 0.6645\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.4650 - accuracy: 0.7780 - val_loss: 0.5754 - val_accuracy: 0.6864\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.4496 - accuracy: 0.7885 - val_loss: 0.5031 - val_accuracy: 0.7519\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.4341 - accuracy: 0.8008 - val_loss: 0.5020 - val_accuracy: 0.7553\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.4166 - accuracy: 0.8119 - val_loss: 0.4514 - val_accuracy: 0.8058\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.4005 - accuracy: 0.8228 - val_loss: 0.5778 - val_accuracy: 0.7073\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.4902 - val_accuracy: 0.7755\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.3700 - accuracy: 0.8440 - val_loss: 0.5116 - val_accuracy: 0.7662\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3566 - accuracy: 0.8531 - val_loss: 0.5065 - val_accuracy: 0.7732\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.3441 - accuracy: 0.8585 - val_loss: 0.5175 - val_accuracy: 0.7673\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.3329 - accuracy: 0.8652 - val_loss: 0.5212 - val_accuracy: 0.7712\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.3253 - accuracy: 0.8707 - val_loss: 0.6130 - val_accuracy: 0.7149\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.3178 - accuracy: 0.8728 - val_loss: 0.4731 - val_accuracy: 0.8070\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.3113 - accuracy: 0.8772 - val_loss: 0.4657 - val_accuracy: 0.8131\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.3061 - accuracy: 0.8788 - val_loss: 0.4519 - val_accuracy: 0.8204\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.3033 - accuracy: 0.8796 - val_loss: 0.4374 - val_accuracy: 0.8268\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2996 - accuracy: 0.8805 - val_loss: 0.4840 - val_accuracy: 0.8057\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.2960 - accuracy: 0.8834 - val_loss: 0.5106 - val_accuracy: 0.7922\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.2935 - accuracy: 0.8855 - val_loss: 0.3979 - val_accuracy: 0.8457\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2905 - accuracy: 0.8859 - val_loss: 0.5434 - val_accuracy: 0.7758\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2887 - accuracy: 0.8878 - val_loss: 0.5135 - val_accuracy: 0.7897\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2877 - accuracy: 0.8878 - val_loss: 0.3651 - val_accuracy: 0.8586\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.2854 - accuracy: 0.8876 - val_loss: 0.4776 - val_accuracy: 0.8092\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.2833 - accuracy: 0.8894 - val_loss: 0.3864 - val_accuracy: 0.8494\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.2827 - accuracy: 0.8900 - val_loss: 0.3997 - val_accuracy: 0.8421\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2815 - accuracy: 0.8898 - val_loss: 0.4958 - val_accuracy: 0.8012\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.2791 - accuracy: 0.8916 - val_loss: 0.3920 - val_accuracy: 0.8477\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2786 - accuracy: 0.8919 - val_loss: 0.4881 - val_accuracy: 0.8047\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2774 - accuracy: 0.8921 - val_loss: 0.4511 - val_accuracy: 0.8212\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2763 - accuracy: 0.8918 - val_loss: 0.4875 - val_accuracy: 0.8027\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2741 - accuracy: 0.8928 - val_loss: 0.4574 - val_accuracy: 0.8175\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2728 - accuracy: 0.8936 - val_loss: 0.6495 - val_accuracy: 0.7228\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.2731 - accuracy: 0.8943 - val_loss: 0.4148 - val_accuracy: 0.8358\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2707 - accuracy: 0.8949 - val_loss: 0.4550 - val_accuracy: 0.8164\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2707 - accuracy: 0.8942 - val_loss: 0.4457 - val_accuracy: 0.8226\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2685 - accuracy: 0.8964 - val_loss: 0.4274 - val_accuracy: 0.8296\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2681 - accuracy: 0.8965 - val_loss: 0.5201 - val_accuracy: 0.7908\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2677 - accuracy: 0.8966 - val_loss: 0.5240 - val_accuracy: 0.7897\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2665 - accuracy: 0.8961 - val_loss: 0.4285 - val_accuracy: 0.8315\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2663 - accuracy: 0.8982 - val_loss: 0.5831 - val_accuracy: 0.7588\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2644 - accuracy: 0.8978 - val_loss: 0.4537 - val_accuracy: 0.8181\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.2634 - accuracy: 0.8981 - val_loss: 0.5326 - val_accuracy: 0.7807\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2642 - accuracy: 0.8974 - val_loss: 0.4721 - val_accuracy: 0.8084\n",
      "Epoch 1/50\n",
      "3311/3344 [============================>.] - ETA: 0s - loss: 0.6517 - accuracy: 0.6231WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.6513 - accuracy: 0.6238 - val_loss: 0.6376 - val_accuracy: 0.6403\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.5945 - accuracy: 0.6916 - val_loss: 0.6168 - val_accuracy: 0.6564\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5648 - accuracy: 0.7128 - val_loss: 0.5922 - val_accuracy: 0.6734\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.5447 - accuracy: 0.7260 - val_loss: 0.5698 - val_accuracy: 0.6848\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.5269 - accuracy: 0.7367 - val_loss: 0.6372 - val_accuracy: 0.6353\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.5142 - accuracy: 0.7420 - val_loss: 0.6255 - val_accuracy: 0.6483\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.5039 - accuracy: 0.7488 - val_loss: 0.5365 - val_accuracy: 0.7103\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.4926 - accuracy: 0.7576 - val_loss: 0.5823 - val_accuracy: 0.6819\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.4808 - accuracy: 0.7640 - val_loss: 0.5760 - val_accuracy: 0.6857\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.4708 - accuracy: 0.7709 - val_loss: 0.5741 - val_accuracy: 0.6894\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.4594 - accuracy: 0.7791 - val_loss: 0.5878 - val_accuracy: 0.6837\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.4471 - accuracy: 0.7881 - val_loss: 0.5904 - val_accuracy: 0.6861\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.4339 - accuracy: 0.7975 - val_loss: 0.6010 - val_accuracy: 0.6822\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.4203 - accuracy: 0.8071 - val_loss: 0.5225 - val_accuracy: 0.7471\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.4050 - accuracy: 0.8195 - val_loss: 0.5204 - val_accuracy: 0.7528\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.3904 - accuracy: 0.8299 - val_loss: 0.4374 - val_accuracy: 0.8236\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3751 - accuracy: 0.8412 - val_loss: 0.4809 - val_accuracy: 0.7965\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.3614 - accuracy: 0.8495 - val_loss: 0.4223 - val_accuracy: 0.8349\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.3497 - accuracy: 0.8569 - val_loss: 0.6534 - val_accuracy: 0.6858\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3381 - accuracy: 0.8643 - val_loss: 0.5923 - val_accuracy: 0.7318\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.3288 - accuracy: 0.8695 - val_loss: 0.5142 - val_accuracy: 0.7883\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.3218 - accuracy: 0.8726 - val_loss: 0.4171 - val_accuracy: 0.8415\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.3145 - accuracy: 0.8745 - val_loss: 0.4971 - val_accuracy: 0.8045\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.3098 - accuracy: 0.8778 - val_loss: 0.4770 - val_accuracy: 0.8159\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.3058 - accuracy: 0.8811 - val_loss: 0.4693 - val_accuracy: 0.8202\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.3033 - accuracy: 0.8823 - val_loss: 0.4374 - val_accuracy: 0.8336\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.2988 - accuracy: 0.8842 - val_loss: 0.4998 - val_accuracy: 0.8084\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2968 - accuracy: 0.8843 - val_loss: 0.4164 - val_accuracy: 0.8424\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.2939 - accuracy: 0.8844 - val_loss: 0.3864 - val_accuracy: 0.8547\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.2915 - accuracy: 0.8873 - val_loss: 0.5037 - val_accuracy: 0.8076\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2887 - accuracy: 0.8884 - val_loss: 0.3819 - val_accuracy: 0.8566\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2878 - accuracy: 0.8882 - val_loss: 0.6931 - val_accuracy: 0.7084\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2846 - accuracy: 0.8888 - val_loss: 0.5264 - val_accuracy: 0.7945\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2843 - accuracy: 0.8891 - val_loss: 0.3956 - val_accuracy: 0.8499\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.2829 - accuracy: 0.8902 - val_loss: 0.4585 - val_accuracy: 0.8234\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.2819 - accuracy: 0.8906 - val_loss: 0.5530 - val_accuracy: 0.7807\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2809 - accuracy: 0.8911 - val_loss: 0.5538 - val_accuracy: 0.7852\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2788 - accuracy: 0.8921 - val_loss: 0.5615 - val_accuracy: 0.7787\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2785 - accuracy: 0.8920 - val_loss: 0.4102 - val_accuracy: 0.8424\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.2772 - accuracy: 0.8923 - val_loss: 0.5906 - val_accuracy: 0.7662\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2754 - accuracy: 0.8934 - val_loss: 0.5052 - val_accuracy: 0.8044\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.2745 - accuracy: 0.8937 - val_loss: 0.4462 - val_accuracy: 0.8269\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.2735 - accuracy: 0.8938 - val_loss: 0.5622 - val_accuracy: 0.7775\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2722 - accuracy: 0.8940 - val_loss: 0.4840 - val_accuracy: 0.8101\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.2713 - accuracy: 0.8953 - val_loss: 0.5671 - val_accuracy: 0.7725\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2702 - accuracy: 0.8961 - val_loss: 0.5353 - val_accuracy: 0.7855\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2700 - accuracy: 0.8959 - val_loss: 0.4253 - val_accuracy: 0.8360\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2694 - accuracy: 0.8961 - val_loss: 0.5415 - val_accuracy: 0.7902\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.2684 - accuracy: 0.8956 - val_loss: 0.4398 - val_accuracy: 0.8288\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2678 - accuracy: 0.8970 - val_loss: 0.5009 - val_accuracy: 0.8029\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.6668 - accuracy: 0.6077 - val_loss: 0.6472 - val_accuracy: 0.6142\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.6131 - accuracy: 0.6821 - val_loss: 0.6129 - val_accuracy: 0.6434\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.5804 - accuracy: 0.7059 - val_loss: 0.5908 - val_accuracy: 0.6573\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5584 - accuracy: 0.7180 - val_loss: 0.5999 - val_accuracy: 0.6500\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.5432 - accuracy: 0.7255 - val_loss: 0.5941 - val_accuracy: 0.6558\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5292 - accuracy: 0.7324 - val_loss: 0.5754 - val_accuracy: 0.6689\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5190 - accuracy: 0.7389 - val_loss: 0.6038 - val_accuracy: 0.6459\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.5096 - accuracy: 0.7453 - val_loss: 0.5693 - val_accuracy: 0.6801\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.4990 - accuracy: 0.7512 - val_loss: 0.5531 - val_accuracy: 0.6963\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.4878 - accuracy: 0.7588 - val_loss: 0.5846 - val_accuracy: 0.6716\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.4754 - accuracy: 0.7704 - val_loss: 0.5562 - val_accuracy: 0.6982\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.4643 - accuracy: 0.7758 - val_loss: 0.5769 - val_accuracy: 0.6856\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.4509 - accuracy: 0.7859 - val_loss: 0.5479 - val_accuracy: 0.7158\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.4371 - accuracy: 0.7949 - val_loss: 0.5867 - val_accuracy: 0.6913\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.4221 - accuracy: 0.8073 - val_loss: 0.5732 - val_accuracy: 0.7062\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.4070 - accuracy: 0.8184 - val_loss: 0.5876 - val_accuracy: 0.7036\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.3904 - accuracy: 0.8298 - val_loss: 0.5009 - val_accuracy: 0.7770\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3756 - accuracy: 0.8426 - val_loss: 0.5395 - val_accuracy: 0.7492\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.3612 - accuracy: 0.8509 - val_loss: 0.4620 - val_accuracy: 0.8140\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.3485 - accuracy: 0.8580 - val_loss: 0.4002 - val_accuracy: 0.8457\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.3380 - accuracy: 0.8643 - val_loss: 0.4414 - val_accuracy: 0.8279\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.3272 - accuracy: 0.8702 - val_loss: 0.5070 - val_accuracy: 0.7924\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.3182 - accuracy: 0.8737 - val_loss: 0.4533 - val_accuracy: 0.8225\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.3136 - accuracy: 0.8759 - val_loss: 0.5453 - val_accuracy: 0.7737\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.3069 - accuracy: 0.8795 - val_loss: 0.4017 - val_accuracy: 0.8466\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 443us/step - loss: 0.3027 - accuracy: 0.8820 - val_loss: 0.4846 - val_accuracy: 0.8127\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.2989 - accuracy: 0.8828 - val_loss: 0.5748 - val_accuracy: 0.7629\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2951 - accuracy: 0.8848 - val_loss: 0.5333 - val_accuracy: 0.7837\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2917 - accuracy: 0.8853 - val_loss: 0.4654 - val_accuracy: 0.8202\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.2888 - accuracy: 0.8877 - val_loss: 0.6463 - val_accuracy: 0.7272\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2859 - accuracy: 0.8880 - val_loss: 0.4721 - val_accuracy: 0.8192\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2833 - accuracy: 0.8891 - val_loss: 0.5141 - val_accuracy: 0.7953\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2827 - accuracy: 0.8901 - val_loss: 0.5083 - val_accuracy: 0.8032\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.2807 - accuracy: 0.8909 - val_loss: 0.5524 - val_accuracy: 0.7828\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.2794 - accuracy: 0.8912 - val_loss: 0.5489 - val_accuracy: 0.7837\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.2771 - accuracy: 0.8915 - val_loss: 0.4956 - val_accuracy: 0.8085\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2757 - accuracy: 0.8921 - val_loss: 0.5170 - val_accuracy: 0.8017\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.2751 - accuracy: 0.8930 - val_loss: 0.4241 - val_accuracy: 0.8366\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2744 - accuracy: 0.8934 - val_loss: 0.4943 - val_accuracy: 0.8091\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2725 - accuracy: 0.8933 - val_loss: 0.4204 - val_accuracy: 0.8379\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2710 - accuracy: 0.8950 - val_loss: 0.4684 - val_accuracy: 0.8181\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.2703 - accuracy: 0.8943 - val_loss: 0.4535 - val_accuracy: 0.8253\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.2687 - accuracy: 0.8953 - val_loss: 0.4583 - val_accuracy: 0.8219\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.2684 - accuracy: 0.8951 - val_loss: 0.5677 - val_accuracy: 0.7760\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2672 - accuracy: 0.8958 - val_loss: 0.4649 - val_accuracy: 0.8209\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2670 - accuracy: 0.8964 - val_loss: 0.4769 - val_accuracy: 0.8139\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.2670 - accuracy: 0.8959 - val_loss: 0.4473 - val_accuracy: 0.8262\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.2637 - accuracy: 0.8969 - val_loss: 0.4837 - val_accuracy: 0.8113\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.2650 - accuracy: 0.8970 - val_loss: 0.5506 - val_accuracy: 0.7785\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2634 - accuracy: 0.8970 - val_loss: 0.4777 - val_accuracy: 0.8129\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.6512 - accuracy: 0.6094 - val_loss: 0.6585 - val_accuracy: 0.5947\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.6073 - accuracy: 0.6597 - val_loss: 0.6086 - val_accuracy: 0.6511\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.5810 - accuracy: 0.6866 - val_loss: 0.6520 - val_accuracy: 0.5911\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.5610 - accuracy: 0.7090 - val_loss: 0.6146 - val_accuracy: 0.6321\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.5462 - accuracy: 0.7188 - val_loss: 0.6015 - val_accuracy: 0.6543\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.5323 - accuracy: 0.7304 - val_loss: 0.6026 - val_accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.5211 - accuracy: 0.7361 - val_loss: 0.5942 - val_accuracy: 0.6705\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.5090 - accuracy: 0.7457 - val_loss: 0.5886 - val_accuracy: 0.6767\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.4976 - accuracy: 0.7535 - val_loss: 0.5677 - val_accuracy: 0.6938\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.4876 - accuracy: 0.7609 - val_loss: 0.5884 - val_accuracy: 0.6802\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.4746 - accuracy: 0.7699 - val_loss: 0.6077 - val_accuracy: 0.6670\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.4628 - accuracy: 0.7784 - val_loss: 0.6068 - val_accuracy: 0.6718\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.6266 - val_accuracy: 0.6644\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.4355 - accuracy: 0.7977 - val_loss: 0.4941 - val_accuracy: 0.7697\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.4219 - accuracy: 0.8089 - val_loss: 0.5574 - val_accuracy: 0.7199\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.4055 - accuracy: 0.8193 - val_loss: 0.5556 - val_accuracy: 0.7239\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.3913 - accuracy: 0.8297 - val_loss: 0.4827 - val_accuracy: 0.7862\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3767 - accuracy: 0.8385 - val_loss: 0.4830 - val_accuracy: 0.7927\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 451us/step - loss: 0.3628 - accuracy: 0.8472 - val_loss: 0.6026 - val_accuracy: 0.7098\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.3518 - accuracy: 0.8555 - val_loss: 0.4594 - val_accuracy: 0.8120\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.3401 - accuracy: 0.8611 - val_loss: 0.4947 - val_accuracy: 0.7951\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.3298 - accuracy: 0.8680 - val_loss: 0.4839 - val_accuracy: 0.8048\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.3236 - accuracy: 0.8696 - val_loss: 0.5250 - val_accuracy: 0.7830\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3158 - accuracy: 0.8749 - val_loss: 0.3957 - val_accuracy: 0.8503\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.3100 - accuracy: 0.8788 - val_loss: 0.3958 - val_accuracy: 0.8497\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.3049 - accuracy: 0.8794 - val_loss: 0.4298 - val_accuracy: 0.8352\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3009 - accuracy: 0.8812 - val_loss: 0.3910 - val_accuracy: 0.8505\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2968 - accuracy: 0.8845 - val_loss: 0.4855 - val_accuracy: 0.8112\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2929 - accuracy: 0.8846 - val_loss: 0.4193 - val_accuracy: 0.8379\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2904 - accuracy: 0.8854 - val_loss: 0.4782 - val_accuracy: 0.8146\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2875 - accuracy: 0.8875 - val_loss: 0.4306 - val_accuracy: 0.8335\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2854 - accuracy: 0.8874 - val_loss: 0.4692 - val_accuracy: 0.8198\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2841 - accuracy: 0.8881 - val_loss: 0.5053 - val_accuracy: 0.7994\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2818 - accuracy: 0.8893 - val_loss: 0.4883 - val_accuracy: 0.8084\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.2816 - accuracy: 0.8894 - val_loss: 0.4270 - val_accuracy: 0.8353\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.2779 - accuracy: 0.8920 - val_loss: 0.4642 - val_accuracy: 0.8182\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2777 - accuracy: 0.8921 - val_loss: 0.4056 - val_accuracy: 0.8461\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.2765 - accuracy: 0.8918 - val_loss: 0.4923 - val_accuracy: 0.8074\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2747 - accuracy: 0.8924 - val_loss: 0.3794 - val_accuracy: 0.8543\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.2735 - accuracy: 0.8925 - val_loss: 0.5337 - val_accuracy: 0.7855\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.2726 - accuracy: 0.8927 - val_loss: 0.5015 - val_accuracy: 0.8028\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2710 - accuracy: 0.8941 - val_loss: 0.4381 - val_accuracy: 0.8284\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.2705 - accuracy: 0.8935 - val_loss: 0.5606 - val_accuracy: 0.7700\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.2689 - accuracy: 0.8947 - val_loss: 0.5163 - val_accuracy: 0.7963\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.2675 - accuracy: 0.8956 - val_loss: 0.4168 - val_accuracy: 0.8364\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2682 - accuracy: 0.8951 - val_loss: 0.6972 - val_accuracy: 0.7044\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.2660 - accuracy: 0.8957 - val_loss: 0.4940 - val_accuracy: 0.8025\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.2653 - accuracy: 0.8956 - val_loss: 0.3927 - val_accuracy: 0.8472\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.2645 - accuracy: 0.8968 - val_loss: 0.5432 - val_accuracy: 0.7824\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.2638 - accuracy: 0.8966 - val_loss: 0.5999 - val_accuracy: 0.7521\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.6703 - accuracy: 0.5970 - val_loss: 0.6841 - val_accuracy: 0.5720\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.6241 - accuracy: 0.6785 - val_loss: 0.6134 - val_accuracy: 0.6650\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.5877 - accuracy: 0.7034 - val_loss: 0.5977 - val_accuracy: 0.6615\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.5611 - accuracy: 0.7213 - val_loss: 0.5838 - val_accuracy: 0.6668\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.5420 - accuracy: 0.7302 - val_loss: 0.6025 - val_accuracy: 0.6522\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5276 - accuracy: 0.7371 - val_loss: 0.5948 - val_accuracy: 0.6649\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5148 - accuracy: 0.7445 - val_loss: 0.5645 - val_accuracy: 0.6914\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5626 - val_accuracy: 0.6929\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.4947 - accuracy: 0.7571 - val_loss: 0.6004 - val_accuracy: 0.6691\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.4842 - accuracy: 0.7648 - val_loss: 0.5824 - val_accuracy: 0.6823\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.4732 - accuracy: 0.7702 - val_loss: 0.6567 - val_accuracy: 0.6375\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.4617 - accuracy: 0.7798 - val_loss: 0.5775 - val_accuracy: 0.6906\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.4498 - accuracy: 0.7871 - val_loss: 0.5570 - val_accuracy: 0.7133\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.4366 - accuracy: 0.7965 - val_loss: 0.5473 - val_accuracy: 0.7269\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.4227 - accuracy: 0.8061 - val_loss: 0.5471 - val_accuracy: 0.7296\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.4084 - accuracy: 0.8158 - val_loss: 0.5354 - val_accuracy: 0.7432\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.3939 - accuracy: 0.8288 - val_loss: 0.5303 - val_accuracy: 0.7530\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.3792 - accuracy: 0.8379 - val_loss: 0.4630 - val_accuracy: 0.8089\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.3646 - accuracy: 0.8460 - val_loss: 0.4772 - val_accuracy: 0.8025\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.3526 - accuracy: 0.8549 - val_loss: 0.4454 - val_accuracy: 0.8219\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.3430 - accuracy: 0.8598 - val_loss: 0.4891 - val_accuracy: 0.7985\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.3319 - accuracy: 0.8666 - val_loss: 0.4756 - val_accuracy: 0.8082\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.3251 - accuracy: 0.8704 - val_loss: 0.5391 - val_accuracy: 0.7718\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.3182 - accuracy: 0.8733 - val_loss: 0.4866 - val_accuracy: 0.8074\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.3105 - accuracy: 0.8771 - val_loss: 0.5690 - val_accuracy: 0.7572\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3060 - accuracy: 0.8800 - val_loss: 0.4069 - val_accuracy: 0.8415\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.3020 - accuracy: 0.8815 - val_loss: 0.4518 - val_accuracy: 0.8233\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.2985 - accuracy: 0.8820 - val_loss: 0.5028 - val_accuracy: 0.8010\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2956 - accuracy: 0.8835 - val_loss: 0.6445 - val_accuracy: 0.7249\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2928 - accuracy: 0.8834 - val_loss: 0.4441 - val_accuracy: 0.8270\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.2900 - accuracy: 0.8867 - val_loss: 0.6053 - val_accuracy: 0.7484\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.2888 - accuracy: 0.8870 - val_loss: 0.4528 - val_accuracy: 0.8241\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2875 - accuracy: 0.8877 - val_loss: 0.4542 - val_accuracy: 0.8231\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2844 - accuracy: 0.8886 - val_loss: 0.3850 - val_accuracy: 0.8520\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2834 - accuracy: 0.8887 - val_loss: 0.4488 - val_accuracy: 0.8255\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2821 - accuracy: 0.8908 - val_loss: 0.4810 - val_accuracy: 0.8129\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2787 - accuracy: 0.8911 - val_loss: 0.4756 - val_accuracy: 0.8142\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2790 - accuracy: 0.8914 - val_loss: 0.3895 - val_accuracy: 0.8512\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.2762 - accuracy: 0.8925 - val_loss: 0.3819 - val_accuracy: 0.8534\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2764 - accuracy: 0.8925 - val_loss: 0.4810 - val_accuracy: 0.8111\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2746 - accuracy: 0.8931 - val_loss: 0.3919 - val_accuracy: 0.8468\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2732 - accuracy: 0.8940 - val_loss: 0.5264 - val_accuracy: 0.7902\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.2712 - accuracy: 0.8946 - val_loss: 0.5263 - val_accuracy: 0.7928\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.2704 - accuracy: 0.8944 - val_loss: 0.3894 - val_accuracy: 0.8493\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.2704 - accuracy: 0.8953 - val_loss: 0.6152 - val_accuracy: 0.7468\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2693 - accuracy: 0.8952 - val_loss: 0.4788 - val_accuracy: 0.8107\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2687 - accuracy: 0.8958 - val_loss: 0.5139 - val_accuracy: 0.7939\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2669 - accuracy: 0.8961 - val_loss: 0.3734 - val_accuracy: 0.8547\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2671 - accuracy: 0.8961 - val_loss: 0.4006 - val_accuracy: 0.8428\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2640 - accuracy: 0.8962 - val_loss: 0.5539 - val_accuracy: 0.7741\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.6510 - accuracy: 0.6202 - val_loss: 0.6308 - val_accuracy: 0.6868\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.6023 - accuracy: 0.6883 - val_loss: 0.6150 - val_accuracy: 0.6809\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.5692 - accuracy: 0.7127 - val_loss: 0.6126 - val_accuracy: 0.6580\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.5446 - accuracy: 0.7289 - val_loss: 0.5541 - val_accuracy: 0.7190\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5280 - accuracy: 0.7382 - val_loss: 0.5733 - val_accuracy: 0.6900\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.5158 - accuracy: 0.7433 - val_loss: 0.6557 - val_accuracy: 0.6230\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.5042 - accuracy: 0.7505 - val_loss: 0.6015 - val_accuracy: 0.6645\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.4951 - accuracy: 0.7561 - val_loss: 0.5941 - val_accuracy: 0.6722\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.4832 - accuracy: 0.7622 - val_loss: 0.6129 - val_accuracy: 0.6581\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.4747 - accuracy: 0.7683 - val_loss: 0.6330 - val_accuracy: 0.6524\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.4640 - accuracy: 0.7775 - val_loss: 0.5778 - val_accuracy: 0.6942\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.4515 - accuracy: 0.7859 - val_loss: 0.5994 - val_accuracy: 0.6840\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.4396 - accuracy: 0.7949 - val_loss: 0.5604 - val_accuracy: 0.7186\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.4267 - accuracy: 0.8041 - val_loss: 0.5352 - val_accuracy: 0.7448\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.4123 - accuracy: 0.8136 - val_loss: 0.4996 - val_accuracy: 0.7776\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.3990 - accuracy: 0.8227 - val_loss: 0.5908 - val_accuracy: 0.7101\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3848 - accuracy: 0.8332 - val_loss: 0.4984 - val_accuracy: 0.7896\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.3704 - accuracy: 0.8426 - val_loss: 0.4710 - val_accuracy: 0.8101\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.3588 - accuracy: 0.8502 - val_loss: 0.5069 - val_accuracy: 0.7879\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.3460 - accuracy: 0.8589 - val_loss: 0.4319 - val_accuracy: 0.8362\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.3363 - accuracy: 0.8640 - val_loss: 0.4724 - val_accuracy: 0.8171\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.3279 - accuracy: 0.8677 - val_loss: 0.5549 - val_accuracy: 0.7690\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.3218 - accuracy: 0.8702 - val_loss: 0.5445 - val_accuracy: 0.7785\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.3148 - accuracy: 0.8754 - val_loss: 0.4327 - val_accuracy: 0.8366\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.3094 - accuracy: 0.8777 - val_loss: 0.5135 - val_accuracy: 0.7996\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.3047 - accuracy: 0.8797 - val_loss: 0.4735 - val_accuracy: 0.8204\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.3005 - accuracy: 0.8814 - val_loss: 0.4089 - val_accuracy: 0.8474\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2981 - accuracy: 0.8832 - val_loss: 0.4022 - val_accuracy: 0.8508\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2950 - accuracy: 0.8836 - val_loss: 0.4715 - val_accuracy: 0.8230\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2918 - accuracy: 0.8868 - val_loss: 0.4476 - val_accuracy: 0.8324\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2899 - accuracy: 0.8868 - val_loss: 0.4292 - val_accuracy: 0.8382\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2868 - accuracy: 0.8871 - val_loss: 0.4750 - val_accuracy: 0.8209\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.2856 - accuracy: 0.8890 - val_loss: 0.4395 - val_accuracy: 0.8347\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2822 - accuracy: 0.8885 - val_loss: 0.5713 - val_accuracy: 0.7801\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2797 - accuracy: 0.8910 - val_loss: 0.5452 - val_accuracy: 0.7892\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2793 - accuracy: 0.8905 - val_loss: 0.4375 - val_accuracy: 0.8364\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.2773 - accuracy: 0.8907 - val_loss: 0.4613 - val_accuracy: 0.8248\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.2764 - accuracy: 0.8914 - val_loss: 0.5754 - val_accuracy: 0.7749\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2766 - accuracy: 0.8930 - val_loss: 0.5227 - val_accuracy: 0.8033\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.2749 - accuracy: 0.8927 - val_loss: 0.4350 - val_accuracy: 0.8370\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2726 - accuracy: 0.8943 - val_loss: 0.4549 - val_accuracy: 0.8299\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.2705 - accuracy: 0.8953 - val_loss: 0.4985 - val_accuracy: 0.8102\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.2696 - accuracy: 0.8945 - val_loss: 0.5848 - val_accuracy: 0.7722\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.2694 - accuracy: 0.8953 - val_loss: 0.5372 - val_accuracy: 0.7956\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.2673 - accuracy: 0.8958 - val_loss: 0.4100 - val_accuracy: 0.8453\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2662 - accuracy: 0.8964 - val_loss: 0.5072 - val_accuracy: 0.8079\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.2664 - accuracy: 0.8969 - val_loss: 0.4771 - val_accuracy: 0.8188\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.2655 - accuracy: 0.8973 - val_loss: 0.5193 - val_accuracy: 0.8036\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2641 - accuracy: 0.8971 - val_loss: 0.4742 - val_accuracy: 0.8189\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.2632 - accuracy: 0.8982 - val_loss: 0.5560 - val_accuracy: 0.7836\n",
      "\n",
      "Training model with noise_multiplier=2.0...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 2.0 iterated over 167200 steps satisfies differential privacy with eps = 0.32 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.6748 - accuracy: 0.5903 - val_loss: 0.6645 - val_accuracy: 0.6281\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.6304 - accuracy: 0.6767 - val_loss: 0.6412 - val_accuracy: 0.6423\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5905 - accuracy: 0.7058 - val_loss: 0.5955 - val_accuracy: 0.6763\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.5606 - accuracy: 0.7221 - val_loss: 0.5841 - val_accuracy: 0.6892\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5373 - accuracy: 0.7358 - val_loss: 0.5697 - val_accuracy: 0.6936\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.5202 - accuracy: 0.7451 - val_loss: 0.5621 - val_accuracy: 0.6967\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5060 - accuracy: 0.7524 - val_loss: 0.5965 - val_accuracy: 0.6765\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.4926 - accuracy: 0.7583 - val_loss: 0.5717 - val_accuracy: 0.6903\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.4783 - accuracy: 0.7689 - val_loss: 0.5760 - val_accuracy: 0.6890\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.4656 - accuracy: 0.7756 - val_loss: 0.5697 - val_accuracy: 0.6962\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.4502 - accuracy: 0.7886 - val_loss: 0.6198 - val_accuracy: 0.6629\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.4350 - accuracy: 0.7989 - val_loss: 0.5473 - val_accuracy: 0.7251\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.4188 - accuracy: 0.8111 - val_loss: 0.5110 - val_accuracy: 0.7595\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.4023 - accuracy: 0.8226 - val_loss: 0.5112 - val_accuracy: 0.7628\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.3861 - accuracy: 0.8340 - val_loss: 0.5805 - val_accuracy: 0.7168\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.3721 - accuracy: 0.8437 - val_loss: 0.5425 - val_accuracy: 0.7501\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.3585 - accuracy: 0.8514 - val_loss: 0.5435 - val_accuracy: 0.7563\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.3444 - accuracy: 0.8605 - val_loss: 0.4751 - val_accuracy: 0.8063\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.3352 - accuracy: 0.8659 - val_loss: 0.4341 - val_accuracy: 0.8289\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.3252 - accuracy: 0.8713 - val_loss: 0.5204 - val_accuracy: 0.7858\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.3169 - accuracy: 0.8759 - val_loss: 0.5090 - val_accuracy: 0.7958\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.3123 - accuracy: 0.8768 - val_loss: 0.4457 - val_accuracy: 0.8251\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 651us/step - loss: 0.3055 - accuracy: 0.8802 - val_loss: 0.6055 - val_accuracy: 0.7429\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.3022 - accuracy: 0.8813 - val_loss: 0.4886 - val_accuracy: 0.8082\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.2974 - accuracy: 0.8833 - val_loss: 0.5129 - val_accuracy: 0.7974\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.2937 - accuracy: 0.8852 - val_loss: 0.4641 - val_accuracy: 0.8205\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.2916 - accuracy: 0.8866 - val_loss: 0.4165 - val_accuracy: 0.8410\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.2879 - accuracy: 0.8879 - val_loss: 0.5352 - val_accuracy: 0.7908\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.2870 - accuracy: 0.8878 - val_loss: 0.5776 - val_accuracy: 0.7703\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.2845 - accuracy: 0.8898 - val_loss: 0.4945 - val_accuracy: 0.8092\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.2837 - accuracy: 0.8903 - val_loss: 0.4662 - val_accuracy: 0.8215\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2810 - accuracy: 0.8897 - val_loss: 0.5351 - val_accuracy: 0.7891\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.2796 - accuracy: 0.8907 - val_loss: 0.4496 - val_accuracy: 0.8265\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.2783 - accuracy: 0.8917 - val_loss: 0.4675 - val_accuracy: 0.8199\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.2773 - accuracy: 0.8911 - val_loss: 0.3848 - val_accuracy: 0.8516\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.2767 - accuracy: 0.8924 - val_loss: 0.4852 - val_accuracy: 0.8127\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.2752 - accuracy: 0.8923 - val_loss: 0.4596 - val_accuracy: 0.8226\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.2730 - accuracy: 0.8941 - val_loss: 0.6215 - val_accuracy: 0.7481\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2723 - accuracy: 0.8937 - val_loss: 0.4345 - val_accuracy: 0.8326\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2711 - accuracy: 0.8944 - val_loss: 0.5013 - val_accuracy: 0.8037\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2698 - accuracy: 0.8953 - val_loss: 0.4188 - val_accuracy: 0.8397\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2689 - accuracy: 0.8948 - val_loss: 0.3997 - val_accuracy: 0.8471\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2692 - accuracy: 0.8953 - val_loss: 0.4327 - val_accuracy: 0.8335\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2672 - accuracy: 0.8976 - val_loss: 0.3776 - val_accuracy: 0.8548\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.2659 - accuracy: 0.8966 - val_loss: 0.5773 - val_accuracy: 0.7710\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2654 - accuracy: 0.8968 - val_loss: 0.4022 - val_accuracy: 0.8457\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.2637 - accuracy: 0.8979 - val_loss: 0.4645 - val_accuracy: 0.8196\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2632 - accuracy: 0.8982 - val_loss: 0.4326 - val_accuracy: 0.8306\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2615 - accuracy: 0.8982 - val_loss: 0.4999 - val_accuracy: 0.8053\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.2616 - accuracy: 0.8986 - val_loss: 0.4240 - val_accuracy: 0.8356\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.6480 - accuracy: 0.6331 - val_loss: 0.6493 - val_accuracy: 0.6168\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.5925 - accuracy: 0.6934 - val_loss: 0.6224 - val_accuracy: 0.6396\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.5582 - accuracy: 0.7172 - val_loss: 0.5987 - val_accuracy: 0.6570\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.5370 - accuracy: 0.7315 - val_loss: 0.6196 - val_accuracy: 0.6416\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.5229 - accuracy: 0.7393 - val_loss: 0.6146 - val_accuracy: 0.6482\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.5107 - accuracy: 0.7445 - val_loss: 0.5941 - val_accuracy: 0.6632\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.5002 - accuracy: 0.7522 - val_loss: 0.5705 - val_accuracy: 0.6834\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.4893 - accuracy: 0.7587 - val_loss: 0.6076 - val_accuracy: 0.6596\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.4779 - accuracy: 0.7663 - val_loss: 0.6400 - val_accuracy: 0.6405\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.4655 - accuracy: 0.7767 - val_loss: 0.6032 - val_accuracy: 0.6711\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.4523 - accuracy: 0.7842 - val_loss: 0.5322 - val_accuracy: 0.7289\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5803 - val_accuracy: 0.6940\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.4237 - accuracy: 0.8068 - val_loss: 0.5006 - val_accuracy: 0.7646\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.4101 - accuracy: 0.8170 - val_loss: 0.4838 - val_accuracy: 0.7858\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.3943 - accuracy: 0.8259 - val_loss: 0.5005 - val_accuracy: 0.7702\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.3790 - accuracy: 0.8366 - val_loss: 0.5754 - val_accuracy: 0.7216\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.3655 - accuracy: 0.8449 - val_loss: 0.5074 - val_accuracy: 0.7756\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.3531 - accuracy: 0.8540 - val_loss: 0.5422 - val_accuracy: 0.7556\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.3430 - accuracy: 0.8605 - val_loss: 0.5493 - val_accuracy: 0.7576\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.3322 - accuracy: 0.8648 - val_loss: 0.4194 - val_accuracy: 0.8393\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.3245 - accuracy: 0.8697 - val_loss: 0.5852 - val_accuracy: 0.7373\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.3191 - accuracy: 0.8712 - val_loss: 0.4937 - val_accuracy: 0.8026\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.3140 - accuracy: 0.8749 - val_loss: 0.4977 - val_accuracy: 0.8011\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.3072 - accuracy: 0.8785 - val_loss: 0.3995 - val_accuracy: 0.8474\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.3048 - accuracy: 0.8797 - val_loss: 0.4641 - val_accuracy: 0.8207\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.3014 - accuracy: 0.8806 - val_loss: 0.4873 - val_accuracy: 0.8102\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.2987 - accuracy: 0.8817 - val_loss: 0.4633 - val_accuracy: 0.8226\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2952 - accuracy: 0.8834 - val_loss: 0.4601 - val_accuracy: 0.8244\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2940 - accuracy: 0.8844 - val_loss: 0.4551 - val_accuracy: 0.8261\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2908 - accuracy: 0.8854 - val_loss: 0.4403 - val_accuracy: 0.8319\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2904 - accuracy: 0.8856 - val_loss: 0.5708 - val_accuracy: 0.7703\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2883 - accuracy: 0.8858 - val_loss: 0.4786 - val_accuracy: 0.8154\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.2857 - accuracy: 0.8873 - val_loss: 0.4045 - val_accuracy: 0.8447\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2857 - accuracy: 0.8877 - val_loss: 0.5134 - val_accuracy: 0.8034\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2837 - accuracy: 0.8885 - val_loss: 0.4460 - val_accuracy: 0.8313\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2819 - accuracy: 0.8886 - val_loss: 0.4475 - val_accuracy: 0.8291\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.2811 - accuracy: 0.8905 - val_loss: 0.4210 - val_accuracy: 0.8382\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2800 - accuracy: 0.8901 - val_loss: 0.3907 - val_accuracy: 0.8516\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2785 - accuracy: 0.8899 - val_loss: 0.4627 - val_accuracy: 0.8224\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.2783 - accuracy: 0.8922 - val_loss: 0.4051 - val_accuracy: 0.8437\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2768 - accuracy: 0.8907 - val_loss: 0.4077 - val_accuracy: 0.8421\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.2757 - accuracy: 0.8927 - val_loss: 0.4045 - val_accuracy: 0.8442\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.2753 - accuracy: 0.8919 - val_loss: 0.4798 - val_accuracy: 0.8116\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.2746 - accuracy: 0.8921 - val_loss: 0.5111 - val_accuracy: 0.8026\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.2737 - accuracy: 0.8940 - val_loss: 0.4217 - val_accuracy: 0.8355\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2728 - accuracy: 0.8933 - val_loss: 0.5339 - val_accuracy: 0.7902\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.2708 - accuracy: 0.8942 - val_loss: 0.5595 - val_accuracy: 0.7733\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2700 - accuracy: 0.8954 - val_loss: 0.5741 - val_accuracy: 0.7710\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.2704 - accuracy: 0.8950 - val_loss: 0.3531 - val_accuracy: 0.8614\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.2676 - accuracy: 0.8963 - val_loss: 0.4166 - val_accuracy: 0.8385\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.6574 - accuracy: 0.6171 - val_loss: 0.6470 - val_accuracy: 0.5983\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5928 - accuracy: 0.6985 - val_loss: 0.6191 - val_accuracy: 0.6298\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.5626 - accuracy: 0.7158 - val_loss: 0.6205 - val_accuracy: 0.6276\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.5445 - accuracy: 0.7266 - val_loss: 0.5949 - val_accuracy: 0.6517\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.5297 - accuracy: 0.7344 - val_loss: 0.6014 - val_accuracy: 0.6486\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.5194 - accuracy: 0.7390 - val_loss: 0.6010 - val_accuracy: 0.6530\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.5096 - accuracy: 0.7443 - val_loss: 0.5799 - val_accuracy: 0.6713\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.5017 - accuracy: 0.7499 - val_loss: 0.5415 - val_accuracy: 0.7136\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.4913 - accuracy: 0.7584 - val_loss: 0.5393 - val_accuracy: 0.7211\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.4806 - accuracy: 0.7660 - val_loss: 0.5889 - val_accuracy: 0.6793\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.4693 - accuracy: 0.7727 - val_loss: 0.5239 - val_accuracy: 0.7388\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.4584 - accuracy: 0.7813 - val_loss: 0.5432 - val_accuracy: 0.7225\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.4449 - accuracy: 0.7922 - val_loss: 0.5746 - val_accuracy: 0.7013\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.4305 - accuracy: 0.8010 - val_loss: 0.6068 - val_accuracy: 0.6817\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.4166 - accuracy: 0.8131 - val_loss: 0.5264 - val_accuracy: 0.7462\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.4016 - accuracy: 0.8236 - val_loss: 0.5943 - val_accuracy: 0.7004\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.3859 - accuracy: 0.8349 - val_loss: 0.6001 - val_accuracy: 0.7010\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.3720 - accuracy: 0.8425 - val_loss: 0.5057 - val_accuracy: 0.7723\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.3599 - accuracy: 0.8506 - val_loss: 0.5494 - val_accuracy: 0.7490\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.3486 - accuracy: 0.8579 - val_loss: 0.4379 - val_accuracy: 0.8291\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.3382 - accuracy: 0.8636 - val_loss: 0.5039 - val_accuracy: 0.7885\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.3303 - accuracy: 0.8670 - val_loss: 0.4758 - val_accuracy: 0.8136\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.3223 - accuracy: 0.8722 - val_loss: 0.5235 - val_accuracy: 0.7849\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.3164 - accuracy: 0.8743 - val_loss: 0.5006 - val_accuracy: 0.8032\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.3121 - accuracy: 0.8777 - val_loss: 0.5017 - val_accuracy: 0.8060\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.3072 - accuracy: 0.8780 - val_loss: 0.4600 - val_accuracy: 0.8264\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.3036 - accuracy: 0.8807 - val_loss: 0.4543 - val_accuracy: 0.8291\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.3016 - accuracy: 0.8810 - val_loss: 0.4763 - val_accuracy: 0.8210\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.2982 - accuracy: 0.8830 - val_loss: 0.4482 - val_accuracy: 0.8327\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.2965 - accuracy: 0.8837 - val_loss: 0.4823 - val_accuracy: 0.8178\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.2919 - accuracy: 0.8868 - val_loss: 0.4639 - val_accuracy: 0.8257\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.2918 - accuracy: 0.8858 - val_loss: 0.3503 - val_accuracy: 0.8701\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.2900 - accuracy: 0.8864 - val_loss: 0.5315 - val_accuracy: 0.7955\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.2887 - accuracy: 0.8873 - val_loss: 0.4158 - val_accuracy: 0.8423\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.2859 - accuracy: 0.8898 - val_loss: 0.4436 - val_accuracy: 0.8329\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.2855 - accuracy: 0.8885 - val_loss: 0.4734 - val_accuracy: 0.8223\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.2842 - accuracy: 0.8891 - val_loss: 0.6378 - val_accuracy: 0.7388\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.2828 - accuracy: 0.8905 - val_loss: 0.4583 - val_accuracy: 0.8249\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2816 - accuracy: 0.8904 - val_loss: 0.6093 - val_accuracy: 0.7522\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.2813 - accuracy: 0.8892 - val_loss: 0.4498 - val_accuracy: 0.8305\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.2809 - accuracy: 0.8901 - val_loss: 0.4723 - val_accuracy: 0.8199\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.2784 - accuracy: 0.8915 - val_loss: 0.4809 - val_accuracy: 0.8144\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2778 - accuracy: 0.8919 - val_loss: 0.4641 - val_accuracy: 0.8242\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2757 - accuracy: 0.8929 - val_loss: 0.4049 - val_accuracy: 0.8454\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2750 - accuracy: 0.8925 - val_loss: 0.4921 - val_accuracy: 0.8107\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2743 - accuracy: 0.8934 - val_loss: 0.5716 - val_accuracy: 0.7740\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2744 - accuracy: 0.8936 - val_loss: 0.4384 - val_accuracy: 0.8329\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2714 - accuracy: 0.8941 - val_loss: 0.4740 - val_accuracy: 0.8170\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2708 - accuracy: 0.8942 - val_loss: 0.4457 - val_accuracy: 0.8289\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2711 - accuracy: 0.8942 - val_loss: 0.4477 - val_accuracy: 0.8267\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.6460 - accuracy: 0.6199 - val_loss: 0.6452 - val_accuracy: 0.6180\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5908 - accuracy: 0.6881 - val_loss: 0.5988 - val_accuracy: 0.6628\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.5592 - accuracy: 0.7141 - val_loss: 0.6148 - val_accuracy: 0.6414\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5396 - accuracy: 0.7267 - val_loss: 0.5887 - val_accuracy: 0.6694\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.5244 - accuracy: 0.7342 - val_loss: 0.6191 - val_accuracy: 0.6477\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5120 - accuracy: 0.7424 - val_loss: 0.5934 - val_accuracy: 0.6718\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.5001 - accuracy: 0.7513 - val_loss: 0.6384 - val_accuracy: 0.6423\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.4888 - accuracy: 0.7598 - val_loss: 0.5996 - val_accuracy: 0.6736\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.4776 - accuracy: 0.7677 - val_loss: 0.6412 - val_accuracy: 0.6483\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.4654 - accuracy: 0.7780 - val_loss: 0.5637 - val_accuracy: 0.7104\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.4518 - accuracy: 0.7873 - val_loss: 0.5941 - val_accuracy: 0.6916\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.4373 - accuracy: 0.7975 - val_loss: 0.5779 - val_accuracy: 0.7097\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.4240 - accuracy: 0.8080 - val_loss: 0.5554 - val_accuracy: 0.7350\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.4086 - accuracy: 0.8201 - val_loss: 0.6309 - val_accuracy: 0.6858\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.3937 - accuracy: 0.8292 - val_loss: 0.5289 - val_accuracy: 0.7697\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.3778 - accuracy: 0.8390 - val_loss: 0.5930 - val_accuracy: 0.7223\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.3650 - accuracy: 0.8488 - val_loss: 0.5581 - val_accuracy: 0.7549\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.3515 - accuracy: 0.8560 - val_loss: 0.4434 - val_accuracy: 0.8297\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.3416 - accuracy: 0.8602 - val_loss: 0.5816 - val_accuracy: 0.7485\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.3317 - accuracy: 0.8672 - val_loss: 0.5998 - val_accuracy: 0.7423\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.3232 - accuracy: 0.8725 - val_loss: 0.4344 - val_accuracy: 0.8363\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3163 - accuracy: 0.8751 - val_loss: 0.4638 - val_accuracy: 0.8264\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.3097 - accuracy: 0.8775 - val_loss: 0.4600 - val_accuracy: 0.8293\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.3065 - accuracy: 0.8786 - val_loss: 0.5504 - val_accuracy: 0.7847\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3025 - accuracy: 0.8806 - val_loss: 0.4261 - val_accuracy: 0.8410\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.2988 - accuracy: 0.8829 - val_loss: 0.4435 - val_accuracy: 0.8355\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2957 - accuracy: 0.8839 - val_loss: 0.4505 - val_accuracy: 0.8337\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.2924 - accuracy: 0.8860 - val_loss: 0.5244 - val_accuracy: 0.8048\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2908 - accuracy: 0.8861 - val_loss: 0.4534 - val_accuracy: 0.8330\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2878 - accuracy: 0.8877 - val_loss: 0.5222 - val_accuracy: 0.8049\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.2859 - accuracy: 0.8888 - val_loss: 0.5691 - val_accuracy: 0.7801\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2855 - accuracy: 0.8890 - val_loss: 0.4404 - val_accuracy: 0.8371\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.2830 - accuracy: 0.8910 - val_loss: 0.5278 - val_accuracy: 0.8031\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2811 - accuracy: 0.8908 - val_loss: 0.4474 - val_accuracy: 0.8321\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2814 - accuracy: 0.8903 - val_loss: 0.5607 - val_accuracy: 0.7873\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2801 - accuracy: 0.8909 - val_loss: 0.5067 - val_accuracy: 0.8111\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2761 - accuracy: 0.8918 - val_loss: 0.5570 - val_accuracy: 0.7873\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2767 - accuracy: 0.8931 - val_loss: 0.4563 - val_accuracy: 0.8304\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2749 - accuracy: 0.8923 - val_loss: 0.4421 - val_accuracy: 0.8343\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.2730 - accuracy: 0.8946 - val_loss: 0.6564 - val_accuracy: 0.7387\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2728 - accuracy: 0.8938 - val_loss: 0.4397 - val_accuracy: 0.8352\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2714 - accuracy: 0.8946 - val_loss: 0.4711 - val_accuracy: 0.8211\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.2712 - accuracy: 0.8950 - val_loss: 0.5110 - val_accuracy: 0.8059\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2700 - accuracy: 0.8949 - val_loss: 0.5007 - val_accuracy: 0.8095\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2680 - accuracy: 0.8963 - val_loss: 0.4979 - val_accuracy: 0.8120\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.2666 - accuracy: 0.8971 - val_loss: 0.4369 - val_accuracy: 0.8342\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2672 - accuracy: 0.8971 - val_loss: 0.5282 - val_accuracy: 0.7977\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.2669 - accuracy: 0.8967 - val_loss: 0.4621 - val_accuracy: 0.8263\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2657 - accuracy: 0.8969 - val_loss: 0.4876 - val_accuracy: 0.8149\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2658 - accuracy: 0.8970 - val_loss: 0.4972 - val_accuracy: 0.8107\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.6480 - accuracy: 0.6253 - val_loss: 0.6360 - val_accuracy: 0.6350\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5891 - accuracy: 0.6928 - val_loss: 0.6130 - val_accuracy: 0.6516\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.5597 - accuracy: 0.7162 - val_loss: 0.6311 - val_accuracy: 0.6270\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 650us/step - loss: 0.5381 - accuracy: 0.7322 - val_loss: 0.5727 - val_accuracy: 0.6838\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.5207 - accuracy: 0.7420 - val_loss: 0.5775 - val_accuracy: 0.6814\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5068 - accuracy: 0.7511 - val_loss: 0.5812 - val_accuracy: 0.6801\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.4935 - accuracy: 0.7600 - val_loss: 0.5702 - val_accuracy: 0.6878\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.4779 - accuracy: 0.7700 - val_loss: 0.5996 - val_accuracy: 0.6696\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.4648 - accuracy: 0.7780 - val_loss: 0.5964 - val_accuracy: 0.6780\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.4457 - accuracy: 0.7927 - val_loss: 0.5312 - val_accuracy: 0.7342\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.4288 - accuracy: 0.8053 - val_loss: 0.5483 - val_accuracy: 0.7224\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.4126 - accuracy: 0.8155 - val_loss: 0.5667 - val_accuracy: 0.7114\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.3942 - accuracy: 0.8267 - val_loss: 0.5612 - val_accuracy: 0.7258\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.3795 - accuracy: 0.8372 - val_loss: 0.5999 - val_accuracy: 0.7034\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.3634 - accuracy: 0.8495 - val_loss: 0.4641 - val_accuracy: 0.8141\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.3491 - accuracy: 0.8573 - val_loss: 0.4640 - val_accuracy: 0.8164\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.3396 - accuracy: 0.8625 - val_loss: 0.4186 - val_accuracy: 0.8382\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.3284 - accuracy: 0.8687 - val_loss: 0.6138 - val_accuracy: 0.7242\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.3208 - accuracy: 0.8726 - val_loss: 0.4665 - val_accuracy: 0.8189\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.3125 - accuracy: 0.8775 - val_loss: 0.5686 - val_accuracy: 0.7645\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.3070 - accuracy: 0.8797 - val_loss: 0.4907 - val_accuracy: 0.8101\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.3039 - accuracy: 0.8801 - val_loss: 0.5344 - val_accuracy: 0.7901\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.2985 - accuracy: 0.8839 - val_loss: 0.4305 - val_accuracy: 0.8347\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.2942 - accuracy: 0.8853 - val_loss: 0.5068 - val_accuracy: 0.8047\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.2917 - accuracy: 0.8863 - val_loss: 0.6271 - val_accuracy: 0.7404\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.2910 - accuracy: 0.8860 - val_loss: 0.4124 - val_accuracy: 0.8451\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.2854 - accuracy: 0.8887 - val_loss: 0.5519 - val_accuracy: 0.7868\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.2850 - accuracy: 0.8888 - val_loss: 0.6758 - val_accuracy: 0.7203\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.2833 - accuracy: 0.8894 - val_loss: 0.4313 - val_accuracy: 0.8348\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.2803 - accuracy: 0.8912 - val_loss: 0.4048 - val_accuracy: 0.8452\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.2793 - accuracy: 0.8914 - val_loss: 0.4963 - val_accuracy: 0.8115\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.2773 - accuracy: 0.8918 - val_loss: 0.4481 - val_accuracy: 0.8269\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.2774 - accuracy: 0.8911 - val_loss: 0.4821 - val_accuracy: 0.8167\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.2738 - accuracy: 0.8938 - val_loss: 0.6594 - val_accuracy: 0.7322\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.2725 - accuracy: 0.8947 - val_loss: 0.6321 - val_accuracy: 0.7498\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.2733 - accuracy: 0.8936 - val_loss: 0.3968 - val_accuracy: 0.8477\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 639us/step - loss: 0.2702 - accuracy: 0.8966 - val_loss: 0.4456 - val_accuracy: 0.8293\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.2703 - accuracy: 0.8954 - val_loss: 0.4671 - val_accuracy: 0.8212\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.2694 - accuracy: 0.8956 - val_loss: 0.5177 - val_accuracy: 0.8018\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.2671 - accuracy: 0.8969 - val_loss: 0.5400 - val_accuracy: 0.7899\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.2670 - accuracy: 0.8974 - val_loss: 0.5528 - val_accuracy: 0.7809\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.2659 - accuracy: 0.8989 - val_loss: 0.4255 - val_accuracy: 0.8372\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.2645 - accuracy: 0.8971 - val_loss: 0.4996 - val_accuracy: 0.8082\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.2649 - accuracy: 0.8980 - val_loss: 0.4717 - val_accuracy: 0.8181\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.2638 - accuracy: 0.8980 - val_loss: 0.5020 - val_accuracy: 0.8087\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.2626 - accuracy: 0.8986 - val_loss: 0.4610 - val_accuracy: 0.8191\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2621 - accuracy: 0.8979 - val_loss: 0.5954 - val_accuracy: 0.7645\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.2603 - accuracy: 0.8990 - val_loss: 0.4476 - val_accuracy: 0.8255\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2607 - accuracy: 0.8992 - val_loss: 0.4247 - val_accuracy: 0.8357\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.2600 - accuracy: 0.9003 - val_loss: 0.4662 - val_accuracy: 0.8189\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.6627 - accuracy: 0.6184 - val_loss: 0.6524 - val_accuracy: 0.6197\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.6096 - accuracy: 0.6890 - val_loss: 0.6053 - val_accuracy: 0.6632\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.5717 - accuracy: 0.7141 - val_loss: 0.6195 - val_accuracy: 0.6248\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5480 - accuracy: 0.7289 - val_loss: 0.5604 - val_accuracy: 0.6980\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.5294 - accuracy: 0.7385 - val_loss: 0.6373 - val_accuracy: 0.6262\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.5146 - accuracy: 0.7469 - val_loss: 0.5583 - val_accuracy: 0.6942\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.5008 - accuracy: 0.7552 - val_loss: 0.5687 - val_accuracy: 0.6882\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.4885 - accuracy: 0.7620 - val_loss: 0.6333 - val_accuracy: 0.6373\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.4747 - accuracy: 0.7719 - val_loss: 0.5946 - val_accuracy: 0.6722\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.4601 - accuracy: 0.7817 - val_loss: 0.5877 - val_accuracy: 0.6837\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.4450 - accuracy: 0.7927 - val_loss: 0.5422 - val_accuracy: 0.7222\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.4284 - accuracy: 0.8050 - val_loss: 0.5285 - val_accuracy: 0.7387\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.4123 - accuracy: 0.8155 - val_loss: 0.5985 - val_accuracy: 0.6903\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.3958 - accuracy: 0.8265 - val_loss: 0.5472 - val_accuracy: 0.7342\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.3795 - accuracy: 0.8395 - val_loss: 0.5082 - val_accuracy: 0.7690\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.3642 - accuracy: 0.8482 - val_loss: 0.4945 - val_accuracy: 0.7840\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.3523 - accuracy: 0.8565 - val_loss: 0.5019 - val_accuracy: 0.7795\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.3409 - accuracy: 0.8628 - val_loss: 0.5501 - val_accuracy: 0.7521\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.3293 - accuracy: 0.8680 - val_loss: 0.5870 - val_accuracy: 0.7304\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.3209 - accuracy: 0.8704 - val_loss: 0.4240 - val_accuracy: 0.8347\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.3131 - accuracy: 0.8756 - val_loss: 0.3960 - val_accuracy: 0.8484\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.3066 - accuracy: 0.8790 - val_loss: 0.4166 - val_accuracy: 0.8377\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.3024 - accuracy: 0.8814 - val_loss: 0.4506 - val_accuracy: 0.8249\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2976 - accuracy: 0.8814 - val_loss: 0.3720 - val_accuracy: 0.8585\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2949 - accuracy: 0.8840 - val_loss: 0.5661 - val_accuracy: 0.7667\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2914 - accuracy: 0.8854 - val_loss: 0.4564 - val_accuracy: 0.8234\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2894 - accuracy: 0.8860 - val_loss: 0.4406 - val_accuracy: 0.8299\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.2860 - accuracy: 0.8874 - val_loss: 0.6165 - val_accuracy: 0.7457\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.2851 - accuracy: 0.8884 - val_loss: 0.4895 - val_accuracy: 0.8097\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2823 - accuracy: 0.8899 - val_loss: 0.4805 - val_accuracy: 0.8142\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2803 - accuracy: 0.8913 - val_loss: 0.4535 - val_accuracy: 0.8244\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2782 - accuracy: 0.8909 - val_loss: 0.4285 - val_accuracy: 0.8361\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2775 - accuracy: 0.8919 - val_loss: 0.6293 - val_accuracy: 0.7469\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2760 - accuracy: 0.8915 - val_loss: 0.5767 - val_accuracy: 0.7655\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.2749 - accuracy: 0.8914 - val_loss: 0.4132 - val_accuracy: 0.8384\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2733 - accuracy: 0.8920 - val_loss: 0.4489 - val_accuracy: 0.8275\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2731 - accuracy: 0.8927 - val_loss: 0.4716 - val_accuracy: 0.8192\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2715 - accuracy: 0.8937 - val_loss: 0.4916 - val_accuracy: 0.8086\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2707 - accuracy: 0.8943 - val_loss: 0.4890 - val_accuracy: 0.8102\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2694 - accuracy: 0.8952 - val_loss: 0.5660 - val_accuracy: 0.7711\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.2694 - accuracy: 0.8948 - val_loss: 0.4499 - val_accuracy: 0.8248\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2683 - accuracy: 0.8951 - val_loss: 0.5421 - val_accuracy: 0.7803\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2671 - accuracy: 0.8962 - val_loss: 0.4007 - val_accuracy: 0.8442\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.2656 - accuracy: 0.8966 - val_loss: 0.4303 - val_accuracy: 0.8350\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2657 - accuracy: 0.8965 - val_loss: 0.4461 - val_accuracy: 0.8275\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2636 - accuracy: 0.8977 - val_loss: 0.4364 - val_accuracy: 0.8320\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.2632 - accuracy: 0.8964 - val_loss: 0.4787 - val_accuracy: 0.8167\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2633 - accuracy: 0.8981 - val_loss: 0.4863 - val_accuracy: 0.8095\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.2616 - accuracy: 0.8978 - val_loss: 0.5666 - val_accuracy: 0.7783\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.2609 - accuracy: 0.8981 - val_loss: 0.4410 - val_accuracy: 0.8268\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.6596 - accuracy: 0.6079 - val_loss: 0.6245 - val_accuracy: 0.6577\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5910 - accuracy: 0.6911 - val_loss: 0.5922 - val_accuracy: 0.6812\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5619 - accuracy: 0.7133 - val_loss: 0.5827 - val_accuracy: 0.6786\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5396 - accuracy: 0.7265 - val_loss: 0.6247 - val_accuracy: 0.6486\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5240 - accuracy: 0.7363 - val_loss: 0.5741 - val_accuracy: 0.6826\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5113 - accuracy: 0.7454 - val_loss: 0.5567 - val_accuracy: 0.6959\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.4988 - accuracy: 0.7525 - val_loss: 0.5358 - val_accuracy: 0.7185\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.4885 - accuracy: 0.7604 - val_loss: 0.5528 - val_accuracy: 0.7046\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 690us/step - loss: 0.4758 - accuracy: 0.7689 - val_loss: 0.5988 - val_accuracy: 0.6720\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.4617 - accuracy: 0.7789 - val_loss: 0.6388 - val_accuracy: 0.6467\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.4483 - accuracy: 0.7887 - val_loss: 0.6006 - val_accuracy: 0.6738\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.4326 - accuracy: 0.7997 - val_loss: 0.5104 - val_accuracy: 0.7557\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.4179 - accuracy: 0.8115 - val_loss: 0.4746 - val_accuracy: 0.7919\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.4018 - accuracy: 0.8227 - val_loss: 0.5142 - val_accuracy: 0.7625\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.3864 - accuracy: 0.8324 - val_loss: 0.4797 - val_accuracy: 0.7925\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.3709 - accuracy: 0.8423 - val_loss: 0.5355 - val_accuracy: 0.7525\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.3597 - accuracy: 0.8489 - val_loss: 0.5168 - val_accuracy: 0.7720\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.3472 - accuracy: 0.8571 - val_loss: 0.6060 - val_accuracy: 0.7104\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.3377 - accuracy: 0.8620 - val_loss: 0.5021 - val_accuracy: 0.7906\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.3298 - accuracy: 0.8660 - val_loss: 0.4629 - val_accuracy: 0.8193\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.3230 - accuracy: 0.8699 - val_loss: 0.5081 - val_accuracy: 0.7944\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.3166 - accuracy: 0.8740 - val_loss: 0.5386 - val_accuracy: 0.7771\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.3100 - accuracy: 0.8772 - val_loss: 0.4855 - val_accuracy: 0.8115\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.3060 - accuracy: 0.8786 - val_loss: 0.4386 - val_accuracy: 0.8311\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.3033 - accuracy: 0.8801 - val_loss: 0.5299 - val_accuracy: 0.7851\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.2993 - accuracy: 0.8804 - val_loss: 0.5222 - val_accuracy: 0.7916\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.2962 - accuracy: 0.8830 - val_loss: 0.4298 - val_accuracy: 0.8343\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.2934 - accuracy: 0.8831 - val_loss: 0.4668 - val_accuracy: 0.8202\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.2921 - accuracy: 0.8843 - val_loss: 0.4654 - val_accuracy: 0.8216\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.2899 - accuracy: 0.8862 - val_loss: 0.4591 - val_accuracy: 0.8258\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.2886 - accuracy: 0.8866 - val_loss: 0.4215 - val_accuracy: 0.8377\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.2852 - accuracy: 0.8872 - val_loss: 0.4345 - val_accuracy: 0.8310\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.2847 - accuracy: 0.8885 - val_loss: 0.4760 - val_accuracy: 0.8172\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.2842 - accuracy: 0.8871 - val_loss: 0.4564 - val_accuracy: 0.8240\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.2811 - accuracy: 0.8899 - val_loss: 0.4089 - val_accuracy: 0.8416\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.2810 - accuracy: 0.8899 - val_loss: 0.4953 - val_accuracy: 0.8049\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.2791 - accuracy: 0.8903 - val_loss: 0.4210 - val_accuracy: 0.8367\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.2779 - accuracy: 0.8906 - val_loss: 0.4744 - val_accuracy: 0.8160\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.2771 - accuracy: 0.8911 - val_loss: 0.4537 - val_accuracy: 0.8244\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.2765 - accuracy: 0.8912 - val_loss: 0.4940 - val_accuracy: 0.8081\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.2748 - accuracy: 0.8920 - val_loss: 0.4490 - val_accuracy: 0.8231\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.2730 - accuracy: 0.8926 - val_loss: 0.4967 - val_accuracy: 0.8045\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.2725 - accuracy: 0.8928 - val_loss: 0.4130 - val_accuracy: 0.8389\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.2723 - accuracy: 0.8938 - val_loss: 0.4450 - val_accuracy: 0.8254\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.2713 - accuracy: 0.8942 - val_loss: 0.4456 - val_accuracy: 0.8247\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.2712 - accuracy: 0.8937 - val_loss: 0.5152 - val_accuracy: 0.7934\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.2696 - accuracy: 0.8944 - val_loss: 0.5582 - val_accuracy: 0.7756\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.2694 - accuracy: 0.8938 - val_loss: 0.5098 - val_accuracy: 0.7972\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.2688 - accuracy: 0.8949 - val_loss: 0.4660 - val_accuracy: 0.8174\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.2676 - accuracy: 0.8949 - val_loss: 0.5069 - val_accuracy: 0.7976\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.6669 - accuracy: 0.6006 - val_loss: 0.6602 - val_accuracy: 0.5971\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.6202 - accuracy: 0.6785 - val_loss: 0.6126 - val_accuracy: 0.6544\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5854 - accuracy: 0.7037 - val_loss: 0.6141 - val_accuracy: 0.6451\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.5598 - accuracy: 0.7197 - val_loss: 0.6329 - val_accuracy: 0.6307\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.5389 - accuracy: 0.7299 - val_loss: 0.5837 - val_accuracy: 0.6726\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5237 - accuracy: 0.7406 - val_loss: 0.5618 - val_accuracy: 0.6894\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5098 - accuracy: 0.7472 - val_loss: 0.6004 - val_accuracy: 0.6664\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.4988 - accuracy: 0.7548 - val_loss: 0.5190 - val_accuracy: 0.7411\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.4866 - accuracy: 0.7630 - val_loss: 0.5635 - val_accuracy: 0.6988\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.4736 - accuracy: 0.7713 - val_loss: 0.5592 - val_accuracy: 0.7053\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.4608 - accuracy: 0.7796 - val_loss: 0.6043 - val_accuracy: 0.6704\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.4460 - accuracy: 0.7902 - val_loss: 0.5530 - val_accuracy: 0.7211\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.4308 - accuracy: 0.8018 - val_loss: 0.5397 - val_accuracy: 0.7355\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.4163 - accuracy: 0.8114 - val_loss: 0.5726 - val_accuracy: 0.7110\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.4007 - accuracy: 0.8233 - val_loss: 0.5309 - val_accuracy: 0.7505\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.3844 - accuracy: 0.8345 - val_loss: 0.4835 - val_accuracy: 0.7896\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.3694 - accuracy: 0.8438 - val_loss: 0.5114 - val_accuracy: 0.7749\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.3568 - accuracy: 0.8524 - val_loss: 0.4789 - val_accuracy: 0.8017\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.3435 - accuracy: 0.8611 - val_loss: 0.4207 - val_accuracy: 0.8358\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.3339 - accuracy: 0.8663 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.3242 - accuracy: 0.8714 - val_loss: 0.4332 - val_accuracy: 0.8314\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.3170 - accuracy: 0.8753 - val_loss: 0.4933 - val_accuracy: 0.8055\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.3105 - accuracy: 0.8775 - val_loss: 0.4571 - val_accuracy: 0.8235\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.3057 - accuracy: 0.8787 - val_loss: 0.4978 - val_accuracy: 0.8058\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.3009 - accuracy: 0.8825 - val_loss: 0.5189 - val_accuracy: 0.7980\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2974 - accuracy: 0.8827 - val_loss: 0.4314 - val_accuracy: 0.8346\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2953 - accuracy: 0.8848 - val_loss: 0.4665 - val_accuracy: 0.8192\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.2917 - accuracy: 0.8856 - val_loss: 0.5142 - val_accuracy: 0.8025\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2890 - accuracy: 0.8878 - val_loss: 0.4136 - val_accuracy: 0.8426\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.2866 - accuracy: 0.8873 - val_loss: 0.3759 - val_accuracy: 0.8565\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2843 - accuracy: 0.8898 - val_loss: 0.4066 - val_accuracy: 0.8454\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2847 - accuracy: 0.8893 - val_loss: 0.4814 - val_accuracy: 0.8142\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2820 - accuracy: 0.8907 - val_loss: 0.3924 - val_accuracy: 0.8512\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2811 - accuracy: 0.8901 - val_loss: 0.5500 - val_accuracy: 0.7851\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2800 - accuracy: 0.8905 - val_loss: 0.5857 - val_accuracy: 0.7691\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.2786 - accuracy: 0.8913 - val_loss: 0.4460 - val_accuracy: 0.8283\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.2778 - accuracy: 0.8921 - val_loss: 0.4892 - val_accuracy: 0.8122\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2754 - accuracy: 0.8933 - val_loss: 0.4893 - val_accuracy: 0.8106\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2741 - accuracy: 0.8929 - val_loss: 0.4576 - val_accuracy: 0.8267\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2737 - accuracy: 0.8934 - val_loss: 0.4339 - val_accuracy: 0.8324\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2712 - accuracy: 0.8937 - val_loss: 0.4845 - val_accuracy: 0.8131\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2706 - accuracy: 0.8953 - val_loss: 0.4499 - val_accuracy: 0.8267\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2691 - accuracy: 0.8956 - val_loss: 0.4520 - val_accuracy: 0.8249\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.2687 - accuracy: 0.8961 - val_loss: 0.4447 - val_accuracy: 0.8286\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2679 - accuracy: 0.8952 - val_loss: 0.4184 - val_accuracy: 0.8414\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2663 - accuracy: 0.8968 - val_loss: 0.5638 - val_accuracy: 0.7789\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.2661 - accuracy: 0.8963 - val_loss: 0.4552 - val_accuracy: 0.8255\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2647 - accuracy: 0.8970 - val_loss: 0.3460 - val_accuracy: 0.8650\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2628 - accuracy: 0.8985 - val_loss: 0.5244 - val_accuracy: 0.7971\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2622 - accuracy: 0.8977 - val_loss: 0.4724 - val_accuracy: 0.8188\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.6436 - accuracy: 0.6372 - val_loss: 0.6529 - val_accuracy: 0.6143\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.5894 - accuracy: 0.7036 - val_loss: 0.6224 - val_accuracy: 0.6413\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.5591 - accuracy: 0.7200 - val_loss: 0.6195 - val_accuracy: 0.6448\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.5375 - accuracy: 0.7313 - val_loss: 0.6085 - val_accuracy: 0.6532\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5226 - accuracy: 0.7405 - val_loss: 0.6198 - val_accuracy: 0.6489\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.5094 - accuracy: 0.7482 - val_loss: 0.6082 - val_accuracy: 0.6625\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.4992 - accuracy: 0.7550 - val_loss: 0.6206 - val_accuracy: 0.6542\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.4875 - accuracy: 0.7614 - val_loss: 0.5570 - val_accuracy: 0.7049\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.4771 - accuracy: 0.7670 - val_loss: 0.5403 - val_accuracy: 0.7244\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.4670 - accuracy: 0.7753 - val_loss: 0.5708 - val_accuracy: 0.7001\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.4550 - accuracy: 0.7845 - val_loss: 0.5776 - val_accuracy: 0.6988\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.4434 - accuracy: 0.7918 - val_loss: 0.5730 - val_accuracy: 0.7081\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 670us/step - loss: 0.4296 - accuracy: 0.8002 - val_loss: 0.6019 - val_accuracy: 0.6901\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.4150 - accuracy: 0.8109 - val_loss: 0.6614 - val_accuracy: 0.6610\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.4009 - accuracy: 0.8213 - val_loss: 0.5652 - val_accuracy: 0.7285\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.3866 - accuracy: 0.8318 - val_loss: 0.5871 - val_accuracy: 0.7171\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.3726 - accuracy: 0.8412 - val_loss: 0.5218 - val_accuracy: 0.7718\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.3596 - accuracy: 0.8491 - val_loss: 0.5276 - val_accuracy: 0.7714\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.3479 - accuracy: 0.8572 - val_loss: 0.5992 - val_accuracy: 0.7273\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.3365 - accuracy: 0.8640 - val_loss: 0.5717 - val_accuracy: 0.7538\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.3273 - accuracy: 0.8688 - val_loss: 0.4025 - val_accuracy: 0.8472\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.3210 - accuracy: 0.8726 - val_loss: 0.5197 - val_accuracy: 0.7934\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.3140 - accuracy: 0.8746 - val_loss: 0.4664 - val_accuracy: 0.8241\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.3091 - accuracy: 0.8776 - val_loss: 0.3830 - val_accuracy: 0.8557\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.3049 - accuracy: 0.8804 - val_loss: 0.4366 - val_accuracy: 0.8363\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.2998 - accuracy: 0.8820 - val_loss: 0.6186 - val_accuracy: 0.7479\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.2976 - accuracy: 0.8827 - val_loss: 0.4222 - val_accuracy: 0.8430\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.2933 - accuracy: 0.8843 - val_loss: 0.4524 - val_accuracy: 0.8310\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.2921 - accuracy: 0.8860 - val_loss: 0.4674 - val_accuracy: 0.8247\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.2893 - accuracy: 0.8875 - val_loss: 0.5266 - val_accuracy: 0.8013\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.2873 - accuracy: 0.8874 - val_loss: 0.6272 - val_accuracy: 0.7469\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.2863 - accuracy: 0.8874 - val_loss: 0.5257 - val_accuracy: 0.8021\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.2832 - accuracy: 0.8908 - val_loss: 0.4364 - val_accuracy: 0.8356\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.2819 - accuracy: 0.8895 - val_loss: 0.4132 - val_accuracy: 0.8451\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.2811 - accuracy: 0.8897 - val_loss: 0.4160 - val_accuracy: 0.8434\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.2788 - accuracy: 0.8917 - val_loss: 0.4834 - val_accuracy: 0.8168\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.2777 - accuracy: 0.8908 - val_loss: 0.5207 - val_accuracy: 0.8017\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2765 - accuracy: 0.8919 - val_loss: 0.4122 - val_accuracy: 0.8449\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.2759 - accuracy: 0.8921 - val_loss: 0.5255 - val_accuracy: 0.8022\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.2739 - accuracy: 0.8929 - val_loss: 0.3833 - val_accuracy: 0.8536\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.2735 - accuracy: 0.8929 - val_loss: 0.4529 - val_accuracy: 0.8266\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.2721 - accuracy: 0.8939 - val_loss: 0.4066 - val_accuracy: 0.8465\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.2694 - accuracy: 0.8943 - val_loss: 0.3871 - val_accuracy: 0.8523\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.2699 - accuracy: 0.8956 - val_loss: 0.4683 - val_accuracy: 0.8202\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.2689 - accuracy: 0.8938 - val_loss: 0.5167 - val_accuracy: 0.8055\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.2679 - accuracy: 0.8956 - val_loss: 0.5353 - val_accuracy: 0.7954\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.2658 - accuracy: 0.8971 - val_loss: 0.4625 - val_accuracy: 0.8219\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.2656 - accuracy: 0.8964 - val_loss: 0.3781 - val_accuracy: 0.8539\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.2639 - accuracy: 0.8974 - val_loss: 0.4431 - val_accuracy: 0.8318\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.2643 - accuracy: 0.8975 - val_loss: 0.4467 - val_accuracy: 0.8294\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.6482 - accuracy: 0.6288 - val_loss: 0.6206 - val_accuracy: 0.6561\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.5942 - accuracy: 0.6938 - val_loss: 0.6250 - val_accuracy: 0.6316\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.5658 - accuracy: 0.7163 - val_loss: 0.6420 - val_accuracy: 0.6049\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.5454 - accuracy: 0.7276 - val_loss: 0.5588 - val_accuracy: 0.6762\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.5286 - accuracy: 0.7378 - val_loss: 0.5892 - val_accuracy: 0.6498\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.5131 - accuracy: 0.7450 - val_loss: 0.5799 - val_accuracy: 0.6565\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.4998 - accuracy: 0.7533 - val_loss: 0.6165 - val_accuracy: 0.6340\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.4875 - accuracy: 0.7630 - val_loss: 0.5394 - val_accuracy: 0.7029\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.4723 - accuracy: 0.7727 - val_loss: 0.5657 - val_accuracy: 0.6821\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.4602 - accuracy: 0.7794 - val_loss: 0.5335 - val_accuracy: 0.7176\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.4458 - accuracy: 0.7919 - val_loss: 0.5525 - val_accuracy: 0.7023\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.4314 - accuracy: 0.8009 - val_loss: 0.5353 - val_accuracy: 0.7212\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.4140 - accuracy: 0.8116 - val_loss: 0.5248 - val_accuracy: 0.7360\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.3984 - accuracy: 0.8243 - val_loss: 0.5876 - val_accuracy: 0.6934\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.3839 - accuracy: 0.8334 - val_loss: 0.5677 - val_accuracy: 0.7119\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.3679 - accuracy: 0.8447 - val_loss: 0.3888 - val_accuracy: 0.8471\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.3560 - accuracy: 0.8522 - val_loss: 0.4982 - val_accuracy: 0.7808\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.3440 - accuracy: 0.8600 - val_loss: 0.4064 - val_accuracy: 0.8369\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.3341 - accuracy: 0.8658 - val_loss: 0.4800 - val_accuracy: 0.8007\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.3245 - accuracy: 0.8709 - val_loss: 0.4075 - val_accuracy: 0.8378\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.3162 - accuracy: 0.8749 - val_loss: 0.6243 - val_accuracy: 0.7091\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.3116 - accuracy: 0.8766 - val_loss: 0.4502 - val_accuracy: 0.8227\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.3050 - accuracy: 0.8809 - val_loss: 0.4402 - val_accuracy: 0.8246\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3006 - accuracy: 0.8823 - val_loss: 0.4361 - val_accuracy: 0.8273\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2968 - accuracy: 0.8835 - val_loss: 0.5203 - val_accuracy: 0.7879\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.2934 - accuracy: 0.8836 - val_loss: 0.3973 - val_accuracy: 0.8437\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.2916 - accuracy: 0.8860 - val_loss: 0.7180 - val_accuracy: 0.6708\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.2868 - accuracy: 0.8874 - val_loss: 0.4382 - val_accuracy: 0.8270\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.2851 - accuracy: 0.8880 - val_loss: 0.4069 - val_accuracy: 0.8388\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.2840 - accuracy: 0.8882 - val_loss: 0.4667 - val_accuracy: 0.8159\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.2812 - accuracy: 0.8906 - val_loss: 0.4369 - val_accuracy: 0.8262\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2793 - accuracy: 0.8902 - val_loss: 0.4764 - val_accuracy: 0.8115\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2785 - accuracy: 0.8913 - val_loss: 0.4478 - val_accuracy: 0.8246\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.2764 - accuracy: 0.8911 - val_loss: 0.4785 - val_accuracy: 0.8115\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.2752 - accuracy: 0.8937 - val_loss: 0.4183 - val_accuracy: 0.8367\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2740 - accuracy: 0.8922 - val_loss: 0.4826 - val_accuracy: 0.8098\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.2726 - accuracy: 0.8927 - val_loss: 0.5036 - val_accuracy: 0.7982\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2697 - accuracy: 0.8944 - val_loss: 0.4553 - val_accuracy: 0.8205\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2693 - accuracy: 0.8954 - val_loss: 0.5137 - val_accuracy: 0.7953\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2688 - accuracy: 0.8949 - val_loss: 0.4386 - val_accuracy: 0.8272\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2668 - accuracy: 0.8962 - val_loss: 0.4324 - val_accuracy: 0.8300\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2662 - accuracy: 0.8957 - val_loss: 0.5531 - val_accuracy: 0.7761\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2658 - accuracy: 0.8961 - val_loss: 0.4635 - val_accuracy: 0.8173\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2654 - accuracy: 0.8963 - val_loss: 0.4713 - val_accuracy: 0.8150\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.2638 - accuracy: 0.8968 - val_loss: 0.5025 - val_accuracy: 0.8019\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2631 - accuracy: 0.8972 - val_loss: 0.4575 - val_accuracy: 0.8167\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2615 - accuracy: 0.8976 - val_loss: 0.3819 - val_accuracy: 0.8506\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.2615 - accuracy: 0.8979 - val_loss: 0.4665 - val_accuracy: 0.8130\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2614 - accuracy: 0.8992 - val_loss: 0.4796 - val_accuracy: 0.8078\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2593 - accuracy: 0.8986 - val_loss: 0.4253 - val_accuracy: 0.8313\n",
      "\n",
      "Training model with noise_multiplier=2.5...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 2.5 iterated over 167200 steps satisfies differential privacy with eps = 0.268 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.6701 - accuracy: 0.5972 - val_loss: 0.6933 - val_accuracy: 0.5452\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.6209 - accuracy: 0.6777 - val_loss: 0.6200 - val_accuracy: 0.6530\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.5900 - accuracy: 0.6992 - val_loss: 0.6385 - val_accuracy: 0.6199\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5664 - accuracy: 0.7135 - val_loss: 0.6491 - val_accuracy: 0.6107\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5502 - accuracy: 0.7221 - val_loss: 0.6371 - val_accuracy: 0.6205\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.5358 - accuracy: 0.7286 - val_loss: 0.5668 - val_accuracy: 0.6806\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5237 - accuracy: 0.7358 - val_loss: 0.5933 - val_accuracy: 0.6583\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5121 - accuracy: 0.7416 - val_loss: 0.6105 - val_accuracy: 0.6477\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.5018 - accuracy: 0.7500 - val_loss: 0.6448 - val_accuracy: 0.6281\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.4905 - accuracy: 0.7561 - val_loss: 0.5910 - val_accuracy: 0.6692\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.4783 - accuracy: 0.7650 - val_loss: 0.6917 - val_accuracy: 0.6102\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.4639 - accuracy: 0.7754 - val_loss: 0.5338 - val_accuracy: 0.7241\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.4495 - accuracy: 0.7875 - val_loss: 0.5498 - val_accuracy: 0.7154\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.4332 - accuracy: 0.7972 - val_loss: 0.5442 - val_accuracy: 0.7254\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 625us/step - loss: 0.4177 - accuracy: 0.8098 - val_loss: 0.4921 - val_accuracy: 0.7672\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 693us/step - loss: 0.4010 - accuracy: 0.8234 - val_loss: 0.5124 - val_accuracy: 0.7578\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.3853 - accuracy: 0.8317 - val_loss: 0.5907 - val_accuracy: 0.7052\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.3697 - accuracy: 0.8418 - val_loss: 0.5100 - val_accuracy: 0.7704\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.3556 - accuracy: 0.8529 - val_loss: 0.4491 - val_accuracy: 0.8192\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.3432 - accuracy: 0.8603 - val_loss: 0.4210 - val_accuracy: 0.8328\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.3345 - accuracy: 0.8655 - val_loss: 0.4380 - val_accuracy: 0.8286\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.3257 - accuracy: 0.8702 - val_loss: 0.5087 - val_accuracy: 0.7921\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.3177 - accuracy: 0.8740 - val_loss: 0.4540 - val_accuracy: 0.8228\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.3110 - accuracy: 0.8759 - val_loss: 0.4055 - val_accuracy: 0.8430\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.3065 - accuracy: 0.8788 - val_loss: 0.4690 - val_accuracy: 0.8179\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.3035 - accuracy: 0.8808 - val_loss: 0.4491 - val_accuracy: 0.8276\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.2975 - accuracy: 0.8832 - val_loss: 0.4691 - val_accuracy: 0.8203\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.2941 - accuracy: 0.8838 - val_loss: 0.4466 - val_accuracy: 0.8305\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.2920 - accuracy: 0.8858 - val_loss: 0.4818 - val_accuracy: 0.8158\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.2900 - accuracy: 0.8873 - val_loss: 0.4630 - val_accuracy: 0.8261\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.2866 - accuracy: 0.8876 - val_loss: 0.4362 - val_accuracy: 0.8347\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.2853 - accuracy: 0.8892 - val_loss: 0.5611 - val_accuracy: 0.7753\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.2835 - accuracy: 0.8897 - val_loss: 0.4400 - val_accuracy: 0.8334\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.2818 - accuracy: 0.8911 - val_loss: 0.4014 - val_accuracy: 0.8479\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.2798 - accuracy: 0.8906 - val_loss: 0.3865 - val_accuracy: 0.8529\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.2785 - accuracy: 0.8912 - val_loss: 0.4156 - val_accuracy: 0.8409\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.2770 - accuracy: 0.8922 - val_loss: 0.4003 - val_accuracy: 0.8454\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.2768 - accuracy: 0.8918 - val_loss: 0.4508 - val_accuracy: 0.8265\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 664us/step - loss: 0.2742 - accuracy: 0.8938 - val_loss: 0.4061 - val_accuracy: 0.8441\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.2738 - accuracy: 0.8928 - val_loss: 0.4359 - val_accuracy: 0.8335\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.2741 - accuracy: 0.8939 - val_loss: 0.4807 - val_accuracy: 0.8140\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 704us/step - loss: 0.2713 - accuracy: 0.8946 - val_loss: 0.5048 - val_accuracy: 0.8033\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 672us/step - loss: 0.2715 - accuracy: 0.8954 - val_loss: 0.4706 - val_accuracy: 0.8189\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.2708 - accuracy: 0.8953 - val_loss: 0.4839 - val_accuracy: 0.8102\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.2686 - accuracy: 0.8956 - val_loss: 0.4467 - val_accuracy: 0.8294\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.2668 - accuracy: 0.8963 - val_loss: 0.6254 - val_accuracy: 0.7463\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.2676 - accuracy: 0.8954 - val_loss: 0.5308 - val_accuracy: 0.7943\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.2662 - accuracy: 0.8964 - val_loss: 0.4010 - val_accuracy: 0.8458\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.2662 - accuracy: 0.8966 - val_loss: 0.3875 - val_accuracy: 0.8488\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.2636 - accuracy: 0.8974 - val_loss: 0.3916 - val_accuracy: 0.8495\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.6574 - accuracy: 0.6065 - val_loss: 0.6294 - val_accuracy: 0.6529\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.6073 - accuracy: 0.6727 - val_loss: 0.5740 - val_accuracy: 0.7096\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.5760 - accuracy: 0.7036 - val_loss: 0.6129 - val_accuracy: 0.6389\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.5539 - accuracy: 0.7217 - val_loss: 0.5916 - val_accuracy: 0.6638\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.5365 - accuracy: 0.7306 - val_loss: 0.6466 - val_accuracy: 0.6161\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.5240 - accuracy: 0.7393 - val_loss: 0.6347 - val_accuracy: 0.6307\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.5129 - accuracy: 0.7447 - val_loss: 0.6526 - val_accuracy: 0.6220\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.5024 - accuracy: 0.7506 - val_loss: 0.6346 - val_accuracy: 0.6380\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.4928 - accuracy: 0.7560 - val_loss: 0.6347 - val_accuracy: 0.6466\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.4817 - accuracy: 0.7638 - val_loss: 0.5846 - val_accuracy: 0.6835\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.4699 - accuracy: 0.7731 - val_loss: 0.5365 - val_accuracy: 0.7303\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.4595 - accuracy: 0.7802 - val_loss: 0.6896 - val_accuracy: 0.6291\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.4457 - accuracy: 0.7887 - val_loss: 0.5447 - val_accuracy: 0.7255\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.4315 - accuracy: 0.7998 - val_loss: 0.5202 - val_accuracy: 0.7490\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.4170 - accuracy: 0.8112 - val_loss: 0.6657 - val_accuracy: 0.6506\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.4018 - accuracy: 0.8223 - val_loss: 0.4763 - val_accuracy: 0.7954\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.3863 - accuracy: 0.8331 - val_loss: 0.5066 - val_accuracy: 0.7781\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3704 - accuracy: 0.8443 - val_loss: 0.5336 - val_accuracy: 0.7608\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.3579 - accuracy: 0.8524 - val_loss: 0.5739 - val_accuracy: 0.7407\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3462 - accuracy: 0.8593 - val_loss: 0.4715 - val_accuracy: 0.8132\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.3357 - accuracy: 0.8668 - val_loss: 0.5615 - val_accuracy: 0.7613\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.3275 - accuracy: 0.8708 - val_loss: 0.6351 - val_accuracy: 0.7158\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.3202 - accuracy: 0.8737 - val_loss: 0.4474 - val_accuracy: 0.8285\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.3135 - accuracy: 0.8771 - val_loss: 0.5266 - val_accuracy: 0.7912\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.3079 - accuracy: 0.8814 - val_loss: 0.6584 - val_accuracy: 0.7165\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3051 - accuracy: 0.8814 - val_loss: 0.3861 - val_accuracy: 0.8555\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.3005 - accuracy: 0.8834 - val_loss: 0.4733 - val_accuracy: 0.8205\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2976 - accuracy: 0.8850 - val_loss: 0.4194 - val_accuracy: 0.8416\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.2946 - accuracy: 0.8857 - val_loss: 0.4116 - val_accuracy: 0.8431\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2924 - accuracy: 0.8861 - val_loss: 0.5673 - val_accuracy: 0.7745\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2902 - accuracy: 0.8877 - val_loss: 0.6136 - val_accuracy: 0.7468\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2881 - accuracy: 0.8879 - val_loss: 0.4356 - val_accuracy: 0.8334\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.2869 - accuracy: 0.8882 - val_loss: 0.3938 - val_accuracy: 0.8502\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.2851 - accuracy: 0.8905 - val_loss: 0.5376 - val_accuracy: 0.7897\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.2836 - accuracy: 0.8891 - val_loss: 0.4054 - val_accuracy: 0.8456\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.2808 - accuracy: 0.8900 - val_loss: 0.3913 - val_accuracy: 0.8526\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2799 - accuracy: 0.8919 - val_loss: 0.4542 - val_accuracy: 0.8253\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2801 - accuracy: 0.8908 - val_loss: 0.5450 - val_accuracy: 0.7857\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2776 - accuracy: 0.8930 - val_loss: 0.6735 - val_accuracy: 0.7212\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2767 - accuracy: 0.8925 - val_loss: 0.5607 - val_accuracy: 0.7778\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2772 - accuracy: 0.8918 - val_loss: 0.4478 - val_accuracy: 0.8261\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2730 - accuracy: 0.8948 - val_loss: 0.5926 - val_accuracy: 0.7632\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2734 - accuracy: 0.8947 - val_loss: 0.4937 - val_accuracy: 0.8054\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2727 - accuracy: 0.8956 - val_loss: 0.4748 - val_accuracy: 0.8146\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2720 - accuracy: 0.8943 - val_loss: 0.3896 - val_accuracy: 0.8508\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2708 - accuracy: 0.8948 - val_loss: 0.4555 - val_accuracy: 0.8215\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2693 - accuracy: 0.8948 - val_loss: 0.5488 - val_accuracy: 0.7841\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.2699 - accuracy: 0.8948 - val_loss: 0.4788 - val_accuracy: 0.8159\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2679 - accuracy: 0.8963 - val_loss: 0.5335 - val_accuracy: 0.7900\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2684 - accuracy: 0.8950 - val_loss: 0.3916 - val_accuracy: 0.8485\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.6574 - accuracy: 0.6115 - val_loss: 0.6462 - val_accuracy: 0.6397\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.5970 - accuracy: 0.6895 - val_loss: 0.6242 - val_accuracy: 0.6519\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.5644 - accuracy: 0.7147 - val_loss: 0.6261 - val_accuracy: 0.6428\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5440 - accuracy: 0.7256 - val_loss: 0.6303 - val_accuracy: 0.6363\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.5299 - accuracy: 0.7346 - val_loss: 0.6095 - val_accuracy: 0.6569\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.5178 - accuracy: 0.7409 - val_loss: 0.5684 - val_accuracy: 0.6895\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.5054 - accuracy: 0.7494 - val_loss: 0.5792 - val_accuracy: 0.6840\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.4941 - accuracy: 0.7565 - val_loss: 0.5537 - val_accuracy: 0.7057\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.4828 - accuracy: 0.7633 - val_loss: 0.5164 - val_accuracy: 0.7459\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.4707 - accuracy: 0.7736 - val_loss: 0.5896 - val_accuracy: 0.6796\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.4563 - accuracy: 0.7821 - val_loss: 0.5499 - val_accuracy: 0.7191\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.4405 - accuracy: 0.7947 - val_loss: 0.5305 - val_accuracy: 0.7442\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.4259 - accuracy: 0.8056 - val_loss: 0.5148 - val_accuracy: 0.7600\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.4105 - accuracy: 0.8162 - val_loss: 0.4940 - val_accuracy: 0.7807\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.3938 - accuracy: 0.8295 - val_loss: 0.4733 - val_accuracy: 0.8018\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.3763 - accuracy: 0.8414 - val_loss: 0.6640 - val_accuracy: 0.6690\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 642us/step - loss: 0.3608 - accuracy: 0.8510 - val_loss: 0.6096 - val_accuracy: 0.7118\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.3480 - accuracy: 0.8590 - val_loss: 0.4909 - val_accuracy: 0.8014\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.3353 - accuracy: 0.8659 - val_loss: 0.4401 - val_accuracy: 0.8296\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.3261 - accuracy: 0.8710 - val_loss: 0.4743 - val_accuracy: 0.8152\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.3178 - accuracy: 0.8757 - val_loss: 0.5489 - val_accuracy: 0.7747\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.3114 - accuracy: 0.8778 - val_loss: 0.5416 - val_accuracy: 0.7812\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.3054 - accuracy: 0.8810 - val_loss: 0.5738 - val_accuracy: 0.7647\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.3013 - accuracy: 0.8819 - val_loss: 0.5116 - val_accuracy: 0.8021\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.2951 - accuracy: 0.8850 - val_loss: 0.4530 - val_accuracy: 0.8291\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.2925 - accuracy: 0.8858 - val_loss: 0.6634 - val_accuracy: 0.7237\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.2893 - accuracy: 0.8870 - val_loss: 0.6158 - val_accuracy: 0.7491\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.2861 - accuracy: 0.8892 - val_loss: 0.4763 - val_accuracy: 0.8178\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.2842 - accuracy: 0.8901 - val_loss: 0.6428 - val_accuracy: 0.7411\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.2820 - accuracy: 0.8912 - val_loss: 0.5275 - val_accuracy: 0.7963\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.2811 - accuracy: 0.8906 - val_loss: 0.4777 - val_accuracy: 0.8191\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.2784 - accuracy: 0.8916 - val_loss: 0.4973 - val_accuracy: 0.8092\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.2787 - accuracy: 0.8930 - val_loss: 0.5744 - val_accuracy: 0.7736\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.2755 - accuracy: 0.8927 - val_loss: 0.4810 - val_accuracy: 0.8171\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.2755 - accuracy: 0.8920 - val_loss: 0.4539 - val_accuracy: 0.8289\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.2731 - accuracy: 0.8932 - val_loss: 0.5108 - val_accuracy: 0.8022\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.2709 - accuracy: 0.8950 - val_loss: 0.6419 - val_accuracy: 0.7401\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.2711 - accuracy: 0.8945 - val_loss: 0.4648 - val_accuracy: 0.8216\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.2684 - accuracy: 0.8951 - val_loss: 0.5765 - val_accuracy: 0.7703\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.2683 - accuracy: 0.8961 - val_loss: 0.3812 - val_accuracy: 0.8550\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.2677 - accuracy: 0.8960 - val_loss: 0.3792 - val_accuracy: 0.8560\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.2664 - accuracy: 0.8968 - val_loss: 0.5413 - val_accuracy: 0.7872\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.2653 - accuracy: 0.8968 - val_loss: 0.6025 - val_accuracy: 0.7580\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.2656 - accuracy: 0.8976 - val_loss: 0.4607 - val_accuracy: 0.8222\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 595us/step - loss: 0.2644 - accuracy: 0.8968 - val_loss: 0.5790 - val_accuracy: 0.7728\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.2629 - accuracy: 0.8970 - val_loss: 0.4424 - val_accuracy: 0.8296\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.2620 - accuracy: 0.8970 - val_loss: 0.5651 - val_accuracy: 0.7785\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.2621 - accuracy: 0.8977 - val_loss: 0.4669 - val_accuracy: 0.8201\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.2615 - accuracy: 0.8974 - val_loss: 0.3910 - val_accuracy: 0.8505\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.2603 - accuracy: 0.8994 - val_loss: 0.4519 - val_accuracy: 0.8242\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.6638 - accuracy: 0.6015 - val_loss: 0.6731 - val_accuracy: 0.5932\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.6187 - accuracy: 0.6762 - val_loss: 0.6404 - val_accuracy: 0.6228\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5865 - accuracy: 0.7006 - val_loss: 0.5989 - val_accuracy: 0.6610\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.5612 - accuracy: 0.7192 - val_loss: 0.6210 - val_accuracy: 0.6340\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.5434 - accuracy: 0.7281 - val_loss: 0.5614 - val_accuracy: 0.6805\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5302 - accuracy: 0.7330 - val_loss: 0.5559 - val_accuracy: 0.6905\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5181 - accuracy: 0.7413 - val_loss: 0.6150 - val_accuracy: 0.6487\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5077 - accuracy: 0.7451 - val_loss: 0.5840 - val_accuracy: 0.6697\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.4962 - accuracy: 0.7516 - val_loss: 0.6348 - val_accuracy: 0.6359\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.4861 - accuracy: 0.7596 - val_loss: 0.5975 - val_accuracy: 0.6648\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.4753 - accuracy: 0.7673 - val_loss: 0.5947 - val_accuracy: 0.6715\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.6352 - val_accuracy: 0.6530\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.4515 - accuracy: 0.7857 - val_loss: 0.5226 - val_accuracy: 0.7426\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.4383 - accuracy: 0.7964 - val_loss: 0.5728 - val_accuracy: 0.7063\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.4246 - accuracy: 0.8040 - val_loss: 0.5553 - val_accuracy: 0.7251\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.4106 - accuracy: 0.8161 - val_loss: 0.5850 - val_accuracy: 0.7073\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3959 - accuracy: 0.8274 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.3794 - accuracy: 0.8374 - val_loss: 0.5582 - val_accuracy: 0.7386\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.3676 - accuracy: 0.8472 - val_loss: 0.5603 - val_accuracy: 0.7451\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.3549 - accuracy: 0.8537 - val_loss: 0.4249 - val_accuracy: 0.8345\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.3450 - accuracy: 0.8598 - val_loss: 0.5119 - val_accuracy: 0.7872\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.3352 - accuracy: 0.8670 - val_loss: 0.4916 - val_accuracy: 0.8014\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.3273 - accuracy: 0.8708 - val_loss: 0.4606 - val_accuracy: 0.8192\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.3195 - accuracy: 0.8723 - val_loss: 0.5471 - val_accuracy: 0.7737\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.3144 - accuracy: 0.8747 - val_loss: 0.4880 - val_accuracy: 0.8089\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.3100 - accuracy: 0.8773 - val_loss: 0.4830 - val_accuracy: 0.8116\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.3053 - accuracy: 0.8789 - val_loss: 0.4441 - val_accuracy: 0.8297\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.3020 - accuracy: 0.8817 - val_loss: 0.3833 - val_accuracy: 0.8564\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.3003 - accuracy: 0.8808 - val_loss: 0.3974 - val_accuracy: 0.8493\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.2967 - accuracy: 0.8833 - val_loss: 0.5616 - val_accuracy: 0.7730\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2950 - accuracy: 0.8840 - val_loss: 0.5771 - val_accuracy: 0.7693\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2932 - accuracy: 0.8847 - val_loss: 0.4712 - val_accuracy: 0.8196\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2896 - accuracy: 0.8875 - val_loss: 0.3670 - val_accuracy: 0.8609\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2894 - accuracy: 0.8858 - val_loss: 0.6515 - val_accuracy: 0.7305\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2885 - accuracy: 0.8877 - val_loss: 0.6374 - val_accuracy: 0.7401\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.2857 - accuracy: 0.8891 - val_loss: 0.4961 - val_accuracy: 0.8068\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2852 - accuracy: 0.8891 - val_loss: 0.4923 - val_accuracy: 0.8078\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.2844 - accuracy: 0.8894 - val_loss: 0.3933 - val_accuracy: 0.8493\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.2839 - accuracy: 0.8885 - val_loss: 0.4266 - val_accuracy: 0.8358\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2821 - accuracy: 0.8892 - val_loss: 0.3796 - val_accuracy: 0.8541\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2813 - accuracy: 0.8902 - val_loss: 0.3882 - val_accuracy: 0.8505\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.2798 - accuracy: 0.8916 - val_loss: 0.5273 - val_accuracy: 0.7942\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.2790 - accuracy: 0.8916 - val_loss: 0.4676 - val_accuracy: 0.8184\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2778 - accuracy: 0.8911 - val_loss: 0.5635 - val_accuracy: 0.7791\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2760 - accuracy: 0.8926 - val_loss: 0.6003 - val_accuracy: 0.7609\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2756 - accuracy: 0.8911 - val_loss: 0.4331 - val_accuracy: 0.8335\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2745 - accuracy: 0.8935 - val_loss: 0.4681 - val_accuracy: 0.8219\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2744 - accuracy: 0.8924 - val_loss: 0.5207 - val_accuracy: 0.7921\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2738 - accuracy: 0.8943 - val_loss: 0.4186 - val_accuracy: 0.8373\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.2726 - accuracy: 0.8936 - val_loss: 0.4418 - val_accuracy: 0.8300\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.6485 - accuracy: 0.6241 - val_loss: 0.6703 - val_accuracy: 0.5847\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5971 - accuracy: 0.6832 - val_loss: 0.6037 - val_accuracy: 0.6564\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.5687 - accuracy: 0.7071 - val_loss: 0.5829 - val_accuracy: 0.6749\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5473 - accuracy: 0.7227 - val_loss: 0.5836 - val_accuracy: 0.6722\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5321 - accuracy: 0.7339 - val_loss: 0.6182 - val_accuracy: 0.6399\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5195 - accuracy: 0.7400 - val_loss: 0.5865 - val_accuracy: 0.6681\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5071 - accuracy: 0.7481 - val_loss: 0.6265 - val_accuracy: 0.6384\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.4965 - accuracy: 0.7553 - val_loss: 0.5775 - val_accuracy: 0.6826\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.4863 - accuracy: 0.7621 - val_loss: 0.5861 - val_accuracy: 0.6757\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.4753 - accuracy: 0.7707 - val_loss: 0.5298 - val_accuracy: 0.7344\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.4643 - accuracy: 0.7788 - val_loss: 0.5496 - val_accuracy: 0.7158\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.4525 - accuracy: 0.7867 - val_loss: 0.5346 - val_accuracy: 0.7325\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.4393 - accuracy: 0.7970 - val_loss: 0.5652 - val_accuracy: 0.7106\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.4254 - accuracy: 0.8061 - val_loss: 0.5828 - val_accuracy: 0.7025\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.4086 - accuracy: 0.8190 - val_loss: 0.5832 - val_accuracy: 0.7109\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.3940 - accuracy: 0.8293 - val_loss: 0.5070 - val_accuracy: 0.7763\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.3791 - accuracy: 0.8400 - val_loss: 0.6173 - val_accuracy: 0.6988\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.3635 - accuracy: 0.8499 - val_loss: 0.6222 - val_accuracy: 0.7012\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 686us/step - loss: 0.3516 - accuracy: 0.8575 - val_loss: 0.5462 - val_accuracy: 0.7616\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.3386 - accuracy: 0.8651 - val_loss: 0.4719 - val_accuracy: 0.8161\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.3295 - accuracy: 0.8688 - val_loss: 0.4541 - val_accuracy: 0.8232\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.3229 - accuracy: 0.8721 - val_loss: 0.5159 - val_accuracy: 0.7933\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.3150 - accuracy: 0.8759 - val_loss: 0.4333 - val_accuracy: 0.8327\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.3080 - accuracy: 0.8786 - val_loss: 0.4786 - val_accuracy: 0.8142\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.3037 - accuracy: 0.8802 - val_loss: 0.4306 - val_accuracy: 0.8342\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.2995 - accuracy: 0.8817 - val_loss: 0.6244 - val_accuracy: 0.7355\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.2948 - accuracy: 0.8838 - val_loss: 0.6313 - val_accuracy: 0.7375\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.2913 - accuracy: 0.8851 - val_loss: 0.3995 - val_accuracy: 0.8475\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.2897 - accuracy: 0.8875 - val_loss: 0.5307 - val_accuracy: 0.7880\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.2874 - accuracy: 0.8874 - val_loss: 0.3614 - val_accuracy: 0.8603\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.2848 - accuracy: 0.8877 - val_loss: 0.4091 - val_accuracy: 0.8435\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.2822 - accuracy: 0.8896 - val_loss: 0.4887 - val_accuracy: 0.8127\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 659us/step - loss: 0.2801 - accuracy: 0.8902 - val_loss: 0.5228 - val_accuracy: 0.7955\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.2779 - accuracy: 0.8910 - val_loss: 0.4020 - val_accuracy: 0.8463\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.2776 - accuracy: 0.8909 - val_loss: 0.3836 - val_accuracy: 0.8528\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.2765 - accuracy: 0.8917 - val_loss: 0.4764 - val_accuracy: 0.8140\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.2749 - accuracy: 0.8940 - val_loss: 0.4812 - val_accuracy: 0.8139\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.2721 - accuracy: 0.8947 - val_loss: 0.4497 - val_accuracy: 0.8251\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.2721 - accuracy: 0.8941 - val_loss: 0.5608 - val_accuracy: 0.7777\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.2700 - accuracy: 0.8952 - val_loss: 0.4274 - val_accuracy: 0.8352\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.2697 - accuracy: 0.8948 - val_loss: 0.4907 - val_accuracy: 0.8075\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.2685 - accuracy: 0.8959 - val_loss: 0.5531 - val_accuracy: 0.7779\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.2662 - accuracy: 0.8964 - val_loss: 0.4884 - val_accuracy: 0.8143\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.2666 - accuracy: 0.8967 - val_loss: 0.6936 - val_accuracy: 0.7012\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.2650 - accuracy: 0.8967 - val_loss: 0.4602 - val_accuracy: 0.8184\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.2657 - accuracy: 0.8972 - val_loss: 0.3748 - val_accuracy: 0.8546\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.2642 - accuracy: 0.8968 - val_loss: 0.4303 - val_accuracy: 0.8335\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.2638 - accuracy: 0.8984 - val_loss: 0.5439 - val_accuracy: 0.7858\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.2614 - accuracy: 0.8978 - val_loss: 0.3772 - val_accuracy: 0.8550\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.2622 - accuracy: 0.8973 - val_loss: 0.4424 - val_accuracy: 0.8247\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.6728 - accuracy: 0.5913 - val_loss: 0.6829 - val_accuracy: 0.5865\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.6230 - accuracy: 0.6774 - val_loss: 0.6289 - val_accuracy: 0.6534\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.5859 - accuracy: 0.7041 - val_loss: 0.6110 - val_accuracy: 0.6509\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.5575 - accuracy: 0.7215 - val_loss: 0.5689 - val_accuracy: 0.6934\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.5388 - accuracy: 0.7318 - val_loss: 0.5835 - val_accuracy: 0.6820\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.5242 - accuracy: 0.7397 - val_loss: 0.5951 - val_accuracy: 0.6737\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5108 - accuracy: 0.7465 - val_loss: 0.6156 - val_accuracy: 0.6610\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.4991 - accuracy: 0.7530 - val_loss: 0.5812 - val_accuracy: 0.6916\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.4874 - accuracy: 0.7633 - val_loss: 0.6112 - val_accuracy: 0.6710\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.4763 - accuracy: 0.7703 - val_loss: 0.6164 - val_accuracy: 0.6679\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.4652 - accuracy: 0.7774 - val_loss: 0.6124 - val_accuracy: 0.6734\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.4515 - accuracy: 0.7883 - val_loss: 0.5689 - val_accuracy: 0.7085\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.4378 - accuracy: 0.7985 - val_loss: 0.5319 - val_accuracy: 0.7443\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.4221 - accuracy: 0.8092 - val_loss: 0.5966 - val_accuracy: 0.6938\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.4059 - accuracy: 0.8194 - val_loss: 0.5092 - val_accuracy: 0.7698\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.3905 - accuracy: 0.8326 - val_loss: 0.5946 - val_accuracy: 0.7078\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.3739 - accuracy: 0.8423 - val_loss: 0.5857 - val_accuracy: 0.7209\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.3595 - accuracy: 0.8523 - val_loss: 0.5265 - val_accuracy: 0.7694\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.3482 - accuracy: 0.8582 - val_loss: 0.5085 - val_accuracy: 0.7860\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.3364 - accuracy: 0.8658 - val_loss: 0.4585 - val_accuracy: 0.8185\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.3261 - accuracy: 0.8689 - val_loss: 0.4517 - val_accuracy: 0.8238\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.3185 - accuracy: 0.8746 - val_loss: 0.5695 - val_accuracy: 0.7578\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.3114 - accuracy: 0.8783 - val_loss: 0.4940 - val_accuracy: 0.8080\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3059 - accuracy: 0.8811 - val_loss: 0.4880 - val_accuracy: 0.8133\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.3013 - accuracy: 0.8831 - val_loss: 0.4082 - val_accuracy: 0.8445\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2979 - accuracy: 0.8845 - val_loss: 0.4744 - val_accuracy: 0.8186\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2933 - accuracy: 0.8865 - val_loss: 0.4205 - val_accuracy: 0.8407\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2905 - accuracy: 0.8882 - val_loss: 0.4645 - val_accuracy: 0.8226\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.2865 - accuracy: 0.8883 - val_loss: 0.5148 - val_accuracy: 0.8008\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.2855 - accuracy: 0.8895 - val_loss: 0.5949 - val_accuracy: 0.7592\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.2837 - accuracy: 0.8905 - val_loss: 0.5763 - val_accuracy: 0.7703\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2804 - accuracy: 0.8920 - val_loss: 0.4795 - val_accuracy: 0.8183\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.2786 - accuracy: 0.8922 - val_loss: 0.5503 - val_accuracy: 0.7847\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.2762 - accuracy: 0.8925 - val_loss: 0.5547 - val_accuracy: 0.7833\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2757 - accuracy: 0.8930 - val_loss: 0.4774 - val_accuracy: 0.8178\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2743 - accuracy: 0.8928 - val_loss: 0.4649 - val_accuracy: 0.8217\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.2728 - accuracy: 0.8940 - val_loss: 0.3765 - val_accuracy: 0.8558\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.2723 - accuracy: 0.8939 - val_loss: 0.5138 - val_accuracy: 0.8000\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2695 - accuracy: 0.8956 - val_loss: 0.5666 - val_accuracy: 0.7788\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2694 - accuracy: 0.8955 - val_loss: 0.4076 - val_accuracy: 0.8445\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2682 - accuracy: 0.8960 - val_loss: 0.7565 - val_accuracy: 0.6777\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2678 - accuracy: 0.8961 - val_loss: 0.4883 - val_accuracy: 0.8111\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2651 - accuracy: 0.8970 - val_loss: 0.5645 - val_accuracy: 0.7776\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.2655 - accuracy: 0.8960 - val_loss: 0.3932 - val_accuracy: 0.8497\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2637 - accuracy: 0.8977 - val_loss: 0.3812 - val_accuracy: 0.8529\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2644 - accuracy: 0.8974 - val_loss: 0.5357 - val_accuracy: 0.7913\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.2630 - accuracy: 0.8986 - val_loss: 0.4727 - val_accuracy: 0.8189\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2613 - accuracy: 0.8988 - val_loss: 0.5101 - val_accuracy: 0.8034\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.2610 - accuracy: 0.8977 - val_loss: 0.4683 - val_accuracy: 0.8192\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2600 - accuracy: 0.8997 - val_loss: 0.4990 - val_accuracy: 0.8090\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.6646 - accuracy: 0.5906 - val_loss: 0.6261 - val_accuracy: 0.6762\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.6137 - accuracy: 0.6668 - val_loss: 0.6160 - val_accuracy: 0.6543\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5817 - accuracy: 0.6981 - val_loss: 0.5953 - val_accuracy: 0.6646\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.5597 - accuracy: 0.7167 - val_loss: 0.6653 - val_accuracy: 0.6010\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5412 - accuracy: 0.7303 - val_loss: 0.5751 - val_accuracy: 0.6769\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.5260 - accuracy: 0.7403 - val_loss: 0.5868 - val_accuracy: 0.6686\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.5147 - accuracy: 0.7450 - val_loss: 0.5877 - val_accuracy: 0.6699\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.5035 - accuracy: 0.7540 - val_loss: 0.5725 - val_accuracy: 0.6824\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.4915 - accuracy: 0.7596 - val_loss: 0.5761 - val_accuracy: 0.6828\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.4793 - accuracy: 0.7682 - val_loss: 0.5519 - val_accuracy: 0.7040\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.4664 - accuracy: 0.7776 - val_loss: 0.6214 - val_accuracy: 0.6534\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.4521 - accuracy: 0.7861 - val_loss: 0.6420 - val_accuracy: 0.6429\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.4371 - accuracy: 0.7983 - val_loss: 0.5423 - val_accuracy: 0.7214\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.4221 - accuracy: 0.8096 - val_loss: 0.4905 - val_accuracy: 0.7740\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.4063 - accuracy: 0.8199 - val_loss: 0.4479 - val_accuracy: 0.8089\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.3907 - accuracy: 0.8308 - val_loss: 0.5036 - val_accuracy: 0.7695\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.3750 - accuracy: 0.8398 - val_loss: 0.5470 - val_accuracy: 0.7420\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.3614 - accuracy: 0.8483 - val_loss: 0.5060 - val_accuracy: 0.7768\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.3470 - accuracy: 0.8568 - val_loss: 0.5790 - val_accuracy: 0.7306\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 705us/step - loss: 0.3372 - accuracy: 0.8624 - val_loss: 0.4892 - val_accuracy: 0.7953\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.3266 - accuracy: 0.8692 - val_loss: 0.4818 - val_accuracy: 0.8058\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.3189 - accuracy: 0.8745 - val_loss: 0.4588 - val_accuracy: 0.8183\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.3129 - accuracy: 0.8776 - val_loss: 0.4639 - val_accuracy: 0.8165\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 642us/step - loss: 0.3069 - accuracy: 0.8789 - val_loss: 0.5096 - val_accuracy: 0.7939\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.3004 - accuracy: 0.8822 - val_loss: 0.4635 - val_accuracy: 0.8204\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.2968 - accuracy: 0.8858 - val_loss: 0.5368 - val_accuracy: 0.7836\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.2938 - accuracy: 0.8850 - val_loss: 0.4024 - val_accuracy: 0.8457\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.2897 - accuracy: 0.8872 - val_loss: 0.4867 - val_accuracy: 0.8117\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.2884 - accuracy: 0.8866 - val_loss: 0.4532 - val_accuracy: 0.8255\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.2853 - accuracy: 0.8887 - val_loss: 0.4745 - val_accuracy: 0.8162\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.2824 - accuracy: 0.8889 - val_loss: 0.4038 - val_accuracy: 0.8436\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.2806 - accuracy: 0.8910 - val_loss: 0.4458 - val_accuracy: 0.8290\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.2791 - accuracy: 0.8907 - val_loss: 0.4873 - val_accuracy: 0.8131\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 595us/step - loss: 0.2771 - accuracy: 0.8910 - val_loss: 0.5092 - val_accuracy: 0.7997\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.2761 - accuracy: 0.8927 - val_loss: 0.4227 - val_accuracy: 0.8357\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.2736 - accuracy: 0.8933 - val_loss: 0.4017 - val_accuracy: 0.8453\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.2719 - accuracy: 0.8940 - val_loss: 0.4873 - val_accuracy: 0.8110\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.2700 - accuracy: 0.8948 - val_loss: 0.4545 - val_accuracy: 0.8238\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.2699 - accuracy: 0.8934 - val_loss: 0.5823 - val_accuracy: 0.7631\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.2692 - accuracy: 0.8954 - val_loss: 0.4555 - val_accuracy: 0.8220\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.2674 - accuracy: 0.8965 - val_loss: 0.4661 - val_accuracy: 0.8162\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.2656 - accuracy: 0.8969 - val_loss: 0.6035 - val_accuracy: 0.7567\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.2659 - accuracy: 0.8955 - val_loss: 0.4998 - val_accuracy: 0.8061\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.2640 - accuracy: 0.8970 - val_loss: 0.4610 - val_accuracy: 0.8199\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.2633 - accuracy: 0.8973 - val_loss: 0.4729 - val_accuracy: 0.8132\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.2618 - accuracy: 0.8979 - val_loss: 0.5616 - val_accuracy: 0.7758\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.2620 - accuracy: 0.8991 - val_loss: 0.5558 - val_accuracy: 0.7765\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 730us/step - loss: 0.2600 - accuracy: 0.8986 - val_loss: 0.5117 - val_accuracy: 0.7991\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.2578 - accuracy: 0.9003 - val_loss: 0.5898 - val_accuracy: 0.7627\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.2582 - accuracy: 0.8988 - val_loss: 0.4108 - val_accuracy: 0.8415\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.6583 - accuracy: 0.6025 - val_loss: 0.6673 - val_accuracy: 0.5966\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 626us/step - loss: 0.6069 - accuracy: 0.6678 - val_loss: 0.6247 - val_accuracy: 0.6486\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5733 - accuracy: 0.7041 - val_loss: 0.6073 - val_accuracy: 0.6509\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.5487 - accuracy: 0.7224 - val_loss: 0.6221 - val_accuracy: 0.6385\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.5297 - accuracy: 0.7350 - val_loss: 0.6032 - val_accuracy: 0.6562\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.5153 - accuracy: 0.7441 - val_loss: 0.6119 - val_accuracy: 0.6462\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.5034 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.6674\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.4907 - accuracy: 0.7588 - val_loss: 0.6637 - val_accuracy: 0.6140\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.4791 - accuracy: 0.7675 - val_loss: 0.5346 - val_accuracy: 0.7255\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.4672 - accuracy: 0.7758 - val_loss: 0.5876 - val_accuracy: 0.6761\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.4538 - accuracy: 0.7855 - val_loss: 0.5993 - val_accuracy: 0.6737\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.4407 - accuracy: 0.7954 - val_loss: 0.4950 - val_accuracy: 0.7686\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.4255 - accuracy: 0.8063 - val_loss: 0.5741 - val_accuracy: 0.7055\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.4100 - accuracy: 0.8157 - val_loss: 0.5565 - val_accuracy: 0.7219\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.3951 - accuracy: 0.8262 - val_loss: 0.5931 - val_accuracy: 0.7010\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.3806 - accuracy: 0.8375 - val_loss: 0.5057 - val_accuracy: 0.7773\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.3654 - accuracy: 0.8492 - val_loss: 0.4500 - val_accuracy: 0.8227\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.3540 - accuracy: 0.8539 - val_loss: 0.4498 - val_accuracy: 0.8256\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.3424 - accuracy: 0.8611 - val_loss: 0.4234 - val_accuracy: 0.8374\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.3319 - accuracy: 0.8666 - val_loss: 0.4924 - val_accuracy: 0.8070\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.3233 - accuracy: 0.8713 - val_loss: 0.5330 - val_accuracy: 0.7827\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.3181 - accuracy: 0.8740 - val_loss: 0.4574 - val_accuracy: 0.8256\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.3121 - accuracy: 0.8772 - val_loss: 0.5011 - val_accuracy: 0.8079\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.3060 - accuracy: 0.8803 - val_loss: 0.4553 - val_accuracy: 0.8274\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.3024 - accuracy: 0.8814 - val_loss: 0.4052 - val_accuracy: 0.8471\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2997 - accuracy: 0.8830 - val_loss: 0.4731 - val_accuracy: 0.8220\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.2963 - accuracy: 0.8835 - val_loss: 0.4198 - val_accuracy: 0.8422\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.2931 - accuracy: 0.8842 - val_loss: 0.4782 - val_accuracy: 0.8195\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2923 - accuracy: 0.8857 - val_loss: 0.4415 - val_accuracy: 0.8324\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.2878 - accuracy: 0.8878 - val_loss: 0.5239 - val_accuracy: 0.8021\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2882 - accuracy: 0.8878 - val_loss: 0.4597 - val_accuracy: 0.8258\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.2853 - accuracy: 0.8884 - val_loss: 0.5140 - val_accuracy: 0.8042\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2844 - accuracy: 0.8889 - val_loss: 0.4770 - val_accuracy: 0.8202\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2817 - accuracy: 0.8883 - val_loss: 0.4397 - val_accuracy: 0.8317\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.2806 - accuracy: 0.8906 - val_loss: 0.4343 - val_accuracy: 0.8318\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.2784 - accuracy: 0.8915 - val_loss: 0.3869 - val_accuracy: 0.8527\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.2764 - accuracy: 0.8940 - val_loss: 0.5326 - val_accuracy: 0.7952\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.2769 - accuracy: 0.8911 - val_loss: 0.3961 - val_accuracy: 0.8488\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.2747 - accuracy: 0.8930 - val_loss: 0.4238 - val_accuracy: 0.8361\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.2741 - accuracy: 0.8935 - val_loss: 0.4633 - val_accuracy: 0.8212\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2714 - accuracy: 0.8942 - val_loss: 0.4133 - val_accuracy: 0.8404\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2720 - accuracy: 0.8953 - val_loss: 0.4467 - val_accuracy: 0.8272\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2707 - accuracy: 0.8956 - val_loss: 0.3808 - val_accuracy: 0.8554\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2703 - accuracy: 0.8948 - val_loss: 0.5042 - val_accuracy: 0.8044\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.2681 - accuracy: 0.8959 - val_loss: 0.5348 - val_accuracy: 0.7906\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2674 - accuracy: 0.8966 - val_loss: 0.5181 - val_accuracy: 0.7997\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.2657 - accuracy: 0.8973 - val_loss: 0.4831 - val_accuracy: 0.8134\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.2647 - accuracy: 0.8970 - val_loss: 0.4966 - val_accuracy: 0.8118\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2655 - accuracy: 0.8970 - val_loss: 0.3799 - val_accuracy: 0.8548\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.2639 - accuracy: 0.8972 - val_loss: 0.4809 - val_accuracy: 0.8163\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.6487 - accuracy: 0.6243 - val_loss: 0.6234 - val_accuracy: 0.6433\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.5916 - accuracy: 0.6960 - val_loss: 0.5805 - val_accuracy: 0.6699\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.5624 - accuracy: 0.7172 - val_loss: 0.5666 - val_accuracy: 0.6761\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.5415 - accuracy: 0.7326 - val_loss: 0.5857 - val_accuracy: 0.6591\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5265 - accuracy: 0.7412 - val_loss: 0.6019 - val_accuracy: 0.6458\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.5104 - accuracy: 0.7500 - val_loss: 0.5926 - val_accuracy: 0.6591\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.4968 - accuracy: 0.7587 - val_loss: 0.6216 - val_accuracy: 0.6347\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.4840 - accuracy: 0.7661 - val_loss: 0.5957 - val_accuracy: 0.6622\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.4695 - accuracy: 0.7756 - val_loss: 0.5881 - val_accuracy: 0.6720\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.4539 - accuracy: 0.7874 - val_loss: 0.5465 - val_accuracy: 0.7137\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.4391 - accuracy: 0.7972 - val_loss: 0.5553 - val_accuracy: 0.7099\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.4235 - accuracy: 0.8076 - val_loss: 0.5682 - val_accuracy: 0.7035\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.4069 - accuracy: 0.8203 - val_loss: 0.6009 - val_accuracy: 0.6904\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3908 - accuracy: 0.8313 - val_loss: 0.4436 - val_accuracy: 0.8137\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.3756 - accuracy: 0.8421 - val_loss: 0.4609 - val_accuracy: 0.8038\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.3609 - accuracy: 0.8509 - val_loss: 0.5513 - val_accuracy: 0.7408\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.3490 - accuracy: 0.8569 - val_loss: 0.4555 - val_accuracy: 0.8143\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.3366 - accuracy: 0.8653 - val_loss: 0.5313 - val_accuracy: 0.7674\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 702us/step - loss: 0.3265 - accuracy: 0.8699 - val_loss: 0.5794 - val_accuracy: 0.7432\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 624us/step - loss: 0.3181 - accuracy: 0.8749 - val_loss: 0.5378 - val_accuracy: 0.7690\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.3122 - accuracy: 0.8754 - val_loss: 0.4883 - val_accuracy: 0.8024\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.3074 - accuracy: 0.8765 - val_loss: 0.4637 - val_accuracy: 0.8162\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.3022 - accuracy: 0.8795 - val_loss: 0.5214 - val_accuracy: 0.7903\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.2980 - accuracy: 0.8814 - val_loss: 0.4448 - val_accuracy: 0.8258\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.2946 - accuracy: 0.8834 - val_loss: 0.5462 - val_accuracy: 0.7744\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.2922 - accuracy: 0.8857 - val_loss: 0.5054 - val_accuracy: 0.7996\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.2883 - accuracy: 0.8866 - val_loss: 0.4842 - val_accuracy: 0.8105\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.2872 - accuracy: 0.8868 - val_loss: 0.5683 - val_accuracy: 0.7682\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.2851 - accuracy: 0.8881 - val_loss: 0.4497 - val_accuracy: 0.8253\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.2830 - accuracy: 0.8898 - val_loss: 0.4560 - val_accuracy: 0.8226\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 683us/step - loss: 0.2821 - accuracy: 0.8891 - val_loss: 0.5042 - val_accuracy: 0.8001\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.2803 - accuracy: 0.8895 - val_loss: 0.4326 - val_accuracy: 0.8318\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.2785 - accuracy: 0.8918 - val_loss: 0.5222 - val_accuracy: 0.7896\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.2760 - accuracy: 0.8923 - val_loss: 0.5946 - val_accuracy: 0.7592\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 641us/step - loss: 0.2767 - accuracy: 0.8923 - val_loss: 0.4511 - val_accuracy: 0.8238\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.2753 - accuracy: 0.8920 - val_loss: 0.5570 - val_accuracy: 0.7772\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.2734 - accuracy: 0.8933 - val_loss: 0.4121 - val_accuracy: 0.8389\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.2723 - accuracy: 0.8923 - val_loss: 0.4112 - val_accuracy: 0.8385\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 604us/step - loss: 0.2722 - accuracy: 0.8931 - val_loss: 0.5424 - val_accuracy: 0.7796\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 641us/step - loss: 0.2689 - accuracy: 0.8942 - val_loss: 0.5310 - val_accuracy: 0.7911\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.2690 - accuracy: 0.8963 - val_loss: 0.6621 - val_accuracy: 0.7192\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 620us/step - loss: 0.2687 - accuracy: 0.8953 - val_loss: 0.5519 - val_accuracy: 0.7776\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.2681 - accuracy: 0.8952 - val_loss: 0.4892 - val_accuracy: 0.8073\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.2666 - accuracy: 0.8957 - val_loss: 0.4009 - val_accuracy: 0.8407\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.2659 - accuracy: 0.8959 - val_loss: 0.5402 - val_accuracy: 0.7820\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 650us/step - loss: 0.2660 - accuracy: 0.8953 - val_loss: 0.4882 - val_accuracy: 0.8050\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.2631 - accuracy: 0.8975 - val_loss: 0.4301 - val_accuracy: 0.8290\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.2636 - accuracy: 0.8972 - val_loss: 0.3858 - val_accuracy: 0.8487\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.2626 - accuracy: 0.8981 - val_loss: 0.5270 - val_accuracy: 0.7912\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.2625 - accuracy: 0.8971 - val_loss: 0.5032 - val_accuracy: 0.8029\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 679us/step - loss: 0.6627 - accuracy: 0.6000 - val_loss: 0.6552 - val_accuracy: 0.6074\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.6044 - accuracy: 0.6810 - val_loss: 0.6163 - val_accuracy: 0.6447\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.5725 - accuracy: 0.7087 - val_loss: 0.6228 - val_accuracy: 0.6313\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.5487 - accuracy: 0.7257 - val_loss: 0.5956 - val_accuracy: 0.6539\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.5322 - accuracy: 0.7346 - val_loss: 0.5841 - val_accuracy: 0.6644\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 644us/step - loss: 0.5164 - accuracy: 0.7460 - val_loss: 0.5961 - val_accuracy: 0.6532\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.5040 - accuracy: 0.7537 - val_loss: 0.6126 - val_accuracy: 0.6416\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.4896 - accuracy: 0.7627 - val_loss: 0.5310 - val_accuracy: 0.7122\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 637us/step - loss: 0.4752 - accuracy: 0.7716 - val_loss: 0.5395 - val_accuracy: 0.7056\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.4612 - accuracy: 0.7805 - val_loss: 0.4782 - val_accuracy: 0.7701\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.4447 - accuracy: 0.7923 - val_loss: 0.6210 - val_accuracy: 0.6572\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 624us/step - loss: 0.4282 - accuracy: 0.8034 - val_loss: 0.5515 - val_accuracy: 0.7068\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.4111 - accuracy: 0.8174 - val_loss: 0.5049 - val_accuracy: 0.7554\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3963 - accuracy: 0.8258 - val_loss: 0.5810 - val_accuracy: 0.7009\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.3807 - accuracy: 0.8367 - val_loss: 0.4136 - val_accuracy: 0.8320\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.3655 - accuracy: 0.8469 - val_loss: 0.4771 - val_accuracy: 0.7931\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.3534 - accuracy: 0.8535 - val_loss: 0.4661 - val_accuracy: 0.8056\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.3405 - accuracy: 0.8623 - val_loss: 0.4838 - val_accuracy: 0.7979\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.3317 - accuracy: 0.8671 - val_loss: 0.5945 - val_accuracy: 0.7172\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.3226 - accuracy: 0.8720 - val_loss: 0.5286 - val_accuracy: 0.7763\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.3165 - accuracy: 0.8745 - val_loss: 0.4450 - val_accuracy: 0.8242\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.3112 - accuracy: 0.8763 - val_loss: 0.4782 - val_accuracy: 0.8099\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.3058 - accuracy: 0.8782 - val_loss: 0.4657 - val_accuracy: 0.8180\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.3023 - accuracy: 0.8801 - val_loss: 0.5270 - val_accuracy: 0.7886\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2995 - accuracy: 0.8826 - val_loss: 0.4790 - val_accuracy: 0.8130\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.2959 - accuracy: 0.8838 - val_loss: 0.4037 - val_accuracy: 0.8423\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.2938 - accuracy: 0.8835 - val_loss: 0.3455 - val_accuracy: 0.8675\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.2909 - accuracy: 0.8850 - val_loss: 0.5522 - val_accuracy: 0.7745\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2897 - accuracy: 0.8876 - val_loss: 0.5486 - val_accuracy: 0.7764\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.2865 - accuracy: 0.8882 - val_loss: 0.4977 - val_accuracy: 0.8044\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.2861 - accuracy: 0.8886 - val_loss: 0.6547 - val_accuracy: 0.7135\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.2844 - accuracy: 0.8890 - val_loss: 0.4877 - val_accuracy: 0.8087\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.2831 - accuracy: 0.8887 - val_loss: 0.4266 - val_accuracy: 0.8326\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.2827 - accuracy: 0.8900 - val_loss: 0.4718 - val_accuracy: 0.8167\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.2806 - accuracy: 0.8902 - val_loss: 0.4945 - val_accuracy: 0.8023\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2795 - accuracy: 0.8911 - val_loss: 0.5244 - val_accuracy: 0.7883\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.2776 - accuracy: 0.8918 - val_loss: 0.4522 - val_accuracy: 0.8199\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.2776 - accuracy: 0.8913 - val_loss: 0.4807 - val_accuracy: 0.8117\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.2747 - accuracy: 0.8916 - val_loss: 0.4005 - val_accuracy: 0.8416\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2738 - accuracy: 0.8928 - val_loss: 0.5518 - val_accuracy: 0.7763\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.2732 - accuracy: 0.8939 - val_loss: 0.4672 - val_accuracy: 0.8144\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.2724 - accuracy: 0.8936 - val_loss: 0.4271 - val_accuracy: 0.8299\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.2718 - accuracy: 0.8936 - val_loss: 0.4344 - val_accuracy: 0.8257\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.2707 - accuracy: 0.8942 - val_loss: 0.4206 - val_accuracy: 0.8308\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.2685 - accuracy: 0.8947 - val_loss: 0.4652 - val_accuracy: 0.8151\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.2681 - accuracy: 0.8960 - val_loss: 0.3995 - val_accuracy: 0.8423\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.2678 - accuracy: 0.8949 - val_loss: 0.3794 - val_accuracy: 0.8509\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.2669 - accuracy: 0.8949 - val_loss: 0.4352 - val_accuracy: 0.8253\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.2676 - accuracy: 0.8950 - val_loss: 0.4134 - val_accuracy: 0.8357\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.2646 - accuracy: 0.8960 - val_loss: 0.5821 - val_accuracy: 0.7615\n"
     ]
    }
   ],
   "source": [
    "# 3. Vary noise_multiplier\n",
    "results_noise_multiplier = {}\n",
    "eps_noise_multiplier = {}\n",
    "for noise in noise_multiplier_values:\n",
    "    print(f\"\\nTraining model with noise_multiplier={noise}...\")\n",
    "    n = len(X_train_filtered)\n",
    "    eps = compute_privacy_budget(n, default_batch_size, noise, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "        batch_size=default_batch_size, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        l2_norm_clip=l2_norm_clip, noise_multiplier=noise\n",
    "    )\n",
    "    results_noise_multiplier[noise] = compute_statistics(results)\n",
    "    eps_noise_multiplier[noise] = eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83a13266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to 'results/CDP_parameter_results.csv'\n",
      "\n",
      "Results (Averages):\n",
      "                No DP (mean)  batch_size=16 (ε=0.85) (mean)  \\\n",
      "ROC AUC              0.8980                         0.8965   \n",
      "Accuracy             0.8377                         0.8259   \n",
      "Precision            0.4037                         0.3857   \n",
      "Recall               0.8077                         0.8020   \n",
      "F1 Score             0.5382                         0.5197   \n",
      "Type I Error         0.1583                         0.1709   \n",
      "Type II Error        0.1923                         0.1980   \n",
      "\n",
      "               batch_size=32 (ε=1.06) (mean)  batch_size=64 (ε=1.42) (mean)  \\\n",
      "ROC AUC                               0.8837                         0.8153   \n",
      "Accuracy                              0.8197                         0.7314   \n",
      "Precision                             0.3736                         0.2686   \n",
      "Recall                                0.7905                         0.7442   \n",
      "F1 Score                              0.5067                         0.3943   \n",
      "Type I Error                          0.1765                         0.2703   \n",
      "Type II Error                         0.2095                         0.2558   \n",
      "\n",
      "               batch_size=128 (ε=2.01) (mean)  \\\n",
      "ROC AUC                                0.7654   \n",
      "Accuracy                               0.6625   \n",
      "Precision                              0.2179   \n",
      "Recall                                 0.7273   \n",
      "F1 Score                               0.3353   \n",
      "Type I Error                           0.3460   \n",
      "Type II Error                          0.2727   \n",
      "\n",
      "               sample_size_ratio=1 (ε=0.85) (mean)  \\\n",
      "ROC AUC                                     0.8957   \n",
      "Accuracy                                    0.8213   \n",
      "Precision                                   0.3788   \n",
      "Recall                                      0.8099   \n",
      "F1 Score                                    0.5154   \n",
      "Type I Error                                0.1772   \n",
      "Type II Error                               0.1901   \n",
      "\n",
      "               sample_size_ratio=0.5 (ε=1.06) (mean)  \\\n",
      "ROC AUC                                       0.8812   \n",
      "Accuracy                                      0.7944   \n",
      "Precision                                     0.3459   \n",
      "Recall                                        0.8167   \n",
      "F1 Score                                      0.4841   \n",
      "Type I Error                                  0.2086   \n",
      "Type II Error                                 0.1833   \n",
      "\n",
      "               sample_size_ratio=0.1 (ε=2.27) (mean)  \\\n",
      "ROC AUC                                       0.7555   \n",
      "Accuracy                                      0.6357   \n",
      "Precision                                     0.2068   \n",
      "Recall                                        0.7437   \n",
      "F1 Score                                      0.3235   \n",
      "Type I Error                                  0.3786   \n",
      "Type II Error                                 0.2563   \n",
      "\n",
      "               sample_size_ratio=0.05 (ε=3.30) (mean)  \\\n",
      "ROC AUC                                        0.7333   \n",
      "Accuracy                                       0.6614   \n",
      "Precision                                      0.2078   \n",
      "Recall                                         0.6722   \n",
      "F1 Score                                       0.3173   \n",
      "Type I Error                                   0.3401   \n",
      "Type II Error                                  0.3278   \n",
      "\n",
      "               noise_multiplier=1.1 (ε=0.85) (mean)  \\\n",
      "ROC AUC                                      0.8952   \n",
      "Accuracy                                     0.7922   \n",
      "Precision                                    0.3483   \n",
      "Recall                                       0.8455   \n",
      "F1 Score                                     0.4907   \n",
      "Type I Error                                 0.2149   \n",
      "Type II Error                                0.1545   \n",
      "\n",
      "               noise_multiplier=1.5 (ε=0.49) (mean)  \\\n",
      "ROC AUC                                      0.8953   \n",
      "Accuracy                                     0.7983   \n",
      "Precision                                    0.3522   \n",
      "Recall                                       0.8428   \n",
      "F1 Score                                     0.4957   \n",
      "Type I Error                                 0.2077   \n",
      "Type II Error                                0.1572   \n",
      "\n",
      "               noise_multiplier=2.0 (ε=0.32) (mean)  \\\n",
      "ROC AUC                                      0.8958   \n",
      "Accuracy                                     0.8234   \n",
      "Precision                                    0.3812   \n",
      "Recall                                       0.8079   \n",
      "F1 Score                                     0.5175   \n",
      "Type I Error                                 0.1745   \n",
      "Type II Error                                0.1921   \n",
      "\n",
      "               noise_multiplier=2.5 (ε=0.27) (mean)  \n",
      "ROC AUC                                      0.8952  \n",
      "Accuracy                                     0.8208  \n",
      "Precision                                    0.3804  \n",
      "Recall                                       0.8091  \n",
      "F1 Score                                     0.5157  \n",
      "Type I Error                                 0.1776  \n",
      "Type II Error                                0.1909  \n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "results_stats = {\n",
    "    'batch_size': results_batch_size,\n",
    "    'sample_size_ratio': results_sample_size,\n",
    "    'noise_multiplier': results_noise_multiplier\n",
    "}\n",
    "data = {}\n",
    "\n",
    "# Add results for non-DP model\n",
    "data['No DP (mean)'] = results_no_dp_stats['mean']\n",
    "data['No DP (min)'] = results_no_dp_stats['min']\n",
    "data['No DP (max)'] = results_no_dp_stats['max']\n",
    "\n",
    "# Add results for DP models\n",
    "for param, stats_dict in results_stats.items():\n",
    "    for value, stats in stats_dict.items():\n",
    "        # Get the corresponding epsilon value based on the parameter\n",
    "        if param == 'batch_size':\n",
    "            eps = eps_batch_size.get(value, float('inf'))\n",
    "        elif param == 'sample_size_ratio':\n",
    "            eps = eps_sample_size.get(value, float('inf'))\n",
    "        else:  # noise_multiplier\n",
    "            eps = eps_noise_multiplier.get(value, float('inf'))\n",
    "        \n",
    "        # Format the model name with epsilon (if finite)\n",
    "        model = f'{param}={value} (ε={eps:.2f})' if eps != float('inf') else f'{param}={value}'\n",
    "        data[f'{model} (mean)'] = stats['mean']\n",
    "        data[f'{model} (min)'] = stats['min']\n",
    "        data[f'{model} (max)'] = stats['max']\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(data).round(4)\n",
    "results_df.to_csv('results/CDP_parameter_results.csv')\n",
    "print(\"\\nResults saved to 'results/CDP_parameter_results.csv'\")\n",
    "print(\"\\nResults (Averages):\\n\", results_df[[col for col in results_df.columns if 'mean' in col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a322053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot results, including No DP model\n",
    "def plot_parameter_results(stats_dict, eps_dict, param_name, colors, no_dp_stats):\n",
    "    metrics = list(no_dp_stats['mean'].keys())\n",
    "    values = list(stats_dict.keys())\n",
    "    n_metrics = len(metrics)\n",
    "    n_values = len(values) + 1  # +1 for No DP\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x_positions = np.arange(n_metrics)\n",
    "    \n",
    "    # Plot No DP model\n",
    "    means = []\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    for metric in metrics:\n",
    "        means.append(no_dp_stats['mean'][metric])\n",
    "        mins.append(no_dp_stats['min'][metric])\n",
    "        maxs.append(no_dp_stats['max'][metric])\n",
    "    \n",
    "    plt.scatter(x_positions + (0 - (n_values-1)/2) * 0.15, means, \n",
    "                color=colors[0], label='No DP', s=100)\n",
    "    for metric_idx in range(n_metrics):\n",
    "        plt.vlines(x_positions[metric_idx] + (0 - (n_values-1)/2) * 0.15, \n",
    "                   mins[metric_idx], maxs[metric_idx], \n",
    "                   color=colors[0], linestyle='-', linewidth=1)\n",
    "    \n",
    "    # Plot results varying the parameter\n",
    "    for value_idx, value in enumerate(values, start=1):\n",
    "        means = []\n",
    "        mins = []\n",
    "        maxs = []\n",
    "        for metric in metrics:\n",
    "            means.append(stats_dict[value]['mean'][metric])\n",
    "            mins.append(stats_dict[value]['min'][metric])\n",
    "            maxs.append(stats_dict[value]['max'][metric])\n",
    "        \n",
    "        plt.scatter(x_positions + (value_idx - (n_values-1)/2) * 0.15, means, \n",
    "                    color=colors[value_idx], label=f'{param_name}={value} (ε={eps_dict[value]:.2f})', s=100)\n",
    "        for metric_idx in range(n_metrics):\n",
    "            plt.vlines(x_positions[metric_idx] + (value_idx - (n_values-1)/2) * 0.15, \n",
    "                       mins[metric_idx], maxs[metric_idx], \n",
    "                       color=colors[value_idx], linestyle='-', linewidth=1)\n",
    "    \n",
    "    plt.xticks(x_positions, metrics, rotation=45)\n",
    "    plt.title(f'Effect of Varying {param_name} on Model Performance')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(title=f'{param_name} Values', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/Effect_of_{param_name}_with_No_DP.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93697b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define colors\n",
    "colors = ['#0d4e9e', '#ffc520', '#7b9ca0', '#242624', '#cc7b4f']\n",
    "\n",
    "# Plot results\n",
    "plot_parameter_results(results_batch_size, eps_batch_size, 'batch_size', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_sample_size, eps_sample_size, 'sample_size_ratio', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_noise_multiplier, eps_noise_multiplier, 'noise_multiplier', colors, results_no_dp_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
