{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0564a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d31136e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (45211, 33)\n"
     ]
    }
   ],
   "source": [
    "# Crear carpetas para resultados y figuras\n",
    "import os\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "data_path = 'C:/Users/danie/OneDrive/Documentos/1 UNIANDES/10 semestre/Tesis/differential-privacy-banking-sector/data/processed/bank-processed.csv'\n",
    "data = pd.read_csv(data_path, sep=',')\n",
    "print(\"Original data shape:\", data.shape)\n",
    "\n",
    "# Separar características y variable objetivo\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y']\n",
    "\n",
    "# Definir columnas numéricas\n",
    "numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Escalar columnas numéricas\n",
    "scale = MinMaxScaler()\n",
    "X[numeric_cols] = scale.fit_transform(X[numeric_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1aec1bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 14\n"
     ]
    }
   ],
   "source": [
    "# Selección de características con BorutaPy (on original data)\n",
    "rf = xgb.XGBClassifier(eval_metric='logloss')\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
    "feat_selector.fit(X.values, y.values.ravel())\n",
    "X_filtered = X.columns[feat_selector.support_].tolist()\n",
    "print(f\"Selected features: {len(X_filtered)}\")\n",
    "X = X[X_filtered]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd7452f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de la red neuronal\n",
    "input_size = len(X_filtered)\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n",
    "n_iterations = 5\n",
    "num_microbatches = 16\n",
    "l2_norm_clip = 1.0\n",
    "\n",
    "# Valores de parámetros a variar\n",
    "noise_multiplier_values = [1.1, 1.5, 2.0, 2.5, 4, 6]\n",
    "batch_size_values = [128, 64, 32, 16]\n",
    "sample_size_ratios = [0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "# Valores fijos por defecto\n",
    "default_noise_multiplier = 1.1\n",
    "default_batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fcfdd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular el presupuesto de privacidad\n",
    "def compute_privacy_budget(n, batch_size, noise_multiplier, epochs, delta=1e-5):\n",
    "    try:\n",
    "        eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "            n=n, batch_size=batch_size, noise_multiplier=noise_multiplier,\n",
    "            epochs=epochs, delta=delta\n",
    "        )[0]\n",
    "        return eps\n",
    "    except Exception as e:\n",
    "        print(f\"Error al calcular el presupuesto de privacidad: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Definir la red neuronal con tf.keras\n",
    "def create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=False,\n",
    "                 num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                 noise_multiplier=default_noise_multiplier):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation='relu', input_shape=(input_size,)))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if use_dp:\n",
    "        optimizer = DPKerasSGDOptimizer(\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "            num_microbatches=num_microbatches,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Función para encontrar el umbral óptimo\n",
    "def find_optimal_threshold(y_true, y_pred_prob):\n",
    "    thresholds = np.arange(0.1, 0.9, 0.1)\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "    for t in thresholds:\n",
    "        y_pred = (y_pred_prob > t).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = t\n",
    "    return best_threshold\n",
    "\n",
    "# Función para entrenar el modelo\n",
    "def train_model(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=False,\n",
    "                num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                noise_multiplier=default_noise_multiplier):\n",
    "    if use_dp and batch_size % num_microbatches != 0:\n",
    "        raise ValueError(f\"batch_size ({batch_size}) must be divisible by num_microbatches ({num_microbatches})\")\n",
    "\n",
    "    model = create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=use_dp,\n",
    "                         num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                         noise_multiplier=noise_multiplier)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    \n",
    "    y_pred_prob_test = model.predict(X_test, batch_size=batch_size).flatten()\n",
    "    optimal_threshold = 0.4 #find_optimal_threshold(y_test, y_pred_prob_test)\n",
    "    print(f\"Optimal threshold: {optimal_threshold:.2f}\")\n",
    "    y_pred_test = (y_pred_prob_test > optimal_threshold).astype(int)\n",
    "    \n",
    "    return y_pred_prob_test, y_pred_test\n",
    "\n",
    "# Función para evaluar el modelo\n",
    "def evaluate_model(y_true, y_pred, y_pred_prob):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    actual_negatives, actual_positives = conf_matrix[0].sum(), conf_matrix[1].sum()\n",
    "    false_positive_rate = conf_matrix[0][1] / actual_negatives if actual_negatives > 0 else 0\n",
    "    false_negative_rate = conf_matrix[1][0] / actual_positives if actual_positives > 0 else 0\n",
    "    return {\n",
    "        'ROC AUC': roc_auc_score(y_true, y_pred_prob),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Type I Error': false_positive_rate,\n",
    "        'Type II Error': false_negative_rate\n",
    "    }\n",
    "\n",
    "# Función para ejecutar múltiples iteraciones y calcular estadísticas\n",
    "def run_iterations(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp, n_iterations,\n",
    "                   num_microbatches, l2_norm_clip, noise_multiplier):\n",
    "    results = []\n",
    "    for _ in range(n_iterations):\n",
    "        y_pred_prob_test, y_pred_test = train_model(\n",
    "            X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=use_dp,\n",
    "            num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier\n",
    "        )\n",
    "        result = evaluate_model(y_test, y_pred_test, y_pred_prob_test)\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Función para calcular estadísticas\n",
    "def compute_statistics(df):\n",
    "    stats = {\n",
    "        'mean': df.mean(),\n",
    "        'min': df.min(),\n",
    "        'max': df.max()\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "# Función para preparar datos con un tamaño de muestra específico\n",
    "def prepare_data(X, y, sample_size_ratio, batch_size):\n",
    "    if sample_size_ratio < 1.0:\n",
    "        X_sample, _, y_sample, _ = train_test_split(X, y, train_size=sample_size_ratio, random_state=42, stratify=y)\n",
    "    else:\n",
    "        X_sample, y_sample = X, y\n",
    "\n",
    "    # Dividir en train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42, stratify=y_sample)\n",
    "\n",
    "    # Skip SMOTEENN as per previous recommendation\n",
    "    X_train_filtered, y_train_filtered = X_train.values, y_train.values\n",
    "    X_test_filtered, y_test_filtered = X_test.values, y_test.values\n",
    "\n",
    "    return X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered, len(X_train_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac5b4b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experimentos con tamaño de muestra completo (100%) ===\n",
      "Entrenando modelo sin DP...\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3574 - accuracy: 0.8769 - val_loss: 0.3129 - val_accuracy: 0.8843\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 546us/step - loss: 0.3130 - accuracy: 0.8902 - val_loss: 0.2973 - val_accuracy: 0.8935\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.2973 - accuracy: 0.8928 - val_loss: 0.2853 - val_accuracy: 0.8945\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.2841 - accuracy: 0.8934 - val_loss: 0.2731 - val_accuracy: 0.8940\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 539us/step - loss: 0.2694 - accuracy: 0.8946 - val_loss: 0.2602 - val_accuracy: 0.8956\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.2589 - accuracy: 0.8969 - val_loss: 0.2512 - val_accuracy: 0.8980\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.2502 - accuracy: 0.8981 - val_loss: 0.2457 - val_accuracy: 0.8990\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.2454 - accuracy: 0.9005 - val_loss: 0.2420 - val_accuracy: 0.8983\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 552us/step - loss: 0.2421 - accuracy: 0.9006 - val_loss: 0.2393 - val_accuracy: 0.9004\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.2392 - accuracy: 0.9009 - val_loss: 0.2394 - val_accuracy: 0.8976\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 552us/step - loss: 0.2369 - accuracy: 0.9016 - val_loss: 0.2363 - val_accuracy: 0.9022\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 547us/step - loss: 0.2353 - accuracy: 0.9013 - val_loss: 0.2355 - val_accuracy: 0.9022\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.2347 - accuracy: 0.9007 - val_loss: 0.2354 - val_accuracy: 0.9022\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.2329 - accuracy: 0.9008 - val_loss: 0.2337 - val_accuracy: 0.9015\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.2323 - accuracy: 0.9018 - val_loss: 0.2345 - val_accuracy: 0.9005\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.2306 - accuracy: 0.9010 - val_loss: 0.2316 - val_accuracy: 0.9031\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.2301 - accuracy: 0.9016 - val_loss: 0.2306 - val_accuracy: 0.9040\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.2291 - accuracy: 0.9015 - val_loss: 0.2299 - val_accuracy: 0.9040\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.2284 - accuracy: 0.9019 - val_loss: 0.2290 - val_accuracy: 0.9031\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 552us/step - loss: 0.2280 - accuracy: 0.9022 - val_loss: 0.2296 - val_accuracy: 0.9039\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.2271 - accuracy: 0.9014 - val_loss: 0.2282 - val_accuracy: 0.9040\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 564us/step - loss: 0.2261 - accuracy: 0.9017 - val_loss: 0.2282 - val_accuracy: 0.9043\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 546us/step - loss: 0.2257 - accuracy: 0.9023 - val_loss: 0.2306 - val_accuracy: 0.9019\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.2258 - accuracy: 0.9038 - val_loss: 0.2272 - val_accuracy: 0.9041\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 550us/step - loss: 0.2249 - accuracy: 0.9028 - val_loss: 0.2272 - val_accuracy: 0.9046\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 559us/step - loss: 0.2243 - accuracy: 0.9035 - val_loss: 0.2263 - val_accuracy: 0.9039\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.2238 - accuracy: 0.9031 - val_loss: 0.2287 - val_accuracy: 0.9042\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 597us/step - loss: 0.2233 - accuracy: 0.9035 - val_loss: 0.2258 - val_accuracy: 0.9042\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.2230 - accuracy: 0.9039 - val_loss: 0.2257 - val_accuracy: 0.9041\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.2224 - accuracy: 0.9036 - val_loss: 0.2252 - val_accuracy: 0.9036\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.2230 - accuracy: 0.9033 - val_loss: 0.2250 - val_accuracy: 0.9035\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.2229 - accuracy: 0.9034 - val_loss: 0.2257 - val_accuracy: 0.9029\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 547us/step - loss: 0.2223 - accuracy: 0.9036 - val_loss: 0.2297 - val_accuracy: 0.9036\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.2216 - accuracy: 0.9027 - val_loss: 0.2307 - val_accuracy: 0.9027\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.2213 - accuracy: 0.9042 - val_loss: 0.2248 - val_accuracy: 0.9028\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.2219 - accuracy: 0.9033 - val_loss: 0.2242 - val_accuracy: 0.9036\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.2205 - accuracy: 0.9035 - val_loss: 0.2243 - val_accuracy: 0.9040\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.2205 - accuracy: 0.9043 - val_loss: 0.2240 - val_accuracy: 0.9030\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.2208 - accuracy: 0.9046 - val_loss: 0.2251 - val_accuracy: 0.9039\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.2201 - accuracy: 0.9050 - val_loss: 0.2237 - val_accuracy: 0.9037\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.2203 - accuracy: 0.9045 - val_loss: 0.2250 - val_accuracy: 0.9037\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.2197 - accuracy: 0.9035 - val_loss: 0.2242 - val_accuracy: 0.9025\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.2194 - accuracy: 0.9046 - val_loss: 0.2231 - val_accuracy: 0.9036\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 553us/step - loss: 0.2196 - accuracy: 0.9048 - val_loss: 0.2227 - val_accuracy: 0.9041\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 553us/step - loss: 0.2191 - accuracy: 0.9045 - val_loss: 0.2236 - val_accuracy: 0.9034\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.2185 - accuracy: 0.9046 - val_loss: 0.2227 - val_accuracy: 0.9048\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.2190 - accuracy: 0.9048 - val_loss: 0.2238 - val_accuracy: 0.9042\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.2185 - accuracy: 0.9053 - val_loss: 0.2253 - val_accuracy: 0.9020\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.2178 - accuracy: 0.9057 - val_loss: 0.2223 - val_accuracy: 0.9036\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 617us/step - loss: 0.2180 - accuracy: 0.9049 - val_loss: 0.2220 - val_accuracy: 0.9042\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 2s 809us/step - loss: 0.3434 - accuracy: 0.8841 - val_loss: 0.3143 - val_accuracy: 0.8864\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.3123 - accuracy: 0.8898 - val_loss: 0.2997 - val_accuracy: 0.8933\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 2s 669us/step - loss: 0.2983 - accuracy: 0.8920 - val_loss: 0.2859 - val_accuracy: 0.8932\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 657us/step - loss: 0.2850 - accuracy: 0.8936 - val_loss: 0.2736 - val_accuracy: 0.8944\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 2s 681us/step - loss: 0.2720 - accuracy: 0.8951 - val_loss: 0.2625 - val_accuracy: 0.8944\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 662us/step - loss: 0.2606 - accuracy: 0.8965 - val_loss: 0.2527 - val_accuracy: 0.8977\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 655us/step - loss: 0.2524 - accuracy: 0.8981 - val_loss: 0.2479 - val_accuracy: 0.8978\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 656us/step - loss: 0.2470 - accuracy: 0.8994 - val_loss: 0.2422 - val_accuracy: 0.8989\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 651us/step - loss: 0.2426 - accuracy: 0.9000 - val_loss: 0.2393 - val_accuracy: 0.9000\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 2s 689us/step - loss: 0.2400 - accuracy: 0.9008 - val_loss: 0.2382 - val_accuracy: 0.9004\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 2s 688us/step - loss: 0.2380 - accuracy: 0.9009 - val_loss: 0.2357 - val_accuracy: 0.9000\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 2s 682us/step - loss: 0.2366 - accuracy: 0.9009 - val_loss: 0.2348 - val_accuracy: 0.8995\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 655us/step - loss: 0.2350 - accuracy: 0.9005 - val_loss: 0.2350 - val_accuracy: 0.9007\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 661us/step - loss: 0.2343 - accuracy: 0.9010 - val_loss: 0.2345 - val_accuracy: 0.9006\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 2s 695us/step - loss: 0.2336 - accuracy: 0.9012 - val_loss: 0.2326 - val_accuracy: 0.9006\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 662us/step - loss: 0.2333 - accuracy: 0.9009 - val_loss: 0.2356 - val_accuracy: 0.8991\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 2s 667us/step - loss: 0.2319 - accuracy: 0.9017 - val_loss: 0.2327 - val_accuracy: 0.9009\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 659us/step - loss: 0.2314 - accuracy: 0.9017 - val_loss: 0.2325 - val_accuracy: 0.9017\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 654us/step - loss: 0.2309 - accuracy: 0.9012 - val_loss: 0.2338 - val_accuracy: 0.9007\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 2s 682us/step - loss: 0.2306 - accuracy: 0.9018 - val_loss: 0.2325 - val_accuracy: 0.9015\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 2s 677us/step - loss: 0.2291 - accuracy: 0.9014 - val_loss: 0.2296 - val_accuracy: 0.9026\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 2s 734us/step - loss: 0.2286 - accuracy: 0.9011 - val_loss: 0.2293 - val_accuracy: 0.9028\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 2s 669us/step - loss: 0.2283 - accuracy: 0.9016 - val_loss: 0.2294 - val_accuracy: 0.9029\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.2278 - accuracy: 0.9024 - val_loss: 0.2295 - val_accuracy: 0.9032\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 2s 732us/step - loss: 0.2280 - accuracy: 0.9010 - val_loss: 0.2303 - val_accuracy: 0.9032\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 2s 707us/step - loss: 0.2267 - accuracy: 0.9020 - val_loss: 0.2295 - val_accuracy: 0.9027\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 2s 704us/step - loss: 0.2262 - accuracy: 0.9027 - val_loss: 0.2278 - val_accuracy: 0.9037\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 643us/step - loss: 0.2261 - accuracy: 0.9025 - val_loss: 0.2278 - val_accuracy: 0.9028\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 2s 685us/step - loss: 0.2262 - accuracy: 0.9026 - val_loss: 0.2276 - val_accuracy: 0.9039\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 661us/step - loss: 0.2253 - accuracy: 0.9025 - val_loss: 0.2311 - val_accuracy: 0.9019\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 2s 670us/step - loss: 0.2247 - accuracy: 0.9032 - val_loss: 0.2297 - val_accuracy: 0.9030\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 2s 739us/step - loss: 0.2254 - accuracy: 0.9021 - val_loss: 0.2266 - val_accuracy: 0.9040\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 2s 721us/step - loss: 0.2245 - accuracy: 0.9031 - val_loss: 0.2262 - val_accuracy: 0.9028\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 2s 707us/step - loss: 0.2244 - accuracy: 0.9030 - val_loss: 0.2265 - val_accuracy: 0.9024\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 661us/step - loss: 0.2243 - accuracy: 0.9035 - val_loss: 0.2260 - val_accuracy: 0.9034\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 663us/step - loss: 0.2232 - accuracy: 0.9023 - val_loss: 0.2259 - val_accuracy: 0.9018\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 2s 675us/step - loss: 0.2235 - accuracy: 0.9035 - val_loss: 0.2253 - val_accuracy: 0.9031\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 2s 695us/step - loss: 0.2241 - accuracy: 0.9031 - val_loss: 0.2264 - val_accuracy: 0.9031\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 2s 672us/step - loss: 0.2228 - accuracy: 0.9036 - val_loss: 0.2251 - val_accuracy: 0.9036\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 2s 668us/step - loss: 0.2226 - accuracy: 0.9040 - val_loss: 0.2256 - val_accuracy: 0.9040\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 657us/step - loss: 0.2224 - accuracy: 0.9036 - val_loss: 0.2248 - val_accuracy: 0.9030\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 2s 667us/step - loss: 0.2218 - accuracy: 0.9041 - val_loss: 0.2270 - val_accuracy: 0.9032\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 2s 752us/step - loss: 0.2224 - accuracy: 0.9030 - val_loss: 0.2242 - val_accuracy: 0.9041\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 2s 686us/step - loss: 0.2215 - accuracy: 0.9039 - val_loss: 0.2246 - val_accuracy: 0.9053\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 2s 707us/step - loss: 0.2209 - accuracy: 0.9041 - val_loss: 0.2237 - val_accuracy: 0.9041\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 2s 668us/step - loss: 0.2216 - accuracy: 0.9037 - val_loss: 0.2249 - val_accuracy: 0.9040\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 2s 697us/step - loss: 0.2204 - accuracy: 0.9045 - val_loss: 0.2236 - val_accuracy: 0.9046\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 2s 685us/step - loss: 0.2207 - accuracy: 0.9041 - val_loss: 0.2237 - val_accuracy: 0.9043\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 628us/step - loss: 0.2205 - accuracy: 0.9045 - val_loss: 0.2230 - val_accuracy: 0.9045\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 658us/step - loss: 0.2196 - accuracy: 0.9037 - val_loss: 0.2235 - val_accuracy: 0.9049\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 2s 747us/step - loss: 0.3572 - accuracy: 0.8713 - val_loss: 0.3105 - val_accuracy: 0.8878\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 2s 812us/step - loss: 0.3095 - accuracy: 0.8910 - val_loss: 0.2967 - val_accuracy: 0.8933\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 2s 800us/step - loss: 0.2948 - accuracy: 0.8927 - val_loss: 0.2823 - val_accuracy: 0.8936\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 2s 724us/step - loss: 0.2805 - accuracy: 0.8941 - val_loss: 0.2683 - val_accuracy: 0.8944\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 620us/step - loss: 0.2660 - accuracy: 0.8956 - val_loss: 0.2569 - val_accuracy: 0.8967\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 644us/step - loss: 0.2556 - accuracy: 0.8977 - val_loss: 0.2495 - val_accuracy: 0.8998\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 626us/step - loss: 0.2479 - accuracy: 0.8994 - val_loss: 0.2450 - val_accuracy: 0.8993\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.2452 - accuracy: 0.9003 - val_loss: 0.2414 - val_accuracy: 0.8988\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.2414 - accuracy: 0.9005 - val_loss: 0.2391 - val_accuracy: 0.8991\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 621us/step - loss: 0.2404 - accuracy: 0.9004 - val_loss: 0.2386 - val_accuracy: 0.9001\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 658us/step - loss: 0.2377 - accuracy: 0.9010 - val_loss: 0.2362 - val_accuracy: 0.9014\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 629us/step - loss: 0.2376 - accuracy: 0.9009 - val_loss: 0.2352 - val_accuracy: 0.9009\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.2352 - accuracy: 0.9014 - val_loss: 0.2363 - val_accuracy: 0.9027\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 600us/step - loss: 0.2337 - accuracy: 0.9020 - val_loss: 0.2333 - val_accuracy: 0.9021\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.2333 - accuracy: 0.9017 - val_loss: 0.2324 - val_accuracy: 0.9005\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 621us/step - loss: 0.2320 - accuracy: 0.9017 - val_loss: 0.2334 - val_accuracy: 0.9009\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.2321 - accuracy: 0.9009 - val_loss: 0.2334 - val_accuracy: 0.9009\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.2312 - accuracy: 0.9017 - val_loss: 0.2305 - val_accuracy: 0.9024\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.2310 - accuracy: 0.9027 - val_loss: 0.2303 - val_accuracy: 0.9012\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 586us/step - loss: 0.2302 - accuracy: 0.9012 - val_loss: 0.2295 - val_accuracy: 0.9021\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 623us/step - loss: 0.2287 - accuracy: 0.9024 - val_loss: 0.2291 - val_accuracy: 0.9031\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.2280 - accuracy: 0.9029 - val_loss: 0.2296 - val_accuracy: 0.9040\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.2274 - accuracy: 0.9025 - val_loss: 0.2283 - val_accuracy: 0.9036\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 590us/step - loss: 0.2283 - accuracy: 0.9028 - val_loss: 0.2307 - val_accuracy: 0.9037\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 637us/step - loss: 0.2272 - accuracy: 0.9031 - val_loss: 0.2289 - val_accuracy: 0.9025\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.2261 - accuracy: 0.9027 - val_loss: 0.2271 - val_accuracy: 0.9039\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 586us/step - loss: 0.2264 - accuracy: 0.9031 - val_loss: 0.2269 - val_accuracy: 0.9034\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.2252 - accuracy: 0.9026 - val_loss: 0.2276 - val_accuracy: 0.9030\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 600us/step - loss: 0.2258 - accuracy: 0.9031 - val_loss: 0.2268 - val_accuracy: 0.9037\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 637us/step - loss: 0.2249 - accuracy: 0.9029 - val_loss: 0.2282 - val_accuracy: 0.9028\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 590us/step - loss: 0.2243 - accuracy: 0.9035 - val_loss: 0.2270 - val_accuracy: 0.9036\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.2241 - accuracy: 0.9043 - val_loss: 0.2261 - val_accuracy: 0.9026\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 588us/step - loss: 0.2240 - accuracy: 0.9034 - val_loss: 0.2258 - val_accuracy: 0.9040\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 619us/step - loss: 0.2232 - accuracy: 0.9034 - val_loss: 0.2256 - val_accuracy: 0.9037\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.2235 - accuracy: 0.9038 - val_loss: 0.2251 - val_accuracy: 0.9032\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 601us/step - loss: 0.2231 - accuracy: 0.9034 - val_loss: 0.2261 - val_accuracy: 0.9034\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.2226 - accuracy: 0.9039 - val_loss: 0.2251 - val_accuracy: 0.9048\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.2227 - accuracy: 0.9037 - val_loss: 0.2247 - val_accuracy: 0.9035\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 631us/step - loss: 0.2224 - accuracy: 0.9035 - val_loss: 0.2246 - val_accuracy: 0.9035\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 601us/step - loss: 0.2217 - accuracy: 0.9045 - val_loss: 0.2246 - val_accuracy: 0.9035\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 595us/step - loss: 0.2222 - accuracy: 0.9040 - val_loss: 0.2248 - val_accuracy: 0.9018\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.2223 - accuracy: 0.9046 - val_loss: 0.2243 - val_accuracy: 0.9027\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 634us/step - loss: 0.2213 - accuracy: 0.9043 - val_loss: 0.2251 - val_accuracy: 0.9039\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 618us/step - loss: 0.2211 - accuracy: 0.9050 - val_loss: 0.2249 - val_accuracy: 0.9040\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 613us/step - loss: 0.2207 - accuracy: 0.9037 - val_loss: 0.2243 - val_accuracy: 0.9037\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.2209 - accuracy: 0.9047 - val_loss: 0.2237 - val_accuracy: 0.9031\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 627us/step - loss: 0.2199 - accuracy: 0.9048 - val_loss: 0.2269 - val_accuracy: 0.9012\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 2s 691us/step - loss: 0.2205 - accuracy: 0.9041 - val_loss: 0.2268 - val_accuracy: 0.8999\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 636us/step - loss: 0.2201 - accuracy: 0.9045 - val_loss: 0.2234 - val_accuracy: 0.9036\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.2191 - accuracy: 0.9057 - val_loss: 0.2236 - val_accuracy: 0.9041\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 657us/step - loss: 0.3592 - accuracy: 0.8729 - val_loss: 0.3112 - val_accuracy: 0.8868\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 599us/step - loss: 0.3104 - accuracy: 0.8898 - val_loss: 0.2996 - val_accuracy: 0.8936\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 593us/step - loss: 0.2967 - accuracy: 0.8931 - val_loss: 0.2868 - val_accuracy: 0.8936\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 627us/step - loss: 0.2831 - accuracy: 0.8932 - val_loss: 0.2722 - val_accuracy: 0.8933\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.2674 - accuracy: 0.8949 - val_loss: 0.2595 - val_accuracy: 0.8955\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.2551 - accuracy: 0.8970 - val_loss: 0.2497 - val_accuracy: 0.8978\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 650us/step - loss: 0.2460 - accuracy: 0.8994 - val_loss: 0.2434 - val_accuracy: 0.8991\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 650us/step - loss: 0.2430 - accuracy: 0.8988 - val_loss: 0.2406 - val_accuracy: 0.9003\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 600us/step - loss: 0.2400 - accuracy: 0.9004 - val_loss: 0.2386 - val_accuracy: 0.9005\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.2376 - accuracy: 0.9013 - val_loss: 0.2397 - val_accuracy: 0.9005\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 624us/step - loss: 0.2362 - accuracy: 0.9007 - val_loss: 0.2357 - val_accuracy: 0.9011\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 594us/step - loss: 0.2342 - accuracy: 0.9012 - val_loss: 0.2348 - val_accuracy: 0.9004\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.2334 - accuracy: 0.9011 - val_loss: 0.2341 - val_accuracy: 0.9015\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.2321 - accuracy: 0.9014 - val_loss: 0.2329 - val_accuracy: 0.9019\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 625us/step - loss: 0.2318 - accuracy: 0.9022 - val_loss: 0.2331 - val_accuracy: 0.9021\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 590us/step - loss: 0.2303 - accuracy: 0.9023 - val_loss: 0.2325 - val_accuracy: 0.9026\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.2296 - accuracy: 0.9015 - val_loss: 0.2316 - val_accuracy: 0.9024\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 613us/step - loss: 0.2288 - accuracy: 0.9023 - val_loss: 0.2308 - val_accuracy: 0.9030\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 586us/step - loss: 0.2279 - accuracy: 0.9026 - val_loss: 0.2297 - val_accuracy: 0.9022\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.2272 - accuracy: 0.9024 - val_loss: 0.2295 - val_accuracy: 0.9018\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.2267 - accuracy: 0.9031 - val_loss: 0.2295 - val_accuracy: 0.9034\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 616us/step - loss: 0.2260 - accuracy: 0.9034 - val_loss: 0.2292 - val_accuracy: 0.9026\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 588us/step - loss: 0.2260 - accuracy: 0.9027 - val_loss: 0.2290 - val_accuracy: 0.9027\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 586us/step - loss: 0.2249 - accuracy: 0.9028 - val_loss: 0.2281 - val_accuracy: 0.9030\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 2s 755us/step - loss: 0.2250 - accuracy: 0.9033 - val_loss: 0.2280 - val_accuracy: 0.9038\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 2s 818us/step - loss: 0.2241 - accuracy: 0.9033 - val_loss: 0.2294 - val_accuracy: 0.9025\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 2s 740us/step - loss: 0.2239 - accuracy: 0.9030 - val_loss: 0.2333 - val_accuracy: 0.9032\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 2s 703us/step - loss: 0.2238 - accuracy: 0.9030 - val_loss: 0.2263 - val_accuracy: 0.9015\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 2s 690us/step - loss: 0.2236 - accuracy: 0.9040 - val_loss: 0.2265 - val_accuracy: 0.9039\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 2s 729us/step - loss: 0.2231 - accuracy: 0.9039 - val_loss: 0.2264 - val_accuracy: 0.9022\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 2s 695us/step - loss: 0.2226 - accuracy: 0.9046 - val_loss: 0.2259 - val_accuracy: 0.9028\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 2s 724us/step - loss: 0.2221 - accuracy: 0.9031 - val_loss: 0.2274 - val_accuracy: 0.9027\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 2s 739us/step - loss: 0.2213 - accuracy: 0.9040 - val_loss: 0.2293 - val_accuracy: 0.9026\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 2s 695us/step - loss: 0.2218 - accuracy: 0.9032 - val_loss: 0.2257 - val_accuracy: 0.9030\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 2s 688us/step - loss: 0.2212 - accuracy: 0.9044 - val_loss: 0.2249 - val_accuracy: 0.9020\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 2s 728us/step - loss: 0.2208 - accuracy: 0.9049 - val_loss: 0.2270 - val_accuracy: 0.9037\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 2s 663us/step - loss: 0.2207 - accuracy: 0.9050 - val_loss: 0.2259 - val_accuracy: 0.9031\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 659us/step - loss: 0.2205 - accuracy: 0.9052 - val_loss: 0.2246 - val_accuracy: 0.9035\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 2s 699us/step - loss: 0.2200 - accuracy: 0.9043 - val_loss: 0.2245 - val_accuracy: 0.9039\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 2s 665us/step - loss: 0.2200 - accuracy: 0.9045 - val_loss: 0.2249 - val_accuracy: 0.9025\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 2s 673us/step - loss: 0.2194 - accuracy: 0.9041 - val_loss: 0.2237 - val_accuracy: 0.9031\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 2s 700us/step - loss: 0.2194 - accuracy: 0.9047 - val_loss: 0.2236 - val_accuracy: 0.9034\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 2s 681us/step - loss: 0.2193 - accuracy: 0.9051 - val_loss: 0.2235 - val_accuracy: 0.9040\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 2s 667us/step - loss: 0.2186 - accuracy: 0.9051 - val_loss: 0.2239 - val_accuracy: 0.9037\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 2s 722us/step - loss: 0.2184 - accuracy: 0.9050 - val_loss: 0.2232 - val_accuracy: 0.9031\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 2s 673us/step - loss: 0.2182 - accuracy: 0.9057 - val_loss: 0.2251 - val_accuracy: 0.9032\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 2s 664us/step - loss: 0.2178 - accuracy: 0.9051 - val_loss: 0.2249 - val_accuracy: 0.9034\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 2s 693us/step - loss: 0.2171 - accuracy: 0.9050 - val_loss: 0.2274 - val_accuracy: 0.9032\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 2s 682us/step - loss: 0.2173 - accuracy: 0.9056 - val_loss: 0.2234 - val_accuracy: 0.9028\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 2s 688us/step - loss: 0.2173 - accuracy: 0.9060 - val_loss: 0.2233 - val_accuracy: 0.9036\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 2s 690us/step - loss: 0.3500 - accuracy: 0.8832 - val_loss: 0.3141 - val_accuracy: 0.8853\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 2s 669us/step - loss: 0.3113 - accuracy: 0.8905 - val_loss: 0.2976 - val_accuracy: 0.8935\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 2s 740us/step - loss: 0.2975 - accuracy: 0.8927 - val_loss: 0.2845 - val_accuracy: 0.8937\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 2s 688us/step - loss: 0.2829 - accuracy: 0.8938 - val_loss: 0.2732 - val_accuracy: 0.8942\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 2s 705us/step - loss: 0.2690 - accuracy: 0.8945 - val_loss: 0.2600 - val_accuracy: 0.8951\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.2578 - accuracy: 0.8978 - val_loss: 0.2579 - val_accuracy: 0.8991\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 650us/step - loss: 0.2508 - accuracy: 0.8981 - val_loss: 0.2500 - val_accuracy: 0.8990\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 2s 682us/step - loss: 0.2462 - accuracy: 0.8994 - val_loss: 0.2432 - val_accuracy: 0.8982\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 643us/step - loss: 0.2437 - accuracy: 0.9000 - val_loss: 0.2412 - val_accuracy: 0.8984\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 659us/step - loss: 0.2408 - accuracy: 0.9000 - val_loss: 0.2407 - val_accuracy: 0.8988\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.2392 - accuracy: 0.9006 - val_loss: 0.2380 - val_accuracy: 0.8996\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 2s 686us/step - loss: 0.2379 - accuracy: 0.9011 - val_loss: 0.2367 - val_accuracy: 0.8996\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 2s 664us/step - loss: 0.2363 - accuracy: 0.9011 - val_loss: 0.2368 - val_accuracy: 0.8994\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 2s 691us/step - loss: 0.2361 - accuracy: 0.9006 - val_loss: 0.2365 - val_accuracy: 0.9006\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 660us/step - loss: 0.2348 - accuracy: 0.9010 - val_loss: 0.2365 - val_accuracy: 0.9003\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 658us/step - loss: 0.2341 - accuracy: 0.9012 - val_loss: 0.2336 - val_accuracy: 0.9014\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 2s 692us/step - loss: 0.2326 - accuracy: 0.9014 - val_loss: 0.2369 - val_accuracy: 0.8997\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 663us/step - loss: 0.2328 - accuracy: 0.9018 - val_loss: 0.2328 - val_accuracy: 0.9021\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 2s 693us/step - loss: 0.2312 - accuracy: 0.9011 - val_loss: 0.2364 - val_accuracy: 0.8998\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 2s 671us/step - loss: 0.2305 - accuracy: 0.9013 - val_loss: 0.2313 - val_accuracy: 0.9018\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 2s 668us/step - loss: 0.2307 - accuracy: 0.9019 - val_loss: 0.2335 - val_accuracy: 0.9024\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 2s 696us/step - loss: 0.2304 - accuracy: 0.9014 - val_loss: 0.2302 - val_accuracy: 0.9024\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 634us/step - loss: 0.2293 - accuracy: 0.9017 - val_loss: 0.2299 - val_accuracy: 0.9021\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 636us/step - loss: 0.2284 - accuracy: 0.9023 - val_loss: 0.2298 - val_accuracy: 0.9029\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 2s 678us/step - loss: 0.2277 - accuracy: 0.9026 - val_loss: 0.2292 - val_accuracy: 0.9043\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 647us/step - loss: 0.2276 - accuracy: 0.9020 - val_loss: 0.2286 - val_accuracy: 0.9027\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 2s 680us/step - loss: 0.2267 - accuracy: 0.9030 - val_loss: 0.2281 - val_accuracy: 0.9034\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 643us/step - loss: 0.2264 - accuracy: 0.9025 - val_loss: 0.2276 - val_accuracy: 0.9036\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.2262 - accuracy: 0.9027 - val_loss: 0.2274 - val_accuracy: 0.9043\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 2s 667us/step - loss: 0.2255 - accuracy: 0.9033 - val_loss: 0.2293 - val_accuracy: 0.9043\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.2250 - accuracy: 0.9031 - val_loss: 0.2274 - val_accuracy: 0.9034\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 627us/step - loss: 0.2243 - accuracy: 0.9038 - val_loss: 0.2263 - val_accuracy: 0.9042\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 570us/step - loss: 0.2244 - accuracy: 0.9034 - val_loss: 0.2264 - val_accuracy: 0.9029\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.2240 - accuracy: 0.9038 - val_loss: 0.2267 - val_accuracy: 0.9032\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 607us/step - loss: 0.2234 - accuracy: 0.9035 - val_loss: 0.2259 - val_accuracy: 0.9048\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 557us/step - loss: 0.2225 - accuracy: 0.9038 - val_loss: 0.2258 - val_accuracy: 0.9032\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 574us/step - loss: 0.2226 - accuracy: 0.9036 - val_loss: 0.2252 - val_accuracy: 0.9038\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 601us/step - loss: 0.2226 - accuracy: 0.9033 - val_loss: 0.2250 - val_accuracy: 0.9029\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.2216 - accuracy: 0.9048 - val_loss: 0.2279 - val_accuracy: 0.9037\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 574us/step - loss: 0.2213 - accuracy: 0.9042 - val_loss: 0.2247 - val_accuracy: 0.9043\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 601us/step - loss: 0.2209 - accuracy: 0.9049 - val_loss: 0.2254 - val_accuracy: 0.9046\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 570us/step - loss: 0.2212 - accuracy: 0.9041 - val_loss: 0.2248 - val_accuracy: 0.9036\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.2209 - accuracy: 0.9041 - val_loss: 0.2240 - val_accuracy: 0.9049\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 627us/step - loss: 0.2202 - accuracy: 0.9053 - val_loss: 0.2237 - val_accuracy: 0.9038\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.2200 - accuracy: 0.9046 - val_loss: 0.2233 - val_accuracy: 0.9032\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 570us/step - loss: 0.2194 - accuracy: 0.9040 - val_loss: 0.2245 - val_accuracy: 0.9026\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 602us/step - loss: 0.2190 - accuracy: 0.9051 - val_loss: 0.2289 - val_accuracy: 0.9028\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.2192 - accuracy: 0.9056 - val_loss: 0.2259 - val_accuracy: 0.9045\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 601us/step - loss: 0.2190 - accuracy: 0.9053 - val_loss: 0.2237 - val_accuracy: 0.9042\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.2188 - accuracy: 0.9051 - val_loss: 0.2226 - val_accuracy: 0.9027\n",
      "Optimal threshold: 0.40\n"
     ]
    }
   ],
   "source": [
    "# 1. Experimentos con tamaño de muestra completo (100%) como referencia\n",
    "print(\"\\n=== Experimentos con tamaño de muestra completo (100%) ===\")\n",
    "X_train_full, X_test_full, y_train_full, y_test_full, n_full = prepare_data(X, y, 1.0, default_batch_size)\n",
    "\n",
    "# Entrenar modelo sin DP (baseline)\n",
    "print(\"Entrenando modelo sin DP...\")\n",
    "results_no_dp = run_iterations(\n",
    "    X_train_full, y_train_full, X_test_full, y_test_full,\n",
    "    default_batch_size, epochs, use_dp=False, n_iterations=n_iterations,\n",
    "    num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=None\n",
    ")\n",
    "results_no_dp_stats = compute_statistics(results_no_dp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0d83cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo con noise_multiplier=1.1...\n",
      "DP-SGD with sampling rate = 0.0442% and noise_multiplier = 1.1 iterated over 113025 steps satisfies differential privacy with eps = 0.96 and delta = 1e-05.\n",
      "The optimal RDP order is 18.0.\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.5370 - accuracy: 0.7778 - val_loss: 0.4235 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.4114 - accuracy: 0.8829 - val_loss: 0.4008 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.4011 - accuracy: 0.8830 - val_loss: 0.3961 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3987 - accuracy: 0.8830 - val_loss: 0.3929 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3944 - accuracy: 0.8830 - val_loss: 0.3901 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3922 - accuracy: 0.8831 - val_loss: 0.3874 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3898 - accuracy: 0.8830 - val_loss: 0.3848 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3888 - accuracy: 0.8830 - val_loss: 0.3822 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3847 - accuracy: 0.8830 - val_loss: 0.3797 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3820 - accuracy: 0.8830 - val_loss: 0.3773 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3802 - accuracy: 0.8830 - val_loss: 0.3749 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3780 - accuracy: 0.8830 - val_loss: 0.3725 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3745 - accuracy: 0.8830 - val_loss: 0.3702 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3678 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3702 - accuracy: 0.8830 - val_loss: 0.3657 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.3690 - accuracy: 0.8830 - val_loss: 0.3636 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3670 - accuracy: 0.8830 - val_loss: 0.3615 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3652 - accuracy: 0.8830 - val_loss: 0.3596 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3643 - accuracy: 0.8830 - val_loss: 0.3578 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3614 - accuracy: 0.8830 - val_loss: 0.3561 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3604 - accuracy: 0.8830 - val_loss: 0.3545 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3594 - accuracy: 0.8830 - val_loss: 0.3529 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.3513 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3561 - accuracy: 0.8830 - val_loss: 0.3499 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3551 - accuracy: 0.8830 - val_loss: 0.3485 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3537 - accuracy: 0.8830 - val_loss: 0.3471 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3525 - accuracy: 0.8830 - val_loss: 0.3458 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3507 - accuracy: 0.8830 - val_loss: 0.3445 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3499 - accuracy: 0.8830 - val_loss: 0.3433 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3481 - accuracy: 0.8831 - val_loss: 0.3421 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3410 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3472 - accuracy: 0.8830 - val_loss: 0.3399 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3456 - accuracy: 0.8831 - val_loss: 0.3388 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3441 - accuracy: 0.8830 - val_loss: 0.3378 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 526us/step - loss: 0.3439 - accuracy: 0.8830 - val_loss: 0.3367 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3434 - accuracy: 0.8831 - val_loss: 0.3358 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3428 - accuracy: 0.8829 - val_loss: 0.3349 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3405 - accuracy: 0.8831 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3402 - accuracy: 0.8832 - val_loss: 0.3333 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3391 - accuracy: 0.8831 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3385 - accuracy: 0.8830 - val_loss: 0.3318 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3378 - accuracy: 0.8832 - val_loss: 0.3312 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 564us/step - loss: 0.3371 - accuracy: 0.8831 - val_loss: 0.3305 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3373 - accuracy: 0.8830 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3362 - accuracy: 0.8832 - val_loss: 0.3293 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3359 - accuracy: 0.8831 - val_loss: 0.3288 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3348 - accuracy: 0.8831 - val_loss: 0.3283 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3351 - accuracy: 0.8833 - val_loss: 0.3278 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3342 - accuracy: 0.8835 - val_loss: 0.3273 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3332 - accuracy: 0.8834 - val_loss: 0.3268 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.4247 - accuracy: 0.8799 - val_loss: 0.3902 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 532us/step - loss: 0.3952 - accuracy: 0.8830 - val_loss: 0.3837 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3873 - accuracy: 0.8829 - val_loss: 0.3795 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3846 - accuracy: 0.8830 - val_loss: 0.3759 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3816 - accuracy: 0.8830 - val_loss: 0.3727 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3784 - accuracy: 0.8830 - val_loss: 0.3696 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3755 - accuracy: 0.8830 - val_loss: 0.3667 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3730 - accuracy: 0.8830 - val_loss: 0.3639 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3690 - accuracy: 0.8830 - val_loss: 0.3612 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.3667 - accuracy: 0.8830 - val_loss: 0.3583 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 2s 729us/step - loss: 0.3637 - accuracy: 0.8830 - val_loss: 0.3555 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 2s 707us/step - loss: 0.3616 - accuracy: 0.8830 - val_loss: 0.3528 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3584 - accuracy: 0.8830 - val_loss: 0.3507 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 604us/step - loss: 0.3562 - accuracy: 0.8830 - val_loss: 0.3488 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3536 - accuracy: 0.8831 - val_loss: 0.3473 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3532 - accuracy: 0.8830 - val_loss: 0.3458 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3520 - accuracy: 0.8830 - val_loss: 0.3445 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.3505 - accuracy: 0.8830 - val_loss: 0.3433 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3484 - accuracy: 0.8830 - val_loss: 0.3421 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 574us/step - loss: 0.3480 - accuracy: 0.8829 - val_loss: 0.3410 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.3475 - accuracy: 0.8831 - val_loss: 0.3399 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3472 - accuracy: 0.8830 - val_loss: 0.3389 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3452 - accuracy: 0.8831 - val_loss: 0.3379 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 603us/step - loss: 0.3448 - accuracy: 0.8831 - val_loss: 0.3370 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3430 - accuracy: 0.8831 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3421 - accuracy: 0.8830 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3405 - accuracy: 0.8831 - val_loss: 0.3345 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 578us/step - loss: 0.3414 - accuracy: 0.8832 - val_loss: 0.3338 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 607us/step - loss: 0.3401 - accuracy: 0.8832 - val_loss: 0.3331 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 574us/step - loss: 0.3397 - accuracy: 0.8830 - val_loss: 0.3324 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3383 - accuracy: 0.8831 - val_loss: 0.3318 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3379 - accuracy: 0.8832 - val_loss: 0.3313 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 623us/step - loss: 0.3386 - accuracy: 0.8831 - val_loss: 0.3306 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.3363 - accuracy: 0.8832 - val_loss: 0.3301 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 2s 681us/step - loss: 0.3360 - accuracy: 0.8833 - val_loss: 0.3296 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 568us/step - loss: 0.3357 - accuracy: 0.8832 - val_loss: 0.3291 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 607us/step - loss: 0.3354 - accuracy: 0.8834 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.3349 - accuracy: 0.8835 - val_loss: 0.3282 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.3350 - accuracy: 0.8835 - val_loss: 0.3278 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 629us/step - loss: 0.3349 - accuracy: 0.8835 - val_loss: 0.3274 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3330 - accuracy: 0.8835 - val_loss: 0.3270 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3326 - accuracy: 0.8834 - val_loss: 0.3267 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3340 - accuracy: 0.8834 - val_loss: 0.3263 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3330 - accuracy: 0.8836 - val_loss: 0.3260 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 638us/step - loss: 0.3319 - accuracy: 0.8837 - val_loss: 0.3257 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 596us/step - loss: 0.3322 - accuracy: 0.8835 - val_loss: 0.3254 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.3328 - accuracy: 0.8840 - val_loss: 0.3251 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3313 - accuracy: 0.8835 - val_loss: 0.3248 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3308 - accuracy: 0.8840 - val_loss: 0.3246 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 616us/step - loss: 0.3304 - accuracy: 0.8839 - val_loss: 0.3243 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.5560 - accuracy: 0.7431 - val_loss: 0.4056 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.4018 - accuracy: 0.8828 - val_loss: 0.3862 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.3914 - accuracy: 0.8830 - val_loss: 0.3817 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.3886 - accuracy: 0.8830 - val_loss: 0.3782 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 631us/step - loss: 0.3847 - accuracy: 0.8830 - val_loss: 0.3748 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.3819 - accuracy: 0.8830 - val_loss: 0.3720 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.3796 - accuracy: 0.8830 - val_loss: 0.3696 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 604us/step - loss: 0.3771 - accuracy: 0.8830 - val_loss: 0.3676 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 625us/step - loss: 0.3741 - accuracy: 0.8830 - val_loss: 0.3659 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.3726 - accuracy: 0.8830 - val_loss: 0.3643 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3692 - accuracy: 0.8830 - val_loss: 0.3627 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.3690 - accuracy: 0.8830 - val_loss: 0.3612 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 605us/step - loss: 0.3687 - accuracy: 0.8830 - val_loss: 0.3597 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 607us/step - loss: 0.3665 - accuracy: 0.8830 - val_loss: 0.3583 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 559us/step - loss: 0.3645 - accuracy: 0.8830 - val_loss: 0.3568 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3637 - accuracy: 0.8830 - val_loss: 0.3555 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.3619 - accuracy: 0.8830 - val_loss: 0.3542 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 598us/step - loss: 0.3603 - accuracy: 0.8830 - val_loss: 0.3528 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3584 - accuracy: 0.8830 - val_loss: 0.3515 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3571 - accuracy: 0.8830 - val_loss: 0.3503 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3570 - accuracy: 0.8830 - val_loss: 0.3491 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3555 - accuracy: 0.8830 - val_loss: 0.3479 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3543 - accuracy: 0.8830 - val_loss: 0.3467 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3525 - accuracy: 0.8830 - val_loss: 0.3457 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3518 - accuracy: 0.8830 - val_loss: 0.3445 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3496 - accuracy: 0.8830 - val_loss: 0.3435 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3488 - accuracy: 0.8830 - val_loss: 0.3425 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3489 - accuracy: 0.8830 - val_loss: 0.3415 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3473 - accuracy: 0.8830 - val_loss: 0.3406 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3473 - accuracy: 0.8830 - val_loss: 0.3397 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3465 - accuracy: 0.8830 - val_loss: 0.3388 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3441 - accuracy: 0.8831 - val_loss: 0.3379 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3432 - accuracy: 0.8830 - val_loss: 0.3372 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3412 - accuracy: 0.8830 - val_loss: 0.3363 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3420 - accuracy: 0.8829 - val_loss: 0.3355 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3414 - accuracy: 0.8829 - val_loss: 0.3348 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3406 - accuracy: 0.8831 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3405 - accuracy: 0.8830 - val_loss: 0.3335 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3391 - accuracy: 0.8830 - val_loss: 0.3328 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3390 - accuracy: 0.8830 - val_loss: 0.3322 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3367 - accuracy: 0.8831 - val_loss: 0.3316 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3386 - accuracy: 0.8830 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3384 - accuracy: 0.8832 - val_loss: 0.3305 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3360 - accuracy: 0.8830 - val_loss: 0.3301 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3357 - accuracy: 0.8831 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3350 - accuracy: 0.8830 - val_loss: 0.3290 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3343 - accuracy: 0.8831 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3345 - accuracy: 0.8831 - val_loss: 0.3281 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 469us/step - loss: 0.3337 - accuracy: 0.8831 - val_loss: 0.3277 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.3338 - accuracy: 0.8833 - val_loss: 0.3273 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.6992 - accuracy: 0.6282 - val_loss: 0.4259 - val_accuracy: 0.8827\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.4134 - accuracy: 0.8814 - val_loss: 0.3968 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3999 - accuracy: 0.8827 - val_loss: 0.3925 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 472us/step - loss: 0.3967 - accuracy: 0.8828 - val_loss: 0.3898 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3961 - accuracy: 0.8829 - val_loss: 0.3873 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3912 - accuracy: 0.8829 - val_loss: 0.3851 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3908 - accuracy: 0.8830 - val_loss: 0.3829 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3883 - accuracy: 0.8830 - val_loss: 0.3807 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3860 - accuracy: 0.8830 - val_loss: 0.3787 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3853 - accuracy: 0.8830 - val_loss: 0.3767 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 472us/step - loss: 0.3834 - accuracy: 0.8829 - val_loss: 0.3748 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3822 - accuracy: 0.8830 - val_loss: 0.3730 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 478us/step - loss: 0.3794 - accuracy: 0.8830 - val_loss: 0.3712 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3782 - accuracy: 0.8830 - val_loss: 0.3695 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3756 - accuracy: 0.8830 - val_loss: 0.3678 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3743 - accuracy: 0.8830 - val_loss: 0.3662 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3730 - accuracy: 0.8830 - val_loss: 0.3647 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3700 - accuracy: 0.8830 - val_loss: 0.3632 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3696 - accuracy: 0.8830 - val_loss: 0.3617 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 474us/step - loss: 0.3685 - accuracy: 0.8830 - val_loss: 0.3602 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3664 - accuracy: 0.8830 - val_loss: 0.3589 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3659 - accuracy: 0.8830 - val_loss: 0.3575 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3638 - accuracy: 0.8830 - val_loss: 0.3562 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3630 - accuracy: 0.8830 - val_loss: 0.3549 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3621 - accuracy: 0.8830 - val_loss: 0.3537 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3611 - accuracy: 0.8830 - val_loss: 0.3525 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3592 - accuracy: 0.8830 - val_loss: 0.3514 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.3502 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3568 - accuracy: 0.8830 - val_loss: 0.3490 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3573 - accuracy: 0.8830 - val_loss: 0.3480 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3551 - accuracy: 0.8830 - val_loss: 0.3470 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3545 - accuracy: 0.8830 - val_loss: 0.3459 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3523 - accuracy: 0.8830 - val_loss: 0.3448 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3507 - accuracy: 0.8830 - val_loss: 0.3438 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3515 - accuracy: 0.8830 - val_loss: 0.3428 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3494 - accuracy: 0.8831 - val_loss: 0.3419 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3492 - accuracy: 0.8830 - val_loss: 0.3409 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3489 - accuracy: 0.8830 - val_loss: 0.3401 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3477 - accuracy: 0.8830 - val_loss: 0.3392 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3463 - accuracy: 0.8829 - val_loss: 0.3384 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3461 - accuracy: 0.8830 - val_loss: 0.3376 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3454 - accuracy: 0.8830 - val_loss: 0.3369 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3442 - accuracy: 0.8829 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3430 - accuracy: 0.8829 - val_loss: 0.3354 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3431 - accuracy: 0.8830 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3421 - accuracy: 0.8831 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3428 - accuracy: 0.8831 - val_loss: 0.3335 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3413 - accuracy: 0.8831 - val_loss: 0.3329 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3415 - accuracy: 0.8832 - val_loss: 0.3324 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3397 - accuracy: 0.8830 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "   1/2261 [..............................] - ETA: 0s - loss: 0.5626 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.4193 - accuracy: 0.8792 - val_loss: 0.3899 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3964 - accuracy: 0.8829 - val_loss: 0.3861 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3938 - accuracy: 0.8830 - val_loss: 0.3832 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3894 - accuracy: 0.8829 - val_loss: 0.3806 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3865 - accuracy: 0.8830 - val_loss: 0.3781 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3835 - accuracy: 0.8830 - val_loss: 0.3758 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3818 - accuracy: 0.8830 - val_loss: 0.3737 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3787 - accuracy: 0.8830 - val_loss: 0.3715 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3764 - accuracy: 0.8830 - val_loss: 0.3696 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.3761 - accuracy: 0.8830 - val_loss: 0.3677 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 2s 711us/step - loss: 0.3714 - accuracy: 0.8830 - val_loss: 0.3658 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3641 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3696 - accuracy: 0.8830 - val_loss: 0.3624 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 620us/step - loss: 0.3678 - accuracy: 0.8830 - val_loss: 0.3608 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3648 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 2s 687us/step - loss: 0.3650 - accuracy: 0.8830 - val_loss: 0.3576 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 612us/step - loss: 0.3625 - accuracy: 0.8830 - val_loss: 0.3561 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 636us/step - loss: 0.3611 - accuracy: 0.8830 - val_loss: 0.3547 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 626us/step - loss: 0.3598 - accuracy: 0.8830 - val_loss: 0.3533 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 636us/step - loss: 0.3593 - accuracy: 0.8830 - val_loss: 0.3520 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 634us/step - loss: 0.3564 - accuracy: 0.8830 - val_loss: 0.3506 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 2s 685us/step - loss: 0.3557 - accuracy: 0.8830 - val_loss: 0.3494 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 651us/step - loss: 0.3550 - accuracy: 0.8830 - val_loss: 0.3482 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 647us/step - loss: 0.3530 - accuracy: 0.8830 - val_loss: 0.3470 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 654us/step - loss: 0.3526 - accuracy: 0.8830 - val_loss: 0.3459 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 640us/step - loss: 0.3512 - accuracy: 0.8830 - val_loss: 0.3448 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 606us/step - loss: 0.3495 - accuracy: 0.8830 - val_loss: 0.3437 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.3494 - accuracy: 0.8830 - val_loss: 0.3427 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 633us/step - loss: 0.3474 - accuracy: 0.8830 - val_loss: 0.3417 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 601us/step - loss: 0.3472 - accuracy: 0.8830 - val_loss: 0.3408 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 590us/step - loss: 0.3462 - accuracy: 0.8830 - val_loss: 0.3399 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.3461 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 593us/step - loss: 0.3450 - accuracy: 0.8830 - val_loss: 0.3383 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3445 - accuracy: 0.8830 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3421 - accuracy: 0.8830 - val_loss: 0.3367 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3409 - accuracy: 0.8830 - val_loss: 0.3360 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3406 - accuracy: 0.8830 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3413 - accuracy: 0.8830 - val_loss: 0.3346 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3397 - accuracy: 0.8830 - val_loss: 0.3340 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3389 - accuracy: 0.8830 - val_loss: 0.3334 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3388 - accuracy: 0.8830 - val_loss: 0.3328 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3382 - accuracy: 0.8830 - val_loss: 0.3322 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 618us/step - loss: 0.3382 - accuracy: 0.8830 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.3370 - accuracy: 0.8830 - val_loss: 0.3312 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 588us/step - loss: 0.3360 - accuracy: 0.8830 - val_loss: 0.3307 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3363 - accuracy: 0.8830 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3359 - accuracy: 0.8830 - val_loss: 0.3298 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.3363 - accuracy: 0.8830 - val_loss: 0.3294 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 639us/step - loss: 0.3350 - accuracy: 0.8830 - val_loss: 0.3289 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.3343 - accuracy: 0.8830 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "Entrenando modelo con noise_multiplier=1.5...\n",
      "DP-SGD with sampling rate = 0.0442% and noise_multiplier = 1.5 iterated over 113025 steps satisfies differential privacy with eps = 0.566 and delta = 1e-05.\n",
      "The optimal RDP order is 33.0.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2261 [..............................] - ETA: 0s - loss: 0.5250 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "2261/2261 [==============================] - 1s 596us/step - loss: 0.4115 - accuracy: 0.8808 - val_loss: 0.3770 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3809 - accuracy: 0.8830 - val_loss: 0.3733 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 597us/step - loss: 0.3798 - accuracy: 0.8830 - val_loss: 0.3705 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3758 - accuracy: 0.8830 - val_loss: 0.3679 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3738 - accuracy: 0.8830 - val_loss: 0.3655 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3718 - accuracy: 0.8830 - val_loss: 0.3632 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3696 - accuracy: 0.8830 - val_loss: 0.3609 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.3677 - accuracy: 0.8830 - val_loss: 0.3589 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 574us/step - loss: 0.3658 - accuracy: 0.8830 - val_loss: 0.3570 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 570us/step - loss: 0.3633 - accuracy: 0.8830 - val_loss: 0.3552 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 557us/step - loss: 0.3622 - accuracy: 0.8830 - val_loss: 0.3535 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.3593 - accuracy: 0.8830 - val_loss: 0.3517 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3596 - accuracy: 0.8831 - val_loss: 0.3501 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3566 - accuracy: 0.8830 - val_loss: 0.3485 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3555 - accuracy: 0.8830 - val_loss: 0.3468 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.3535 - accuracy: 0.8831 - val_loss: 0.3452 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 616us/step - loss: 0.3535 - accuracy: 0.8831 - val_loss: 0.3436 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 558us/step - loss: 0.3519 - accuracy: 0.8830 - val_loss: 0.3422 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3494 - accuracy: 0.8830 - val_loss: 0.3408 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3484 - accuracy: 0.8830 - val_loss: 0.3393 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3379 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3463 - accuracy: 0.8830 - val_loss: 0.3366 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3439 - accuracy: 0.8831 - val_loss: 0.3356 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.3435 - accuracy: 0.8832 - val_loss: 0.3346 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3424 - accuracy: 0.8832 - val_loss: 0.3337 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3423 - accuracy: 0.8833 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3408 - accuracy: 0.8835 - val_loss: 0.3323 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3399 - accuracy: 0.8832 - val_loss: 0.3316 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3381 - accuracy: 0.8833 - val_loss: 0.3310 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3387 - accuracy: 0.8833 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3397 - accuracy: 0.8833 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 526us/step - loss: 0.3383 - accuracy: 0.8832 - val_loss: 0.3294 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3375 - accuracy: 0.8833 - val_loss: 0.3288 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3377 - accuracy: 0.8835 - val_loss: 0.3284 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3357 - accuracy: 0.8837 - val_loss: 0.3280 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3364 - accuracy: 0.8832 - val_loss: 0.3276 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3351 - accuracy: 0.8835 - val_loss: 0.3273 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3346 - accuracy: 0.8838 - val_loss: 0.3268 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3335 - accuracy: 0.8838 - val_loss: 0.3265 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3347 - accuracy: 0.8839 - val_loss: 0.3261 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3336 - accuracy: 0.8838 - val_loss: 0.3258 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3332 - accuracy: 0.8834 - val_loss: 0.3255 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3329 - accuracy: 0.8840 - val_loss: 0.3252 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3327 - accuracy: 0.8838 - val_loss: 0.3249 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 546us/step - loss: 0.3329 - accuracy: 0.8842 - val_loss: 0.3246 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 596us/step - loss: 0.3331 - accuracy: 0.8841 - val_loss: 0.3244 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3327 - accuracy: 0.8835 - val_loss: 0.3242 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3315 - accuracy: 0.8842 - val_loss: 0.3239 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3312 - accuracy: 0.8846 - val_loss: 0.3237 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3313 - accuracy: 0.8840 - val_loss: 0.3235 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.4506 - accuracy: 0.8737 - val_loss: 0.4004 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.4045 - accuracy: 0.8829 - val_loss: 0.3914 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3959 - accuracy: 0.8830 - val_loss: 0.3872 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3936 - accuracy: 0.8830 - val_loss: 0.3837 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3918 - accuracy: 0.8830 - val_loss: 0.3806 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3881 - accuracy: 0.8830 - val_loss: 0.3778 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3837 - accuracy: 0.8830 - val_loss: 0.3754 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3812 - accuracy: 0.8829 - val_loss: 0.3731 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3809 - accuracy: 0.8830 - val_loss: 0.3708 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3784 - accuracy: 0.8830 - val_loss: 0.3688 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3763 - accuracy: 0.8830 - val_loss: 0.3668 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3740 - accuracy: 0.8830 - val_loss: 0.3649 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3709 - accuracy: 0.8829 - val_loss: 0.3631 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3696 - accuracy: 0.8830 - val_loss: 0.3613 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3679 - accuracy: 0.8830 - val_loss: 0.3596 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3665 - accuracy: 0.8830 - val_loss: 0.3580 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3660 - accuracy: 0.8830 - val_loss: 0.3564 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3631 - accuracy: 0.8830 - val_loss: 0.3549 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3614 - accuracy: 0.8830 - val_loss: 0.3536 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3608 - accuracy: 0.8830 - val_loss: 0.3522 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 524us/step - loss: 0.3597 - accuracy: 0.8830 - val_loss: 0.3509 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3576 - accuracy: 0.8830 - val_loss: 0.3496 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3573 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3551 - accuracy: 0.8830 - val_loss: 0.3472 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3534 - accuracy: 0.8830 - val_loss: 0.3460 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3527 - accuracy: 0.8830 - val_loss: 0.3450 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3519 - accuracy: 0.8829 - val_loss: 0.3439 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3512 - accuracy: 0.8830 - val_loss: 0.3429 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3490 - accuracy: 0.8830 - val_loss: 0.3420 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3499 - accuracy: 0.8830 - val_loss: 0.3412 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3480 - accuracy: 0.8830 - val_loss: 0.3403 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3489 - accuracy: 0.8830 - val_loss: 0.3395 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3470 - accuracy: 0.8830 - val_loss: 0.3388 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3458 - accuracy: 0.8829 - val_loss: 0.3381 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3454 - accuracy: 0.8830 - val_loss: 0.3374 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3442 - accuracy: 0.8830 - val_loss: 0.3367 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3429 - accuracy: 0.8830 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3424 - accuracy: 0.8830 - val_loss: 0.3355 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3413 - accuracy: 0.8830 - val_loss: 0.3349 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3431 - accuracy: 0.8830 - val_loss: 0.3344 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3411 - accuracy: 0.8831 - val_loss: 0.3338 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3404 - accuracy: 0.8829 - val_loss: 0.3334 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3404 - accuracy: 0.8830 - val_loss: 0.3329 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 478us/step - loss: 0.3403 - accuracy: 0.8830 - val_loss: 0.3324 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3393 - accuracy: 0.8830 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3386 - accuracy: 0.8830 - val_loss: 0.3315 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3387 - accuracy: 0.8830 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3384 - accuracy: 0.8832 - val_loss: 0.3307 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3382 - accuracy: 0.8831 - val_loss: 0.3303 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3373 - accuracy: 0.8831 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 532us/step - loss: 0.5852 - accuracy: 0.7131 - val_loss: 0.4095 - val_accuracy: 0.8809\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.4081 - accuracy: 0.8812 - val_loss: 0.3920 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3987 - accuracy: 0.8822 - val_loss: 0.3876 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3957 - accuracy: 0.8824 - val_loss: 0.3840 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3913 - accuracy: 0.8827 - val_loss: 0.3810 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3887 - accuracy: 0.8828 - val_loss: 0.3785 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 553us/step - loss: 0.3866 - accuracy: 0.8829 - val_loss: 0.3763 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 2s 692us/step - loss: 0.3851 - accuracy: 0.8829 - val_loss: 0.3743 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.3807 - accuracy: 0.8830 - val_loss: 0.3724 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 552us/step - loss: 0.3812 - accuracy: 0.8829 - val_loss: 0.3706 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 578us/step - loss: 0.3792 - accuracy: 0.8830 - val_loss: 0.3688 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 550us/step - loss: 0.3763 - accuracy: 0.8830 - val_loss: 0.3672 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3755 - accuracy: 0.8830 - val_loss: 0.3655 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.3732 - accuracy: 0.8830 - val_loss: 0.3640 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 556us/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3625 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3610 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3684 - accuracy: 0.8830 - val_loss: 0.3596 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 557us/step - loss: 0.3674 - accuracy: 0.8830 - val_loss: 0.3582 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.3656 - accuracy: 0.8830 - val_loss: 0.3568 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 558us/step - loss: 0.3638 - accuracy: 0.8830 - val_loss: 0.3555 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 590us/step - loss: 0.3635 - accuracy: 0.8829 - val_loss: 0.3541 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 550us/step - loss: 0.3623 - accuracy: 0.8830 - val_loss: 0.3528 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 557us/step - loss: 0.3595 - accuracy: 0.8830 - val_loss: 0.3515 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3583 - accuracy: 0.8830 - val_loss: 0.3503 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3585 - accuracy: 0.8830 - val_loss: 0.3491 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 611us/step - loss: 0.3568 - accuracy: 0.8830 - val_loss: 0.3480 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.3551 - accuracy: 0.8830 - val_loss: 0.3469 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3549 - accuracy: 0.8830 - val_loss: 0.3459 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.3533 - accuracy: 0.8830 - val_loss: 0.3450 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 556us/step - loss: 0.3514 - accuracy: 0.8830 - val_loss: 0.3440 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 598us/step - loss: 0.3513 - accuracy: 0.8831 - val_loss: 0.3431 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 557us/step - loss: 0.3496 - accuracy: 0.8830 - val_loss: 0.3422 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.3493 - accuracy: 0.8830 - val_loss: 0.3413 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 552us/step - loss: 0.3482 - accuracy: 0.8830 - val_loss: 0.3405 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 595us/step - loss: 0.3489 - accuracy: 0.8830 - val_loss: 0.3396 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3478 - accuracy: 0.8830 - val_loss: 0.3389 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 559us/step - loss: 0.3467 - accuracy: 0.8830 - val_loss: 0.3381 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.3460 - accuracy: 0.8830 - val_loss: 0.3374 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3447 - accuracy: 0.8831 - val_loss: 0.3367 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.3442 - accuracy: 0.8831 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 557us/step - loss: 0.3432 - accuracy: 0.8831 - val_loss: 0.3355 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3421 - accuracy: 0.8830 - val_loss: 0.3349 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.3416 - accuracy: 0.8830 - val_loss: 0.3342 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 598us/step - loss: 0.3411 - accuracy: 0.8829 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 568us/step - loss: 0.3412 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3400 - accuracy: 0.8831 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3394 - accuracy: 0.8829 - val_loss: 0.3320 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 602us/step - loss: 0.3399 - accuracy: 0.8830 - val_loss: 0.3316 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3395 - accuracy: 0.8831 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3387 - accuracy: 0.8832 - val_loss: 0.3306 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 603us/step - loss: 0.4510 - accuracy: 0.8551 - val_loss: 0.3901 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 599us/step - loss: 0.3987 - accuracy: 0.8827 - val_loss: 0.3843 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 596us/step - loss: 0.3933 - accuracy: 0.8827 - val_loss: 0.3810 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 599us/step - loss: 0.3893 - accuracy: 0.8830 - val_loss: 0.3782 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 631us/step - loss: 0.3875 - accuracy: 0.8829 - val_loss: 0.3755 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.3828 - accuracy: 0.8830 - val_loss: 0.3732 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 595us/step - loss: 0.3807 - accuracy: 0.8830 - val_loss: 0.3707 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 570us/step - loss: 0.3781 - accuracy: 0.8829 - val_loss: 0.3682 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 568us/step - loss: 0.3764 - accuracy: 0.8830 - val_loss: 0.3661 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3753 - accuracy: 0.8830 - val_loss: 0.3641 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3721 - accuracy: 0.8830 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3694 - accuracy: 0.8830 - val_loss: 0.3606 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3680 - accuracy: 0.8830 - val_loss: 0.3589 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 608us/step - loss: 0.3668 - accuracy: 0.8830 - val_loss: 0.3574 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3649 - accuracy: 0.8830 - val_loss: 0.3557 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3628 - accuracy: 0.8830 - val_loss: 0.3543 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3626 - accuracy: 0.8830 - val_loss: 0.3529 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3601 - accuracy: 0.8831 - val_loss: 0.3516 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3592 - accuracy: 0.8830 - val_loss: 0.3502 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3589 - accuracy: 0.8830 - val_loss: 0.3489 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3564 - accuracy: 0.8830 - val_loss: 0.3477 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3549 - accuracy: 0.8830 - val_loss: 0.3465 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.3545 - accuracy: 0.8830 - val_loss: 0.3453 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.3534 - accuracy: 0.8830 - val_loss: 0.3441 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3511 - accuracy: 0.8830 - val_loss: 0.3432 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3504 - accuracy: 0.8829 - val_loss: 0.3422 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3502 - accuracy: 0.8831 - val_loss: 0.3411 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3493 - accuracy: 0.8830 - val_loss: 0.3402 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3477 - accuracy: 0.8830 - val_loss: 0.3392 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3462 - accuracy: 0.8830 - val_loss: 0.3383 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3456 - accuracy: 0.8830 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3442 - accuracy: 0.8831 - val_loss: 0.3367 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3442 - accuracy: 0.8830 - val_loss: 0.3358 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3427 - accuracy: 0.8830 - val_loss: 0.3351 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3418 - accuracy: 0.8830 - val_loss: 0.3343 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3425 - accuracy: 0.8831 - val_loss: 0.3337 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3407 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3400 - accuracy: 0.8831 - val_loss: 0.3323 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3392 - accuracy: 0.8830 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3389 - accuracy: 0.8831 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3392 - accuracy: 0.8831 - val_loss: 0.3306 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3379 - accuracy: 0.8831 - val_loss: 0.3300 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3369 - accuracy: 0.8831 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3372 - accuracy: 0.8830 - val_loss: 0.3290 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3351 - accuracy: 0.8830 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3353 - accuracy: 0.8831 - val_loss: 0.3280 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3360 - accuracy: 0.8833 - val_loss: 0.3275 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3349 - accuracy: 0.8829 - val_loss: 0.3271 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3349 - accuracy: 0.8831 - val_loss: 0.3267 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3341 - accuracy: 0.8831 - val_loss: 0.3264 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "   1/2261 [..............................] - ETA: 0s - loss: 1.1273 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.5126 - accuracy: 0.7827 - val_loss: 0.3973 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 472us/step - loss: 0.3980 - accuracy: 0.8830 - val_loss: 0.3864 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 472us/step - loss: 0.3911 - accuracy: 0.8830 - val_loss: 0.3820 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3869 - accuracy: 0.8830 - val_loss: 0.3783 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.3840 - accuracy: 0.8830 - val_loss: 0.3750 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3799 - accuracy: 0.8830 - val_loss: 0.3720 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 469us/step - loss: 0.3766 - accuracy: 0.8830 - val_loss: 0.3692 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3750 - accuracy: 0.8830 - val_loss: 0.3667 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 469us/step - loss: 0.3718 - accuracy: 0.8830 - val_loss: 0.3644 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3703 - accuracy: 0.8830 - val_loss: 0.3622 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 468us/step - loss: 0.3665 - accuracy: 0.8830 - val_loss: 0.3602 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3653 - accuracy: 0.8830 - val_loss: 0.3583 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3638 - accuracy: 0.8830 - val_loss: 0.3565 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3605 - accuracy: 0.8830 - val_loss: 0.3548 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3607 - accuracy: 0.8830 - val_loss: 0.3533 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 462us/step - loss: 0.3588 - accuracy: 0.8830 - val_loss: 0.3517 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 467us/step - loss: 0.3563 - accuracy: 0.8830 - val_loss: 0.3503 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3546 - accuracy: 0.8830 - val_loss: 0.3490 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3541 - accuracy: 0.8830 - val_loss: 0.3477 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3529 - accuracy: 0.8830 - val_loss: 0.3465 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3522 - accuracy: 0.8830 - val_loss: 0.3454 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3506 - accuracy: 0.8830 - val_loss: 0.3443 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3489 - accuracy: 0.8830 - val_loss: 0.3433 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3487 - accuracy: 0.8830 - val_loss: 0.3423 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3473 - accuracy: 0.8830 - val_loss: 0.3414 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3459 - accuracy: 0.8830 - val_loss: 0.3405 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3462 - accuracy: 0.8830 - val_loss: 0.3396 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3446 - accuracy: 0.8830 - val_loss: 0.3388 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 473us/step - loss: 0.3443 - accuracy: 0.8830 - val_loss: 0.3381 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3433 - accuracy: 0.8830 - val_loss: 0.3373 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3433 - accuracy: 0.8830 - val_loss: 0.3366 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3428 - accuracy: 0.8830 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.3416 - accuracy: 0.8830 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3402 - accuracy: 0.8830 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3403 - accuracy: 0.8830 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3391 - accuracy: 0.8830 - val_loss: 0.3335 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3390 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3379 - accuracy: 0.8830 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3380 - accuracy: 0.8830 - val_loss: 0.3320 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.3365 - accuracy: 0.8830 - val_loss: 0.3315 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3370 - accuracy: 0.8830 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3362 - accuracy: 0.8830 - val_loss: 0.3307 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3370 - accuracy: 0.8830 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3357 - accuracy: 0.8830 - val_loss: 0.3298 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3358 - accuracy: 0.8830 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3357 - accuracy: 0.8830 - val_loss: 0.3291 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3341 - accuracy: 0.8830 - val_loss: 0.3288 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3345 - accuracy: 0.8830 - val_loss: 0.3284 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3336 - accuracy: 0.8830 - val_loss: 0.3281 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3331 - accuracy: 0.8830 - val_loss: 0.3278 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "Entrenando modelo con noise_multiplier=2.0...\n",
      "DP-SGD with sampling rate = 0.0442% and noise_multiplier = 2.0 iterated over 113025 steps satisfies differential privacy with eps = 0.385 and delta = 1e-05.\n",
      "The optimal RDP order is 60.0.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.4055 - accuracy: 0.8830 - val_loss: 0.3939 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3994 - accuracy: 0.8830 - val_loss: 0.3912 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.3962 - accuracy: 0.8829 - val_loss: 0.3889 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3944 - accuracy: 0.8830 - val_loss: 0.3867 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3927 - accuracy: 0.8830 - val_loss: 0.3848 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3895 - accuracy: 0.8830 - val_loss: 0.3829 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3892 - accuracy: 0.8830 - val_loss: 0.3811 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3872 - accuracy: 0.8830 - val_loss: 0.3794 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3858 - accuracy: 0.8830 - val_loss: 0.3777 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 2s 724us/step - loss: 0.3825 - accuracy: 0.8830 - val_loss: 0.3761 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 610us/step - loss: 0.3821 - accuracy: 0.8830 - val_loss: 0.3746 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 578us/step - loss: 0.3797 - accuracy: 0.8830 - val_loss: 0.3731 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.3789 - accuracy: 0.8830 - val_loss: 0.3716 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 595us/step - loss: 0.3764 - accuracy: 0.8830 - val_loss: 0.3702 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.3764 - accuracy: 0.8830 - val_loss: 0.3688 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.3736 - accuracy: 0.8830 - val_loss: 0.3674 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3726 - accuracy: 0.8830 - val_loss: 0.3660 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 570us/step - loss: 0.3710 - accuracy: 0.8830 - val_loss: 0.3648 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 607us/step - loss: 0.3686 - accuracy: 0.8830 - val_loss: 0.3635 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.3682 - accuracy: 0.8830 - val_loss: 0.3622 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3656 - accuracy: 0.8830 - val_loss: 0.3609 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3666 - accuracy: 0.8830 - val_loss: 0.3597 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3649 - accuracy: 0.8830 - val_loss: 0.3585 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3635 - accuracy: 0.8830 - val_loss: 0.3573 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3629 - accuracy: 0.8830 - val_loss: 0.3561 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 574us/step - loss: 0.3615 - accuracy: 0.8830 - val_loss: 0.3550 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.3608 - accuracy: 0.8830 - val_loss: 0.3539 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.3596 - accuracy: 0.8830 - val_loss: 0.3527 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.3587 - accuracy: 0.8830 - val_loss: 0.3516 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3572 - accuracy: 0.8830 - val_loss: 0.3505 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3556 - accuracy: 0.8830 - val_loss: 0.3494 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3546 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3532 - accuracy: 0.8830 - val_loss: 0.3474 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3527 - accuracy: 0.8830 - val_loss: 0.3463 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 605us/step - loss: 0.3511 - accuracy: 0.8830 - val_loss: 0.3453 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 570us/step - loss: 0.3507 - accuracy: 0.8830 - val_loss: 0.3444 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 564us/step - loss: 0.3492 - accuracy: 0.8830 - val_loss: 0.3434 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3487 - accuracy: 0.8830 - val_loss: 0.3425 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3484 - accuracy: 0.8830 - val_loss: 0.3416 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 608us/step - loss: 0.3468 - accuracy: 0.8830 - val_loss: 0.3407 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3459 - accuracy: 0.8830 - val_loss: 0.3398 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.3457 - accuracy: 0.8830 - val_loss: 0.3390 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3435 - accuracy: 0.8830 - val_loss: 0.3382 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 554us/step - loss: 0.3435 - accuracy: 0.8830 - val_loss: 0.3374 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 552us/step - loss: 0.3435 - accuracy: 0.8830 - val_loss: 0.3366 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 554us/step - loss: 0.3431 - accuracy: 0.8830 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 554us/step - loss: 0.3415 - accuracy: 0.8830 - val_loss: 0.3352 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.3414 - accuracy: 0.8830 - val_loss: 0.3345 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 553us/step - loss: 0.3389 - accuracy: 0.8830 - val_loss: 0.3338 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 586us/step - loss: 0.3395 - accuracy: 0.8830 - val_loss: 0.3331 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.4170 - accuracy: 0.8805 - val_loss: 0.3785 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 556us/step - loss: 0.3833 - accuracy: 0.8830 - val_loss: 0.3741 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3785 - accuracy: 0.8830 - val_loss: 0.3719 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3766 - accuracy: 0.8830 - val_loss: 0.3698 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3745 - accuracy: 0.8830 - val_loss: 0.3677 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3737 - accuracy: 0.8830 - val_loss: 0.3658 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 568us/step - loss: 0.3712 - accuracy: 0.8830 - val_loss: 0.3640 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3678 - accuracy: 0.8830 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 600us/step - loss: 0.3681 - accuracy: 0.8830 - val_loss: 0.3607 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3663 - accuracy: 0.8830 - val_loss: 0.3590 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.3652 - accuracy: 0.8830 - val_loss: 0.3575 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 556us/step - loss: 0.3636 - accuracy: 0.8830 - val_loss: 0.3560 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 546us/step - loss: 0.3618 - accuracy: 0.8830 - val_loss: 0.3547 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3602 - accuracy: 0.8830 - val_loss: 0.3532 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 564us/step - loss: 0.3585 - accuracy: 0.8830 - val_loss: 0.3519 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3574 - accuracy: 0.8830 - val_loss: 0.3507 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 655us/step - loss: 0.3577 - accuracy: 0.8830 - val_loss: 0.3495 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 2s 716us/step - loss: 0.3552 - accuracy: 0.8830 - val_loss: 0.3483 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 600us/step - loss: 0.3543 - accuracy: 0.8830 - val_loss: 0.3471 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3518 - accuracy: 0.8830 - val_loss: 0.3460 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3517 - accuracy: 0.8830 - val_loss: 0.3450 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3505 - accuracy: 0.8830 - val_loss: 0.3439 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3507 - accuracy: 0.8830 - val_loss: 0.3429 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3486 - accuracy: 0.8830 - val_loss: 0.3419 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 526us/step - loss: 0.3491 - accuracy: 0.8830 - val_loss: 0.3410 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3478 - accuracy: 0.8829 - val_loss: 0.3400 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3456 - accuracy: 0.8831 - val_loss: 0.3383 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3444 - accuracy: 0.8829 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3438 - accuracy: 0.8830 - val_loss: 0.3368 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3436 - accuracy: 0.8830 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3419 - accuracy: 0.8829 - val_loss: 0.3355 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3414 - accuracy: 0.8830 - val_loss: 0.3349 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3411 - accuracy: 0.8830 - val_loss: 0.3345 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3403 - accuracy: 0.8829 - val_loss: 0.3339 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3406 - accuracy: 0.8830 - val_loss: 0.3335 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3395 - accuracy: 0.8829 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3400 - accuracy: 0.8829 - val_loss: 0.3327 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3389 - accuracy: 0.8830 - val_loss: 0.3322 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3395 - accuracy: 0.8831 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3369 - accuracy: 0.8829 - val_loss: 0.3315 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3369 - accuracy: 0.8829 - val_loss: 0.3312 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3378 - accuracy: 0.8830 - val_loss: 0.3309 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3371 - accuracy: 0.8830 - val_loss: 0.3306 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3365 - accuracy: 0.8832 - val_loss: 0.3303 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3367 - accuracy: 0.8831 - val_loss: 0.3300 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3356 - accuracy: 0.8829 - val_loss: 0.3297 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3365 - accuracy: 0.8829 - val_loss: 0.3294 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3362 - accuracy: 0.8828 - val_loss: 0.3291 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3372 - accuracy: 0.8827 - val_loss: 0.3289 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.4419 - accuracy: 0.8707 - val_loss: 0.4099 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.4135 - accuracy: 0.8822 - val_loss: 0.4046 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.4089 - accuracy: 0.8829 - val_loss: 0.4003 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.4054 - accuracy: 0.8828 - val_loss: 0.3967 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.4003 - accuracy: 0.8830 - val_loss: 0.3937 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3989 - accuracy: 0.8830 - val_loss: 0.3909 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3938 - accuracy: 0.8830 - val_loss: 0.3883 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3921 - accuracy: 0.8830 - val_loss: 0.3859 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3897 - accuracy: 0.8830 - val_loss: 0.3835 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3861 - accuracy: 0.8830 - val_loss: 0.3814 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3847 - accuracy: 0.8830 - val_loss: 0.3793 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3845 - accuracy: 0.8830 - val_loss: 0.3772 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 546us/step - loss: 0.3816 - accuracy: 0.8830 - val_loss: 0.3752 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3797 - accuracy: 0.8830 - val_loss: 0.3733 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3772 - accuracy: 0.8830 - val_loss: 0.3714 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3760 - accuracy: 0.8830 - val_loss: 0.3697 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3735 - accuracy: 0.8830 - val_loss: 0.3680 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3724 - accuracy: 0.8830 - val_loss: 0.3663 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3703 - accuracy: 0.8830 - val_loss: 0.3647 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3695 - accuracy: 0.8830 - val_loss: 0.3632 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3669 - accuracy: 0.8830 - val_loss: 0.3616 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3656 - accuracy: 0.8830 - val_loss: 0.3601 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3630 - accuracy: 0.8830 - val_loss: 0.3587 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3621 - accuracy: 0.8830 - val_loss: 0.3573 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3615 - accuracy: 0.8830 - val_loss: 0.3559 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3603 - accuracy: 0.8830 - val_loss: 0.3545 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3587 - accuracy: 0.8830 - val_loss: 0.3533 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3567 - accuracy: 0.8830 - val_loss: 0.3519 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3568 - accuracy: 0.8830 - val_loss: 0.3507 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3561 - accuracy: 0.8830 - val_loss: 0.3495 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3544 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3537 - accuracy: 0.8830 - val_loss: 0.3472 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3521 - accuracy: 0.8830 - val_loss: 0.3460 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3505 - accuracy: 0.8830 - val_loss: 0.3449 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3508 - accuracy: 0.8830 - val_loss: 0.3439 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3487 - accuracy: 0.8830 - val_loss: 0.3429 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3465 - accuracy: 0.8830 - val_loss: 0.3418 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3464 - accuracy: 0.8830 - val_loss: 0.3409 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3451 - accuracy: 0.8830 - val_loss: 0.3400 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3453 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3444 - accuracy: 0.8830 - val_loss: 0.3382 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3431 - accuracy: 0.8830 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3420 - accuracy: 0.8830 - val_loss: 0.3366 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3408 - accuracy: 0.8830 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3401 - accuracy: 0.8830 - val_loss: 0.3352 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3401 - accuracy: 0.8830 - val_loss: 0.3345 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3399 - accuracy: 0.8830 - val_loss: 0.3338 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3384 - accuracy: 0.8830 - val_loss: 0.3332 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3380 - accuracy: 0.8830 - val_loss: 0.3326 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3375 - accuracy: 0.8830 - val_loss: 0.3320 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.4577 - accuracy: 0.8673 - val_loss: 0.3878 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3848 - accuracy: 0.8830 - val_loss: 0.3756 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3787 - accuracy: 0.8830 - val_loss: 0.3722 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3749 - accuracy: 0.8830 - val_loss: 0.3699 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3741 - accuracy: 0.8830 - val_loss: 0.3679 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3734 - accuracy: 0.8830 - val_loss: 0.3662 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3707 - accuracy: 0.8830 - val_loss: 0.3647 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3691 - accuracy: 0.8830 - val_loss: 0.3632 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.3685 - accuracy: 0.8831 - val_loss: 0.3618 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 2s 679us/step - loss: 0.3659 - accuracy: 0.8830 - val_loss: 0.3604 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 604us/step - loss: 0.3647 - accuracy: 0.8830 - val_loss: 0.3591 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3635 - accuracy: 0.8830 - val_loss: 0.3579 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3622 - accuracy: 0.8830 - val_loss: 0.3565 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3618 - accuracy: 0.8830 - val_loss: 0.3553 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3610 - accuracy: 0.8830 - val_loss: 0.3542 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3596 - accuracy: 0.8830 - val_loss: 0.3531 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 564us/step - loss: 0.3581 - accuracy: 0.8830 - val_loss: 0.3520 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.3570 - accuracy: 0.8830 - val_loss: 0.3509 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 540us/step - loss: 0.3555 - accuracy: 0.8830 - val_loss: 0.3498 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3538 - accuracy: 0.8830 - val_loss: 0.3487 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 546us/step - loss: 0.3534 - accuracy: 0.8831 - val_loss: 0.3477 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 547us/step - loss: 0.3529 - accuracy: 0.8830 - val_loss: 0.3466 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.3523 - accuracy: 0.8830 - val_loss: 0.3457 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.3510 - accuracy: 0.8830 - val_loss: 0.3448 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3493 - accuracy: 0.8830 - val_loss: 0.3438 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3488 - accuracy: 0.8830 - val_loss: 0.3430 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3485 - accuracy: 0.8830 - val_loss: 0.3421 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3468 - accuracy: 0.8832 - val_loss: 0.3412 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 550us/step - loss: 0.3458 - accuracy: 0.8830 - val_loss: 0.3404 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3452 - accuracy: 0.8830 - val_loss: 0.3396 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3452 - accuracy: 0.8830 - val_loss: 0.3389 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.3451 - accuracy: 0.8832 - val_loss: 0.3381 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3431 - accuracy: 0.8831 - val_loss: 0.3374 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3437 - accuracy: 0.8830 - val_loss: 0.3367 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3426 - accuracy: 0.8831 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3411 - accuracy: 0.8830 - val_loss: 0.3354 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3414 - accuracy: 0.8831 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 547us/step - loss: 0.3401 - accuracy: 0.8830 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3405 - accuracy: 0.8829 - val_loss: 0.3335 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.3401 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3373 - accuracy: 0.8830 - val_loss: 0.3324 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.3384 - accuracy: 0.8831 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3376 - accuracy: 0.8831 - val_loss: 0.3314 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 612us/step - loss: 0.3373 - accuracy: 0.8830 - val_loss: 0.3309 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3359 - accuracy: 0.8830 - val_loss: 0.3305 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 556us/step - loss: 0.3358 - accuracy: 0.8833 - val_loss: 0.3300 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3359 - accuracy: 0.8832 - val_loss: 0.3296 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3352 - accuracy: 0.8831 - val_loss: 0.3291 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3343 - accuracy: 0.8833 - val_loss: 0.3287 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 556us/step - loss: 0.3349 - accuracy: 0.8835 - val_loss: 0.3284 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.4640 - accuracy: 0.8658 - val_loss: 0.3910 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3876 - accuracy: 0.8830 - val_loss: 0.3788 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 557us/step - loss: 0.3817 - accuracy: 0.8830 - val_loss: 0.3760 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3796 - accuracy: 0.8830 - val_loss: 0.3740 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3769 - accuracy: 0.8830 - val_loss: 0.3723 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 559us/step - loss: 0.3761 - accuracy: 0.8830 - val_loss: 0.3707 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3735 - accuracy: 0.8830 - val_loss: 0.3691 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 558us/step - loss: 0.3724 - accuracy: 0.8830 - val_loss: 0.3676 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 558us/step - loss: 0.3713 - accuracy: 0.8830 - val_loss: 0.3662 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3696 - accuracy: 0.8830 - val_loss: 0.3648 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.3686 - accuracy: 0.8830 - val_loss: 0.3634 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.3670 - accuracy: 0.8830 - val_loss: 0.3620 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3656 - accuracy: 0.8830 - val_loss: 0.3606 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3644 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3626 - accuracy: 0.8830 - val_loss: 0.3578 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3616 - accuracy: 0.8830 - val_loss: 0.3564 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.3596 - accuracy: 0.8830 - val_loss: 0.3551 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3590 - accuracy: 0.8830 - val_loss: 0.3537 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3571 - accuracy: 0.8830 - val_loss: 0.3522 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3559 - accuracy: 0.8830 - val_loss: 0.3508 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3555 - accuracy: 0.8830 - val_loss: 0.3495 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3524 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3528 - accuracy: 0.8830 - val_loss: 0.3468 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3511 - accuracy: 0.8830 - val_loss: 0.3456 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 524us/step - loss: 0.3494 - accuracy: 0.8830 - val_loss: 0.3444 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3489 - accuracy: 0.8830 - val_loss: 0.3432 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 0.3421 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3460 - accuracy: 0.8830 - val_loss: 0.3410 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3451 - accuracy: 0.8830 - val_loss: 0.3399 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3440 - accuracy: 0.8830 - val_loss: 0.3389 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3427 - accuracy: 0.8830 - val_loss: 0.3378 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3428 - accuracy: 0.8830 - val_loss: 0.3369 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3412 - accuracy: 0.8830 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3394 - accuracy: 0.8830 - val_loss: 0.3350 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3393 - accuracy: 0.8830 - val_loss: 0.3342 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3395 - accuracy: 0.8830 - val_loss: 0.3334 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3372 - accuracy: 0.8830 - val_loss: 0.3326 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3378 - accuracy: 0.8830 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3364 - accuracy: 0.8830 - val_loss: 0.3312 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3354 - accuracy: 0.8830 - val_loss: 0.3305 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3353 - accuracy: 0.8830 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3352 - accuracy: 0.8830 - val_loss: 0.3293 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3338 - accuracy: 0.8830 - val_loss: 0.3287 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3339 - accuracy: 0.8830 - val_loss: 0.3281 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 526us/step - loss: 0.3328 - accuracy: 0.8830 - val_loss: 0.3276 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3326 - accuracy: 0.8830 - val_loss: 0.3271 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3317 - accuracy: 0.8830 - val_loss: 0.3266 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3308 - accuracy: 0.8830 - val_loss: 0.3261 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3324 - accuracy: 0.8831 - val_loss: 0.3257 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 524us/step - loss: 0.3315 - accuracy: 0.8830 - val_loss: 0.3253 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "Entrenando modelo con noise_multiplier=2.5...\n",
      "DP-SGD with sampling rate = 0.0442% and noise_multiplier = 2.5 iterated over 113025 steps satisfies differential privacy with eps = 0.307 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.5219 - accuracy: 0.7713 - val_loss: 0.3863 - val_accuracy: 0.8829\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3905 - accuracy: 0.8829 - val_loss: 0.3759 - val_accuracy: 0.8829\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3838 - accuracy: 0.8830 - val_loss: 0.3730 - val_accuracy: 0.8829\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3819 - accuracy: 0.8830 - val_loss: 0.3704 - val_accuracy: 0.8829\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3783 - accuracy: 0.8831 - val_loss: 0.3680 - val_accuracy: 0.8829\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3753 - accuracy: 0.8830 - val_loss: 0.3656 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3730 - accuracy: 0.8831 - val_loss: 0.3633 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3706 - accuracy: 0.8831 - val_loss: 0.3610 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3673 - accuracy: 0.8831 - val_loss: 0.3588 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3660 - accuracy: 0.8830 - val_loss: 0.3568 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.3638 - accuracy: 0.8829 - val_loss: 0.3548 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3626 - accuracy: 0.8829 - val_loss: 0.3529 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3598 - accuracy: 0.8829 - val_loss: 0.3510 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3587 - accuracy: 0.8831 - val_loss: 0.3493 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3576 - accuracy: 0.8830 - val_loss: 0.3476 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3537 - accuracy: 0.8831 - val_loss: 0.3460 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3534 - accuracy: 0.8831 - val_loss: 0.3444 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3519 - accuracy: 0.8830 - val_loss: 0.3429 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3505 - accuracy: 0.8832 - val_loss: 0.3415 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3490 - accuracy: 0.8832 - val_loss: 0.3401 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3478 - accuracy: 0.8830 - val_loss: 0.3388 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3457 - accuracy: 0.8831 - val_loss: 0.3376 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3440 - accuracy: 0.8832 - val_loss: 0.3364 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3440 - accuracy: 0.8832 - val_loss: 0.3351 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3426 - accuracy: 0.8831 - val_loss: 0.3340 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.3408 - accuracy: 0.8831 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3407 - accuracy: 0.8831 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3386 - accuracy: 0.8833 - val_loss: 0.3310 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3389 - accuracy: 0.8831 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3366 - accuracy: 0.8830 - val_loss: 0.3292 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3370 - accuracy: 0.8834 - val_loss: 0.3283 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3356 - accuracy: 0.8834 - val_loss: 0.3274 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3359 - accuracy: 0.8834 - val_loss: 0.3266 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.3336 - accuracy: 0.8833 - val_loss: 0.3259 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3335 - accuracy: 0.8833 - val_loss: 0.3252 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3322 - accuracy: 0.8833 - val_loss: 0.3246 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3312 - accuracy: 0.8838 - val_loss: 0.3240 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3318 - accuracy: 0.8835 - val_loss: 0.3235 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.3302 - accuracy: 0.8842 - val_loss: 0.3230 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3314 - accuracy: 0.8837 - val_loss: 0.3225 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3297 - accuracy: 0.8839 - val_loss: 0.3221 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3298 - accuracy: 0.8842 - val_loss: 0.3217 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3282 - accuracy: 0.8845 - val_loss: 0.3213 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3294 - accuracy: 0.8843 - val_loss: 0.3209 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3285 - accuracy: 0.8845 - val_loss: 0.3206 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3284 - accuracy: 0.8844 - val_loss: 0.3203 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3278 - accuracy: 0.8850 - val_loss: 0.3200 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 570us/step - loss: 0.3278 - accuracy: 0.8842 - val_loss: 0.3197 - val_accuracy: 0.8837\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3285 - accuracy: 0.8849 - val_loss: 0.3194 - val_accuracy: 0.8837\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3273 - accuracy: 0.8849 - val_loss: 0.3192 - val_accuracy: 0.8838\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.4967 - accuracy: 0.8027 - val_loss: 0.3970 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.3976 - accuracy: 0.8830 - val_loss: 0.3877 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3894 - accuracy: 0.8830 - val_loss: 0.3836 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 539us/step - loss: 0.3877 - accuracy: 0.8830 - val_loss: 0.3800 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3850 - accuracy: 0.8830 - val_loss: 0.3767 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3819 - accuracy: 0.8830 - val_loss: 0.3734 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3787 - accuracy: 0.8830 - val_loss: 0.3707 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3751 - accuracy: 0.8830 - val_loss: 0.3681 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3724 - accuracy: 0.8830 - val_loss: 0.3658 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3690 - accuracy: 0.8830 - val_loss: 0.3637 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 2s 781us/step - loss: 0.3683 - accuracy: 0.8830 - val_loss: 0.3619 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 617us/step - loss: 0.3663 - accuracy: 0.8830 - val_loss: 0.3601 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 588us/step - loss: 0.3659 - accuracy: 0.8830 - val_loss: 0.3585 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.3634 - accuracy: 0.8830 - val_loss: 0.3569 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.3613 - accuracy: 0.8830 - val_loss: 0.3554 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 620us/step - loss: 0.3606 - accuracy: 0.8830 - val_loss: 0.3539 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3594 - accuracy: 0.8830 - val_loss: 0.3525 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.3581 - accuracy: 0.8830 - val_loss: 0.3514 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.3562 - accuracy: 0.8830 - val_loss: 0.3500 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3549 - accuracy: 0.8830 - val_loss: 0.3488 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3551 - accuracy: 0.8830 - val_loss: 0.3477 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 615us/step - loss: 0.3526 - accuracy: 0.8830 - val_loss: 0.3465 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.3519 - accuracy: 0.8830 - val_loss: 0.3455 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3498 - accuracy: 0.8830 - val_loss: 0.3445 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 646us/step - loss: 0.3495 - accuracy: 0.8830 - val_loss: 0.3435 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3495 - accuracy: 0.8830 - val_loss: 0.3426 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3486 - accuracy: 0.8830 - val_loss: 0.3419 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 615us/step - loss: 0.3475 - accuracy: 0.8830 - val_loss: 0.3409 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3470 - accuracy: 0.8830 - val_loss: 0.3401 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3458 - accuracy: 0.8830 - val_loss: 0.3394 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3459 - accuracy: 0.8830 - val_loss: 0.3386 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.3442 - accuracy: 0.8831 - val_loss: 0.3379 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 615us/step - loss: 0.3430 - accuracy: 0.8830 - val_loss: 0.3372 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3424 - accuracy: 0.8830 - val_loss: 0.3366 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.3422 - accuracy: 0.8831 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3421 - accuracy: 0.8830 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3409 - accuracy: 0.8831 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.3409 - accuracy: 0.8831 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 619us/step - loss: 0.3401 - accuracy: 0.8831 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3397 - accuracy: 0.8831 - val_loss: 0.3331 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3395 - accuracy: 0.8830 - val_loss: 0.3326 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3381 - accuracy: 0.8830 - val_loss: 0.3321 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3374 - accuracy: 0.8832 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 613us/step - loss: 0.3392 - accuracy: 0.8830 - val_loss: 0.3312 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.3371 - accuracy: 0.8830 - val_loss: 0.3308 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.3364 - accuracy: 0.8830 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 574us/step - loss: 0.3362 - accuracy: 0.8832 - val_loss: 0.3300 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3358 - accuracy: 0.8831 - val_loss: 0.3297 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 624us/step - loss: 0.3348 - accuracy: 0.8830 - val_loss: 0.3293 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.3350 - accuracy: 0.8833 - val_loss: 0.3289 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.4139 - accuracy: 0.8824 - val_loss: 0.4004 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 596us/step - loss: 0.4076 - accuracy: 0.8828 - val_loss: 0.3967 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.4031 - accuracy: 0.8829 - val_loss: 0.3932 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 616us/step - loss: 0.4004 - accuracy: 0.8829 - val_loss: 0.3897 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 590us/step - loss: 0.3964 - accuracy: 0.8829 - val_loss: 0.3864 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 586us/step - loss: 0.3930 - accuracy: 0.8829 - val_loss: 0.3832 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3906 - accuracy: 0.8830 - val_loss: 0.3799 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 612us/step - loss: 0.3871 - accuracy: 0.8830 - val_loss: 0.3766 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 593us/step - loss: 0.3830 - accuracy: 0.8830 - val_loss: 0.3736 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3800 - accuracy: 0.8830 - val_loss: 0.3706 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3770 - accuracy: 0.8830 - val_loss: 0.3679 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3740 - accuracy: 0.8830 - val_loss: 0.3653 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 613us/step - loss: 0.3729 - accuracy: 0.8830 - val_loss: 0.3629 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3711 - accuracy: 0.8830 - val_loss: 0.3606 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3687 - accuracy: 0.8830 - val_loss: 0.3584 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3669 - accuracy: 0.8830 - val_loss: 0.3563 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3648 - accuracy: 0.8830 - val_loss: 0.3543 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 637us/step - loss: 0.3608 - accuracy: 0.8830 - val_loss: 0.3524 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3600 - accuracy: 0.8830 - val_loss: 0.3506 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3596 - accuracy: 0.8830 - val_loss: 0.3489 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.3569 - accuracy: 0.8830 - val_loss: 0.3472 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3554 - accuracy: 0.8830 - val_loss: 0.3457 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3544 - accuracy: 0.8830 - val_loss: 0.3442 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3530 - accuracy: 0.8829 - val_loss: 0.3428 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3518 - accuracy: 0.8830 - val_loss: 0.3415 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3499 - accuracy: 0.8831 - val_loss: 0.3403 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 535us/step - loss: 0.3485 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3472 - accuracy: 0.8830 - val_loss: 0.3379 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3465 - accuracy: 0.8831 - val_loss: 0.3370 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3459 - accuracy: 0.8830 - val_loss: 0.3360 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3442 - accuracy: 0.8830 - val_loss: 0.3350 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3432 - accuracy: 0.8830 - val_loss: 0.3342 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3423 - accuracy: 0.8830 - val_loss: 0.3333 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3419 - accuracy: 0.8831 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3416 - accuracy: 0.8830 - val_loss: 0.3318 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3401 - accuracy: 0.8830 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3404 - accuracy: 0.8831 - val_loss: 0.3305 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3390 - accuracy: 0.8832 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3382 - accuracy: 0.8830 - val_loss: 0.3294 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3373 - accuracy: 0.8832 - val_loss: 0.3287 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3376 - accuracy: 0.8831 - val_loss: 0.3283 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3374 - accuracy: 0.8832 - val_loss: 0.3278 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3373 - accuracy: 0.8833 - val_loss: 0.3273 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3361 - accuracy: 0.8831 - val_loss: 0.3270 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3364 - accuracy: 0.8831 - val_loss: 0.3265 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3359 - accuracy: 0.8830 - val_loss: 0.3262 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3350 - accuracy: 0.8834 - val_loss: 0.3258 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3349 - accuracy: 0.8833 - val_loss: 0.3255 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3347 - accuracy: 0.8832 - val_loss: 0.3251 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3336 - accuracy: 0.8833 - val_loss: 0.3248 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.5007 - accuracy: 0.8046 - val_loss: 0.4075 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.4078 - accuracy: 0.8821 - val_loss: 0.3971 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3996 - accuracy: 0.8824 - val_loss: 0.3921 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3962 - accuracy: 0.8828 - val_loss: 0.3883 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3922 - accuracy: 0.8828 - val_loss: 0.3849 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3898 - accuracy: 0.8829 - val_loss: 0.3820 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3859 - accuracy: 0.8829 - val_loss: 0.3793 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3841 - accuracy: 0.8829 - val_loss: 0.3771 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3810 - accuracy: 0.8830 - val_loss: 0.3748 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3793 - accuracy: 0.8830 - val_loss: 0.3728 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3790 - accuracy: 0.8830 - val_loss: 0.3708 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3748 - accuracy: 0.8830 - val_loss: 0.3688 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3720 - accuracy: 0.8830 - val_loss: 0.3671 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3719 - accuracy: 0.8830 - val_loss: 0.3654 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3700 - accuracy: 0.8830 - val_loss: 0.3638 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3678 - accuracy: 0.8830 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3672 - accuracy: 0.8830 - val_loss: 0.3608 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3652 - accuracy: 0.8830 - val_loss: 0.3595 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3644 - accuracy: 0.8830 - val_loss: 0.3580 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3628 - accuracy: 0.8830 - val_loss: 0.3568 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3626 - accuracy: 0.8830 - val_loss: 0.3556 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.3610 - accuracy: 0.8830 - val_loss: 0.3544 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3605 - accuracy: 0.8830 - val_loss: 0.3532 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3590 - accuracy: 0.8830 - val_loss: 0.3521 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 524us/step - loss: 0.3575 - accuracy: 0.8830 - val_loss: 0.3512 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3568 - accuracy: 0.8830 - val_loss: 0.3500 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3559 - accuracy: 0.8829 - val_loss: 0.3491 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3544 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3531 - accuracy: 0.8830 - val_loss: 0.3472 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3521 - accuracy: 0.8829 - val_loss: 0.3463 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3524 - accuracy: 0.8830 - val_loss: 0.3455 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3495 - accuracy: 0.8830 - val_loss: 0.3446 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3506 - accuracy: 0.8830 - val_loss: 0.3439 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3488 - accuracy: 0.8830 - val_loss: 0.3430 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3493 - accuracy: 0.8829 - val_loss: 0.3423 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 556us/step - loss: 0.3477 - accuracy: 0.8830 - val_loss: 0.3416 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3471 - accuracy: 0.8831 - val_loss: 0.3409 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3467 - accuracy: 0.8830 - val_loss: 0.3403 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3452 - accuracy: 0.8830 - val_loss: 0.3396 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3450 - accuracy: 0.8830 - val_loss: 0.3390 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3441 - accuracy: 0.8829 - val_loss: 0.3383 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3439 - accuracy: 0.8831 - val_loss: 0.3378 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3435 - accuracy: 0.8829 - val_loss: 0.3372 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3432 - accuracy: 0.8830 - val_loss: 0.3368 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3415 - accuracy: 0.8831 - val_loss: 0.3362 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3423 - accuracy: 0.8830 - val_loss: 0.3356 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3413 - accuracy: 0.8833 - val_loss: 0.3351 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3409 - accuracy: 0.8829 - val_loss: 0.3348 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3396 - accuracy: 0.8829 - val_loss: 0.3342 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3387 - accuracy: 0.8831 - val_loss: 0.3337 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.4013 - accuracy: 0.8792 - val_loss: 0.3796 - val_accuracy: 0.8808\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3866 - accuracy: 0.8816 - val_loss: 0.3752 - val_accuracy: 0.8821\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3831 - accuracy: 0.8822 - val_loss: 0.3718 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 524us/step - loss: 0.3783 - accuracy: 0.8822 - val_loss: 0.3688 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3775 - accuracy: 0.8827 - val_loss: 0.3660 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3732 - accuracy: 0.8828 - val_loss: 0.3636 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.3706 - accuracy: 0.8828 - val_loss: 0.3614 - val_accuracy: 0.8832\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 539us/step - loss: 0.3661 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 2s 734us/step - loss: 0.3651 - accuracy: 0.8829 - val_loss: 0.3572 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 2s 765us/step - loss: 0.3644 - accuracy: 0.8830 - val_loss: 0.3552 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.3611 - accuracy: 0.8832 - val_loss: 0.3533 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 645us/step - loss: 0.3603 - accuracy: 0.8830 - val_loss: 0.3513 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 2s 674us/step - loss: 0.3575 - accuracy: 0.8830 - val_loss: 0.3496 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 637us/step - loss: 0.3559 - accuracy: 0.8829 - val_loss: 0.3478 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 2s 687us/step - loss: 0.3540 - accuracy: 0.8831 - val_loss: 0.3461 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 637us/step - loss: 0.3525 - accuracy: 0.8831 - val_loss: 0.3445 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.3509 - accuracy: 0.8831 - val_loss: 0.3429 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 2s 675us/step - loss: 0.3487 - accuracy: 0.8831 - val_loss: 0.3415 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 647us/step - loss: 0.3481 - accuracy: 0.8831 - val_loss: 0.3402 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 642us/step - loss: 0.3473 - accuracy: 0.8830 - val_loss: 0.3389 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 625us/step - loss: 0.3448 - accuracy: 0.8830 - val_loss: 0.3377 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.3431 - accuracy: 0.8830 - val_loss: 0.3366 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 635us/step - loss: 0.3441 - accuracy: 0.8831 - val_loss: 0.3356 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 628us/step - loss: 0.3422 - accuracy: 0.8831 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 588us/step - loss: 0.3414 - accuracy: 0.8832 - val_loss: 0.3338 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 594us/step - loss: 0.3417 - accuracy: 0.8831 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 633us/step - loss: 0.3402 - accuracy: 0.8830 - val_loss: 0.3323 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 570us/step - loss: 0.3390 - accuracy: 0.8832 - val_loss: 0.3315 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3383 - accuracy: 0.8829 - val_loss: 0.3308 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 610us/step - loss: 0.3369 - accuracy: 0.8830 - val_loss: 0.3301 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 559us/step - loss: 0.3373 - accuracy: 0.8830 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3363 - accuracy: 0.8831 - val_loss: 0.3289 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 632us/step - loss: 0.3364 - accuracy: 0.8832 - val_loss: 0.3284 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3357 - accuracy: 0.8830 - val_loss: 0.3278 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 556us/step - loss: 0.3354 - accuracy: 0.8831 - val_loss: 0.3273 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3337 - accuracy: 0.8831 - val_loss: 0.3269 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 558us/step - loss: 0.3328 - accuracy: 0.8831 - val_loss: 0.3264 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 553us/step - loss: 0.3336 - accuracy: 0.8835 - val_loss: 0.3260 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3327 - accuracy: 0.8834 - val_loss: 0.3255 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 554us/step - loss: 0.3313 - accuracy: 0.8835 - val_loss: 0.3251 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 550us/step - loss: 0.3320 - accuracy: 0.8834 - val_loss: 0.3247 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.3316 - accuracy: 0.8837 - val_loss: 0.3244 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 586us/step - loss: 0.3313 - accuracy: 0.8838 - val_loss: 0.3240 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.3319 - accuracy: 0.8833 - val_loss: 0.3237 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 595us/step - loss: 0.3307 - accuracy: 0.8836 - val_loss: 0.3234 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3307 - accuracy: 0.8839 - val_loss: 0.3231 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.3291 - accuracy: 0.8837 - val_loss: 0.3228 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3298 - accuracy: 0.8838 - val_loss: 0.3225 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.3297 - accuracy: 0.8838 - val_loss: 0.3223 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.3287 - accuracy: 0.8838 - val_loss: 0.3220 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "Entrenando modelo con noise_multiplier=4...\n",
      "DP-SGD with sampling rate = 0.0442% and noise_multiplier = 4 iterated over 113025 steps satisfies differential privacy with eps = 0.182 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 578us/step - loss: 0.4617 - accuracy: 0.8642 - val_loss: 0.4012 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 604us/step - loss: 0.3984 - accuracy: 0.8829 - val_loss: 0.3897 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 568us/step - loss: 0.3915 - accuracy: 0.8830 - val_loss: 0.3852 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.3889 - accuracy: 0.8830 - val_loss: 0.3814 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 595us/step - loss: 0.3837 - accuracy: 0.8830 - val_loss: 0.3781 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3823 - accuracy: 0.8830 - val_loss: 0.3754 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3780 - accuracy: 0.8830 - val_loss: 0.3731 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 607us/step - loss: 0.3777 - accuracy: 0.8830 - val_loss: 0.3710 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3746 - accuracy: 0.8830 - val_loss: 0.3690 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 550us/step - loss: 0.3740 - accuracy: 0.8830 - val_loss: 0.3672 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 607us/step - loss: 0.3715 - accuracy: 0.8830 - val_loss: 0.3655 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3703 - accuracy: 0.8830 - val_loss: 0.3638 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3688 - accuracy: 0.8830 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 602us/step - loss: 0.3670 - accuracy: 0.8830 - val_loss: 0.3607 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 561us/step - loss: 0.3653 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 648us/step - loss: 0.3640 - accuracy: 0.8830 - val_loss: 0.3577 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.3632 - accuracy: 0.8830 - val_loss: 0.3563 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3608 - accuracy: 0.8830 - val_loss: 0.3549 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 524us/step - loss: 0.3603 - accuracy: 0.8830 - val_loss: 0.3536 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3584 - accuracy: 0.8830 - val_loss: 0.3522 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.3510 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3557 - accuracy: 0.8830 - val_loss: 0.3497 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3552 - accuracy: 0.8830 - val_loss: 0.3486 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3542 - accuracy: 0.8830 - val_loss: 0.3474 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3524 - accuracy: 0.8830 - val_loss: 0.3463 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3518 - accuracy: 0.8830 - val_loss: 0.3451 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3501 - accuracy: 0.8830 - val_loss: 0.3440 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3502 - accuracy: 0.8830 - val_loss: 0.3429 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3485 - accuracy: 0.8830 - val_loss: 0.3418 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3478 - accuracy: 0.8830 - val_loss: 0.3407 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3462 - accuracy: 0.8830 - val_loss: 0.3396 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3452 - accuracy: 0.8830 - val_loss: 0.3386 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.3440 - accuracy: 0.8830 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3444 - accuracy: 0.8830 - val_loss: 0.3365 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3429 - accuracy: 0.8830 - val_loss: 0.3357 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3407 - accuracy: 0.8830 - val_loss: 0.3349 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3415 - accuracy: 0.8830 - val_loss: 0.3342 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3408 - accuracy: 0.8830 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3394 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.3393 - accuracy: 0.8831 - val_loss: 0.3324 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3394 - accuracy: 0.8830 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3386 - accuracy: 0.8830 - val_loss: 0.3314 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3390 - accuracy: 0.8830 - val_loss: 0.3309 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3373 - accuracy: 0.8830 - val_loss: 0.3305 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3360 - accuracy: 0.8830 - val_loss: 0.3301 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3365 - accuracy: 0.8831 - val_loss: 0.3296 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 532us/step - loss: 0.3355 - accuracy: 0.8830 - val_loss: 0.3292 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3360 - accuracy: 0.8830 - val_loss: 0.3288 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3345 - accuracy: 0.8830 - val_loss: 0.3285 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3352 - accuracy: 0.8830 - val_loss: 0.3281 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.4983 - accuracy: 0.8040 - val_loss: 0.4037 - val_accuracy: 0.8819\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.4100 - accuracy: 0.8809 - val_loss: 0.3922 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.4030 - accuracy: 0.8821 - val_loss: 0.3886 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3986 - accuracy: 0.8825 - val_loss: 0.3859 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3950 - accuracy: 0.8827 - val_loss: 0.3834 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 532us/step - loss: 0.3916 - accuracy: 0.8829 - val_loss: 0.3811 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3899 - accuracy: 0.8830 - val_loss: 0.3789 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3864 - accuracy: 0.8829 - val_loss: 0.3769 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3857 - accuracy: 0.8830 - val_loss: 0.3749 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3845 - accuracy: 0.8830 - val_loss: 0.3729 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3802 - accuracy: 0.8830 - val_loss: 0.3711 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3784 - accuracy: 0.8830 - val_loss: 0.3693 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3764 - accuracy: 0.8830 - val_loss: 0.3676 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3746 - accuracy: 0.8830 - val_loss: 0.3658 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3731 - accuracy: 0.8830 - val_loss: 0.3641 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3699 - accuracy: 0.8830 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.3685 - accuracy: 0.8830 - val_loss: 0.3607 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3673 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3646 - accuracy: 0.8830 - val_loss: 0.3577 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3646 - accuracy: 0.8830 - val_loss: 0.3562 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3635 - accuracy: 0.8830 - val_loss: 0.3547 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3612 - accuracy: 0.8830 - val_loss: 0.3533 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3603 - accuracy: 0.8830 - val_loss: 0.3519 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3575 - accuracy: 0.8830 - val_loss: 0.3505 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 546us/step - loss: 0.3571 - accuracy: 0.8830 - val_loss: 0.3492 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3552 - accuracy: 0.8830 - val_loss: 0.3480 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3549 - accuracy: 0.8830 - val_loss: 0.3468 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3526 - accuracy: 0.8830 - val_loss: 0.3456 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3523 - accuracy: 0.8830 - val_loss: 0.3445 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3502 - accuracy: 0.8830 - val_loss: 0.3433 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3494 - accuracy: 0.8830 - val_loss: 0.3423 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3485 - accuracy: 0.8830 - val_loss: 0.3413 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.3474 - accuracy: 0.8830 - val_loss: 0.3403 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3461 - accuracy: 0.8830 - val_loss: 0.3393 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3453 - accuracy: 0.8830 - val_loss: 0.3384 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3451 - accuracy: 0.8830 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3431 - accuracy: 0.8830 - val_loss: 0.3367 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3422 - accuracy: 0.8830 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3413 - accuracy: 0.8830 - val_loss: 0.3351 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3409 - accuracy: 0.8830 - val_loss: 0.3343 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3401 - accuracy: 0.8830 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3395 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3390 - accuracy: 0.8830 - val_loss: 0.3323 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3379 - accuracy: 0.8830 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3381 - accuracy: 0.8830 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3359 - accuracy: 0.8830 - val_loss: 0.3306 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3360 - accuracy: 0.8830 - val_loss: 0.3301 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3365 - accuracy: 0.8830 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.3353 - accuracy: 0.8830 - val_loss: 0.3291 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3346 - accuracy: 0.8830 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.5022 - accuracy: 0.7931 - val_loss: 0.3996 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.4021 - accuracy: 0.8821 - val_loss: 0.3901 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 478us/step - loss: 0.3965 - accuracy: 0.8827 - val_loss: 0.3860 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3929 - accuracy: 0.8829 - val_loss: 0.3828 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 2s 681us/step - loss: 0.3911 - accuracy: 0.8830 - val_loss: 0.3799 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 661us/step - loss: 0.3870 - accuracy: 0.8829 - val_loss: 0.3772 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 641us/step - loss: 0.3849 - accuracy: 0.8829 - val_loss: 0.3747 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3815 - accuracy: 0.8830 - val_loss: 0.3724 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.3800 - accuracy: 0.8830 - val_loss: 0.3701 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.3789 - accuracy: 0.8830 - val_loss: 0.3680 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 606us/step - loss: 0.3745 - accuracy: 0.8830 - val_loss: 0.3659 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3741 - accuracy: 0.8830 - val_loss: 0.3638 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 606us/step - loss: 0.3722 - accuracy: 0.8830 - val_loss: 0.3619 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 578us/step - loss: 0.3709 - accuracy: 0.8830 - val_loss: 0.3601 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 615us/step - loss: 0.3691 - accuracy: 0.8830 - val_loss: 0.3583 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.3656 - accuracy: 0.8830 - val_loss: 0.3565 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 594us/step - loss: 0.3645 - accuracy: 0.8830 - val_loss: 0.3547 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 611us/step - loss: 0.3640 - accuracy: 0.8830 - val_loss: 0.3529 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.3615 - accuracy: 0.8830 - val_loss: 0.3513 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 604us/step - loss: 0.3597 - accuracy: 0.8830 - val_loss: 0.3496 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.3570 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 626us/step - loss: 0.3557 - accuracy: 0.8830 - val_loss: 0.3465 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3546 - accuracy: 0.8830 - val_loss: 0.3452 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 613us/step - loss: 0.3524 - accuracy: 0.8830 - val_loss: 0.3439 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 569us/step - loss: 0.3519 - accuracy: 0.8830 - val_loss: 0.3427 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3514 - accuracy: 0.8829 - val_loss: 0.3415 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 613us/step - loss: 0.3497 - accuracy: 0.8830 - val_loss: 0.3404 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 573us/step - loss: 0.3485 - accuracy: 0.8831 - val_loss: 0.3393 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 615us/step - loss: 0.3476 - accuracy: 0.8828 - val_loss: 0.3383 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.3460 - accuracy: 0.8831 - val_loss: 0.3373 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 608us/step - loss: 0.3451 - accuracy: 0.8831 - val_loss: 0.3364 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 598us/step - loss: 0.3459 - accuracy: 0.8830 - val_loss: 0.3355 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 625us/step - loss: 0.3442 - accuracy: 0.8831 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.3436 - accuracy: 0.8828 - val_loss: 0.3339 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 613us/step - loss: 0.3424 - accuracy: 0.8830 - val_loss: 0.3332 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 578us/step - loss: 0.3405 - accuracy: 0.8834 - val_loss: 0.3324 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.3416 - accuracy: 0.8831 - val_loss: 0.3318 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 631us/step - loss: 0.3400 - accuracy: 0.8834 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3394 - accuracy: 0.8833 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 616us/step - loss: 0.3381 - accuracy: 0.8833 - val_loss: 0.3298 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3372 - accuracy: 0.8834 - val_loss: 0.3293 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 635us/step - loss: 0.3367 - accuracy: 0.8832 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3378 - accuracy: 0.8833 - val_loss: 0.3282 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 625us/step - loss: 0.3370 - accuracy: 0.8835 - val_loss: 0.3277 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 592us/step - loss: 0.3362 - accuracy: 0.8834 - val_loss: 0.3273 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 616us/step - loss: 0.3357 - accuracy: 0.8835 - val_loss: 0.3269 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3360 - accuracy: 0.8832 - val_loss: 0.3265 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 606us/step - loss: 0.3351 - accuracy: 0.8833 - val_loss: 0.3262 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 647us/step - loss: 0.3341 - accuracy: 0.8838 - val_loss: 0.3259 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.3337 - accuracy: 0.8837 - val_loss: 0.3256 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.4107 - accuracy: 0.8824 - val_loss: 0.3820 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 627us/step - loss: 0.3862 - accuracy: 0.8830 - val_loss: 0.3778 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 603us/step - loss: 0.3819 - accuracy: 0.8830 - val_loss: 0.3753 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 604us/step - loss: 0.3804 - accuracy: 0.8830 - val_loss: 0.3727 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.3751 - accuracy: 0.8830 - val_loss: 0.3701 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3744 - accuracy: 0.8830 - val_loss: 0.3676 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 609us/step - loss: 0.3712 - accuracy: 0.8830 - val_loss: 0.3652 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3694 - accuracy: 0.8830 - val_loss: 0.3629 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 612us/step - loss: 0.3667 - accuracy: 0.8830 - val_loss: 0.3608 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 601us/step - loss: 0.3646 - accuracy: 0.8830 - val_loss: 0.3588 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 597us/step - loss: 0.3630 - accuracy: 0.8830 - val_loss: 0.3568 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 611us/step - loss: 0.3611 - accuracy: 0.8830 - val_loss: 0.3550 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3597 - accuracy: 0.8830 - val_loss: 0.3532 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3573 - accuracy: 0.8830 - val_loss: 0.3515 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 547us/step - loss: 0.3553 - accuracy: 0.8830 - val_loss: 0.3499 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3546 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3530 - accuracy: 0.8830 - val_loss: 0.3465 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 540us/step - loss: 0.3516 - accuracy: 0.8830 - val_loss: 0.3450 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3504 - accuracy: 0.8830 - val_loss: 0.3435 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3487 - accuracy: 0.8830 - val_loss: 0.3418 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3468 - accuracy: 0.8830 - val_loss: 0.3404 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.3463 - accuracy: 0.8830 - val_loss: 0.3390 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3439 - accuracy: 0.8830 - val_loss: 0.3377 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.3429 - accuracy: 0.8830 - val_loss: 0.3364 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3410 - accuracy: 0.8830 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3419 - accuracy: 0.8832 - val_loss: 0.3342 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3391 - accuracy: 0.8831 - val_loss: 0.3332 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3383 - accuracy: 0.8832 - val_loss: 0.3323 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3377 - accuracy: 0.8829 - val_loss: 0.3313 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3378 - accuracy: 0.8831 - val_loss: 0.3305 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3363 - accuracy: 0.8832 - val_loss: 0.3296 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3346 - accuracy: 0.8833 - val_loss: 0.3289 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3351 - accuracy: 0.8830 - val_loss: 0.3282 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3343 - accuracy: 0.8833 - val_loss: 0.3275 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3336 - accuracy: 0.8835 - val_loss: 0.3268 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3325 - accuracy: 0.8835 - val_loss: 0.3263 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3326 - accuracy: 0.8833 - val_loss: 0.3257 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3321 - accuracy: 0.8833 - val_loss: 0.3252 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3311 - accuracy: 0.8833 - val_loss: 0.3246 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3310 - accuracy: 0.8834 - val_loss: 0.3241 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3295 - accuracy: 0.8836 - val_loss: 0.3237 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3296 - accuracy: 0.8837 - val_loss: 0.3232 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3290 - accuracy: 0.8841 - val_loss: 0.3228 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3289 - accuracy: 0.8839 - val_loss: 0.3224 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3280 - accuracy: 0.8838 - val_loss: 0.3221 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3279 - accuracy: 0.8839 - val_loss: 0.3217 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3271 - accuracy: 0.8844 - val_loss: 0.3214 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3267 - accuracy: 0.8846 - val_loss: 0.3210 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3268 - accuracy: 0.8840 - val_loss: 0.3207 - val_accuracy: 0.8834\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3259 - accuracy: 0.8843 - val_loss: 0.3204 - val_accuracy: 0.8834\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.4863 - accuracy: 0.8218 - val_loss: 0.4021 - val_accuracy: 0.8809\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.4040 - accuracy: 0.8807 - val_loss: 0.3932 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3986 - accuracy: 0.8819 - val_loss: 0.3902 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3974 - accuracy: 0.8822 - val_loss: 0.3871 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3925 - accuracy: 0.8825 - val_loss: 0.3844 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3898 - accuracy: 0.8827 - val_loss: 0.3823 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3882 - accuracy: 0.8827 - val_loss: 0.3803 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3858 - accuracy: 0.8828 - val_loss: 0.3784 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3833 - accuracy: 0.8828 - val_loss: 0.3766 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3828 - accuracy: 0.8829 - val_loss: 0.3749 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3814 - accuracy: 0.8829 - val_loss: 0.3732 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3786 - accuracy: 0.8830 - val_loss: 0.3715 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3779 - accuracy: 0.8830 - val_loss: 0.3698 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3775 - accuracy: 0.8830 - val_loss: 0.3682 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3740 - accuracy: 0.8830 - val_loss: 0.3665 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3730 - accuracy: 0.8830 - val_loss: 0.3647 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3704 - accuracy: 0.8830 - val_loss: 0.3630 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 540us/step - loss: 0.3674 - accuracy: 0.8830 - val_loss: 0.3614 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 526us/step - loss: 0.3672 - accuracy: 0.8830 - val_loss: 0.3599 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3663 - accuracy: 0.8830 - val_loss: 0.3585 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3648 - accuracy: 0.8830 - val_loss: 0.3571 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3626 - accuracy: 0.8830 - val_loss: 0.3557 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3605 - accuracy: 0.8830 - val_loss: 0.3544 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3613 - accuracy: 0.8830 - val_loss: 0.3531 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3584 - accuracy: 0.8830 - val_loss: 0.3519 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3577 - accuracy: 0.8830 - val_loss: 0.3507 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 554us/step - loss: 0.3564 - accuracy: 0.8830 - val_loss: 0.3495 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.3553 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.3526 - accuracy: 0.8830 - val_loss: 0.3472 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3540 - accuracy: 0.8830 - val_loss: 0.3463 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.3524 - accuracy: 0.8830 - val_loss: 0.3451 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3510 - accuracy: 0.8830 - val_loss: 0.3441 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3501 - accuracy: 0.8830 - val_loss: 0.3431 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3495 - accuracy: 0.8831 - val_loss: 0.3422 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.3481 - accuracy: 0.8831 - val_loss: 0.3412 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.3477 - accuracy: 0.8830 - val_loss: 0.3403 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 535us/step - loss: 0.3474 - accuracy: 0.8831 - val_loss: 0.3394 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3451 - accuracy: 0.8831 - val_loss: 0.3385 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3443 - accuracy: 0.8830 - val_loss: 0.3378 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3426 - accuracy: 0.8831 - val_loss: 0.3368 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3429 - accuracy: 0.8831 - val_loss: 0.3360 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3418 - accuracy: 0.8831 - val_loss: 0.3352 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3416 - accuracy: 0.8831 - val_loss: 0.3344 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3399 - accuracy: 0.8830 - val_loss: 0.3337 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3402 - accuracy: 0.8831 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3385 - accuracy: 0.8833 - val_loss: 0.3322 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3385 - accuracy: 0.8831 - val_loss: 0.3316 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3379 - accuracy: 0.8830 - val_loss: 0.3309 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3384 - accuracy: 0.8833 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 2s 680us/step - loss: 0.3370 - accuracy: 0.8831 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "Entrenando modelo con noise_multiplier=6...\n",
      "DP-SGD with sampling rate = 0.0442% and noise_multiplier = 6 iterated over 113025 steps satisfies differential privacy with eps = 0.125 and delta = 1e-05.\n",
      "The optimal RDP order is 256.0.\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 2s 727us/step - loss: 0.5258 - accuracy: 0.7687 - val_loss: 0.4051 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 612us/step - loss: 0.4021 - accuracy: 0.8827 - val_loss: 0.3919 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 599us/step - loss: 0.3955 - accuracy: 0.8829 - val_loss: 0.3869 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.3892 - accuracy: 0.8830 - val_loss: 0.3832 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.3861 - accuracy: 0.8830 - val_loss: 0.3800 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 628us/step - loss: 0.3828 - accuracy: 0.8830 - val_loss: 0.3772 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 590us/step - loss: 0.3822 - accuracy: 0.8830 - val_loss: 0.3746 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 608us/step - loss: 0.3777 - accuracy: 0.8830 - val_loss: 0.3722 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 584us/step - loss: 0.3759 - accuracy: 0.8830 - val_loss: 0.3699 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 631us/step - loss: 0.3745 - accuracy: 0.8830 - val_loss: 0.3677 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 611us/step - loss: 0.3711 - accuracy: 0.8830 - val_loss: 0.3657 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 593us/step - loss: 0.3688 - accuracy: 0.8830 - val_loss: 0.3637 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 580us/step - loss: 0.3672 - accuracy: 0.8830 - val_loss: 0.3618 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 612us/step - loss: 0.3650 - accuracy: 0.8830 - val_loss: 0.3601 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 627us/step - loss: 0.3634 - accuracy: 0.8830 - val_loss: 0.3583 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 627us/step - loss: 0.3624 - accuracy: 0.8830 - val_loss: 0.3567 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 606us/step - loss: 0.3597 - accuracy: 0.8830 - val_loss: 0.3551 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 587us/step - loss: 0.3591 - accuracy: 0.8830 - val_loss: 0.3536 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 615us/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.3521 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 614us/step - loss: 0.3544 - accuracy: 0.8830 - val_loss: 0.3507 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3546 - accuracy: 0.8830 - val_loss: 0.3494 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 627us/step - loss: 0.3527 - accuracy: 0.8830 - val_loss: 0.3482 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 615us/step - loss: 0.3529 - accuracy: 0.8830 - val_loss: 0.3470 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3510 - accuracy: 0.8830 - val_loss: 0.3459 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 598us/step - loss: 0.3495 - accuracy: 0.8830 - val_loss: 0.3448 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.3492 - accuracy: 0.8830 - val_loss: 0.3437 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 597us/step - loss: 0.3473 - accuracy: 0.8830 - val_loss: 0.3427 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 596us/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 0.3418 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.3462 - accuracy: 0.8830 - val_loss: 0.3408 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3453 - accuracy: 0.8830 - val_loss: 0.3400 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.3442 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3433 - accuracy: 0.8830 - val_loss: 0.3383 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 588us/step - loss: 0.3427 - accuracy: 0.8830 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 568us/step - loss: 0.3412 - accuracy: 0.8830 - val_loss: 0.3368 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3410 - accuracy: 0.8830 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3404 - accuracy: 0.8830 - val_loss: 0.3354 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 594us/step - loss: 0.3400 - accuracy: 0.8830 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 568us/step - loss: 0.3395 - accuracy: 0.8830 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 600us/step - loss: 0.3385 - accuracy: 0.8830 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 564us/step - loss: 0.3375 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 588us/step - loss: 0.3370 - accuracy: 0.8830 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 604us/step - loss: 0.3364 - accuracy: 0.8830 - val_loss: 0.3320 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3372 - accuracy: 0.8830 - val_loss: 0.3315 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 609us/step - loss: 0.3361 - accuracy: 0.8830 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 613us/step - loss: 0.3356 - accuracy: 0.8830 - val_loss: 0.3307 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3345 - accuracy: 0.8830 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 610us/step - loss: 0.3354 - accuracy: 0.8830 - val_loss: 0.3298 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.3339 - accuracy: 0.8830 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 611us/step - loss: 0.3346 - accuracy: 0.8830 - val_loss: 0.3291 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3340 - accuracy: 0.8830 - val_loss: 0.3287 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 576us/step - loss: 0.4524 - accuracy: 0.8544 - val_loss: 0.3845 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 2s 718us/step - loss: 0.3937 - accuracy: 0.8829 - val_loss: 0.3797 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 2s 814us/step - loss: 0.3904 - accuracy: 0.8830 - val_loss: 0.3767 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 2s 851us/step - loss: 0.3866 - accuracy: 0.8830 - val_loss: 0.3737 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 2s 915us/step - loss: 0.3813 - accuracy: 0.8830 - val_loss: 0.3710 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 2s 759us/step - loss: 0.3778 - accuracy: 0.8830 - val_loss: 0.3682 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 605us/step - loss: 0.3751 - accuracy: 0.8830 - val_loss: 0.3658 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3724 - accuracy: 0.8830 - val_loss: 0.3634 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 625us/step - loss: 0.3699 - accuracy: 0.8830 - val_loss: 0.3610 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.3685 - accuracy: 0.8830 - val_loss: 0.3588 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 535us/step - loss: 0.3648 - accuracy: 0.8830 - val_loss: 0.3569 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 603us/step - loss: 0.3627 - accuracy: 0.8830 - val_loss: 0.3549 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 554us/step - loss: 0.3611 - accuracy: 0.8830 - val_loss: 0.3530 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3600 - accuracy: 0.8830 - val_loss: 0.3512 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3572 - accuracy: 0.8830 - val_loss: 0.3495 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 652us/step - loss: 0.3562 - accuracy: 0.8830 - val_loss: 0.3478 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 2s 704us/step - loss: 0.3536 - accuracy: 0.8830 - val_loss: 0.3463 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 599us/step - loss: 0.3531 - accuracy: 0.8830 - val_loss: 0.3448 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 2s 797us/step - loss: 0.3514 - accuracy: 0.8830 - val_loss: 0.3435 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3502 - accuracy: 0.8830 - val_loss: 0.3424 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3496 - accuracy: 0.8830 - val_loss: 0.3410 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 3s 2ms/step - loss: 0.3479 - accuracy: 0.8830 - val_loss: 0.3398 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3456 - accuracy: 0.8830 - val_loss: 0.3389 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3457 - accuracy: 0.8830 - val_loss: 0.3378 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3435 - accuracy: 0.8830 - val_loss: 0.3368 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3428 - accuracy: 0.8830 - val_loss: 0.3360 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3420 - accuracy: 0.8830 - val_loss: 0.3351 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3412 - accuracy: 0.8831 - val_loss: 0.3343 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3417 - accuracy: 0.8830 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3409 - accuracy: 0.8831 - val_loss: 0.3328 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3391 - accuracy: 0.8832 - val_loss: 0.3323 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3385 - accuracy: 0.8831 - val_loss: 0.3316 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3379 - accuracy: 0.8830 - val_loss: 0.3310 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3367 - accuracy: 0.8831 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3371 - accuracy: 0.8830 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3364 - accuracy: 0.8833 - val_loss: 0.3294 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3354 - accuracy: 0.8831 - val_loss: 0.3290 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3350 - accuracy: 0.8830 - val_loss: 0.3285 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3351 - accuracy: 0.8832 - val_loss: 0.3281 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3348 - accuracy: 0.8832 - val_loss: 0.3277 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3334 - accuracy: 0.8832 - val_loss: 0.3274 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 3s 2ms/step - loss: 0.3340 - accuracy: 0.8831 - val_loss: 0.3269 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3339 - accuracy: 0.8830 - val_loss: 0.3266 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 3s 2ms/step - loss: 0.3325 - accuracy: 0.8829 - val_loss: 0.3263 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3322 - accuracy: 0.8832 - val_loss: 0.3260 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 3s 2ms/step - loss: 0.3314 - accuracy: 0.8831 - val_loss: 0.3256 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3316 - accuracy: 0.8833 - val_loss: 0.3254 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3321 - accuracy: 0.8835 - val_loss: 0.3251 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 3s 2ms/step - loss: 0.3311 - accuracy: 0.8833 - val_loss: 0.3248 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3307 - accuracy: 0.8830 - val_loss: 0.3246 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.4908 - accuracy: 0.8232 - val_loss: 0.4067 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 3s 2ms/step - loss: 0.4072 - accuracy: 0.8830 - val_loss: 0.3974 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 3s 2ms/step - loss: 0.4008 - accuracy: 0.8829 - val_loss: 0.3929 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3960 - accuracy: 0.8830 - val_loss: 0.3891 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3949 - accuracy: 0.8830 - val_loss: 0.3857 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 3s 2ms/step - loss: 0.3904 - accuracy: 0.8830 - val_loss: 0.3827 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3875 - accuracy: 0.8830 - val_loss: 0.3796 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3833 - accuracy: 0.8830 - val_loss: 0.3768 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3811 - accuracy: 0.8830 - val_loss: 0.3739 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3801 - accuracy: 0.8830 - val_loss: 0.3713 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3760 - accuracy: 0.8830 - val_loss: 0.3688 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3731 - accuracy: 0.8830 - val_loss: 0.3663 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3721 - accuracy: 0.8830 - val_loss: 0.3640 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3698 - accuracy: 0.8830 - val_loss: 0.3619 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3661 - accuracy: 0.8830 - val_loss: 0.3598 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3649 - accuracy: 0.8830 - val_loss: 0.3578 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 3s 2ms/step - loss: 0.3625 - accuracy: 0.8830 - val_loss: 0.3559 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3614 - accuracy: 0.8830 - val_loss: 0.3541 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3585 - accuracy: 0.8830 - val_loss: 0.3524 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.3507 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3560 - accuracy: 0.8830 - val_loss: 0.3492 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3542 - accuracy: 0.8830 - val_loss: 0.3477 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3523 - accuracy: 0.8830 - val_loss: 0.3461 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3528 - accuracy: 0.8830 - val_loss: 0.3447 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.3504 - accuracy: 0.8830 - val_loss: 0.3433 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3489 - accuracy: 0.8830 - val_loss: 0.3421 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3474 - accuracy: 0.8830 - val_loss: 0.3407 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3465 - accuracy: 0.8830 - val_loss: 0.3394 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3457 - accuracy: 0.8830 - val_loss: 0.3382 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 620us/step - loss: 0.3438 - accuracy: 0.8830 - val_loss: 0.3369 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 602us/step - loss: 0.3428 - accuracy: 0.8830 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 656us/step - loss: 0.3411 - accuracy: 0.8830 - val_loss: 0.3349 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 564us/step - loss: 0.3416 - accuracy: 0.8830 - val_loss: 0.3339 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3403 - accuracy: 0.8830 - val_loss: 0.3331 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.3396 - accuracy: 0.8831 - val_loss: 0.3322 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 602us/step - loss: 0.3388 - accuracy: 0.8830 - val_loss: 0.3314 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3381 - accuracy: 0.8831 - val_loss: 0.3307 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 5s 2ms/step - loss: 0.3368 - accuracy: 0.8832 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3362 - accuracy: 0.8831 - val_loss: 0.3293 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 2s 691us/step - loss: 0.3369 - accuracy: 0.8830 - val_loss: 0.3287 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 3s 1ms/step - loss: 0.3356 - accuracy: 0.8829 - val_loss: 0.3281 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3352 - accuracy: 0.8833 - val_loss: 0.3276 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3339 - accuracy: 0.8831 - val_loss: 0.3271 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3340 - accuracy: 0.8832 - val_loss: 0.3266 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3333 - accuracy: 0.8833 - val_loss: 0.3262 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3322 - accuracy: 0.8833 - val_loss: 0.3257 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.3316 - accuracy: 0.8833 - val_loss: 0.3253 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3314 - accuracy: 0.8836 - val_loss: 0.3248 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3316 - accuracy: 0.8835 - val_loss: 0.3245 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3316 - accuracy: 0.8836 - val_loss: 0.3241 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.4648 - accuracy: 0.8358 - val_loss: 0.3967 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 535us/step - loss: 0.4029 - accuracy: 0.8827 - val_loss: 0.3901 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3968 - accuracy: 0.8829 - val_loss: 0.3856 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3913 - accuracy: 0.8829 - val_loss: 0.3817 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3891 - accuracy: 0.8829 - val_loss: 0.3780 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3853 - accuracy: 0.8830 - val_loss: 0.3748 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 526us/step - loss: 0.3813 - accuracy: 0.8829 - val_loss: 0.3713 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3777 - accuracy: 0.8830 - val_loss: 0.3681 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3747 - accuracy: 0.8829 - val_loss: 0.3649 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3716 - accuracy: 0.8830 - val_loss: 0.3620 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3690 - accuracy: 0.8830 - val_loss: 0.3593 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3657 - accuracy: 0.8830 - val_loss: 0.3569 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3634 - accuracy: 0.8830 - val_loss: 0.3548 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 606us/step - loss: 0.3603 - accuracy: 0.8830 - val_loss: 0.3527 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.3585 - accuracy: 0.8829 - val_loss: 0.3509 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3566 - accuracy: 0.8830 - val_loss: 0.3492 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 586us/step - loss: 0.3554 - accuracy: 0.8830 - val_loss: 0.3476 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 2s 787us/step - loss: 0.3525 - accuracy: 0.8830 - val_loss: 0.3461 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 2s 778us/step - loss: 0.3530 - accuracy: 0.8829 - val_loss: 0.3447 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 2s 895us/step - loss: 0.3518 - accuracy: 0.8830 - val_loss: 0.3433 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 2s 828us/step - loss: 0.3486 - accuracy: 0.8830 - val_loss: 0.3420 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 2s 879us/step - loss: 0.3496 - accuracy: 0.8830 - val_loss: 0.3407 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 2s 827us/step - loss: 0.3469 - accuracy: 0.8830 - val_loss: 0.3397 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 2s 984us/step - loss: 0.3466 - accuracy: 0.8831 - val_loss: 0.3386 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 2s 791us/step - loss: 0.3455 - accuracy: 0.8830 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 2s 759us/step - loss: 0.3437 - accuracy: 0.8830 - val_loss: 0.3365 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 2s 881us/step - loss: 0.3427 - accuracy: 0.8830 - val_loss: 0.3356 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 4s 2ms/step - loss: 0.3420 - accuracy: 0.8829 - val_loss: 0.3348 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 2s 670us/step - loss: 0.3408 - accuracy: 0.8830 - val_loss: 0.3340 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 2s 705us/step - loss: 0.3413 - accuracy: 0.8831 - val_loss: 0.3333 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.3386 - accuracy: 0.8831 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3394 - accuracy: 0.8830 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 444us/step - loss: 0.3393 - accuracy: 0.8832 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3377 - accuracy: 0.8830 - val_loss: 0.3305 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 624us/step - loss: 0.3373 - accuracy: 0.8832 - val_loss: 0.3298 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 2s 736us/step - loss: 0.3355 - accuracy: 0.8830 - val_loss: 0.3291 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 639us/step - loss: 0.3346 - accuracy: 0.8831 - val_loss: 0.3285 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3347 - accuracy: 0.8832 - val_loss: 0.3280 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 572us/step - loss: 0.3342 - accuracy: 0.8833 - val_loss: 0.3275 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3336 - accuracy: 0.8832 - val_loss: 0.3270 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 547us/step - loss: 0.3339 - accuracy: 0.8830 - val_loss: 0.3265 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3325 - accuracy: 0.8834 - val_loss: 0.3262 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3325 - accuracy: 0.8835 - val_loss: 0.3256 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 626us/step - loss: 0.3317 - accuracy: 0.8835 - val_loss: 0.3252 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.3313 - accuracy: 0.8830 - val_loss: 0.3248 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 595us/step - loss: 0.3309 - accuracy: 0.8834 - val_loss: 0.3243 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 618us/step - loss: 0.3300 - accuracy: 0.8831 - val_loss: 0.3239 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 2s 860us/step - loss: 0.3303 - accuracy: 0.8837 - val_loss: 0.3237 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 2s 948us/step - loss: 0.3306 - accuracy: 0.8833 - val_loss: 0.3233 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 2s 824us/step - loss: 0.3295 - accuracy: 0.8836 - val_loss: 0.3229 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 2s 792us/step - loss: 0.4535 - accuracy: 0.8757 - val_loss: 0.4189 - val_accuracy: 0.8828\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 2s 744us/step - loss: 0.4211 - accuracy: 0.8824 - val_loss: 0.4078 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 2s 824us/step - loss: 0.4136 - accuracy: 0.8825 - val_loss: 0.4021 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 2s 706us/step - loss: 0.4089 - accuracy: 0.8829 - val_loss: 0.3971 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 2s 695us/step - loss: 0.4029 - accuracy: 0.8830 - val_loss: 0.3927 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 2s 772us/step - loss: 0.4004 - accuracy: 0.8829 - val_loss: 0.3889 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.3961 - accuracy: 0.8830 - val_loss: 0.3853 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3933 - accuracy: 0.8830 - val_loss: 0.3820 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3909 - accuracy: 0.8830 - val_loss: 0.3790 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 604us/step - loss: 0.3874 - accuracy: 0.8829 - val_loss: 0.3763 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 554us/step - loss: 0.3854 - accuracy: 0.8830 - val_loss: 0.3736 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 553us/step - loss: 0.3816 - accuracy: 0.8829 - val_loss: 0.3712 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.3807 - accuracy: 0.8829 - val_loss: 0.3689 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 643us/step - loss: 0.3771 - accuracy: 0.8830 - val_loss: 0.3667 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 612us/step - loss: 0.3761 - accuracy: 0.8828 - val_loss: 0.3646 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 600us/step - loss: 0.3749 - accuracy: 0.8828 - val_loss: 0.3625 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 611us/step - loss: 0.3721 - accuracy: 0.8829 - val_loss: 0.3606 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 2s 668us/step - loss: 0.3708 - accuracy: 0.8829 - val_loss: 0.3589 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.3687 - accuracy: 0.8828 - val_loss: 0.3571 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 588us/step - loss: 0.3666 - accuracy: 0.8830 - val_loss: 0.3555 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 558us/step - loss: 0.3656 - accuracy: 0.8831 - val_loss: 0.3538 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 625us/step - loss: 0.3642 - accuracy: 0.8830 - val_loss: 0.3523 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 2s 756us/step - loss: 0.3622 - accuracy: 0.8831 - val_loss: 0.3509 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 2s 863us/step - loss: 0.3612 - accuracy: 0.8830 - val_loss: 0.3496 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.3600 - accuracy: 0.8830 - val_loss: 0.3483 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 568us/step - loss: 0.3589 - accuracy: 0.8829 - val_loss: 0.3471 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 615us/step - loss: 0.3580 - accuracy: 0.8829 - val_loss: 0.3459 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3555 - accuracy: 0.8831 - val_loss: 0.3447 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 554us/step - loss: 0.3548 - accuracy: 0.8830 - val_loss: 0.3437 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3535 - accuracy: 0.8829 - val_loss: 0.3426 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3524 - accuracy: 0.8835 - val_loss: 0.3417 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3507 - accuracy: 0.8829 - val_loss: 0.3407 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 583us/step - loss: 0.3500 - accuracy: 0.8832 - val_loss: 0.3399 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 616us/step - loss: 0.3507 - accuracy: 0.8830 - val_loss: 0.3390 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3493 - accuracy: 0.8829 - val_loss: 0.3383 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 553us/step - loss: 0.3487 - accuracy: 0.8830 - val_loss: 0.3374 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 559us/step - loss: 0.3477 - accuracy: 0.8829 - val_loss: 0.3366 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3444 - accuracy: 0.8831 - val_loss: 0.3352 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3442 - accuracy: 0.8832 - val_loss: 0.3345 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 594us/step - loss: 0.3444 - accuracy: 0.8830 - val_loss: 0.3338 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.3433 - accuracy: 0.8832 - val_loss: 0.3333 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.3431 - accuracy: 0.8830 - val_loss: 0.3327 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3424 - accuracy: 0.8829 - val_loss: 0.3322 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 555us/step - loss: 0.3420 - accuracy: 0.8835 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 610us/step - loss: 0.3409 - accuracy: 0.8830 - val_loss: 0.3313 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 590us/step - loss: 0.3395 - accuracy: 0.8833 - val_loss: 0.3307 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 550us/step - loss: 0.3401 - accuracy: 0.8831 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3392 - accuracy: 0.8833 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 567us/step - loss: 0.3395 - accuracy: 0.8832 - val_loss: 0.3294 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n"
     ]
    }
   ],
   "source": [
    "# 2. Variar noise_multiplier\n",
    "results_noise_multiplier = {}\n",
    "eps_noise_multiplier = {}\n",
    "for noise in noise_multiplier_values:\n",
    "    print(f\"\\nEntrenando modelo con noise_multiplier={noise}...\")\n",
    "    eps = compute_privacy_budget(n_full, default_batch_size, noise, epochs)\n",
    "    results = run_iterations(\n",
    "        X_train_full, y_train_full, X_test_full, y_test_full,\n",
    "        default_batch_size, epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=noise\n",
    "    )\n",
    "    results_noise_multiplier[noise] = compute_statistics(results)\n",
    "    eps_noise_multiplier[noise] = eps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9dc80bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo con batch_size=128...\n",
      "DP-SGD with sampling rate = 0.354% and noise_multiplier = 1.1 iterated over 14129 steps satisfies differential privacy with eps = 2.48 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "Epoch 1/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8830 - val_loss: 0.4071 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 0s 880us/step - loss: 0.4111 - accuracy: 0.8830 - val_loss: 0.4035 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 0s 865us/step - loss: 0.4080 - accuracy: 0.8830 - val_loss: 0.4011 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 0s 862us/step - loss: 0.4046 - accuracy: 0.8830 - val_loss: 0.3994 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "283/283 [==============================] - 0s 936us/step - loss: 0.4016 - accuracy: 0.8830 - val_loss: 0.3981 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "283/283 [==============================] - 0s 881us/step - loss: 0.4030 - accuracy: 0.8830 - val_loss: 0.3972 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "283/283 [==============================] - 0s 843us/step - loss: 0.4016 - accuracy: 0.8830 - val_loss: 0.3964 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "283/283 [==============================] - 0s 862us/step - loss: 0.3994 - accuracy: 0.8830 - val_loss: 0.3958 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "283/283 [==============================] - 0s 894us/step - loss: 0.3995 - accuracy: 0.8830 - val_loss: 0.3952 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "283/283 [==============================] - 0s 886us/step - loss: 0.3992 - accuracy: 0.8830 - val_loss: 0.3947 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "283/283 [==============================] - 0s 903us/step - loss: 0.3987 - accuracy: 0.8830 - val_loss: 0.3943 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "283/283 [==============================] - 0s 898us/step - loss: 0.3981 - accuracy: 0.8830 - val_loss: 0.3939 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "283/283 [==============================] - 0s 921us/step - loss: 0.3975 - accuracy: 0.8830 - val_loss: 0.3935 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "283/283 [==============================] - 0s 847us/step - loss: 0.3971 - accuracy: 0.8830 - val_loss: 0.3931 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "283/283 [==============================] - 0s 860us/step - loss: 0.3971 - accuracy: 0.8830 - val_loss: 0.3927 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "283/283 [==============================] - 0s 857us/step - loss: 0.3971 - accuracy: 0.8830 - val_loss: 0.3923 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "283/283 [==============================] - 0s 889us/step - loss: 0.3957 - accuracy: 0.8830 - val_loss: 0.3919 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "283/283 [==============================] - 0s 907us/step - loss: 0.3950 - accuracy: 0.8830 - val_loss: 0.3915 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.8830 - val_loss: 0.3911 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "283/283 [==============================] - 0s 915us/step - loss: 0.3958 - accuracy: 0.8830 - val_loss: 0.3908 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8830 - val_loss: 0.3904 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3940 - accuracy: 0.8830 - val_loss: 0.3900 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3918 - accuracy: 0.8830 - val_loss: 0.3896 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3923 - accuracy: 0.8830 - val_loss: 0.3893 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8830 - val_loss: 0.3889 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8830 - val_loss: 0.3885 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.8830 - val_loss: 0.3881 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8830 - val_loss: 0.3878 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "283/283 [==============================] - 0s 943us/step - loss: 0.3911 - accuracy: 0.8830 - val_loss: 0.3874 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "283/283 [==============================] - 0s 951us/step - loss: 0.3912 - accuracy: 0.8830 - val_loss: 0.3870 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8830 - val_loss: 0.3867 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "283/283 [==============================] - 0s 934us/step - loss: 0.3887 - accuracy: 0.8830 - val_loss: 0.3863 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "283/283 [==============================] - 0s 895us/step - loss: 0.3896 - accuracy: 0.8830 - val_loss: 0.3860 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "283/283 [==============================] - 0s 937us/step - loss: 0.3895 - accuracy: 0.8830 - val_loss: 0.3856 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "283/283 [==============================] - 0s 860us/step - loss: 0.3872 - accuracy: 0.8830 - val_loss: 0.3852 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "283/283 [==============================] - 0s 900us/step - loss: 0.3895 - accuracy: 0.8830 - val_loss: 0.3849 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8830 - val_loss: 0.3846 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8830 - val_loss: 0.3842 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8830 - val_loss: 0.3839 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8830 - val_loss: 0.3835 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8830 - val_loss: 0.3832 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8830 - val_loss: 0.3829 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3870 - accuracy: 0.8830 - val_loss: 0.3826 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8830 - val_loss: 0.3822 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8830 - val_loss: 0.3819 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8830 - val_loss: 0.3816 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "283/283 [==============================] - 0s 926us/step - loss: 0.3859 - accuracy: 0.8830 - val_loss: 0.3813 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "283/283 [==============================] - 0s 825us/step - loss: 0.3839 - accuracy: 0.8830 - val_loss: 0.3810 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "283/283 [==============================] - 0s 906us/step - loss: 0.3848 - accuracy: 0.8830 - val_loss: 0.3807 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "283/283 [==============================] - 0s 885us/step - loss: 0.3834 - accuracy: 0.8830 - val_loss: 0.3805 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "283/283 [==============================] - 0s 984us/step - loss: 0.4950 - accuracy: 0.8648 - val_loss: 0.4638 - val_accuracy: 0.8792\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 0s 962us/step - loss: 0.4600 - accuracy: 0.8756 - val_loss: 0.4387 - val_accuracy: 0.8817\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 0s 973us/step - loss: 0.4400 - accuracy: 0.8790 - val_loss: 0.4237 - val_accuracy: 0.8822\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 0s 896us/step - loss: 0.4290 - accuracy: 0.8802 - val_loss: 0.4144 - val_accuracy: 0.8822\n",
      "Epoch 5/50\n",
      "283/283 [==============================] - 0s 963us/step - loss: 0.4199 - accuracy: 0.8809 - val_loss: 0.4082 - val_accuracy: 0.8826\n",
      "Epoch 6/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8814 - val_loss: 0.4042 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.8813 - val_loss: 0.4014 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "283/283 [==============================] - 0s 822us/step - loss: 0.4085 - accuracy: 0.8824 - val_loss: 0.3994 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "283/283 [==============================] - 0s 850us/step - loss: 0.4073 - accuracy: 0.8824 - val_loss: 0.3979 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "283/283 [==============================] - 0s 793us/step - loss: 0.4046 - accuracy: 0.8824 - val_loss: 0.3968 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "283/283 [==============================] - 0s 956us/step - loss: 0.4032 - accuracy: 0.8822 - val_loss: 0.3959 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "283/283 [==============================] - 0s 953us/step - loss: 0.4039 - accuracy: 0.8823 - val_loss: 0.3952 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "283/283 [==============================] - 0s 990us/step - loss: 0.4024 - accuracy: 0.8825 - val_loss: 0.3946 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "283/283 [==============================] - 0s 920us/step - loss: 0.4012 - accuracy: 0.8825 - val_loss: 0.3940 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "283/283 [==============================] - 0s 977us/step - loss: 0.4014 - accuracy: 0.8825 - val_loss: 0.3935 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8826 - val_loss: 0.3931 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8827 - val_loss: 0.3926 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8829 - val_loss: 0.3922 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8828 - val_loss: 0.3918 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3980 - accuracy: 0.8827 - val_loss: 0.3914 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8827 - val_loss: 0.3911 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "283/283 [==============================] - 0s 869us/step - loss: 0.3967 - accuracy: 0.8826 - val_loss: 0.3907 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "283/283 [==============================] - 0s 813us/step - loss: 0.3978 - accuracy: 0.8829 - val_loss: 0.3904 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "283/283 [==============================] - 0s 865us/step - loss: 0.3969 - accuracy: 0.8828 - val_loss: 0.3900 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8828 - val_loss: 0.3897 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "283/283 [==============================] - 0s 874us/step - loss: 0.3970 - accuracy: 0.8827 - val_loss: 0.3894 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "283/283 [==============================] - 0s 794us/step - loss: 0.3960 - accuracy: 0.8829 - val_loss: 0.3891 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "283/283 [==============================] - 0s 795us/step - loss: 0.3966 - accuracy: 0.8828 - val_loss: 0.3888 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "283/283 [==============================] - 0s 791us/step - loss: 0.3963 - accuracy: 0.8829 - val_loss: 0.3884 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "283/283 [==============================] - 0s 801us/step - loss: 0.3949 - accuracy: 0.8829 - val_loss: 0.3882 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "283/283 [==============================] - 0s 937us/step - loss: 0.3964 - accuracy: 0.8829 - val_loss: 0.3879 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8829 - val_loss: 0.3876 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8828 - val_loss: 0.3873 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3948 - accuracy: 0.8828 - val_loss: 0.3870 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8828 - val_loss: 0.3867 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8829 - val_loss: 0.3864 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3941 - accuracy: 0.8828 - val_loss: 0.3862 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8829 - val_loss: 0.3859 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8829 - val_loss: 0.3856 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8829 - val_loss: 0.3853 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8830 - val_loss: 0.3851 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "283/283 [==============================] - 0s 986us/step - loss: 0.3914 - accuracy: 0.8828 - val_loss: 0.3848 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "283/283 [==============================] - 0s 928us/step - loss: 0.3901 - accuracy: 0.8830 - val_loss: 0.3845 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "283/283 [==============================] - 0s 912us/step - loss: 0.3916 - accuracy: 0.8829 - val_loss: 0.3843 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "283/283 [==============================] - 0s 955us/step - loss: 0.3897 - accuracy: 0.8829 - val_loss: 0.3840 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8830 - val_loss: 0.3837 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8829 - val_loss: 0.3835 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8830 - val_loss: 0.3832 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8830 - val_loss: 0.3830 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "283/283 [==============================] - 0s 927us/step - loss: 0.3901 - accuracy: 0.8829 - val_loss: 0.3827 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.8393 - val_loss: 0.4665 - val_accuracy: 0.8832\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.8727 - val_loss: 0.4283 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8795 - val_loss: 0.4071 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8817 - val_loss: 0.3945 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8825 - val_loss: 0.3866 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "283/283 [==============================] - 0s 994us/step - loss: 0.3957 - accuracy: 0.8824 - val_loss: 0.3815 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "283/283 [==============================] - 0s 991us/step - loss: 0.3910 - accuracy: 0.8827 - val_loss: 0.3782 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8830 - val_loss: 0.3758 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8830 - val_loss: 0.3741 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8830 - val_loss: 0.3728 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3832 - accuracy: 0.8829 - val_loss: 0.3717 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8830 - val_loss: 0.3709 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8830 - val_loss: 0.3702 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8830 - val_loss: 0.3696 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8831 - val_loss: 0.3691 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8831 - val_loss: 0.3686 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8830 - val_loss: 0.3682 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3772 - accuracy: 0.8830 - val_loss: 0.3678 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8830 - val_loss: 0.3674 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8830 - val_loss: 0.3671 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3766 - accuracy: 0.8830 - val_loss: 0.3667 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8829 - val_loss: 0.3664 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "283/283 [==============================] - 0s 993us/step - loss: 0.3753 - accuracy: 0.8830 - val_loss: 0.3661 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8830 - val_loss: 0.3657 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8831 - val_loss: 0.3654 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3732 - accuracy: 0.8830 - val_loss: 0.3651 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8830 - val_loss: 0.3649 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8830 - val_loss: 0.3646 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8830 - val_loss: 0.3643 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3640 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3637 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3723 - accuracy: 0.8830 - val_loss: 0.3635 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3632 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8830 - val_loss: 0.3629 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 0.3707 - accuracy: 0.8830 - val_loss: 0.3627 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 0.3723 - accuracy: 0.8830 - val_loss: 0.3624 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3622 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3619 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 0.3702 - accuracy: 0.8830 - val_loss: 0.3617 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3712 - accuracy: 0.8830 - val_loss: 0.3614 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3696 - accuracy: 0.8830 - val_loss: 0.3612 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3687 - accuracy: 0.8830 - val_loss: 0.3609 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3691 - accuracy: 0.8830 - val_loss: 0.3607 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3693 - accuracy: 0.8830 - val_loss: 0.3604 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 0.3685 - accuracy: 0.8830 - val_loss: 0.3602 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 0.3679 - accuracy: 0.8830 - val_loss: 0.3600 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 0.3671 - accuracy: 0.8830 - val_loss: 0.3597 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3688 - accuracy: 0.8830 - val_loss: 0.3595 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3665 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8830 - val_loss: 0.3590 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.9173 - accuracy: 0.2191 - val_loss: 0.7493 - val_accuracy: 0.1848\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.5954 - val_loss: 0.5823 - val_accuracy: 0.8796\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.8359 - val_loss: 0.5007 - val_accuracy: 0.8811\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8742 - val_loss: 0.4563 - val_accuracy: 0.8828\n",
      "Epoch 5/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.8802 - val_loss: 0.4304 - val_accuracy: 0.8828\n",
      "Epoch 6/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8821 - val_loss: 0.4142 - val_accuracy: 0.8829\n",
      "Epoch 7/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.4165 - accuracy: 0.8823 - val_loss: 0.4038 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8828 - val_loss: 0.3967 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8825 - val_loss: 0.3917 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.8828 - val_loss: 0.3882 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8827 - val_loss: 0.3856 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3922 - accuracy: 0.8829 - val_loss: 0.3836 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8829 - val_loss: 0.3821 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8829 - val_loss: 0.3810 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "283/283 [==============================] - 0s 984us/step - loss: 0.3876 - accuracy: 0.8829 - val_loss: 0.3800 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8829 - val_loss: 0.3792 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8829 - val_loss: 0.3785 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8830 - val_loss: 0.3779 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "283/283 [==============================] - 0s 914us/step - loss: 0.3848 - accuracy: 0.8830 - val_loss: 0.3773 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "283/283 [==============================] - 0s 957us/step - loss: 0.3830 - accuracy: 0.8830 - val_loss: 0.3768 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8829 - val_loss: 0.3763 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8830 - val_loss: 0.3759 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8830 - val_loss: 0.3755 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8829 - val_loss: 0.3751 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8829 - val_loss: 0.3748 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8830 - val_loss: 0.3744 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8830 - val_loss: 0.3741 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "283/283 [==============================] - 0s 947us/step - loss: 0.3806 - accuracy: 0.8830 - val_loss: 0.3737 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "283/283 [==============================] - 0s 929us/step - loss: 0.3784 - accuracy: 0.8830 - val_loss: 0.3734 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "283/283 [==============================] - 0s 957us/step - loss: 0.3790 - accuracy: 0.8830 - val_loss: 0.3730 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8830 - val_loss: 0.3727 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8829 - val_loss: 0.3724 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "283/283 [==============================] - 0s 890us/step - loss: 0.3787 - accuracy: 0.8830 - val_loss: 0.3720 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8830 - val_loss: 0.3717 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8830 - val_loss: 0.3714 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8829 - val_loss: 0.3711 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8830 - val_loss: 0.3708 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8830 - val_loss: 0.3705 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8830 - val_loss: 0.3701 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "283/283 [==============================] - 0s 994us/step - loss: 0.3763 - accuracy: 0.8830 - val_loss: 0.3698 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8830 - val_loss: 0.3695 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8830 - val_loss: 0.3692 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8830 - val_loss: 0.3690 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8830 - val_loss: 0.3687 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8830 - val_loss: 0.3684 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8830 - val_loss: 0.3681 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "283/283 [==============================] - 0s 964us/step - loss: 0.3743 - accuracy: 0.8830 - val_loss: 0.3678 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8830 - val_loss: 0.3675 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8830 - val_loss: 0.3673 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.3746 - accuracy: 0.8830 - val_loss: 0.3670 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7982 - val_loss: 0.4712 - val_accuracy: 0.8802\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8630 - val_loss: 0.4305 - val_accuracy: 0.8827\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.8762 - val_loss: 0.4122 - val_accuracy: 0.8828\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8805 - val_loss: 0.4029 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8817 - val_loss: 0.3977 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4076 - accuracy: 0.8821 - val_loss: 0.3947 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8822 - val_loss: 0.3929 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "283/283 [==============================] - 0s 997us/step - loss: 0.4028 - accuracy: 0.8825 - val_loss: 0.3916 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8827 - val_loss: 0.3907 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8826 - val_loss: 0.3900 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8827 - val_loss: 0.3894 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.8828 - val_loss: 0.3889 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.4010 - accuracy: 0.8828 - val_loss: 0.3884 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.8826 - val_loss: 0.3880 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "283/283 [==============================] - 0s 951us/step - loss: 0.3973 - accuracy: 0.8827 - val_loss: 0.3876 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.8828 - val_loss: 0.3872 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8829 - val_loss: 0.3868 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8829 - val_loss: 0.3864 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3967 - accuracy: 0.8828 - val_loss: 0.3860 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8828 - val_loss: 0.3856 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "283/283 [==============================] - 0s 974us/step - loss: 0.3943 - accuracy: 0.8829 - val_loss: 0.3852 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "283/283 [==============================] - 0s 955us/step - loss: 0.3942 - accuracy: 0.8830 - val_loss: 0.3849 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8829 - val_loss: 0.3845 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8829 - val_loss: 0.3841 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8830 - val_loss: 0.3838 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8829 - val_loss: 0.3834 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8830 - val_loss: 0.3831 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8829 - val_loss: 0.3827 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8829 - val_loss: 0.3824 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3922 - accuracy: 0.8828 - val_loss: 0.3821 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8829 - val_loss: 0.3817 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8830 - val_loss: 0.3814 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3911 - accuracy: 0.8830 - val_loss: 0.3811 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8830 - val_loss: 0.3808 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8830 - val_loss: 0.3805 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8829 - val_loss: 0.3802 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8830 - val_loss: 0.3800 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.8830 - val_loss: 0.3797 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8830 - val_loss: 0.3794 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "283/283 [==============================] - 0s 980us/step - loss: 0.3869 - accuracy: 0.8830 - val_loss: 0.3792 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "283/283 [==============================] - 0s 931us/step - loss: 0.3878 - accuracy: 0.8829 - val_loss: 0.3789 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "283/283 [==============================] - 0s 996us/step - loss: 0.3885 - accuracy: 0.8830 - val_loss: 0.3786 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8829 - val_loss: 0.3784 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.8829 - val_loss: 0.3781 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8829 - val_loss: 0.3779 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8830 - val_loss: 0.3776 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8829 - val_loss: 0.3774 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8829 - val_loss: 0.3772 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8829 - val_loss: 0.3769 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "283/283 [==============================] - 0s 919us/step - loss: 0.3839 - accuracy: 0.8830 - val_loss: 0.3767 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "Entrenando modelo con batch_size=64...\n",
      "DP-SGD with sampling rate = 0.177% and noise_multiplier = 1.1 iterated over 28257 steps satisfies differential privacy with eps = 1.72 and delta = 1e-05.\n",
      "The optimal RDP order is 14.0.\n",
      "Epoch 1/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.4681 - accuracy: 0.8694 - val_loss: 0.4266 - val_accuracy: 0.8827\n",
      "Epoch 2/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.4224 - accuracy: 0.8794 - val_loss: 0.4036 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.4089 - accuracy: 0.8812 - val_loss: 0.3949 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8821 - val_loss: 0.3910 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3967 - accuracy: 0.8822 - val_loss: 0.3890 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "566/566 [==============================] - 1s 916us/step - loss: 0.3962 - accuracy: 0.8825 - val_loss: 0.3877 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3927 - accuracy: 0.8825 - val_loss: 0.3866 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "566/566 [==============================] - 0s 872us/step - loss: 0.3936 - accuracy: 0.8825 - val_loss: 0.3856 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "566/566 [==============================] - 0s 798us/step - loss: 0.3921 - accuracy: 0.8825 - val_loss: 0.3846 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "566/566 [==============================] - 0s 852us/step - loss: 0.3913 - accuracy: 0.8826 - val_loss: 0.3834 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "566/566 [==============================] - 1s 986us/step - loss: 0.3893 - accuracy: 0.8827 - val_loss: 0.3823 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "566/566 [==============================] - 0s 822us/step - loss: 0.3890 - accuracy: 0.8824 - val_loss: 0.3812 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "566/566 [==============================] - 1s 889us/step - loss: 0.3882 - accuracy: 0.8825 - val_loss: 0.3802 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3865 - accuracy: 0.8826 - val_loss: 0.3792 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "566/566 [==============================] - 0s 826us/step - loss: 0.3869 - accuracy: 0.8828 - val_loss: 0.3782 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "566/566 [==============================] - 0s 774us/step - loss: 0.3856 - accuracy: 0.8827 - val_loss: 0.3773 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "566/566 [==============================] - 0s 745us/step - loss: 0.3845 - accuracy: 0.8827 - val_loss: 0.3763 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "566/566 [==============================] - 0s 844us/step - loss: 0.3833 - accuracy: 0.8828 - val_loss: 0.3755 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "566/566 [==============================] - 0s 763us/step - loss: 0.3848 - accuracy: 0.8827 - val_loss: 0.3746 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3824 - accuracy: 0.8828 - val_loss: 0.3738 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3825 - accuracy: 0.8827 - val_loss: 0.3730 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "566/566 [==============================] - 0s 814us/step - loss: 0.3805 - accuracy: 0.8830 - val_loss: 0.3723 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "566/566 [==============================] - 0s 784us/step - loss: 0.3798 - accuracy: 0.8827 - val_loss: 0.3716 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3779 - accuracy: 0.8827 - val_loss: 0.3709 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3786 - accuracy: 0.8828 - val_loss: 0.3702 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3770 - accuracy: 0.8829 - val_loss: 0.3696 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3787 - accuracy: 0.8829 - val_loss: 0.3689 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3762 - accuracy: 0.8829 - val_loss: 0.3683 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3754 - accuracy: 0.8830 - val_loss: 0.3678 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3749 - accuracy: 0.8829 - val_loss: 0.3672 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3738 - accuracy: 0.8828 - val_loss: 0.3666 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3740 - accuracy: 0.8830 - val_loss: 0.3661 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3730 - accuracy: 0.8830 - val_loss: 0.3656 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3729 - accuracy: 0.8830 - val_loss: 0.3651 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3726 - accuracy: 0.8828 - val_loss: 0.3645 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3737 - accuracy: 0.8828 - val_loss: 0.3640 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "566/566 [==============================] - 1s 978us/step - loss: 0.3717 - accuracy: 0.8829 - val_loss: 0.3635 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3630 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3714 - accuracy: 0.8830 - val_loss: 0.3625 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3702 - accuracy: 0.8830 - val_loss: 0.3620 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3693 - accuracy: 0.8830 - val_loss: 0.3616 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3690 - accuracy: 0.8831 - val_loss: 0.3611 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3687 - accuracy: 0.8829 - val_loss: 0.3606 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "566/566 [==============================] - 1s 976us/step - loss: 0.3675 - accuracy: 0.8829 - val_loss: 0.3602 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3680 - accuracy: 0.8830 - val_loss: 0.3597 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3661 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3669 - accuracy: 0.8830 - val_loss: 0.3588 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "566/566 [==============================] - 1s 896us/step - loss: 0.3662 - accuracy: 0.8829 - val_loss: 0.3583 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "566/566 [==============================] - 1s 896us/step - loss: 0.3653 - accuracy: 0.8829 - val_loss: 0.3579 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "566/566 [==============================] - 1s 957us/step - loss: 0.3655 - accuracy: 0.8830 - val_loss: 0.3575 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4824 - accuracy: 0.8502 - val_loss: 0.4217 - val_accuracy: 0.8776\n",
      "Epoch 2/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.4143 - accuracy: 0.8764 - val_loss: 0.3961 - val_accuracy: 0.8785\n",
      "Epoch 3/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3981 - accuracy: 0.8786 - val_loss: 0.3890 - val_accuracy: 0.8801\n",
      "Epoch 4/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3936 - accuracy: 0.8796 - val_loss: 0.3862 - val_accuracy: 0.8807\n",
      "Epoch 5/50\n",
      "566/566 [==============================] - 0s 841us/step - loss: 0.3907 - accuracy: 0.8802 - val_loss: 0.3848 - val_accuracy: 0.8808\n",
      "Epoch 6/50\n",
      "566/566 [==============================] - 0s 740us/step - loss: 0.3906 - accuracy: 0.8805 - val_loss: 0.3838 - val_accuracy: 0.8810\n",
      "Epoch 7/50\n",
      "566/566 [==============================] - 0s 672us/step - loss: 0.3874 - accuracy: 0.8808 - val_loss: 0.3830 - val_accuracy: 0.8826\n",
      "Epoch 8/50\n",
      "566/566 [==============================] - 0s 645us/step - loss: 0.3876 - accuracy: 0.8814 - val_loss: 0.3822 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "566/566 [==============================] - 0s 681us/step - loss: 0.3860 - accuracy: 0.8809 - val_loss: 0.3815 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "566/566 [==============================] - 1s 924us/step - loss: 0.3859 - accuracy: 0.8814 - val_loss: 0.3807 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "566/566 [==============================] - 0s 778us/step - loss: 0.3852 - accuracy: 0.8819 - val_loss: 0.3800 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "566/566 [==============================] - 0s 703us/step - loss: 0.3842 - accuracy: 0.8818 - val_loss: 0.3792 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "566/566 [==============================] - 0s 768us/step - loss: 0.3825 - accuracy: 0.8818 - val_loss: 0.3785 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "566/566 [==============================] - 0s 830us/step - loss: 0.3832 - accuracy: 0.8820 - val_loss: 0.3777 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "566/566 [==============================] - 0s 776us/step - loss: 0.3828 - accuracy: 0.8820 - val_loss: 0.3770 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3819 - accuracy: 0.8822 - val_loss: 0.3763 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3824 - accuracy: 0.8822 - val_loss: 0.3756 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "566/566 [==============================] - 0s 833us/step - loss: 0.3804 - accuracy: 0.8824 - val_loss: 0.3749 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "566/566 [==============================] - 1s 940us/step - loss: 0.3798 - accuracy: 0.8824 - val_loss: 0.3743 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "566/566 [==============================] - 0s 685us/step - loss: 0.3787 - accuracy: 0.8825 - val_loss: 0.3737 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "566/566 [==============================] - 0s 634us/step - loss: 0.3766 - accuracy: 0.8825 - val_loss: 0.3731 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "566/566 [==============================] - 0s 656us/step - loss: 0.3779 - accuracy: 0.8829 - val_loss: 0.3725 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "566/566 [==============================] - 0s 657us/step - loss: 0.3768 - accuracy: 0.8827 - val_loss: 0.3719 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "566/566 [==============================] - 0s 654us/step - loss: 0.3770 - accuracy: 0.8828 - val_loss: 0.3714 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "566/566 [==============================] - 0s 633us/step - loss: 0.3769 - accuracy: 0.8827 - val_loss: 0.3708 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "566/566 [==============================] - 1s 903us/step - loss: 0.3758 - accuracy: 0.8828 - val_loss: 0.3703 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3748 - accuracy: 0.8827 - val_loss: 0.3698 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3758 - accuracy: 0.8828 - val_loss: 0.3693 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "566/566 [==============================] - 1s 884us/step - loss: 0.3737 - accuracy: 0.8829 - val_loss: 0.3688 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "566/566 [==============================] - 0s 786us/step - loss: 0.3732 - accuracy: 0.8829 - val_loss: 0.3683 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "566/566 [==============================] - 1s 985us/step - loss: 0.3727 - accuracy: 0.8829 - val_loss: 0.3678 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "566/566 [==============================] - 1s 954us/step - loss: 0.3739 - accuracy: 0.8830 - val_loss: 0.3673 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3726 - accuracy: 0.8829 - val_loss: 0.3668 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3727 - accuracy: 0.8829 - val_loss: 0.3663 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3707 - accuracy: 0.8829 - val_loss: 0.3659 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "566/566 [==============================] - 0s 841us/step - loss: 0.3702 - accuracy: 0.8830 - val_loss: 0.3654 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "566/566 [==============================] - 1s 936us/step - loss: 0.3701 - accuracy: 0.8830 - val_loss: 0.3649 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "566/566 [==============================] - 1s 928us/step - loss: 0.3686 - accuracy: 0.8830 - val_loss: 0.3645 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "566/566 [==============================] - 0s 804us/step - loss: 0.3694 - accuracy: 0.8830 - val_loss: 0.3640 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "566/566 [==============================] - 0s 869us/step - loss: 0.3683 - accuracy: 0.8830 - val_loss: 0.3636 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "566/566 [==============================] - 0s 806us/step - loss: 0.3677 - accuracy: 0.8831 - val_loss: 0.3632 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "566/566 [==============================] - 1s 916us/step - loss: 0.3689 - accuracy: 0.8830 - val_loss: 0.3627 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "566/566 [==============================] - 0s 702us/step - loss: 0.3669 - accuracy: 0.8830 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "566/566 [==============================] - 0s 779us/step - loss: 0.3670 - accuracy: 0.8830 - val_loss: 0.3619 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "566/566 [==============================] - 0s 742us/step - loss: 0.3666 - accuracy: 0.8830 - val_loss: 0.3614 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "566/566 [==============================] - 0s 876us/step - loss: 0.3663 - accuracy: 0.8830 - val_loss: 0.3610 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "566/566 [==============================] - 0s 819us/step - loss: 0.3669 - accuracy: 0.8830 - val_loss: 0.3606 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8830 - val_loss: 0.3602 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "566/566 [==============================] - 1s 913us/step - loss: 0.3661 - accuracy: 0.8830 - val_loss: 0.3597 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "566/566 [==============================] - 0s 854us/step - loss: 0.3652 - accuracy: 0.8830 - val_loss: 0.3593 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "566/566 [==============================] - 0s 823us/step - loss: 0.4869 - accuracy: 0.8640 - val_loss: 0.4353 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "566/566 [==============================] - 0s 735us/step - loss: 0.4263 - accuracy: 0.8816 - val_loss: 0.4038 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "566/566 [==============================] - 0s 654us/step - loss: 0.4040 - accuracy: 0.8826 - val_loss: 0.3915 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "566/566 [==============================] - 0s 669us/step - loss: 0.3953 - accuracy: 0.8830 - val_loss: 0.3858 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "566/566 [==============================] - 0s 878us/step - loss: 0.3907 - accuracy: 0.8830 - val_loss: 0.3827 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "566/566 [==============================] - 0s 771us/step - loss: 0.3881 - accuracy: 0.8830 - val_loss: 0.3807 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "566/566 [==============================] - 1s 966us/step - loss: 0.3861 - accuracy: 0.8830 - val_loss: 0.3791 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "566/566 [==============================] - 0s 814us/step - loss: 0.3847 - accuracy: 0.8830 - val_loss: 0.3777 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "566/566 [==============================] - 1s 929us/step - loss: 0.3841 - accuracy: 0.8830 - val_loss: 0.3765 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "566/566 [==============================] - 0s 822us/step - loss: 0.3819 - accuracy: 0.8830 - val_loss: 0.3753 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "566/566 [==============================] - 1s 908us/step - loss: 0.3818 - accuracy: 0.8830 - val_loss: 0.3742 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "566/566 [==============================] - 0s 804us/step - loss: 0.3796 - accuracy: 0.8830 - val_loss: 0.3731 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "566/566 [==============================] - 0s 747us/step - loss: 0.3796 - accuracy: 0.8830 - val_loss: 0.3720 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "566/566 [==============================] - 0s 727us/step - loss: 0.3764 - accuracy: 0.8830 - val_loss: 0.3709 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "566/566 [==============================] - 0s 748us/step - loss: 0.3769 - accuracy: 0.8830 - val_loss: 0.3699 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "566/566 [==============================] - 0s 825us/step - loss: 0.3750 - accuracy: 0.8830 - val_loss: 0.3688 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "566/566 [==============================] - 0s 796us/step - loss: 0.3743 - accuracy: 0.8830 - val_loss: 0.3678 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "566/566 [==============================] - 0s 783us/step - loss: 0.3729 - accuracy: 0.8830 - val_loss: 0.3668 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "566/566 [==============================] - 1s 900us/step - loss: 0.3717 - accuracy: 0.8830 - val_loss: 0.3658 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "566/566 [==============================] - 0s 709us/step - loss: 0.3715 - accuracy: 0.8830 - val_loss: 0.3648 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "566/566 [==============================] - 0s 692us/step - loss: 0.3705 - accuracy: 0.8830 - val_loss: 0.3638 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "566/566 [==============================] - 0s 806us/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3628 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "566/566 [==============================] - 0s 844us/step - loss: 0.3692 - accuracy: 0.8830 - val_loss: 0.3619 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "566/566 [==============================] - 0s 840us/step - loss: 0.3671 - accuracy: 0.8830 - val_loss: 0.3610 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "566/566 [==============================] - 0s 827us/step - loss: 0.3674 - accuracy: 0.8830 - val_loss: 0.3601 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "566/566 [==============================] - 0s 743us/step - loss: 0.3678 - accuracy: 0.8830 - val_loss: 0.3593 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "566/566 [==============================] - 0s 644us/step - loss: 0.3643 - accuracy: 0.8830 - val_loss: 0.3585 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "566/566 [==============================] - 0s 620us/step - loss: 0.3630 - accuracy: 0.8830 - val_loss: 0.3577 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "566/566 [==============================] - 1s 985us/step - loss: 0.3641 - accuracy: 0.8830 - val_loss: 0.3570 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "566/566 [==============================] - 1s 953us/step - loss: 0.3620 - accuracy: 0.8830 - val_loss: 0.3563 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "566/566 [==============================] - 1s 966us/step - loss: 0.3613 - accuracy: 0.8830 - val_loss: 0.3556 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "566/566 [==============================] - 0s 858us/step - loss: 0.3614 - accuracy: 0.8830 - val_loss: 0.3549 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3605 - accuracy: 0.8830 - val_loss: 0.3542 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "566/566 [==============================] - 0s 756us/step - loss: 0.3599 - accuracy: 0.8830 - val_loss: 0.3535 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "566/566 [==============================] - 0s 780us/step - loss: 0.3602 - accuracy: 0.8830 - val_loss: 0.3529 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "566/566 [==============================] - 0s 696us/step - loss: 0.3593 - accuracy: 0.8830 - val_loss: 0.3523 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "566/566 [==============================] - 1s 893us/step - loss: 0.3589 - accuracy: 0.8830 - val_loss: 0.3516 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "566/566 [==============================] - 0s 876us/step - loss: 0.3587 - accuracy: 0.8830 - val_loss: 0.3510 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "566/566 [==============================] - 0s 646us/step - loss: 0.3581 - accuracy: 0.8830 - val_loss: 0.3504 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "566/566 [==============================] - 0s 680us/step - loss: 0.3573 - accuracy: 0.8830 - val_loss: 0.3498 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "566/566 [==============================] - 0s 714us/step - loss: 0.3562 - accuracy: 0.8830 - val_loss: 0.3493 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "566/566 [==============================] - 0s 816us/step - loss: 0.3561 - accuracy: 0.8830 - val_loss: 0.3487 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3548 - accuracy: 0.8830 - val_loss: 0.3482 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3541 - accuracy: 0.8830 - val_loss: 0.3476 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "566/566 [==============================] - 1s 981us/step - loss: 0.3534 - accuracy: 0.8831 - val_loss: 0.3471 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "566/566 [==============================] - 0s 822us/step - loss: 0.3536 - accuracy: 0.8830 - val_loss: 0.3466 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "566/566 [==============================] - 0s 883us/step - loss: 0.3532 - accuracy: 0.8830 - val_loss: 0.3461 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "566/566 [==============================] - 0s 720us/step - loss: 0.3526 - accuracy: 0.8831 - val_loss: 0.3456 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "566/566 [==============================] - 0s 821us/step - loss: 0.3522 - accuracy: 0.8831 - val_loss: 0.3451 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "566/566 [==============================] - 0s 824us/step - loss: 0.3509 - accuracy: 0.8830 - val_loss: 0.3446 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "566/566 [==============================] - 0s 853us/step - loss: 0.5642 - accuracy: 0.7543 - val_loss: 0.4537 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "566/566 [==============================] - 0s 647us/step - loss: 0.4403 - accuracy: 0.8798 - val_loss: 0.4111 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "566/566 [==============================] - 0s 664us/step - loss: 0.4145 - accuracy: 0.8826 - val_loss: 0.3996 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "566/566 [==============================] - 0s 699us/step - loss: 0.4067 - accuracy: 0.8829 - val_loss: 0.3950 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "566/566 [==============================] - 0s 648us/step - loss: 0.4029 - accuracy: 0.8830 - val_loss: 0.3926 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "566/566 [==============================] - 0s 630us/step - loss: 0.3994 - accuracy: 0.8829 - val_loss: 0.3907 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "566/566 [==============================] - 0s 663us/step - loss: 0.3977 - accuracy: 0.8830 - val_loss: 0.3892 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "566/566 [==============================] - 0s 753us/step - loss: 0.3966 - accuracy: 0.8830 - val_loss: 0.3878 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "566/566 [==============================] - 0s 701us/step - loss: 0.3963 - accuracy: 0.8830 - val_loss: 0.3866 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "566/566 [==============================] - 0s 645us/step - loss: 0.3929 - accuracy: 0.8830 - val_loss: 0.3855 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "566/566 [==============================] - 0s 674us/step - loss: 0.3928 - accuracy: 0.8830 - val_loss: 0.3845 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "566/566 [==============================] - 0s 695us/step - loss: 0.3918 - accuracy: 0.8830 - val_loss: 0.3836 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "566/566 [==============================] - 0s 675us/step - loss: 0.3911 - accuracy: 0.8830 - val_loss: 0.3827 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "566/566 [==============================] - 0s 638us/step - loss: 0.3884 - accuracy: 0.8830 - val_loss: 0.3819 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "566/566 [==============================] - 0s 732us/step - loss: 0.3904 - accuracy: 0.8830 - val_loss: 0.3812 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "566/566 [==============================] - 0s 782us/step - loss: 0.3894 - accuracy: 0.8830 - val_loss: 0.3804 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "566/566 [==============================] - 0s 625us/step - loss: 0.3870 - accuracy: 0.8830 - val_loss: 0.3798 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "566/566 [==============================] - 0s 627us/step - loss: 0.3877 - accuracy: 0.8830 - val_loss: 0.3791 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "566/566 [==============================] - 0s 606us/step - loss: 0.3871 - accuracy: 0.8830 - val_loss: 0.3784 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "566/566 [==============================] - 0s 805us/step - loss: 0.3846 - accuracy: 0.8830 - val_loss: 0.3778 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "566/566 [==============================] - 0s 636us/step - loss: 0.3857 - accuracy: 0.8830 - val_loss: 0.3772 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "566/566 [==============================] - 0s 657us/step - loss: 0.3832 - accuracy: 0.8830 - val_loss: 0.3766 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "566/566 [==============================] - 0s 801us/step - loss: 0.3852 - accuracy: 0.8830 - val_loss: 0.3760 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "566/566 [==============================] - 0s 658us/step - loss: 0.3840 - accuracy: 0.8830 - val_loss: 0.3754 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "566/566 [==============================] - 0s 617us/step - loss: 0.3816 - accuracy: 0.8830 - val_loss: 0.3749 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "566/566 [==============================] - 0s 648us/step - loss: 0.3820 - accuracy: 0.8830 - val_loss: 0.3743 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "566/566 [==============================] - 0s 615us/step - loss: 0.3821 - accuracy: 0.8830 - val_loss: 0.3738 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "566/566 [==============================] - 0s 713us/step - loss: 0.3825 - accuracy: 0.8830 - val_loss: 0.3732 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "566/566 [==============================] - 0s 717us/step - loss: 0.3797 - accuracy: 0.8830 - val_loss: 0.3727 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "566/566 [==============================] - 0s 844us/step - loss: 0.3791 - accuracy: 0.8830 - val_loss: 0.3721 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "566/566 [==============================] - 0s 727us/step - loss: 0.3785 - accuracy: 0.8830 - val_loss: 0.3716 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "566/566 [==============================] - 0s 669us/step - loss: 0.3785 - accuracy: 0.8830 - val_loss: 0.3711 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "566/566 [==============================] - 0s 710us/step - loss: 0.3761 - accuracy: 0.8830 - val_loss: 0.3705 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "566/566 [==============================] - 0s 861us/step - loss: 0.3778 - accuracy: 0.8830 - val_loss: 0.3700 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "566/566 [==============================] - 0s 736us/step - loss: 0.3773 - accuracy: 0.8830 - val_loss: 0.3694 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "566/566 [==============================] - 0s 662us/step - loss: 0.3755 - accuracy: 0.8830 - val_loss: 0.3689 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "566/566 [==============================] - 0s 665us/step - loss: 0.3752 - accuracy: 0.8830 - val_loss: 0.3683 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "566/566 [==============================] - 0s 726us/step - loss: 0.3752 - accuracy: 0.8830 - val_loss: 0.3678 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "566/566 [==============================] - 0s 660us/step - loss: 0.3747 - accuracy: 0.8830 - val_loss: 0.3672 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "566/566 [==============================] - 0s 615us/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3666 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "566/566 [==============================] - 0s 609us/step - loss: 0.3740 - accuracy: 0.8830 - val_loss: 0.3660 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "566/566 [==============================] - 0s 639us/step - loss: 0.3723 - accuracy: 0.8830 - val_loss: 0.3655 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "566/566 [==============================] - 0s 679us/step - loss: 0.3721 - accuracy: 0.8830 - val_loss: 0.3649 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "566/566 [==============================] - 0s 747us/step - loss: 0.3700 - accuracy: 0.8830 - val_loss: 0.3644 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "566/566 [==============================] - 0s 740us/step - loss: 0.3709 - accuracy: 0.8830 - val_loss: 0.3640 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "566/566 [==============================] - 0s 738us/step - loss: 0.3701 - accuracy: 0.8830 - val_loss: 0.3635 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "566/566 [==============================] - 0s 685us/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3630 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "566/566 [==============================] - 0s 681us/step - loss: 0.3698 - accuracy: 0.8830 - val_loss: 0.3625 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "566/566 [==============================] - 0s 687us/step - loss: 0.3694 - accuracy: 0.8830 - val_loss: 0.3621 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "566/566 [==============================] - 0s 724us/step - loss: 0.3677 - accuracy: 0.8830 - val_loss: 0.3616 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566/566 [==============================] - 1s 950us/step - loss: 0.6779 - accuracy: 0.6139 - val_loss: 0.4443 - val_accuracy: 0.8825\n",
      "Epoch 2/50\n",
      "566/566 [==============================] - 0s 735us/step - loss: 0.4377 - accuracy: 0.8673 - val_loss: 0.3990 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "566/566 [==============================] - 0s 695us/step - loss: 0.4097 - accuracy: 0.8796 - val_loss: 0.3911 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "566/566 [==============================] - 0s 725us/step - loss: 0.4063 - accuracy: 0.8809 - val_loss: 0.3887 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "566/566 [==============================] - 0s 675us/step - loss: 0.4022 - accuracy: 0.8815 - val_loss: 0.3874 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "566/566 [==============================] - 0s 667us/step - loss: 0.4013 - accuracy: 0.8822 - val_loss: 0.3863 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "566/566 [==============================] - 0s 687us/step - loss: 0.3997 - accuracy: 0.8819 - val_loss: 0.3852 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "566/566 [==============================] - 0s 685us/step - loss: 0.3963 - accuracy: 0.8825 - val_loss: 0.3841 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "566/566 [==============================] - 0s 673us/step - loss: 0.3969 - accuracy: 0.8824 - val_loss: 0.3831 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "566/566 [==============================] - 0s 736us/step - loss: 0.3961 - accuracy: 0.8822 - val_loss: 0.3820 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "566/566 [==============================] - 0s 779us/step - loss: 0.3962 - accuracy: 0.8821 - val_loss: 0.3810 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "566/566 [==============================] - 0s 700us/step - loss: 0.3944 - accuracy: 0.8825 - val_loss: 0.3801 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "566/566 [==============================] - 0s 692us/step - loss: 0.3923 - accuracy: 0.8826 - val_loss: 0.3792 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "566/566 [==============================] - 0s 664us/step - loss: 0.3897 - accuracy: 0.8828 - val_loss: 0.3783 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "566/566 [==============================] - 0s 724us/step - loss: 0.3910 - accuracy: 0.8828 - val_loss: 0.3774 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "566/566 [==============================] - 0s 806us/step - loss: 0.3889 - accuracy: 0.8826 - val_loss: 0.3766 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "566/566 [==============================] - 0s 842us/step - loss: 0.3875 - accuracy: 0.8826 - val_loss: 0.3759 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "566/566 [==============================] - 0s 730us/step - loss: 0.3864 - accuracy: 0.8829 - val_loss: 0.3751 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "566/566 [==============================] - 0s 702us/step - loss: 0.3871 - accuracy: 0.8828 - val_loss: 0.3744 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "566/566 [==============================] - 0s 652us/step - loss: 0.3868 - accuracy: 0.8827 - val_loss: 0.3736 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "566/566 [==============================] - 0s 623us/step - loss: 0.3854 - accuracy: 0.8828 - val_loss: 0.3729 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "566/566 [==============================] - 0s 624us/step - loss: 0.3855 - accuracy: 0.8828 - val_loss: 0.3722 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "566/566 [==============================] - 0s 624us/step - loss: 0.3839 - accuracy: 0.8829 - val_loss: 0.3716 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3824 - accuracy: 0.8827 - val_loss: 0.3709 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "566/566 [==============================] - 0s 818us/step - loss: 0.3815 - accuracy: 0.8826 - val_loss: 0.3703 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "566/566 [==============================] - 0s 783us/step - loss: 0.3800 - accuracy: 0.8829 - val_loss: 0.3697 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 0.3793 - accuracy: 0.8830 - val_loss: 0.3691 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "566/566 [==============================] - 0s 773us/step - loss: 0.3792 - accuracy: 0.8829 - val_loss: 0.3686 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "566/566 [==============================] - 0s 682us/step - loss: 0.3779 - accuracy: 0.8829 - val_loss: 0.3680 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "566/566 [==============================] - 0s 677us/step - loss: 0.3785 - accuracy: 0.8829 - val_loss: 0.3674 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "566/566 [==============================] - 0s 617us/step - loss: 0.3787 - accuracy: 0.8829 - val_loss: 0.3669 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "566/566 [==============================] - 0s 668us/step - loss: 0.3770 - accuracy: 0.8830 - val_loss: 0.3664 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "566/566 [==============================] - 0s 667us/step - loss: 0.3772 - accuracy: 0.8829 - val_loss: 0.3659 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "566/566 [==============================] - 0s 812us/step - loss: 0.3752 - accuracy: 0.8829 - val_loss: 0.3654 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "566/566 [==============================] - 0s 784us/step - loss: 0.3751 - accuracy: 0.8827 - val_loss: 0.3649 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "566/566 [==============================] - 0s 631us/step - loss: 0.3745 - accuracy: 0.8829 - val_loss: 0.3644 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "566/566 [==============================] - 0s 712us/step - loss: 0.3749 - accuracy: 0.8830 - val_loss: 0.3639 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "566/566 [==============================] - 0s 650us/step - loss: 0.3741 - accuracy: 0.8830 - val_loss: 0.3635 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "566/566 [==============================] - 0s 654us/step - loss: 0.3745 - accuracy: 0.8830 - val_loss: 0.3630 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "566/566 [==============================] - 0s 693us/step - loss: 0.3722 - accuracy: 0.8830 - val_loss: 0.3625 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "566/566 [==============================] - 0s 656us/step - loss: 0.3713 - accuracy: 0.8829 - val_loss: 0.3621 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "566/566 [==============================] - 0s 676us/step - loss: 0.3727 - accuracy: 0.8829 - val_loss: 0.3616 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "566/566 [==============================] - 0s 700us/step - loss: 0.3708 - accuracy: 0.8831 - val_loss: 0.3612 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "566/566 [==============================] - 0s 644us/step - loss: 0.3699 - accuracy: 0.8830 - val_loss: 0.3607 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "566/566 [==============================] - 0s 616us/step - loss: 0.3713 - accuracy: 0.8830 - val_loss: 0.3603 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "566/566 [==============================] - 0s 681us/step - loss: 0.3687 - accuracy: 0.8830 - val_loss: 0.3599 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "566/566 [==============================] - 0s 675us/step - loss: 0.3687 - accuracy: 0.8829 - val_loss: 0.3594 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "566/566 [==============================] - 0s 658us/step - loss: 0.3675 - accuracy: 0.8830 - val_loss: 0.3590 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "566/566 [==============================] - 0s 633us/step - loss: 0.3686 - accuracy: 0.8830 - val_loss: 0.3586 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "566/566 [==============================] - 0s 615us/step - loss: 0.3679 - accuracy: 0.8830 - val_loss: 0.3582 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "Entrenando modelo con batch_size=32...\n",
      "DP-SGD with sampling rate = 0.0885% and noise_multiplier = 1.1 iterated over 56513 steps satisfies differential privacy with eps = 1.24 and delta = 1e-05.\n",
      "The optimal RDP order is 16.0.\n",
      "Epoch 1/50\n",
      "1131/1131 [==============================] - 1s 604us/step - loss: 0.4434 - accuracy: 0.8742 - val_loss: 0.4083 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "1131/1131 [==============================] - 1s 598us/step - loss: 0.4150 - accuracy: 0.8825 - val_loss: 0.3968 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "1131/1131 [==============================] - 1s 570us/step - loss: 0.4037 - accuracy: 0.8828 - val_loss: 0.3930 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "1131/1131 [==============================] - 1s 588us/step - loss: 0.4025 - accuracy: 0.8829 - val_loss: 0.3910 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "1131/1131 [==============================] - 1s 565us/step - loss: 0.4012 - accuracy: 0.8829 - val_loss: 0.3895 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "1131/1131 [==============================] - 1s 577us/step - loss: 0.3998 - accuracy: 0.8829 - val_loss: 0.3881 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "1131/1131 [==============================] - 1s 548us/step - loss: 0.3973 - accuracy: 0.8830 - val_loss: 0.3867 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "1131/1131 [==============================] - 1s 575us/step - loss: 0.3960 - accuracy: 0.8830 - val_loss: 0.3855 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "1131/1131 [==============================] - 1s 541us/step - loss: 0.3940 - accuracy: 0.8830 - val_loss: 0.3843 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "1131/1131 [==============================] - 1s 559us/step - loss: 0.3928 - accuracy: 0.8830 - val_loss: 0.3832 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "1131/1131 [==============================] - 1s 566us/step - loss: 0.3929 - accuracy: 0.8830 - val_loss: 0.3821 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "1131/1131 [==============================] - 1s 583us/step - loss: 0.3916 - accuracy: 0.8830 - val_loss: 0.3811 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "1131/1131 [==============================] - 1s 622us/step - loss: 0.3888 - accuracy: 0.8830 - val_loss: 0.3801 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "1131/1131 [==============================] - 1s 615us/step - loss: 0.3877 - accuracy: 0.8830 - val_loss: 0.3791 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "1131/1131 [==============================] - 1s 624us/step - loss: 0.3872 - accuracy: 0.8830 - val_loss: 0.3781 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "1131/1131 [==============================] - 1s 559us/step - loss: 0.3865 - accuracy: 0.8830 - val_loss: 0.3772 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "1131/1131 [==============================] - 1s 644us/step - loss: 0.3855 - accuracy: 0.8830 - val_loss: 0.3762 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "1131/1131 [==============================] - 1s 592us/step - loss: 0.3847 - accuracy: 0.8830 - val_loss: 0.3752 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "1131/1131 [==============================] - 1s 560us/step - loss: 0.3829 - accuracy: 0.8830 - val_loss: 0.3743 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "1131/1131 [==============================] - 1s 612us/step - loss: 0.3799 - accuracy: 0.8830 - val_loss: 0.3734 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "1131/1131 [==============================] - 1s 567us/step - loss: 0.3801 - accuracy: 0.8830 - val_loss: 0.3725 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "1131/1131 [==============================] - 1s 564us/step - loss: 0.3800 - accuracy: 0.8830 - val_loss: 0.3716 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "1131/1131 [==============================] - 1s 554us/step - loss: 0.3778 - accuracy: 0.8830 - val_loss: 0.3708 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "1131/1131 [==============================] - 1s 547us/step - loss: 0.3761 - accuracy: 0.8830 - val_loss: 0.3699 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "1131/1131 [==============================] - 1s 598us/step - loss: 0.3761 - accuracy: 0.8830 - val_loss: 0.3690 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "1131/1131 [==============================] - 1s 636us/step - loss: 0.3758 - accuracy: 0.8830 - val_loss: 0.3681 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "1131/1131 [==============================] - 1s 651us/step - loss: 0.3739 - accuracy: 0.8830 - val_loss: 0.3671 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "1131/1131 [==============================] - 1s 582us/step - loss: 0.3729 - accuracy: 0.8830 - val_loss: 0.3661 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "1131/1131 [==============================] - 1s 569us/step - loss: 0.3723 - accuracy: 0.8830 - val_loss: 0.3650 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "1131/1131 [==============================] - 1s 538us/step - loss: 0.3708 - accuracy: 0.8830 - val_loss: 0.3638 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "1131/1131 [==============================] - 1s 543us/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3627 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "1131/1131 [==============================] - 1s 562us/step - loss: 0.3674 - accuracy: 0.8830 - val_loss: 0.3615 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "1131/1131 [==============================] - 1s 563us/step - loss: 0.3682 - accuracy: 0.8830 - val_loss: 0.3604 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "1131/1131 [==============================] - 1s 580us/step - loss: 0.3672 - accuracy: 0.8830 - val_loss: 0.3594 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "1131/1131 [==============================] - 1s 537us/step - loss: 0.3659 - accuracy: 0.8830 - val_loss: 0.3585 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "1131/1131 [==============================] - 1s 533us/step - loss: 0.3652 - accuracy: 0.8830 - val_loss: 0.3577 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "1131/1131 [==============================] - 1s 597us/step - loss: 0.3652 - accuracy: 0.8830 - val_loss: 0.3569 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "1131/1131 [==============================] - 1s 580us/step - loss: 0.3630 - accuracy: 0.8830 - val_loss: 0.3561 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "1131/1131 [==============================] - 1s 547us/step - loss: 0.3623 - accuracy: 0.8830 - val_loss: 0.3554 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "1131/1131 [==============================] - 1s 571us/step - loss: 0.3619 - accuracy: 0.8830 - val_loss: 0.3547 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "1131/1131 [==============================] - 1s 563us/step - loss: 0.3621 - accuracy: 0.8830 - val_loss: 0.3540 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "1131/1131 [==============================] - 1s 573us/step - loss: 0.3601 - accuracy: 0.8830 - val_loss: 0.3533 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "1131/1131 [==============================] - 1s 540us/step - loss: 0.3598 - accuracy: 0.8830 - val_loss: 0.3527 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "1131/1131 [==============================] - 1s 538us/step - loss: 0.3594 - accuracy: 0.8830 - val_loss: 0.3520 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "1131/1131 [==============================] - 1s 568us/step - loss: 0.3590 - accuracy: 0.8830 - val_loss: 0.3514 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "1131/1131 [==============================] - 1s 524us/step - loss: 0.3574 - accuracy: 0.8830 - val_loss: 0.3508 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "1131/1131 [==============================] - 1s 527us/step - loss: 0.3572 - accuracy: 0.8830 - val_loss: 0.3502 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "1131/1131 [==============================] - 1s 560us/step - loss: 0.3571 - accuracy: 0.8830 - val_loss: 0.3496 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "1131/1131 [==============================] - 1s 557us/step - loss: 0.3560 - accuracy: 0.8830 - val_loss: 0.3490 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "1131/1131 [==============================] - 1s 526us/step - loss: 0.3556 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131/1131 [==============================] - 1s 568us/step - loss: 0.5145 - accuracy: 0.8073 - val_loss: 0.4147 - val_accuracy: 0.8825\n",
      "Epoch 2/50\n",
      "1131/1131 [==============================] - 1s 510us/step - loss: 0.4081 - accuracy: 0.8819 - val_loss: 0.3912 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "1131/1131 [==============================] - 1s 522us/step - loss: 0.3964 - accuracy: 0.8828 - val_loss: 0.3861 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "1131/1131 [==============================] - 1s 543us/step - loss: 0.3921 - accuracy: 0.8830 - val_loss: 0.3837 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "1131/1131 [==============================] - 1s 687us/step - loss: 0.3889 - accuracy: 0.8830 - val_loss: 0.3820 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "1131/1131 [==============================] - 1s 557us/step - loss: 0.3894 - accuracy: 0.8830 - val_loss: 0.3806 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "1131/1131 [==============================] - 1s 596us/step - loss: 0.3872 - accuracy: 0.8830 - val_loss: 0.3793 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "1131/1131 [==============================] - 1s 571us/step - loss: 0.3859 - accuracy: 0.8830 - val_loss: 0.3782 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "1131/1131 [==============================] - 1s 534us/step - loss: 0.3845 - accuracy: 0.8830 - val_loss: 0.3770 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "1131/1131 [==============================] - 1s 651us/step - loss: 0.3842 - accuracy: 0.8830 - val_loss: 0.3759 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "1131/1131 [==============================] - 1s 574us/step - loss: 0.3816 - accuracy: 0.8830 - val_loss: 0.3748 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "1131/1131 [==============================] - 1s 601us/step - loss: 0.3807 - accuracy: 0.8830 - val_loss: 0.3738 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "1131/1131 [==============================] - 1s 606us/step - loss: 0.3793 - accuracy: 0.8830 - val_loss: 0.3728 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "1131/1131 [==============================] - 1s 576us/step - loss: 0.3787 - accuracy: 0.8830 - val_loss: 0.3719 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "1131/1131 [==============================] - 1s 531us/step - loss: 0.3783 - accuracy: 0.8830 - val_loss: 0.3709 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "1131/1131 [==============================] - 1s 593us/step - loss: 0.3775 - accuracy: 0.8830 - val_loss: 0.3701 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "1131/1131 [==============================] - 1s 575us/step - loss: 0.3763 - accuracy: 0.8830 - val_loss: 0.3692 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "1131/1131 [==============================] - 1s 541us/step - loss: 0.3759 - accuracy: 0.8830 - val_loss: 0.3683 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "1131/1131 [==============================] - 1s 577us/step - loss: 0.3747 - accuracy: 0.8830 - val_loss: 0.3675 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "1131/1131 [==============================] - 1s 585us/step - loss: 0.3744 - accuracy: 0.8830 - val_loss: 0.3667 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "1131/1131 [==============================] - 1s 539us/step - loss: 0.3725 - accuracy: 0.8830 - val_loss: 0.3659 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "1131/1131 [==============================] - 1s 567us/step - loss: 0.3708 - accuracy: 0.8830 - val_loss: 0.3651 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "1131/1131 [==============================] - 1s 567us/step - loss: 0.3717 - accuracy: 0.8830 - val_loss: 0.3644 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "1131/1131 [==============================] - 1s 551us/step - loss: 0.3701 - accuracy: 0.8830 - val_loss: 0.3636 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "1131/1131 [==============================] - 1s 553us/step - loss: 0.3698 - accuracy: 0.8830 - val_loss: 0.3629 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "1131/1131 [==============================] - 1s 579us/step - loss: 0.3677 - accuracy: 0.8830 - val_loss: 0.3622 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "1131/1131 [==============================] - 1s 540us/step - loss: 0.3675 - accuracy: 0.8830 - val_loss: 0.3615 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "1131/1131 [==============================] - 1s 598us/step - loss: 0.3675 - accuracy: 0.8830 - val_loss: 0.3608 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "1131/1131 [==============================] - 1s 555us/step - loss: 0.3661 - accuracy: 0.8830 - val_loss: 0.3602 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "1131/1131 [==============================] - 1s 599us/step - loss: 0.3663 - accuracy: 0.8830 - val_loss: 0.3595 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "1131/1131 [==============================] - 1s 658us/step - loss: 0.3645 - accuracy: 0.8830 - val_loss: 0.3588 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "1131/1131 [==============================] - 1s 656us/step - loss: 0.3645 - accuracy: 0.8830 - val_loss: 0.3582 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "1131/1131 [==============================] - 1s 620us/step - loss: 0.3649 - accuracy: 0.8830 - val_loss: 0.3576 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "1131/1131 [==============================] - 1s 557us/step - loss: 0.3628 - accuracy: 0.8830 - val_loss: 0.3569 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "1131/1131 [==============================] - 1s 622us/step - loss: 0.3614 - accuracy: 0.8830 - val_loss: 0.3563 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "1131/1131 [==============================] - 1s 566us/step - loss: 0.3626 - accuracy: 0.8830 - val_loss: 0.3557 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "1131/1131 [==============================] - 1s 609us/step - loss: 0.3623 - accuracy: 0.8830 - val_loss: 0.3551 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "1131/1131 [==============================] - 1s 545us/step - loss: 0.3599 - accuracy: 0.8830 - val_loss: 0.3545 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "1131/1131 [==============================] - 1s 598us/step - loss: 0.3593 - accuracy: 0.8830 - val_loss: 0.3539 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "1131/1131 [==============================] - 1s 590us/step - loss: 0.3601 - accuracy: 0.8830 - val_loss: 0.3534 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "1131/1131 [==============================] - 1s 553us/step - loss: 0.3571 - accuracy: 0.8830 - val_loss: 0.3528 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "1131/1131 [==============================] - 1s 586us/step - loss: 0.3585 - accuracy: 0.8830 - val_loss: 0.3523 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "1131/1131 [==============================] - 1s 552us/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.3517 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "1131/1131 [==============================] - 1s 536us/step - loss: 0.3572 - accuracy: 0.8830 - val_loss: 0.3512 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "1131/1131 [==============================] - 1s 540us/step - loss: 0.3570 - accuracy: 0.8830 - val_loss: 0.3506 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "1131/1131 [==============================] - 1s 567us/step - loss: 0.3569 - accuracy: 0.8830 - val_loss: 0.3501 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "1131/1131 [==============================] - 1s 534us/step - loss: 0.3556 - accuracy: 0.8830 - val_loss: 0.3496 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "1131/1131 [==============================] - 1s 630us/step - loss: 0.3541 - accuracy: 0.8830 - val_loss: 0.3491 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "1131/1131 [==============================] - 1s 546us/step - loss: 0.3550 - accuracy: 0.8830 - val_loss: 0.3486 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "1131/1131 [==============================] - 1s 578us/step - loss: 0.3539 - accuracy: 0.8830 - val_loss: 0.3482 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131/1131 [==============================] - 1s 588us/step - loss: 0.4354 - accuracy: 0.8761 - val_loss: 0.3937 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "1131/1131 [==============================] - 1s 509us/step - loss: 0.3993 - accuracy: 0.8825 - val_loss: 0.3824 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "1131/1131 [==============================] - 1s 516us/step - loss: 0.3908 - accuracy: 0.8829 - val_loss: 0.3792 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "1131/1131 [==============================] - 1s 514us/step - loss: 0.3879 - accuracy: 0.8829 - val_loss: 0.3773 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "1131/1131 [==============================] - 1s 620us/step - loss: 0.3860 - accuracy: 0.8829 - val_loss: 0.3756 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "1131/1131 [==============================] - 1s 529us/step - loss: 0.3831 - accuracy: 0.8829 - val_loss: 0.3740 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "1131/1131 [==============================] - 1s 729us/step - loss: 0.3820 - accuracy: 0.8829 - val_loss: 0.3724 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "1131/1131 [==============================] - 1s 584us/step - loss: 0.3808 - accuracy: 0.8830 - val_loss: 0.3708 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "1131/1131 [==============================] - 1s 557us/step - loss: 0.3799 - accuracy: 0.8829 - val_loss: 0.3692 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "1131/1131 [==============================] - 1s 579us/step - loss: 0.3763 - accuracy: 0.8829 - val_loss: 0.3677 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "1131/1131 [==============================] - 1s 559us/step - loss: 0.3760 - accuracy: 0.8830 - val_loss: 0.3663 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "1131/1131 [==============================] - 1s 558us/step - loss: 0.3748 - accuracy: 0.8829 - val_loss: 0.3650 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "1131/1131 [==============================] - 1s 578us/step - loss: 0.3724 - accuracy: 0.8830 - val_loss: 0.3636 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "1131/1131 [==============================] - 1s 572us/step - loss: 0.3719 - accuracy: 0.8830 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "1131/1131 [==============================] - 1s 584us/step - loss: 0.3702 - accuracy: 0.8830 - val_loss: 0.3610 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "1131/1131 [==============================] - 1s 648us/step - loss: 0.3675 - accuracy: 0.8830 - val_loss: 0.3597 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "1131/1131 [==============================] - 1s 555us/step - loss: 0.3674 - accuracy: 0.8830 - val_loss: 0.3585 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "1131/1131 [==============================] - 1s 534us/step - loss: 0.3666 - accuracy: 0.8830 - val_loss: 0.3572 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "1131/1131 [==============================] - 1s 614us/step - loss: 0.3653 - accuracy: 0.8830 - val_loss: 0.3561 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "1131/1131 [==============================] - 1s 596us/step - loss: 0.3634 - accuracy: 0.8830 - val_loss: 0.3549 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "1131/1131 [==============================] - 1s 580us/step - loss: 0.3615 - accuracy: 0.8830 - val_loss: 0.3538 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "1131/1131 [==============================] - 1s 565us/step - loss: 0.3609 - accuracy: 0.8830 - val_loss: 0.3526 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "1131/1131 [==============================] - 1s 543us/step - loss: 0.3607 - accuracy: 0.8830 - val_loss: 0.3516 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "1131/1131 [==============================] - 1s 546us/step - loss: 0.3575 - accuracy: 0.8830 - val_loss: 0.3506 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "1131/1131 [==============================] - 1s 519us/step - loss: 0.3576 - accuracy: 0.8830 - val_loss: 0.3495 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "1131/1131 [==============================] - 1s 527us/step - loss: 0.3567 - accuracy: 0.8830 - val_loss: 0.3486 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "1131/1131 [==============================] - 1s 533us/step - loss: 0.3550 - accuracy: 0.8830 - val_loss: 0.3477 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "1131/1131 [==============================] - 1s 529us/step - loss: 0.3544 - accuracy: 0.8830 - val_loss: 0.3468 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "1131/1131 [==============================] - 1s 575us/step - loss: 0.3522 - accuracy: 0.8830 - val_loss: 0.3460 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "1131/1131 [==============================] - 1s 626us/step - loss: 0.3530 - accuracy: 0.8830 - val_loss: 0.3451 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "1131/1131 [==============================] - 1s 540us/step - loss: 0.3516 - accuracy: 0.8830 - val_loss: 0.3443 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "1131/1131 [==============================] - 1s 583us/step - loss: 0.3515 - accuracy: 0.8830 - val_loss: 0.3436 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "1131/1131 [==============================] - 1s 642us/step - loss: 0.3516 - accuracy: 0.8830 - val_loss: 0.3429 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "1131/1131 [==============================] - 1s 590us/step - loss: 0.3498 - accuracy: 0.8830 - val_loss: 0.3422 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "1131/1131 [==============================] - 1s 625us/step - loss: 0.3492 - accuracy: 0.8831 - val_loss: 0.3415 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "1131/1131 [==============================] - 1s 524us/step - loss: 0.3484 - accuracy: 0.8829 - val_loss: 0.3409 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "1131/1131 [==============================] - 1s 528us/step - loss: 0.3472 - accuracy: 0.8831 - val_loss: 0.3402 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "1131/1131 [==============================] - 1s 571us/step - loss: 0.3474 - accuracy: 0.8829 - val_loss: 0.3396 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "1131/1131 [==============================] - 1s 541us/step - loss: 0.3468 - accuracy: 0.8830 - val_loss: 0.3390 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "1131/1131 [==============================] - 1s 572us/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 0.3385 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "1131/1131 [==============================] - 1s 553us/step - loss: 0.3454 - accuracy: 0.8830 - val_loss: 0.3379 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "1131/1131 [==============================] - 1s 572us/step - loss: 0.3443 - accuracy: 0.8830 - val_loss: 0.3374 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "1131/1131 [==============================] - 1s 591us/step - loss: 0.3451 - accuracy: 0.8830 - val_loss: 0.3369 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "1131/1131 [==============================] - 1s 651us/step - loss: 0.3440 - accuracy: 0.8830 - val_loss: 0.3364 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "1131/1131 [==============================] - 1s 583us/step - loss: 0.3429 - accuracy: 0.8830 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "1131/1131 [==============================] - 1s 629us/step - loss: 0.3434 - accuracy: 0.8831 - val_loss: 0.3354 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "1131/1131 [==============================] - 1s 620us/step - loss: 0.3422 - accuracy: 0.8830 - val_loss: 0.3350 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "1131/1131 [==============================] - 1s 534us/step - loss: 0.3428 - accuracy: 0.8832 - val_loss: 0.3345 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "1131/1131 [==============================] - 1s 564us/step - loss: 0.3412 - accuracy: 0.8830 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "1131/1131 [==============================] - 1s 536us/step - loss: 0.3409 - accuracy: 0.8830 - val_loss: 0.3337 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "1131/1131 [==============================] - 1s 604us/step - loss: 0.4901 - accuracy: 0.8271 - val_loss: 0.4103 - val_accuracy: 0.8712\n",
      "Epoch 2/50\n",
      "1131/1131 [==============================] - 1s 582us/step - loss: 0.4059 - accuracy: 0.8774 - val_loss: 0.3903 - val_accuracy: 0.8829\n",
      "Epoch 3/50\n",
      "1131/1131 [==============================] - 1s 612us/step - loss: 0.3963 - accuracy: 0.8807 - val_loss: 0.3859 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "1131/1131 [==============================] - 1s 588us/step - loss: 0.3931 - accuracy: 0.8818 - val_loss: 0.3836 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "1131/1131 [==============================] - 1s 586us/step - loss: 0.3892 - accuracy: 0.8821 - val_loss: 0.3817 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "1131/1131 [==============================] - 1s 569us/step - loss: 0.3877 - accuracy: 0.8825 - val_loss: 0.3801 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "1131/1131 [==============================] - 1s 575us/step - loss: 0.3862 - accuracy: 0.8826 - val_loss: 0.3785 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "1131/1131 [==============================] - 1s 549us/step - loss: 0.3843 - accuracy: 0.8826 - val_loss: 0.3772 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "1131/1131 [==============================] - 1s 625us/step - loss: 0.3827 - accuracy: 0.8829 - val_loss: 0.3758 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "1131/1131 [==============================] - 1s 623us/step - loss: 0.3817 - accuracy: 0.8829 - val_loss: 0.3747 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "1131/1131 [==============================] - 1s 539us/step - loss: 0.3806 - accuracy: 0.8828 - val_loss: 0.3735 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "1131/1131 [==============================] - 1s 520us/step - loss: 0.3797 - accuracy: 0.8830 - val_loss: 0.3724 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "1131/1131 [==============================] - 1s 544us/step - loss: 0.3777 - accuracy: 0.8830 - val_loss: 0.3713 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "1131/1131 [==============================] - 1s 539us/step - loss: 0.3777 - accuracy: 0.8830 - val_loss: 0.3703 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "1131/1131 [==============================] - 1s 526us/step - loss: 0.3746 - accuracy: 0.8830 - val_loss: 0.3693 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "1131/1131 [==============================] - 1s 555us/step - loss: 0.3742 - accuracy: 0.8830 - val_loss: 0.3684 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "1131/1131 [==============================] - 1s 540us/step - loss: 0.3738 - accuracy: 0.8830 - val_loss: 0.3674 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "1131/1131 [==============================] - 1s 546us/step - loss: 0.3729 - accuracy: 0.8829 - val_loss: 0.3665 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "1131/1131 [==============================] - 1s 531us/step - loss: 0.3721 - accuracy: 0.8830 - val_loss: 0.3656 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "1131/1131 [==============================] - 1s 524us/step - loss: 0.3708 - accuracy: 0.8830 - val_loss: 0.3648 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "1131/1131 [==============================] - 1s 519us/step - loss: 0.3701 - accuracy: 0.8830 - val_loss: 0.3639 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "1131/1131 [==============================] - 1s 697us/step - loss: 0.3683 - accuracy: 0.8830 - val_loss: 0.3631 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "1131/1131 [==============================] - 1s 621us/step - loss: 0.3696 - accuracy: 0.8830 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "1131/1131 [==============================] - 1s 628us/step - loss: 0.3671 - accuracy: 0.8830 - val_loss: 0.3615 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "1131/1131 [==============================] - 1s 639us/step - loss: 0.3661 - accuracy: 0.8830 - val_loss: 0.3607 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "1131/1131 [==============================] - 1s 589us/step - loss: 0.3658 - accuracy: 0.8830 - val_loss: 0.3600 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "1131/1131 [==============================] - 1s 638us/step - loss: 0.3644 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "1131/1131 [==============================] - 1s 614us/step - loss: 0.3641 - accuracy: 0.8830 - val_loss: 0.3585 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "1131/1131 [==============================] - 1s 597us/step - loss: 0.3637 - accuracy: 0.8830 - val_loss: 0.3578 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "1131/1131 [==============================] - 1s 597us/step - loss: 0.3630 - accuracy: 0.8830 - val_loss: 0.3571 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "1131/1131 [==============================] - 1s 579us/step - loss: 0.3639 - accuracy: 0.8830 - val_loss: 0.3564 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "1131/1131 [==============================] - 1s 556us/step - loss: 0.3608 - accuracy: 0.8830 - val_loss: 0.3557 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "1131/1131 [==============================] - 1s 590us/step - loss: 0.3604 - accuracy: 0.8830 - val_loss: 0.3551 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "1131/1131 [==============================] - 1s 641us/step - loss: 0.3598 - accuracy: 0.8830 - val_loss: 0.3544 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "1131/1131 [==============================] - 1s 800us/step - loss: 0.3588 - accuracy: 0.8830 - val_loss: 0.3538 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "1131/1131 [==============================] - 1s 576us/step - loss: 0.3593 - accuracy: 0.8830 - val_loss: 0.3532 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "1131/1131 [==============================] - 1s 707us/step - loss: 0.3584 - accuracy: 0.8830 - val_loss: 0.3526 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "1131/1131 [==============================] - 1s 543us/step - loss: 0.3583 - accuracy: 0.8830 - val_loss: 0.3520 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "1131/1131 [==============================] - 1s 513us/step - loss: 0.3564 - accuracy: 0.8830 - val_loss: 0.3514 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "1131/1131 [==============================] - 1s 637us/step - loss: 0.3566 - accuracy: 0.8830 - val_loss: 0.3508 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "1131/1131 [==============================] - 1s 666us/step - loss: 0.3555 - accuracy: 0.8830 - val_loss: 0.3502 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "1131/1131 [==============================] - 1s 553us/step - loss: 0.3560 - accuracy: 0.8830 - val_loss: 0.3496 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "1131/1131 [==============================] - 1s 680us/step - loss: 0.3554 - accuracy: 0.8830 - val_loss: 0.3491 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "1131/1131 [==============================] - 1s 841us/step - loss: 0.3541 - accuracy: 0.8830 - val_loss: 0.3485 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "1131/1131 [==============================] - 1s 812us/step - loss: 0.3527 - accuracy: 0.8830 - val_loss: 0.3480 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "1131/1131 [==============================] - 1s 911us/step - loss: 0.3525 - accuracy: 0.8830 - val_loss: 0.3475 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "1131/1131 [==============================] - 1s 650us/step - loss: 0.3535 - accuracy: 0.8830 - val_loss: 0.3470 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "1131/1131 [==============================] - 1s 626us/step - loss: 0.3522 - accuracy: 0.8830 - val_loss: 0.3465 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "1131/1131 [==============================] - 1s 621us/step - loss: 0.3510 - accuracy: 0.8830 - val_loss: 0.3460 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "1131/1131 [==============================] - 1s 628us/step - loss: 0.3511 - accuracy: 0.8830 - val_loss: 0.3455 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "1131/1131 [==============================] - 1s 676us/step - loss: 0.3999 - accuracy: 0.8829 - val_loss: 0.3843 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "1131/1131 [==============================] - 1s 624us/step - loss: 0.3910 - accuracy: 0.8830 - val_loss: 0.3805 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3870 - accuracy: 0.8830 - val_loss: 0.3787 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "1131/1131 [==============================] - 1s 980us/step - loss: 0.3863 - accuracy: 0.8830 - val_loss: 0.3774 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "1131/1131 [==============================] - 1s 968us/step - loss: 0.3834 - accuracy: 0.8830 - val_loss: 0.3762 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "1131/1131 [==============================] - 1s 936us/step - loss: 0.3834 - accuracy: 0.8830 - val_loss: 0.3749 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "1131/1131 [==============================] - 1s 943us/step - loss: 0.3816 - accuracy: 0.8830 - val_loss: 0.3736 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "1131/1131 [==============================] - 1s 940us/step - loss: 0.3798 - accuracy: 0.8830 - val_loss: 0.3724 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3790 - accuracy: 0.8830 - val_loss: 0.3712 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "1131/1131 [==============================] - 1s 960us/step - loss: 0.3777 - accuracy: 0.8830 - val_loss: 0.3701 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "1131/1131 [==============================] - 1s 873us/step - loss: 0.3760 - accuracy: 0.8830 - val_loss: 0.3689 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "1131/1131 [==============================] - 1s 969us/step - loss: 0.3744 - accuracy: 0.8830 - val_loss: 0.3678 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "1131/1131 [==============================] - 1s 869us/step - loss: 0.3752 - accuracy: 0.8830 - val_loss: 0.3667 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "1131/1131 [==============================] - 1s 901us/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3656 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "1131/1131 [==============================] - 1s 999us/step - loss: 0.3727 - accuracy: 0.8830 - val_loss: 0.3645 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3713 - accuracy: 0.8830 - val_loss: 0.3635 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "1131/1131 [==============================] - 1s 956us/step - loss: 0.3708 - accuracy: 0.8830 - val_loss: 0.3624 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "1131/1131 [==============================] - 1s 968us/step - loss: 0.3679 - accuracy: 0.8830 - val_loss: 0.3614 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "1131/1131 [==============================] - 1s 972us/step - loss: 0.3692 - accuracy: 0.8830 - val_loss: 0.3604 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3677 - accuracy: 0.8830 - val_loss: 0.3594 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "1131/1131 [==============================] - 1s 942us/step - loss: 0.3658 - accuracy: 0.8830 - val_loss: 0.3584 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3646 - accuracy: 0.8830 - val_loss: 0.3574 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "1131/1131 [==============================] - 1s 991us/step - loss: 0.3636 - accuracy: 0.8830 - val_loss: 0.3564 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3649 - accuracy: 0.8830 - val_loss: 0.3555 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3631 - accuracy: 0.8830 - val_loss: 0.3545 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "1131/1131 [==============================] - 1s 998us/step - loss: 0.3611 - accuracy: 0.8830 - val_loss: 0.3536 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "1131/1131 [==============================] - 1s 934us/step - loss: 0.3602 - accuracy: 0.8830 - val_loss: 0.3527 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "1131/1131 [==============================] - 1s 992us/step - loss: 0.3589 - accuracy: 0.8830 - val_loss: 0.3518 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3583 - accuracy: 0.8830 - val_loss: 0.3509 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3586 - accuracy: 0.8830 - val_loss: 0.3501 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3562 - accuracy: 0.8830 - val_loss: 0.3492 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3563 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "1131/1131 [==============================] - 1s 916us/step - loss: 0.3543 - accuracy: 0.8830 - val_loss: 0.3476 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3541 - accuracy: 0.8830 - val_loss: 0.3469 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "1131/1131 [==============================] - 1s 929us/step - loss: 0.3534 - accuracy: 0.8830 - val_loss: 0.3461 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "1131/1131 [==============================] - 1s 911us/step - loss: 0.3531 - accuracy: 0.8830 - val_loss: 0.3454 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "1131/1131 [==============================] - 1s 987us/step - loss: 0.3526 - accuracy: 0.8830 - val_loss: 0.3447 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3519 - accuracy: 0.8830 - val_loss: 0.3441 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "1131/1131 [==============================] - 1s 983us/step - loss: 0.3513 - accuracy: 0.8830 - val_loss: 0.3435 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3509 - accuracy: 0.8830 - val_loss: 0.3428 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "1131/1131 [==============================] - 1s 967us/step - loss: 0.3509 - accuracy: 0.8830 - val_loss: 0.3423 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "1131/1131 [==============================] - 1s 914us/step - loss: 0.3491 - accuracy: 0.8830 - val_loss: 0.3417 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "1131/1131 [==============================] - 1s 973us/step - loss: 0.3497 - accuracy: 0.8830 - val_loss: 0.3411 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3481 - accuracy: 0.8830 - val_loss: 0.3406 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "1131/1131 [==============================] - 1s 917us/step - loss: 0.3465 - accuracy: 0.8830 - val_loss: 0.3401 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3396 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "1131/1131 [==============================] - 1s 973us/step - loss: 0.3464 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "1131/1131 [==============================] - 1s 984us/step - loss: 0.3460 - accuracy: 0.8830 - val_loss: 0.3387 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "1131/1131 [==============================] - 1s 955us/step - loss: 0.3459 - accuracy: 0.8830 - val_loss: 0.3382 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3449 - accuracy: 0.8830 - val_loss: 0.3378 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "Entrenando modelo con batch_size=16...\n",
      "DP-SGD with sampling rate = 0.0442% and noise_multiplier = 1.1 iterated over 113025 steps satisfies differential privacy with eps = 0.96 and delta = 1e-05.\n",
      "The optimal RDP order is 18.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 2s 723us/step - loss: 0.4949 - accuracy: 0.8033 - val_loss: 0.4018 - val_accuracy: 0.8815\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 582us/step - loss: 0.4004 - accuracy: 0.8809 - val_loss: 0.3918 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3931 - accuracy: 0.8824 - val_loss: 0.3878 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3915 - accuracy: 0.8826 - val_loss: 0.3842 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3880 - accuracy: 0.8828 - val_loss: 0.3807 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 594us/step - loss: 0.3834 - accuracy: 0.8828 - val_loss: 0.3776 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 544us/step - loss: 0.3813 - accuracy: 0.8829 - val_loss: 0.3746 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 558us/step - loss: 0.3783 - accuracy: 0.8829 - val_loss: 0.3717 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3751 - accuracy: 0.8829 - val_loss: 0.3691 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3727 - accuracy: 0.8829 - val_loss: 0.3664 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3707 - accuracy: 0.8831 - val_loss: 0.3639 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3670 - accuracy: 0.8830 - val_loss: 0.3614 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 539us/step - loss: 0.3650 - accuracy: 0.8830 - val_loss: 0.3590 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 482us/step - loss: 0.3619 - accuracy: 0.8831 - val_loss: 0.3568 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3607 - accuracy: 0.8831 - val_loss: 0.3548 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3589 - accuracy: 0.8830 - val_loss: 0.3528 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3589 - accuracy: 0.8830 - val_loss: 0.3510 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3558 - accuracy: 0.8830 - val_loss: 0.3493 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3541 - accuracy: 0.8830 - val_loss: 0.3476 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3532 - accuracy: 0.8831 - val_loss: 0.3460 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3507 - accuracy: 0.8830 - val_loss: 0.3444 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3483 - accuracy: 0.8831 - val_loss: 0.3430 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 540us/step - loss: 0.3476 - accuracy: 0.8831 - val_loss: 0.3415 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3463 - accuracy: 0.8831 - val_loss: 0.3402 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 478us/step - loss: 0.3452 - accuracy: 0.8831 - val_loss: 0.3389 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 478us/step - loss: 0.3434 - accuracy: 0.8831 - val_loss: 0.3377 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3433 - accuracy: 0.8831 - val_loss: 0.3366 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3412 - accuracy: 0.8832 - val_loss: 0.3355 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3405 - accuracy: 0.8834 - val_loss: 0.3345 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 478us/step - loss: 0.3400 - accuracy: 0.8835 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3390 - accuracy: 0.8830 - val_loss: 0.3327 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3385 - accuracy: 0.8834 - val_loss: 0.3318 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3375 - accuracy: 0.8834 - val_loss: 0.3310 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3377 - accuracy: 0.8836 - val_loss: 0.3303 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3358 - accuracy: 0.8836 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 478us/step - loss: 0.3351 - accuracy: 0.8837 - val_loss: 0.3288 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 467us/step - loss: 0.3345 - accuracy: 0.8837 - val_loss: 0.3282 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 473us/step - loss: 0.3338 - accuracy: 0.8837 - val_loss: 0.3276 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3334 - accuracy: 0.8838 - val_loss: 0.3270 - val_accuracy: 0.8833\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3325 - accuracy: 0.8840 - val_loss: 0.3264 - val_accuracy: 0.8836\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3321 - accuracy: 0.8841 - val_loss: 0.3259 - val_accuracy: 0.8837\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3312 - accuracy: 0.8840 - val_loss: 0.3254 - val_accuracy: 0.8837\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3308 - accuracy: 0.8846 - val_loss: 0.3250 - val_accuracy: 0.8839\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3315 - accuracy: 0.8843 - val_loss: 0.3246 - val_accuracy: 0.8844\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3317 - accuracy: 0.8841 - val_loss: 0.3242 - val_accuracy: 0.8849\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3301 - accuracy: 0.8848 - val_loss: 0.3239 - val_accuracy: 0.8849\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3290 - accuracy: 0.8850 - val_loss: 0.3235 - val_accuracy: 0.8853\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3301 - accuracy: 0.8851 - val_loss: 0.3231 - val_accuracy: 0.8853\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3287 - accuracy: 0.8853 - val_loss: 0.3228 - val_accuracy: 0.8853\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3293 - accuracy: 0.8851 - val_loss: 0.3226 - val_accuracy: 0.8853\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.4251 - accuracy: 0.8812 - val_loss: 0.3928 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 473us/step - loss: 0.3969 - accuracy: 0.8830 - val_loss: 0.3880 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3926 - accuracy: 0.8830 - val_loss: 0.3851 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3894 - accuracy: 0.8830 - val_loss: 0.3823 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3867 - accuracy: 0.8830 - val_loss: 0.3795 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3840 - accuracy: 0.8830 - val_loss: 0.3770 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 640us/step - loss: 0.3819 - accuracy: 0.8830 - val_loss: 0.3747 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 2s 713us/step - loss: 0.3798 - accuracy: 0.8830 - val_loss: 0.3727 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 561us/step - loss: 0.3767 - accuracy: 0.8830 - val_loss: 0.3705 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3753 - accuracy: 0.8830 - val_loss: 0.3684 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3731 - accuracy: 0.8830 - val_loss: 0.3664 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3709 - accuracy: 0.8830 - val_loss: 0.3644 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3689 - accuracy: 0.8830 - val_loss: 0.3626 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.3670 - accuracy: 0.8830 - val_loss: 0.3609 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3652 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3627 - accuracy: 0.8830 - val_loss: 0.3576 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3618 - accuracy: 0.8830 - val_loss: 0.3560 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3601 - accuracy: 0.8830 - val_loss: 0.3545 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3584 - accuracy: 0.8830 - val_loss: 0.3530 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 470us/step - loss: 0.3581 - accuracy: 0.8830 - val_loss: 0.3515 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 474us/step - loss: 0.3570 - accuracy: 0.8830 - val_loss: 0.3501 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 474us/step - loss: 0.3547 - accuracy: 0.8830 - val_loss: 0.3488 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3527 - accuracy: 0.8830 - val_loss: 0.3475 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3516 - accuracy: 0.8830 - val_loss: 0.3462 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3507 - accuracy: 0.8830 - val_loss: 0.3450 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 598us/step - loss: 0.3498 - accuracy: 0.8830 - val_loss: 0.3438 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 616us/step - loss: 0.3496 - accuracy: 0.8830 - val_loss: 0.3427 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 575us/step - loss: 0.3477 - accuracy: 0.8830 - val_loss: 0.3416 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 625us/step - loss: 0.3462 - accuracy: 0.8830 - val_loss: 0.3406 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 594us/step - loss: 0.3461 - accuracy: 0.8830 - val_loss: 0.3397 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 610us/step - loss: 0.3448 - accuracy: 0.8830 - val_loss: 0.3387 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3437 - accuracy: 0.8830 - val_loss: 0.3378 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3435 - accuracy: 0.8830 - val_loss: 0.3370 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 474us/step - loss: 0.3415 - accuracy: 0.8830 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 475us/step - loss: 0.3415 - accuracy: 0.8831 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3407 - accuracy: 0.8831 - val_loss: 0.3346 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3393 - accuracy: 0.8831 - val_loss: 0.3339 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3398 - accuracy: 0.8830 - val_loss: 0.3332 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3382 - accuracy: 0.8830 - val_loss: 0.3326 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3382 - accuracy: 0.8831 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 473us/step - loss: 0.3369 - accuracy: 0.8832 - val_loss: 0.3313 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3373 - accuracy: 0.8831 - val_loss: 0.3308 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 478us/step - loss: 0.3365 - accuracy: 0.8832 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3357 - accuracy: 0.8829 - val_loss: 0.3297 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3353 - accuracy: 0.8832 - val_loss: 0.3292 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3356 - accuracy: 0.8830 - val_loss: 0.3288 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3334 - accuracy: 0.8833 - val_loss: 0.3283 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3348 - accuracy: 0.8832 - val_loss: 0.3279 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3343 - accuracy: 0.8832 - val_loss: 0.3275 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3335 - accuracy: 0.8833 - val_loss: 0.3271 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.4390 - accuracy: 0.8638 - val_loss: 0.3874 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.4003 - accuracy: 0.8819 - val_loss: 0.3828 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3957 - accuracy: 0.8826 - val_loss: 0.3798 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3913 - accuracy: 0.8827 - val_loss: 0.3767 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 546us/step - loss: 0.3865 - accuracy: 0.8826 - val_loss: 0.3738 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3843 - accuracy: 0.8827 - val_loss: 0.3712 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3823 - accuracy: 0.8828 - val_loss: 0.3686 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3790 - accuracy: 0.8829 - val_loss: 0.3664 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3775 - accuracy: 0.8829 - val_loss: 0.3644 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3760 - accuracy: 0.8829 - val_loss: 0.3624 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3717 - accuracy: 0.8830 - val_loss: 0.3608 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3703 - accuracy: 0.8830 - val_loss: 0.3590 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 467us/step - loss: 0.3694 - accuracy: 0.8829 - val_loss: 0.3572 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 470us/step - loss: 0.3683 - accuracy: 0.8830 - val_loss: 0.3557 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 473us/step - loss: 0.3650 - accuracy: 0.8829 - val_loss: 0.3542 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3633 - accuracy: 0.8830 - val_loss: 0.3526 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3621 - accuracy: 0.8830 - val_loss: 0.3511 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 591us/step - loss: 0.3618 - accuracy: 0.8830 - val_loss: 0.3497 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3584 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3571 - accuracy: 0.8830 - val_loss: 0.3471 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3572 - accuracy: 0.8829 - val_loss: 0.3459 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3539 - accuracy: 0.8830 - val_loss: 0.3447 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3534 - accuracy: 0.8830 - val_loss: 0.3436 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3521 - accuracy: 0.8829 - val_loss: 0.3426 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3511 - accuracy: 0.8830 - val_loss: 0.3417 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 478us/step - loss: 0.3507 - accuracy: 0.8829 - val_loss: 0.3407 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3484 - accuracy: 0.8830 - val_loss: 0.3396 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 577us/step - loss: 0.3481 - accuracy: 0.8830 - val_loss: 0.3389 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3479 - accuracy: 0.8830 - val_loss: 0.3381 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3455 - accuracy: 0.8830 - val_loss: 0.3373 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3451 - accuracy: 0.8831 - val_loss: 0.3367 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3446 - accuracy: 0.8829 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 554us/step - loss: 0.3449 - accuracy: 0.8830 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3438 - accuracy: 0.8830 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.3433 - accuracy: 0.8827 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3426 - accuracy: 0.8830 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.3423 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 585us/step - loss: 0.3412 - accuracy: 0.8832 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3404 - accuracy: 0.8830 - val_loss: 0.3321 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 568us/step - loss: 0.3411 - accuracy: 0.8832 - val_loss: 0.3316 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3398 - accuracy: 0.8829 - val_loss: 0.3312 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 483us/step - loss: 0.3386 - accuracy: 0.8830 - val_loss: 0.3307 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3383 - accuracy: 0.8833 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 561us/step - loss: 0.3387 - accuracy: 0.8829 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3376 - accuracy: 0.8829 - val_loss: 0.3296 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.3376 - accuracy: 0.8830 - val_loss: 0.3292 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.3379 - accuracy: 0.8829 - val_loss: 0.3288 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3382 - accuracy: 0.8829 - val_loss: 0.3285 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 631us/step - loss: 0.3368 - accuracy: 0.8831 - val_loss: 0.3281 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 2s 870us/step - loss: 0.3357 - accuracy: 0.8831 - val_loss: 0.3278 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 624us/step - loss: 0.5173 - accuracy: 0.7716 - val_loss: 0.3939 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 590us/step - loss: 0.3993 - accuracy: 0.8819 - val_loss: 0.3868 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 581us/step - loss: 0.3926 - accuracy: 0.8822 - val_loss: 0.3830 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 617us/step - loss: 0.3893 - accuracy: 0.8826 - val_loss: 0.3794 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 566us/step - loss: 0.3853 - accuracy: 0.8829 - val_loss: 0.3761 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.3818 - accuracy: 0.8828 - val_loss: 0.3730 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3785 - accuracy: 0.8830 - val_loss: 0.3700 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3757 - accuracy: 0.8830 - val_loss: 0.3674 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.3734 - accuracy: 0.8830 - val_loss: 0.3646 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 533us/step - loss: 0.3709 - accuracy: 0.8829 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.3688 - accuracy: 0.8829 - val_loss: 0.3601 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3664 - accuracy: 0.8830 - val_loss: 0.3579 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3647 - accuracy: 0.8830 - val_loss: 0.3558 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3623 - accuracy: 0.8831 - val_loss: 0.3538 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 579us/step - loss: 0.3601 - accuracy: 0.8830 - val_loss: 0.3519 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3587 - accuracy: 0.8830 - val_loss: 0.3501 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 616us/step - loss: 0.3564 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3544 - accuracy: 0.8830 - val_loss: 0.3468 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 589us/step - loss: 0.3534 - accuracy: 0.8831 - val_loss: 0.3452 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.3519 - accuracy: 0.8831 - val_loss: 0.3435 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3503 - accuracy: 0.8830 - val_loss: 0.3421 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3488 - accuracy: 0.8830 - val_loss: 0.3407 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3475 - accuracy: 0.8831 - val_loss: 0.3395 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3464 - accuracy: 0.8831 - val_loss: 0.3381 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3447 - accuracy: 0.8830 - val_loss: 0.3369 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3449 - accuracy: 0.8831 - val_loss: 0.3358 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.3419 - accuracy: 0.8831 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.3420 - accuracy: 0.8831 - val_loss: 0.3337 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3402 - accuracy: 0.8831 - val_loss: 0.3327 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3395 - accuracy: 0.8832 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3378 - accuracy: 0.8832 - val_loss: 0.3310 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3374 - accuracy: 0.8833 - val_loss: 0.3301 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3367 - accuracy: 0.8831 - val_loss: 0.3294 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3360 - accuracy: 0.8830 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3348 - accuracy: 0.8829 - val_loss: 0.3279 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3343 - accuracy: 0.8833 - val_loss: 0.3273 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3345 - accuracy: 0.8832 - val_loss: 0.3267 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 524us/step - loss: 0.3328 - accuracy: 0.8831 - val_loss: 0.3261 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3328 - accuracy: 0.8834 - val_loss: 0.3255 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3318 - accuracy: 0.8834 - val_loss: 0.3250 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3312 - accuracy: 0.8834 - val_loss: 0.3245 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3306 - accuracy: 0.8832 - val_loss: 0.3240 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3307 - accuracy: 0.8838 - val_loss: 0.3236 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 548us/step - loss: 0.3301 - accuracy: 0.8835 - val_loss: 0.3231 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.3300 - accuracy: 0.8836 - val_loss: 0.3227 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 557us/step - loss: 0.3289 - accuracy: 0.8835 - val_loss: 0.3224 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.3298 - accuracy: 0.8835 - val_loss: 0.3219 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3281 - accuracy: 0.8843 - val_loss: 0.3216 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3284 - accuracy: 0.8842 - val_loss: 0.3213 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 532us/step - loss: 0.3277 - accuracy: 0.8838 - val_loss: 0.3210 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.4561 - accuracy: 0.8622 - val_loss: 0.3874 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3886 - accuracy: 0.8829 - val_loss: 0.3771 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3840 - accuracy: 0.8830 - val_loss: 0.3736 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3784 - accuracy: 0.8830 - val_loss: 0.3708 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3758 - accuracy: 0.8830 - val_loss: 0.3682 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3749 - accuracy: 0.8830 - val_loss: 0.3657 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3722 - accuracy: 0.8830 - val_loss: 0.3634 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3698 - accuracy: 0.8830 - val_loss: 0.3612 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3683 - accuracy: 0.8830 - val_loss: 0.3590 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 467us/step - loss: 0.3644 - accuracy: 0.8830 - val_loss: 0.3570 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 471us/step - loss: 0.3623 - accuracy: 0.8831 - val_loss: 0.3550 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3613 - accuracy: 0.8830 - val_loss: 0.3531 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3577 - accuracy: 0.8830 - val_loss: 0.3512 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3567 - accuracy: 0.8830 - val_loss: 0.3493 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3557 - accuracy: 0.8830 - val_loss: 0.3476 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3536 - accuracy: 0.8830 - val_loss: 0.3459 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3525 - accuracy: 0.8830 - val_loss: 0.3443 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3507 - accuracy: 0.8830 - val_loss: 0.3427 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.3495 - accuracy: 0.8831 - val_loss: 0.3413 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 563us/step - loss: 0.3484 - accuracy: 0.8830 - val_loss: 0.3400 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 550us/step - loss: 0.3445 - accuracy: 0.8830 - val_loss: 0.3387 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3449 - accuracy: 0.8830 - val_loss: 0.3374 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3440 - accuracy: 0.8831 - val_loss: 0.3362 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3423 - accuracy: 0.8832 - val_loss: 0.3351 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3417 - accuracy: 0.8830 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3415 - accuracy: 0.8832 - val_loss: 0.3331 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3398 - accuracy: 0.8832 - val_loss: 0.3322 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3381 - accuracy: 0.8832 - val_loss: 0.3313 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3382 - accuracy: 0.8831 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3369 - accuracy: 0.8833 - val_loss: 0.3297 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 473us/step - loss: 0.3369 - accuracy: 0.8831 - val_loss: 0.3289 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 476us/step - loss: 0.3363 - accuracy: 0.8835 - val_loss: 0.3283 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3350 - accuracy: 0.8832 - val_loss: 0.3276 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 479us/step - loss: 0.3346 - accuracy: 0.8831 - val_loss: 0.3270 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3345 - accuracy: 0.8832 - val_loss: 0.3265 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3340 - accuracy: 0.8832 - val_loss: 0.3259 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.3330 - accuracy: 0.8833 - val_loss: 0.3254 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3331 - accuracy: 0.8836 - val_loss: 0.3249 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.3313 - accuracy: 0.8838 - val_loss: 0.3244 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 524us/step - loss: 0.3310 - accuracy: 0.8838 - val_loss: 0.3240 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3307 - accuracy: 0.8838 - val_loss: 0.3236 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3305 - accuracy: 0.8840 - val_loss: 0.3232 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3304 - accuracy: 0.8841 - val_loss: 0.3228 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3297 - accuracy: 0.8843 - val_loss: 0.3224 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.3304 - accuracy: 0.8843 - val_loss: 0.3221 - val_accuracy: 0.8833\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 532us/step - loss: 0.3293 - accuracy: 0.8844 - val_loss: 0.3218 - val_accuracy: 0.8841\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 526us/step - loss: 0.3279 - accuracy: 0.8845 - val_loss: 0.3215 - val_accuracy: 0.8841\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3278 - accuracy: 0.8846 - val_loss: 0.3211 - val_accuracy: 0.8843\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3285 - accuracy: 0.8848 - val_loss: 0.3209 - val_accuracy: 0.8844\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3274 - accuracy: 0.8856 - val_loss: 0.3206 - val_accuracy: 0.8847\n",
      "Optimal threshold: 0.40\n"
     ]
    }
   ],
   "source": [
    "# 3. Variar batch_size\n",
    "results_batch_size = {}\n",
    "eps_batch_size = {}\n",
    "for bs in batch_size_values:\n",
    "    print(f\"\\nEntrenando modelo con batch_size={bs}...\")\n",
    "    eps = compute_privacy_budget(n_full, bs, default_noise_multiplier, epochs)\n",
    "    results = run_iterations(\n",
    "        X_train_full, y_train_full, X_test_full, y_test_full,\n",
    "        bs, epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_batch_size[bs] = compute_statistics(results)\n",
    "    eps_batch_size[bs] = eps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47b3d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experimentos con tamaño de muestra 70.0% ===\n",
      "Training set size: 25317\n",
      "DP-SGD with sampling rate = 0.0632% and noise_multiplier = 1.1 iterated over 79116 steps satisfies differential privacy with eps = 1.08 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1583/1583 [==============================] - 1s 558us/step - loss: 0.4948 - accuracy: 0.8234 - val_loss: 0.3933 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "1583/1583 [==============================] - 1s 481us/step - loss: 0.3965 - accuracy: 0.8828 - val_loss: 0.3787 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1583/1583 [==============================] - 1s 504us/step - loss: 0.3920 - accuracy: 0.8829 - val_loss: 0.3753 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1583/1583 [==============================] - 1s 554us/step - loss: 0.3866 - accuracy: 0.8830 - val_loss: 0.3729 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1583/1583 [==============================] - 1s 494us/step - loss: 0.3841 - accuracy: 0.8828 - val_loss: 0.3708 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1583/1583 [==============================] - 1s 475us/step - loss: 0.3821 - accuracy: 0.8830 - val_loss: 0.3688 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1583/1583 [==============================] - 1s 486us/step - loss: 0.3813 - accuracy: 0.8830 - val_loss: 0.3670 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1583/1583 [==============================] - 1s 487us/step - loss: 0.3781 - accuracy: 0.8830 - val_loss: 0.3653 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1583/1583 [==============================] - 1s 471us/step - loss: 0.3776 - accuracy: 0.8830 - val_loss: 0.3636 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1583/1583 [==============================] - 1s 491us/step - loss: 0.3731 - accuracy: 0.8830 - val_loss: 0.3621 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1583/1583 [==============================] - 1s 482us/step - loss: 0.3725 - accuracy: 0.8830 - val_loss: 0.3606 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1583/1583 [==============================] - 1s 478us/step - loss: 0.3713 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1583/1583 [==============================] - 1s 496us/step - loss: 0.3698 - accuracy: 0.8830 - val_loss: 0.3579 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1583/1583 [==============================] - 1s 484us/step - loss: 0.3678 - accuracy: 0.8829 - val_loss: 0.3566 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1583/1583 [==============================] - 1s 483us/step - loss: 0.3665 - accuracy: 0.8830 - val_loss: 0.3554 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1583/1583 [==============================] - 1s 483us/step - loss: 0.3649 - accuracy: 0.8830 - val_loss: 0.3542 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1583/1583 [==============================] - 1s 481us/step - loss: 0.3634 - accuracy: 0.8830 - val_loss: 0.3530 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1583/1583 [==============================] - 1s 486us/step - loss: 0.3623 - accuracy: 0.8830 - val_loss: 0.3519 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1583/1583 [==============================] - 1s 554us/step - loss: 0.3617 - accuracy: 0.8830 - val_loss: 0.3509 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1583/1583 [==============================] - 1s 493us/step - loss: 0.3603 - accuracy: 0.8830 - val_loss: 0.3498 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1583/1583 [==============================] - 1s 481us/step - loss: 0.3567 - accuracy: 0.8830 - val_loss: 0.3488 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1583/1583 [==============================] - 1s 485us/step - loss: 0.3572 - accuracy: 0.8830 - val_loss: 0.3478 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1583/1583 [==============================] - 1s 502us/step - loss: 0.3567 - accuracy: 0.8830 - val_loss: 0.3469 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1583/1583 [==============================] - 1s 507us/step - loss: 0.3551 - accuracy: 0.8830 - val_loss: 0.3460 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1583/1583 [==============================] - 1s 519us/step - loss: 0.3543 - accuracy: 0.8831 - val_loss: 0.3452 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1583/1583 [==============================] - 1s 577us/step - loss: 0.3534 - accuracy: 0.8830 - val_loss: 0.3443 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1583/1583 [==============================] - 1s 528us/step - loss: 0.3523 - accuracy: 0.8830 - val_loss: 0.3435 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1583/1583 [==============================] - 1s 517us/step - loss: 0.3516 - accuracy: 0.8830 - val_loss: 0.3427 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1583/1583 [==============================] - 1s 506us/step - loss: 0.3497 - accuracy: 0.8830 - val_loss: 0.3420 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1583/1583 [==============================] - 1s 486us/step - loss: 0.3490 - accuracy: 0.8830 - val_loss: 0.3412 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1583/1583 [==============================] - 1s 639us/step - loss: 0.3476 - accuracy: 0.8830 - val_loss: 0.3405 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1583/1583 [==============================] - 1s 555us/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3398 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1583/1583 [==============================] - 1s 559us/step - loss: 0.3474 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1583/1583 [==============================] - 1s 534us/step - loss: 0.3467 - accuracy: 0.8830 - val_loss: 0.3385 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1583/1583 [==============================] - 1s 507us/step - loss: 0.3462 - accuracy: 0.8830 - val_loss: 0.3379 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1583/1583 [==============================] - 1s 499us/step - loss: 0.3448 - accuracy: 0.8830 - val_loss: 0.3373 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1583/1583 [==============================] - 1s 481us/step - loss: 0.3442 - accuracy: 0.8830 - val_loss: 0.3367 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1583/1583 [==============================] - 1s 510us/step - loss: 0.3434 - accuracy: 0.8830 - val_loss: 0.3361 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1583/1583 [==============================] - 1s 509us/step - loss: 0.3440 - accuracy: 0.8829 - val_loss: 0.3356 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1583/1583 [==============================] - 1s 498us/step - loss: 0.3437 - accuracy: 0.8831 - val_loss: 0.3351 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1583/1583 [==============================] - 1s 505us/step - loss: 0.3419 - accuracy: 0.8831 - val_loss: 0.3346 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1583/1583 [==============================] - 1s 477us/step - loss: 0.3417 - accuracy: 0.8829 - val_loss: 0.3341 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1583/1583 [==============================] - 1s 519us/step - loss: 0.3398 - accuracy: 0.8831 - val_loss: 0.3336 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1583/1583 [==============================] - 1s 509us/step - loss: 0.3399 - accuracy: 0.8831 - val_loss: 0.3332 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1583/1583 [==============================] - 1s 525us/step - loss: 0.3392 - accuracy: 0.8830 - val_loss: 0.3328 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1583/1583 [==============================] - 1s 509us/step - loss: 0.3394 - accuracy: 0.8829 - val_loss: 0.3324 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1583/1583 [==============================] - 1s 521us/step - loss: 0.3381 - accuracy: 0.8830 - val_loss: 0.3320 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1583/1583 [==============================] - 1s 512us/step - loss: 0.3381 - accuracy: 0.8829 - val_loss: 0.3317 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1583/1583 [==============================] - 1s 486us/step - loss: 0.3377 - accuracy: 0.8829 - val_loss: 0.3313 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1583/1583 [==============================] - 1s 472us/step - loss: 0.3368 - accuracy: 0.8828 - val_loss: 0.3310 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "1583/1583 [==============================] - 1s 520us/step - loss: 0.4366 - accuracy: 0.8755 - val_loss: 0.3918 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "1583/1583 [==============================] - 1s 485us/step - loss: 0.4009 - accuracy: 0.8826 - val_loss: 0.3841 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1583/1583 [==============================] - 1s 504us/step - loss: 0.3969 - accuracy: 0.8830 - val_loss: 0.3807 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1583/1583 [==============================] - 1s 528us/step - loss: 0.3930 - accuracy: 0.8830 - val_loss: 0.3779 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1583/1583 [==============================] - 1s 522us/step - loss: 0.3883 - accuracy: 0.8830 - val_loss: 0.3753 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1583/1583 [==============================] - 1s 570us/step - loss: 0.3865 - accuracy: 0.8830 - val_loss: 0.3729 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1583/1583 [==============================] - 1s 501us/step - loss: 0.3846 - accuracy: 0.8830 - val_loss: 0.3707 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1583/1583 [==============================] - 1s 495us/step - loss: 0.3814 - accuracy: 0.8830 - val_loss: 0.3685 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1583/1583 [==============================] - 1s 504us/step - loss: 0.3795 - accuracy: 0.8830 - val_loss: 0.3665 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1583/1583 [==============================] - 1s 512us/step - loss: 0.3782 - accuracy: 0.8830 - val_loss: 0.3646 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1583/1583 [==============================] - 1s 492us/step - loss: 0.3749 - accuracy: 0.8830 - val_loss: 0.3628 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1583/1583 [==============================] - 1s 519us/step - loss: 0.3734 - accuracy: 0.8830 - val_loss: 0.3610 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1583/1583 [==============================] - 1s 493us/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1583/1583 [==============================] - 1s 490us/step - loss: 0.3680 - accuracy: 0.8830 - val_loss: 0.3575 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1583/1583 [==============================] - 1s 523us/step - loss: 0.3679 - accuracy: 0.8830 - val_loss: 0.3558 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1583/1583 [==============================] - 1s 539us/step - loss: 0.3658 - accuracy: 0.8830 - val_loss: 0.3542 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1583/1583 [==============================] - 1s 538us/step - loss: 0.3632 - accuracy: 0.8830 - val_loss: 0.3528 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1583/1583 [==============================] - 1s 528us/step - loss: 0.3627 - accuracy: 0.8830 - val_loss: 0.3514 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1583/1583 [==============================] - 1s 560us/step - loss: 0.3609 - accuracy: 0.8829 - val_loss: 0.3502 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1583/1583 [==============================] - 1s 527us/step - loss: 0.3581 - accuracy: 0.8830 - val_loss: 0.3490 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1583/1583 [==============================] - 1s 499us/step - loss: 0.3597 - accuracy: 0.8831 - val_loss: 0.3479 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1583/1583 [==============================] - 1s 547us/step - loss: 0.3558 - accuracy: 0.8830 - val_loss: 0.3469 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1583/1583 [==============================] - 1s 927us/step - loss: 0.3557 - accuracy: 0.8830 - val_loss: 0.3460 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1583/1583 [==============================] - 1s 816us/step - loss: 0.3552 - accuracy: 0.8830 - val_loss: 0.3451 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1583/1583 [==============================] - 1s 559us/step - loss: 0.3531 - accuracy: 0.8831 - val_loss: 0.3442 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1583/1583 [==============================] - 1s 564us/step - loss: 0.3527 - accuracy: 0.8830 - val_loss: 0.3434 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1583/1583 [==============================] - 1s 473us/step - loss: 0.3515 - accuracy: 0.8830 - val_loss: 0.3427 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1583/1583 [==============================] - 1s 468us/step - loss: 0.3509 - accuracy: 0.8830 - val_loss: 0.3419 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1583/1583 [==============================] - 1s 474us/step - loss: 0.3508 - accuracy: 0.8830 - val_loss: 0.3412 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1583/1583 [==============================] - 1s 483us/step - loss: 0.3478 - accuracy: 0.8830 - val_loss: 0.3405 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1583/1583 [==============================] - 1s 502us/step - loss: 0.3484 - accuracy: 0.8830 - val_loss: 0.3399 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1583/1583 [==============================] - 1s 496us/step - loss: 0.3472 - accuracy: 0.8830 - val_loss: 0.3393 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1583/1583 [==============================] - 1s 519us/step - loss: 0.3475 - accuracy: 0.8830 - val_loss: 0.3387 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1583/1583 [==============================] - 1s 619us/step - loss: 0.3464 - accuracy: 0.8830 - val_loss: 0.3381 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1583/1583 [==============================] - 1s 672us/step - loss: 0.3444 - accuracy: 0.8830 - val_loss: 0.3376 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1583/1583 [==============================] - 1s 541us/step - loss: 0.3442 - accuracy: 0.8830 - val_loss: 0.3370 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1583/1583 [==============================] - 1s 511us/step - loss: 0.3434 - accuracy: 0.8830 - val_loss: 0.3365 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1583/1583 [==============================] - 1s 480us/step - loss: 0.3430 - accuracy: 0.8830 - val_loss: 0.3360 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1583/1583 [==============================] - 1s 522us/step - loss: 0.3430 - accuracy: 0.8830 - val_loss: 0.3355 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1583/1583 [==============================] - 1s 484us/step - loss: 0.3425 - accuracy: 0.8830 - val_loss: 0.3351 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1583/1583 [==============================] - 1s 501us/step - loss: 0.3412 - accuracy: 0.8830 - val_loss: 0.3346 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1583/1583 [==============================] - 1s 483us/step - loss: 0.3424 - accuracy: 0.8830 - val_loss: 0.3342 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1583/1583 [==============================] - 1s 537us/step - loss: 0.3414 - accuracy: 0.8830 - val_loss: 0.3338 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1583/1583 [==============================] - 1s 545us/step - loss: 0.3397 - accuracy: 0.8829 - val_loss: 0.3334 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1583/1583 [==============================] - 1s 477us/step - loss: 0.3395 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1583/1583 [==============================] - 1s 488us/step - loss: 0.3390 - accuracy: 0.8831 - val_loss: 0.3326 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1583/1583 [==============================] - 1s 483us/step - loss: 0.3381 - accuracy: 0.8830 - val_loss: 0.3323 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1583/1583 [==============================] - 1s 503us/step - loss: 0.3392 - accuracy: 0.8830 - val_loss: 0.3319 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1583/1583 [==============================] - 1s 505us/step - loss: 0.3387 - accuracy: 0.8831 - val_loss: 0.3316 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1583/1583 [==============================] - 1s 489us/step - loss: 0.3383 - accuracy: 0.8831 - val_loss: 0.3313 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "1583/1583 [==============================] - 1s 534us/step - loss: 0.4998 - accuracy: 0.8082 - val_loss: 0.3929 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "1583/1583 [==============================] - 1s 717us/step - loss: 0.3966 - accuracy: 0.8827 - val_loss: 0.3778 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1583/1583 [==============================] - 1s 536us/step - loss: 0.3902 - accuracy: 0.8829 - val_loss: 0.3749 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1583/1583 [==============================] - 1s 530us/step - loss: 0.3878 - accuracy: 0.8830 - val_loss: 0.3730 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1583/1583 [==============================] - 1s 538us/step - loss: 0.3859 - accuracy: 0.8830 - val_loss: 0.3712 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1583/1583 [==============================] - 1s 517us/step - loss: 0.3825 - accuracy: 0.8829 - val_loss: 0.3694 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1583/1583 [==============================] - 1s 496us/step - loss: 0.3797 - accuracy: 0.8830 - val_loss: 0.3676 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1583/1583 [==============================] - 1s 523us/step - loss: 0.3809 - accuracy: 0.8830 - val_loss: 0.3657 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1583/1583 [==============================] - 1s 534us/step - loss: 0.3771 - accuracy: 0.8830 - val_loss: 0.3638 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1583/1583 [==============================] - 1s 589us/step - loss: 0.3755 - accuracy: 0.8828 - val_loss: 0.3621 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1583/1583 [==============================] - 1s 565us/step - loss: 0.3711 - accuracy: 0.8830 - val_loss: 0.3605 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1583/1583 [==============================] - 1s 528us/step - loss: 0.3716 - accuracy: 0.8830 - val_loss: 0.3591 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1583/1583 [==============================] - 1s 505us/step - loss: 0.3698 - accuracy: 0.8829 - val_loss: 0.3577 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1583/1583 [==============================] - 1s 535us/step - loss: 0.3685 - accuracy: 0.8829 - val_loss: 0.3564 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1583/1583 [==============================] - 1s 538us/step - loss: 0.3674 - accuracy: 0.8830 - val_loss: 0.3552 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1583/1583 [==============================] - 1s 509us/step - loss: 0.3658 - accuracy: 0.8830 - val_loss: 0.3540 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1583/1583 [==============================] - 1s 528us/step - loss: 0.3642 - accuracy: 0.8830 - val_loss: 0.3529 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1583/1583 [==============================] - 1s 593us/step - loss: 0.3629 - accuracy: 0.8830 - val_loss: 0.3519 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1583/1583 [==============================] - 1s 502us/step - loss: 0.3612 - accuracy: 0.8830 - val_loss: 0.3509 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1583/1583 [==============================] - 1s 571us/step - loss: 0.3617 - accuracy: 0.8830 - val_loss: 0.3499 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1583/1583 [==============================] - 1s 546us/step - loss: 0.3597 - accuracy: 0.8830 - val_loss: 0.3489 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1583/1583 [==============================] - 1s 525us/step - loss: 0.3579 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1583/1583 [==============================] - 1s 511us/step - loss: 0.3576 - accuracy: 0.8830 - val_loss: 0.3472 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1583/1583 [==============================] - 1s 526us/step - loss: 0.3562 - accuracy: 0.8829 - val_loss: 0.3464 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1583/1583 [==============================] - 1s 565us/step - loss: 0.3566 - accuracy: 0.8830 - val_loss: 0.3456 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1583/1583 [==============================] - 1s 496us/step - loss: 0.3562 - accuracy: 0.8830 - val_loss: 0.3448 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1583/1583 [==============================] - 1s 524us/step - loss: 0.3544 - accuracy: 0.8830 - val_loss: 0.3440 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1583/1583 [==============================] - 1s 479us/step - loss: 0.3543 - accuracy: 0.8830 - val_loss: 0.3433 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1583/1583 [==============================] - 1s 515us/step - loss: 0.3527 - accuracy: 0.8830 - val_loss: 0.3425 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1583/1583 [==============================] - 1s 525us/step - loss: 0.3508 - accuracy: 0.8830 - val_loss: 0.3418 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1583/1583 [==============================] - 1s 495us/step - loss: 0.3504 - accuracy: 0.8830 - val_loss: 0.3412 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1583/1583 [==============================] - 1s 491us/step - loss: 0.3502 - accuracy: 0.8830 - val_loss: 0.3405 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1583/1583 [==============================] - 1s 539us/step - loss: 0.3496 - accuracy: 0.8830 - val_loss: 0.3399 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1583/1583 [==============================] - 1s 516us/step - loss: 0.3493 - accuracy: 0.8831 - val_loss: 0.3393 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1583/1583 [==============================] - 1s 518us/step - loss: 0.3482 - accuracy: 0.8830 - val_loss: 0.3387 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1583/1583 [==============================] - 1s 704us/step - loss: 0.3473 - accuracy: 0.8831 - val_loss: 0.3382 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1583/1583 [==============================] - 1s 552us/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3376 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1583/1583 [==============================] - 1s 647us/step - loss: 0.3465 - accuracy: 0.8830 - val_loss: 0.3371 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1583/1583 [==============================] - 1s 804us/step - loss: 0.3456 - accuracy: 0.8831 - val_loss: 0.3366 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1583/1583 [==============================] - 1s 768us/step - loss: 0.3446 - accuracy: 0.8830 - val_loss: 0.3361 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1583/1583 [==============================] - 1s 740us/step - loss: 0.3438 - accuracy: 0.8830 - val_loss: 0.3356 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1583/1583 [==============================] - 1s 636us/step - loss: 0.3436 - accuracy: 0.8829 - val_loss: 0.3352 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1583/1583 [==============================] - 1s 574us/step - loss: 0.3429 - accuracy: 0.8830 - val_loss: 0.3347 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1583/1583 [==============================] - 1s 577us/step - loss: 0.3433 - accuracy: 0.8829 - val_loss: 0.3343 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1583/1583 [==============================] - 1s 727us/step - loss: 0.3429 - accuracy: 0.8831 - val_loss: 0.3339 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1583/1583 [==============================] - 1s 531us/step - loss: 0.3421 - accuracy: 0.8832 - val_loss: 0.3335 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1583/1583 [==============================] - 1s 544us/step - loss: 0.3417 - accuracy: 0.8831 - val_loss: 0.3331 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1583/1583 [==============================] - 1s 511us/step - loss: 0.3404 - accuracy: 0.8829 - val_loss: 0.3327 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1583/1583 [==============================] - 1s 623us/step - loss: 0.3411 - accuracy: 0.8828 - val_loss: 0.3323 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1583/1583 [==============================] - 1s 655us/step - loss: 0.3404 - accuracy: 0.8829 - val_loss: 0.3320 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "1583/1583 [==============================] - 1s 563us/step - loss: 0.4653 - accuracy: 0.8604 - val_loss: 0.4054 - val_accuracy: 0.8823\n",
      "Epoch 2/50\n",
      "1583/1583 [==============================] - 1s 524us/step - loss: 0.4137 - accuracy: 0.8821 - val_loss: 0.3963 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1583/1583 [==============================] - 1s 507us/step - loss: 0.4093 - accuracy: 0.8826 - val_loss: 0.3936 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1583/1583 [==============================] - 1s 515us/step - loss: 0.4093 - accuracy: 0.8828 - val_loss: 0.3916 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1583/1583 [==============================] - 1s 535us/step - loss: 0.4042 - accuracy: 0.8828 - val_loss: 0.3897 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1583/1583 [==============================] - 1s 506us/step - loss: 0.4041 - accuracy: 0.8829 - val_loss: 0.3880 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1583/1583 [==============================] - 1s 528us/step - loss: 0.3996 - accuracy: 0.8829 - val_loss: 0.3863 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1583/1583 [==============================] - 1s 488us/step - loss: 0.3994 - accuracy: 0.8830 - val_loss: 0.3847 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1583/1583 [==============================] - 1s 502us/step - loss: 0.3958 - accuracy: 0.8830 - val_loss: 0.3832 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1583/1583 [==============================] - 1s 633us/step - loss: 0.3949 - accuracy: 0.8830 - val_loss: 0.3817 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1583/1583 [==============================] - 1s 564us/step - loss: 0.3903 - accuracy: 0.8830 - val_loss: 0.3802 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1583/1583 [==============================] - 1s 519us/step - loss: 0.3914 - accuracy: 0.8830 - val_loss: 0.3788 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1583/1583 [==============================] - 1s 514us/step - loss: 0.3916 - accuracy: 0.8830 - val_loss: 0.3774 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1583/1583 [==============================] - 1s 535us/step - loss: 0.3891 - accuracy: 0.8830 - val_loss: 0.3760 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1583/1583 [==============================] - 1s 484us/step - loss: 0.3886 - accuracy: 0.8830 - val_loss: 0.3747 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1583/1583 [==============================] - 1s 493us/step - loss: 0.3861 - accuracy: 0.8830 - val_loss: 0.3733 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1583/1583 [==============================] - 1s 522us/step - loss: 0.3848 - accuracy: 0.8830 - val_loss: 0.3720 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1583/1583 [==============================] - 1s 493us/step - loss: 0.3825 - accuracy: 0.8830 - val_loss: 0.3708 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1583/1583 [==============================] - 1s 523us/step - loss: 0.3808 - accuracy: 0.8830 - val_loss: 0.3695 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1583/1583 [==============================] - 1s 728us/step - loss: 0.3785 - accuracy: 0.8830 - val_loss: 0.3683 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1583/1583 [==============================] - 1s 509us/step - loss: 0.3785 - accuracy: 0.8830 - val_loss: 0.3672 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1583/1583 [==============================] - 1s 489us/step - loss: 0.3767 - accuracy: 0.8830 - val_loss: 0.3660 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1583/1583 [==============================] - 1s 487us/step - loss: 0.3745 - accuracy: 0.8830 - val_loss: 0.3649 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1583/1583 [==============================] - 1s 485us/step - loss: 0.3741 - accuracy: 0.8830 - val_loss: 0.3637 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1583/1583 [==============================] - 1s 484us/step - loss: 0.3735 - accuracy: 0.8830 - val_loss: 0.3626 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1583/1583 [==============================] - 1s 556us/step - loss: 0.3706 - accuracy: 0.8830 - val_loss: 0.3615 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1583/1583 [==============================] - 1s 533us/step - loss: 0.3701 - accuracy: 0.8830 - val_loss: 0.3605 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1583/1583 [==============================] - 1s 487us/step - loss: 0.3687 - accuracy: 0.8830 - val_loss: 0.3594 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1583/1583 [==============================] - 1s 496us/step - loss: 0.3678 - accuracy: 0.8830 - val_loss: 0.3583 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1583/1583 [==============================] - 1s 498us/step - loss: 0.3677 - accuracy: 0.8830 - val_loss: 0.3572 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1583/1583 [==============================] - 1s 483us/step - loss: 0.3670 - accuracy: 0.8830 - val_loss: 0.3562 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1583/1583 [==============================] - 1s 483us/step - loss: 0.3639 - accuracy: 0.8830 - val_loss: 0.3552 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1583/1583 [==============================] - 1s 523us/step - loss: 0.3650 - accuracy: 0.8830 - val_loss: 0.3543 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1583/1583 [==============================] - 1s 485us/step - loss: 0.3629 - accuracy: 0.8830 - val_loss: 0.3534 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1583/1583 [==============================] - 1s 480us/step - loss: 0.3620 - accuracy: 0.8830 - val_loss: 0.3525 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1583/1583 [==============================] - 1s 488us/step - loss: 0.3616 - accuracy: 0.8830 - val_loss: 0.3517 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1583/1583 [==============================] - 1s 476us/step - loss: 0.3601 - accuracy: 0.8830 - val_loss: 0.3508 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1583/1583 [==============================] - 1s 478us/step - loss: 0.3609 - accuracy: 0.8830 - val_loss: 0.3500 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1583/1583 [==============================] - 1s 535us/step - loss: 0.3573 - accuracy: 0.8830 - val_loss: 0.3492 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1583/1583 [==============================] - 1s 535us/step - loss: 0.3570 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1583/1583 [==============================] - 1s 503us/step - loss: 0.3569 - accuracy: 0.8830 - val_loss: 0.3476 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1583/1583 [==============================] - 1s 526us/step - loss: 0.3546 - accuracy: 0.8830 - val_loss: 0.3468 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1583/1583 [==============================] - 1s 743us/step - loss: 0.3549 - accuracy: 0.8830 - val_loss: 0.3460 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1583/1583 [==============================] - 1s 646us/step - loss: 0.3526 - accuracy: 0.8830 - val_loss: 0.3453 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1583/1583 [==============================] - 1s 796us/step - loss: 0.3520 - accuracy: 0.8830 - val_loss: 0.3445 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1583/1583 [==============================] - 1s 634us/step - loss: 0.3523 - accuracy: 0.8830 - val_loss: 0.3438 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1583/1583 [==============================] - 1s 575us/step - loss: 0.3499 - accuracy: 0.8830 - val_loss: 0.3431 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1583/1583 [==============================] - 1s 574us/step - loss: 0.3502 - accuracy: 0.8830 - val_loss: 0.3424 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1583/1583 [==============================] - 1s 546us/step - loss: 0.3502 - accuracy: 0.8830 - val_loss: 0.3417 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1583/1583 [==============================] - 1s 690us/step - loss: 0.3482 - accuracy: 0.8830 - val_loss: 0.3410 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583/1583 [==============================] - 1s 647us/step - loss: 0.4507 - accuracy: 0.8618 - val_loss: 0.3893 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "1583/1583 [==============================] - 1s 548us/step - loss: 0.3977 - accuracy: 0.8829 - val_loss: 0.3822 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1583/1583 [==============================] - 1s 562us/step - loss: 0.3942 - accuracy: 0.8829 - val_loss: 0.3790 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1583/1583 [==============================] - 1s 767us/step - loss: 0.3912 - accuracy: 0.8830 - val_loss: 0.3764 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1583/1583 [==============================] - 1s 537us/step - loss: 0.3880 - accuracy: 0.8829 - val_loss: 0.3741 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1583/1583 [==============================] - 1s 506us/step - loss: 0.3858 - accuracy: 0.8830 - val_loss: 0.3718 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1583/1583 [==============================] - 1s 551us/step - loss: 0.3820 - accuracy: 0.8828 - val_loss: 0.3697 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1583/1583 [==============================] - 1s 511us/step - loss: 0.3806 - accuracy: 0.8829 - val_loss: 0.3677 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1583/1583 [==============================] - 1s 530us/step - loss: 0.3773 - accuracy: 0.8829 - val_loss: 0.3658 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1583/1583 [==============================] - 1s 515us/step - loss: 0.3779 - accuracy: 0.8829 - val_loss: 0.3640 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1583/1583 [==============================] - 1s 563us/step - loss: 0.3753 - accuracy: 0.8830 - val_loss: 0.3624 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1583/1583 [==============================] - 1s 661us/step - loss: 0.3721 - accuracy: 0.8829 - val_loss: 0.3608 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1583/1583 [==============================] - 1s 594us/step - loss: 0.3700 - accuracy: 0.8829 - val_loss: 0.3593 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1583/1583 [==============================] - 1s 529us/step - loss: 0.3695 - accuracy: 0.8830 - val_loss: 0.3579 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1583/1583 [==============================] - 1s 624us/step - loss: 0.3684 - accuracy: 0.8830 - val_loss: 0.3566 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1583/1583 [==============================] - 1s 667us/step - loss: 0.3658 - accuracy: 0.8830 - val_loss: 0.3554 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1583/1583 [==============================] - 1s 553us/step - loss: 0.3656 - accuracy: 0.8829 - val_loss: 0.3542 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1583/1583 [==============================] - 1s 545us/step - loss: 0.3644 - accuracy: 0.8830 - val_loss: 0.3531 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1583/1583 [==============================] - 1s 509us/step - loss: 0.3623 - accuracy: 0.8830 - val_loss: 0.3520 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1583/1583 [==============================] - 1s 532us/step - loss: 0.3625 - accuracy: 0.8830 - val_loss: 0.3510 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1583/1583 [==============================] - 1s 536us/step - loss: 0.3604 - accuracy: 0.8829 - val_loss: 0.3500 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1583/1583 [==============================] - 1s 517us/step - loss: 0.3600 - accuracy: 0.8829 - val_loss: 0.3490 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1583/1583 [==============================] - 1s 521us/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.3480 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1583/1583 [==============================] - 1s 515us/step - loss: 0.3564 - accuracy: 0.8830 - val_loss: 0.3471 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1583/1583 [==============================] - 1s 586us/step - loss: 0.3560 - accuracy: 0.8830 - val_loss: 0.3462 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1583/1583 [==============================] - 1s 528us/step - loss: 0.3556 - accuracy: 0.8830 - val_loss: 0.3454 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1583/1583 [==============================] - 1s 524us/step - loss: 0.3547 - accuracy: 0.8830 - val_loss: 0.3446 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1583/1583 [==============================] - 1s 533us/step - loss: 0.3535 - accuracy: 0.8829 - val_loss: 0.3438 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1583/1583 [==============================] - 1s 558us/step - loss: 0.3527 - accuracy: 0.8830 - val_loss: 0.3430 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1583/1583 [==============================] - 1s 562us/step - loss: 0.3515 - accuracy: 0.8830 - val_loss: 0.3423 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1583/1583 [==============================] - 1s 561us/step - loss: 0.3510 - accuracy: 0.8830 - val_loss: 0.3415 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1583/1583 [==============================] - 1s 623us/step - loss: 0.3506 - accuracy: 0.8830 - val_loss: 0.3409 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1583/1583 [==============================] - 1s 535us/step - loss: 0.3500 - accuracy: 0.8830 - val_loss: 0.3402 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1583/1583 [==============================] - 1s 533us/step - loss: 0.3480 - accuracy: 0.8830 - val_loss: 0.3396 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1583/1583 [==============================] - 1s 527us/step - loss: 0.3486 - accuracy: 0.8831 - val_loss: 0.3389 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1583/1583 [==============================] - 1s 527us/step - loss: 0.3465 - accuracy: 0.8828 - val_loss: 0.3383 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1583/1583 [==============================] - 1s 533us/step - loss: 0.3459 - accuracy: 0.8829 - val_loss: 0.3376 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1583/1583 [==============================] - 1s 596us/step - loss: 0.3450 - accuracy: 0.8830 - val_loss: 0.3371 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1583/1583 [==============================] - 1s 535us/step - loss: 0.3449 - accuracy: 0.8831 - val_loss: 0.3365 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1583/1583 [==============================] - 1s 515us/step - loss: 0.3447 - accuracy: 0.8830 - val_loss: 0.3360 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1583/1583 [==============================] - 1s 558us/step - loss: 0.3422 - accuracy: 0.8831 - val_loss: 0.3354 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1583/1583 [==============================] - 1s 528us/step - loss: 0.3440 - accuracy: 0.8828 - val_loss: 0.3350 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1583/1583 [==============================] - 1s 521us/step - loss: 0.3430 - accuracy: 0.8828 - val_loss: 0.3345 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1583/1583 [==============================] - 1s 520us/step - loss: 0.3417 - accuracy: 0.8829 - val_loss: 0.3340 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1583/1583 [==============================] - 1s 516us/step - loss: 0.3407 - accuracy: 0.8828 - val_loss: 0.3335 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1583/1583 [==============================] - 1s 536us/step - loss: 0.3422 - accuracy: 0.8828 - val_loss: 0.3331 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1583/1583 [==============================] - 1s 528us/step - loss: 0.3402 - accuracy: 0.8831 - val_loss: 0.3326 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1583/1583 [==============================] - 1s 524us/step - loss: 0.3402 - accuracy: 0.8830 - val_loss: 0.3323 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1583/1583 [==============================] - 1s 581us/step - loss: 0.3406 - accuracy: 0.8829 - val_loss: 0.3319 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1583/1583 [==============================] - 1s 533us/step - loss: 0.3384 - accuracy: 0.8828 - val_loss: 0.3314 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "=== Experimentos con tamaño de muestra 80.0% ===\n",
      "Training set size: 28934\n",
      "DP-SGD with sampling rate = 0.0553% and noise_multiplier = 1.1 iterated over 90419 steps satisfies differential privacy with eps = 1.03 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1809/1809 [==============================] - 1s 550us/step - loss: 0.5958 - accuracy: 0.6995 - val_loss: 0.4346 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "1809/1809 [==============================] - 1s 512us/step - loss: 0.4204 - accuracy: 0.8825 - val_loss: 0.3983 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1809/1809 [==============================] - 1s 510us/step - loss: 0.4031 - accuracy: 0.8830 - val_loss: 0.3916 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1809/1809 [==============================] - 1s 528us/step - loss: 0.3994 - accuracy: 0.8830 - val_loss: 0.3884 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1809/1809 [==============================] - 1s 528us/step - loss: 0.3978 - accuracy: 0.8830 - val_loss: 0.3862 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1809/1809 [==============================] - 1s 516us/step - loss: 0.3929 - accuracy: 0.8830 - val_loss: 0.3842 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1809/1809 [==============================] - 1s 512us/step - loss: 0.3936 - accuracy: 0.8830 - val_loss: 0.3824 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1809/1809 [==============================] - 1s 541us/step - loss: 0.3897 - accuracy: 0.8830 - val_loss: 0.3808 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1809/1809 [==============================] - 1s 563us/step - loss: 0.3886 - accuracy: 0.8830 - val_loss: 0.3793 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1809/1809 [==============================] - 1s 526us/step - loss: 0.3883 - accuracy: 0.8830 - val_loss: 0.3778 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1809/1809 [==============================] - 1s 531us/step - loss: 0.3852 - accuracy: 0.8830 - val_loss: 0.3763 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1809/1809 [==============================] - 1s 517us/step - loss: 0.3849 - accuracy: 0.8830 - val_loss: 0.3749 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1809/1809 [==============================] - 1s 521us/step - loss: 0.3827 - accuracy: 0.8830 - val_loss: 0.3735 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1809/1809 [==============================] - 1s 542us/step - loss: 0.3806 - accuracy: 0.8830 - val_loss: 0.3722 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1809/1809 [==============================] - 1s 529us/step - loss: 0.3790 - accuracy: 0.8830 - val_loss: 0.3708 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1809/1809 [==============================] - 1s 523us/step - loss: 0.3780 - accuracy: 0.8830 - val_loss: 0.3694 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1809/1809 [==============================] - 1s 575us/step - loss: 0.3775 - accuracy: 0.8830 - val_loss: 0.3680 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1809/1809 [==============================] - 1s 549us/step - loss: 0.3753 - accuracy: 0.8830 - val_loss: 0.3666 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1809/1809 [==============================] - 1s 515us/step - loss: 0.3738 - accuracy: 0.8830 - val_loss: 0.3652 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1809/1809 [==============================] - 1s 519us/step - loss: 0.3722 - accuracy: 0.8830 - val_loss: 0.3637 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1809/1809 [==============================] - 1s 518us/step - loss: 0.3707 - accuracy: 0.8830 - val_loss: 0.3623 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1809/1809 [==============================] - 1s 519us/step - loss: 0.3673 - accuracy: 0.8830 - val_loss: 0.3610 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1809/1809 [==============================] - 1s 524us/step - loss: 0.3678 - accuracy: 0.8830 - val_loss: 0.3598 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1809/1809 [==============================] - 1s 515us/step - loss: 0.3661 - accuracy: 0.8830 - val_loss: 0.3585 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1809/1809 [==============================] - 1s 553us/step - loss: 0.3657 - accuracy: 0.8830 - val_loss: 0.3573 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1809/1809 [==============================] - 1s 537us/step - loss: 0.3633 - accuracy: 0.8830 - val_loss: 0.3562 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1809/1809 [==============================] - 1s 519us/step - loss: 0.3624 - accuracy: 0.8830 - val_loss: 0.3551 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1809/1809 [==============================] - 1s 617us/step - loss: 0.3614 - accuracy: 0.8830 - val_loss: 0.3541 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1809/1809 [==============================] - 1s 522us/step - loss: 0.3600 - accuracy: 0.8830 - val_loss: 0.3530 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1809/1809 [==============================] - 1s 510us/step - loss: 0.3592 - accuracy: 0.8830 - val_loss: 0.3520 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1809/1809 [==============================] - 1s 536us/step - loss: 0.3587 - accuracy: 0.8830 - val_loss: 0.3511 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1809/1809 [==============================] - 1s 512us/step - loss: 0.3573 - accuracy: 0.8830 - val_loss: 0.3502 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1809/1809 [==============================] - 1s 535us/step - loss: 0.3559 - accuracy: 0.8830 - val_loss: 0.3492 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1809/1809 [==============================] - 1s 543us/step - loss: 0.3557 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1809/1809 [==============================] - 1s 516us/step - loss: 0.3552 - accuracy: 0.8830 - val_loss: 0.3475 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1809/1809 [==============================] - 1s 560us/step - loss: 0.3541 - accuracy: 0.8830 - val_loss: 0.3467 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1809/1809 [==============================] - 1s 682us/step - loss: 0.3528 - accuracy: 0.8830 - val_loss: 0.3458 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1809/1809 [==============================] - 1s 686us/step - loss: 0.3518 - accuracy: 0.8830 - val_loss: 0.3450 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1809/1809 [==============================] - 1s 584us/step - loss: 0.3506 - accuracy: 0.8830 - val_loss: 0.3443 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1809/1809 [==============================] - 1s 560us/step - loss: 0.3495 - accuracy: 0.8830 - val_loss: 0.3435 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1809/1809 [==============================] - 1s 497us/step - loss: 0.3498 - accuracy: 0.8830 - val_loss: 0.3427 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3483 - accuracy: 0.8830 - val_loss: 0.3420 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1809/1809 [==============================] - 1s 496us/step - loss: 0.3477 - accuracy: 0.8830 - val_loss: 0.3412 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1809/1809 [==============================] - 1s 495us/step - loss: 0.3464 - accuracy: 0.8830 - val_loss: 0.3405 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1809/1809 [==============================] - 1s 494us/step - loss: 0.3460 - accuracy: 0.8830 - val_loss: 0.3398 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1809/1809 [==============================] - 1s 497us/step - loss: 0.3447 - accuracy: 0.8830 - val_loss: 0.3392 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1809/1809 [==============================] - 1s 492us/step - loss: 0.3450 - accuracy: 0.8830 - val_loss: 0.3385 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1809/1809 [==============================] - 1s 543us/step - loss: 0.3442 - accuracy: 0.8830 - val_loss: 0.3379 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1809/1809 [==============================] - 1s 487us/step - loss: 0.3426 - accuracy: 0.8830 - val_loss: 0.3373 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1809/1809 [==============================] - 1s 494us/step - loss: 0.3424 - accuracy: 0.8830 - val_loss: 0.3367 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "   1/1809 [..............................] - ETA: 0s - loss: 0.6049 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1809/1809 [==============================] - 1s 532us/step - loss: 0.4414 - accuracy: 0.8766 - val_loss: 0.4021 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "1809/1809 [==============================] - 1s 493us/step - loss: 0.4102 - accuracy: 0.8830 - val_loss: 0.3945 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1809/1809 [==============================] - 1s 489us/step - loss: 0.4042 - accuracy: 0.8830 - val_loss: 0.3907 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1809/1809 [==============================] - 1s 487us/step - loss: 0.3991 - accuracy: 0.8829 - val_loss: 0.3879 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1809/1809 [==============================] - 1s 489us/step - loss: 0.3969 - accuracy: 0.8829 - val_loss: 0.3857 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1809/1809 [==============================] - 1s 504us/step - loss: 0.3953 - accuracy: 0.8829 - val_loss: 0.3836 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1809/1809 [==============================] - 1s 492us/step - loss: 0.3934 - accuracy: 0.8830 - val_loss: 0.3815 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1809/1809 [==============================] - 1s 523us/step - loss: 0.3901 - accuracy: 0.8830 - val_loss: 0.3797 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1809/1809 [==============================] - 1s 526us/step - loss: 0.3882 - accuracy: 0.8830 - val_loss: 0.3779 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1809/1809 [==============================] - 1s 544us/step - loss: 0.3856 - accuracy: 0.8830 - val_loss: 0.3761 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1809/1809 [==============================] - 1s 593us/step - loss: 0.3854 - accuracy: 0.8830 - val_loss: 0.3745 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1809/1809 [==============================] - 1s 542us/step - loss: 0.3852 - accuracy: 0.8830 - val_loss: 0.3730 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1809/1809 [==============================] - 1s 555us/step - loss: 0.3819 - accuracy: 0.8830 - val_loss: 0.3716 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1809/1809 [==============================] - 1s 574us/step - loss: 0.3798 - accuracy: 0.8830 - val_loss: 0.3702 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1809/1809 [==============================] - 1s 569us/step - loss: 0.3788 - accuracy: 0.8830 - val_loss: 0.3689 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1809/1809 [==============================] - 1s 571us/step - loss: 0.3764 - accuracy: 0.8830 - val_loss: 0.3675 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1809/1809 [==============================] - 1s 576us/step - loss: 0.3757 - accuracy: 0.8830 - val_loss: 0.3663 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1809/1809 [==============================] - 1s 566us/step - loss: 0.3747 - accuracy: 0.8830 - val_loss: 0.3650 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1809/1809 [==============================] - 1s 573us/step - loss: 0.3735 - accuracy: 0.8830 - val_loss: 0.3638 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1809/1809 [==============================] - 1s 566us/step - loss: 0.3711 - accuracy: 0.8830 - val_loss: 0.3626 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1809/1809 [==============================] - 1s 582us/step - loss: 0.3697 - accuracy: 0.8830 - val_loss: 0.3615 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1809/1809 [==============================] - 1s 621us/step - loss: 0.3695 - accuracy: 0.8830 - val_loss: 0.3603 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1809/1809 [==============================] - 1s 593us/step - loss: 0.3678 - accuracy: 0.8830 - val_loss: 0.3592 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1809/1809 [==============================] - 1s 586us/step - loss: 0.3678 - accuracy: 0.8830 - val_loss: 0.3581 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1809/1809 [==============================] - 1s 535us/step - loss: 0.3647 - accuracy: 0.8830 - val_loss: 0.3570 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1809/1809 [==============================] - 1s 502us/step - loss: 0.3641 - accuracy: 0.8830 - val_loss: 0.3560 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1809/1809 [==============================] - 1s 510us/step - loss: 0.3639 - accuracy: 0.8830 - val_loss: 0.3549 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1809/1809 [==============================] - 1s 541us/step - loss: 0.3611 - accuracy: 0.8830 - val_loss: 0.3539 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1809/1809 [==============================] - 1s 544us/step - loss: 0.3601 - accuracy: 0.8830 - val_loss: 0.3528 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1809/1809 [==============================] - 1s 519us/step - loss: 0.3612 - accuracy: 0.8830 - val_loss: 0.3518 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1809/1809 [==============================] - 1s 517us/step - loss: 0.3586 - accuracy: 0.8830 - val_loss: 0.3509 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1809/1809 [==============================] - 1s 500us/step - loss: 0.3585 - accuracy: 0.8830 - val_loss: 0.3499 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1809/1809 [==============================] - 1s 555us/step - loss: 0.3559 - accuracy: 0.8830 - val_loss: 0.3490 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1809/1809 [==============================] - 1s 508us/step - loss: 0.3560 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1809/1809 [==============================] - 1s 511us/step - loss: 0.3544 - accuracy: 0.8830 - val_loss: 0.3472 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1809/1809 [==============================] - 1s 502us/step - loss: 0.3548 - accuracy: 0.8830 - val_loss: 0.3463 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1809/1809 [==============================] - 1s 493us/step - loss: 0.3534 - accuracy: 0.8830 - val_loss: 0.3455 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1809/1809 [==============================] - 1s 521us/step - loss: 0.3526 - accuracy: 0.8830 - val_loss: 0.3446 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1809/1809 [==============================] - 1s 496us/step - loss: 0.3516 - accuracy: 0.8830 - val_loss: 0.3438 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1809/1809 [==============================] - 1s 507us/step - loss: 0.3499 - accuracy: 0.8830 - val_loss: 0.3430 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1809/1809 [==============================] - 1s 503us/step - loss: 0.3497 - accuracy: 0.8830 - val_loss: 0.3422 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1809/1809 [==============================] - 1s 506us/step - loss: 0.3496 - accuracy: 0.8830 - val_loss: 0.3415 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1809/1809 [==============================] - 1s 527us/step - loss: 0.3490 - accuracy: 0.8830 - val_loss: 0.3407 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1809/1809 [==============================] - 1s 483us/step - loss: 0.3478 - accuracy: 0.8830 - val_loss: 0.3400 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1809/1809 [==============================] - 1s 484us/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3394 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1809/1809 [==============================] - 1s 726us/step - loss: 0.3464 - accuracy: 0.8830 - val_loss: 0.3387 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1809/1809 [==============================] - 1s 543us/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 0.3380 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1809/1809 [==============================] - 1s 490us/step - loss: 0.3446 - accuracy: 0.8830 - val_loss: 0.3374 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1809/1809 [==============================] - 1s 490us/step - loss: 0.3438 - accuracy: 0.8830 - val_loss: 0.3368 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1809/1809 [==============================] - 1s 485us/step - loss: 0.3442 - accuracy: 0.8830 - val_loss: 0.3363 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "1809/1809 [==============================] - 1s 543us/step - loss: 0.4514 - accuracy: 0.8665 - val_loss: 0.3929 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "1809/1809 [==============================] - 1s 526us/step - loss: 0.3964 - accuracy: 0.8825 - val_loss: 0.3801 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1809/1809 [==============================] - 1s 562us/step - loss: 0.3878 - accuracy: 0.8828 - val_loss: 0.3767 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3855 - accuracy: 0.8830 - val_loss: 0.3743 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1809/1809 [==============================] - 1s 501us/step - loss: 0.3833 - accuracy: 0.8830 - val_loss: 0.3721 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1809/1809 [==============================] - 1s 501us/step - loss: 0.3821 - accuracy: 0.8829 - val_loss: 0.3701 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1809/1809 [==============================] - 1s 503us/step - loss: 0.3787 - accuracy: 0.8830 - val_loss: 0.3683 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1809/1809 [==============================] - 1s 510us/step - loss: 0.3769 - accuracy: 0.8830 - val_loss: 0.3666 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1809/1809 [==============================] - 1s 504us/step - loss: 0.3743 - accuracy: 0.8830 - val_loss: 0.3649 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3725 - accuracy: 0.8830 - val_loss: 0.3634 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1809/1809 [==============================] - 1s 497us/step - loss: 0.3723 - accuracy: 0.8830 - val_loss: 0.3619 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1809/1809 [==============================] - 1s 557us/step - loss: 0.3709 - accuracy: 0.8830 - val_loss: 0.3604 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1809/1809 [==============================] - 1s 503us/step - loss: 0.3693 - accuracy: 0.8830 - val_loss: 0.3590 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1809/1809 [==============================] - 1s 494us/step - loss: 0.3662 - accuracy: 0.8830 - val_loss: 0.3577 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1809/1809 [==============================] - 1s 495us/step - loss: 0.3645 - accuracy: 0.8830 - val_loss: 0.3563 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1809/1809 [==============================] - 1s 496us/step - loss: 0.3634 - accuracy: 0.8830 - val_loss: 0.3548 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3622 - accuracy: 0.8830 - val_loss: 0.3534 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1809/1809 [==============================] - 1s 508us/step - loss: 0.3608 - accuracy: 0.8830 - val_loss: 0.3522 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3599 - accuracy: 0.8830 - val_loss: 0.3510 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1809/1809 [==============================] - 1s 516us/step - loss: 0.3604 - accuracy: 0.8830 - val_loss: 0.3499 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1809/1809 [==============================] - 1s 530us/step - loss: 0.3573 - accuracy: 0.8830 - val_loss: 0.3488 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1809/1809 [==============================] - 1s 505us/step - loss: 0.3563 - accuracy: 0.8830 - val_loss: 0.3478 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1809/1809 [==============================] - 1s 495us/step - loss: 0.3551 - accuracy: 0.8830 - val_loss: 0.3468 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1809/1809 [==============================] - 1s 532us/step - loss: 0.3533 - accuracy: 0.8830 - val_loss: 0.3458 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3523 - accuracy: 0.8830 - val_loss: 0.3448 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1809/1809 [==============================] - 1s 523us/step - loss: 0.3522 - accuracy: 0.8831 - val_loss: 0.3438 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1809/1809 [==============================] - 1s 532us/step - loss: 0.3505 - accuracy: 0.8830 - val_loss: 0.3427 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1809/1809 [==============================] - 1s 504us/step - loss: 0.3490 - accuracy: 0.8830 - val_loss: 0.3417 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1809/1809 [==============================] - 1s 538us/step - loss: 0.3488 - accuracy: 0.8830 - val_loss: 0.3409 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3485 - accuracy: 0.8830 - val_loss: 0.3401 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1809/1809 [==============================] - 1s 492us/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3393 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1809/1809 [==============================] - 1s 489us/step - loss: 0.3469 - accuracy: 0.8830 - val_loss: 0.3386 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3464 - accuracy: 0.8830 - val_loss: 0.3380 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1809/1809 [==============================] - 1s 491us/step - loss: 0.3446 - accuracy: 0.8830 - val_loss: 0.3373 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1809/1809 [==============================] - 1s 495us/step - loss: 0.3442 - accuracy: 0.8831 - val_loss: 0.3367 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1809/1809 [==============================] - 1s 503us/step - loss: 0.3445 - accuracy: 0.8830 - val_loss: 0.3361 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1809/1809 [==============================] - 1s 534us/step - loss: 0.3435 - accuracy: 0.8830 - val_loss: 0.3355 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1809/1809 [==============================] - 1s 494us/step - loss: 0.3424 - accuracy: 0.8830 - val_loss: 0.3350 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1809/1809 [==============================] - 1s 605us/step - loss: 0.3410 - accuracy: 0.8830 - val_loss: 0.3344 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3421 - accuracy: 0.8830 - val_loss: 0.3339 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1809/1809 [==============================] - 1s 497us/step - loss: 0.3410 - accuracy: 0.8830 - val_loss: 0.3334 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1809/1809 [==============================] - 1s 490us/step - loss: 0.3395 - accuracy: 0.8831 - val_loss: 0.3329 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1809/1809 [==============================] - 1s 540us/step - loss: 0.3395 - accuracy: 0.8831 - val_loss: 0.3325 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1809/1809 [==============================] - 1s 648us/step - loss: 0.3387 - accuracy: 0.8831 - val_loss: 0.3320 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1809/1809 [==============================] - 1s 544us/step - loss: 0.3385 - accuracy: 0.8831 - val_loss: 0.3316 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3382 - accuracy: 0.8830 - val_loss: 0.3312 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1809/1809 [==============================] - 1s 497us/step - loss: 0.3379 - accuracy: 0.8830 - val_loss: 0.3308 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3383 - accuracy: 0.8831 - val_loss: 0.3304 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1809/1809 [==============================] - 1s 525us/step - loss: 0.3386 - accuracy: 0.8831 - val_loss: 0.3300 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1809/1809 [==============================] - 1s 496us/step - loss: 0.3359 - accuracy: 0.8831 - val_loss: 0.3297 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "1809/1809 [==============================] - 1s 550us/step - loss: 0.4086 - accuracy: 0.8787 - val_loss: 0.3828 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "1809/1809 [==============================] - 1s 497us/step - loss: 0.3917 - accuracy: 0.8820 - val_loss: 0.3795 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1809/1809 [==============================] - 1s 497us/step - loss: 0.3902 - accuracy: 0.8822 - val_loss: 0.3772 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1809/1809 [==============================] - 1s 496us/step - loss: 0.3859 - accuracy: 0.8824 - val_loss: 0.3749 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1809/1809 [==============================] - 1s 494us/step - loss: 0.3835 - accuracy: 0.8827 - val_loss: 0.3728 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1809/1809 [==============================] - 1s 496us/step - loss: 0.3824 - accuracy: 0.8828 - val_loss: 0.3709 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3791 - accuracy: 0.8830 - val_loss: 0.3692 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1809/1809 [==============================] - 1s 511us/step - loss: 0.3784 - accuracy: 0.8829 - val_loss: 0.3676 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1809/1809 [==============================] - 1s 530us/step - loss: 0.3758 - accuracy: 0.8829 - val_loss: 0.3660 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3746 - accuracy: 0.8829 - val_loss: 0.3645 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3737 - accuracy: 0.8830 - val_loss: 0.3632 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1809/1809 [==============================] - 1s 546us/step - loss: 0.3716 - accuracy: 0.8830 - val_loss: 0.3618 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1809/1809 [==============================] - 1s 507us/step - loss: 0.3697 - accuracy: 0.8830 - val_loss: 0.3604 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3684 - accuracy: 0.8830 - val_loss: 0.3591 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1809/1809 [==============================] - 1s 575us/step - loss: 0.3672 - accuracy: 0.8830 - val_loss: 0.3577 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1809/1809 [==============================] - 1s 531us/step - loss: 0.3658 - accuracy: 0.8830 - val_loss: 0.3564 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1809/1809 [==============================] - 1s 508us/step - loss: 0.3645 - accuracy: 0.8830 - val_loss: 0.3552 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3627 - accuracy: 0.8830 - val_loss: 0.3540 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1809/1809 [==============================] - 1s 539us/step - loss: 0.3608 - accuracy: 0.8830 - val_loss: 0.3529 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3598 - accuracy: 0.8830 - val_loss: 0.3518 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1809/1809 [==============================] - 1s 505us/step - loss: 0.3588 - accuracy: 0.8830 - val_loss: 0.3507 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1809/1809 [==============================] - 1s 578us/step - loss: 0.3576 - accuracy: 0.8830 - val_loss: 0.3497 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1809/1809 [==============================] - 1s 536us/step - loss: 0.3569 - accuracy: 0.8830 - val_loss: 0.3487 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1809/1809 [==============================] - 1s 491us/step - loss: 0.3563 - accuracy: 0.8830 - val_loss: 0.3478 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1809/1809 [==============================] - 1s 488us/step - loss: 0.3533 - accuracy: 0.8830 - val_loss: 0.3468 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1809/1809 [==============================] - 1s 487us/step - loss: 0.3533 - accuracy: 0.8830 - val_loss: 0.3459 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1809/1809 [==============================] - 1s 490us/step - loss: 0.3533 - accuracy: 0.8830 - val_loss: 0.3450 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1809/1809 [==============================] - 1s 488us/step - loss: 0.3511 - accuracy: 0.8830 - val_loss: 0.3441 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1809/1809 [==============================] - 1s 508us/step - loss: 0.3511 - accuracy: 0.8829 - val_loss: 0.3433 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1809/1809 [==============================] - 1s 514us/step - loss: 0.3503 - accuracy: 0.8830 - val_loss: 0.3425 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1809/1809 [==============================] - 1s 489us/step - loss: 0.3500 - accuracy: 0.8830 - val_loss: 0.3417 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1809/1809 [==============================] - 1s 495us/step - loss: 0.3481 - accuracy: 0.8830 - val_loss: 0.3409 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1809/1809 [==============================] - 1s 492us/step - loss: 0.3475 - accuracy: 0.8830 - val_loss: 0.3401 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1809/1809 [==============================] - 1s 491us/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3395 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3458 - accuracy: 0.8830 - val_loss: 0.3387 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1809/1809 [==============================] - 1s 573us/step - loss: 0.3459 - accuracy: 0.8831 - val_loss: 0.3381 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1809/1809 [==============================] - 1s 525us/step - loss: 0.3443 - accuracy: 0.8830 - val_loss: 0.3374 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1809/1809 [==============================] - 1s 510us/step - loss: 0.3448 - accuracy: 0.8829 - val_loss: 0.3369 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1809/1809 [==============================] - 1s 496us/step - loss: 0.3428 - accuracy: 0.8830 - val_loss: 0.3362 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1809/1809 [==============================] - 1s 486us/step - loss: 0.3423 - accuracy: 0.8830 - val_loss: 0.3357 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1809/1809 [==============================] - 1s 487us/step - loss: 0.3412 - accuracy: 0.8831 - val_loss: 0.3351 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1809/1809 [==============================] - 1s 514us/step - loss: 0.3419 - accuracy: 0.8830 - val_loss: 0.3347 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1809/1809 [==============================] - 1s 514us/step - loss: 0.3412 - accuracy: 0.8831 - val_loss: 0.3341 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3396 - accuracy: 0.8831 - val_loss: 0.3336 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1809/1809 [==============================] - 1s 516us/step - loss: 0.3395 - accuracy: 0.8833 - val_loss: 0.3332 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1809/1809 [==============================] - 1s 493us/step - loss: 0.3395 - accuracy: 0.8830 - val_loss: 0.3327 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1809/1809 [==============================] - 1s 492us/step - loss: 0.3382 - accuracy: 0.8831 - val_loss: 0.3324 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1809/1809 [==============================] - 1s 487us/step - loss: 0.3385 - accuracy: 0.8833 - val_loss: 0.3319 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1809/1809 [==============================] - 1s 547us/step - loss: 0.3392 - accuracy: 0.8830 - val_loss: 0.3315 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3374 - accuracy: 0.8832 - val_loss: 0.3312 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "1809/1809 [==============================] - 1s 515us/step - loss: 0.5233 - accuracy: 0.7870 - val_loss: 0.4105 - val_accuracy: 0.8815\n",
      "Epoch 2/50\n",
      "1809/1809 [==============================] - 1s 483us/step - loss: 0.4124 - accuracy: 0.8811 - val_loss: 0.3881 - val_accuracy: 0.8831\n",
      "Epoch 3/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.4011 - accuracy: 0.8823 - val_loss: 0.3830 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "1809/1809 [==============================] - 1s 509us/step - loss: 0.3951 - accuracy: 0.8826 - val_loss: 0.3800 - val_accuracy: 0.8831\n",
      "Epoch 5/50\n",
      "1809/1809 [==============================] - 1s 550us/step - loss: 0.3931 - accuracy: 0.8829 - val_loss: 0.3774 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "1809/1809 [==============================] - 1s 504us/step - loss: 0.3905 - accuracy: 0.8830 - val_loss: 0.3751 - val_accuracy: 0.8831\n",
      "Epoch 7/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3890 - accuracy: 0.8830 - val_loss: 0.3729 - val_accuracy: 0.8831\n",
      "Epoch 8/50\n",
      "1809/1809 [==============================] - 1s 484us/step - loss: 0.3847 - accuracy: 0.8829 - val_loss: 0.3709 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "1809/1809 [==============================] - 1s 506us/step - loss: 0.3822 - accuracy: 0.8830 - val_loss: 0.3690 - val_accuracy: 0.8831\n",
      "Epoch 10/50\n",
      "1809/1809 [==============================] - 1s 490us/step - loss: 0.3816 - accuracy: 0.8829 - val_loss: 0.3671 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "1809/1809 [==============================] - 1s 501us/step - loss: 0.3802 - accuracy: 0.8830 - val_loss: 0.3653 - val_accuracy: 0.8831\n",
      "Epoch 12/50\n",
      "1809/1809 [==============================] - 1s 532us/step - loss: 0.3780 - accuracy: 0.8829 - val_loss: 0.3636 - val_accuracy: 0.8831\n",
      "Epoch 13/50\n",
      "1809/1809 [==============================] - 1s 494us/step - loss: 0.3744 - accuracy: 0.8829 - val_loss: 0.3619 - val_accuracy: 0.8831\n",
      "Epoch 14/50\n",
      "1809/1809 [==============================] - 1s 486us/step - loss: 0.3741 - accuracy: 0.8830 - val_loss: 0.3602 - val_accuracy: 0.8831\n",
      "Epoch 15/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3715 - accuracy: 0.8830 - val_loss: 0.3586 - val_accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "1809/1809 [==============================] - 1s 524us/step - loss: 0.3712 - accuracy: 0.8829 - val_loss: 0.3571 - val_accuracy: 0.8831\n",
      "Epoch 17/50\n",
      "1809/1809 [==============================] - 1s 533us/step - loss: 0.3673 - accuracy: 0.8830 - val_loss: 0.3557 - val_accuracy: 0.8831\n",
      "Epoch 18/50\n",
      "1809/1809 [==============================] - 1s 554us/step - loss: 0.3675 - accuracy: 0.8831 - val_loss: 0.3543 - val_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "1809/1809 [==============================] - 1s 497us/step - loss: 0.3666 - accuracy: 0.8828 - val_loss: 0.3531 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "1809/1809 [==============================] - 1s 493us/step - loss: 0.3638 - accuracy: 0.8830 - val_loss: 0.3519 - val_accuracy: 0.8831\n",
      "Epoch 21/50\n",
      "1809/1809 [==============================] - 1s 488us/step - loss: 0.3624 - accuracy: 0.8829 - val_loss: 0.3506 - val_accuracy: 0.8831\n",
      "Epoch 22/50\n",
      "1809/1809 [==============================] - 1s 491us/step - loss: 0.3618 - accuracy: 0.8829 - val_loss: 0.3495 - val_accuracy: 0.8831\n",
      "Epoch 23/50\n",
      "1809/1809 [==============================] - 1s 530us/step - loss: 0.3600 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8831\n",
      "Epoch 24/50\n",
      "1809/1809 [==============================] - 1s 516us/step - loss: 0.3602 - accuracy: 0.8829 - val_loss: 0.3474 - val_accuracy: 0.8831\n",
      "Epoch 25/50\n",
      "1809/1809 [==============================] - 1s 490us/step - loss: 0.3583 - accuracy: 0.8830 - val_loss: 0.3464 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3571 - accuracy: 0.8831 - val_loss: 0.3455 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "1809/1809 [==============================] - 1s 494us/step - loss: 0.3557 - accuracy: 0.8830 - val_loss: 0.3446 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "1809/1809 [==============================] - 1s 492us/step - loss: 0.3550 - accuracy: 0.8830 - val_loss: 0.3437 - val_accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "1809/1809 [==============================] - 1s 535us/step - loss: 0.3537 - accuracy: 0.8830 - val_loss: 0.3429 - val_accuracy: 0.8831\n",
      "Epoch 30/50\n",
      "1809/1809 [==============================] - 1s 494us/step - loss: 0.3527 - accuracy: 0.8831 - val_loss: 0.3421 - val_accuracy: 0.8831\n",
      "Epoch 31/50\n",
      "1809/1809 [==============================] - 1s 503us/step - loss: 0.3515 - accuracy: 0.8830 - val_loss: 0.3412 - val_accuracy: 0.8831\n",
      "Epoch 32/50\n",
      "1809/1809 [==============================] - 1s 492us/step - loss: 0.3515 - accuracy: 0.8830 - val_loss: 0.3405 - val_accuracy: 0.8831\n",
      "Epoch 33/50\n",
      "1809/1809 [==============================] - 1s 491us/step - loss: 0.3494 - accuracy: 0.8831 - val_loss: 0.3397 - val_accuracy: 0.8831\n",
      "Epoch 34/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3489 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "1809/1809 [==============================] - 1s 547us/step - loss: 0.3478 - accuracy: 0.8831 - val_loss: 0.3384 - val_accuracy: 0.8831\n",
      "Epoch 36/50\n",
      "1809/1809 [==============================] - 1s 499us/step - loss: 0.3504 - accuracy: 0.8830 - val_loss: 0.3377 - val_accuracy: 0.8831\n",
      "Epoch 37/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3482 - accuracy: 0.8830 - val_loss: 0.3371 - val_accuracy: 0.8831\n",
      "Epoch 38/50\n",
      "1809/1809 [==============================] - 1s 497us/step - loss: 0.3474 - accuracy: 0.8830 - val_loss: 0.3366 - val_accuracy: 0.8831\n",
      "Epoch 39/50\n",
      "1809/1809 [==============================] - 1s 494us/step - loss: 0.3466 - accuracy: 0.8833 - val_loss: 0.3360 - val_accuracy: 0.8831\n",
      "Epoch 40/50\n",
      "1809/1809 [==============================] - 1s 546us/step - loss: 0.3459 - accuracy: 0.8834 - val_loss: 0.3355 - val_accuracy: 0.8831\n",
      "Epoch 41/50\n",
      "1809/1809 [==============================] - 1s 490us/step - loss: 0.3451 - accuracy: 0.8831 - val_loss: 0.3349 - val_accuracy: 0.8831\n",
      "Epoch 42/50\n",
      "1809/1809 [==============================] - 1s 518us/step - loss: 0.3449 - accuracy: 0.8832 - val_loss: 0.3345 - val_accuracy: 0.8831\n",
      "Epoch 43/50\n",
      "1809/1809 [==============================] - 1s 493us/step - loss: 0.3436 - accuracy: 0.8833 - val_loss: 0.3340 - val_accuracy: 0.8831\n",
      "Epoch 44/50\n",
      "1809/1809 [==============================] - 1s 487us/step - loss: 0.3440 - accuracy: 0.8834 - val_loss: 0.3335 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "1809/1809 [==============================] - 1s 501us/step - loss: 0.3434 - accuracy: 0.8829 - val_loss: 0.3331 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "1809/1809 [==============================] - 1s 549us/step - loss: 0.3418 - accuracy: 0.8831 - val_loss: 0.3327 - val_accuracy: 0.8831\n",
      "Epoch 47/50\n",
      "1809/1809 [==============================] - 1s 500us/step - loss: 0.3420 - accuracy: 0.8834 - val_loss: 0.3322 - val_accuracy: 0.8831\n",
      "Epoch 48/50\n",
      "1809/1809 [==============================] - 1s 498us/step - loss: 0.3414 - accuracy: 0.8829 - val_loss: 0.3318 - val_accuracy: 0.8831\n",
      "Epoch 49/50\n",
      "1809/1809 [==============================] - 1s 501us/step - loss: 0.3415 - accuracy: 0.8834 - val_loss: 0.3314 - val_accuracy: 0.8831\n",
      "Epoch 50/50\n",
      "1809/1809 [==============================] - 1s 503us/step - loss: 0.3415 - accuracy: 0.8833 - val_loss: 0.3311 - val_accuracy: 0.8831\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "=== Experimentos con tamaño de muestra 90.0% ===\n",
      "Training set size: 32551\n",
      "DP-SGD with sampling rate = 0.0492% and noise_multiplier = 1.1 iterated over 101722 steps satisfies differential privacy with eps = 0.992 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "2035/2035 [==============================] - 1s 548us/step - loss: 0.4491 - accuracy: 0.8606 - val_loss: 0.3769 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3874 - accuracy: 0.8830 - val_loss: 0.3681 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2035/2035 [==============================] - 1s 505us/step - loss: 0.3818 - accuracy: 0.8830 - val_loss: 0.3653 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2035/2035 [==============================] - 1s 490us/step - loss: 0.3786 - accuracy: 0.8830 - val_loss: 0.3631 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2035/2035 [==============================] - 1s 528us/step - loss: 0.3769 - accuracy: 0.8830 - val_loss: 0.3613 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2035/2035 [==============================] - 1s 494us/step - loss: 0.3758 - accuracy: 0.8829 - val_loss: 0.3596 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3728 - accuracy: 0.8830 - val_loss: 0.3580 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2035/2035 [==============================] - 1s 497us/step - loss: 0.3730 - accuracy: 0.8830 - val_loss: 0.3565 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2035/2035 [==============================] - 1s 492us/step - loss: 0.3703 - accuracy: 0.8830 - val_loss: 0.3550 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2035/2035 [==============================] - 1s 539us/step - loss: 0.3690 - accuracy: 0.8830 - val_loss: 0.3537 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2035/2035 [==============================] - 1s 494us/step - loss: 0.3677 - accuracy: 0.8830 - val_loss: 0.3522 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2035/2035 [==============================] - 1s 492us/step - loss: 0.3661 - accuracy: 0.8830 - val_loss: 0.3509 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2035/2035 [==============================] - 1s 497us/step - loss: 0.3637 - accuracy: 0.8830 - val_loss: 0.3496 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2035/2035 [==============================] - 1s 519us/step - loss: 0.3642 - accuracy: 0.8830 - val_loss: 0.3483 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2035/2035 [==============================] - 1s 536us/step - loss: 0.3614 - accuracy: 0.8830 - val_loss: 0.3470 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3593 - accuracy: 0.8830 - val_loss: 0.3457 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2035/2035 [==============================] - 1s 504us/step - loss: 0.3576 - accuracy: 0.8829 - val_loss: 0.3445 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2035/2035 [==============================] - 1s 497us/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.3433 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2035/2035 [==============================] - 1s 540us/step - loss: 0.3560 - accuracy: 0.8830 - val_loss: 0.3422 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3551 - accuracy: 0.8831 - val_loss: 0.3411 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2035/2035 [==============================] - 1s 514us/step - loss: 0.3528 - accuracy: 0.8831 - val_loss: 0.3400 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3521 - accuracy: 0.8830 - val_loss: 0.3390 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2035/2035 [==============================] - 1s 532us/step - loss: 0.3517 - accuracy: 0.8830 - val_loss: 0.3380 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3516 - accuracy: 0.8830 - val_loss: 0.3371 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3486 - accuracy: 0.8831 - val_loss: 0.3362 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2035/2035 [==============================] - 1s 491us/step - loss: 0.3483 - accuracy: 0.8831 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2035/2035 [==============================] - 1s 526us/step - loss: 0.3482 - accuracy: 0.8830 - val_loss: 0.3345 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2035/2035 [==============================] - 1s 515us/step - loss: 0.3473 - accuracy: 0.8830 - val_loss: 0.3337 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3450 - accuracy: 0.8833 - val_loss: 0.3329 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3444 - accuracy: 0.8830 - val_loss: 0.3321 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2035/2035 [==============================] - 1s 493us/step - loss: 0.3444 - accuracy: 0.8831 - val_loss: 0.3313 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2035/2035 [==============================] - 1s 536us/step - loss: 0.3422 - accuracy: 0.8830 - val_loss: 0.3306 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2035/2035 [==============================] - 1s 494us/step - loss: 0.3418 - accuracy: 0.8832 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3407 - accuracy: 0.8832 - val_loss: 0.3292 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2035/2035 [==============================] - 1s 516us/step - loss: 0.3415 - accuracy: 0.8833 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2035/2035 [==============================] - 1s 547us/step - loss: 0.3399 - accuracy: 0.8833 - val_loss: 0.3279 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2035/2035 [==============================] - 1s 503us/step - loss: 0.3400 - accuracy: 0.8831 - val_loss: 0.3273 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2035/2035 [==============================] - 1s 492us/step - loss: 0.3390 - accuracy: 0.8833 - val_loss: 0.3267 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2035/2035 [==============================] - 1s 505us/step - loss: 0.3369 - accuracy: 0.8834 - val_loss: 0.3261 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2035/2035 [==============================] - 1s 621us/step - loss: 0.3385 - accuracy: 0.8834 - val_loss: 0.3254 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2035/2035 [==============================] - 1s 541us/step - loss: 0.3373 - accuracy: 0.8834 - val_loss: 0.3248 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2035/2035 [==============================] - 1s 498us/step - loss: 0.3371 - accuracy: 0.8832 - val_loss: 0.3242 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2035/2035 [==============================] - 1s 492us/step - loss: 0.3369 - accuracy: 0.8835 - val_loss: 0.3236 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2035/2035 [==============================] - 1s 540us/step - loss: 0.3362 - accuracy: 0.8835 - val_loss: 0.3230 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3350 - accuracy: 0.8836 - val_loss: 0.3225 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2035/2035 [==============================] - 1s 503us/step - loss: 0.3339 - accuracy: 0.8837 - val_loss: 0.3219 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3348 - accuracy: 0.8839 - val_loss: 0.3214 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2035/2035 [==============================] - 1s 510us/step - loss: 0.3334 - accuracy: 0.8838 - val_loss: 0.3209 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2035/2035 [==============================] - 1s 509us/step - loss: 0.3320 - accuracy: 0.8841 - val_loss: 0.3205 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3333 - accuracy: 0.8841 - val_loss: 0.3201 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2035/2035 [==============================] - 1s 509us/step - loss: 0.5147 - accuracy: 0.7842 - val_loss: 0.3879 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2035/2035 [==============================] - 1s 501us/step - loss: 0.3937 - accuracy: 0.8827 - val_loss: 0.3720 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2035/2035 [==============================] - 1s 540us/step - loss: 0.3874 - accuracy: 0.8830 - val_loss: 0.3688 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2035/2035 [==============================] - 1s 498us/step - loss: 0.3830 - accuracy: 0.8829 - val_loss: 0.3668 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2035/2035 [==============================] - 1s 521us/step - loss: 0.3822 - accuracy: 0.8830 - val_loss: 0.3650 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2035/2035 [==============================] - 1s 522us/step - loss: 0.3794 - accuracy: 0.8830 - val_loss: 0.3634 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2035/2035 [==============================] - 1s 518us/step - loss: 0.3770 - accuracy: 0.8830 - val_loss: 0.3619 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2035/2035 [==============================] - 1s 502us/step - loss: 0.3766 - accuracy: 0.8830 - val_loss: 0.3606 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2035/2035 [==============================] - 1s 507us/step - loss: 0.3747 - accuracy: 0.8830 - val_loss: 0.3594 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2035/2035 [==============================] - 1s 552us/step - loss: 0.3736 - accuracy: 0.8830 - val_loss: 0.3582 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2035/2035 [==============================] - 1s 502us/step - loss: 0.3704 - accuracy: 0.8830 - val_loss: 0.3572 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2035/2035 [==============================] - 1s 510us/step - loss: 0.3688 - accuracy: 0.8830 - val_loss: 0.3561 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2035/2035 [==============================] - 1s 497us/step - loss: 0.3692 - accuracy: 0.8830 - val_loss: 0.3550 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2035/2035 [==============================] - 1s 546us/step - loss: 0.3677 - accuracy: 0.8830 - val_loss: 0.3540 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2035/2035 [==============================] - 1s 506us/step - loss: 0.3669 - accuracy: 0.8830 - val_loss: 0.3529 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3660 - accuracy: 0.8830 - val_loss: 0.3520 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2035/2035 [==============================] - 1s 512us/step - loss: 0.3651 - accuracy: 0.8830 - val_loss: 0.3510 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2035/2035 [==============================] - 1s 526us/step - loss: 0.3634 - accuracy: 0.8830 - val_loss: 0.3500 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2035/2035 [==============================] - 1s 503us/step - loss: 0.3615 - accuracy: 0.8830 - val_loss: 0.3490 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3608 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2035/2035 [==============================] - 1s 520us/step - loss: 0.3604 - accuracy: 0.8830 - val_loss: 0.3472 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2035/2035 [==============================] - 1s 516us/step - loss: 0.3583 - accuracy: 0.8830 - val_loss: 0.3463 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2035/2035 [==============================] - 1s 497us/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.3454 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2035/2035 [==============================] - 1s 507us/step - loss: 0.3574 - accuracy: 0.8830 - val_loss: 0.3446 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2035/2035 [==============================] - 1s 553us/step - loss: 0.3554 - accuracy: 0.8830 - val_loss: 0.3437 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2035/2035 [==============================] - 1s 516us/step - loss: 0.3551 - accuracy: 0.8830 - val_loss: 0.3429 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3529 - accuracy: 0.8830 - val_loss: 0.3421 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2035/2035 [==============================] - 1s 514us/step - loss: 0.3532 - accuracy: 0.8830 - val_loss: 0.3413 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2035/2035 [==============================] - 1s 537us/step - loss: 0.3528 - accuracy: 0.8830 - val_loss: 0.3406 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2035/2035 [==============================] - 1s 490us/step - loss: 0.3516 - accuracy: 0.8830 - val_loss: 0.3398 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2035/2035 [==============================] - 1s 512us/step - loss: 0.3505 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2035/2035 [==============================] - 1s 606us/step - loss: 0.3497 - accuracy: 0.8830 - val_loss: 0.3384 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2035/2035 [==============================] - 1s 617us/step - loss: 0.3486 - accuracy: 0.8830 - val_loss: 0.3377 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2035/2035 [==============================] - 1s 611us/step - loss: 0.3480 - accuracy: 0.8830 - val_loss: 0.3371 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2035/2035 [==============================] - 1s 567us/step - loss: 0.3471 - accuracy: 0.8830 - val_loss: 0.3364 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2035/2035 [==============================] - 1s 528us/step - loss: 0.3476 - accuracy: 0.8830 - val_loss: 0.3357 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2035/2035 [==============================] - 1s 492us/step - loss: 0.3459 - accuracy: 0.8830 - val_loss: 0.3351 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2035/2035 [==============================] - 1s 528us/step - loss: 0.3456 - accuracy: 0.8830 - val_loss: 0.3345 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2035/2035 [==============================] - 1s 527us/step - loss: 0.3449 - accuracy: 0.8830 - val_loss: 0.3340 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2035/2035 [==============================] - 1s 505us/step - loss: 0.3439 - accuracy: 0.8830 - val_loss: 0.3334 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2035/2035 [==============================] - 1s 498us/step - loss: 0.3428 - accuracy: 0.8830 - val_loss: 0.3328 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2035/2035 [==============================] - 1s 503us/step - loss: 0.3424 - accuracy: 0.8830 - val_loss: 0.3322 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2035/2035 [==============================] - 1s 630us/step - loss: 0.3429 - accuracy: 0.8830 - val_loss: 0.3318 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2035/2035 [==============================] - 1s 541us/step - loss: 0.3417 - accuracy: 0.8830 - val_loss: 0.3312 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2035/2035 [==============================] - 1s 515us/step - loss: 0.3428 - accuracy: 0.8830 - val_loss: 0.3307 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2035/2035 [==============================] - 1s 501us/step - loss: 0.3411 - accuracy: 0.8830 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2035/2035 [==============================] - 1s 545us/step - loss: 0.3390 - accuracy: 0.8830 - val_loss: 0.3297 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2035/2035 [==============================] - 1s 497us/step - loss: 0.3388 - accuracy: 0.8830 - val_loss: 0.3291 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2035/2035 [==============================] - 1s 500us/step - loss: 0.3393 - accuracy: 0.8830 - val_loss: 0.3287 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2035/2035 [==============================] - 1s 535us/step - loss: 0.3388 - accuracy: 0.8830 - val_loss: 0.3283 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2035/2035 [==============================] - 1s 514us/step - loss: 0.4600 - accuracy: 0.8606 - val_loss: 0.4010 - val_accuracy: 0.8829\n",
      "Epoch 2/50\n",
      "2035/2035 [==============================] - 1s 487us/step - loss: 0.4171 - accuracy: 0.8820 - val_loss: 0.3938 - val_accuracy: 0.8829\n",
      "Epoch 3/50\n",
      "2035/2035 [==============================] - 1s 516us/step - loss: 0.4117 - accuracy: 0.8826 - val_loss: 0.3901 - val_accuracy: 0.8829\n",
      "Epoch 4/50\n",
      "2035/2035 [==============================] - 1s 516us/step - loss: 0.4053 - accuracy: 0.8826 - val_loss: 0.3869 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.4016 - accuracy: 0.8829 - val_loss: 0.3839 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2035/2035 [==============================] - 1s 512us/step - loss: 0.3992 - accuracy: 0.8829 - val_loss: 0.3811 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2035/2035 [==============================] - 1s 528us/step - loss: 0.3965 - accuracy: 0.8829 - val_loss: 0.3784 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2035/2035 [==============================] - 1s 500us/step - loss: 0.3934 - accuracy: 0.8830 - val_loss: 0.3758 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2035/2035 [==============================] - 1s 491us/step - loss: 0.3916 - accuracy: 0.8830 - val_loss: 0.3732 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2035/2035 [==============================] - 1s 540us/step - loss: 0.3886 - accuracy: 0.8831 - val_loss: 0.3708 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2035/2035 [==============================] - 1s 508us/step - loss: 0.3841 - accuracy: 0.8829 - val_loss: 0.3682 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2035/2035 [==============================] - 1s 501us/step - loss: 0.3837 - accuracy: 0.8830 - val_loss: 0.3656 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2035/2035 [==============================] - 1s 554us/step - loss: 0.3818 - accuracy: 0.8830 - val_loss: 0.3631 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2035/2035 [==============================] - 1s 504us/step - loss: 0.3785 - accuracy: 0.8830 - val_loss: 0.3607 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2035/2035 [==============================] - 1s 498us/step - loss: 0.3766 - accuracy: 0.8830 - val_loss: 0.3584 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2035/2035 [==============================] - 1s 534us/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3564 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2035/2035 [==============================] - 1s 544us/step - loss: 0.3690 - accuracy: 0.8830 - val_loss: 0.3545 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3685 - accuracy: 0.8830 - val_loss: 0.3528 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3671 - accuracy: 0.8830 - val_loss: 0.3511 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2035/2035 [==============================] - 1s 516us/step - loss: 0.3642 - accuracy: 0.8830 - val_loss: 0.3495 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2035/2035 [==============================] - 1s 524us/step - loss: 0.3641 - accuracy: 0.8830 - val_loss: 0.3480 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2035/2035 [==============================] - 1s 506us/step - loss: 0.3626 - accuracy: 0.8830 - val_loss: 0.3466 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3602 - accuracy: 0.8831 - val_loss: 0.3453 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2035/2035 [==============================] - 1s 536us/step - loss: 0.3577 - accuracy: 0.8830 - val_loss: 0.3440 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2035/2035 [==============================] - 1s 492us/step - loss: 0.3568 - accuracy: 0.8830 - val_loss: 0.3428 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3555 - accuracy: 0.8831 - val_loss: 0.3416 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2035/2035 [==============================] - 1s 530us/step - loss: 0.3548 - accuracy: 0.8831 - val_loss: 0.3404 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2035/2035 [==============================] - 1s 507us/step - loss: 0.3521 - accuracy: 0.8832 - val_loss: 0.3393 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3514 - accuracy: 0.8832 - val_loss: 0.3383 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2035/2035 [==============================] - 1s 541us/step - loss: 0.3518 - accuracy: 0.8829 - val_loss: 0.3372 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2035/2035 [==============================] - 1s 507us/step - loss: 0.3510 - accuracy: 0.8828 - val_loss: 0.3363 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3495 - accuracy: 0.8830 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2035/2035 [==============================] - 1s 522us/step - loss: 0.3472 - accuracy: 0.8830 - val_loss: 0.3344 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2035/2035 [==============================] - 1s 534us/step - loss: 0.3460 - accuracy: 0.8830 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2035/2035 [==============================] - 1s 506us/step - loss: 0.3466 - accuracy: 0.8833 - val_loss: 0.3327 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2035/2035 [==============================] - 1s 515us/step - loss: 0.3445 - accuracy: 0.8832 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2035/2035 [==============================] - 1s 540us/step - loss: 0.3447 - accuracy: 0.8828 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2035/2035 [==============================] - 1s 506us/step - loss: 0.3431 - accuracy: 0.8831 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2035/2035 [==============================] - 1s 497us/step - loss: 0.3418 - accuracy: 0.8832 - val_loss: 0.3297 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2035/2035 [==============================] - 1s 539us/step - loss: 0.3409 - accuracy: 0.8832 - val_loss: 0.3290 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2035/2035 [==============================] - 1s 498us/step - loss: 0.3405 - accuracy: 0.8832 - val_loss: 0.3284 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3404 - accuracy: 0.8833 - val_loss: 0.3278 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2035/2035 [==============================] - 1s 494us/step - loss: 0.3409 - accuracy: 0.8832 - val_loss: 0.3272 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2035/2035 [==============================] - 1s 531us/step - loss: 0.3386 - accuracy: 0.8833 - val_loss: 0.3267 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3382 - accuracy: 0.8837 - val_loss: 0.3261 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2035/2035 [==============================] - 1s 497us/step - loss: 0.3372 - accuracy: 0.8835 - val_loss: 0.3256 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2035/2035 [==============================] - 1s 537us/step - loss: 0.3367 - accuracy: 0.8838 - val_loss: 0.3251 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2035/2035 [==============================] - 1s 491us/step - loss: 0.3371 - accuracy: 0.8834 - val_loss: 0.3247 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2035/2035 [==============================] - 1s 485us/step - loss: 0.3354 - accuracy: 0.8834 - val_loss: 0.3243 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2035/2035 [==============================] - 1s 532us/step - loss: 0.3364 - accuracy: 0.8834 - val_loss: 0.3239 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "1938/2035 [===========================>..] - ETA: 0s - loss: 0.4803 - accuracy: 0.8625WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0011s). Check your callbacks.\n",
      "2035/2035 [==============================] - 1s 513us/step - loss: 0.4783 - accuracy: 0.8627 - val_loss: 0.4128 - val_accuracy: 0.8826\n",
      "Epoch 2/50\n",
      "2035/2035 [==============================] - 1s 493us/step - loss: 0.4179 - accuracy: 0.8826 - val_loss: 0.3981 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2035/2035 [==============================] - 1s 493us/step - loss: 0.4084 - accuracy: 0.8829 - val_loss: 0.3937 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2035/2035 [==============================] - 1s 536us/step - loss: 0.4060 - accuracy: 0.8829 - val_loss: 0.3907 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2035/2035 [==============================] - 1s 500us/step - loss: 0.4009 - accuracy: 0.8829 - val_loss: 0.3879 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2035/2035 [==============================] - 1s 537us/step - loss: 0.3982 - accuracy: 0.8830 - val_loss: 0.3852 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2035/2035 [==============================] - 1s 523us/step - loss: 0.3960 - accuracy: 0.8830 - val_loss: 0.3826 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2035/2035 [==============================] - 1s 526us/step - loss: 0.3940 - accuracy: 0.8830 - val_loss: 0.3801 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2035/2035 [==============================] - 1s 505us/step - loss: 0.3911 - accuracy: 0.8830 - val_loss: 0.3777 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2035/2035 [==============================] - 1s 545us/step - loss: 0.3875 - accuracy: 0.8830 - val_loss: 0.3755 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2035/2035 [==============================] - 1s 501us/step - loss: 0.3855 - accuracy: 0.8830 - val_loss: 0.3735 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3832 - accuracy: 0.8830 - val_loss: 0.3716 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2035/2035 [==============================] - 1s 550us/step - loss: 0.3813 - accuracy: 0.8830 - val_loss: 0.3697 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2035/2035 [==============================] - 1s 514us/step - loss: 0.3800 - accuracy: 0.8830 - val_loss: 0.3679 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2035/2035 [==============================] - 1s 498us/step - loss: 0.3782 - accuracy: 0.8830 - val_loss: 0.3661 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2035/2035 [==============================] - 1s 514us/step - loss: 0.3761 - accuracy: 0.8830 - val_loss: 0.3644 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2035/2035 [==============================] - 1s 533us/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3627 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3716 - accuracy: 0.8830 - val_loss: 0.3611 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3700 - accuracy: 0.8830 - val_loss: 0.3594 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2035/2035 [==============================] - 1s 538us/step - loss: 0.3688 - accuracy: 0.8830 - val_loss: 0.3579 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3672 - accuracy: 0.8830 - val_loss: 0.3563 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2035/2035 [==============================] - 1s 510us/step - loss: 0.3652 - accuracy: 0.8830 - val_loss: 0.3548 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2035/2035 [==============================] - 1s 540us/step - loss: 0.3635 - accuracy: 0.8830 - val_loss: 0.3534 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3622 - accuracy: 0.8830 - val_loss: 0.3521 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2035/2035 [==============================] - 1s 520us/step - loss: 0.3613 - accuracy: 0.8830 - val_loss: 0.3508 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2035/2035 [==============================] - 1s 562us/step - loss: 0.3592 - accuracy: 0.8830 - val_loss: 0.3495 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2035/2035 [==============================] - 1s 500us/step - loss: 0.3585 - accuracy: 0.8830 - val_loss: 0.3483 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2035/2035 [==============================] - 1s 546us/step - loss: 0.3574 - accuracy: 0.8830 - val_loss: 0.3471 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2035/2035 [==============================] - 1s 509us/step - loss: 0.3561 - accuracy: 0.8830 - val_loss: 0.3459 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2035/2035 [==============================] - 1s 513us/step - loss: 0.3546 - accuracy: 0.8830 - val_loss: 0.3448 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2035/2035 [==============================] - 1s 535us/step - loss: 0.3531 - accuracy: 0.8830 - val_loss: 0.3437 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2035/2035 [==============================] - 1s 522us/step - loss: 0.3519 - accuracy: 0.8830 - val_loss: 0.3426 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2035/2035 [==============================] - 1s 504us/step - loss: 0.3511 - accuracy: 0.8830 - val_loss: 0.3416 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2035/2035 [==============================] - 1s 540us/step - loss: 0.3503 - accuracy: 0.8830 - val_loss: 0.3406 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2035/2035 [==============================] - 1s 502us/step - loss: 0.3491 - accuracy: 0.8830 - val_loss: 0.3397 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2035/2035 [==============================] - 1s 504us/step - loss: 0.3483 - accuracy: 0.8830 - val_loss: 0.3388 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2035/2035 [==============================] - 1s 532us/step - loss: 0.3478 - accuracy: 0.8830 - val_loss: 0.3380 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2035/2035 [==============================] - 1s 503us/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 0.3371 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2035/2035 [==============================] - 1s 500us/step - loss: 0.3453 - accuracy: 0.8830 - val_loss: 0.3363 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2035/2035 [==============================] - 1s 543us/step - loss: 0.3445 - accuracy: 0.8830 - val_loss: 0.3355 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2035/2035 [==============================] - 1s 527us/step - loss: 0.3446 - accuracy: 0.8830 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3435 - accuracy: 0.8830 - val_loss: 0.3340 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2035/2035 [==============================] - 1s 531us/step - loss: 0.3427 - accuracy: 0.8830 - val_loss: 0.3332 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2035/2035 [==============================] - 1s 503us/step - loss: 0.3424 - accuracy: 0.8830 - val_loss: 0.3326 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2035/2035 [==============================] - 1s 503us/step - loss: 0.3411 - accuracy: 0.8830 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2035/2035 [==============================] - 1s 538us/step - loss: 0.3400 - accuracy: 0.8830 - val_loss: 0.3313 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2035/2035 [==============================] - 1s 536us/step - loss: 0.3404 - accuracy: 0.8830 - val_loss: 0.3307 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2035/2035 [==============================] - 1s 516us/step - loss: 0.3400 - accuracy: 0.8830 - val_loss: 0.3301 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2035/2035 [==============================] - 1s 535us/step - loss: 0.3382 - accuracy: 0.8830 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3379 - accuracy: 0.8830 - val_loss: 0.3290 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2035/2035 [==============================] - 1s 512us/step - loss: 0.3967 - accuracy: 0.8817 - val_loss: 0.3732 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2035/2035 [==============================] - 1s 531us/step - loss: 0.3870 - accuracy: 0.8828 - val_loss: 0.3704 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2035/2035 [==============================] - 1s 499us/step - loss: 0.3841 - accuracy: 0.8827 - val_loss: 0.3681 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2035/2035 [==============================] - 1s 495us/step - loss: 0.3828 - accuracy: 0.8830 - val_loss: 0.3661 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2035/2035 [==============================] - 1s 540us/step - loss: 0.3791 - accuracy: 0.8830 - val_loss: 0.3641 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3770 - accuracy: 0.8829 - val_loss: 0.3623 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2035/2035 [==============================] - 1s 645us/step - loss: 0.3721 - accuracy: 0.8828 - val_loss: 0.3606 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2035/2035 [==============================] - 1s 722us/step - loss: 0.3740 - accuracy: 0.8828 - val_loss: 0.3590 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2035/2035 [==============================] - 1s 639us/step - loss: 0.3720 - accuracy: 0.8829 - val_loss: 0.3575 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2035/2035 [==============================] - 1s 618us/step - loss: 0.3700 - accuracy: 0.8829 - val_loss: 0.3559 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2035/2035 [==============================] - 1s 498us/step - loss: 0.3674 - accuracy: 0.8830 - val_loss: 0.3543 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2035/2035 [==============================] - 1s 494us/step - loss: 0.3679 - accuracy: 0.8830 - val_loss: 0.3527 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2035/2035 [==============================] - 1s 539us/step - loss: 0.3647 - accuracy: 0.8830 - val_loss: 0.3510 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2035/2035 [==============================] - 1s 505us/step - loss: 0.3639 - accuracy: 0.8831 - val_loss: 0.3495 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2035/2035 [==============================] - 1s 503us/step - loss: 0.3620 - accuracy: 0.8829 - val_loss: 0.3481 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2035/2035 [==============================] - 1s 555us/step - loss: 0.3606 - accuracy: 0.8831 - val_loss: 0.3466 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2035/2035 [==============================] - 1s 500us/step - loss: 0.3590 - accuracy: 0.8829 - val_loss: 0.3453 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2035/2035 [==============================] - 1s 491us/step - loss: 0.3567 - accuracy: 0.8830 - val_loss: 0.3440 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2035/2035 [==============================] - 1s 535us/step - loss: 0.3551 - accuracy: 0.8829 - val_loss: 0.3427 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2035/2035 [==============================] - 1s 503us/step - loss: 0.3550 - accuracy: 0.8830 - val_loss: 0.3415 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2035/2035 [==============================] - 1s 516us/step - loss: 0.3533 - accuracy: 0.8830 - val_loss: 0.3403 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2035/2035 [==============================] - 1s 525us/step - loss: 0.3529 - accuracy: 0.8830 - val_loss: 0.3392 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2035/2035 [==============================] - 1s 513us/step - loss: 0.3513 - accuracy: 0.8829 - val_loss: 0.3381 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2035/2035 [==============================] - 1s 524us/step - loss: 0.3485 - accuracy: 0.8829 - val_loss: 0.3370 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2035/2035 [==============================] - 1s 524us/step - loss: 0.3477 - accuracy: 0.8829 - val_loss: 0.3359 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2035/2035 [==============================] - 1s 500us/step - loss: 0.3461 - accuracy: 0.8830 - val_loss: 0.3348 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2035/2035 [==============================] - 1s 540us/step - loss: 0.3470 - accuracy: 0.8830 - val_loss: 0.3339 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2035/2035 [==============================] - 1s 511us/step - loss: 0.3460 - accuracy: 0.8829 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2035/2035 [==============================] - 1s 500us/step - loss: 0.3437 - accuracy: 0.8831 - val_loss: 0.3321 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2035/2035 [==============================] - 1s 534us/step - loss: 0.3444 - accuracy: 0.8830 - val_loss: 0.3313 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3419 - accuracy: 0.8830 - val_loss: 0.3306 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3422 - accuracy: 0.8829 - val_loss: 0.3299 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2035/2035 [==============================] - 1s 547us/step - loss: 0.3405 - accuracy: 0.8830 - val_loss: 0.3292 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2035/2035 [==============================] - 1s 559us/step - loss: 0.3394 - accuracy: 0.8830 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2035/2035 [==============================] - 1s 590us/step - loss: 0.3402 - accuracy: 0.8829 - val_loss: 0.3279 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2035/2035 [==============================] - 1s 562us/step - loss: 0.3386 - accuracy: 0.8829 - val_loss: 0.3274 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2035/2035 [==============================] - 1s 523us/step - loss: 0.3374 - accuracy: 0.8829 - val_loss: 0.3268 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2035/2035 [==============================] - 1s 538us/step - loss: 0.3377 - accuracy: 0.8832 - val_loss: 0.3263 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2035/2035 [==============================] - 1s 496us/step - loss: 0.3376 - accuracy: 0.8830 - val_loss: 0.3258 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2035/2035 [==============================] - 1s 525us/step - loss: 0.3366 - accuracy: 0.8830 - val_loss: 0.3253 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2035/2035 [==============================] - 1s 514us/step - loss: 0.3364 - accuracy: 0.8831 - val_loss: 0.3248 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2035/2035 [==============================] - 1s 504us/step - loss: 0.3353 - accuracy: 0.8831 - val_loss: 0.3243 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2035/2035 [==============================] - 1s 542us/step - loss: 0.3349 - accuracy: 0.8831 - val_loss: 0.3239 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2035/2035 [==============================] - 1s 501us/step - loss: 0.3345 - accuracy: 0.8832 - val_loss: 0.3234 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2035/2035 [==============================] - 1s 508us/step - loss: 0.3339 - accuracy: 0.8831 - val_loss: 0.3230 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2035/2035 [==============================] - 1s 561us/step - loss: 0.3333 - accuracy: 0.8829 - val_loss: 0.3227 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2035/2035 [==============================] - 1s 504us/step - loss: 0.3329 - accuracy: 0.8833 - val_loss: 0.3223 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2035/2035 [==============================] - 1s 533us/step - loss: 0.3324 - accuracy: 0.8834 - val_loss: 0.3219 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2035/2035 [==============================] - 1s 507us/step - loss: 0.3321 - accuracy: 0.8838 - val_loss: 0.3216 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2035/2035 [==============================] - 1s 506us/step - loss: 0.3322 - accuracy: 0.8834 - val_loss: 0.3213 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "\n",
      "=== Experimentos con tamaño de muestra 100.0% ===\n",
      "Training set size: 36168\n",
      "DP-SGD with sampling rate = 0.0442% and noise_multiplier = 1.1 iterated over 113025 steps satisfies differential privacy with eps = 0.96 and delta = 1e-05.\n",
      "The optimal RDP order is 18.0.\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.4220 - accuracy: 0.8787 - val_loss: 0.3947 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.4064 - accuracy: 0.8824 - val_loss: 0.3904 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.4002 - accuracy: 0.8825 - val_loss: 0.3875 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3963 - accuracy: 0.8828 - val_loss: 0.3845 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 532us/step - loss: 0.3940 - accuracy: 0.8827 - val_loss: 0.3816 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3910 - accuracy: 0.8829 - val_loss: 0.3789 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3881 - accuracy: 0.8829 - val_loss: 0.3765 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3861 - accuracy: 0.8830 - val_loss: 0.3742 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3820 - accuracy: 0.8829 - val_loss: 0.3720 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.3804 - accuracy: 0.8830 - val_loss: 0.3699 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3778 - accuracy: 0.8830 - val_loss: 0.3679 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3754 - accuracy: 0.8830 - val_loss: 0.3659 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3751 - accuracy: 0.8829 - val_loss: 0.3640 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3722 - accuracy: 0.8830 - val_loss: 0.3622 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.3698 - accuracy: 0.8830 - val_loss: 0.3603 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3688 - accuracy: 0.8830 - val_loss: 0.3585 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 526us/step - loss: 0.3663 - accuracy: 0.8830 - val_loss: 0.3569 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3649 - accuracy: 0.8830 - val_loss: 0.3551 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.3622 - accuracy: 0.8830 - val_loss: 0.3535 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3623 - accuracy: 0.8830 - val_loss: 0.3520 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3588 - accuracy: 0.8830 - val_loss: 0.3504 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 535us/step - loss: 0.3566 - accuracy: 0.8830 - val_loss: 0.3489 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3567 - accuracy: 0.8830 - val_loss: 0.3474 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 560us/step - loss: 0.3551 - accuracy: 0.8830 - val_loss: 0.3459 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3535 - accuracy: 0.8830 - val_loss: 0.3445 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3517 - accuracy: 0.8830 - val_loss: 0.3432 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3491 - accuracy: 0.8830 - val_loss: 0.3418 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3501 - accuracy: 0.8830 - val_loss: 0.3405 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 561us/step - loss: 0.3474 - accuracy: 0.8830 - val_loss: 0.3392 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3465 - accuracy: 0.8830 - val_loss: 0.3380 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3449 - accuracy: 0.8831 - val_loss: 0.3368 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3435 - accuracy: 0.8831 - val_loss: 0.3357 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3418 - accuracy: 0.8830 - val_loss: 0.3346 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3421 - accuracy: 0.8831 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3403 - accuracy: 0.8831 - val_loss: 0.3326 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3399 - accuracy: 0.8831 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 501us/step - loss: 0.3383 - accuracy: 0.8831 - val_loss: 0.3309 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.3373 - accuracy: 0.8830 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 504us/step - loss: 0.3363 - accuracy: 0.8831 - val_loss: 0.3294 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.3365 - accuracy: 0.8831 - val_loss: 0.3287 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3347 - accuracy: 0.8832 - val_loss: 0.3281 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 551us/step - loss: 0.3338 - accuracy: 0.8832 - val_loss: 0.3275 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3336 - accuracy: 0.8831 - val_loss: 0.3269 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3338 - accuracy: 0.8836 - val_loss: 0.3263 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3328 - accuracy: 0.8834 - val_loss: 0.3258 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3328 - accuracy: 0.8833 - val_loss: 0.3254 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 578us/step - loss: 0.3328 - accuracy: 0.8832 - val_loss: 0.3249 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 562us/step - loss: 0.3312 - accuracy: 0.8834 - val_loss: 0.3245 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3313 - accuracy: 0.8837 - val_loss: 0.3241 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3311 - accuracy: 0.8835 - val_loss: 0.3237 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 571us/step - loss: 0.4660 - accuracy: 0.8602 - val_loss: 0.3963 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3980 - accuracy: 0.8830 - val_loss: 0.3854 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3916 - accuracy: 0.8830 - val_loss: 0.3825 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3876 - accuracy: 0.8830 - val_loss: 0.3803 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3873 - accuracy: 0.8830 - val_loss: 0.3781 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3847 - accuracy: 0.8830 - val_loss: 0.3761 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 553us/step - loss: 0.3831 - accuracy: 0.8830 - val_loss: 0.3742 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3809 - accuracy: 0.8830 - val_loss: 0.3723 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3789 - accuracy: 0.8830 - val_loss: 0.3706 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 526us/step - loss: 0.3778 - accuracy: 0.8830 - val_loss: 0.3689 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3762 - accuracy: 0.8830 - val_loss: 0.3670 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3728 - accuracy: 0.8830 - val_loss: 0.3652 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 540us/step - loss: 0.3719 - accuracy: 0.8830 - val_loss: 0.3635 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3709 - accuracy: 0.8830 - val_loss: 0.3618 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 517us/step - loss: 0.3688 - accuracy: 0.8830 - val_loss: 0.3601 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3666 - accuracy: 0.8830 - val_loss: 0.3586 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.3661 - accuracy: 0.8830 - val_loss: 0.3570 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.3648 - accuracy: 0.8830 - val_loss: 0.3555 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3624 - accuracy: 0.8830 - val_loss: 0.3541 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3617 - accuracy: 0.8830 - val_loss: 0.3528 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3600 - accuracy: 0.8830 - val_loss: 0.3515 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 542us/step - loss: 0.3587 - accuracy: 0.8830 - val_loss: 0.3503 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3571 - accuracy: 0.8830 - val_loss: 0.3492 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3552 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 531us/step - loss: 0.3552 - accuracy: 0.8830 - val_loss: 0.3470 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.3549 - accuracy: 0.8830 - val_loss: 0.3460 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 523us/step - loss: 0.3538 - accuracy: 0.8830 - val_loss: 0.3450 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 516us/step - loss: 0.3525 - accuracy: 0.8830 - val_loss: 0.3441 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.3513 - accuracy: 0.8830 - val_loss: 0.3433 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3502 - accuracy: 0.8830 - val_loss: 0.3424 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3494 - accuracy: 0.8830 - val_loss: 0.3414 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3486 - accuracy: 0.8830 - val_loss: 0.3407 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3479 - accuracy: 0.8830 - val_loss: 0.3399 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3463 - accuracy: 0.8830 - val_loss: 0.3391 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 540us/step - loss: 0.3469 - accuracy: 0.8830 - val_loss: 0.3384 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3456 - accuracy: 0.8830 - val_loss: 0.3377 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3453 - accuracy: 0.8830 - val_loss: 0.3371 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3440 - accuracy: 0.8830 - val_loss: 0.3364 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3434 - accuracy: 0.8830 - val_loss: 0.3358 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 532us/step - loss: 0.3429 - accuracy: 0.8831 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3423 - accuracy: 0.8830 - val_loss: 0.3346 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3412 - accuracy: 0.8830 - val_loss: 0.3341 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3415 - accuracy: 0.8830 - val_loss: 0.3335 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 534us/step - loss: 0.3407 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3401 - accuracy: 0.8830 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3399 - accuracy: 0.8830 - val_loss: 0.3321 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 508us/step - loss: 0.3402 - accuracy: 0.8830 - val_loss: 0.3316 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 553us/step - loss: 0.3384 - accuracy: 0.8830 - val_loss: 0.3312 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3378 - accuracy: 0.8830 - val_loss: 0.3308 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 540us/step - loss: 0.3379 - accuracy: 0.8830 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "   1/2261 [..............................] - ETA: 0s - loss: 0.5205 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 536us/step - loss: 0.4233 - accuracy: 0.8747 - val_loss: 0.3898 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3953 - accuracy: 0.8826 - val_loss: 0.3864 - val_accuracy: 0.8829\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3915 - accuracy: 0.8827 - val_loss: 0.3833 - val_accuracy: 0.8829\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3874 - accuracy: 0.8828 - val_loss: 0.3803 - val_accuracy: 0.8829\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3852 - accuracy: 0.8831 - val_loss: 0.3775 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3816 - accuracy: 0.8829 - val_loss: 0.3749 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 522us/step - loss: 0.3793 - accuracy: 0.8830 - val_loss: 0.3727 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.3777 - accuracy: 0.8830 - val_loss: 0.3704 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3765 - accuracy: 0.8830 - val_loss: 0.3683 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3745 - accuracy: 0.8830 - val_loss: 0.3664 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3717 - accuracy: 0.8830 - val_loss: 0.3646 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3687 - accuracy: 0.8830 - val_loss: 0.3627 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3669 - accuracy: 0.8829 - val_loss: 0.3610 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3664 - accuracy: 0.8830 - val_loss: 0.3594 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3639 - accuracy: 0.8830 - val_loss: 0.3577 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3625 - accuracy: 0.8830 - val_loss: 0.3562 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3612 - accuracy: 0.8830 - val_loss: 0.3548 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3588 - accuracy: 0.8830 - val_loss: 0.3531 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 527us/step - loss: 0.3587 - accuracy: 0.8830 - val_loss: 0.3518 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3558 - accuracy: 0.8830 - val_loss: 0.3505 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3560 - accuracy: 0.8830 - val_loss: 0.3492 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3555 - accuracy: 0.8830 - val_loss: 0.3478 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3528 - accuracy: 0.8830 - val_loss: 0.3465 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3515 - accuracy: 0.8830 - val_loss: 0.3455 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3514 - accuracy: 0.8830 - val_loss: 0.3443 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3505 - accuracy: 0.8831 - val_loss: 0.3432 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 487us/step - loss: 0.3487 - accuracy: 0.8830 - val_loss: 0.3421 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 528us/step - loss: 0.3467 - accuracy: 0.8831 - val_loss: 0.3412 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 0.3401 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3452 - accuracy: 0.8830 - val_loss: 0.3392 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3446 - accuracy: 0.8830 - val_loss: 0.3382 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3433 - accuracy: 0.8830 - val_loss: 0.3373 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3442 - accuracy: 0.8830 - val_loss: 0.3366 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3419 - accuracy: 0.8831 - val_loss: 0.3357 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3414 - accuracy: 0.8830 - val_loss: 0.3349 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3412 - accuracy: 0.8830 - val_loss: 0.3342 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3403 - accuracy: 0.8831 - val_loss: 0.3336 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3394 - accuracy: 0.8830 - val_loss: 0.3328 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3391 - accuracy: 0.8833 - val_loss: 0.3321 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3381 - accuracy: 0.8829 - val_loss: 0.3315 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3374 - accuracy: 0.8831 - val_loss: 0.3308 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3360 - accuracy: 0.8832 - val_loss: 0.3303 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3357 - accuracy: 0.8832 - val_loss: 0.3297 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3363 - accuracy: 0.8830 - val_loss: 0.3292 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3349 - accuracy: 0.8833 - val_loss: 0.3286 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 532us/step - loss: 0.3341 - accuracy: 0.8832 - val_loss: 0.3282 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3341 - accuracy: 0.8833 - val_loss: 0.3276 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 510us/step - loss: 0.3342 - accuracy: 0.8831 - val_loss: 0.3272 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3327 - accuracy: 0.8833 - val_loss: 0.3268 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3336 - accuracy: 0.8832 - val_loss: 0.3264 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.4384 - accuracy: 0.8772 - val_loss: 0.4021 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.4038 - accuracy: 0.8825 - val_loss: 0.3940 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 512us/step - loss: 0.3961 - accuracy: 0.8827 - val_loss: 0.3883 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3913 - accuracy: 0.8829 - val_loss: 0.3839 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3878 - accuracy: 0.8830 - val_loss: 0.3800 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3850 - accuracy: 0.8829 - val_loss: 0.3766 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3802 - accuracy: 0.8830 - val_loss: 0.3735 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3774 - accuracy: 0.8830 - val_loss: 0.3706 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3748 - accuracy: 0.8830 - val_loss: 0.3680 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3655 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3709 - accuracy: 0.8830 - val_loss: 0.3631 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3687 - accuracy: 0.8830 - val_loss: 0.3610 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3665 - accuracy: 0.8830 - val_loss: 0.3588 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3643 - accuracy: 0.8830 - val_loss: 0.3567 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3633 - accuracy: 0.8830 - val_loss: 0.3549 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3605 - accuracy: 0.8830 - val_loss: 0.3532 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3583 - accuracy: 0.8830 - val_loss: 0.3513 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 498us/step - loss: 0.3572 - accuracy: 0.8830 - val_loss: 0.3497 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 538us/step - loss: 0.3563 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 561us/step - loss: 0.3544 - accuracy: 0.8830 - val_loss: 0.3466 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3520 - accuracy: 0.8830 - val_loss: 0.3452 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3527 - accuracy: 0.8830 - val_loss: 0.3439 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3509 - accuracy: 0.8830 - val_loss: 0.3426 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3490 - accuracy: 0.8830 - val_loss: 0.3414 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3475 - accuracy: 0.8830 - val_loss: 0.3402 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3468 - accuracy: 0.8831 - val_loss: 0.3392 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3454 - accuracy: 0.8830 - val_loss: 0.3382 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3444 - accuracy: 0.8830 - val_loss: 0.3373 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3441 - accuracy: 0.8830 - val_loss: 0.3364 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3435 - accuracy: 0.8829 - val_loss: 0.3356 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3431 - accuracy: 0.8829 - val_loss: 0.3348 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3417 - accuracy: 0.8831 - val_loss: 0.3340 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3417 - accuracy: 0.8830 - val_loss: 0.3333 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 537us/step - loss: 0.3402 - accuracy: 0.8828 - val_loss: 0.3327 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3399 - accuracy: 0.8830 - val_loss: 0.3320 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3389 - accuracy: 0.8832 - val_loss: 0.3315 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 505us/step - loss: 0.3378 - accuracy: 0.8831 - val_loss: 0.3308 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 524us/step - loss: 0.3374 - accuracy: 0.8829 - val_loss: 0.3303 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3386 - accuracy: 0.8830 - val_loss: 0.3298 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 521us/step - loss: 0.3367 - accuracy: 0.8831 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.3368 - accuracy: 0.8832 - val_loss: 0.3289 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3347 - accuracy: 0.8832 - val_loss: 0.3284 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3353 - accuracy: 0.8831 - val_loss: 0.3281 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3354 - accuracy: 0.8832 - val_loss: 0.3277 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3352 - accuracy: 0.8831 - val_loss: 0.3273 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3336 - accuracy: 0.8830 - val_loss: 0.3270 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3329 - accuracy: 0.8832 - val_loss: 0.3266 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3336 - accuracy: 0.8833 - val_loss: 0.3263 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 480us/step - loss: 0.3326 - accuracy: 0.8833 - val_loss: 0.3259 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 486us/step - loss: 0.3326 - accuracy: 0.8833 - val_loss: 0.3257 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.4430 - accuracy: 0.8672 - val_loss: 0.3960 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 530us/step - loss: 0.4009 - accuracy: 0.8824 - val_loss: 0.3906 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3960 - accuracy: 0.8827 - val_loss: 0.3872 - val_accuracy: 0.8830\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3933 - accuracy: 0.8829 - val_loss: 0.3843 - val_accuracy: 0.8830\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3894 - accuracy: 0.8828 - val_loss: 0.3816 - val_accuracy: 0.8830\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3869 - accuracy: 0.8829 - val_loss: 0.3792 - val_accuracy: 0.8830\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3845 - accuracy: 0.8830 - val_loss: 0.3770 - val_accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.3825 - accuracy: 0.8829 - val_loss: 0.3751 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3810 - accuracy: 0.8829 - val_loss: 0.3731 - val_accuracy: 0.8830\n",
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 1s 556us/step - loss: 0.3797 - accuracy: 0.8830 - val_loss: 0.3713 - val_accuracy: 0.8830\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 1s 513us/step - loss: 0.3768 - accuracy: 0.8830 - val_loss: 0.3694 - val_accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3753 - accuracy: 0.8830 - val_loss: 0.3676 - val_accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3733 - accuracy: 0.8830 - val_loss: 0.3659 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 1s 545us/step - loss: 0.3719 - accuracy: 0.8830 - val_loss: 0.3642 - val_accuracy: 0.8830\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 491us/step - loss: 0.3700 - accuracy: 0.8830 - val_loss: 0.3626 - val_accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3674 - accuracy: 0.8830 - val_loss: 0.3610 - val_accuracy: 0.8830\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 1s 495us/step - loss: 0.3668 - accuracy: 0.8830 - val_loss: 0.3595 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3647 - accuracy: 0.8830 - val_loss: 0.3581 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3639 - accuracy: 0.8830 - val_loss: 0.3566 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 1s 525us/step - loss: 0.3631 - accuracy: 0.8830 - val_loss: 0.3552 - val_accuracy: 0.8830\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3613 - accuracy: 0.8830 - val_loss: 0.3539 - val_accuracy: 0.8830\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 1s 520us/step - loss: 0.3593 - accuracy: 0.8830 - val_loss: 0.3526 - val_accuracy: 0.8830\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 1s 519us/step - loss: 0.3577 - accuracy: 0.8830 - val_loss: 0.3512 - val_accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3567 - accuracy: 0.8830 - val_loss: 0.3500 - val_accuracy: 0.8830\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 506us/step - loss: 0.3564 - accuracy: 0.8830 - val_loss: 0.3488 - val_accuracy: 0.8830\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 1s 515us/step - loss: 0.3547 - accuracy: 0.8830 - val_loss: 0.3475 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3534 - accuracy: 0.8830 - val_loss: 0.3464 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 1s 514us/step - loss: 0.3520 - accuracy: 0.8830 - val_loss: 0.3452 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3509 - accuracy: 0.8830 - val_loss: 0.3441 - val_accuracy: 0.8830\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3507 - accuracy: 0.8830 - val_loss: 0.3430 - val_accuracy: 0.8830\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 518us/step - loss: 0.3496 - accuracy: 0.8830 - val_loss: 0.3420 - val_accuracy: 0.8830\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3480 - accuracy: 0.8830 - val_loss: 0.3411 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 1s 502us/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 0.3400 - val_accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 1s 499us/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 0.3392 - val_accuracy: 0.8830\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 494us/step - loss: 0.3451 - accuracy: 0.8830 - val_loss: 0.3384 - val_accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 1s 529us/step - loss: 0.3444 - accuracy: 0.8830 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3443 - accuracy: 0.8830 - val_loss: 0.3368 - val_accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 1s 500us/step - loss: 0.3441 - accuracy: 0.8830 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.3422 - accuracy: 0.8830 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.3423 - accuracy: 0.8830 - val_loss: 0.3347 - val_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 0.3407 - accuracy: 0.8830 - val_loss: 0.3340 - val_accuracy: 0.8830\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 1s 497us/step - loss: 0.3408 - accuracy: 0.8830 - val_loss: 0.3334 - val_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3402 - accuracy: 0.8830 - val_loss: 0.3328 - val_accuracy: 0.8830\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 493us/step - loss: 0.3403 - accuracy: 0.8830 - val_loss: 0.3322 - val_accuracy: 0.8830\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3390 - accuracy: 0.8831 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 1s 503us/step - loss: 0.3383 - accuracy: 0.8830 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 1s 552us/step - loss: 0.3382 - accuracy: 0.8830 - val_loss: 0.3306 - val_accuracy: 0.8830\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3368 - accuracy: 0.8830 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.3360 - accuracy: 0.8830 - val_loss: 0.3296 - val_accuracy: 0.8830\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 1s 488us/step - loss: 0.3370 - accuracy: 0.8831 - val_loss: 0.3292 - val_accuracy: 0.8830\n",
      "Optimal threshold: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 4. Variar tamaño de muestra\n",
    "results_sample_size = {}\n",
    "eps_sample_size = {}\n",
    "for ratio in sample_size_ratios:\n",
    "    print(f\"\\n=== Experimentos con tamaño de muestra {ratio*100}% ===\")\n",
    "    X_train_ss, X_test_ss, y_train_ss, y_test_ss, n_ss = prepare_data(X, y, ratio, default_batch_size)\n",
    "    print(f\"Training set size: {n_ss}\")\n",
    "    eps = compute_privacy_budget(n_ss, default_batch_size, default_noise_multiplier, epochs)\n",
    "    results = run_iterations(\n",
    "        X_train_ss, y_train_ss, X_test_ss, y_test_ss,\n",
    "        default_batch_size, epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_sample_size[ratio] = compute_statistics(results)\n",
    "    eps_sample_size[ratio] = eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a932e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados guardados en 'results/CDP_parameter_results_updated.csv'\n",
      "\n",
      "Resultados (Promedios):\n",
      "                noise_multiplier=1.1 (ε=0.96) (mean)  \\\n",
      "ROC AUC                                      0.7218   \n",
      "Accuracy                                     0.8845   \n",
      "Precision                                    0.4345   \n",
      "Recall                                       0.0208   \n",
      "F1 Score                                     0.0387   \n",
      "Type I Error                                 0.0010   \n",
      "Type II Error                                0.9792   \n",
      "\n",
      "               noise_multiplier=1.5 (ε=0.57) (mean)  \\\n",
      "ROC AUC                                      0.7218   \n",
      "Accuracy                                     0.8845   \n",
      "Precision                                    0.4810   \n",
      "Recall                                       0.0210   \n",
      "F1 Score                                     0.0383   \n",
      "Type I Error                                 0.0011   \n",
      "Type II Error                                0.9790   \n",
      "\n",
      "               noise_multiplier=2.0 (ε=0.39) (mean)  \\\n",
      "ROC AUC                                      0.7220   \n",
      "Accuracy                                     0.8835   \n",
      "Precision                                    0.3647   \n",
      "Recall                                       0.0055   \n",
      "F1 Score                                     0.0106   \n",
      "Type I Error                                 0.0002   \n",
      "Type II Error                                0.9945   \n",
      "\n",
      "               noise_multiplier=2.5 (ε=0.31) (mean)  \\\n",
      "ROC AUC                                      0.7244   \n",
      "Accuracy                                     0.8854   \n",
      "Precision                                    0.8056   \n",
      "Recall                                       0.0365   \n",
      "F1 Score                                     0.0661   \n",
      "Type I Error                                 0.0022   \n",
      "Type II Error                                0.9635   \n",
      "\n",
      "               noise_multiplier=4 (ε=0.18) (mean)  \\\n",
      "ROC AUC                                    0.7224   \n",
      "Accuracy                                   0.8846   \n",
      "Precision                                  0.7082   \n",
      "Recall                                     0.0233   \n",
      "F1 Score                                   0.0434   \n",
      "Type I Error                               0.0013   \n",
      "Type II Error                              0.9767   \n",
      "\n",
      "               noise_multiplier=6 (ε=0.13) (mean)  \\\n",
      "ROC AUC                                    0.7252   \n",
      "Accuracy                                   0.8847   \n",
      "Precision                                  0.6334   \n",
      "Recall                                     0.0208   \n",
      "F1 Score                                   0.0399   \n",
      "Type I Error                               0.0009   \n",
      "Type II Error                              0.9792   \n",
      "\n",
      "               batch_size=128 (ε=2.48) (mean)  batch_size=64 (ε=1.72) (mean)  \\\n",
      "ROC AUC                                0.5396                         0.6100   \n",
      "Accuracy                               0.8798                         0.8814   \n",
      "Precision                              0.2757                         0.2563   \n",
      "Recall                                 0.0049                         0.0068   \n",
      "F1 Score                               0.0095                         0.0129   \n",
      "Type I Error                           0.0042                         0.0027   \n",
      "Type II Error                          0.9951                         0.9932   \n",
      "\n",
      "               batch_size=32 (ε=1.24) (mean)  batch_size=16 (ε=0.96) (mean)  \\\n",
      "ROC AUC                               0.6755                         0.7265   \n",
      "Accuracy                              0.8831                         0.8868   \n",
      "Precision                             0.2396                         0.6815   \n",
      "Recall                                0.0030                         0.0569   \n",
      "F1 Score                              0.0060                         0.1017   \n",
      "Type I Error                          0.0003                         0.0033   \n",
      "Type II Error                         0.9970                         0.9431   \n",
      "\n",
      "               sample_size=70.0% (ε=1.08) (mean)  \\\n",
      "ROC AUC                                   0.7063   \n",
      "Accuracy                                  0.8838   \n",
      "Precision                                 0.7265   \n",
      "Recall                                    0.0068   \n",
      "F1 Score                                  0.0133   \n",
      "Type I Error                              0.0001   \n",
      "Type II Error                             0.9932   \n",
      "\n",
      "               sample_size=80.0% (ε=1.03) (mean)  \\\n",
      "ROC AUC                                   0.7048   \n",
      "Accuracy                                  0.8839   \n",
      "Precision                                 0.6267   \n",
      "Recall                                    0.0125   \n",
      "F1 Score                                  0.0244   \n",
      "Type I Error                              0.0007   \n",
      "Type II Error                             0.9875   \n",
      "\n",
      "               sample_size=90.0% (ε=0.99) (mean)  \\\n",
      "ROC AUC                                   0.7366   \n",
      "Accuracy                                  0.8841   \n",
      "Precision                                 0.7913   \n",
      "Recall                                    0.0189   \n",
      "F1 Score                                  0.0359   \n",
      "Type I Error                              0.0012   \n",
      "Type II Error                             0.9811   \n",
      "\n",
      "               sample_size=100.0% (ε=0.96) (mean)  \n",
      "ROC AUC                                    0.7240  \n",
      "Accuracy                                   0.8840  \n",
      "Precision                                  0.4207  \n",
      "Recall                                     0.0147  \n",
      "F1 Score                                   0.0284  \n",
      "Type I Error                               0.0008  \n",
      "Type II Error                              0.9853  \n"
     ]
    }
   ],
   "source": [
    "# Guardar resultados en un CSV\n",
    "results_stats = {\n",
    "    'noise_multiplier': results_noise_multiplier,\n",
    "    'batch_size': results_batch_size,\n",
    "    'sample_size': results_sample_size\n",
    "}\n",
    "data = {}\n",
    "for param, stats_dict in results_stats.items():\n",
    "    for value, stats in stats_dict.items():\n",
    "        if param == 'sample_size':\n",
    "            model = f'{param}={value*100}% (ε={eps_sample_size[value]:.2f})'\n",
    "        else:\n",
    "            model = f'{param}={value} (ε={eps_noise_multiplier.get(value, eps_batch_size.get(value, 0)):.2f})'\n",
    "        data[f'{model} (mean)'] = stats['mean']\n",
    "        data[f'{model} (min)'] = stats['min']\n",
    "        data[f'{model} (max)'] = stats['max']\n",
    "results_df = pd.DataFrame(data).round(4)\n",
    "results_df.to_csv('results/CDP_parameter_results_updated.csv')\n",
    "print(\"\\nResultados guardados en 'results/CDP_parameter_results_updated.csv'\")\n",
    "print(\"\\nResultados (Promedios):\\n\", results_df[[col for col in results_df.columns if 'mean' in col]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e2681bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar resultados, incluyendo el modelo sin DP\n",
    "def plot_parameter_results(stats_dict, eps_dict, param_name, colors, no_dp_stats):\n",
    "    metrics = list(no_dp_stats['mean'].keys())  # All metrics: ROC AUC, Accuracy, Precision, Recall, F1 Score, Type I Error, Type II Error\n",
    "    values = list(stats_dict.keys())\n",
    "    n_metrics = len(metrics)\n",
    "    n_values = len(values) + 1  # +1 for No DP\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))  # Increased width to accommodate all metrics\n",
    "    x_positions = np.arange(n_metrics) * 1.3  # Space out the metrics for clarity\n",
    "    \n",
    "    # No DP\n",
    "    means = [no_dp_stats['mean'][metric] for metric in metrics]\n",
    "    mins = [no_dp_stats['min'][metric] for metric in metrics]\n",
    "    maxs = [no_dp_stats['max'][metric] for metric in metrics]\n",
    "    plt.scatter(x_positions + (0 - (n_values-1)/2) * 0.15, means, \n",
    "                color=colors[0], label='No DP', s=100)\n",
    "    for metric_idx in range(n_metrics):\n",
    "        plt.vlines(x_positions[metric_idx] + (0 - (n_values-1)/2) * 0.15, \n",
    "                   mins[metric_idx], maxs[metric_idx], \n",
    "                   color=colors[0], linestyle='-', linewidth=1)\n",
    "    \n",
    "    # DP models\n",
    "    for value_idx, value in enumerate(values, start=1):\n",
    "        means = [stats_dict[value]['mean'][metric] for metric in metrics]\n",
    "        mins = [stats_dict[value]['min'][metric] for metric in metrics]\n",
    "        maxs = [stats_dict[value]['max'][metric] for metric in metrics]\n",
    "        if param_name == 'sample_size':\n",
    "            label = f'{param_name}={value*100}% (ε={eps_dict[value]:.2f})'\n",
    "        else:\n",
    "            label = f'{param_name}={value} (ε={eps_dict[value]:.2f})'\n",
    "        plt.scatter(x_positions + (value_idx - (n_values-1)/2) * 0.15, means, \n",
    "                    color=colors[value_idx], label=label, s=100)\n",
    "        for metric_idx in range(n_metrics):\n",
    "            plt.vlines(x_positions[metric_idx] + (value_idx - (n_values-1)/2) * 0.15, \n",
    "                       mins[metric_idx], maxs[metric_idx], \n",
    "                       color=colors[value_idx], linestyle='-', linewidth=1)\n",
    "    \n",
    "    plt.xticks(x_positions, metrics, rotation=45, ha='right', fontsize=10)\n",
    "    plt.title(f'Effect of Varying {param_name} on Model Performance', fontsize=14)\n",
    "    plt.xlabel('Metrics', fontsize=12)\n",
    "    plt.ylabel('Value', fontsize=12)\n",
    "    plt.legend(title=f'{param_name} Values', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/Effect_of_{param_name}_All_Metrics.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d2260c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKEAAAJOCAYAAABvBRRKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAD0mklEQVR4nOzdd1xT1/sH8M+FQAh7CILKUAFF64C6UFEQKlqlVan7Jw5Qse69irN1tI462tq6UOuqe7dOKtZVB1ZFqaKIC1FBWTGs+/uDJl8jYQqC8nm/XnlZzz3n3ueGJDYP5zxHEEVRBBERERERERERUSnSKusAiIiIiIiIiIjow8ckFBERERERERERlTomoYiIiIiIiIiIqNQxCUVERERERERERKWOSSgiIiIiIiIiIip1TEIREREREREREVGpYxKKiIiIiIiIiIhKHZNQRERERERERERU6piEIiIiIiIiIiKiUsckFFEFsHnzZri5ucHIyAiCIGDUqFGFOva+S0pKwsiRI1G9enXo6OhAEARERESUdVglpl+/fhAEATExMWUdCgAgNDQUgiAgNDS0rEMpkKenJwRBKLPrv0/PVUUhCAI8PT3f6hzl7T1ZkA/585+IiIjKJyahiN4jMTExEAQh34eDg4PamDNnzqB3795ISkrCkCFDMH36dLRr167AY6UlLCwMgiBgxowZpXodAJgwYQKWLl2Kjz76CJMmTcL06dNhbW2tse+UKVMgCALmzp2b7zmzs7NhZ2cHbW1t3L9/vzTCpjwoX//9+vUr61CoBCgTgYIgYP/+/Xn2a9q0qapfWFjYuwvwHXBwcFD7/NbW1kalSpXQtm1b7Nmzp1SvXRaf/0RERESSsg6AiIquZs2a+L//+z+Nx0xNTdX+fuDAAYiiiPXr16N58+aFPvYh2L9/P5ydnbFv374C+w4YMABz587F2rVrMXny5Dz7HTlyBPfv30e7du1ga2tbkuEW2dy5czFp0iRUrVq1TOOgouvcuTOaNWsGGxubsg6lzEkkEqxZswYdO3bMdez69es4f/48JBIJMjMzyyC60qetrY2vvvoKAJCeno6bN29i7969OHLkCBYsWICxY8eWynU/9M9/IiIiKp+YhCJ6Dzk6OhZ6JtGjR48AAFWqVCnSsQ/Bo0eP0KpVq0L1dXR0ROvWrfHnn38iPDwcHh4eGvutWbMGABAYGFhicRaXjY0NkxjvKRMTE5iYmJR1GOVC+/btsX//fjx9+hSWlpZqx1avXg0tLS34+vriwIEDZRRh6ZJIJLk+zw8fPox27dph2rRpGDJkCPT19Uv8uh/65z8RERGVT1yOR/SBUi57W7t2LQCgevXqqiUfyno0mo69Xsvk7t27CAoKgp2dHaRSKWxsbNCvXz/cu3dP4zXv3LmDQYMGoXr16pBKpbCysoKnp6eq7s2MGTPg5eUFAJg5c6baMpTC1FDJzMzEokWL0KBBA8hkMpiYmMDLyyvXTCdlXRZRFPHnn3+qrlFQvRdlYkmZaHpTQkIC9uzZg0qVKuGzzz5Deno6li1bBl9fX9ja2qruuUuXLrh8+XKu8a/XAdq3bx9atGgBIyMjODg44OjRoxAEAV9++aXGa0dHR6u+jL95n68/d68vd7xw4QI++eQTGBkZwcTEBJ07d87zed65cycaNWoEmUyGypUrY+DAgUhMTISDg0OuJZ6FsWfPHjRp0gT6+vqwtLTEgAED8OTJk1z9du3ahZ49e8LR0RH6+vowMTGBh4cHduzYkeu5q169OgBg3bp1aq+d15doiaKItWvXwsPDA6amptDX14eTkxMGDx6M2NjYXNfPyMjAjBkz4ODgAKlUCmdnZ/z4449Fvl+lly9fYtq0aahTpw4MDQ1hbGwMR0dH9O3bV+19o6kmlPLnmdfjzddveno6Fi1aBDc3NxgYGMDIyAgeHh7Yu3dvkWIu7PvqzbgPHz6M5s2bQ19fHxYWFujbty+eP39epGsDObMQMzIysGHDBrX2jIwM/Prrr2jbti2qVauW5/h9+/bBy8sLJiYmkMlkaNCgARYtWpTnzKlVq1bho48+gp6eHmxtbTFhwgS8evUqz/MnJydj+vTpqFu3LmQyGUxNTeHr64tTp04V+V4Lq23btqhVqxbS0tJw/fp1Vfs///yDHj16wMbGBrq6urC3t8fw4cNzPe+vL129ceMGOnfuDAsLiyJ9/v/111/o0KEDzM3Noaenh9q1a2P69OlIS0vLFa/y9fnw4UMEBATA2toaWlpaCAsLU/tMOn36NLy8vGBkZARLS0t8+eWXkMvlAHJmZrm7u8PAwACVK1fGhAkTcv0MX758ifnz56N169aoUqUKdHV1UaVKFQQEBCA6OjpXXDNmzFB9RmzatAkNGzaETCaDjY0NRo4cqbr2m06ePIlOnTqhcuXKkEqlsLW1RZcuXXL9zEVRxJo1a9CiRQsYGxtDX18fjRo1yvPfECIiIuJMKKIPloODA6ZPn47du3fjypUrGDlypGqpXsOGDfM8pvzz3Llz8PX1RWpqKjp27AgnJyfExMRg48aNOHToEM6cOYMaNWqornfq1Cl06NABycnJ8PX1RY8ePZCYmIjLly9jyZIl6NevHzw9PRETE4N169ahdevWal+q31xG+CZRFPHFF19gz549cHZ2xtChQ5GamoqtW7fis88+w6JFizB69GgAQKdOneDg4ICZM2fC3t5eVUOooGTKF198geHDh2Pbtm1YtmwZDA0N1Y5v2rQJCoUCX375JXR1dREXF4dRo0bBw8MDn376KczMzHDnzh3s3bsXhw4dwsmTJ9G4ceNc19m2bRsOHz6Mjh074ssvv0RSUhK8vb1Rs2ZNbNq0CQsWLMg182HVqlUQRREDBw7M9x6U/v77b3z77bfw8vLC4MGDcfnyZezevRtXr17FtWvXoKenp+q7Zs0aBAYGwtjYGAEBATAxMcHBgwfxySefICMjAzo6OoW6ptKOHTvwxx9/4IsvvoCPjw/Onj2LtWvXIjw8HOfPn4eZmZmq7+TJk6Grq4uWLVvCxsYGT58+xd69e/HFF19g6dKlGD58OICc1+zIkSOxZMkSNGjQAJ06dVKdQ/lzzc7ORvfu3bF9+3ZUrVoVPXv2hLGxMWJiYvDbb7+hffv2sLOzU4u1Z8+eOH/+PNq3bw9tbW389ttvGDp0KHR0dAr9XCuJoghfX1+cO3cOLVq0QLt27aClpYV79+5h79696NOnD+zt7fMcr3zdvunMmTM4fPiw2mtCoVCgXbt2CAsLQ8OGDREYGIiMjAwcOHAAn3/+OZYtW4Zhw4YVKubCvq9et3fvXhw4cAB+fn5o3rw5Tp48ifXr1yM6OrrIyZlmzZqhTp06WLt2LcaMGaNq37dvH54+fYoBAwbg2LFjGscuWrQIY8eOhbm5OXr16gUDAwPs3bsXY8eORXh4OHbu3KlWgH727NmYNm2aKtGqo6ODrVu34saNGxrPn5CQgFatWuH69eto0aIFgoODkZSUhD179sDLywvbtm1Tey2WBmX8e/fuRbdu3aClpYXPP/8ctra2iIyMxPLly/HHH3/g3Llzau8tALh9+zaaNWuGevXqoV+/fnj+/DmcnZ0L/Pzftm0bevbsCalUiu7du8PKygqHDx/GrFmz8McffyAsLEztMwQAnj9/Dnd3d5ibm6NHjx549eoVjI2NkZSUBCDn35T58+fD19cXgwcPxokTJ/DTTz8hKSkJfn5+6NevHz7//HO4u7vjwIED+O6772BoaIhp06aprnHjxg1MmzYNXl5e6Ny5MwwMDHDz5k1s2rQJBw4cwKVLlzS+x5YvX47ff/8dn3/+Odq0aYPff/8dS5cuxbNnz7Bx40a1vkuWLMHo0aMhk8nQuXNn2NnZ4eHDhzh16hS2b9+Oli1bAsh57/Tu3RubN2+Gk5MTevXqBV1dXRw5cgSBgYGIjIzEggULiv+DJyIi+lCJRPTeuHv3rghArFmzpjh9+nSNj0OHDqmN6du3rwhAvHv3bq7z5XUsPT1ddHBwEI2MjMRLly6pHQsPDxe1tbXFjh07qtpevXolVq1aVdTS0sp1fVEUxfv376v++8SJEyIAcfr06UW693Xr1okAxNatW4sKhULVfu/ePbFSpUqiRCIRo6Oj1cYo+xdFcHCwCEBctWpVrmOurq4iAPHatWuiKObc94MHD3L1u3btmmhoaCj6+Piota9du1YEIGppaYlHjhzJNW7+/PkiADE0NFStPSMjQ7SxsRGtrKzE9PR0Vbumn5/y+QUgbtmyRe08ffr0EQGImzdvVrUlJiaKhoaGooGBgfjvv/+qXbNNmzYiANHe3l7DM5Wb8v4AiL///rvasUmTJokAxGHDhqm1v/kzE0VRTE5OFuvVqyeamJiIqampqnbl679v374ar79s2TIRgOjt7S2mpaWpHUtLSxOfP3+u+nvr1q1FAGLTpk3Fly9fqtpv3rwpSiQSsVatWoW659f9888/IgCxU6dOuY69evVKTE5OVv1d+VytXbs233PevHlTNDU1Fc3NzdV+PlOmTBEBiCEhIWJ2draqPSkpSWzUqJGoq6srPnz4sMCYi/q+UsYtkUjEU6dOqdozMzNFT09PEYB45syZAq8riv/7GTx+/FhcsGCBCEA8f/686vinn34qWlhYiAqFQhw8eLAIQDxx4oTq+O3bt0WJRCJaWVmJsbGxqvZXr16JLVu2FAGI69evV7XfunVLlEgkYtWqVcUnT56o2l++fCnWqlVL4+dFr169RADiypUr1dqfPHki2traipaWlqJcLle15/d5q4m9vb0olUpztR89elQUBEE0MDAQ09LSxGfPnonGxsZi1apVxZiYGLW+mzdvzvXeUr5XAIjTpk3TeO28Yn358qVoYmIiSqVS8cqVK6r2rKwssXv37iIAcdasWWpjlNfq37+/mJmZqXbs9c+k3bt3q9rT09PF+vXri4IgiJUqVVL72SclJYlWVlaiubm52mfeixcv1N7HSsePHxe1tLTEoKAgtfbp06eLAEQTExPx5s2bqva0tDTR2dlZ1NLSUnufREREiFpaWmKVKlVyPS/Z2dlqfX/55RfVPb8eo0KhEP38/EQA4oULF3LFSkREVNExCUX0Hnn9i0Vej5EjR6qNKU4SaufOnRq/aCh16dJF1NLSUn1537p1qwhADAgIKPAeipuEUiZEzp07l+vYN998k+cXo6Imof7++28RgNi8eXO19oiICBGA2KRJk0Kdx8/PT9TV1VX7cqL8At+5c2eNY+Lj40VdXV2xZcuWau27d+8WAYjjx49Xa88vCdWqVatc51ceGzNmjKotNDRUBCCOGDEiV//Tp08XKwn1ZvJNFHMSS6ampqKxsbGYlZVV4LkWLlwoAhDDwsJUbQUloVxcXERtbW21ZE1elAmQ48eP53ksKSmpwPO8TpmE6tmzZ4F9C5OEevr0qVizZk1RV1dX/PPPP1XtWVlZopmZmVizZk21BJTS3r17RQDismXLCoyjqO8rZdya3uvKY0uXLi3wuqKonoR68uSJqKOjIwYHB4uiKIoPHz4UtbW1VZ9nmpJQs2bNEgGI8+fPz3Xuv/76SwQgtmnTRtU2c+ZMEYC4cOHCXP03bNiQ6/Pi6dOnora2tto5Xrd06VIRgLhv3z5VW3GSUNra2qpfIkyZMkX09/cXJRKJCEBctGiRKIqiuGjRolxJtde5ubmJlSpVUv1d+V6xtrZWSy6+Lq9Y169fLwIQhwwZkmvMvXv3RIlEItaoUUOtHYCoq6srPn36NNcY5eeOl5dXrmPKn2H//v1zHRswYIAIQLxz547G+N9Ur1490cHBQa1NmYTSlIhTHtu7d6+qbciQISIAcc2aNQVer379+qok4ZuUnwVjx44tVOxEREQVCZfjEb2HfH198fvvv5fa+c+ePQsAiIqK0lgAPS4uDtnZ2fj333/RqFEjnD9/HkBOHZPScvnyZejr66NJkya5jinrTEVERLz1dRo1aoQGDRrg9OnTiIqKQq1atQDkFEgGchckj4iIwLfffotTp04hLi4OGRkZasefPXuWq3i4pnsAAEtLS3Tp0gVbtmzBzZs3Ubt2bQA5S/EAICgoqND38fHHH+dqU9bVefHihartypUrAKBaYvK6pk2bQiIp+j8Tmoq6GxoaomHDhggLC8OdO3fg6OgIAIiPj8e8efNw6NAh3Lt3L1eNFmXx5IKkpKTgxo0bcHR0hJOTU6FjLeh5MjIyKvS5XFxcUL9+fWzevBkPHjxAp06d4OnpiYYNG0JLq2glGBUKBTp37ozo6GiEhoaqFdiPiopCYmIiqlSpgpkzZ+Ya+/TpUwDAzZs3C7xOcd9XhX19FZaVlRU6dOiALVu2YPHixVi3bh2ysrIwYMCAfGMHoLHWm7u7O/T09NRiV77WNb0+NbX9/fffyMrKgkKh0Pg5eOvWLQA5z7Omnf0KKysrS/Vz1NLSgpmZGdq0aYOhQ4fis88+A/C/z+Rz585prH306tUrPHv2DM+ePUOlSpVU7Q0aNICurm6R4snvebWzs0ONGjXw77//Ijk5We39Ub16dbVrv6lhw4a52pSfjfkde/TokaoeHJBT9+7777/HuXPn8OzZM7W6UXnda2Ffr4X9tywtLQ1Xr15FlSpVMH/+/FzHlf8OFOY9SEREVNEwCUVEuSQkJABArloZb0pNTQWQUywWAKpWrVpqMSUlJcHW1lbjMeWXFWXtkbcVGBiIESNGYM2aNZg/fz7S09OxadMm6Ovro0ePHqp+p0+fRps2bQDkfGlxcnKCoaEhBEFQ1VtRKBS5zl+5cuU8rz148GBs2bIFq1atwoIFC/Do0SMcOnQIrVu3hrOzc6HvwdjYOFebMqGUlZWlalM+Z1ZWVrn6a2lp5fulMi953Z+yXfl6SUhIQOPGjREbG4sWLVrAx8cHpqam0NbWRkREBPbs2aPx+dOkuK/Bwj5PhSGRSHD8+HHMmDEDO3bswNixYwHkJBeHDRuGqVOnQltbu1DnCgwMxKlTpzBlyhT07dtX7Zjy/Xn9+nW1otVvUr4/81Pc91VJPm9KAwYMwO7du7Fjxw6sXbsWH3/8MerXr59nf2Vcml5vgiCgcuXKePjwoapN+RrR9FrXdA7l8/zXX3/hr7/+yjOOwjzP+ZFKpfkWRn89lh9++CHffqmpqWrv2fw+a/KS3/MK5Lwu/v33XyQlJakloQq6Vn6vmfyOvZ7Y37ZtG7p37w5DQ0P4+vrCwcEB+vr6qoLreW2aUdjX68uXLyEIQoG7jiYmJkIURTx8+FBjIljpbV8bREREHyImoYgoF+X/sO/bt69Qv+FXFrN9/QtfacQUHx+v8VhcXJyqT0no3bs3xo8fj/Xr1+Obb77Bnj178Pz5c/Tt21ftGt988w0UCgXCw8NzzSQ6e/asaubFm14vlPwmT09P1K5dG+vXr8ecOXOwdu1aZGVlFblIdmEp70fTc5udnY1nz54VObGjaRe819tNTEwA5Mwui42NxezZs/HVV1+p9Z03bx727NlT6Gsqz1mar8HCsLCwwLJly7B06VLcvHkTx48fx7JlyzB9+nTo6Ohg8uTJBZ5j5syZ2LhxI7p27Yqvv/4613Hlz8zf3x/bt29/q3jf5fuqIJ9++ilsbGwwceJEPHz4sMBdCpVxPXnyJFcxalEU8eTJE7XYla+R+Pj4XP01vWaVY8eOHVvmBaaVsVy9ehUfffRRocfl91lT0LXyeh/n9boozrWKasaMGdDT08PFixdzzXjcsmXLW5/f1NQUoiji8ePH+X7uKe/9448/xoULF976ukRERBVJ0dYHEFGF0LRpUwA5u3IVhnIpz+HDhwvsq5wJUtTZEq6urkhLS1Mtl3hdWFgYAM1LOorD3NwcnTt3RlxcHA4ePKjabvvNpXjR0dEwNzfPlYBKS0vDpUuXin39QYMG4enTp9i9ezfWrFkDMzMz+Pv7F/t8+WnQoAEAaJzpcf78+Ty3uc9PeHh4rraUlBRERETA2NhYtauiclnR559/Xqhz5PfaMTQ0RJ06dXD37l3VMqmyJAgCXFxcMHToUBw5cgRAzu5mBdm8eTNmzJiBJk2aYN26dRq/2Lu4uMDY2BgXLlzItfyzqN7l+6og2traCAgIwMOHD6Gnp4eePXvm29/V1RXA/+J83blz5/Dq1Su12JWvdU2vLU1tjRs3hiAIhf4cLE1F/Ux+G/k9r/fv30d0dDRq1KhRpKWqJSU6OhouLi65ElCPHz/GnTt33vr8hf23zMjICC4uLrhx40axlp8SERFVZExCEVEun3/+Oezs7LBo0SKcPHky1/GMjAy1bdg/++wzVKtWDb/++iv++OOPXP1fn51ibm4OIOfLTFEolyRNnjxZ7Yv3/fv3sWjRIkgkEvTu3btI58yPMuE0d+5cHD58GM7Ozrnqxtjb2yMxMVFtSVRWVhbGjRunqstTHH379oWenh5Gjx6NO3fuoE+fPrm2Qy8pn3/+OQwNDbF69Wq1WjOZmZkICQkp1jmPHj2a63XwzTff4MWLFwgICFDVR1LORnn9tQQAmzZtwsGDB3Od18zMDIIg5PnaGTp0KLKysvDll1/mqi316tUr1ZKm0hITE4OYmJhc7coZJQX9DE+fPo3+/fvDzs4Oe/fuhUwm09hPIpFgyJAhuHfvHsaNG6cxEXXt2rU8Zzi97l2/rwoyZswY7Nq1C3/88YdqhmVeevXqBYlEgkWLFqnVDktPT8fEiRMBAP369VPrr62tjUWLFqk9N0lJSRpnnFlbW6Nbt244ffo0vvvuO4iimKvPuXPnkJaWVsS7LLr+/fvDyMgIU6dO1bgEMy0tTVU36m19/vnnMDExwdq1a9WuJYoiJk6ciMzMTLXn9V2yt7fH7du31WZpvXr1CkOGDHnrhCwABAcHQ1tbG1999VWupX2iKKq9zkaMGIG0tDQMHDhQ47K7u3fvavw8ICIiqui4HI/oPXT79m2NhXKVJk2a9FZJC6lUiu3bt6N9+/Zo3bo12rRpg3r16kEQBNy7dw/h4eGwsLBQFV2VSqX47bff0K5dO7Rv3x7t2rVDgwYNkJSUhIiICKSlpamK3dauXRtVqlTBli1bIJVKUa1aNQiCgOHDh6uWy2jSp08f7Ny5E3v27EH9+vXRsWNHpKamYuvWrUhISMDChQtVM2xKgre3NxwcHFRf7DQVSB4+fDgOHz6Mli1bolu3btDT00NYWBgePnwIT09PjTMJCsPc3Bxdu3bFhg0bAKDUluIBOctPFi1ahEGDBuHjjz9Gjx49YGJigoMHD0IqlaJKlSpFLqrdsWNH+Pn54YsvvlA9hydOnEDNmjUxa9YsVb8+ffpg/vz5GD58OE6cOAF7e3tcuXIFx44dQ5cuXbBz50618xoaGqJx48Y4efIk+vTpAycnJ2hpaaFPnz6wt7fHkCFD8Oeff+K3336Dk5MTPvvsMxgbGyM2NhZ//PEHVq9ejU6dOpXE06ZRREQEunTpgiZNmqBOnTqwtrbGw4cPsXv3bmhpaWH06NH5jg8KCoJCoUCTJk3w008/5Tru4OCg+vI/c+ZMXLp0CUuXLsWBAwfQqlUrWFlZ4eHDh7h69SquXLmCM2fOaKx/9Lp3/b4qiJWVVaF/RjVr1sT8+fMxduxY1K9fH926dYOBgQH27duHqKgofP755/i///s/VX9HR0dMmzYN06dPV/WXSCTYsWMH6tevj6ioqFzX+PHHHxEVFYUJEyZgw4YNcHd3h6mpKe7fv48LFy7g1q1bePz4MfT19UvqKdDI0tISmzdvRteuXdGgQQO0a9cOtWvXhkKhQExMDP788080b968RDasMDY2xsqVK9GzZ080bdoU3bt3h6WlJY4ePYqLFy+iSZMmGD9+fAncVdENHz4cw4cPh6urK7744gtkZmbiyJEjEEURDRo0yHMJdGHVq1cP33//PUaMGIG6deuiU6dOsLe3R1xcHE6ePIkOHTrg+++/B5BTv+/s2bNYt24d/vrrL/j4+KBKlSp48uQJbt68iXPnzmHTpk1wcHB4+xsnIiL6kJThznxEVETKbbcLeiQmJqrG5LdleEHbiT948EAcOXKk6OTkJEqlUtHY2Fh0cXERg4KCxGPHjuXqf/v2bTEwMFCsVq2aqKOjI1pZWYmenp65thU/e/as2Lp1a9HIyEgVc2G2NM/IyBAXLFgg1qtXT5RKpaKRkZHYunVrcc+ePRr7440t14tKuaW7tra2+OjRI419tm/fLrq5uYn6+vpipUqVxG7duonR0dEan1vlFvZr164t8NpHjx4VAYjNmjXLs4+mayi3Q58+fXqu/srXT9++fXMd27Ztm+jq6ipKpVLRyspKDAoKEp8/fy4aGhqKDRo0KDBeUVS/v927d4uNGzcWZTKZaGFhIfbr1098/PhxrjERERFi27ZtRTMzM9XP8+jRo3k+V1FRUeKnn34qmpqaioIgiADEEydOqI5nZ2eLq1atEps1ayYaGBiI+vr6opOTkxgcHCzGxsaq+rVu3VrM65/Agt4Xebl//744adIksVmzZqKVlZWoq6sr2tnZiV26dBHPnDmT53OlZG9vn+/7+s3XcmZmpvjzzz+LLVq0EI2NjUWpVCra2dmJ7dq1E3/66ScxJSWlUHEX5X2V32s4v9eeJsqfgabXxZsGDx6c62ettGfPHtXniVQqFevVqycuXLhQzMjI0HiulStXinXq1BF1dXXFatWqiePGjRPT0tLy/LxIS0sTv/32W/Hjjz8WDQwMRJlMJlavXl3s1KmTuH79erXrFPW1Y29vL0ql0kL1FUVRvHnzphgYGCja29uLurq6opmZmVivXj1xxIgR4vnz51X98nuvFzbWkydPiu3btxdNTU1FXV1d0dnZWQwJCdH4usrvsza/10V+r6fp06drfH+vWLFCrFu3rqinpydaW1uLgYGBYnx8vMb3tKZzFObaJ06cEDt27Ciam5urXif+/v7iX3/9lavv1q1bRR8fH9HMzEzU0dERq1atKnp6eooLFy4Unz59qvE5ISIiqsgEUdQwv5yIiMrUggULMH78eKxevTrfbepL0+3bt+Hk5IRu3bph69atZRIDERERERF9OFgTioionHn16hWWL18OMzMz9OjRo9Svl5iYCIVCodYml8tVy8dKcwkbERERERFVHKwJRURUTpw6dQp//vkn/vjjD9y7dw9z584t9VozAPDnn38iMDAQbdu2hZ2dHZ49e4bjx48jJiYGbdq0Qffu3Us9BiIiIiIi+vAxCUVEVE4cPXoUM2fORKVKlTB69GiMGzfunVy3bt26+OSTT/DXX39h9+7dAHKKOM+ePRvjxo0rcmHyD0lERITqOcnP60XDiYiIiIhIM9aEIiIiykNoaCj69+9fYL/WrVsXezdEIiIiIqKKgkkoIiIiIiIiIiIqdRV3jQUREREREREREb0zFb4mVHZ2Nh49egQjIyMIglDW4RAREREREb0ToigiOTkZVapUqdA1IIno3anwSahHjx7B1ta2rMMgIiIiIiIqE/fv30e1atXKOgwiqgAqfBLKyMgIQM4Hr7GxcRlHQ0RERERE9G4kJSXB1tZW9Z2IiKi0VfgklHIJnrGxMZNQRERERERU4bAsCRG9K1z4S0REREREREREpY5JKCIiIiIiIiIiKnVMQhERERERERERUamr8DWhiIiIiIiI6P2XlZWFjIyMsg6DqELR0dGBtrZ2ofszCUVERERERETvLVEUERcXhxcvXpR1KEQVkqmpKaytrQu1yQGTUERERERERPTeUiagrKysoK+vz93+iN4RURSRlpaG+Ph4AICNjU2BY5iEIiIiIiIiovdSVlaWKgFlYWFR1uEQVTgymQwAEB8fDysrqwKX5rEwOREREREREb2XlDWg9PX1yzgSoopL+f4rTE02JqGIiIiIiIjovcYleERlpyjvPyahiIiIiIiIiIio1DEJRURERERERFSOeHp6YtSoUe/8ujExMRAEARERESV+7rCwMAiCUK53MSzN+6ccTEIREREREREVgiiKSEhIwIMHD5CQkABRFMs6JKI8lbekT/PmzfH48WOYmJiU+LmfPHkCHR0dbNmyRePxwMBAuLm5lfh1qeiYhCIiIiIioveTKAIZCcCrBzl/FjIpJIoiUl+9QmJyClJfvSowmZSUlITQdaHwaeuDpu5N4eXthabuTeHT1geh60KRlJRUEndD9EHT1dWFtbV1qdTvqly5Mjp06IA1a9bkOpaamorffvsNgYGBJX5dKrpylYQ6efIk/Pz8UKVKFQiCgN27dxc4JiwsDG5ubpBKpXB0dERoaGipx0lERERERGUoMwl4tBa45An8/TFwyeO/Pz1z2jM1J4XkinScvhaJxdt2Ye7GrVj42w7M3bgVi7ftwulrkZAr0nONCQ8Ph0drD8yZOwf3799XO3b//n3MmTsHHq09EB4eXgo3ShVZZmYmhg0bBhMTE1SqVAkhISFqCdMNGzagUaNGMDIygrW1NXr16oX4+HgAOcvKvLy8AABmZmYQBAH9+vUDAGRnZ+Pbb7+Fo6MjpFIp7Ozs8M0336hd+86dO/Dy8oK+vj4aNGiAM2fOFCrme/fuwc/PD2ZmZjAwMEDdunVx8OBBALlnZnl6ekIQhFyPmJgYAMCLFy8QFBQES0tLGBsbo02bNrhy5Uqe1w4MDMSxY8cQGxur1r5t2zZkZmaid+/e+P3339GyZUuYmprCwsICHTt2RHR0dJ7nDA0NhampqVrb7t27cyXS9uzZAzc3N+jp6aFGjRqYOXMmMjMzAeQkvWfMmAE7OztIpVJUqVIFI0aMKMzT+UEqV0mo1NRUNGjQAD/88EOh+t+9excdOnSAl5cXIiIiMGrUKAQFBeGPP/4o5UiJiIiIiKhMJP4JXHAHYmYDCvWkEBT3c9ovuOf0e82tBw/x3ZZtOHjubyQkJ6sdS0hOxsFzf+O7Ldtw68FDVXt4eDiCBgVBLpdDFMVcM6aUbXK5HEGDgpiIohK1bt06SCQSnD9/HkuWLMGiRYuwatUq1fGMjAzMnj0bV65cwe7duxETE6NKNNna2mLHjh0AgKioKDx+/BhLliwBAEyePBnz5s1DSEgIIiMjsWnTJlSuXFnt2lOnTsW4ceMQEREBZ2dn9OzZU5VUyc/QoUOhUChw8uRJXL16FfPnz4ehoaHGvjt37sTjx49Vjy5duqBWrVqqWLp27Yr4+HgcOnQIFy9ehJubG7y9vZGQkKDxfJ9++ikqV66ca2LK2rVr0aVLF5iamiI1NRVjxozBhQsXcOzYMWhpaaFz587Izs4u8N7yEh4ejoCAAIwcORKRkZH4+eefERoaqkrs7dixA4sXL8bPP/+MW7duYffu3ahXr16xr/e+E8RyupBZEATs2rULnTp1yrPPxIkTceDAAVy7dk3V1qNHD7x48QK///57oa6TlJQEExMTvHz5EsbGxm8bNhERERERlZbEP4EbAwCI/z3yIuQ8XNYAZq1x68FDrD98DBDFAkdBEBDQ1huVjY3g0dpDlYAqiCAIkMlkCP8z/L35XvEhfBd69eoV7t69i+rVq0NPT6+swykxnp6eiI+Px/Xr11WzbiZNmoS9e/ciMjJS45gLFy6gcePGSE5OhqGhIcLCwuDl5YXExETVbJ7k5GRYWlpi+fLlCAoKynWOmJgYVK9eHatWrVItX4uMjETdunVx48YN1K5dO9+469evD39/f0yfPj3XMU3xKC1evBizZs3CuXPn4OzsjFOnTqFDhw6Ij4+HVCpV9XN0dMSECRMwaNAgjdefPHkytm7diujoaAiCgOjoaDg5OeHIkSPw9vbO1f/Zs2ewtLTE1atX8dFHH6nu//Lly2jYsCFCQ0MxatQotbpau3fvRufOnVWfCz4+PvD29sbkyZNVfX799VdMmDABjx49wqJFi/Dzzz/j2rVr0NHRyff5e18V5X1YrmZCFdWZM2fg4+Oj1ubr61voqYJERERERPSeyEwCor5EwQko/K9P1JeQpz3D5mNhBSaglKMgith8LAxbt20rdAIqZ1jOjKhdu3cVqj9RQZo1a6a27Mvd3R23bt1CVlYWAODixYvw8/ODnZ0djIyM0Lp1awDItRztdTdu3IBCodCYkHld/fr1Vf9tY2MDAKqlfvkZMWIEvv76a7Ro0QLTp0/HP//8U+CYQ4cOYdKkSdi6dSucnZ0BAFeuXEFKSgosLCxgaGioety9ezff5XMDBgzA3bt3ceLECQA5s6AcHBzQpk0bAMCtW7fQs2dP1KhRA8bGxnBwcACQ/3NWkCtXrmDWrFlqcQ4cOBCPHz9GWloaunbtCrlcjho1amDgwIHYtWtXoWaVfaje6yRUXFxcrmmDlStXRlJSEuRyucYxCoUCSUlJag8iIiIiIirn4ncA2XIUnIBSEoFsOS5H7EN6ZmZRRkGRkYHQ9aHFCnP9hvXcNY9KXWpqKnx9fWFsbIyNGzfi77//xq5dOQnQ9PTctc2UZDJZoc7/+owdZSKsMEvWgoKCcOfOHfTp0wdXr15Fo0aNsGzZsjz7R0ZGokePHpg3bx7atm2rak9JSYGNjQ0iIiLUHlFRURg/fnye53NycoKHhwfWrl2L7OxsrF+/Hv3791fdg5+fHxISErBy5UqcO3cO586dA5D3c6alpZXr/ZyRkaH295SUFMycOVMtzqtXr+LWrVvQ09ODra0toqKi8OOPP0Imk+HLL79Eq1atcp2nonivk1DFMXfuXJiYmKgetra2ZR0SERERERHlRxSBx6HFGnY2OqXI49LlcsTHxRU5mSSKImJjY9WW7hAVlzJBonT27Fk4OTlBW1sbN2/exPPnzzFv3jx4eHigdu3auWYq6erqAoBq5hSQk6SRyWQ4duxYqcVta2uL4OBg7Ny5E2PHjsXKlSs19nv27Bn8/Pzg7++P0aNHqx1zc3NDXFwcJBIJHB0d1R6VKlXK9/qBgYHYsWMHduzYgYcPH6rqZD1//hxRUVH46quv4O3tDRcXFyQmJuZ7LktLSyQnJyM1NVXVFhERkSvWqKioXHE6OjpCSysn5SKTyeDn54elS5ciLCwMZ86cwdWrV/O99ofqvU5CWVtb48mTJ2ptT548gbGxcZ4Z3smTJ+Ply5eqx5s7XBARERERUTmTmQgoYlH4WVA50rJkSEgveq2jzIy8Z5IUxutfWImKKzY2FmPGjEFUVBQ2b96MZcuWYeTIkQAAOzs76OrqYtmyZbhz5w727t2L2bNnq423t7eHIAjYv38/nj59ipSUFOjp6WHixImYMGEC1q9fj+joaJw9exarV68ukZhHjRqFP/74A3fv3sWlS5dw4sQJuLi4aOzr7+8PfX19zJgxA3FxcapHVlYWfHx84O7ujk6dOuHw4cOIiYnB6dOnMXXqVFy4cCHfGLp27QodHR0MHjwYbdu2VU08MTMzg4WFBX755Rfcvn0bx48fx5gxY/I9V9OmTaGvr48pU6YgOjoamzZtylX4fNq0aVi/fj1mzpyJ69ev48aNG9iyZQu++uorADk77K1evRrXrl3DnTt38Ouvv0Imk8He3r6Qz+qH5b1OQrm7u+fK4B45cgTu7u55jpFKpTA2NlZ7EBERERFROZaVVqxh6dm6xRon0SneOCUDAwO1v2ckJ+DRsc3ISNa8qxeRJgEBAZDL5WjSpAmGDh2KkSNHqgpyW1paIjQ0FNu2bUOdOnUwb948LFiwQG181apVMXPmTEyaNAmVK1fGsGHDAAAhISEYO3Yspk2bBhcXF3Tv3r1Q9Z4KIysrC0OHDoWLiwvatWsHZ2dn/Pjjjxr7njx5EteuXYO9vT1sbGxUj/v370MQBBw8eBCtWrVC//794ezsjB49euDevXu5SvK8SV9fHz169EBiYiIGDBigatfS0sKWLVtw8eJFfPTRRxg9ejS+++67fM9lbm6OX3/9FQcPHkS9evWwefNmzJgxQ62Pr68v9u/fj8OHD6Nx48Zo1qwZFi9erEoymZqaYuXKlWjRogXq16+Po0ePYt++fbCwsCjEM/rhKVe746WkpOD27dsAAFdXVyxatAheXl4wNzeHnZ0dJk+ejIcPH2L9+vUAgLt37+Kjjz7C0KFDMWDAABw/fhwjRozAgQMH4OvrW6hrfgg7QhARERERfdAyEoC/Py7ysNRMfcy9NaHI40RRxIGVPyLt5YsiLckTBAG2trY4evioWkHptEfRuPHjWLh8uRD6VWoWOZ7S8iF8F/pQd8cjep+8t7vjXbhwAa6urnB1dQUAjBkzBq6urpg2bRoA4PHjx2pV66tXr44DBw7gyJEjaNCgARYuXIhVq1YVOgFFRERERETvAYkZILUDIBTY9XX62nKY6xZ9IyJBENCwecsijwOAgD4BagkoIiL6H0lZB/A6T0/PfH/T8ObaS+WYy5cvl2JURERERERUpgQBsOkHxMwusOubw5rVNMTBG0W/5P/17InLYccgl8sLNRtKS0sLenp66Nypc9EvRvSeaN++PcLDwzUemzJlCqZMmfKOI6L3TblKQhEREREREWlk5Q/ELgCy5ShcgXItQEsPrvX9cPTWH8jIzCzUKAGAjkSCFg0aYPnS5QgaFAQA+SailDOfli9b/t4uayMqjFWrVkEul2s8Zm5u/o6jofdRuVqOR0REREREpJHEGKj1I3LSRAUtd/vveO2fINOvhJ7enoAgFG6UIKCntydkUl14eHhg1S+rIJPJIAhCrmV2yjaZTIZVK1fBo6VHce6M6L1RtWpVODo6anwwCUWFwSQUERERERG9H8xaAy5rAC0ZNCej/mvTkgF11gKmrQAATtWqIqCtN3Qk+S8E0ZFIENDWG07VqqraPDw8EP5nOKZOmara6l3J1tYWU6dMxamTp5iAIiIqBC7HIyIiIiKi94dZa6DRGeDpDuBRKKD438ZFkNoCVfoBlv45M6de41StKsb36IqI29E4c/0GEpKTVcfMjYzgXtcFrk41oaerm+uSxsbG6BvQFwF9AvDixQukpqbCwMAApqamLEJORFQETEIREREREdH7RWIM2PQHrPsBmS+ArFRA2wCQmOZUI8+DTKoL97ouaFanNuQKBRQZmZDqSCCTSguVTBIEAWZmZjAzMyuxWyEiqkiYhCIiIiIioveTIAA6ZjmPIg0ToK+nB329UoqLiIg0YhKKiIiIiIiIKjRRFJGQrECKPAOGMh2YGxVudhwRFQ2TUERERERERFQhvUhRYNOJ2/h5/w3cjftfnbDq1kYY3NEFvbwcYWooLcMIiT4s3B2PiIiIiIiIKpyjlx7CJfA3TF59HjFPktWOxTxJxuTV5+ES+BuOXnpY4tfu168fBEHAvHnz1Np379791jOwQkNDIQgCBEGAtrY2zMzM0LRpU8yaNQsvX77UGIcgCNDV1YWjoyNmzZqFzMzMt4qBKC9MQhEREREREZUSURSRKU8FAGTKUyGKYhlHREBOAqrr7COQKzIhisCbPxZlm1yRia6zj5RKIkpPTw/z589HYmJiiZ/b2NgYjx8/xoMHD3D69GkMGjQI69evR8OGDfHo0SO1vu3atcPjx49x69YtjB07FjNmzMB3331X4jERAUxCERERERERlbhMeQqenN6H64uH4NbaaQCAW2un4friIXhyeh8y5SllHGHF9SJFgT7zj0MURWQXkBPMFnMSiX3mH8eLFEWJxuHj4wNra2vMnTs33347duxA3bp1IZVK4eDggIULFxZ4bkEQYG1tDRsbG7i4uCAwMBCnT59GSkoKJkyYoNZXKpXC2toa9vb2GDJkCHx8fLB37963ujeivDAJRUREREREVIJe3rqMq98F4cHBNVAkPFE7pkh4ggcH1+Dqd0F4eetyGUVYsW06cRtpiswCE1BK2SKQpsjE5hPRJRqHtrY25syZg2XLluHBgwca+1y8eBHdunVDjx49cPXqVcyYMQMhISEIDQ0t8vWsrKzQu3dv7N27F1lZWXn2k8lkSE9PL/L5iQqDSSgiIiIiIqIS8vLWZdxePxvZGQoA4n+P1+W0ZWcocHv9bCai3jFRFPHz/hu5fyyFsGJ/ZIkvp+zcuTMaNmyI6dOnazy+aNEieHt7IyQkBM7OzujXrx+GDRtW7OVytWvXRnJyMp4/f57rmCiKOHr0KP744w+0adOmWOcnKgiTUERERERERCUgU56CO5vnA9BQZOhNYk4y6s7m+Vya9w4lJCtwNy65yDkoUQTuxiUjIblkl+QBwPz587Fu3TrcuHEj17EbN26gRYsWam0tWrTArVu38p3NlBdlEu314uf79++HoaEh9PT00L59e3Tv3h0zZswo8rmJCoNJKCIiIiIiohLw/PIJZKcrCk5AKYkistMVSIgIK9W46H9S5BllOl6TVq1awdfXF5MnTy7xc7/pxo0bMDY2hoWFharNy8sLERERuHXrFuRyOdatWwcDA4NSj4UqJklZB0BERERERPS+E0URT88eQHHWecWf2Q/LZh3UZqdQ6TCU6ZTp+LzMmzcPDRs2RK1atdTaXVxc8Ndff6m1/fXXX3B2doa2tnaRrhEfH49NmzahU6dO0NL633wUAwMDODo6Fj94oiJgEoqIiIiIiOgtZaUlQ5EQV4yRIhQJcciSJ0Oib1zicZE6cyMpqlsbIeZJcqEnrAGAIAAOlY1gbiQtlbjq1auH3r17Y+nSpWrtY8eORePGjTF79mx0794dZ86cwfLly/Hjjz/mez5RFBEXFwdRFPHixQucOXMGc+bMgYmJCebNm1cq90BUGFyOR0RERERE9Jay0uVvN17xduOpcARBwOCOLsUaG9yxTqnOVps1axays7PV2tzc3PDbb79hy5Yt+OijjzBt2jTMmjUL/fr1y/dcSUlJsLGxQdWqVeHu7o6ff/4Zffv2xeXLl2FjY1Nq90BUEEEs6fL+75mkpCSYmJjg5cuXMDbmbx6IiIiIiKjoMlOTcGVuQLHHN5iy/p3PhPoQvgu9evUKd+/eRfXq1aGnp1eoMS9SFHAJ/A1yRSayC/FtWEsAZFIJbqzuBlPD0pkJRfQ+K8r7kDOhiIiIiIiI3pK2vhGk5tYAijpTRoDU3BraMqPSCIs0MDWUYsPENhAEAVoF/Li0hJzZU79OasMEFFEJYBKKiIiIiIjoLQmCAMtmHYo11sq9I4uSv2M+blWxLeQTyKQSCEJOzafXKdtkUgm2T/sE3q5VyyZQog8Mk1BEREREREQlwMLVC1q60twZjbwIArR0pTBv6FmqcZFmPm5VcWN1N8wLbAqHyuoz0RwqG2FeYFPcXNOdCSiiEsTd8cohURSRkKxAijwDhjIdmBtJ+ZsRIiIiIqJyTiIzRI2eE3F7/eycVXn5ld8VBAACavacCInM8F2FSG8wNZRiiF8dBHd04XcwoneASahy5EWKAptO3MbP+2/gblyyqr26tREGd3RBLy9HrkMmIiIiIirHTJxc4RgQgjub5yM7XfFf6+vJqJzEhpaOFDV7ToSxk+s7j5FyEwQBFsZ6sDAuXHFzIioe7o5XTnaEOHrpIfrMP440RSYA9V+aKBPw+lIJNkxsAx83TgclIiIiIirPMuUpSIgIQ/yZ/VAkxKnapebWsHLvCAtXL2jrGZRhhOXnu9DbKM7ueERUsoryPuRMqHLg6KWH6Dr7CERR1DhjV9kmV2Si6+wj2BbyCRNRRERERETlmERmCCv3jrBs1gHJd6/i1pppcBowC0bV63GZFxFVWCxMXsZepCjQZ/5xiKKI7ALmpGWLOfWi+sw/jhcpivw7ExERERFRmRMEAZL/ZjxJ9AyYgCKiCo1JqDK26cRtpCkyC0xAKWWLQJoiE5tPRJduYFTiRFHE86RXuPckGc+TXqGCr4QlIiIiIio/RBHISABePcj5k/+vTlQqmIQqQ6Io4uf9N9TrFBbSiv2RTGK8J16kKPDjvutoGLwD1ftsRr1B21G9z2Y0DN6BH/dd56w2IiIiIqKykpkEPFoLXPIE/v4YuOTx35+eOe2ZSaVyWU9PT4waNapUzp2fmJgYCIKAiIiIEj93WFgYBEHAixcvSvzc74Njx47BxcUFWVlZZR1KiZo0aRKGDx9eYudjEqoMJSQrcDcuucg5KFEE7sYlIyGZyYvy7uilh3AJ/A2TV59HzJNktWMxT5IxefV5uAT+hqOXHpZRhEREREREFVTin8AFdyBmNqC4r35McT+n/YJ7Tr9yqLwlfZo3b47Hjx/DxMSkTK6/c+dOtG3bFhYWFhoTbQkJCRg+fDhq1aoFmUwGOzs7jBgxAi9fvlTr9/fff8Pb2xumpqYwMzODr68vrly5UuD1J0yYgK+++gra2toleVsAcn7Wn3/+OWxsbGBgYICGDRti48aNhR7//PlzVKtWTePrZePGjWjQoAH09fVhY2ODAQMG4Pnz56rj48aNw7p163Dnzp0SuRcmocpQijyjTMdT6VIWnJcrMiGKuWf0KtuUBeeZiCIiIiIiekcS/wRuDACy5chZmvLm1ID/2rLlOf3KaSKqPNHV1YW1tXWZ1T1LTU1Fy5YtMX/+fI3HHz16hEePHmHBggW4du0aQkND8fvvvyMwMFDVJyUlBe3atYOdnR3OnTuHU6dOwcjICL6+vsjIyPv796lTpxAdHQ1/f/8Svy8AOH36NOrXr48dO3bgn3/+Qf/+/REQEID9+/cXanxgYCDq16+fq/2vv/5CQEAAAgMDcf36dWzbtg3nz5/HwIEDVX0qVaoEX19f/PTTTyVyL0xClSFDmU6ZjqfSU5EKzouiiMzUJCgSnyAzNYnLRImIiIiofMtMAqK+hObk05v+6xP1ZYkvzcvMzMSwYcNgYmKCSpUqISQkRO3/pTds2IBGjRrByMgI1tbW6NWrF+Lj4wHkLKvz8vICAJiZmUEQBPTr1w8AkJ2djW+//RaOjo6QSqWws7PDN998o3btO3fuwMvLC/r6+mjQoAHOnDlTqJjv3bsHPz8/mJmZwcDAAHXr1sXBgwcB5J6Z5enpCUEQcj1iYmIAAC9evEBQUBAsLS1hbGyMNm3aFGrGUV769OmDadOmwcfHR+Pxjz76CDt27ICfnx9q1qyJNm3a4JtvvsG+ffuQmZkJALh58yYSEhIwa9Ys1KpVC3Xr1sX06dPx5MkT3Lt3L89rb9myBZ988gn09PRUbfHx8ejatSssLCygp6eHGjVqYOXKlcW6tylTpmD27Nlo3rw5atasiZEjR6Jdu3bYuXNngWN/+uknvHjxAuPGjct17MyZM3BwcMCIESNQvXp1tGzZEoMHD8b58+fV+vn5+WHLli3Fiv1NTEKVIXMjKapbG6GoiWJBAKpbG8HcSFo6gdFbqwgF5zPlKXhyeh+uLx6CK3MDcG3hYFyZG4Dri4fgyel9yJSnlHWIRERERES5xe94bQZUYfw3I+rpjhINY926dZBIJDh//jyWLFmCRYsWYdWqVarjGRkZmD17Nq5cuYLdu3cjJiZGlWiytbXFjh058URFReHx48dYsmQJAGDy5MmYN28eQkJCEBkZiU2bNqFy5cpq1546dSrGjRuHiIgIODs7o2fPnqpETH6GDh0KhUKBkydP4urVq5g/fz4MDQ019t25cyceP36senTp0gW1atVSxdK1a1fEx8fj0KFDuHjxItzc3ODt7Y2EhAQAQHh4OAwNDfN9FGVJmiYvX76EsbExJBIJAKBWrVqwsLDA6tWrkZ6eDrlcjtWrV8PFxQUODg55nic8PByNGjVSa5s0aRKio6Nx8OBB/Pvvv9i8eTMaNmyoOt6+fft8761u3boFxm5ubp5vn8jISMyaNQvr16+Hllbu9I+7uzvu37+PgwcPQhRFPHnyBNu3b8enn36q1q9JkyZ48OCBKoH4NiRvfQYqNkEQMLijCyavPl9w5zcEd6zD7V3LqbctOB/c0aVMfraiKCIxMRFpaWnQ19dX/UZFk5e3LuPO5vnITs89c0uR8AQPDq7Bo6MbUaPnRJg4uZZ26EREREREhSOKwOPQ4o19FApY90ORZxHkwdbWFosXL4YgCKhVqxauXr2KxYsXq5ZCDRgwQNW3Ro0aWLp0KRo3boyUlBQYGhqqEhBWVlYwNTUFACQnJ2PJkiVYvnw5+vbtCwCoWbMmWrZsqXbtcePGoUOHDgCAmTNnom7durh9+zZq166db8yxsbHw9/dHvXr1VHHl5fUEyeLFi3H8+HGcO3cOMpkMp06dwvnz5xEfHw+pNGdyxYIFC7B7925s374dgwYNQqNGjQosoP5mcq0onj17htmzZ2PQoEGqNiMjI4SFhaFTp06YPXs2AMDJyQl//PGHKlGlyb1791ClShW1tszMTFhYWKBWrVowNTWFnZ2d2vFVq1ZBLpfneU4dnbxXPv3222/4+++/8fPPP+fZR6FQoGfPnvjuu+9gZ2ensaZTixYtsHHjRnTv3h2vXr1CZmYm/Pz88MMPP6j1U97bvXv38k3GFQZnQpWxXl6O0JdKoFXIzzEtAdCXStDTq2bpBkbFVqIF54u5Vawoikh99QqJySlIffUq3yVySUlJCF0XCp+2Pmjq3hRe3l5o6t4UPm19ELouFElJ6tOOX966jNvrZyM7Q4H81s9nZyhwe/1svLx1uVAxExERERGVusxEQBGLov/GWMwZl/mixEJp1qyZ2i993d3dcevWLdXuahcvXoSfnx/s7OxgZGSE1q1bA8hJBOXlxo0bUCgU8Pb2zvfar9cHsrGxAQDVUr/8jBgxAl9//TVatGiB6dOn459//ilwzKFDhzBp0iRs3boVzs7OAIArV64gJSUFFhYWarN/7t69i+jonNUhMpkMjo6O+T6MjIwKvL4mSUlJ6NChA+rUqYMZM2ao2uVyOQIDA9GiRQucPXsWf/31Fz766CN06NAh34SRXC5XW4oHAIsWLcKrV69gZmYGQ0PDXPWbqlatmu+92dvba7zWiRMn0L9/f6xcuTLf2VKTJ0+Gi4sL/u///i/PPpGRkRg5ciSmTZuGixcv4vfff0dMTAyCg4PV+slkMgBAWlpanucqLM6EKmOmhlJsmNgGXWcfgRbyrx+kJeTMnvp1UhuYGnIpXnlVEgXnLfTTc6YJPw797x/J/0jtAJt+gJU/IDHONVauSMflW7dxNvImEpL/txufuZERmtWpDVcnR8ikuqr28PBwDBsxTOMH6v379zFn7hws/n4xli9dDg8PD2TKU3Bn83wAGiqtv0kUAQG4s3k+6o1fBYlM8zRdIiIiIqJ3Justv0RnpQI6ZiUTSz5SU1Ph6+sLX19fbNy4EZaWloiNjYWvry/S09PzHKdMFhTk9Vk2ykRYdnZ2geOCgoLg6+uLAwcO4PDhw5g7dy4WLlyI4cOHa+wfGRmJHj16YN68eWjbtq2qPSUlBTY2NggLC8s1RjmrKzw8HO3bt883np9//hm9e/cuMO7XJScno127djAyMsKuXbvUnotNmzYhJiYGZ86cUS1f27RpE8zMzLBnzx706NFD4zkrVaqExMREtbYVK1YgISEBR44cgb29fa6ZUu3bt0d4eHiecdrb2+P69etqbX/++Sf8/PywePFiBAQE5Hufx48fx9WrV7F9+3YAUE1MqFSpEqZOnYqZM2di7ty5aNGiBcaPHw8gJzlpYGAADw8PfP3116oEpXKJpKWlZb7XLAwmocoBH7eq2BbyCfrMP440Rc463Ne/3yuT4zKpBL9OagNv16plECUV1tsWjDfLPAdcGPnfOvU3KLeKjV0A1PoRMGutOnTrwUNsPhaGdA1ruROSk3Hw3N84evEyenp7wqlaVYSHhyNoUBBEUdQ4U0rZJpfLETQoCKt+WQVn7Rf/LcEr5G+ORBHZ6QokRITByr1j4cYQEREREZUWbf23HG9QMnEAOHfunNrfz549CycnJ2hra+PmzZt4/vw55s2bB1tbWwDAhQsX1Prr6ub8clk5cwrIWTomk8lw7NgxBAUFlVisr7O1tUVwcDCCg4MxefJkrFy5UmMS6tmzZ/Dz84O/vz9Gjx6tdszNzQ1xcXGQSCR5Lu8qjeV4SUlJ8PX1hVQqxd69e3PNXkpLS4OWlpbaDDXl3/NL0rm6uiIyMlKtbcuWLRg0aFCehdKLuhwvLCwMHTt2xPz589WWEOZlx44dauf/+++/MWDAAISHh6NmzZyVVWlpabmWGWprawOA2nfEa9euQUdHp8A6VYXBJFQ54eNWFTdWd8PmE9FYsT8Sd+P+N4vFobIRgjvWQa82jjAx0M3nLFQeKAvOxzxJLuzqOQA5ycZero9gdO9r5L1Tx39tyq1iXdYAZq1x68FDrD98rMDZSRmZmVh/+Bi6NG+CYSOG5ZmAUrvif8eHjRiGDb2b5hFX/uLP7Idlsw6sY0ZEREQVko6RGWy8ukPHqPRn0FABJGY5qwsU91G0/68VAKktIDEtsVBiY2MxZswYDB48GJcuXcKyZcuwcOFCAICdnR10dXWxbNkyBAcH49q1a6oaRUr29vYQBAH79+/Hp59+CplMBkNDQ0ycOBETJkyArq4uWrRogadPn+L69esIDAx865hHjRqF9u3bw9nZGYmJiThx4gRcXFw09vX394e+vj5mzJiBuLg4VbulpSV8fHzg7u6OTp064dtvv4WzszMePXqEAwcOoHPnzmjUqJFqOV5hJSQkIDY2Fo8ePQKQU7AdAKytrWFtbY2kpCS0bdsWaWlp+PXXX5GUlKQqPWJpaQltbW188sknGD9+PIYOHYrhw4cjOzsb8+bNg0QiUe1GqImvry/WrVun1ubm5oYVK1agbt26cHZ2xtOnTxEZGYk+ffoAyFmOV1gnTpxAx44dMXLkSPj7+6ueT11dXVXtrV27dmHy5Mm4efMmAKgSTUrPnj0DALi4uKhmm/n5+WHgwIH46aef4Ovri8ePH2PUqFFo0qSJ2syt8PBweHh4FHqmXX5YE6ocMTWUYohfHUSs8MfdDT1x9ZcvcHdDT0Ss8McQvzpMQL0nlAXni8pE+gpLfX6FUMStYuVpz7D5WBggioUaBVHEt8t+gFwuLzABpRonipBkpSPjRcHrxDVdVZEQhyx5csFdiYiIiD5AOkbmqOLdEzpG+e9kRe+AIOSUtyiOKv1KrCg5AAQEBEAul6NJkyYYOnQoRo4cqZrhYmlpidDQUGzbtg116tTBvHnzsGDBArXxVatWxcyZMzFp0iRUrlwZw4YNAwCEhIRg7NixmDZtGlxcXNC9e/dC1XsqjKysLAwdOhQuLi5o164dnJ2d8eOPP2rse/LkSVy7dg329vawsbFRPe7fvw9BEHDw4EG0atUK/fv3h7OzM3r06IF79+4Vu9j43r174erqqiq43qNHD7i6umLFihUAgEuXLuHcuXO4evUqHB0dc8UEALVr18a+ffvwzz//wN3dHR4eHnj06BF+//131dI0TXr37o3r16+rEl8AsGzZMrRu3Rr9+vWDo6MjOnbsiMuXi1cvd926dUhLS8PcuXPV4u7SpYuqz8uXL9WuXxj9+vXDokWLsHz5cnz00Ufo2rUratWqhZ07d6r127Jli6pg/tsSxMJ+C/1AJSUlwcTERLU1I1FJeJGigEvgb5ArMvOt86WkJQDDm/6NWa1//y8JVVgCTiMEB28UPp8siiIOrPwRqS8SC+78GksDXSz71KlIY1730difITUr/u4VRERERFSyPoTvQq9evcLdu3dRvXr1XEur8pSZBFxw/6/8RWH+31sL0NIDGp3RWJeVCADGjx+PpKSkfHesex8dOnQIY8eOxT///JPnDoFFeR9yJhRRKVAWnBcEocCdD3MKzgOTPf9BUX+vIorA2eiUIo1Jl8uLnIACgFcZWQV3yoe29O2nbhIRERERvTWJcU59VQj/PfLz3/HaPzEBRfmaOnUq7O3tC1Xg/X2SmpqKtWvX5pmAKiomoYhKibLgvEwqgSDknrmrbJNJJdgT0gT64kMUtd5SWpYMCelF+8cwMyPv3TTyk5yehbgURTFGCpCaW0NbVrztU4mIiIiISpxZ65z6qloyaE5G/demJQPqrAVMW737GMtA+/btYWhoqPExZ86csg6vXDM1NcWUKVNUu+p9KL744gs0bdq0xM7HwuREpajQBee144FLRT9/enbR64RJdIpfW+yPWwno65r3Wui8WLl3ZFFyIiIiIipfzFrnLLF7ugN4FAooYv93TGqbUwPK0r9CzYDKb8c2ZQFsorfBJBRRKVMWnA/u6IKEZAVS5BkwlOnA3Ej6v8RMRvG2itXVKvqsJl2ZDAamZkVekicIAqKzDKGlq4fsDEWBO/H9NwhaOlKYN/QscpxERERERKVOYgzY9Aes+wGZL4CsVEDbIGcXvAr4S9Si7NhGVBwf1jwxonJMEARYGOvBvrIRLIz11GcGKbeKLWJVKH1tOcx1k4och7Nb4yKNUerWKwA1ek4EoGF9Ye4LARBQs+dESGSGxboeEREREdE7IQiAjhmgVy3nzwqYgCJ6F5iEIioPirlVrCAAzWoWPcHj8FF9SPX0Cr1ETktLCzKZDJ07dYaJkyscA0KgpSNFfuvntXSkcAoIgbGTa5HjIyIiIiIiog8Pk1BE5YWV/2uFEQtDC9CSwbWhH3QlkkKPEgAYGhri+8VLIAhCgYko5fHly5artu41cXJFvfGrYNshEFLzymr9peaVYdshEPUnrGYCioiIiIiIiFRYE4qovFBuFXtjwH8N+dVc+t9WsTL9Sujp7Yn1h49BEMWCRwkCenp7wqlaVaz6ZRWGjRimKj4ovlbnSZl8kslkWL5sOTxaeqiHKzOElXtHWDbrgCx5MrIUcmhLZdCWGbEIOREREREREeXCmVBE5Ukxt4p1qlYVAW29oSPJP6+sI5EgoK03nKrlFBz08PBA+J/hmDplKmxtbdX62traYuqUqTh18lSuBJRaRIIAib4xpGaVIdE3ZgKKiIiIiN47oigi9dUrJCanIPXVK7VfzhJRyRHECv7uSkpKgomJCV6+fKlaakRU5jKT8tgq1i7frWLlinRE3I7Gmes3kJCcrGo3NzKCe10XuDrVhJ6ursZLiqKIFy9eIDU1FQYGBjA1NWVCiYiIiOgD9iF8F3r16hXu3r2L6tWrQ09Pr8jj5Yp0XL51G2cjb+b6/+dmdWrD1ckRMqnm/39+G56enmjYsCG+//77Ej93fmJiYlC9enVcvnwZDRs2LNFzh4WFwcvLC4mJiTA1NS3Rc5e1qKgotG7dGrdu3YKRkVFZh1NiVqxYgQMHDmDfvn1vdZ6ivA85E4qoPFJuFesWBjS+BLiF//dnWE67hgQUAMikunCv64LRXTtjSu/uGNvNH1N6d8forp3hXtclzwQUkDOjyczMDNWqVYOZmRkTUERERET0Qbv14CG+27INB8/9rZaAAoCE5GQcPPc3vtuyDbcePCyjCPMXFhYGQRDw4sWLsg4FANC8eXM8fvwYJiYmZRbDjRs38Nlnn8HExAQGBgZo3LgxYmNjc/UTRRHt27eHIAjYvXt3geedPHkyhg8fXmoJqBEjRuDjjz+GVCotVHIwJiZGVd/3zce2bdsAAFeuXEHPnj1ha2sLmUwGFxcXLFmyRO08AwYMwKVLlxAeHl4at6URk1BE5Vkxt4oVBAH6enowMzKEfhF2wSMiIiIiqghuPXiI9YePISMzM99+GZmZWH/4WLlNRJUnurq6sLa2LrPvHtHR0WjZsiVq166NsLAw/PPPPwgJCdE4M+f7778vdJyxsbHYv38/+vXrV8IRqxswYAC6d+9eqL62trZ4/Pix2mPmzJkwNDRE+/btAQAXL16ElZUVfv31V1y/fh1Tp07F5MmTsXz5ctV5dHV10atXLyxdurRU7kkTJqGIiIiIiIiowpAr0rH5WBhQwKY+wH9bBYkiNh8Lg1yRXqJxZGZmYtiwYTAxMUGlSpUQEhKiVotqw4YNaNSoEYyMjGBtbY1evXohPj4eQM5MGC8vLwBQrWJQJkmys7Px7bffwtHREVKpFHZ2dvjmm2/Urn3nzh14eXlBX18fDRo0wJkzZwoV87179+Dn5wczMzMYGBigbt26OHjwIIDcM7M8PT01ztSJiYkBALx48QJBQUGwtLSEsbEx2rRpgytXrhT36cTUqVPx6aef4ttvv4Wrqytq1qyJzz77DFZWVmr9IiIisHDhQqxZs6ZQ5/3tt9/QoEEDVK1aVdWWlpaGgQMHonLlytDV1YWtrS1mzZpV7NiXLl2KoUOHokaNGoXqr62tDWtra7XHrl270K1bNxgaGgLISWotWbIErVu3Ro0aNfB///d/6N+/P3bu3Kl2Lj8/P+zdu1e1WVVpYxKKiIiIiIiIKozLt24jPTOzwASUkgggPTMTEbejSzSOdevWQSKR4Pz581iyZAkWLVqEVatWqY5nZGRg9uzZuHLlCnbv3o2YmBhVosnW1hY7duwAkFOv6PHjx6qlVpMnT8a8efMQEhKCyMhIbNq0CZUrV1a79tSpUzFu3DhERETA2dkZPXv2RGYBs8IAYOjQoVAoFDh58iSuXr2K+fPnq5Ieb9q5c6faTJ0uXbqgVq1aqli6du2K+Ph4HDp0CBcvXoSbmxu8vb2RkJAAAAgPD4ehoWG+j40bNwLISbwdOHAAzs7O8PX1hZWVFZo2bZprqV1aWhp69eqFH374AdbW1gXerzKORo0aqbUtWLAAhw8fxpYtWxAdHY09e/bA09NTdTw4OLjA2EvSxYsXERERgcDAwHz7vXz5Eubm5mptjRo1QmZmJs6dO1eiMeUl/620iIiIiIiIiD4QoijibOTNYo09c/0GmtWpXWLLzWxtbbF48WIIgoBatWrh6tWrWLx4MQYOHAggZyaLUo0aNbB06VI0btwYKSkpMDQ0VCUTrKysVIXAk5OTsWTJEixfvhx9+/YFANSsWRMtW7ZUu/a4cePQoUMHAMDMmTNRt25d3L59G7Vr18435tjYWPj7+6NevXqquPLyerJj8eLFOH78OM6dOweZTIZTp07h/PnziI+Ph1QqBZCT2Nm9eze2b9+OQYMGoVGjRoiIiMg3HmVCKz4+HikpKZg3bx6+/vprzJ8/H7///ju6dOmCEydOoHXr1gCA0aNHo3nz5vj888/zPe/r7t27lysJlZmZCRMTE9SuXRs2Nja5dhqfNWsWxo0bV+hrvK3Vq1fDxcUFzZs3z7PP6dOnsXXrVhw4cECtXV9fHyYmJrh3715phwmASSgiIiIiIiKqINIUilxFyAsrITkZcoUC+sXYhU+TZs2aqSW03N3dsXDhQmRlZUFbWxsXL17EjBkzcOXKFSQmJiI7OxtATiKoTp06Gs9548YNKBQKeHt753vt+vXrq/7bxsYGQE4ip6Ak1IgRIzBkyBAcPnwYPj4+8Pf3VzuXJocOHcKkSZOwb98+ODs7A8gpmp2SkgILCwu1vnK5HNHROTPOZDIZHB0d8z23kvK5+fzzzzF69GgAQMOGDXH69GmsWLECrVu3xt69e3H8+HFcvny5UOd8PaY360pNmjQJkZGRqFKlCvT19fHdd9/hyy+/VB23srLKtQywtMjlcmzatAkhISF59rl27Ro+//xzTJ8+HW3bts11XCaTIS0trTTDVOFyPCIiIiIiIqoQ0jMKXnKWH8Vbji+s1NRU+Pr6wtjYGBs3bsTff/+NXbt2AQDS0/OuTSWTyQp1fh0dHdV/KxNhykROfoKCgnDnzh306dMHV69eRaNGjbBs2bI8+0dGRqJHjx6YN2+eWvIjJSUFNjY2iIiIUHtERUVh/PjxAIq2HK9SpUqQSCS5knMuLi6q3fGOHz+O6OhomJqaQiKRQCLJmZPj7++vtpTuTZUqVUJiYqJa2/bt23H27Fns3bsXly9fRu/evdWOv8vleNu3b0daWhoCAgI0Ho+MjIS3tzcGDRqEr776SmOfhIQEWFpallhM+eFMKCIiIiIiIqoQdHXe7iuw9C3Hv+7NGjxnz56Fk5MTtLW1cfPmTTx//hzz5s1TLfW6cOGCWn9dXV0AQFZWlqrNyckJMpkMx44dQ1BQUInF+jpbW1sEBwcjODgYkydPxsqVKzF8+PBc/Z49ewY/Pz/4+/urZicpubm5IS4uDhKJBA4ODhqvU5TleLq6umjcuDGioqLUjv/777+wt7cHkDN76c3npF69eli8eDH8/PzyvIarqysiIyPV2n777Td07do1z3Hvcjne6tWr8dlnn2lMIl2/fh1t2rRB3759cxWnV4qOjsarV6/g6upa2qECYBKKiIiIiIiIKgh9qRTmRkbFWpJnbmQE2X/1i0pCbGwsxowZg8GDB+PSpUtYtmwZFi5cCACws7ODrq4uli1bhuDgYFy7dg2zZ89WG29vbw9BELB//358+umnkMlkMDQ0xMSJEzFhwgTo6uqiRYsWePr0Ka5fv15g0erCGDVqFNq3bw9nZ2ckJibixIkTcHFx0djX398f+vr6mDFjBuLi4lTtlpaW8PHxgbu7Ozp16oRvv/0Wzs7OePToEQ4cOIDOnTujUaNGRVqOBwDjx49H9+7d0apVK3h5eeH333/Hvn37EBYWBgCqXeTeZGdnh+rVq+d5Xl9fXwQFBamWSQI5SbRffvkFnp6eaNiwIV6+fImzZ89i0KBBAIq+HO/27dtISUlBXFwc5HK5KvlWp04d6Orq4uHDh/D29sb69evRpEkTtXEnT55U7VD4umvXrqFNmzbw9fXFmDFjVD8DbW1ttYRVeHg4atSogZo1axY63rfBJBQRERERERFVCIIgoFmd2jh47u8ij3Wv61JiRckBICAgAHK5HE2aNIG2tjZGjhypSmJYWloiNDQUU6ZMwdKlS+Hm5oYFCxbgs88+U42vWrUqZs6ciUmTJqF///4ICAhAaGgoQkJCIJFIMG3aNDx69Ag2NjYIDg4ukZizsrIwdOhQPHjwAMbGxmjXrh0WL16sse/JkycBQDUTSenu3btwcHDAwYMHMXXqVPTv3x9Pnz6FtbU1WrVqlWsnv8Lq3LkzVqxYgblz52LEiBGoVasWduzYkasoe1G1b98eEokER48eha+vLwDgq6++gkKhwKhRo/Do0SMYGxujTZs2qp9fUQUFBeHPP/9U/V05K0n5XGVkZCAqKipX3aY1a9agWrVqGus8bd++HU+fPsWvv/6KX3/9VdVub2+PmJgY1d83b96sKob/LgiiKBZ2Z8oPUlJSEkxMTPDy5UsYGxuXdThERERERETvxIfwXejVq1e4e/cuqlevnqt4dF7kinR8t2UbMjIzUZgvwwIAHYkE43t0hUyq+1bx0vvphx9+wN69e/HHH3+UdSglSrlc799//4WJiUmxz1OU9yELkxMREREREVGFIZPqoqe3JyAIKGhekwAAgoCe3p5MQFVggwcPRqtWrZBczJ0Vy6vHjx9j/fr1b5WAKiomoYiIiIiIiKhCcapWFQFtvaEjyb9CjY5EgoC23nCqVvUdRVa22rdvn+dubnPmzCnr8MqMRCLB1KlTYWRkVNahlCgfHx/VEsN3hTWhiIiIiIiIqMJxqlYV43t0RcTtaJy5fkOtWLm5kRHc67rA1akm9HQrzgyoVatWQS6Xazxmbm7+jqOhDxGTUERERERERFQhyaS6cK/rgmZ1akOuUECRkQmpjgQyqbREi5C/L6pWrRgzvqjsMAlFREREREREFZogCNDX04N+4WqbE1ExsSYUERERERERERGVOiahiIiIiIiIiIio1DEJRUREREREREREpY41oYiIiIiIiKhCE0URiYmJSEtLg76+PszMzCpkYXKi0lbuZkL98MMPcHBwgJ6eHpo2bYrz58/n2//7779HrVq1IJPJYGtri9GjR+PVq1fvKFoiIiIiIiJ6XyUlJSF0XSh82vqgqXtTeHl7oal7U/i09UHoulAkJSWVynU9PT0xatSoUjl3fmJiYiAIAiIiIkr83GFhYRAEAS9evCjxc5e1Y8eOwcXFBVlZWWUdSomaNGkShg8f/k6vWa6SUFu3bsWYMWMwffp0XLp0CQ0aNICvry/i4+M19t+0aRMmTZqE6dOn48aNG1i9ejW2bt2KKVOmvOPIiYiIiIiI6H0SHh4Oj9YemDN3Du7fv6927P79+5gzdw48WnsgPDy8jCLMX3lL+jRv3hyPHz+GiYlJmVx/xowZqF27NgwMDGBmZgYfHx+cO3dOdTwmJgaBgYGoXr06ZDIZatasienTpyM9Pb3Ac0+YMAFfffUVtLW1SzzuV69eoV+/fqhXrx4kEgk6depU4Jii3svt27dhZGQEU1NTtfZx48Zh3bp1uHPnTgncSeGUqyTUokWLMHDgQPTv3x916tTBihUroK+vjzVr1mjsf/r0abRo0QK9evWCg4MD2rZti549exY4e4qIiIiIiIgqrvDwcAQNCoJcLocoihBFUe24sk0ulyNoUFC5TUSVJ7q6urC2ti6zZYzOzs5Yvnw5rl69ilOnTqlyBE+fPgUA3Lx5E9nZ2fj5559x/fp1LF68GCtWrChwEsupU6cQHR0Nf3//Uok7KysLMpkMI0aMgI+PT6HGFOVeMjIy0LNnT3h4eOQ6VqlSJfj6+uKnn3566/sorHKThEpPT8fFixfVnnQtLS34+PjgzJkzGsc0b94cFy9eVCWd7ty5g4MHD+LTTz/N8zoKhQJJSUlqDyIiIiIiIqoYkpKSMGzEMI3Jpzcp+wwbMazEvztmZmZi2LBhMDExQaVKlRASEqIWz4YNG9CoUSMYGRnB2toavXr1Uq0SiomJgZeXFwCo6lf169cPAJCdnY1vv/0Wjo6OkEqlsLOzwzfffKN27Tt37sDLywv6+vpo0KBBnt+533Tv3j34+fnBzMwMBgYGqFu3Lg4ePAgg98wsT09PCIKQ6xETEwMAePHiBYKCgmBpaQljY2O0adMGV65cKe7TiV69esHHxwc1atRA3bp1sWjRIiQlJeGff/4BALRr1w5r165F27ZtUaNGDXz22WcYN24cdu7cme95t2zZgk8++QR6enqqtvj4eHTt2hUWFhbQ09NDjRo1sHLlymLFbWBggJ9++gkDBw6EtbV1ocYU5V6++uor1K5dG926ddN4Lj8/P2zZsqVYsRdHuUlCPXv2DFlZWahcubJae+XKlREXF6dxTK9evTBr1iy0bNkSOjo6qFmzJjw9PfPNZM6dOxcmJiaqh62tbYneBxEREREREZVfO3ftVM2AKgzljKhdu3eVaBzr1q2DRCLB+fPnsWTJEixatAirVq1SHc/IyMDs2bNx5coV7N69GzExMapEk62tLXbs2AEAiIqKwuPHj7FkyRIAwOTJkzFv3jyEhIQgMjISmzZtyvU9e+rUqRg3bhwiIiLg7OyMnj17IjMzs8CYhw4dCoVCgZMnT+Lq1auYP38+DA0NNfbduXMnHj9+rHp06dIFtWrVUsXStWtXxMfH49ChQ7h48SLc3Nzg7e2NhIQEADmz1QwNDfN9bNy4UeO109PT8csvv8DExAQNGjTI835evnwJc3PzfO85PDwcjRo1UmubNGkSoqOjcfDgQfz777/YvHkzGjZsqDrevn37fOOuW7duvtcsDk33cvz4cWzbtg0//PBDnuOaNGmCBw8eqJKDpe293h0vLCwMc+bMwY8//oimTZvi9u3bGDlyJGbPno2QkBCNYyZPnowxY8ao/p6UlMREFBERERERUQUgiiI2/LqhWGPXb1iPgD4BJbbczNbWFosXL4YgCKhVqxauXr2KxYsXY+DAgQCAAQMGqPrWqFEDS5cuRePGjZGSkgJDQ0NVwsHKykpV6yc5ORlLlizB8uXL0bdvXwBAzZo10bJlS7Vrjxs3Dh06dAAAzJw5E3Xr1sXt27dRu3btfGOOjY2Fv78/6tWrp4orL68nRBYvXozjx4/j3LlzkMlkOHXqFM6fP4/4+HhIpVIAwIIFC7B7925s374dgwYNQqNGjQosoP5mcm3//v3o0aMH0tLSYGNjgyNHjqBSpUoax96+fRvLli3DggUL8r3GvXv3UKVKFbW2zMxMWFhYoFatWjA1NYWdnZ3a8VWrVkEul+d5Th0dnXyvWVSa7uX58+fo168ffv31VxgbG+c5Vnlv9+7dg4ODQ4nGpUm5SUJVqlQJ2traePLkiVr7kydP8pySFhISgj59+iAoKAgAUK9ePaSmpmLQoEGYOnUqtLRyT/SSSqWqFzkRERERERFVHImJiYiNjS3yOFEUERsbixcvXsDMzKxEYmnWrJlaQsvd3R0LFy5EVlYWtLW1cfHiRcyYMQNXrlxBYmIisrOzAeQkgurUqaPxnDdu3IBCoYC3t3e+165fv77qv21sbADkLDErKAk1YsQIDBkyBIcPH4aPjw/8/f3VzqXJoUOHMGnSJOzbtw/Ozs4AgCtXriAlJQUWFhZqfeVyOaKjowEAMpkMjo6O+Z77TV5eXoiIiMCzZ8+wcuVKdOvWDefOnYOVlZVav4cPH6Jdu3bo2rWrKumXF7lcrrYUD8ipZ925c2fVssQtW7agY8eOquNVq1YtUtxvI697GThwIHr16oVWrVrlO14mkwEA0tLSSjVOpXKzHE9XVxcff/wxjh07pmrLzs7GsWPH4O7urnFMWlparkSTslp9YadWEhERERERUcXwtl+0U1NTSyiSgq/j6+sLY2NjbNy4EX///Td27cpZDpjfbm7KhEJBXp+Jo0yEKZNc+QkKCsKdO3fQp08fXL16FY0aNcKyZcvy7B8ZGYkePXpg3rx5aNu2rao9JSUFNjY2iIiIUHtERUVh/PjxAIq3HM/AwACOjo5o1qwZVq9eDYlEgtWrV6v1efToEby8vNC8eXP88ssvBd5zpUqVkJiYqNa2YsUKJCQk4MiRI7h8+bKqPpfSu1qOl9+9HD9+HAsWLIBEIoFEIkFgYCBevnwJiUSitvmbcvmjpaVlicRUkHIzEwoAxowZg759+6JRo0Zo0qQJvv/+e6SmpqJ///4AgICAAFStWhVz584FkFNAa9GiRXB1dVUtxwsJCYGfn1+pbJ1IRERERERE7y99ff23Gm9gYFBCkQDnzp1T+/vZs2fh5OQEbW1t3Lx5E8+fP8e8efNU5WMuXLig1l9XVxdAzu5qSk5OTpDJZDh27JhqxVBJs7W1RXBwMIKDgzF58mSsXLkSw4cPz9Xv2bNn8PPzg7+/P0aPHq12zM3NDXFxcZBIJHkuASvOcrw3ZWdnQ6FQqP7+8OFDeHl54eOPP8batWs1rp56k6urKyIjI9XatmzZgkGDBuW5m927WI5X0L2cOXNG7bWxZ88ezJ8/H6dPn1abqXXt2jXo6OiUSp0qTcpVEqp79+54+vQppk2bhri4ODRs2BC///676oUVGxur9sR+9dVXEAQBX331FR4+fAhLS0v4+fnlqvxPRERFk5GcgKfn/4BlE1/oGOVfrJGIiIjofWFmZgY7Ozvcv3+/SKtnBEGAra2tqvZSSYiNjcWYMWMwePBgXLp0CcuWLcPChQsBAHZ2dtDV1cWyZcsQHByMa9euYfbs2Wrj7e3tIQgC9u/fj08//RQymQyGhoaYOHEiJkyYAF1dXbRo0QJPnz7F9evXERgY+NYxjxo1Cu3bt4ezszMSExNx4sQJuLi4aOzr7+8PfX19zJgxQ22zMUtLS/j4+MDd3R2dOnXCt99+C2dnZzx69AgHDhxA586d0ahRoyItx0tNTcU333yDzz77DDY2Nnj27Bl++OEHPHz4EF27dgWQk7Tx9PSEvb09FixYgKdPn6rG57crna+vL9atW6fW5ubmhhUrVqBu3bpwdnbG06dPERkZiT59+gAo+nK8yMhIpKenIyEhAcnJyarkm7LY+fnz5xEQEIBjx46hatWqhbqXN38uFy5cgJaWFj766CO19vDwcHh4eBR6Ft3bKldJKAAYNmwYhg0bpvFYWFiY2t8lEgmmT5+O6dOnv4PIiIgqjozkRDw+sRWmLk2YhCIiIqIPhiAI6PN/fTBn7pwijy3JouRAzkofuVyOJk2aQFtbGyNHjsSgQYMA5CRqQkNDMWXKFCxduhRubm5YsGABPvvsM9X4qlWrYubMmZg0aRL69++PgIAAhIaGIiQkBBKJBNOmTcOjR49gY2OD4ODgEok5KysLQ4cOxYMHD2BsbIx27dph8eLFGvuePHkSQE6y7HV3796Fg4MDDh48iKlTp6J///54+vQprK2t0apVqwJnN2minD22bt06PHv2DBYWFmjcuDHCw8NVM3yOHDmC27dv4/bt26hWrZra+PwSkr1798aECRMQFRWFWrVqAQCWLVuGiRMnol+/foiPj4eFhQV69uypSkIV1aeffop79+6p/u7q6qoWV1paGqKiopCRkfFW96LJli1bMGPGjGLFXRyCWMGLJyUlJcHExAQvX77Mt2I8EVFFkvYoGjd+HAuXLxdCv0rNsg6HiIiISsGH8F3o1atXuHv3LqpXr56reHRekpKS4NHaA3K5vFBf2LW0tKCnp4fwP8Pf2+eJ3s748eORlJSEn3/+uaxDKVGHDh3C2LFj8c8//0AiKf4cpaK8D8tNYXIiIiIiIiKi0mZsbIzlS5dDEIQCZzYpjy9ftpwJqAps6tSpsLe3L1Tx9vdJamoq1q5d+1YJqKJiEoqIiIiIiIgqFA8PD6z6ZRVkMpnGZJSyTSaTYdXKVfBo6VFGkb5b+e3qNmdO0ZcwfihMTU0xZcqUQhUyf5988cUXaNq06Tu9ZrmrCUVERERERERU2jw8PBD+Zzh27d6F9RvWIzY2VnXM1tYWAX0C0KVzFxgZGZVhlO9Wfru6mZuzTii9PSahiIiIiIiIqEIyNjZG34C+COgTgBcvXiA1NRUGBgYwNTUt0SLk74ui7upGVFRMQhEREREREVGFJggCzMzMYGZmVtahEH3QPqwFjURElEt8fDyWLluK+Pj4sg6FiIiIiIgqMCahiIg+cE+fPsWy5cvw9OnTsg6FiIiIiIgqMCahiIiIiIiIiIio1LEmFBEREREREVVooigiKy0ZWelyaOvKoK1vVCELkxOVNs6EIiIiIiIiogopU56CJ6f34friIbgyNwDXFg7GlbkBuL54CJ6c3odMeUqpXNfT0xOjRo0qlXPnJyYmBoIgICIiosTPHRYWBkEQ8OLFixI/d1l7/vw5rKysEBMTU9ahlKjIyEhUq1YNqamp7+yaTEIRERERERFRhfPy1mVc/S4IDw6ugSLhidoxRcITPDi4Ble/C8LLW5fLKML8lbekT/PmzfH48WOYmJiUyfV37tyJtm3bwsLCIt9E25kzZ9CmTRsYGBjA2NgYrVq1glwuz/fc33zzDT7//HM4ODiUfOAAEhIS0Lt3bxgbG8PU1BSBgYFISck/ARodHY3OnTvD0tISxsbG6NatG548eZKr34EDB9C0aVPIZDKYmZmhU6dOqmN16tRBs2bNsGjRopK+pTwxCUVEREREREQVystbl3F7/WxkZygAiP89XpfTlp2hwO31s8ttIqo80dXVhbW1dZktY0xNTUXLli0xf/78PPucOXMG7dq1Q9u2bXH+/Hn8/fffGDZsGLS08k6NpKWlYfXq1QgMDCyNsAEAvXv3xvXr13HkyBHs378fJ0+exKBBg/Lsn5qairZt20IQBBw/fhx//fUX0tPT4efnh+zsbFW/HTt2oE+fPujfvz+uXLmCv/76C7169VI7V//+/fHTTz8hMzOz1O7vdUxCERERERERUYWRKU/Bnc3zAYiA+Gby6Q1iTjLqzub5Jb40LzMzE8OGDYOJiQkqVaqEkJAQiK/Fs2HDBjRq1AhGRkawtrZGr169EB8fDyBnWZ2XlxcAwMzMDIIgoF+/fgCA7OxsfPvtt3B0dIRUKoWdnR2++eYbtWvfuXMHXl5e0NfXR4MGDXDmzJlCxXzv3j34+fnBzMwMBgYGqFu3Lg4ePAgg98wsT09PCIKQ66Fc0vbixQsEBQWpZvK0adMGV65cKe7TiT59+mDatGnw8fHJs8/o0aMxYsQITJo0CXXr1kWtWrXQrVs3SKXSPMccPHgQUqkUzZo1U7VlZWVh4sSJqFatmir5FhwcXKy4b9y4gd9//x2rVq1C06ZN0bJlSyxbtgxbtmzBo0ePNI7566+/EBMTg9DQUNSrVw/16tXDunXrcOHCBRw/fhxAzutr5MiR+O677xAcHAxnZ2fUqVMH3bp1UzvXJ598goSEBPz555/Fir+omIQiInpPJKel4dilCCSnpZV1KERERETvreeXTyA7XVFwAkpJFJGdrkBCRFiJxrFu3TpIJBKcP38eS5YswaJFi7Bq1SrV8YyMDMyePRtXrlzB7t27ERMTo0o02draYseOHQCAqKgoPH78GEuWLAEATJ48GfPmzUNISAgiIyOxadMmVK5cWe3aU6dOxbhx4xAREQFnZ2f07NmzUDNhhg4dCoVCgZMnT+Lq1auYP38+DA0NNfbduXMnHj9+rHp06dIFtWrVUsXStWtXxMfH49ChQ7h48SLc3Nzg7e2NhIQEAEB4eDgMDQ3zfWzcuLHQz3d8fDzOnTsHKysrNG/eHJUrV0br1q1x6tSpfMeFh4fj448/VmvbuHEjfv75Z/z000+Ijo7GkSNH0LlzZ9XxOXPmFBh7bGwsgJzZWaampmjUqJFqvI+PD7S0tHDu3DmNMSkUCgiCoJY809PTg5aWlup+Ll26hIcPH0JLSwuurq6wsbFB+/btce3aNbVz6erqomHDhggPDy/Es/j2uDsevTPccYLo7SSnyXHi8hW42NnCSF+/rMMhIiIieu+IooinZw8g9/K7gsWf2Q/LZh1K7DuMra0tFi9eDEEQUKtWLVy9ehWLFy/GwIEDAQADBgxQ9a1RowaWLl2Kxo0bIyUlBYaGhjA3NwcAWFlZwdTUFACQnJyMJUuWYPny5ejbty8AoGbNmmjZsqXatceNG4cOHToAAGbOnIm6devi9u3bqF27dr4xx8bGwt/fH/Xq1VPFlRdlfACwePFiHD9+HOfOnYNMJsOpU6dw/vx5xMfHqxIpCxYswO7du7F9+3YMGjQIjRo1KrCA+pvJtfzcuXMHADBjxgwsWLAADRs2xPr16+Ht7Y1r167ByclJ47h79+6hSpUqam2ZmZnQ19dH7dq1YWtrC1tbW9VzAgDBwcG5Zhy9SXnOuLg4WFlZqR2TSCQwNzdHXFycxrHNmjWDgYEBJk6ciDlz5kAURUyaNAlZWVl4/PhxrvtdtGgRHBwcsHDhQnh6euLff/9V+/lUqVIF9+7dyzfeksIkFJW6THkKnl8+gadnD0CR8L83kdTcGpbNOsDC1QsSmebsORERERERUUnJSktW+05SeCIUCXHIkidDom9cIrE0a9ZMLaHl7u6OhQsXIisrC9ra2rh48SJmzJiBK1euIDExUVXrJzY2FnXq1NF4zhs3bkChUMDb2zvfa9evX1/13zY2NgByZgoVlIQaMWIEhgwZgsOHD8PHxwf+/v5q59Lk0KFDmDRpEvbt2wdnZ2cAwJUrV5CSkgILCwu1vnK5HNHR0QAAmUwGR0fHfM9dFMrnb/Dgwejfvz8AwNXVFceOHcOaNWswd+5cjePkcjn09PTU2vr27YtLly7B2dkZMpkMw4cPV6tFZW5urpbkKWmWlpbYtm0bhgwZgqVLl0JLSws9e/aEm5ubqr6V8n6nTp0Kf39/AMDatWtRrVo1bNu2DYMHD1adTyaTIe0drbZgEopK1ctbl3Fn8/yc6a5vUO448ejoRtToOREmTq5lECEREREREVUUWen574JW4HiFvMSSUPlJTU2Fr68vfH19sXHjRlhaWiI2Nha+vr5IT0/Pc5xMJivU+XV0dFT/rUyEvV7QOi9BQUHw9fXFgQMHcPjwYcydOxcLFy7E8OHDNfaPjIxEjx49MG/ePLRt21bVnpKSAhsbG4SFheUao5zVFR4ejvbt2+cbz88//4zevXsXGDfwv2Tbmwk8FxcX1dI4TSpVqoTExES1trCwMGzZsgUbN26Em5sbKlWqpHZ8zpw5mDNnTr7xREZGws7ODtbW1qpaX0qZmZlISEiAtbV1nuPbtm2L6OhoPHv2DBKJBKamprC2tlbNTtN0v1KpFDVq1Mh1vwkJCahZs2a+8ZYUJqGo1Ch3nNC82wRUbcodJxwDQpiIIiIiIiKiUqOtW7gkTZ7jpW83/nVv1vs5e/YsnJycoK2tjZs3b+L58+eYN28ebG1tAQAXLlxQ66+rqwsgp0i2kpOTE2QyGY4dO4agoKASi/V1tra2CA4ORnBwMCZPnoyVK1dqTEI9e/YMfn5+8Pf3x+jRo9WOubm5IS4uDhKJBA4ODhqvU9LL8RwcHFClShVERUWptf/777/5JrtcXV3x66+/qrXt2rULHh4euXaaUyrKcjx3d3e8ePECFy9eVNWeOn78OLKzs9G0adMC70uZADt+/Dji4+Px2WefAQA+/vhjSKVSREVFqZZjZmRkICYmBvb29mrnuHbtGr744osCr1USmISiUlHkHScE4M7m+ag3fhWX5hERERERUanQ1jeC1NwaioQnKFpdKAFS88rQlhmVWCyxsbEYM2YMBg8ejEuXLmHZsmVYuHAhAMDOzg66urpYtmwZgoODce3aNcyePVttvL29PQRBwP79+/Hpp59CJpPB0NAQEydOxIQJE6Crq4sWLVrg6dOnuH79OgIDA9865lGjRqF9+/ZwdnZGYmIiTpw4ARcXF419/f39oa+vjxkzZqjVNrK0tISPjw/c3d3RqVMnfPvtt3B2dsajR49w4MABdO7cGY0aNSrycryEhATExsaqdpRTJpusra1hbW0NQRAwfvx4TJ8+HQ0aNEDDhg2xbt063Lx5E9u3b8/zvL6+vpg8eTISExNhZmYGICeJFhoaig0bNsDDwwNpaWkIDw9Hv379IJVKi7Qcz8XFBe3atcPAgQOxYsUKZGRkYNiwYejRo4cqUfXw4UN4e3tj/fr1aNKkCYCcpXUuLi6wtLTEmTNnMHLkSIwePRq1atUCABgbGyM4OBjTp0+Hra0t7O3t8d133wHIKQqvFBMTg4cPH+a7q2BJYhKKSoVqx4nCfrC/tuOElXvHUo2NiIiIiIgqJkEQYNmsAx4cXFPksVbuHUt0Y6WAgADI5XI0adIE2traGDlyJAYNGgQgJ1ETGhqKKVOmYOnSpXBzc8OCBQtUs1wAoGrVqpg5cyYmTZqE/v37IyAgAKGhoQgJCYFEIsG0adPw6NEj2NjYIDg4uERizsrKwtChQ/HgwQMYGxujXbt2WLx4sca+J0+eBIBcs27u3r0LBwcHHDx4EFOnTkX//v3x9OlTWFtbo1WrVkWa3fS6vXv3qmo9AUCPHj0AANOnT8eMGTMA5CTRXr16hdGjRyMhIQENGjTAkSNH8l2KVq9ePbi5ueG3335T1VEaMGAAnj17hq+//hqxsbHQ09ODm5ubavfCotq4cSOGDRsGb29vaGlpwd/fH0uXLlUdz8jIQFRUlFrdpqioKEyePBkJCQlwcHDA1KlTc804++677yCRSNCnTx/I5XI0bdoUx48fVyXTAGDz5s1o27Ztrp9TaRFEsbD7Un6YkpKSYGJigpcvX8LYuPTX9lYEoiji+uIhxSj4l/Pbhbqjf+KueUQaPHr2HD/u2Y8vP++IKpUsCh7wn+vXr6NTl07YvXM36tatW6gxaY+icePHsXD5ciH0q7yb9eFERET0bn0I34VevXqFu3fvonr16rmKR+clU56Cq98FITtDUfCqDQAQBGjpSLlqowI7cOAAxo8fj2vXrqkKf38I0tPT4eTkhE2bNqFFixbFPk9R3ocfzrNH5UZJ7DhBRERERERUGiQyQ9ToORGAABT0y29BACCgZs+JTEBVYB06dMCgQYPw8OHDsg6lRMXGxmLKlClvlYAqKiahqMSVxI4TREREREREpcXEyRWOASHQ0pECEP57vC6nTUtHCqeAEBhXkA2U2rdvD0NDQ42PgnZ7+9CNGjVKVST+Q+Ho6KhaYviusCYUlbjytOMEERERERGRJiZOrqg3fhUSIsIQf2a/2moOqXllWLl3hIWrF7T1DMowyndr1apVkMs1TwoobKFtovwwCUUlrjztOEFERERERJQXicwQVu4dYdmsA7LkychSyKEtlUFbZlQh69RWrVq1rEOgDxyX41GJU+44URwlveMEERERERFRQQRBgETfGFKzypDoG/M7CVEpYRKKSoWFqxe0dKUFF/pTEgRo6Uph3tCzVOMiIiIiIqIPTwXf9J2oTBXl/cckFJUK7jhBRERERESlTUdHBwCQlpZWxpEQVVzK95/y/Zgf1oSiUqPcceLO5vnITlf81/p6hjQnOaWlI0XNnhMrzI4TRERERERUMrS1tWFqaor4+HgAgL6+PpfSEb0joigiLS0N8fHxMDU1hba2doFjmISiYouPj8eWrVvQo3sPWFlZaezDHSeIiIiIiKg0WVtbA4AqEUVE75apqanqfVgQJqGo2J4+fYply5fBu413nkkogDtOEBERERFR6REEATY2NrCyskJGRkZZh0NUoejo6BRqBpQSk1D0zih3nJDoG5d1KERERERE9IHR1tYu0pdhInr3WJiciIjUiKKITHkqACBTnsrdZoiIiIiIqERwJhQREQEAMuUpeH75BJ6ePaCq33Zr7TRIza1h2awDLFy9uIMlEREREREVG5NQRESEl7cuv7GT5f8oEp7gwcE1eHR0I2r0nAgT7mRJRERERETFwOV4VCyiKOJl0ksAwMukl1yuQ/Qee3nrMm6vn43sDAUA8b/H63LasjMUuL1+Nl7euvzugyQiIiIiovcek1BUJElJSQhdFwqftj7o268vAKBvv77waeuD0HWhSEpKKuMIiagoMuUpuLN5PgARKCiZLOYko+5sno9Mecq7CI+IiIiIiD4gTEJRoYWHh8OjtQfmzJ2D+/fvqx27f/8+5sydA4/WHggPDy+jCImoqJ5fPpGzBK+wsxlFEdnpCiREhJVqXERERERE9OFhEooKJTw8HEGDgiCXyyGKYq7ld8o2uVyOoEFBTEQRvQdEUcTTsweQe/ldweLP7OcyXCIiIiIiKhImoahASUlJGDZimMbk05uUfYaNGMaleUTlXFZasmoXvKIRoUiIQ5Y8ucRjIiIiIiKiDxeTUFSgnbt2qmZAFYZyRtSu3btKOTIiehtZ6fK3G694u/FERERERFSxMAlF+RJFERt+3VCsses3rOdyHaJyTFtX9nbjpW83noiIiIiIKhYmoShfiYmJiI2NLXIySRRFxMbG4sWLF6UTGBG9NW19I0jNrQEIRRwpQGpuDW2ZUWmERUREREREHygmoShfaWlpbzU+NTW1hCIhopImCAIsm3Uo1lgr944QhKImr4iIiIiIqCJjEorypa+v/1bjDQwMSigSIioNFq5e0NKVAoVNKAkCtHSlMG/oWapxERERERHRh4dJKMqXmZkZ7OzsijzjQRAE2NnZwdTUtHQCI6ISIZEZokbPiQCEghNRggBAQM2eEyGRGb6L8IiIiIiI6APCJBQhOS0Nxy5FIFnD0jtBENDn//oU67wBfQK4XIfoPWDi5ArHgBBo6UiRUx/qzfdtTpuWjhROASEwdnJ990ESEREREdF7j0koQnKaHCcuX0Fymubt1rt07gKZTFbohJKWlhZkMhk6d+pckmESUSkycXJFvfGrYNshEFLzymrHpOaVYdshEPUnrGYCioiIiIiIik1S1gFQ+WdsbIzlS5cjaFAQAOS7U54yUbV82XIYGxu/k/iIqGRIZIawcu8Iy2YdkHz3Km6tmQanAbNgVL0eZzUSEREREdFb40woKhQPDw+s+mWVakbUm19IlW0ymQyrVq6CR0uPMoqUiN6WIAiQ6OVsKiDRM2ACioiIiIiISgRnQlGheXh4IPzPcOzavQvrN6xHbGys6pitrS0C+gSgS+cuMDIyKsMoiYiIiIiIiKg8YhKKisTY2Bh9A/oioE8Azp49i4B+AVgfuh7NmjXjbAkiIiIiIiIiyhOX41GxCIKAmjVrYviw4ahZsyYTUERERERERESUL86EomKzsrLCiOEjyjoMIiIiIiIiInoPcCYUERERERERERGVOiahiIiIiIiIiIio1DEJRUREREREREREpY5JKCIiIiIiIiIiKnVMQhERERERERERUaljEoqIiIiIiIiIiEodk1BERERERERERFTqmISq4ERRhDxdAQCQpysgimIZR0REREREREREHyJJWQdAZUOuSMflW7dxNvImEpKTAQBrDx2BuZERmtWpDVcnR8ikumUcJRERERERERF9KJiEqoBuPXiIzcfCkJ6ZmetYQnIyDp77G0cvXkZPb084VataBhESERERERER0YeGy/EqmFsPHmL94WPI0JCAel1GZibWHz6GWw8evqPIiIiIiIiIiOhDxiRUBSJXpGPzsTBAFFFQ5ScRAEQRm4+FQa5IL/3giIiIiIiIiOiDxiRUBXL51m2kZ2YWmIBSEgGkZ2Yi4nZ0aYZFRERERERERBUAk1AVhCiKOBt5s1hjz1y/wV3ziIiIiIiIiOitMAlVQaQpFKpd8IoqITkZcoWihCMiIiIiIiIiooqk3CWhfvjhBzg4OEBPTw9NmzbF+fPn8+3/4sULDB06FDY2NpBKpXB2dsbBgwffUbTvj/SM/AuRF0TxluOJiIiIiIiIqGKTlHUAr9u6dSvGjBmDFStWoGnTpvj+++/h6+uLqKgoWFlZ5eqfnp6OTz75BFZWVti+fTuqVq2Ke/fuwdTU9N0HX87p6rzdj1r6luOJiIiIiIiIqGIrV5mFRYsWYeDAgejfvz8AYMWKFThw4ADWrFmDSZMm5eq/Zs0aJCQk4PTp09DR0QEAODg4vMuQ3xv6UinMjYyKtSTP3MgIMqm0FKIiIiIiIiIiooqi3CzHS09Px8WLF+Hj46Nq09LSgo+PD86cOaNxzN69e+Hu7o6hQ4eicuXK+OijjzBnzhxkZWXleR2FQoGkpCS1R0UgCAKa1aldrLHudV0gCEIJR0REREREREREFUm5SUI9e/YMWVlZqFy5slp75cqVERcXp3HMnTt3sH37dmRlZeHgwYMICQnBwoUL8fXXX+d5nblz58LExET1sLW1LdH7KM9cnRyhK5GgsOkkAYCuRIKGjjVLMyyiiik9Hoj9PudPIiIiIiKiCqDcJKGKIzs7G1ZWVvjll1/w8ccfo3v37pg6dSpWrFiR55jJkyfj5cuXqsf9+/ffYcRlSybVRU9vT0AQCkxECQAgCOjp7QmZVLf0gyOqaNLjgQdLmIQiIiIiIqIKo9zUhKpUqRK0tbXx5MkTtfYnT57A2tpa4xgbGxvo6OhAW1tb1ebi4oK4uDikp6dDVzd38kQqlUJagesbOVWrioC23th8LAzpmXnveKcjkaCntyecqlV9h9ERERERERER0Yeq3MyE0tXVxccff4xjx46p2rKzs3Hs2DG4u7trHNOiRQvcvn0b2dnZqrZ///0XNjY2GhNQFUIhlvg4VauK8T26okOzJjA3MlI7Zm70/+3dd1iV9f/H8ddhg4CKCeTE1HKkOXLlV81R5ir3zK1pDjSz1Fy/0pzlypkj09yZliNLzT3LkTND00ANFzJEZN6/P4gTOAE5ngM+H9fFpd7jnDfenMN9v87787k91KByRX3YpgUBFAAAAAAAyDA2E0JJ0oABAzR37lx9/fXXOn36tN59911FRkaa75bXoUMHDRkyxLz9u+++q5CQEPXr109//vmnNmzYoDFjxqh3797W+hasL5VDfFydnVSlZHG916KJutR7TZLUpd5req9FE1UpWVwuT2uIB6RRcMhtjVl2RMEht61dCgAAAADYNJsZjidJrVq10rVr1zRixAgFBwerTJky2rRpk3my8sDAQNnZ/Zeb5c+fXz/99JPee+89lS5dWnnz5lW/fv00aNAga30LmY7JZJKLU+LwRBcnZ+6CB6RR8M3bGrf8qOpXzC9fLzdrlwMAAAAANsumQihJ6tOnj/r06XPfddu3b79nWZUqVbR//34LVwUAAAAAAIDHYVPD8QAgMzEMQ2GRMZKksMgYGYZh5YoAAAAAwHbZXCcUANi60FvRWrrtrOasP63zwRGSpEbDf1IhXw/1aFhcbWsWUQ73p/cunICtMQxDIRHRuhUVK3dXR3l5MPwcAADAGgihACANthy+pPbjf9Ht6Lh71l24EqEh8w9q1DeHtXhQLdUpxx0mAWu6X2AsicAYAADAShiOBwCptOXwJbUYtVlR0XEyDOnu0XdJy6Ki49Ri1GZtOXzJOoXisRiGoRvhd/T3lQjdCL/DMMtMasvhSyredaWGzD+oC1ciUqxLCoyLd13J6xQAAOAJohMKAFIh9Fa02o//RYZhKOERmUSCIdnJUPvxv+j0/JZ0WmQSdM1kHUmBsWEY94TF0n8BclJgvGr4a3QuAgAAPAF0QgFAKizddla3o+MeGUAlSTCk29FxWrbtnGULQ4agaybrSGtgbBiJgXHoregnUyAAAMBTjBAK8nBzVc2yL8nDzdXapQA2yTAMzVl/WkrHqKzZ608xnMvGMcwyayEwBgAAsF2EUJCHm5tqlysjDzc3a5cC2KSQiGidD45IcwZlGNL54AiFRNBhYavomslaCIwBAABsGyEUADzCrahYq+4Py6FrJmshMAYAALBthFAA8Ajuro5W3R+WQddM1kNgDAAAYNsIobISw5DiwhL/Hhd278QmANLFy8NZhXw9ZDKlbT+TKfHOal4e3FHNFtE1k/UQGAMAANg2QqisIC5cuvyVdPhV6dTbictOvZ3478tfJa4HkG4mk0k9GhZP1749G5aQKa3pFZ4IumayHgJjAAAA20YIldnd3CH9VkW6MEqKDkq5LjoocflvVRK3A5BubWsWkZuzg+xSeXFrZ5LcnB3UpmZhyxaGdKNrJushMAYAALBthFCZ2c0d0ukuUkKUEic1uXtQyb/LEqIStyOIAtIth7uzFg+qJZPJ9Mggys6UeDH8zeBayuFOZ4WtomsmayIwBgAAsF3pDqHi4+O1fPly9ejRQ02aNNHx48clSWFhYfruu+905cqVDCsS9xEXLp3ppfuHT3f7d5szvRiaBzyGOuXyatXw1+Tq7CCTSfeEF0nLXJ0d9O2I11S7bF7rFIpUoWsmayIwBgAAsF3pCqFCQ0NVtWpVtW3bVsuWLdMPP/yga9euSZLc3d3l7++vqVOnZmihuMvV1ck6oFLj346oa6stWRWQ5dUpl1en57fUuK6V5OfjkWKdn4+HxnWtpD8WtMr0AZSjR049W7OVHD1yWrsUi6JrJmsiMAYAALBNDunZafDgwTp58qR++uknlS1bVt7e3uZ19vb2at68uTZu3KgxY8ZkWKFIxjCkfxamb9/LCyXfTveekQNItRzuznq3UQn1bFhcIRHRuhUVK3dXR3l5OGeZ7hhHDy/lqd3G2mVYXFLXTItRm2UnQwkPyfXpmslckgLjZdvOafb6UzofHGFe5+fjoZ4NS6htrSLKns3JilUCAAA8XdIVQq1du1Z9+/bVa6+9phs3btyz/vnnn9fChQsftzY8SNxNKTowHTsaifvFhUqOWbu7AXgSTCaTcnm6KJeni7VLwWNI6pppP/4X3Y6Ok5SY9SdJyhVdnR30zeBadM1kIk9DYAwAAJCZpCuECgsLU6FChR64PjY2VnFxcekuCo8Qf/sx948khAKAZOiaydoIjAEAAGxDukKowoUL6/Dhww9c//PPP6tEiRLpLgqPYO/2mPtny5g6ACALoWsGAAAAsKx0TUzerVs3LViwQCtWrJDx75gFk8mk6OhoDR06VJs2bVKPHj0ytFAk45BTci4gKa0XRabE/RxyWKAoAMgakrpmCvp4KJenCwEUAAAAkEHS1QnVr18/nTx5Um3atFGOHDkkSW3bttWNGzcUFxenHj16qGvXrhlZJ5IzmaRnO0kXRqV93zydmJQcAAAAAAA8cekKoUwmk+bOnauOHTvq22+/VUBAgBISElS4cGG1bNlS1atXz+g6cTfvZlLgZ1JClKSH3M7JzE6yc5FyN7N0ZQAAAAAAAPdIVwiV5H//+5/+97//ZVQtSAsHT+mFmdLpLv8ueFgQ9W/nU7FZifsBAAAAAAA8YemaEwo2ImcNqfgCyc5ViUHT3cPs/l1m5yqV+ErKQYcaAAAAAACwjnR1QhUqVOiRE7WaTCadO3cuXUUhDXLWkF7eJ11bLV1eKEUH/rfOOX/iHFC5m9EBBQAAAAAArCpdIVSNGjXuCaHi4+P1999/a8+ePXrxxRdVtmzZDCkQqeDgKT3bWfLtJIXtk061k0oskbJXYRJyAAAAAABgE9IVQi1cuPCB637//XfVrVtX7dq1S29NSC+T6b+OJwdPAigAAAAAAGAzMnxOqJdeekk9evTQoEGDMvqhAQAAAAAAkElZZGJyHx8fnTp1yhIPjUdx8pby9Uv8EwAAAAAAwEakazjew9y4cUPz589Xvnz5MvqhkRpO3lKB/tauAgAAAAAAIIV0hVC1atW67/LQ0FD98ccfiomJ0eLFix+rMAAAAAAAAGQd6QqhEhIS7rk7nslkUqFChVSnTh116dJFxYoVy5ACAQAAAAAAkPmlK4Tavn17BpcBAAAAAACArMwiE5MDAAAAAAAAyaWqE2rRokXpevAOHTqkaz8AAAAAAABkLakKoTp16pTmBzaZTIRQAAAAAAAAkJTKEOr8+fOWrgMAAAAAAABZWKpCqIIFC1q6DgAAAAAAAGRhTEwOAAAAAAAAi0tVJ9T9BAcHa/78+Tp8+LDCwsKUkJCQYr3JZNLWrVsfu0AAAAAAAABkfukKoY4dO6ZXX31VUVFReuGFF3T8+HGVKFFCoaGhunTpkgoXLqz8+fNndK0AAAAAAADIpNI1HG/w4MFyd3fXmTNntGXLFhmGoalTpyooKEgrVqzQzZs3NW7cuIyuFQAAAAAAAJlUukKoPXv2qEePHipQoIDs7BIfImk4XosWLdSuXTt98MEHGVclAAAAAAAAMrV0hVAJCQny8fGRJOXIkUP29vYKCQkxry9VqpQOHTqUMRUCAAAAAAAg00tXCFWoUCGdP38+8QHs7FSoUCFt2bLFvH7v3r3KkSNHhhQIAAAAAACAzC/VIdTNmzfNf3/99de1atUq87/fffddzZs3T3Xq1FHt2rX19ddfq23bthlbKQAAAAAAADKtVN8dz9fXV/Xr11e7du30/vvvq02bNoqNjZWjo6P69++vyMhIrV69Wvb29ho+fLg++ugjS9YNAAAAAACATCTVIVTz5s31ww8/6IcffpCHh4eaNm2qdu3aqVatWjKZTBo2bJiGDRtmyVoBAAAAAACQSaV6ON6SJUt09epVffPNN6pWrZqWLFmi119/XXnz5tX777+vw4cPW7JOAAAAAFmYYRg6HXhTg+bu1+nAmzIMw9olAQAyWJomJnd1dVWbNm20bt06BQcHa+bMmSpatKimTJmiChUqqFixYho9erT++usvS9ULAAAAIAsJvRWtmetOqkzP1arUd61mrT+tSn3XqkzP1Zq57qRCb0Vbu0QAQAZJ193xJClnzpzq0aOHduzYocDAQI0bN05ubm4aMWKEihYtqldeeSUj6wQAAACQxWw5fEnFu67UkPkHdeFKRIp1F65EaMj8gyredaW2HL5kpQoBABkp3SFUcnnz5tUHH3ygr7/+Wm+99ZYMw9CBAwcy4qEBAAAAZEFbDl9Si1GbFRUdJ8OQ7h59l7QsKjpOLUZtJogCgCwg1ROTP0hgYKCWLl2qZcuW6cSJEzIMQ6+88oratWuXEfUBAAAAyGJCb0Wr/fhfZBiGEh4x9VOCIdnJUPvxv+j0/JbK4e78ZIoEAGS4dIVQ169f18qVK7V06VLt27dPhmGoWLFi+uSTT9SuXTv5+fllcJkAAAAAsoql287q9r8dUKmRYEi3o+O0bNs5vduohGWLAwBYTKpDqMjISK1Zs0ZLly7V1q1bFRsbq2effVb9+/dXu3btVK5cOUvWCQAAACALMAxDc9afltJx87vZ60+pZ8PiMplMGV8YAMDiUh1CeXt7686dO3J3d1fbtm3Vrl071apVS3Z2GTKtFAAAAICnQEhEtM4HRzx6w7sYhnQ+OEIhEdHK5eligcoAAJaW6hCqTp06ateund588025uPCmDwAAACDtbkXFPvb+hFAAkDmlOoT6/vvvLVkHAAAAgKeAu6ujVfcHAFgPY+kAAAAAPDFeHs4q5OuhtE7rZDJJhXw95OXB3fEAILMihAIAAADwxJhMJvVoWDxd+/ZsWIJJyQEgEyOEAgAAAPBEta1ZRG7ODrJLZZ5kZ5LcnB3UpmZhyxYGALAoQigAAAAAT1QOd2ctHlRLJpPpkUGUnSmxe+qbwbWUw52heACQmRFCAQAAAHji6pTLq1XDX5Ors4NMJt0zR1TSMldnB3074jXVLpvXOoUCADJMqu+OBwAAAAAZqU65vDo9v6WWbTun2etP6XxwhHmdn4+HejYsoba1iih7NicrVgkAyCiEUAAAAACsJoe7s95tVEI9GxZXSES0bkXFyt3VUV4ezkxCDgBZDCEUAAAAAKszmUzK5emiXJ4u1i4FAGAhzAkFAAAAAAAAiyOEAgAAAAAAgMURQgEAAAAAAMDibDKEmjFjhvz8/OTi4qJKlSrp4MGDqdpv+fLlMplMaty4sWULBAAAAAAAQJrYXAi1YsUKDRgwQCNHjtThw4f10ksvqW7durp69epD97tw4YIGDhyoatWqPaFKAQAAAAAAkFo2F0JNmjRJ3bt3V+fOnVWiRAnNnj1bbm5uWrBgwQP3iY+PV7t27fTxxx/rueeee4LVAgAAAAAAIDVsKoSKiYnRoUOHVKdOHfMyOzs71alTR/v27Xvgfp988om8vb3VtWvXRz5HdHS0wsPDU3wBAAAAAADAsmwqhLp+/bri4+Pl4+OTYrmPj4+Cg4Pvu8/u3bs1f/58zZ07N1XPMXbsWGXPnt38lT9//seuGwAAAAAAAA9nUyFUWkVERKh9+/aaO3eunnnmmVTtM2TIEIWFhZm/goKCLFwlAAAAAAAAHKxdQHLPPPOM7O3tdeXKlRTLr1y5Il9f33u2P3funC5cuKBGjRqZlyUkJEiSHBwcdObMGRUuXDjFPs7OznJ2drZA9QAAAAAAAHgQm+qEcnJyUvny5bV161bzsoSEBG3dulVVqlS5Z/tixYrp+PHjOnr0qPnrzTffVM2aNXX06FGG2gEAAAAAANgIm+qEkqQBAwaoY8eOevnll1WxYkVNmTJFkZGR6ty5sySpQ4cOyps3r8aOHSsXFxe9+OKLKfbPkSOHJN2zHAAAAAAAANZjcyFUq1atdO3aNY0YMULBwcEqU6aMNm3aZJ6sPDAwUHZ2NtXABQAAAAAAgEewuRBKkvr06aM+ffrcd9327dsfuu/ChQszviAAAAAAAAA8FlqKAAAAAAAAYHGEUAAAAAAAALA4QigAAAAAAABYHCEUAAAAAAAALI4QCgAAAAAAABZHCAUAAAAAAACLI4QCAAAAAACAxRFCAQAAAAAAwOIIoQAAAAAAAGBxhFAAAAAAAACwOEIoAAAAAAAAWBwhFAAAAAAAACyOEAoAAAAAAAAWRwgFAAAAAAAAiyOEAgAAAAAAgMURQgEAAAAAAMDiCKEAAAAAAABgcYRQAAAAAAAAsDhCKAAAAAAAAFgcIRQAAAAAAAAsjhAKAAAAAAAAFkcIBQAAAAAAAIsjhAIAAAAAAIDFEUIBAAAAAADA4gihAAAAAAAAYHGEUAAAAAAAALA4QigAAAAAAABYHCEUAAAAAAAALI4QCgAAAAAAABZHCAUAAAAAAACLI4QCAAAAAACAxRFCAQAAAAAAwOIIoQAAAAAAAGBxhFAAAAAAAACwOEIoAAAAAAAAWBwhFAAAAAAAACyOEAoAnjTDkOLCEv8eF5b4bwAAAADI4hysXQAAPDXiwqWrq6V/FkrRgYnLTr0tOReQnu0keTeTHDytWSEAAAAAWAydUADwJNzcIf1WRbowSooOSrkuOihx+W9VErcDAAAAgCyIEAoALO3mDul0FykhSpLx71dy/y5LiErcjiAKAAAAQBZECAUAlhQXLp3ppfuHT3f7d5szvRL3AwAAAIAshBAKACzp6upkHVCp8W9H1LXVlqwKAAAAAJ44QigAsBTDSJyEPD0uL+SueQAAAACyFEIoALCUuJv/3gUvrWGSkbhfXOh/SwxDUTHRkqSomGgZBFQAAAAAMhkHaxcAAFlW/O3H3D9SUQnZdCTgrPaf+kMhERGSpK9+3CwvDw9VLlFMZYsWkauzUwYUCwAAAACWRQgFAJZi7/ZYuwcER2rZjlWKiYu7Z11IRIQ2HvhVWw4dUZvar6povryP9VwAAAAAYGkMxwMAS3HIKTkXkGRK444mBURX0aJfDij2PgFUcrFxcVr081YFXLyU7jIBAAAA4EkghAIASzGZpGc7pXm3qHhnLfv7dckwHjmblCFJhqFlW7crKjomHUUCAAAAwJNBCAUAluTdTLJzVeq7oex0JLyCYuJNqZ7O3JAUExeno2fPpa9GAAAAAHgCCKEAwJIcPKUXZioxhHpUEGWSYUj7I+qm66n2nTzNXfMAAAAA2CxCKACwtJw1pOILknVE3R1G/bvMzlW3i8xTSOTD54F6kJCICEVFR6dYZhiGwsLDJElh4WGEVAAAAACshrvjAcCTkLOG9PI+6dpq6fJCKTrwv3XO+aU8naTczRQTZScp8AEP8mjRsXFyc5HCw8P13ZrvtPibxQoMTHy8jp06qkCBAmr/dns1bdJUnp6ej/UtAQAAAEBamIyn/GPx8PBwZc+eXWFhYVyQAXgyDEMK2yedaieVWCJlr5I4ibmkyDt3NHbJinQ/9EftWunQr7+qj38fRUVF/ft0/73Nm/59HldXV02fNl3VqlV7jG8EAABkZlwLAXjSGI4HAE+ayZQ4V5SU+Kfpv+F5bs7O8vLwSNfDenl46LeDB9XtnW6KioqSYRj3DL9LWhYVFaVu73TTrl270v1tAAAAAEBaEEIBgA0xmUyqXKJYuvYt7Zdfffv1vW/4dLekbfr491F4eHi6ng8AAAAA0oIQCgBsTNmiReTk4PDIe+klMUlycnDQ+ePHzB1QqZHUEbVm7Zp01woAAAAAqUUIBQA2xtXZSW1qvyqZTI8MokySZDKpda0aWr58abqeb9HiRdw1DwAAAIDFEUIBgA0qmi+vOrxeW44OD7+JqaODgzq8XlvPZHNTYGBgmsMkwzAUGBio0NDQx6gWAAAAAB7t4Vc3AACrKZovrz5o3UJHz57TvpOnFRIRYV7n5eGhKiWLq2zRwnJxctLFixcf67kiIyOVM2fOxy0ZAAAAAB6IEAoAbJirs5OqlCyuyiWK6fw//2jBj5vVpd5rKvTsszIlv6uem9tjPU+2bNket1QAAAAAeCiG4wFAJmAymeTi5CxJcnFyThFASVLOnDlVoECBe5an5nELFCigHDlyZFSpAAAAAHBfhFAAkAWYTCa1f7t9uvbt0L5DmsMrAAAAAEgrQigAyCKaNmkqV1fXVAdKdnZ2cnV1VZPGTSxcGQAAAAAQQgFAluHp6anp06bLZDI9MohKWj/9i+ny9PR8EuUBAAAAeMoRQgFAFlKtWjXN+3KeuSPq7jAqaZmrq6vmzZ2nav+rZqVKAQAAADxtuDseAGQx1apV064du7Rm7RotWrxIgYGB5nX58+dXh/Yd1LRJU3l4eFixSgAAAABPG0IoAMiCPD091bFDR3Vo30H79+9Xh04dtGjhIlWuXJlJyAEAAABYBcPxACALM5lM5jmfPD09CaAAAAAAWA0hFAAAAAAAACyOEAoAAAAAAAAWZ5Mh1IwZM+Tn5ycXFxdVqlRJBw8efOC2c+fOVbVq1ZQzZ07lzJlTderUeej2AAAAAAAAePJsLoRasWKFBgwYoJEjR+rw4cN66aWXVLduXV29evW+22/fvl1t2rTRtm3btG/fPuXPn1+vv/66Ll269IQrBwAAAAAAwIPYXAg1adIkde/eXZ07d1aJEiU0e/Zsubm5acGCBffdfsmSJerVq5fKlCmjYsWKad68eUpISNDWrVufcOUAAAAAAAB4EJsKoWJiYnTo0CHVqVPHvMzOzk516tTRvn37UvUYt2/fVmxsrLy8vO67Pjo6WuHh4Sm+AAAAAAAAYFk2FUJdv35d8fHx8vHxSbHcx8dHwcHBqXqMQYMGKU+ePCmCrOTGjh2r7Nmzm7/y58//2HUDAAAAAADg4WwqhHpc48aN0/Lly7VmzRq5uLjcd5shQ4YoLCzM/BUUFPSEqwQAAAAAAHj6OFi7gOSeeeYZ2dvb68qVKymWX7lyRb6+vg/d97PPPtO4ceO0ZcsWlS5d+oHbOTs7y9nZOUPqBQAAAAAAQOrYVCeUk5OTypcvn2JS8aRJxqtUqfLA/SZMmKBRo0Zp06ZNevnll59EqQAAAAAAAEgDm+qEkqQBAwaoY8eOevnll1WxYkVNmTJFkZGR6ty5sySpQ4cOyps3r8aOHStJGj9+vEaMGKGlS5fKz8/PPHeUu7u73N3drfZ9AAAAAAAA4D82F0K1atVK165d04gRIxQcHKwyZcpo06ZN5snKAwMDZWf3XwPXrFmzFBMTo+bNm6d4nJEjR+r//u//nmTpAAAAT1RsRIiuHfxJuSvWlaPH/e8MDAAAYCtsLoSSpD59+qhPnz73Xbd9+/YU/75w4YLlCwIAALBBsRE39c+2FcpRvCIhFAAAsHk2NScUAAAAAAAAsiZCKAAAAAAAAFgcIRQAAAAAAAAsjhAKAAAAAAAAFkcIBQAAAAAAAIsjhAIAAAAAAIDFEUIBAAAAAADA4gihAAAAAAAAYHGEUAAAAAAAALA4QigAAAAAAABYHCEUAAAAAAAALI4QCgAAAAAAABZHCAUAAAAAAACLI4QCAAAAAACAxRFCAQAAAAAAwOIIoQAAAAAAAGBxhFAAAAAAAACwOEIoAAAAAAAAWBwhFAAAAAAAACyOEAoAAAAAAAAWRwgFAAAAAAAAiyOEAgAAAAAAgMURQgEAAAAAAMDiCKEAAAAAAABgcYRQAAAAAAAAsDhCKAAAgEzIMAzFRUVKkuKiImUYhpUrAgAAeDgHaxcAAACA1IuLuqUbR7bp2v4Nig4JliQFfDVCzl6+yl25gXKVrSkHV3crVwkAAHAvQigAAIBMIizgiP5aNl4JMdH3rIsOuaKLGxfo8pYleq7NIGUvWtYKFQIAADwYw/EAAAAygbCAIzq7aJQSYqMlGf9+JZe4LCE2WmcXjVJYwJEnXyQAAMBDEEIBAADYuLioW/pr2XhJhvSouZ+MxDDqr2XjFRd160mUBwAAkCqEUAAAPCViI0J0eesyxUaEWLsUpNGNI9sSh+CldvJxw1BCTLRCjm63aF0AAABpQQgFAMBTIjbipv7ZtkKxETetXQrSwDAMXdu/QfcOv3u0q/vWc9c8AABgMwihAAAAbFj87QjzXfDSxlB0SLDioyIyvCYAAID0IIQCAACwYfExUY+3f/Tj7Q8AAJBRCKEAAABsmL2T6+Pt7/x4+wMAAGQUQigAAAAbZu/mIWcvX0mmNO5pkrOXr+xdPSxRFgAAQJoRQgEAANgwk8mk3JUbpGtf7yoNZTKlNbwCAACwDEIoAAAAG5erbE3ZOTlLqQ2UTCbZOTnLq8yrFq0LAAAgLQihAAAAbJyDq7ueazNIkunRQZTJJMmkwm0GycHV/UmUBwAAkCqEUAAAAJlA9qJlVaTDcNk5Oitxfqi7w6jEZXaOziraYbg8i5Z98kUCAAA8hIO1CwAAAEDqZC9aVqU+mKeQo9t1dd96RYcEm9c5e/nIu0pD5SpbU/Yu2axYJQAAwP0RQgEAAGQiDq7u8q7SULkrN1DE+eMKWDBCRbt8Io9CpZiEHAAA2DSG4wEAAGRCJpNJDv92PDm4ZCOAAgAANo9OKAAAngKGYSguKlKSFBcVKcMwCC2QaRmGoZCIaN2KipW7q6O8PJz5eQYAIBMghAIAIAuLi7qlG0e26dr+Deb5gwK+GiFnL1/lrtxAucrW5A5qyDRCb0Vr6bazmrP+tM4HR5iXF/L1UI+GxdW2ZhHlcHe2YoUAAOBhCKEAAMiiwgKO6K9l45UQE33PuuiQK7q4cYEub1mi59oMUnbupAYbt+XwJbUf/4tuR8fds+7ClQgNmX9Qo745rMWDaqlOubxWqBAAADwKc0IBAJAFhQUc0dlFo5QQGy3J+PcrucRlCbHROrtolMICjjz5IoFU2nL4klqM2qyo6DgZhmTc9eOctCwqOk4tRm3WlsOXrFMoAAB4KEIoAACymLioW/pr2XhJ97lav5uRGEb9tWy84qJuPYnygDQJvRWt9uN/kWEYSnjEj3OCkThfVPvxvyj01r0dgAAAwLoIoQAAyGJuHNmWOATvUQFUEsNQQky0Qo5ut2hdQHos3XZWt6PjHhlAJUkwpNvRcVq27ZxlCwMAAGlGCAUAQBZiGIau7d+ge4ffPdrVfetlpDa4Ap4AwzA0Z/3p9Pw4a/b6U/w8AwBgYwihAADIQuJvR5jvgpc2hqJDghUfFfHoTYEnJCQiWueDI9KcQRmGdD44QiERDMkDAMCWEEIBAJCFxMdEPd7+0Y+3P5CRbkXFWnV/AACQsQihAMAanLylfP0S/wQykL2T6+Pt7/x4+wMZyd3V0ar7AwCAjEUIBQDW4OQtFehPCIUMZ+/mIWcvX0mmNO5pkrOXr+xdPSxRFpAuXh7OKuTrIVMaf5xNJqmQr4e8PJwtUxgAAEgXQigAALIQk8mk3JUbpGtf7yoNZUrr1T5gQSaTST0aFk/Xvj0bluDnGQAAG0MIBQBAFpOrbE3ZOTkr1e0jJpPsnJzlVeZVi9YFpEfbmkXk5uwgu1T+ONuZJDdnB7WpWdiyhQEAgDQjhAIAIItxcHXXc20GSTI9OogymSSZVLjNIDm4uj+J8oA0yeHurMWDaslkMj0yiLIzJXZPfTO4lnK4MxQPAABbQwgFAEAWlL1oWRXpMFx2js5KnB/q7qv3xGV2js4q2mG4PIuWffJFAqlUp1xerRr+mlydHWS6T7aatMzV2UHfjnhNtcvmtU6hAADgoRysXQAAALCM7EXLqtQH8xRydLuu7luv6JBg8zpnLx95V2moXGVryt4lmxWrBFKnTrm8Oj2/pZZtO6fZ60/pfHCEeZ2fj4d6NiyhtrWKKHs2JytWCQAAHoYQCgCALMzB1V3eVRoqd+UGijh/XAELRqhol0/kUagUkzYj08nh7qx3G5VQz4bFFRIRrVtRsXJ3dZSXhzM/zwAAZAKEUAAAPAVMJpMc/u14cnDJxgU7MjWTyaRcni7K5eli7VIAAEAaMCcUAABABjEMQ1du3tSGfQd15eZNGYZh7ZIAAABsBp1QAAAA92MYUtxNKf62ZO8mOeR84N0Go6JjdCTgrPaf+kMhEYlzFe07dVpeHh6qXKKYyhYtIldn5ioCAABPN0IoAACsxDAM3Y6OVkxsnJwcHeTmzLw2NiEuXLq6WvpnoRQd+N9y5wLSs50k72aSg6d5ccDFS1q2dbti4uLueaiQiAhtPPCrthw6oja1X1XRfNy1DQAAPL0IoQAAeFxp6JiR7t81I4muGVtwc4d0ppeUEHXvuugg6cIoKfAz6YWZUs4aCrh4SYt+3pr4M/AQsXFxWvTzVnV4vfZ9gyjDMHTz5k3dvn1bbm5uypkzJ4GkJaTxtQoAADIWIRQAAOmVxo4Z6fG7ZggrLOjmDul0F0nGv193+3dZQpR0uouiCs/Vsq3/SIZx363v3tNkGFq2dbs+aN3CHDKGh4fruzXfafE3ixUY+N/PUIECBdT+7fZq2qSpPD09H/CoSLV0vFaTe5Jdi4ZhKP52hOJjomTv5Cp7Nw9e4wCALIMQCgCA9Ehjx4ykx+qaIaywsLjwxOP5wAAqucT1R35bqJi42ql+CkNSTFycjp49pyoli2vXrl3q499HUVH3/gwFBQVpzNgxmjxlsqZPm65q1aql+nlwl3S8VpM8TtdiWgPjuKhbunFkm67t36DokGDzcmcvX+Wu3EC5ytaUg6t7Gr95AABsC3fHAwAgrZI6ZhKidP/Q4t9l/3bM6OYORUXHaNnW7anumtG/XTNR0THatWuXqtWopjFjxygoKCjFtklhRbUa1bRr164M+gafQldXJzuej2YYhvbfKJvq7ZPbd/K0du7cqW7vdFNUVJQMw7jnLnpJy6KiotTtnW4c2/RKx2s1ScDFS5q4fJU2Hvg1RQAl/de1OHH5KgVcvJRiXXh4uBZ+vVB1Xq+jSlUqqWbtmqpUpZLqvF5HC79eqPDw8HvKDAs4ouMTu+nixgWKDrmSYl10yBVd3LhAxyd2U1jAkcf4zwAAwPoIoQAASIs0d8wY0pleOnLmhGLi4lIdWSR1zSxatYqwwtIMI3GYVhrcjndTSKyXpLQPkwq+dk19/Pvc93jeW1riNn38+9w3vMBDpPO1qrhwc9di7H2GzSaX1LWYFESlJzAOCziis4tGKSE2+gG1Ji5LiI3W2UWjCKIAAJkaIRQAAGmRxo4ZyZARH6X9J4+l+ali7tzRlPFjCCssLe7mv/MEpb6rKSYh/RPHXzhxTHfu3HnkMU2SFDKuWbsm3c/5VErHa1UJUYq6vDpdXYtbfvklzYFxXNQt/bVsfOIjPernwUgMo/5aNl5xUbdS+T0BAGBbbDKEmjFjhvz8/OTi4qJKlSrp4MGDD91+1apVKlasmFxcXFSqVClt3LjxCVUKAHiqpKNjRpJux7sq5HbaO2YunDimuJgYwgpLi7+d5l2c7GLS9VSGYejPw7+ma99Fixfd87Pg6JFTz9ZsJUePnOl6zCwrna9VSTpy6mCauxZv3bql/u/1S3NgfGnfj0qIiX50APXfzkqIiVbI0e2prA4AANticyHUihUrNGDAAI0cOVKHDx/WSy+9pLp16+rq1av33X7v3r1q06aNunbtqiNHjqhx48Zq3LixTpw48YQrBwBkeenomJHS1zWT0WEFHsLeLc27uNnflpdjiKSENO0XExWlyNCbaT4+hmEoMDBQoaGhKZY7engpT+02cvTwStPjZXnpfK0ahqH9V59P89NdOHFM0enobru0a22aa5Skq/vW8xoHAGRKNhdCTZo0Sd27d1fnzp1VokQJzZ49W25ublqwYMF9t586dareeOMNffDBBypevLhGjRqlcuXKafr06U+4cgBAlpeOjhkpfV0zSWFFWj0orJDomnkgh5yScwGlZX4nk0mq7HUwTftIUlxs+jqokkRGRj7W/k+NdL5W/5vrK/XSGxh7ONnLOTY9x9NQdEiw4qMiHr0pAAA2xqZCqJiYGB06dEh16tQxL7Ozs1OdOnW0b9++++6zb9++FNtLUt26dR+4fXR0tMLDw1N8AQCQKunomJGSd82kniXCCrpmHsBkkp7tlObdymY/Kif71MdQJkmurq5pfp7ksmXL9lj7PzXS+VpNT9diegNjZ/u0D9FNLj466rH2BwDAGmwqhLp+/bri4+Pl4+OTYrmPj4+Cg4Pvu09wcHCath87dqyyZ89u/sqfP3/GFA8AFubh5qqaZV+Sh1vaLmJz586tvn36Knfu3Baq7CmSjo4ZSTKZTKrs/Wfansox/RNfS4QVaebdTLJzVeqPrZ1cHe3UpmZVyWR65F4mSTKZ1KlhfRUoUEAmU9p/hgoUKKAcOXKkab+nVjpfq+npWkxvYHwnLm1DOe9m7/x4gSYAANZgUyHUkzBkyBCFhYWZv+6+fS4A2CoPNzfVLldGHm5p+4Tf29tb/n395e3tbaHKniLp7JiRpLIlKsrJwSHVl8TOrq5yz5GTsOJJcfCUXpipxNAiVZGSVGyWihYsqg6v15ajg8ND93B0cFCH12vr+fz51P7t9ukqsUP7Dmn+eXhqpfO16mYfJS+3tM21lN7AOCImXsG3opXWoEwyydnLV/auHul6XgAArMmmQqhnnnlG9vb2unLlSorlV65cka+v73338fX1TdP2zs7O8vT0TPEFAECqpaNjRnaucs3TTG1qv5rqrhmTnZ3atm2XrhIJK9IpZw2p+IJkx/fu/8N/l9m5SiW+knJUlyQVzZdXH7RuoQaVK8rLI2Uw4OXhoQaVK+rDNi1UNF9eSVLTJk3l6uqa6mNkZ2cnV1dXNWnc5PG+v6dNOl6rJntXVS5ZOk1P4+TqqmzpDIwPXE/f5OLeVRryGgcAZEo2FUI5OTmpfPny2rp1q3lZQkKCtm7dqipVqtx3nypVqqTYXpI2b978wO0BAHgs6eyYkYOniubLm6aumR6dOxNWPGk5a0gv75MKDZec7xqy75w/cfnL+8wBVBJXZydVKVlc77Vooo/atdL7LZvpo3at9F6LJqpSsrhcnP7rlvH09NT0adNlMpkeeWyT1k//YjofnKVVOl+rZV94MU1di3Ymk4q/XCldJRat3Ux2Ts6JnVupYTLJzslZXmVeTdfzAQBgbSbDxu7vumLFCnXs2FFz5sxRxYoVNWXKFK1cuVJ//PGHfHx81KFDB+XNm1djx46VJO3du1c1atTQuHHj1KBBAy1fvlxjxozR4cOH9eKLLz7y+cLDw5U9e3aFhYVxcgcASL2bO6QzvaSEpMmBk/86/feC0s41MYC6K7CIio7R0bPntO/kaYVE/HeHKy8PD1UpWVxlixY2hxa7du1St3e6yTCMh96SPSnQmDd3nqr9r1pGfIcwDCkuVIqPlOyzSQ45Uh8WpMKuXbvUx7+PoqKi/n26/45vUvjk6uqq6V9M55g+jnS8VgMuXtKin7dKhqGHnSgnzfXV9JWK6tSmlaKioh76Ok1iZ2cnFxcX7dqxS8aVczq7aFRiXQ/b15QYphXtMFyeRcs+8jmA1OBaCMCTZnMhlCRNnz5dEydOVHBwsMqUKaNp06apUqXET5heffVV+fn5aeHChebtV61apWHDhunChQsqWrSoJkyYoPr166fquXjjBQCkW1y4dG21dHmhFB3433LnAlKeTlLuZondGA9gGIaioqMVHRsnZ0cHuTo737czhrAi6woPD9eatWu0aPEiBQb+9zNUoEABdWjfQU2bNJWHB3P/PLZ0vFYDLl7Ssq3bFRMX98CHdXJwUJvar6povryPFRiHBRzRX8vGKyEm+t+t7g3K7JycVbjNIAIoZCiuhQA8aTYZQj1JvPECAB6bhTtmJMKKrM4wDIWGhioyMlLZsmVTjhw5mPPHEtL4Wk1L16L0eIFxXNQthRzdrqv71is65L+7PDt7+cq7SkPlKltT9i7c9RIZi2shAE8aIRRvvACATISwAnjyUtu1KD1+YGwYhuKjIhQfHSV7Z1fZu3rwGofFcC0E4EkjhOKNFwAAABmMwBiZAddCAJ60h9+eBwAAAECamUwm5cyZUzlz5rR2KQAA2Aw7axcAAAAAAACArI8QCgAAAAAAABZHCAUAAAAAAACLI4QCAAAAAACAxRFCAQAAAAAAwOIIoQAAAAAAAGBxhFAAAAAAAACwOEIoAAAAAAAAWBwhFAAAAAAAACzOwdoFWJthGJKk8PBwK1cCAAAAAE9O0jVQ0jURAFjaUx9CRURESJLy589v5UoAAAAA4MmLiIhQ9uzZrV0GgKeAyXjKY++EhARdvnxZHh4eMplM1i7HKsLDw5U/f34FBQXJ09PT2uUgg3Bcsx6OadbEcc16OKZZE8c16+GYJnZARUREKE+ePLKzY6YWAJb31HdC2dnZKV++fNYuwyZ4eno+tb+AszKOa9bDMc2aOK5ZD8c0a+K4Zj1P+zGlAwrAk0TcDQAAAAAAAIsjhAIAAAAAAIDFEUJBzs7OGjlypJydna1dCjIQxzXr4ZhmTRzXrIdjmjVxXLMejikAPHlP/cTkAAAAAAAAsDw6oQAAAAAAAGBxhFAAAAAAAACwOEIoAAAAAAAAWBwhFAAAAAAAACyOECoLY855AACAh+N8KWtJSEgw/z0+Pt6KlQAA7ocQKou6cOGCpk2bpmHDhunSpUvWLgcZJOnEihNmwLbt2bMnxYUQsh7eh7OGhIQEmUwmSdLly5etXA0ygp1d4uXN4MGD9eGHH/JaBQAbQwiVBR0/flyvvfaajh8/roiICOXOndvaJSGDJJ1YBQUFWbkSAA9y9OhRVatWTaNGjSKIyiKSLmJv3Lih0NBQRUVFmYMLZF6GYZh/r3744Yfq0qWLwsPDrVwV0it52LRp0yZ9//33atGiBa9VALAxhFBZzJ9//qlatWqpRYsWmjNnjqZOnSonJyc+BcpC1q9fr1deeUUXL160dinIQLxGs44yZcpo9uzZGjNmjMaMGUMQlckZhiGTyaR169apfv36qlGjhl588UXNmzdP//zzj7XLQzolHVdJ2r17t3bv3q1PPvlEnp6eVq4M6ZV0PDds2KDvvvtOTZo0UeXKlRmSBwA2hhAqC4mNjdXnn3+uN954Q8OGDZO9vb15HZ8CZR2urq7y9PQ0DxvgAjdzSwqfoqKi7rscmcfcuXO1d+9eJSQk6J133tGMGTM0cuRIgqhMzmQy6aefflLr1q3VqlUrrVu3Tm+88YZ69+6t06dPW7s8pFPSedGKFSs0a9YsFSlSRBUrVlRcXJyVK8PjCA4O1ogRI7R48WJz17i9vT3vwQBgQwihshBHR0ft27dPhQsXlpub2z3rk34B37lz50mXhnS630lT7dq1VbBgQX3wwQeS/huih8zJZDLpxx9/VKtWrdSsWTPNnj1bkZGRMplMBFGZiGEY+vjjj9WlSxcdPnxYCQkJ6tatm+bMmUMQlYnFx8crLi5OixYtUq9evTRgwADZ29tr8+bN6tSpk2rVqmXtEvEYDMPQunXrtH79eh0/flwJCQlycHDgtZqJJP2eTPrT19dXCxYsULVq1bRv3z6tWrVKUuK5Er9TAcA2cPWaRcTFxSk4OFgXL15UkSJFzMuSSworpkyZohs3bjzxGpF2Scfs9u3bKZYPHz5ct27d0pYtWyTRNZOZ7d27V2+99ZaKFCmikJAQff311+rTp48iIiIIojKJpGE958+fl6urqzp16qRDhw4RRGViSa+7O3fuyMHBQX///bdef/11RUZGqmLFiqpZs6bmzJkjSfrmm2905swZa5aLVLr7/dRkMmnhwoXq1q2brl+/rlGjRunWrVsEFplE8knlQ0NDFR0drTt37uill17S+PHjVaBAAS1YsEDr1q2TlHi8eQ8GAOsjhMrkrl27JklycHCQt7e3SpcurS+//FJXr16Vg4PDPSdRx44d0w8//KCbN29ao1ykw5w5c1S0aFF98skn5gudUqVKydHRUWvWrJHEcMvMKiAgQHv37tW4ceM0efJkbdmyRW3bttWZM2fUu3dvcxDFSbNtM5lMiouLk6Ojow4ePCiTyaTOnTsTRGViJpNJy5cvV+3atSVJRYsW1cSJE1WiRAk1btxYX3zxhaTEDwhWr16tdevWcVxtXPLA4ty5c7p8+bICAwPl4OCgcePGqVGjRlq/fr1mzZql27dv895r45JPKj927Fg1adJE//vf/9S0aVP98ccfKlu2rD7//HNFR0dr1qxZWr9+vSS6xwHAFvBOnIlFRESoTJkyeueddyQl/mKtU6eOjhw5opkzZ+rGjRv3hBOrV6+Wp6cnd8yzYclPeu/cuaNmzZqpffv2OnDggMqXL69Bgwbpzz//1MSJE7V69WodOHDAitUivQICAtStWzdNmzZNOXPmlJQ4b0WPHj3Utm1bBQQEyN/fX+Hh4Zw0ZwIODg6KjY2Vo6OjDh8+/MAgavTo0Ro6dCgXtzYq6YOboKAgzZw5U+3atZMktWjRQv/88488PT31xRdfyMnJSZL06aef6tixY2ratCmvUxuWPLAYPny4mjZtqgoVKuj111/XlClT5OjoqKlTp6p8+fL69ttvNXPmTHNHFGxT0vnt8OHD9fnnn6tVq1Zq1KiR4uPjValSJW3fvl1ly5bV+PHjFRsbq08++UR79uyxctUAAEmSgUwrLi7OWLBggeHu7m74+/ublzdq1MhwcnIy+vbtawQEBBiGYRinTp0y/P39DS8vL+PYsWPWKhmPEB8fb/77hAkTjKFDhxrnz583DMMwbt26ZSxevNho2LChUbBgQaNChQpG3rx5jSlTphiGkfjzgMwjPDzcGDhwoJEnTx6jefPmRkJCgnldTEyMMXPmTKNYsWJGz549U6yDbXnQsYmJiTFKlixplCxZ0jh48KD5tT1t2jQjV65cxrVr155kmUiDQ4cOGd26dTOaNGlihIaGGoZhGFFRUcbo0aONUqVKGZUrVzb69OljNG3a1PDy8jIOHz5s5YqRWp9++qnh5eVlrF+/3li5cqUxatQow97e3vjoo48Mw0h83b777ruGn5+fsWTJEitXi/tJ/p4bFBRklC5d2li+fLl52a1bt4xOnToZ2bNnNy5dumQYhmEcOHDA6Nu3b4pzLACA9ZgMg0HvmVl8fLxWrlypzp07q3v37uYhAm+//bZ++eUXhYWFydfXVx4eHoqPj9fixYtVpkwZ6xaNRxo0aJAWLlyosWPH6o033lCePHnM60JCQnT58mWNGjVKBw4ckGEY+v3335UjRw7rFYxHMpLdDjzJrVu3NHHiRH3//fd64403NGrUKDk6OkpKvNvlwoUL9dprr8nPz88KFeNRko7pjh07tGvXLl24cEHdunXT888/Ly8vL8XGxqps2bKSpIULF6pcuXKys7NTaGgor1cbFRsbqw8++EDffvutsmXLlmKup6ioKG3btk0rV65UaGioihYtqm7duumFF16wYsV4mOTvu1FRUXrzzTdVv359vffee+ZtlixZovbt2+ubb75R27ZtFRsbq6lTp+q9995LcZdhWF9CQoK5Oy0sLEyxsbHy8/PThg0bVKNGDfP6a9euqW7dumrevLkGDx6coqMt+WMAAKyDECqTSTqhio+PN58cxcfHa8WKFeratau6du2q6dOnS5K2bt2qM2fO6OrVq6pQoYLKlSunZ5991prlIxV+/PFHvfPOO/ruu+9UoUIF8/K7T5wSEhJ06NAh9e/fX23btlXv3r3vG3TA+pKOy4EDB7R//37Fx8erXLlyevXVVxUZGamxY8dq8+bNqlmzpkaPHi0HBwdrl4xUWrNmjbp06aLq1asrNjZWBw8e1KBBg9SiRQv5+fkpNjZWFSpU0LVr17Ru3TqVK1fO2iXjPpK/d167dk2TJ0/WnDlz1KVLF02YMIH31Uwo+TE9efKkSpYsqbx586pPnz4aMmSIpP+Gv7dv31729vb68ssv5eLiYn6M5OdasK7kx/PDDz/UxYsXtXDhQtWqVUvFixfX9OnT5ezsLMMwFB8fr1dffVWvvPKKJkyYYOXKAQB346OATCQwMFCDBg1SaGio7O3tFR8fLylxHplWrVppwYIFmjt3roYNGyZJql27tnr16qX/+7//U4MGDQigMokrV67I19dXxYoVMx9j49/5LJLf8dDOzs4cLP7666+SmKDcVplMJq1evVqvv/66li9frsWLF6tWrVoaNmyYXF1dNWTIENWpU0e7d+9W//7977mzJWzTgQMH1LdvX02aNEnff/+91q9fr/DwcE2aNEkLFy5UUFCQebLyggUL0v1kg5I+h7t586bu3LmjkJAQ5c6dWwMHDlSXLl20Y8cOffLJJ+btY2Nj79kXtid5YDF48GB17NhRt27dUvPmzbVhwwadOnVKUuLvUTs7O3l4eCgsLCxFACWJAMpGJD+e27dv19atW+Xv7y9HR0c1bNhQp06d0tSpUyUpxV1lk+ZbBADYFj5uz0TWrFmjdevW6c6dOxo9erQ8PT3Nn9LZ29urSZMmunbtmiZMmKCGDRuqcuXK1i4Z6XDp0iUFBQXJw8NDkhQXFycHBwclJCRo9+7d5oDKMAzZ29vL29tb586dU3R0tJycnAiibNCff/4pf39/ff755+rSpYvi4uLM3Yv29vb6+OOPNWjQIEVGRurkyZMKCQmRt7e3tcvGQyQkJCgwMFBvv/22OnfurPPnz6tmzZp69913lStXLn388cdydHRUq1atVKRIEe3du9faJeMuSRe2P/zwgyZMmKDw8HA5ODho4MCBatu2rYYOHSrDMLRx40bZ29tr2LBh5uGyEqG/LUs6NgcOHNChQ4c0ffp0ubu7q06dOjp8+LB5uF2xYsUUGRmps2fPqnjx4lauGveTPIBas2aN1q5dq0qVKpnPcf39/XX58mUtX75cP/zwg6pWrardu3crNDRUH3zwgTVLBwA8AJ1QmUjv3r3VuXNn/frrrxoyZIjCw8NTdES5uLiofv36MgxD//zzj5WrxaM86O5YjRs3VrZs2TRgwAAZhmEemhUREaExY8Zo3759khJPso8ePaoDBw5o/PjxcnZ25qLIBkybNk2nT59OsSw8PFzu7u6qXbu2TCaTnJyc1L59e3355ZcaPXq09u3bJ09PT3366adaunQpAZSNSvp0PS4uTnZ2dqpcubI6dOigO3fu6N1331WdOnU0efJkjRgxQnnz5tX48eP13XffKS4ujq4ZG2QymbRp0ya1aNFCjRo1Uvfu3fXqq6/q7bff1scff6wcOXJo8ODBql69uhYvXsywnkwg+e/VpUuXasKECXJ1dTUPg23UqJE6deqkP/74Q3Xq1NFrr72m6tWrKzg4WJMnT5ZEh5stSUhIMJ/XnDt3TrNmzdJ3332nP/74w7yNm5ubxo8fr8GDB6tQoUIKCAhQ2bJl9fvvv8vBwcF8jgwAsB10QmUSSd0wAwYMUEJCgr7//nsNGTJEY8eOlaenp3l9zpw55efnp2zZslm7ZDxE8vmdDh06pNjYWHl5een555/Xc889p7fffls//vijunTpoo8++kiBgYGaPHmyrl+/rvbt25sfp0yZMvr555+VK1cua30r+JdhGLp9+7ZmzpypevXqpVgXGxurgIAAhYSEqFChQubXa+PGjTV27FidOXNGVapUUbZs2Xjt2qikT+M3b96sPXv2qEuXLipQoICkxKHS//zzj/r06SM7OzsFBwfr1VdfVf78+dW0aVPm+LJRCQkJWrRokTp16qRBgwaZl7/44ovq1q2bSpYsqebNm+uDDz6Qi4uLWrZsacVq8ShJw9Yl6Y8//tDhw4e1d+9eOTo66urVq8qXL58kqWvXripTpoyOHj2qY8eOKX/+/Orfv78cHBzM782wvuTHs1evXpKk6dOn69NPP9W2bds0bdo083uuq6urWrZsqZYtW6Y4v+J4AoBtohPKhoWFhSk0NFSSzJ/mJA0VePPNN3X48GENHDhQkZGR5l+ykyZN0vXr1/Xiiy9asXI8TPITq2HDhqlZs2bq0KGDSpcurcmTJ8vOzk4DBw5U586ddfjwYZUuXVp9+/ZVdHS0Dhw4YP5ZSPrElwDKdmTLlk0nT55U0aJFtX//fp04cUKGYahKlSpq2LChPvzwQ/3xxx/m16uLi4vc3Ny4U08mYDKZ9N1336lZs2a6deuWbt++bV4XEhKia9eu6Z9//tFff/2lOXPm6OzZsxo6dKiKFClixarxMDExMbpw4YI8PT0lJU5CHR8fry5duqhHjx6aNm2aIiIi5O3trY8//pi7VNqw5B0z/v7+evvttzVs2DANHjxY9vb2Gjt2rIKCgszbly9fXl27dtXUqVM1cODAFOdYsL7kQ/AuXryoAwcOqGXLlnr++ec1efJkValSRatWrdL8+fNTdKhKSvH7lOMJALaJu+PZqAsXLuiVV15RrVq1VLp0aX344Yf3fLozZcoUffvtt4qOjlbt2rUVHBysbdu2acOGDSpTpox1vwE80ujRozVz5kwtWbJENWvWVO/evTV//nwNHDhQQ4cOlaurqyTp4MGD8vb2VoECBcyTk3NiZbuShl4VLFhQPj4+WrJkiUqUKKF169bpiy++UHR0tD799FO5u7tr1apVmjdvng4cOMAFro07deqU6tatq5EjR6pbt273rPf399eCBQvk6+uriIgI/fjjj9wJz8YkXdheu3ZNuXPnliS9//77Wr9+vX755RflzZvXPM/iJ598op9//lm7d++2ctVIi5s3b6pXr17q1q2bateuLUkaP368VqxYoVq1aql///7Kly8fd5K1YbGxsea518aOHavffvtNbm5umjt3rnnagWvXrql37976559/1KlTJ3Xp0oXjCQCZCB+/26jDhw8rLCxMb775phYsWKAmTZroww8/VEhIiPnTuv79++vjjz/Wyy+/rJMnTypXrlz65ZdfCKBsVPK5Kv7880/t3btXs2bNUs2aNbV27VotW7ZMzZs315gxYzRmzBjzvF4VK1aUn5+f7OzslJCQQABlo5J/Guvo6KgjR44oLCxM3bp1U0BAgBo1aqT+/fvrmWeeUfXq1dWmTRutWrVKmzZtIoDKBIKDg5UrVy41aNDAPMdI8tf0tGnTtGbNGs2YMUMHDx4kgLIxSaHD+vXr1a1bNy1atEiS9NZbbylv3rwaOHCgLl++bL4b2rVr15Q9e3bdvn2bOYJsWFK3uCTNmDFDJUuWVFBQkIoWLWpePmjQILVs2dI8hOvvv/8msLBRy5cv19y5cxUXF6f4+Hg5Oztr48aN+v3332VnZyeTyaTY2Fjlzp1bM2bMUL58+TRx4kStX7/e2qUDANLCgM2qXLmyMWnSJOPOnTvGjBkzjKZNmxp+fn7GsGHDjG3btqXYNi4uzjpFIlUSEhLMfz9z5oxhGIbx9ddfG1FRUcbu3buNvHnzGtOmTTMMwzC6du1quLm5Gf379zdCQ0OtUi/SJun4btu2zRg1apRx9uxZwzAM4+rVq0a+fPmMKlWqGH/++ad5+99//934888/jStXrlilXqTd119/bTg7Oxu3bt0yDCPle+6vv/5qBAUFWas0pNLatWsNZ2dnY9KkScaJEyfMy7/66ivj1VdfNQoWLGh06dLFaNy4seHu7m78/vvvVqwWjzJv3jyjb9++RkREhGEYhrFnzx6jfPnyhqenp/k9ODo62rz9uHHjjLx58xrTp0+3Sr14uDlz5hgmk8nYvHmzeVlkZKQxd+5cw8HBwRgxYoR5eWxsrGEYhnHlyhVj+PDhnAMDQCbDcDwblDQcYPHixfr++++1aNEiubm5SZIKFSokwzB09epVdezYUS+++KJ69+5t5YrxMMmHUfr7+2v+/Pm6evWqEhIS5OHhoX79+unGjRuaP3++nJ2d9eGHH2rfvn1KSEjQ7t27+cTWxhn/dlisXr1anTt31gcffKA333xTpUuXlslk0tWrV1WuXDkVKFBAc+fOVYkSJTimmdDff/+tN954Q2+++aY++ugjZc+e3fxe3blzZxUrVkwffPAB83vZqODgYDVu3FgtWrTQ+++/f8/6gwcPav369fr999+VL18+9e7dWyVKlLBCpUiNuXPnqkePHvr+++/VqFEjSYm/aw8dOqS2bdvK29tbO3bskIODQ4rhXYsXL1bbtm3NHW+wDXPmzFGfPn20atUqNW7cOMW62NhYffnll/L399fo0aM1ZMgQ8/Kk4yr9d+4MALB9jOuxQUm/RCtVqqQPP/xQGzZsUIsWLdS5c2fduXNH69evV2hoqIYPH64DBw6oSZMmypMnj5WrxoMkXZQGBATo1q1b+vHHH5UtWzYZhqG4uDidOXNGzz77rPlk6s8//9Rnn32mSpUqSRJzV9ig5Ce/JpNJBw4cUI8ePTRp0qQU8wVdv35d3t7eOnz4sCpWrKjWrVtr1apVKlasmLVKxyMkvd5+++03nTp1SuHh4apUqZIqVKigFi1a6Oeff1ZMTIyGDh2qGzduaPHixdqwYYM+/PBDAigbcvfcedHR0bp06ZKKFy9uXpb8vbVixYqqWLEiF7KZwJw5c9S7d29999135gBKSgyhKlSooKVLl6pVq1aqU6eOtm7dKkdHR8XExMjJycl8d1mOs+1YuHChevfurR9++EH169c3Lx82bJjatGmjkiVLqnv37pKk/v37y87OToMGDUoRQEnieAJAJkIIZaMMw9Dzzz+vwYMHa+HChVq4cKEOHTqkH3/8UWXLlpUkvfTSS7Kzs5OXl5eVq8WjLFu2TCNGjFDOnDlVokQJc3eUg4ODGjZsKH9/f4WEhOjChQuKj49X+fLlJRFA2aL3339fZcqUUfv27c3H58CBA+bbukdGRmrLli1atGiRzp07p969e6t79+7av3+/6tSpIxcXF2t/C3iIpK62d955R9WqVVNgYKAWLFigZs2aaeTIkbKzs9P69evl4+Oj4sWLKyoqSj/99FOKcAPWdeHCBa1Zs0Yvv/yyqlWrJkmKjIyUyWRKMXdbUkj166+/6uTJk+rUqRMXsjbu66+/Vu/evbVu3TrVq1fPvLxDhw5q1qyZ3nrrLVWoUEErVqxQ69at9dprr2nz5s1ycnJK8TgcZ9vw66+/qkuXLurTp0+KAKp58+Y6cOCA+vTpI0lycnJS9+7dZWdnp969eytPnjzmQBEAkPnwsa2NSgoeKlWqpOPHj+vs2bPas2ePOYAyDEPPPPMMAZSNSpqwOOnPqKgo+fr6KiAgQHFxcbKzs1NsbKwkqU+fPpo1a5a8vLxUq1YtHT161Hy7aAIo2+Ps7KxSpUpJ+u/45s6dW4GBgRo1apSaNm2q+fPny2Qy6Y033lCPHj30+++/y9fXV8eOHWMScht3/Phx+fv7a8yYMVq7dq3mz5+v06dP69atW7K3t9eIESP0yy+/aO3atfrqq6+0e/du8/syrO/48eN67bXXdOjQIfPNHSSpRIkSKl68uPkGH8m7pFatWqXNmzfr1q1b1igZqWAYhi5cuKAuXbqofv36qlixonldy5YttXPnzhQ3A6hQoYKWL1+uffv2qV+/ftYoGalQoUIFNWrUSHv27NGqVaskSa1atdKff/6p3bt3y9fX1/x71snJSe+++65WrlypNm3aWLNsAMBjYk4oK0r6JDb5nEH306tXL+3cuVMnTpyQRHdMZnLo0CGVL19eCQkJWrNmjUaOHKmcOXPq22+/lY+PT4pP45P/HNw9lATWd/frbtOmTbp06ZI6duyoS5cuadq0adq8ebNeeeUVtW/fXlWrVlVAQIDatWunb775Rs8//zyvXRvyoPfd1atX67PPPtO+fft0/vx51axZU3Xr1tWcOXMkSSdOnNCLL774pMtFKpw+fVpVq1bVO++8o379+unZZ59Nsf7vv/9Wo0aNFBUVpVGjRskwDO3fv19fffWV9uzZYw6XYbumTp2qKVOmqGPHjurXr5969uypU6dOad26dfLz87vnPfaPP/5Q0aJF6XyyQcmHRDZr1kznzp2Ts7OzuZvY19c3xfGcP3++mjZtqpw5c0riPAkAMjPeva3k3LlzWrBggcLDw1W/fv0UbeVJki6SunXrpoMHD2r58uVq3bo1F7GZxO7du1W9enVNnTpVffv2VdOmTRUXF6cZM2aoQ4cOWrRokXx8fMzzCyW/IObEyvbc/br78ccf9cUXX8jOzk6dO3fW559/rtDQUOXIkcO8zddff63bt2+bl/HatQ1J761BQUH6+eeflZCQoGLFiqlatWpydHSUj4+PgoKCVL16ddWvX18zZ86UJO3atUs///yzcuXKdU/AAeu6c+eORo8erXbt2mncuHHm5VFRUQoJCdGVK1dUrlw57dixQ127dtWoUaMUHR2tfPnyadeuXQRQNi7pNduvXz+ZTCZNnDhRy5Ytk52dnbZv3y4fH58UwfLHH3+st956S2XKlJHEHFC2yN7e3nxcVq9erXbt2mnlypX67LPPlDt3bkn//c587bXXFBkZqc6dO5v35zwJADIv3sGt4Pjx46pfv77efPNNPf/886pdu/Z9t0s6mSpevLju3LmjNWvWqEWLFpxIZRIlS5bUiBEjNGDAAPM8Bi1btpRhGJo1a5Y6deqkBQsWcDGbSSR9IhscHCxfX19NnTpVTk5O6tGjhxISEtSmTRtz2LR9+3atXLlSy5cv1y+//CJvb2/rFg+zpAvVY8eO6c0335SPj4/OnTunHDlyaNKkSSpdurQ2btyoH3/8UT179tTUqVPN+65cuVIXLlww360UtsPBwUHnzp1TyZIlzcs2bdqkjRs3atGiRZKkmjVratWqVfruu+908eJFOTs7y9nZWZ6entYqG6lkZ2dnfu36+/vLxcVFAwcOVIcOHczDtezs7GQYhurWravLly9r2LBh5v05b7JNyYOoJUuWKCYmRvPnz1euXLnUunVrOTg4qH79+goMDNSJEyfMx5gPdAAgcyOEesLOnTunN954Q+3bt0/xae2DfqkmJCTI1dVVX331ldzd3TmRslH3O345c+Y038mlb9++MplM6tWrl1q1aiWTyaSPP/5YEyZM0OTJk61UNVIr6fiuX79eU6dOVbt27dSpUydNnDhRhmGoV69eMplMat26taKiorR161b9888/2rlzJ0O3bEjyAKpKlSry9/fX8OHDtXfvXnXs2FGzZ8/Wxo0bNWvWLL377rvKly+fAgMDFRsbqzlz5mjJkiXatWuXsmfPbu1vBckYhqFbt27Jy8tLQUFB2r9/v3bs2KEFCxaofPny+uSTT/T888+rXbt2+vDDDzVp0iTly5fP2mUjFZJ3NyUPot555x3FxMRo3Lhx8vT0VN++ffXss8+qQYMGCgoK0rFjx2Rvb//I6Q7w5AQEBKho0aL3LE8eRK1atUrNmjXTxIkTZWdnp6+//loXLlzQiRMn5OjoyBA8AMgqDDwxCQkJxogRI4w333zTuHHjhrXLgQV89tlnxvLly1Msu3nzpvHxxx8bJpPJmDdvnmEYhhEfH29s3rzZiIuLs0aZSIe1a9cazs7OxpQpU4zDhw+nWPf+++8bTk5OxoIFCwzDMIzQ0FAjNDTUGmXiEQIDA41nnnnGaNGiRYrlFSpUMIoWLWqEhoYat27dMubPn2+4uLgYBQsWNIoXL26UKFHinuMO27JkyRKjaNGiRoECBYycOXMac+fONc6dO2de36pVK6NJkyZWrBCptWPHDvPf4+PjU6xL/u+pU6ca+fLlM4YNG2ZUr17deP75542YmBjDMAwjNjb2yRSLRzpz5oxhMpmMiRMnPnCb5OdDLVq0MEwmk1G6dGmOJwBkQXyc8ASZTCbt2LFDBQoUuO9d7ZI+sYuMjJSzszOf9mQCRrIOqFu3buno0aMaPny4XFxc9NZbb0mScuTIoXfffVc7d+5U9+7dFRERof79+6tOnTqSmKsiM7h27ZrGjRunjz/+OMWdlmJiYuTk5KTPPvtMJpNJXbt2laOjo95++20rVouHiY+PV6FChRQdHa09e/aoatWqGjt2rH777Te9/PLL6tChg3LlyqWGDRtqw4YNioqKUsGCBZU7d275+PhYu3zcR9L7cNu2bVW+fHnFxsbq2WefVa5cuczbxMfHKyYmRsWKFbNipUiNGzduqEmTJipVqpS2b9+eogNKundoXtKfpUuXpmPGRuXNm1effvqphg4dKkdHx/vesTB5R9TKlSv16aefatCgQXJwcOB4AkAWwzv6E2IYhiIjI3Xnzh3zhUzSBWySpBOsSZMmqXr16qpRo4ZVakXqJD8pPnv2rPz8/DRx4kTlzJlTHTp00MKFC9WkSRNJUu7cuVW8eHGFhoZq9erV5hMwk8lEAJUJREZGKjAw8J7Ji52cnMwXwBMnTpSjo6PKly9vpSqRGn5+flqyZIn8/f01YcIEeXt76/vvv9fKlStVsWJFHTp0SCdOnFDPnj2VLVs2lStXTqtXr7Z22XgIk8lkfh2+8MIL96yPiYnRJ598ogMHDmj8+PFWqBBpkStXLq1Zs0YdO3bUG2+8oU2bNj00iOrTp48KFSqkunXrEljYmJ07d6p69erKli2b/P395eTkpPfee0+SHhhEJR2/oUOHSuIueACQFTFQ/glIOjl2d3dXqVKltGDBAl25ckVOTk7mCTWT/PXXX9q/fz8T39q45CfDI0aMUP/+/fXDDz/I19dX7733ntq3b6/OnTvrhx9+kJR456br169r+PDh2rVrF5NqZhKGYUhKPN7ZsmXTzZs371m3d+9eLViwQJI0ZswYFS9e/MkXijQpWrSopk6dqqioKH3zzTf68MMP1bx5cxUoUEBNmjTR8OHDdfr0aU2cODHF3H2wXQ96T/3uu+/k7++vefPmaf369fedkwa2p3r16vrmm2904sQJvfHGG5L+C56SJP93gwYNCKBsTFJHW9IHqtmyZVPPnj01ceJEvffeeylu+pDc3ceP4wkAWQ8hlAXFx8dLSuyiSNK6dWs5OjqqU6dOunz58j0TZi5atEjh4eEqWLDgE60VaZN03IYPH66ZM2eqV69eqlq1qiSpUKFC+uCDD9S5c2c1btxYtWrVUoUKFfTHH3+oYcOGkh48ET2sLylcSu65555ToUKFNH78eP3111+S/rvoXbdundatW6eIiIgnWicez/PPP69Zs2apevXq+uWXX7R7927zutjYWOXKlUvNmzcntLAhERERKX6fPsrBgwc1b948hYWFadu2bSpbtqwFq0NGq1q1qlasWPHIICo5AgvbkdTRFhgYqLp160pKfRAFAMjaTMb9rrjw2AICAjR79mwdPHhQd+7c0csvv6zWrVurRo0aGj9+vCZNmqSCBQvqiy++MN+B6ZtvvtHSpUu1Y8cOlS5d2trfAh7h5MmTatWqlT7//HPzCVZyUVFR2rhxo7Zs2aJnnnlGI0eOlIODA3NA2bCkcHDLli1auXKlgoKC9PLLL6t///6SpBo1apjvcpgjRw7t2bNHixYt0p49e+4ZqofMISAgQP7+/jIMQ8OHDzeHybAtp06dUrt27dS3b1+1bdtWLi4uqdrv4sWL8vT0lKenp4UrhKXs2bNHrVq10osvvqhNmzZJEne9y0SSjl/JkiX1008/SUr8cHb27NkaNGiQJk2aJH9/fytXCQB4kgihLODYsWOqVauW6tWrJw8PD7m6umr+/PnKli2bBgwYoPfff1+zZs3SzJkzdfLkSXl4eCh//vxyd3fXl19+SQCVSRw5ckT16tXTunXrVKFChRTrYmJiFBsbq2zZsqUInRgqYPvWrl2rDh06qF27dnrxxRf10UcfqWLFilq6dKnc3d3Vrl07/f333woLC1PBggU1adIkvfTSS9YuG48hICBAAwYM0PXr1zV58mRVrlzZ2iUhmaCgIDVo0ECXL19WfHy8vvjiCzVv3vyhQRTdplnLnj171Lp1a5UuXVobNmywdjlIowcFUXPmzNHAgQO1fPlytWzZ0spVAgCeFEKoDHbx4kVVr15dbdq00aeffppieZcuXXTs2DGNHj1a3bp1U0hIiPbu3avQ0FAVK1ZMfn5+euaZZ6xYPR7kfp+67ty5Uw0bNtRPP/2kKlWqpJhoftu2bQoKClLr1q1TTD4P23b58mU1aNBAnTt3lr+/v+Lj4+Xr66v27dvrs88+M/8M3Lx5UzExMcqWLZvc3d2tXDUywh9//KHhw4fr888/V4ECBaxdDv4VHx+vr776SuvWrdPs2bM1evRoLViwQHPnzn1kEAXbltZupr1796p69erq16+fPv/8cwtWBku4XxB169YtrVu3Ti1atOADOgB4ihBCZbBVq1Zp9uzZWrlypXLkyCF7e3vFxsbK0dFRQUFBeuutt5SQkKDt27crR44c1i4XqZD8RHn69Om6deuWBg8eLElq3LixDh8+rF9//dV818OoqCg1adJEL774oj777DOr1Y3USd4xcfXqVdWrV087d+7UtWvXVLVqVTVo0EBffvmlJGnXrl2qWrUqw0CyqLvvWArbcPToUQUFBalRo0aSpF69eumrr77S3Llz1axZM7m6uqbYni4o25f89+rBgwdlGIYSEhJUpUqVh+53/PhxlShRgiHtmVRSR1upUqW0cePGFOvoFAeApwdXUhns0KFDOn/+vLy8vMwnSY6OjkpISFD+/Pk1bdo0HTt2THv37rVypUitpBPlDz74QOPHj1d0dLQCAwMlSf/3f/+nQoUKqXjx4po8ebLGjh2rt956S5cuXeKuWpmEyWTSypUrNXfuXDk4OOj69ev67rvv9Nprr6lhw4aaOXOmJOnMmTMaO3asDhw4YOWKYSkEULbj8OHD+uSTTyRJZcqUMQdQkjRz5kx16dJF3bt31+rVq3Xnzh1J0sqVK/XPP/8QQNk4wzDMv1c/+ugjvf322+rWrZsaNGigd955R3///fcD9y1VqpTs7e3NN36B9d19l+eHSZps/ueff9aAAQNSrCOAAoCnB+/4GSxpDqDIyEi5u7ubP+1LOuHy8/NT9uzZFRISYuVKkRYrV67U4sWL75n/qUyZMlq5cqXGjh2rJUuWyNXVVUWKFNGGDRu4XbQNS94pceLECb3zzjv6+OOP5eXlpaZNm+qdd95RrVq1NGfOHPM+ixYt0tWrV7lzJWBhx44dU4UKFfTee++lWJ7ULWNvb68ZM2ZIkrp3766EhATt3LlTmzZt0r59+6xRMtIg6b130qRJmjt3rtavX69KlSpp1KhRGjlypLp37/7I91k6oWxDejraXnnlFR05ckQlSpR4UmUCAGwMV8cZrEGDBho5cqQmTZqkESNGyM7OTvHx8bKzs5PJZNKdO3fk5+cnPz8/a5eKNPjjjz/0v//9TxUqVDBPNJ4UMPn4+GjKlCkKCQlR9uzZmYTcRiU/WU4eQK1atUo9evRQv379JEktW7bUn3/+qUuXLmnx4sVydnbW7t279fXXX2vnzp3KkyeP1b4HIKv7/fffVaVKFQ0ePDjFvIpS4us2qQsmeRDVqVMnubu7a9u2bcqfP781ykY6HD16VCNHjlSlSpX07bffatKkSZoxY4YqVKjA0NhM4O6Otm+//VbOzs66dOmSmjdvrqFDhz4wTEy6myx3CwaApxPD8R7DjRs3dOrUKR0/fty8rECBAurcubM+/fRT83xA9vb25ove+fPnKz4+Xs8//7xVasajJbWWJ28xv3Hjhi5cuGD+FN4wDDk4OCg6Otp8p57kQzCT1sM2JAVQly5d0ooVK7R06VKtW7dOY8eO1YwZMxQaGmretkqVKho4cKCqVq0qf39/jR07Vn/++ad27drFXfAACzp79qwqV66s999/X59++qmSpqxcvHixdu3aZd4u+XAsNzc35cyZUwcOHFD58uWtUjfSxjAMRUVFaf/+/fLx8dHevXvVuXNnjR07Vu+++65iY2M1dOhQbdu2zdql4iHu7mhbvHixjh8/rvfee0/z5s3T1atXH/kYBFAA8HTiKjmdTpw4oS5duujatWsyDEOvv/66vvzySz3zzDPq27evwsLCNGjQIB06dEj169eXyWTSvn37tHjxYu3cuVPe3t7W/hZwH8uXL9fPP/+swYMHK2/evMqWLZukxE/t1q5dq40bN6pOnTrmOzLdvn1bY8eOVVRUlJo3b25+HOYksR1JAdSxY8fUpEkTubi4KCAgQKVLl1bevHlVsWJF/fjjjzp69KjKlCkjSapZs6Zq1qyp//u//5Onp6fi4uLMPwsAMl5CQoIWLFggDw8P5cqVS1Li++jo0aM1bdo0c9ifxN7eXqtWrdLnn3+ugwcPqnjx4tYoG6lw913wTCaTXF1d9fbbb+uzzz7T77//rlmzZqlz586SpIiICB09elR58uRRzZo1rVU2UomONgBAWnF3vHT4/fffVbVqVfXs2VMNGzbUt99+q7lz52ry5Mnq1auXpMRJjDds2KApU6YoKipKzzzzjIoVK6ZRo0bpxRdftPJ3gPsJDw9XuXLlFB4eLl9fX1WsWFH/+9//1KlTJ0lSw4YNdebMGQ0bNkxVq1ZVbGysBg4cqBs3bmjPnj18omeDkgdQVapUUZ8+fdSvXz/99ttvmjlzpiIiItS4cWP98MMP8vLy0qhRo1S6dOkUc88AeDIuX76sCRMmaP/+/erUqZPCw8P12Wef6euvv1a9evXu2f6ff/5RQkKC8ubNa4VqkRrJA6jz58/rzp075sBw9+7d6tu3rzw8PLRgwQIVKVJEV65cUZcuXRQaGqqdO3fyHmzDDMPQnTt39NJLL+nTTz9V3rx5VbduXU2cOFE9e/ZUbGysPvroI9WvX58wEQCQAiFUGp09e1alSpXSwIEDNWrUKEmJJ1bFihVT3759zUPwkoSHh+vq1avKmTOn3Nzc7rmVNGxHfHy8hg8froIFC6pChQr65Zdf9Omnn+q1115TzZo19c4776hNmza6ePGi9u/fr5deekkuLi7auXOnHB0dmdvARgUFBalcuXKqWbOmVq5caV4+e/ZsDRkyRL///rsOHz6s6dOny93dXaNGjTLPVwHgyQoODtann36qzZs369y5c/rpp59Uq1Yt3l8zucGDB2v58uUKCQlR4cKF1aFDB/Xu3Vvr1q3ThAkTdPHiRT377LPmeYb27t3L71Ubc3dHW5JPPvlEGzZsuKejLSQkRK1atVL9+vXvuckAAODpxnC8NLjfcAEpcQhXbGysAgICNGXKFHl5eally5ZycHCQp6enPD09rVg1Usve3l7VqlVTq1attHv3bg0cOFB9+vTRmDFj1Lt3b61cuVL169dX8+bN5e3tLVdXV1WoUEF2dnZMQm7D4uPjVahQIUVHR2v37t363//+J0kqXLiwTCaTIiMj1bhxY0VHR2vBggXq16+fvvjiC5UsWdLKlQNPH19fXw0bNkx2dnbavn27jhw5olq1aqWYkBy2L3lg8c0332jx4sWaNm2aChQooLlz52rZsmX6559/NG7cOJUoUUKHDx9WUFCQnnvuOTVr1izFzT9gfQ/raKtVq5bWrFmjihUrqlq1apJk7mi7ffu2/P39rVY3AMA20QmVRsmHC3Ts2FEREREaN26cevfurTJlymjJkiUKCgrSlStXVLRoUQ0YMEANGjSwdtlIg969e0uS+c5LJUuW1PPPPy8/Pz+dOXNGmzZt0uLFi9WuXTtJD/50ELYjICBA/v7+SkhI0JQpU5Q/f34999xz6ty5s8aPH2/ebtGiRVq9erVmzJihfPnyWbFi4OmW1BH166+/qkmTJho0aJAk3m8zm7Vr1+r8+fOyt7dPEUaMGTNGy5Yt06hRo9S4ceN79iNwtE10tAEAMgIhVDo8aLiAJPMnd9OnT9fhw4c1cOBAlShRwsoVIy3mz5+vr776SuvWrVPt2rXl5uamjRs3ytPTU5cuXdKuXbvUvHlzPqHNZAICAtSvXz/dvn1bx44dU8eOHTV58mRJUmxsrBwdHSUlTorr4eFhzVIB6L/ftUeOHFHt2rX18ccfW7skPEJSSGgYhq5fv66CBQvqzp076tevn/n9NknNmjWVPXt2rV271jrF4pHu7mgbNGhQio62o0eP6tVXX9W4ceN05swZOtoAAKlCCJVOV65c0ZgxY7R9+3Z16NBB77//viSluBMIv3gzr4oVK+q3335T9erV9d1338nLy+uebTi+mU9AQIB69uypc+fOadGiRapevbokmW8Fz10NAdsSHBysIUOG6OLFi1q+fHmKofCwXb/++qsqVKigkydPqlWrVnJ0dNSaNWvk5+dn3ub//u//tH//fq1bt878IQBsEx1tAICMRAj1GB40XIBwIvMyDEMmk0nffPONxo8fr4ULF6p8+fLm5cj8zp49q759+8owDA0fPlxVq1a1dkkAHuLKlSuSJB8fHytXgtTYv3+/XnnlFe3evVuvvPKKTp06pbp16+qFF17Q1KlT5efnJ5PJpNq1a+u5557TkiVLrF0y7kJHGwDAkphY4TH4+vpq6NChqlChgtatW6eRI0dKEgFUJpYUNNWsWVM3btzQ5s2bUyxH5lekSBFNmzZNjo6OGjhwoPbv32/tkgA8hI+PDwGUDbt9+3aKf+fJk0fVq1fX0aNHJUklSpTQpk2b9Oeff6pWrVqqV6+eOnbsqOjoaH311VeS/utGhW1IGoL322+/KXfu3Pr1119VokQJbd++XRcuXEixbY0aNXTnzh3FxsZaoVIAQGZECPWYkoKookWLau/evbpx44a1S0IGyJs3r4YMGaLPPvtMp06dsnY5yGBFixbVxIkTlS9fPuXJk8fa5QBAprRw4UJNnDhR0dHR5mUFChRQ5cqVNXr0aHNAVbJkSW3atEk+Pj46e/asBgwYoEOHDsnJyUmxsbF80GOD9u/fr0qVKmnv3r0qWbKkVq5cqevXr6tbt246efKkIiMjdfv2bf3000/KlSsXQyoBAKnGcLwMwnCBrOfcuXP65JNP9NVXX3E3piwq+RxuAIDU+/LLL9WzZ0/9+uuvyps3r9zc3OTp6SlJCg0NVZ06ddS2bVu999575rulnTp1SnXq1NFLL72kZcuWKXv27ARQNuL27dtyc3Mz/zswMFAdOnRQy5Yt1atXL0nSyZMnVa9ePUVHR+uFF16Qj4+Pzp07p/3798vJyYmpCwAAqcKVdQZhuEDWU7hwYS1cuFB2dnaKj4+3djmwAAIoAEi7xYsXq3fv3lq3bp2uX7+uwoULq2vXrvrhhx8UHx+vHDlyqFKlSvr5559lMplkZ2enhIQElShRQps3b9bp06dVv3593bx509rfCkRHGwDgySKEAh4i6YSKu7sAAJAYWHTs2FE1a9ZUgwYNVLduXU2dOlV58+ZVixYt1KpVK82bN0/+/v7as2ePli9fLum/eYZKliypH374QaGhobp165Y1vxUosaOtS5cuatiwoW7evKnw8HDzusGDBytPnjyaPXu2DMMwB4lJx/STTz5RWFiYDMNgOB4AINUYjgcAAIBHmjt3rnr27KkuXbpo48aNaty4sWbMmGFe/+uvv+q7777TypUr5e7urkuXLqlevXrmYe3Jh7YzHNr6Fi9erC5dumjt2rVycHBQ06ZNVb9+fbVv314NGjSQvb29evfurXPnzmnTpk2S/rtz3smTJ9WgQQPlyZNH69evl5eXl5W/GwBAZkEIBQAAgIeaMmWKBgwYoA0bNqhevXqaM2eOhg0bptatW+uLL74wb5eQkKDY2FhNmDBB+/fv1y+//KIDBw6odOnSVqwed1u4cKG6dOmiOnXq6Oeff5YkzZs3TydOnNCsWbPUqFEjvfHGG6pWrZpefvllzZ07V61bt07xGMeOHVPr1q21adMmFShQwBrfBgAgEyKEAgAAwEPt2LFD//zzjzmICAsL04oVKzR06FC1bdtWU6dOlZSywyk0NFRdunSRl5eXZs2aJQcHB+YNsgF0tAEArIkQCgAAAKmS/A5o4eHhWr58+T1BVGxsrHmOoFGjRmnnzp3avHmz1WrGf+hoAwBYm4O1CwAAAEDmkLyTydPT09wZNWzYMNnZ2Wny5MlydHQ0h1VRUVG6ePGiIiIi5O7uTieUlZUtW1ZLly5VvXr1JEmtW7eWyWTS0KFDZWdnZw4S4+Li5OzsrOHDh5s72qZNm0ZHGwDgsRFCAQAAIF2SgiiTyaQePXrIz89P/fr1k8lk0t9//62//vpLS5culYeHh7VLhaQaNWpI+q+jLXv27OYgcejQoZKkqVOnysnJydzRliNHDpUtW1Y7d+7kLngAgMdGCAUAAIB08/T0VIsWLeTt7a2GDRualxcsWFDz589XtmzZrFgd7oeONgCAtRBCAQAA4LHkyJFDb731lqTEoVz29vYymUwEUJkEHW0AgCeFickBAAAAKDQ0VDt27FDDhg1lb29vXh4ZGUmgCADIEIRQAAAAAFJI3tEGAEBGIYQCAAAAAACAxdlZuwAAAAAAAABkfYRQAAAAAAAAsDhCKAAAAAAAAFgcIRQAAAAAAAAsjhAKAAAAAAAAFkcIBQAAAAAAAIsjhAIAAAAAAIDFEUIBAAAAAADA4gihAACwcQsXLpTJZNKFCxesXQoAAACQboRQAAAkkxT4mEwm7d69+571hmEof/78MplMatiwYZoff+bMmVq4cGEGVAoAAABkLoRQAADch4uLi5YuXXrP8h07dujixYtydnZO1+OmJ4Rq3769oqKiVLBgwXQ9JwAAAGALCKEAALiP+vXra9WqVYqLi0uxfOnSpSpfvrx8fX0tXkNkZKQkyd7eXi4uLjKZTBZ/TgAAAMBSCKEAALiPNm3a6MaNG9q8ebN5WUxMjL799lu1bdv2nu0TEhI0ZcoUlSxZUi4uLvLx8VGPHj108+ZN8zZ+fn46efKkduzYYR7y9+qrr0r6bxjgjh071KtXL3l7eytfvnwp1t09J9SPP/6oGjVqyMPDQ56enqpQoUKK7q2AgAA1a9ZMvr6+cnFxUb58+dS6dWuFhYVl4P8UAAAAkDoO1i4AAABb5OfnpypVqmjZsmWqV6+epMTQJywsTK1bt9a0adNSbN+jRw8tXLhQnTt3lr+/v86fP6/p06fryJEj2rNnjxwdHTVlyhT17dtX7u7uGjp0qCTJx8cnxeP06tVLuXPn1ogRI8ydUPezcOFCdenSRSVLltSQIUOUI0cOHTlyRJs2bVLbtm0VExOjunXrKjo6Wn379pWvr68uXbqk9evXKzQ0VNmzZ8/g/zEAAADg4QihAAB4gLZt22rIkCGKioqSq6urlixZoho1aihPnjwpttu9e7fmzZunJUuWpOiSqlmzpt544w2tWrVKbdu2VePGjTVs2DA988wzevvtt+/7nF5eXtq6davs7e0fWFdYWJj8/f1VsWJFbd++XS4uLuZ1hmFIkk6dOqXz589r1apVat68uXn9iBEj0vV/AQAAADwuhuMBAPAALVu2VFRUlNavX6+IiAitX7/+vkPxVq1apezZs+u1117T9evXzV/ly5eXu7u7tm3blurn7N69+0MDKEnavHmzIiIiNHjw4BQBlCTzvFFJnU4//fSTbt++nernBwAAACyFTigAAB4gd+7cqlOnjpYuXarbt28rPj4+RVdRkoCAAIWFhcnb2/u+j3P16tVUP2ehQoUeuc25c+ckSS+++OJDH2fAgAGaNGmSlixZomrVqunNN9/U22+/zVA8AAAAWAUhFAAAD9G2bVt1795dwcHBqlevnnLkyHHPNgkJCfL29taSJUvu+xi5c+dO9fO5urqmt9R7fP755+rUqZO+//57/fzzz/L399fYsWO1f/9+86TnAAAAwJNCCAUAwEM0adJEPXr00P79+7VixYr7blO4cGFt2bJFVatWfWSIlDRc7nEULlxYknTixAkVKVLkoduWKlVKpUqV0rBhw7R3715VrVpVs2fP1ujRox+7DgAAACAtmBMKAICHcHd316xZs/R///d/atSo0X23admypeLj4zVq1Kh71sXFxSk0NNT872zZsqX4d3q8/vrr8vDw0NixY3Xnzp0U65ImJg8PD1dcXFyKdaVKlZKdnZ2io6Mf6/kBAACA9KATCgCAR+jYseND19eoUUM9evTQ2LFjdfToUb3++utydHRUQECAVq1apalTp5rnkipfvrxmzZql0aNHq0iRIvL29latWrXSVI+np6cmT56sbt26qUKFCmrbtq1y5syp33//Xbdv39bXX3+tX375RX369FGLFi30/PPPKy4uTosXL5a9vb2aNWuW7v8LAAAAIL0IoQAAyACzZ89W+fLlNWfOHH300UdycHCQn5+f3n77bVWtWtW83YgRI/T3339rwoQJioiIUI0aNdIcQklS165d5e3trXHjxmnUqFFydHRUsWLF9N5770mSXnrpJdWtW1fr1q3TpUuX5Obmppdeekk//vijKleunGHfNwAAAJBaJiOpbx8AAAAAAACwEOaEAgAAAAAAgMURQgEAAAAAAMDiCKEAAAAAAABgcYRQAAAAAAAAsDhCKAAAAAAAAFgcIRQAAAAAAAAsjhAKAAAAAAAAFkcIBQAAAAAAAIsjhAIAAAAAAIDFEUIBAAAAAADA4gihAAAAAAAAYHGEUAAAAAAAALA4QigAAAAAAABY3P8DecxEWa3+yUgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir colores para cada valor de los parámetros\n",
    "colors = ['#0d4e9e', '#ffc520', '#7b9ca0', '#242624', '#cc7b4f', '#7764B4','#7764B4']\n",
    "\n",
    "# Graficar resultados para cada parámetro\n",
    "plot_parameter_results(results_noise_multiplier, eps_noise_multiplier, 'noise_multiplier', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_batch_size, eps_batch_size, 'batch_size', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_sample_size, eps_sample_size, 'sample_size', colors, results_no_dp_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
