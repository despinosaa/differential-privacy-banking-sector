{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5021593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9777853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 33)\n"
     ]
    }
   ],
   "source": [
    "# Crear carpetas para resultados y figuras\n",
    "import os\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "data_path = 'C:/Users/danie/OneDrive/Documentos/1 UNIANDES/10 semestre/Tesis/differential-privacy-banking-sector/data/processed/bank-processed.csv'\n",
    "data = pd.read_csv(data_path, sep=',')\n",
    "print(data.shape)\n",
    "\n",
    "# Separar características y variable objetivo\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y']\n",
    "\n",
    "# Definir columnas numéricas\n",
    "numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Escalar columnas numéricas\n",
    "scale = MinMaxScaler()\n",
    "X[numeric_cols] = scale.fit_transform(X[numeric_cols])\n",
    "\n",
    "# Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b15972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTEENN para balancear clases\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_resample, y_resample = smoteenn.fit_resample(X_train, y_train)\n",
    "X_resample = pd.DataFrame(X_resample, columns=X.columns)\n",
    "y_resample = pd.Series(y_resample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42cce6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 26\n"
     ]
    }
   ],
   "source": [
    "# Selección de características con BorutaPy\n",
    "rf = xgb.XGBClassifier(eval_metric='logloss')\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
    "feat_selector.fit(X_resample.values, y_resample.values.ravel())\n",
    "X_filtered = X.columns[feat_selector.support_].tolist()\n",
    "print(f\"Selected features: {len(X_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979f0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar datos con las características seleccionadas\n",
    "X_train_filtered = X_resample[X_filtered].values\n",
    "X_test_filtered = X_test[X_filtered].values\n",
    "y_train_filtered = y_resample.values\n",
    "y_test_filtered = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de la red neuronal\n",
    "input_size = len(X_filtered)\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n",
    "n_iterations = 5\n",
    "\n",
    "# Definir valores a probar para cada parámetro\n",
    "num_microbatches_values = [4, 8, 16, 32]\n",
    "l2_norm_clip_values = [0.1, 1, 1.5, 2]\n",
    "noise_multiplier_values = [1.1, 1.5, 2.0, 2.5]\n",
    "\n",
    "batch_size = [32] # TODO: Probar diferentes tamaños de batch\n",
    "\n",
    "# TODO: Probar diferentes tamaños de la muestra\n",
    "sample_size_ratio = [1, 0.9, 0.8, 0.7, 0.6]\n",
    "\n",
    "# Valores fijos por defecto\n",
    "default_num_microbatches = 32\n",
    "default_l2_norm_clip = 1.0\n",
    "default_noise_multiplier = 1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d58341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular el presupuesto de privacidad\n",
    "def compute_privacy_budget(n, batch_size, noise_multiplier, epochs, delta=1e-5):\n",
    "    try:\n",
    "        eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "            n=n, batch_size=batch_size, noise_multiplier=noise_multiplier,\n",
    "            epochs=epochs, delta=delta\n",
    "        )[0]\n",
    "        return eps\n",
    "    except Exception as e:\n",
    "        print(f\"Error al calcular el presupuesto de privacidad: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Definir la red neuronal con tf.keras\n",
    "def create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=False,\n",
    "                 num_microbatches=default_num_microbatches, l2_norm_clip=default_l2_norm_clip,\n",
    "                 noise_multiplier=default_noise_multiplier):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation='relu', input_shape=(input_size,)))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if use_dp:\n",
    "        optimizer = DPKerasSGDOptimizer(\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "            num_microbatches=num_microbatches,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Función para entrenar el modelo\n",
    "def train_model(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=False,\n",
    "                num_microbatches=default_num_microbatches, l2_norm_clip=default_l2_norm_clip,\n",
    "                noise_multiplier=default_noise_multiplier):\n",
    "    model = create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=use_dp,\n",
    "                         num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                         noise_multiplier=noise_multiplier)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    \n",
    "    y_pred_prob_test = model.predict(X_test, batch_size=batch_size).flatten()\n",
    "    y_pred_test = (y_pred_prob_test > 0.4).astype(int)\n",
    "    \n",
    "    return y_pred_prob_test, y_pred_test\n",
    "\n",
    "# Función para evaluar el modelo\n",
    "def evaluate_model(y_true, y_pred, y_pred_prob):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    actual_negatives, actual_positives = conf_matrix[0].sum(), conf_matrix[1].sum()\n",
    "    false_positive_rate = conf_matrix[0][1] / actual_negatives if actual_negatives > 0 else 0\n",
    "    false_negative_rate = conf_matrix[1][0] / actual_positives if actual_positives > 0 else 0\n",
    "    return {\n",
    "        'ROC AUC': roc_auc_score(y_true, y_pred_prob),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Type I Error': false_positive_rate,\n",
    "        'Type II Error': false_negative_rate\n",
    "    }\n",
    "\n",
    "# Función para ejecutar múltiples iteraciones y calcular estadísticas\n",
    "def run_iterations(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp, n_iterations,\n",
    "                   num_microbatches, l2_norm_clip, noise_multiplier):\n",
    "    results = []\n",
    "    for _ in range(n_iterations):\n",
    "        y_pred_prob_test, y_pred_test = train_model(\n",
    "            X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=use_dp,\n",
    "            num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier\n",
    "        )\n",
    "        result = evaluate_model(y_test, y_pred_test, y_pred_prob_test)\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Función para calcular estadísticas\n",
    "def compute_statistics(df):\n",
    "    stats = {\n",
    "        'mean': df.mean(),\n",
    "        'min': df.min(),\n",
    "        'max': df.max()\n",
    "    }\n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47b3b80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo sin DP...\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.5697 - accuracy: 0.7050 - val_loss: 0.5909 - val_accuracy: 0.6756\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.4549 - accuracy: 0.7859 - val_loss: 0.5288 - val_accuracy: 0.7390\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.3759 - accuracy: 0.8384 - val_loss: 0.4949 - val_accuracy: 0.7909\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.3129 - accuracy: 0.8768 - val_loss: 0.4762 - val_accuracy: 0.8172\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.2818 - accuracy: 0.8915 - val_loss: 0.4682 - val_accuracy: 0.8219\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.2672 - accuracy: 0.8986 - val_loss: 0.4891 - val_accuracy: 0.8113\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.2588 - accuracy: 0.9008 - val_loss: 0.4936 - val_accuracy: 0.8110\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.2535 - accuracy: 0.9027 - val_loss: 0.4497 - val_accuracy: 0.8261\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.2502 - accuracy: 0.9048 - val_loss: 0.4896 - val_accuracy: 0.8084\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.2475 - accuracy: 0.9044 - val_loss: 0.4612 - val_accuracy: 0.8181\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.2436 - accuracy: 0.9062 - val_loss: 0.4955 - val_accuracy: 0.8070\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.2410 - accuracy: 0.9069 - val_loss: 0.4582 - val_accuracy: 0.8184\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.2383 - accuracy: 0.9089 - val_loss: 0.4379 - val_accuracy: 0.8270\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 937us/step - loss: 0.2367 - accuracy: 0.9085 - val_loss: 0.4403 - val_accuracy: 0.8231\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 832us/step - loss: 0.2341 - accuracy: 0.9105 - val_loss: 0.5042 - val_accuracy: 0.8019\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.2326 - accuracy: 0.9105 - val_loss: 0.4217 - val_accuracy: 0.8319\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.2310 - accuracy: 0.9108 - val_loss: 0.4304 - val_accuracy: 0.8293\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.2293 - accuracy: 0.9125 - val_loss: 0.4771 - val_accuracy: 0.8110\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.2276 - accuracy: 0.9120 - val_loss: 0.4658 - val_accuracy: 0.8148\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.2254 - accuracy: 0.9135 - val_loss: 0.4503 - val_accuracy: 0.8222\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.2236 - accuracy: 0.9139 - val_loss: 0.4238 - val_accuracy: 0.8347\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.2228 - accuracy: 0.9147 - val_loss: 0.4230 - val_accuracy: 0.8348\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.2214 - accuracy: 0.9146 - val_loss: 0.4637 - val_accuracy: 0.8162\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 815us/step - loss: 0.2201 - accuracy: 0.9158 - val_loss: 0.4916 - val_accuracy: 0.8100\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 849us/step - loss: 0.2187 - accuracy: 0.9163 - val_loss: 0.4646 - val_accuracy: 0.8206\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 826us/step - loss: 0.2176 - accuracy: 0.9168 - val_loss: 0.4420 - val_accuracy: 0.8265\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.2165 - accuracy: 0.9172 - val_loss: 0.4560 - val_accuracy: 0.8191\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 829us/step - loss: 0.2154 - accuracy: 0.9176 - val_loss: 0.4681 - val_accuracy: 0.8153\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 788us/step - loss: 0.2143 - accuracy: 0.9177 - val_loss: 0.4545 - val_accuracy: 0.8223\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.2135 - accuracy: 0.9184 - val_loss: 0.4666 - val_accuracy: 0.8160\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.2124 - accuracy: 0.9188 - val_loss: 0.4726 - val_accuracy: 0.8152\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.2116 - accuracy: 0.9191 - val_loss: 0.4333 - val_accuracy: 0.8325\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.2105 - accuracy: 0.9200 - val_loss: 0.4629 - val_accuracy: 0.8168\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.2100 - accuracy: 0.9211 - val_loss: 0.4865 - val_accuracy: 0.8105\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.2091 - accuracy: 0.9202 - val_loss: 0.4435 - val_accuracy: 0.8245\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.2077 - accuracy: 0.9211 - val_loss: 0.4436 - val_accuracy: 0.8291\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.2070 - accuracy: 0.9208 - val_loss: 0.4443 - val_accuracy: 0.8283\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.2062 - accuracy: 0.9214 - val_loss: 0.5094 - val_accuracy: 0.8064\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 922us/step - loss: 0.2063 - accuracy: 0.9213 - val_loss: 0.4923 - val_accuracy: 0.8084\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 893us/step - loss: 0.2042 - accuracy: 0.9222 - val_loss: 0.4597 - val_accuracy: 0.8204\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 852us/step - loss: 0.2045 - accuracy: 0.9217 - val_loss: 0.4673 - val_accuracy: 0.8164\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 907us/step - loss: 0.2031 - accuracy: 0.9220 - val_loss: 0.4988 - val_accuracy: 0.8049\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 811us/step - loss: 0.2028 - accuracy: 0.9222 - val_loss: 0.4605 - val_accuracy: 0.8216\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.2017 - accuracy: 0.9235 - val_loss: 0.4922 - val_accuracy: 0.8120\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.2017 - accuracy: 0.9230 - val_loss: 0.4631 - val_accuracy: 0.8195\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.2007 - accuracy: 0.9223 - val_loss: 0.4770 - val_accuracy: 0.8180\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.2004 - accuracy: 0.9238 - val_loss: 0.4599 - val_accuracy: 0.8228\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.1988 - accuracy: 0.9236 - val_loss: 0.5428 - val_accuracy: 0.7973\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.1985 - accuracy: 0.9239 - val_loss: 0.4856 - val_accuracy: 0.8144\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.1977 - accuracy: 0.9242 - val_loss: 0.4696 - val_accuracy: 0.8210\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5820 - accuracy: 0.6969 - val_loss: 0.5804 - val_accuracy: 0.6577\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 815us/step - loss: 0.4647 - accuracy: 0.7835 - val_loss: 0.5550 - val_accuracy: 0.6998\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.3878 - accuracy: 0.8329 - val_loss: 0.5023 - val_accuracy: 0.7744\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.3270 - accuracy: 0.8722 - val_loss: 0.4672 - val_accuracy: 0.8131\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2927 - accuracy: 0.8877 - val_loss: 0.4938 - val_accuracy: 0.8068\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.2747 - accuracy: 0.8948 - val_loss: 0.4467 - val_accuracy: 0.8290\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.2663 - accuracy: 0.8984 - val_loss: 0.4821 - val_accuracy: 0.8146\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.2592 - accuracy: 0.9004 - val_loss: 0.4329 - val_accuracy: 0.8325\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 861us/step - loss: 0.2556 - accuracy: 0.9019 - val_loss: 0.4703 - val_accuracy: 0.8189\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.2514 - accuracy: 0.9038 - val_loss: 0.4651 - val_accuracy: 0.8180\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 846us/step - loss: 0.2479 - accuracy: 0.9054 - val_loss: 0.5058 - val_accuracy: 0.8014\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.2441 - accuracy: 0.9073 - val_loss: 0.5380 - val_accuracy: 0.7906\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.2416 - accuracy: 0.9080 - val_loss: 0.4554 - val_accuracy: 0.8195\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.2395 - accuracy: 0.9082 - val_loss: 0.4505 - val_accuracy: 0.8216\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.2363 - accuracy: 0.9093 - val_loss: 0.4938 - val_accuracy: 0.8063\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 897us/step - loss: 0.2341 - accuracy: 0.9094 - val_loss: 0.4570 - val_accuracy: 0.8211\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.2322 - accuracy: 0.9109 - val_loss: 0.4451 - val_accuracy: 0.8251\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.2302 - accuracy: 0.9111 - val_loss: 0.4625 - val_accuracy: 0.8184\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.2280 - accuracy: 0.9128 - val_loss: 0.4458 - val_accuracy: 0.8203\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.2267 - accuracy: 0.9123 - val_loss: 0.4553 - val_accuracy: 0.8221\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.2251 - accuracy: 0.9133 - val_loss: 0.4356 - val_accuracy: 0.8326\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.2230 - accuracy: 0.9148 - val_loss: 0.4256 - val_accuracy: 0.8324\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.2213 - accuracy: 0.9150 - val_loss: 0.4679 - val_accuracy: 0.8163\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.2202 - accuracy: 0.9143 - val_loss: 0.4789 - val_accuracy: 0.8096\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2179 - accuracy: 0.9154 - val_loss: 0.4523 - val_accuracy: 0.8246\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2177 - accuracy: 0.9170 - val_loss: 0.4298 - val_accuracy: 0.8296\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2158 - accuracy: 0.9175 - val_loss: 0.4565 - val_accuracy: 0.8209\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.2153 - accuracy: 0.9178 - val_loss: 0.4721 - val_accuracy: 0.8139\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2136 - accuracy: 0.9176 - val_loss: 0.4653 - val_accuracy: 0.8168\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2134 - accuracy: 0.9179 - val_loss: 0.4690 - val_accuracy: 0.8199\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2120 - accuracy: 0.9181 - val_loss: 0.4303 - val_accuracy: 0.8318\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2104 - accuracy: 0.9187 - val_loss: 0.4478 - val_accuracy: 0.8258\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.2103 - accuracy: 0.9196 - val_loss: 0.4349 - val_accuracy: 0.8320\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2087 - accuracy: 0.9205 - val_loss: 0.4833 - val_accuracy: 0.8116\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2073 - accuracy: 0.9207 - val_loss: 0.4745 - val_accuracy: 0.8205\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2074 - accuracy: 0.9212 - val_loss: 0.4365 - val_accuracy: 0.8303\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2056 - accuracy: 0.9203 - val_loss: 0.4381 - val_accuracy: 0.8339\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2053 - accuracy: 0.9217 - val_loss: 0.4910 - val_accuracy: 0.8117\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2042 - accuracy: 0.9215 - val_loss: 0.4590 - val_accuracy: 0.8253\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2037 - accuracy: 0.9225 - val_loss: 0.4516 - val_accuracy: 0.8279\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.2026 - accuracy: 0.9228 - val_loss: 0.4531 - val_accuracy: 0.8249\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2022 - accuracy: 0.9225 - val_loss: 0.4452 - val_accuracy: 0.8274\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2014 - accuracy: 0.9232 - val_loss: 0.4373 - val_accuracy: 0.8293\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2001 - accuracy: 0.9233 - val_loss: 0.4931 - val_accuracy: 0.8111\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.2004 - accuracy: 0.9232 - val_loss: 0.4450 - val_accuracy: 0.8290\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.1994 - accuracy: 0.9243 - val_loss: 0.4393 - val_accuracy: 0.8280\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.1981 - accuracy: 0.9247 - val_loss: 0.4490 - val_accuracy: 0.8289\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.1976 - accuracy: 0.9242 - val_loss: 0.4469 - val_accuracy: 0.8297\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.1968 - accuracy: 0.9251 - val_loss: 0.4600 - val_accuracy: 0.8240\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.1973 - accuracy: 0.9249 - val_loss: 0.4970 - val_accuracy: 0.8141\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.5782 - accuracy: 0.6971 - val_loss: 0.5795 - val_accuracy: 0.6710\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.4561 - accuracy: 0.7857 - val_loss: 0.5037 - val_accuracy: 0.7584\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.3770 - accuracy: 0.8382 - val_loss: 0.5327 - val_accuracy: 0.7640\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.3199 - accuracy: 0.8741 - val_loss: 0.4696 - val_accuracy: 0.8205\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2913 - accuracy: 0.8889 - val_loss: 0.4935 - val_accuracy: 0.8149\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2764 - accuracy: 0.8946 - val_loss: 0.4635 - val_accuracy: 0.8264\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2688 - accuracy: 0.8970 - val_loss: 0.5023 - val_accuracy: 0.8120\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2634 - accuracy: 0.8995 - val_loss: 0.4826 - val_accuracy: 0.8164\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2597 - accuracy: 0.9005 - val_loss: 0.4675 - val_accuracy: 0.8233\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2560 - accuracy: 0.9015 - val_loss: 0.5176 - val_accuracy: 0.8012\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2532 - accuracy: 0.9028 - val_loss: 0.4795 - val_accuracy: 0.8172\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2500 - accuracy: 0.9035 - val_loss: 0.4725 - val_accuracy: 0.8182\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2481 - accuracy: 0.9045 - val_loss: 0.4602 - val_accuracy: 0.8231\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2457 - accuracy: 0.9058 - val_loss: 0.4736 - val_accuracy: 0.8158\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2438 - accuracy: 0.9065 - val_loss: 0.4916 - val_accuracy: 0.8116\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2418 - accuracy: 0.9066 - val_loss: 0.4834 - val_accuracy: 0.8129\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2394 - accuracy: 0.9088 - val_loss: 0.4641 - val_accuracy: 0.8216\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2378 - accuracy: 0.9084 - val_loss: 0.4481 - val_accuracy: 0.8249\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2362 - accuracy: 0.9087 - val_loss: 0.4461 - val_accuracy: 0.8234\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2343 - accuracy: 0.9096 - val_loss: 0.4649 - val_accuracy: 0.8188\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2323 - accuracy: 0.9103 - val_loss: 0.4657 - val_accuracy: 0.8186\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2309 - accuracy: 0.9102 - val_loss: 0.4403 - val_accuracy: 0.8264\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2297 - accuracy: 0.9114 - val_loss: 0.4805 - val_accuracy: 0.8139\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2280 - accuracy: 0.9112 - val_loss: 0.4629 - val_accuracy: 0.8217\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2269 - accuracy: 0.9123 - val_loss: 0.5298 - val_accuracy: 0.7892\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2244 - accuracy: 0.9127 - val_loss: 0.4382 - val_accuracy: 0.8270\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2237 - accuracy: 0.9133 - val_loss: 0.4603 - val_accuracy: 0.8221\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2219 - accuracy: 0.9144 - val_loss: 0.4714 - val_accuracy: 0.8172\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2214 - accuracy: 0.9139 - val_loss: 0.4456 - val_accuracy: 0.8237\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2196 - accuracy: 0.9157 - val_loss: 0.4107 - val_accuracy: 0.8399\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2184 - accuracy: 0.9155 - val_loss: 0.4889 - val_accuracy: 0.8118\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2175 - accuracy: 0.9151 - val_loss: 0.4462 - val_accuracy: 0.8231\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2158 - accuracy: 0.9158 - val_loss: 0.4583 - val_accuracy: 0.8214\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2158 - accuracy: 0.9166 - val_loss: 0.4141 - val_accuracy: 0.8415\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2137 - accuracy: 0.9167 - val_loss: 0.4514 - val_accuracy: 0.8263\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2133 - accuracy: 0.9175 - val_loss: 0.4460 - val_accuracy: 0.8272\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2112 - accuracy: 0.9189 - val_loss: 0.4430 - val_accuracy: 0.8308\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2112 - accuracy: 0.9186 - val_loss: 0.4622 - val_accuracy: 0.8212\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2101 - accuracy: 0.9189 - val_loss: 0.4576 - val_accuracy: 0.8248\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2087 - accuracy: 0.9197 - val_loss: 0.4583 - val_accuracy: 0.8224\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2076 - accuracy: 0.9203 - val_loss: 0.4730 - val_accuracy: 0.8204\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2072 - accuracy: 0.9205 - val_loss: 0.4317 - val_accuracy: 0.8321\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2062 - accuracy: 0.9205 - val_loss: 0.4220 - val_accuracy: 0.8407\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2053 - accuracy: 0.9205 - val_loss: 0.4751 - val_accuracy: 0.8186\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2036 - accuracy: 0.9220 - val_loss: 0.4027 - val_accuracy: 0.8497\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2042 - accuracy: 0.9214 - val_loss: 0.4177 - val_accuracy: 0.8414\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2025 - accuracy: 0.9214 - val_loss: 0.4586 - val_accuracy: 0.8251\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2025 - accuracy: 0.9226 - val_loss: 0.4466 - val_accuracy: 0.8283\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2017 - accuracy: 0.9228 - val_loss: 0.4741 - val_accuracy: 0.8199\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2014 - accuracy: 0.9225 - val_loss: 0.4374 - val_accuracy: 0.8366\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5782 - accuracy: 0.6990 - val_loss: 0.6127 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.4523 - accuracy: 0.7898 - val_loss: 0.5699 - val_accuracy: 0.7137\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.3734 - accuracy: 0.8444 - val_loss: 0.5159 - val_accuracy: 0.7871\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.3171 - accuracy: 0.8775 - val_loss: 0.5176 - val_accuracy: 0.7996\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2870 - accuracy: 0.8904 - val_loss: 0.4729 - val_accuracy: 0.8243\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2731 - accuracy: 0.8971 - val_loss: 0.4756 - val_accuracy: 0.8233\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2649 - accuracy: 0.8994 - val_loss: 0.4589 - val_accuracy: 0.8299\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2579 - accuracy: 0.9022 - val_loss: 0.4710 - val_accuracy: 0.8244\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2539 - accuracy: 0.9044 - val_loss: 0.4989 - val_accuracy: 0.8097\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2498 - accuracy: 0.9054 - val_loss: 0.4671 - val_accuracy: 0.8220\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2472 - accuracy: 0.9065 - val_loss: 0.4636 - val_accuracy: 0.8233\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2437 - accuracy: 0.9076 - val_loss: 0.4432 - val_accuracy: 0.8297\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2412 - accuracy: 0.9084 - val_loss: 0.3944 - val_accuracy: 0.8479\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2385 - accuracy: 0.9100 - val_loss: 0.4613 - val_accuracy: 0.8212\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2358 - accuracy: 0.9101 - val_loss: 0.4413 - val_accuracy: 0.8293\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 857us/step - loss: 0.2337 - accuracy: 0.9112 - val_loss: 0.4569 - val_accuracy: 0.8248\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 914us/step - loss: 0.2320 - accuracy: 0.9116 - val_loss: 0.4530 - val_accuracy: 0.8257\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 800us/step - loss: 0.2301 - accuracy: 0.9129 - val_loss: 0.4809 - val_accuracy: 0.8131\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.2284 - accuracy: 0.9128 - val_loss: 0.4598 - val_accuracy: 0.8219\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.2260 - accuracy: 0.9140 - val_loss: 0.4371 - val_accuracy: 0.8337\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.2243 - accuracy: 0.9137 - val_loss: 0.4527 - val_accuracy: 0.8263\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.2224 - accuracy: 0.9148 - val_loss: 0.4632 - val_accuracy: 0.8261\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.2209 - accuracy: 0.9162 - val_loss: 0.4377 - val_accuracy: 0.8303\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.2193 - accuracy: 0.9170 - val_loss: 0.4405 - val_accuracy: 0.8322\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.2189 - accuracy: 0.9166 - val_loss: 0.4560 - val_accuracy: 0.8251\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.2163 - accuracy: 0.9180 - val_loss: 0.4744 - val_accuracy: 0.8201\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.2148 - accuracy: 0.9181 - val_loss: 0.4305 - val_accuracy: 0.8337\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.2145 - accuracy: 0.9182 - val_loss: 0.4622 - val_accuracy: 0.8200\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.2120 - accuracy: 0.9194 - val_loss: 0.4684 - val_accuracy: 0.8245\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.2120 - accuracy: 0.9190 - val_loss: 0.4998 - val_accuracy: 0.8091\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 708us/step - loss: 0.2102 - accuracy: 0.9191 - val_loss: 0.5137 - val_accuracy: 0.8059\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.2089 - accuracy: 0.9191 - val_loss: 0.4488 - val_accuracy: 0.8308\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.2084 - accuracy: 0.9204 - val_loss: 0.4475 - val_accuracy: 0.8325\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.2076 - accuracy: 0.9216 - val_loss: 0.4314 - val_accuracy: 0.8331\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.2062 - accuracy: 0.9219 - val_loss: 0.4747 - val_accuracy: 0.8200\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.2056 - accuracy: 0.9221 - val_loss: 0.4541 - val_accuracy: 0.8320\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.2039 - accuracy: 0.9222 - val_loss: 0.4967 - val_accuracy: 0.8125\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.2032 - accuracy: 0.9224 - val_loss: 0.4758 - val_accuracy: 0.8207\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.2025 - accuracy: 0.9231 - val_loss: 0.4749 - val_accuracy: 0.8186\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.2008 - accuracy: 0.9227 - val_loss: 0.4665 - val_accuracy: 0.8275\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.1989 - accuracy: 0.9241 - val_loss: 0.4850 - val_accuracy: 0.8154\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.1997 - accuracy: 0.9230 - val_loss: 0.4054 - val_accuracy: 0.8452\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 699us/step - loss: 0.1989 - accuracy: 0.9241 - val_loss: 0.4596 - val_accuracy: 0.8313\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.1984 - accuracy: 0.9243 - val_loss: 0.4311 - val_accuracy: 0.8340\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.1970 - accuracy: 0.9247 - val_loss: 0.4422 - val_accuracy: 0.8311\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.1961 - accuracy: 0.9257 - val_loss: 0.4651 - val_accuracy: 0.8282\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.1961 - accuracy: 0.9250 - val_loss: 0.4465 - val_accuracy: 0.8322\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.1946 - accuracy: 0.9256 - val_loss: 0.4400 - val_accuracy: 0.8351\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.1943 - accuracy: 0.9258 - val_loss: 0.4768 - val_accuracy: 0.8184\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.1941 - accuracy: 0.9257 - val_loss: 0.4314 - val_accuracy: 0.8357\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.5790 - accuracy: 0.6969 - val_loss: 0.5814 - val_accuracy: 0.6872\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.4606 - accuracy: 0.7832 - val_loss: 0.5387 - val_accuracy: 0.7316\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 765us/step - loss: 0.3823 - accuracy: 0.8363 - val_loss: 0.5309 - val_accuracy: 0.7673\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.3205 - accuracy: 0.8773 - val_loss: 0.4539 - val_accuracy: 0.8318\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.2876 - accuracy: 0.8908 - val_loss: 0.4632 - val_accuracy: 0.8294\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.2721 - accuracy: 0.8966 - val_loss: 0.4590 - val_accuracy: 0.8317\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.2633 - accuracy: 0.9010 - val_loss: 0.4550 - val_accuracy: 0.8337\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.2595 - accuracy: 0.9026 - val_loss: 0.4674 - val_accuracy: 0.8270\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 841us/step - loss: 0.2550 - accuracy: 0.9037 - val_loss: 0.5068 - val_accuracy: 0.8075\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.2519 - accuracy: 0.9048 - val_loss: 0.4534 - val_accuracy: 0.8293\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.2491 - accuracy: 0.9065 - val_loss: 0.4927 - val_accuracy: 0.8146\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.2460 - accuracy: 0.9071 - val_loss: 0.4935 - val_accuracy: 0.8134\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.2439 - accuracy: 0.9069 - val_loss: 0.5402 - val_accuracy: 0.7937\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.2418 - accuracy: 0.9080 - val_loss: 0.4586 - val_accuracy: 0.8270\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 832us/step - loss: 0.2389 - accuracy: 0.9088 - val_loss: 0.5022 - val_accuracy: 0.8100\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.2370 - accuracy: 0.9113 - val_loss: 0.4757 - val_accuracy: 0.8185\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.2356 - accuracy: 0.9108 - val_loss: 0.4945 - val_accuracy: 0.8126\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 828us/step - loss: 0.2342 - accuracy: 0.9120 - val_loss: 0.4777 - val_accuracy: 0.8168\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.2324 - accuracy: 0.9123 - val_loss: 0.4692 - val_accuracy: 0.8204\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.2309 - accuracy: 0.9128 - val_loss: 0.4629 - val_accuracy: 0.8252\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.2288 - accuracy: 0.9131 - val_loss: 0.4620 - val_accuracy: 0.8244\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.2277 - accuracy: 0.9152 - val_loss: 0.4315 - val_accuracy: 0.8308\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.2264 - accuracy: 0.9144 - val_loss: 0.4674 - val_accuracy: 0.8212\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.2243 - accuracy: 0.9154 - val_loss: 0.4733 - val_accuracy: 0.8192\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2237 - accuracy: 0.9156 - val_loss: 0.4542 - val_accuracy: 0.8264\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.2212 - accuracy: 0.9166 - val_loss: 0.4670 - val_accuracy: 0.8225\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.2210 - accuracy: 0.9165 - val_loss: 0.4506 - val_accuracy: 0.8258\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.2193 - accuracy: 0.9176 - val_loss: 0.4523 - val_accuracy: 0.8238\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.2186 - accuracy: 0.9174 - val_loss: 0.5038 - val_accuracy: 0.8067\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.2172 - accuracy: 0.9177 - val_loss: 0.4833 - val_accuracy: 0.8123\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.2160 - accuracy: 0.9186 - val_loss: 0.4931 - val_accuracy: 0.8129\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.2142 - accuracy: 0.9185 - val_loss: 0.4546 - val_accuracy: 0.8254\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.2135 - accuracy: 0.9191 - val_loss: 0.4715 - val_accuracy: 0.8206\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.2128 - accuracy: 0.9197 - val_loss: 0.4565 - val_accuracy: 0.8254\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.2119 - accuracy: 0.9194 - val_loss: 0.4265 - val_accuracy: 0.8358\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.2108 - accuracy: 0.9205 - val_loss: 0.4835 - val_accuracy: 0.8142\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.2085 - accuracy: 0.9202 - val_loss: 0.4644 - val_accuracy: 0.8223\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.2087 - accuracy: 0.9204 - val_loss: 0.4326 - val_accuracy: 0.8303\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.2076 - accuracy: 0.9211 - val_loss: 0.4828 - val_accuracy: 0.8174\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.2073 - accuracy: 0.9210 - val_loss: 0.4939 - val_accuracy: 0.8117\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.2060 - accuracy: 0.9212 - val_loss: 0.4615 - val_accuracy: 0.8270\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.2052 - accuracy: 0.9215 - val_loss: 0.4602 - val_accuracy: 0.8263\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.2043 - accuracy: 0.9225 - val_loss: 0.4369 - val_accuracy: 0.8337\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.2038 - accuracy: 0.9225 - val_loss: 0.5080 - val_accuracy: 0.8090\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2025 - accuracy: 0.9223 - val_loss: 0.4640 - val_accuracy: 0.8243\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.2017 - accuracy: 0.9228 - val_loss: 0.4716 - val_accuracy: 0.8217\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.2011 - accuracy: 0.9227 - val_loss: 0.4469 - val_accuracy: 0.8278\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.2012 - accuracy: 0.9228 - val_loss: 0.4892 - val_accuracy: 0.8164\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.1996 - accuracy: 0.9238 - val_loss: 0.4535 - val_accuracy: 0.8300\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.1991 - accuracy: 0.9245 - val_loss: 0.4485 - val_accuracy: 0.8314\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelo sin DP (como en el código original)\n",
    "print(\"Entrenando modelo sin DP...\")\n",
    "results_no_dp = run_iterations(\n",
    "    X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "    batch_size, epochs, use_dp=False, n_iterations=n_iterations,\n",
    "    num_microbatches=None, l2_norm_clip=None, noise_multiplier=None\n",
    ")\n",
    "results_no_dp_stats = compute_statistics(results_no_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b15ceca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar experimentos variando un parámetro a la vez\n",
    "n = len(X_train_filtered)\n",
    "delta = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbdd0d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo con num_microbatches=4...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.7372 - accuracy: 0.4603 - val_loss: 0.7075 - val_accuracy: 0.3656\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.7106 - accuracy: 0.4782 - val_loss: 0.7299 - val_accuracy: 0.2497\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.7038 - accuracy: 0.4959 - val_loss: 0.7257 - val_accuracy: 0.2735\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6983 - accuracy: 0.5099 - val_loss: 0.7163 - val_accuracy: 0.3612\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6921 - accuracy: 0.5273 - val_loss: 0.7146 - val_accuracy: 0.4150\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6874 - accuracy: 0.5435 - val_loss: 0.7093 - val_accuracy: 0.4619\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6833 - accuracy: 0.5557 - val_loss: 0.7035 - val_accuracy: 0.4952\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.6786 - accuracy: 0.5680 - val_loss: 0.7013 - val_accuracy: 0.5185\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6750 - accuracy: 0.5790 - val_loss: 0.6940 - val_accuracy: 0.5553\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6713 - accuracy: 0.5929 - val_loss: 0.6902 - val_accuracy: 0.5681\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6690 - accuracy: 0.5955 - val_loss: 0.6873 - val_accuracy: 0.5736\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6650 - accuracy: 0.6089 - val_loss: 0.6842 - val_accuracy: 0.5781\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6627 - accuracy: 0.6144 - val_loss: 0.6820 - val_accuracy: 0.5782\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.6600 - accuracy: 0.6182 - val_loss: 0.6777 - val_accuracy: 0.5871\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6568 - accuracy: 0.6303 - val_loss: 0.6749 - val_accuracy: 0.5908\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6548 - accuracy: 0.6337 - val_loss: 0.6726 - val_accuracy: 0.5946\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6521 - accuracy: 0.6402 - val_loss: 0.6733 - val_accuracy: 0.5886\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6492 - accuracy: 0.6434 - val_loss: 0.6701 - val_accuracy: 0.5914\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.6467 - accuracy: 0.6480 - val_loss: 0.6674 - val_accuracy: 0.5935\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6445 - accuracy: 0.6527 - val_loss: 0.6690 - val_accuracy: 0.5876\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6413 - accuracy: 0.6572 - val_loss: 0.6623 - val_accuracy: 0.5991\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6389 - accuracy: 0.6629 - val_loss: 0.6599 - val_accuracy: 0.6047\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6355 - accuracy: 0.6643 - val_loss: 0.6552 - val_accuracy: 0.6126\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6323 - accuracy: 0.6687 - val_loss: 0.6532 - val_accuracy: 0.6130\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6295 - accuracy: 0.6710 - val_loss: 0.6535 - val_accuracy: 0.6102\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6273 - accuracy: 0.6745 - val_loss: 0.6521 - val_accuracy: 0.6096\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6256 - accuracy: 0.6772 - val_loss: 0.6482 - val_accuracy: 0.6106\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6233 - accuracy: 0.6780 - val_loss: 0.6440 - val_accuracy: 0.6140\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6209 - accuracy: 0.6792 - val_loss: 0.6444 - val_accuracy: 0.6112\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6186 - accuracy: 0.6812 - val_loss: 0.6447 - val_accuracy: 0.6088\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6158 - accuracy: 0.6852 - val_loss: 0.6428 - val_accuracy: 0.6130\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6131 - accuracy: 0.6894 - val_loss: 0.6382 - val_accuracy: 0.6226\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6114 - accuracy: 0.6886 - val_loss: 0.6385 - val_accuracy: 0.6220\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6099 - accuracy: 0.6882 - val_loss: 0.6370 - val_accuracy: 0.6221\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6070 - accuracy: 0.6926 - val_loss: 0.6329 - val_accuracy: 0.6252\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6049 - accuracy: 0.6914 - val_loss: 0.6318 - val_accuracy: 0.6270\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6026 - accuracy: 0.6950 - val_loss: 0.6340 - val_accuracy: 0.6242\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6005 - accuracy: 0.6971 - val_loss: 0.6347 - val_accuracy: 0.6220\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5985 - accuracy: 0.6984 - val_loss: 0.6291 - val_accuracy: 0.6287\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5968 - accuracy: 0.6976 - val_loss: 0.6282 - val_accuracy: 0.6277\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5946 - accuracy: 0.6998 - val_loss: 0.6276 - val_accuracy: 0.6271\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.5933 - accuracy: 0.7012 - val_loss: 0.6162 - val_accuracy: 0.6389\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5910 - accuracy: 0.7034 - val_loss: 0.6231 - val_accuracy: 0.6292\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5891 - accuracy: 0.7037 - val_loss: 0.6289 - val_accuracy: 0.6248\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5875 - accuracy: 0.7040 - val_loss: 0.6195 - val_accuracy: 0.6310\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5853 - accuracy: 0.7075 - val_loss: 0.6201 - val_accuracy: 0.6302\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5837 - accuracy: 0.7085 - val_loss: 0.6216 - val_accuracy: 0.6295\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5830 - accuracy: 0.7091 - val_loss: 0.6102 - val_accuracy: 0.6388\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5802 - accuracy: 0.7110 - val_loss: 0.6197 - val_accuracy: 0.6292\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5799 - accuracy: 0.7085 - val_loss: 0.6178 - val_accuracy: 0.6295\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.7339 - accuracy: 0.5012 - val_loss: 0.6752 - val_accuracy: 0.6082\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6941 - accuracy: 0.5359 - val_loss: 0.7002 - val_accuracy: 0.4665\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6842 - accuracy: 0.5596 - val_loss: 0.6974 - val_accuracy: 0.4732\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6759 - accuracy: 0.5841 - val_loss: 0.6892 - val_accuracy: 0.5173\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6712 - accuracy: 0.5952 - val_loss: 0.6848 - val_accuracy: 0.5492\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6641 - accuracy: 0.6100 - val_loss: 0.6855 - val_accuracy: 0.5457\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6593 - accuracy: 0.6197 - val_loss: 0.6774 - val_accuracy: 0.5734\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6555 - accuracy: 0.6268 - val_loss: 0.6738 - val_accuracy: 0.5816\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6515 - accuracy: 0.6362 - val_loss: 0.6726 - val_accuracy: 0.5840\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6481 - accuracy: 0.6380 - val_loss: 0.6643 - val_accuracy: 0.6043\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6452 - accuracy: 0.6423 - val_loss: 0.6651 - val_accuracy: 0.5975\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6413 - accuracy: 0.6465 - val_loss: 0.6643 - val_accuracy: 0.5959\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6382 - accuracy: 0.6527 - val_loss: 0.6527 - val_accuracy: 0.6185\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6349 - accuracy: 0.6556 - val_loss: 0.6580 - val_accuracy: 0.6033\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6321 - accuracy: 0.6602 - val_loss: 0.6530 - val_accuracy: 0.6099\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6289 - accuracy: 0.6649 - val_loss: 0.6498 - val_accuracy: 0.6134\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6270 - accuracy: 0.6615 - val_loss: 0.6481 - val_accuracy: 0.6135\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6242 - accuracy: 0.6680 - val_loss: 0.6475 - val_accuracy: 0.6115\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6220 - accuracy: 0.6687 - val_loss: 0.6476 - val_accuracy: 0.6086\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6192 - accuracy: 0.6697 - val_loss: 0.6451 - val_accuracy: 0.6141\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6166 - accuracy: 0.6745 - val_loss: 0.6377 - val_accuracy: 0.6298\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6156 - accuracy: 0.6722 - val_loss: 0.6364 - val_accuracy: 0.6302\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6132 - accuracy: 0.6747 - val_loss: 0.6380 - val_accuracy: 0.6245\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6109 - accuracy: 0.6768 - val_loss: 0.6276 - val_accuracy: 0.6434\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6074 - accuracy: 0.6812 - val_loss: 0.6322 - val_accuracy: 0.6320\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6067 - accuracy: 0.6797 - val_loss: 0.6304 - val_accuracy: 0.6341\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6053 - accuracy: 0.6801 - val_loss: 0.6303 - val_accuracy: 0.6329\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6032 - accuracy: 0.6820 - val_loss: 0.6325 - val_accuracy: 0.6277\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6010 - accuracy: 0.6860 - val_loss: 0.6294 - val_accuracy: 0.6309\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5988 - accuracy: 0.6843 - val_loss: 0.6253 - val_accuracy: 0.6365\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5975 - accuracy: 0.6859 - val_loss: 0.6265 - val_accuracy: 0.6334\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5953 - accuracy: 0.6879 - val_loss: 0.6301 - val_accuracy: 0.6265\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5945 - accuracy: 0.6881 - val_loss: 0.6266 - val_accuracy: 0.6318\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.5927 - accuracy: 0.6883 - val_loss: 0.6218 - val_accuracy: 0.6366\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5912 - accuracy: 0.6908 - val_loss: 0.6174 - val_accuracy: 0.6420\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5881 - accuracy: 0.6943 - val_loss: 0.6240 - val_accuracy: 0.6298\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5873 - accuracy: 0.6935 - val_loss: 0.6183 - val_accuracy: 0.6370\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5854 - accuracy: 0.6958 - val_loss: 0.6234 - val_accuracy: 0.6295\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5842 - accuracy: 0.6955 - val_loss: 0.6200 - val_accuracy: 0.6321\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5838 - accuracy: 0.6960 - val_loss: 0.6211 - val_accuracy: 0.6294\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5818 - accuracy: 0.6993 - val_loss: 0.6173 - val_accuracy: 0.6324\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.5798 - accuracy: 0.6997 - val_loss: 0.6186 - val_accuracy: 0.6299\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5780 - accuracy: 0.7010 - val_loss: 0.6114 - val_accuracy: 0.6359\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5772 - accuracy: 0.7016 - val_loss: 0.6156 - val_accuracy: 0.6301\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5765 - accuracy: 0.7024 - val_loss: 0.6126 - val_accuracy: 0.6329\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5745 - accuracy: 0.7042 - val_loss: 0.6169 - val_accuracy: 0.6272\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5724 - accuracy: 0.7068 - val_loss: 0.6224 - val_accuracy: 0.6205\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5719 - accuracy: 0.7071 - val_loss: 0.6111 - val_accuracy: 0.6313\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5705 - accuracy: 0.7085 - val_loss: 0.6141 - val_accuracy: 0.6272\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5699 - accuracy: 0.7081 - val_loss: 0.6147 - val_accuracy: 0.6265\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.7684 - accuracy: 0.3438WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.7231 - accuracy: 0.4777 - val_loss: 0.7105 - val_accuracy: 0.4217\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.7119 - accuracy: 0.4944 - val_loss: 0.7170 - val_accuracy: 0.3756\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.7028 - accuracy: 0.5089 - val_loss: 0.7039 - val_accuracy: 0.4608\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6945 - accuracy: 0.5235 - val_loss: 0.6997 - val_accuracy: 0.4988\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6893 - accuracy: 0.5359 - val_loss: 0.6928 - val_accuracy: 0.5542\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6821 - accuracy: 0.5488 - val_loss: 0.6933 - val_accuracy: 0.5555\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6765 - accuracy: 0.5632 - val_loss: 0.6894 - val_accuracy: 0.5733\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6723 - accuracy: 0.5702 - val_loss: 0.6840 - val_accuracy: 0.5954\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6668 - accuracy: 0.5833 - val_loss: 0.6811 - val_accuracy: 0.6025\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6632 - accuracy: 0.5910 - val_loss: 0.6823 - val_accuracy: 0.5966\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6584 - accuracy: 0.6007 - val_loss: 0.6765 - val_accuracy: 0.6105\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6552 - accuracy: 0.6067 - val_loss: 0.6741 - val_accuracy: 0.6133\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6530 - accuracy: 0.6112 - val_loss: 0.6699 - val_accuracy: 0.6204\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6486 - accuracy: 0.6192 - val_loss: 0.6671 - val_accuracy: 0.6239\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6447 - accuracy: 0.6289 - val_loss: 0.6565 - val_accuracy: 0.6453\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6426 - accuracy: 0.6304 - val_loss: 0.6545 - val_accuracy: 0.6456\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6391 - accuracy: 0.6368 - val_loss: 0.6538 - val_accuracy: 0.6441\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6366 - accuracy: 0.6390 - val_loss: 0.6538 - val_accuracy: 0.6399\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6330 - accuracy: 0.6461 - val_loss: 0.6488 - val_accuracy: 0.6464\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6309 - accuracy: 0.6491 - val_loss: 0.6559 - val_accuracy: 0.6319\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6278 - accuracy: 0.6507 - val_loss: 0.6509 - val_accuracy: 0.6373\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6263 - accuracy: 0.6542 - val_loss: 0.6424 - val_accuracy: 0.6493\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6235 - accuracy: 0.6563 - val_loss: 0.6449 - val_accuracy: 0.6434\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6209 - accuracy: 0.6601 - val_loss: 0.6404 - val_accuracy: 0.6474\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6198 - accuracy: 0.6610 - val_loss: 0.6408 - val_accuracy: 0.6451\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6161 - accuracy: 0.6651 - val_loss: 0.6367 - val_accuracy: 0.6487\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6140 - accuracy: 0.6656 - val_loss: 0.6339 - val_accuracy: 0.6514\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.6116 - accuracy: 0.6688 - val_loss: 0.6313 - val_accuracy: 0.6539\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6101 - accuracy: 0.6702 - val_loss: 0.6356 - val_accuracy: 0.6467\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.6081 - accuracy: 0.6710 - val_loss: 0.6263 - val_accuracy: 0.6583\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.6065 - accuracy: 0.6753 - val_loss: 0.6280 - val_accuracy: 0.6538\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6048 - accuracy: 0.6770 - val_loss: 0.6219 - val_accuracy: 0.6617\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6018 - accuracy: 0.6780 - val_loss: 0.6281 - val_accuracy: 0.6519\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6014 - accuracy: 0.6780 - val_loss: 0.6285 - val_accuracy: 0.6500\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5994 - accuracy: 0.6823 - val_loss: 0.6295 - val_accuracy: 0.6482\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.5974 - accuracy: 0.6848 - val_loss: 0.6196 - val_accuracy: 0.6587\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5961 - accuracy: 0.6853 - val_loss: 0.6193 - val_accuracy: 0.6575\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5941 - accuracy: 0.6858 - val_loss: 0.6155 - val_accuracy: 0.6618\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5938 - accuracy: 0.6884 - val_loss: 0.6143 - val_accuracy: 0.6638\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.5917 - accuracy: 0.6905 - val_loss: 0.6170 - val_accuracy: 0.6584\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.5896 - accuracy: 0.6893 - val_loss: 0.6104 - val_accuracy: 0.6654\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.5881 - accuracy: 0.6935 - val_loss: 0.6193 - val_accuracy: 0.6545\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5874 - accuracy: 0.6940 - val_loss: 0.6135 - val_accuracy: 0.6595\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5863 - accuracy: 0.6950 - val_loss: 0.6118 - val_accuracy: 0.6597\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.5842 - accuracy: 0.6971 - val_loss: 0.6201 - val_accuracy: 0.6518\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.5831 - accuracy: 0.6984 - val_loss: 0.6106 - val_accuracy: 0.6593\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.5811 - accuracy: 0.7003 - val_loss: 0.6097 - val_accuracy: 0.6597\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.5805 - accuracy: 0.7030 - val_loss: 0.6079 - val_accuracy: 0.6597\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5791 - accuracy: 0.7033 - val_loss: 0.6109 - val_accuracy: 0.6577\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.5787 - accuracy: 0.7042 - val_loss: 0.6152 - val_accuracy: 0.6514\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.7080 - accuracy: 0.5167 - val_loss: 0.6981 - val_accuracy: 0.4830\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6854 - accuracy: 0.5576 - val_loss: 0.7068 - val_accuracy: 0.4611\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6781 - accuracy: 0.5764 - val_loss: 0.7042 - val_accuracy: 0.4807\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6750 - accuracy: 0.5883 - val_loss: 0.6923 - val_accuracy: 0.5228\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6688 - accuracy: 0.6010 - val_loss: 0.6912 - val_accuracy: 0.5310\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6649 - accuracy: 0.6123 - val_loss: 0.6868 - val_accuracy: 0.5435\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6609 - accuracy: 0.6208 - val_loss: 0.6843 - val_accuracy: 0.5486\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6581 - accuracy: 0.6266 - val_loss: 0.6825 - val_accuracy: 0.5515\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6540 - accuracy: 0.6323 - val_loss: 0.6765 - val_accuracy: 0.5657\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6500 - accuracy: 0.6411 - val_loss: 0.6747 - val_accuracy: 0.5723\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6473 - accuracy: 0.6440 - val_loss: 0.6673 - val_accuracy: 0.5840\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6439 - accuracy: 0.6484 - val_loss: 0.6648 - val_accuracy: 0.5876\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6412 - accuracy: 0.6520 - val_loss: 0.6668 - val_accuracy: 0.5864\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6387 - accuracy: 0.6564 - val_loss: 0.6649 - val_accuracy: 0.5881\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6351 - accuracy: 0.6615 - val_loss: 0.6628 - val_accuracy: 0.5908\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6339 - accuracy: 0.6614 - val_loss: 0.6584 - val_accuracy: 0.5959\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6307 - accuracy: 0.6661 - val_loss: 0.6560 - val_accuracy: 0.6000\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.6285 - accuracy: 0.6671 - val_loss: 0.6525 - val_accuracy: 0.6051\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6255 - accuracy: 0.6711 - val_loss: 0.6512 - val_accuracy: 0.6054\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6235 - accuracy: 0.6739 - val_loss: 0.6512 - val_accuracy: 0.6048\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6215 - accuracy: 0.6748 - val_loss: 0.6461 - val_accuracy: 0.6100\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.6203 - accuracy: 0.6746 - val_loss: 0.6405 - val_accuracy: 0.6175\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6189 - accuracy: 0.6754 - val_loss: 0.6449 - val_accuracy: 0.6105\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6155 - accuracy: 0.6789 - val_loss: 0.6437 - val_accuracy: 0.6117\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6141 - accuracy: 0.6810 - val_loss: 0.6413 - val_accuracy: 0.6144\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6124 - accuracy: 0.6818 - val_loss: 0.6397 - val_accuracy: 0.6154\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6107 - accuracy: 0.6824 - val_loss: 0.6291 - val_accuracy: 0.6281\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6082 - accuracy: 0.6862 - val_loss: 0.6337 - val_accuracy: 0.6219\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6069 - accuracy: 0.6831 - val_loss: 0.6302 - val_accuracy: 0.6256\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6062 - accuracy: 0.6856 - val_loss: 0.6333 - val_accuracy: 0.6207\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6024 - accuracy: 0.6903 - val_loss: 0.6266 - val_accuracy: 0.6276\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6023 - accuracy: 0.6877 - val_loss: 0.6324 - val_accuracy: 0.6194\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.5998 - accuracy: 0.6915 - val_loss: 0.6239 - val_accuracy: 0.6277\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.5981 - accuracy: 0.6931 - val_loss: 0.6265 - val_accuracy: 0.6244\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5979 - accuracy: 0.6939 - val_loss: 0.6257 - val_accuracy: 0.6238\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.5950 - accuracy: 0.6962 - val_loss: 0.6254 - val_accuracy: 0.6241\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.5937 - accuracy: 0.6966 - val_loss: 0.6222 - val_accuracy: 0.6267\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.5935 - accuracy: 0.6956 - val_loss: 0.6257 - val_accuracy: 0.6227\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.5911 - accuracy: 0.6984 - val_loss: 0.6251 - val_accuracy: 0.6222\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5897 - accuracy: 0.6997 - val_loss: 0.6218 - val_accuracy: 0.6257\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5887 - accuracy: 0.7011 - val_loss: 0.6226 - val_accuracy: 0.6239\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5868 - accuracy: 0.7020 - val_loss: 0.6170 - val_accuracy: 0.6302\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.5864 - accuracy: 0.7020 - val_loss: 0.6211 - val_accuracy: 0.6227\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5841 - accuracy: 0.7035 - val_loss: 0.6163 - val_accuracy: 0.6279\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.5829 - accuracy: 0.7049 - val_loss: 0.6234 - val_accuracy: 0.6186\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5817 - accuracy: 0.7051 - val_loss: 0.6142 - val_accuracy: 0.6284\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.5804 - accuracy: 0.7072 - val_loss: 0.6159 - val_accuracy: 0.6263\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.5795 - accuracy: 0.7074 - val_loss: 0.6179 - val_accuracy: 0.6234\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5778 - accuracy: 0.7103 - val_loss: 0.6144 - val_accuracy: 0.6277\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.5762 - accuracy: 0.7104 - val_loss: 0.6095 - val_accuracy: 0.6320\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6935 - accuracy: 0.5451 - val_loss: 0.7229 - val_accuracy: 0.4174\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6816 - accuracy: 0.5695 - val_loss: 0.7009 - val_accuracy: 0.5058\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6733 - accuracy: 0.5888 - val_loss: 0.6949 - val_accuracy: 0.5347\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6672 - accuracy: 0.6046 - val_loss: 0.6865 - val_accuracy: 0.5594\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6607 - accuracy: 0.6157 - val_loss: 0.6822 - val_accuracy: 0.5734\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.6556 - accuracy: 0.6267 - val_loss: 0.6762 - val_accuracy: 0.5798\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6521 - accuracy: 0.6336 - val_loss: 0.6747 - val_accuracy: 0.5807\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6478 - accuracy: 0.6399 - val_loss: 0.6694 - val_accuracy: 0.5880\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6450 - accuracy: 0.6433 - val_loss: 0.6667 - val_accuracy: 0.5922\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6426 - accuracy: 0.6465 - val_loss: 0.6647 - val_accuracy: 0.5949\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6393 - accuracy: 0.6504 - val_loss: 0.6627 - val_accuracy: 0.5964\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6364 - accuracy: 0.6543 - val_loss: 0.6575 - val_accuracy: 0.6040\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6338 - accuracy: 0.6555 - val_loss: 0.6567 - val_accuracy: 0.6038\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6317 - accuracy: 0.6591 - val_loss: 0.6543 - val_accuracy: 0.6050\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6294 - accuracy: 0.6625 - val_loss: 0.6529 - val_accuracy: 0.6057\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6267 - accuracy: 0.6630 - val_loss: 0.6508 - val_accuracy: 0.6069\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6240 - accuracy: 0.6698 - val_loss: 0.6450 - val_accuracy: 0.6105\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6208 - accuracy: 0.6738 - val_loss: 0.6533 - val_accuracy: 0.6000\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6186 - accuracy: 0.6731 - val_loss: 0.6446 - val_accuracy: 0.6079\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6177 - accuracy: 0.6755 - val_loss: 0.6471 - val_accuracy: 0.6038\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6152 - accuracy: 0.6774 - val_loss: 0.6412 - val_accuracy: 0.6073\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6134 - accuracy: 0.6788 - val_loss: 0.6421 - val_accuracy: 0.6068\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.6111 - accuracy: 0.6811 - val_loss: 0.6351 - val_accuracy: 0.6143\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6093 - accuracy: 0.6823 - val_loss: 0.6380 - val_accuracy: 0.6094\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6082 - accuracy: 0.6819 - val_loss: 0.6350 - val_accuracy: 0.6151\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6058 - accuracy: 0.6851 - val_loss: 0.6352 - val_accuracy: 0.6152\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6038 - accuracy: 0.6864 - val_loss: 0.6368 - val_accuracy: 0.6146\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6018 - accuracy: 0.6889 - val_loss: 0.6247 - val_accuracy: 0.6290\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6002 - accuracy: 0.6921 - val_loss: 0.6279 - val_accuracy: 0.6266\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.5976 - accuracy: 0.6914 - val_loss: 0.6292 - val_accuracy: 0.6248\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.5971 - accuracy: 0.6956 - val_loss: 0.6283 - val_accuracy: 0.6265\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.5960 - accuracy: 0.6936 - val_loss: 0.6271 - val_accuracy: 0.6277\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5945 - accuracy: 0.6940 - val_loss: 0.6274 - val_accuracy: 0.6288\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.5919 - accuracy: 0.6967 - val_loss: 0.6279 - val_accuracy: 0.6277\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5908 - accuracy: 0.6967 - val_loss: 0.6217 - val_accuracy: 0.6366\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5899 - accuracy: 0.6990 - val_loss: 0.6155 - val_accuracy: 0.6419\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5879 - accuracy: 0.7010 - val_loss: 0.6173 - val_accuracy: 0.6396\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.5870 - accuracy: 0.7017 - val_loss: 0.6224 - val_accuracy: 0.6337\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.5867 - accuracy: 0.7000 - val_loss: 0.6204 - val_accuracy: 0.6361\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5842 - accuracy: 0.7034 - val_loss: 0.6237 - val_accuracy: 0.6332\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5833 - accuracy: 0.7048 - val_loss: 0.6183 - val_accuracy: 0.6383\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5820 - accuracy: 0.7048 - val_loss: 0.6214 - val_accuracy: 0.6346\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5798 - accuracy: 0.7085 - val_loss: 0.6185 - val_accuracy: 0.6362\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5794 - accuracy: 0.7053 - val_loss: 0.6089 - val_accuracy: 0.6410\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5784 - accuracy: 0.7064 - val_loss: 0.6174 - val_accuracy: 0.6349\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5770 - accuracy: 0.7087 - val_loss: 0.6182 - val_accuracy: 0.6334\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5762 - accuracy: 0.7097 - val_loss: 0.6102 - val_accuracy: 0.6374\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5742 - accuracy: 0.7090 - val_loss: 0.6143 - val_accuracy: 0.6336\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5729 - accuracy: 0.7119 - val_loss: 0.6126 - val_accuracy: 0.6343\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.5721 - accuracy: 0.7122 - val_loss: 0.6089 - val_accuracy: 0.6355\n",
      "\n",
      "Entrenando modelo con num_microbatches=8...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6865 - accuracy: 0.5328 - val_loss: 0.7200 - val_accuracy: 0.3574\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6779 - accuracy: 0.5632 - val_loss: 0.7060 - val_accuracy: 0.4746\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6724 - accuracy: 0.5823 - val_loss: 0.6965 - val_accuracy: 0.5338\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6688 - accuracy: 0.5953 - val_loss: 0.6900 - val_accuracy: 0.5608\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6652 - accuracy: 0.6040 - val_loss: 0.6839 - val_accuracy: 0.5896\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6614 - accuracy: 0.6157 - val_loss: 0.6807 - val_accuracy: 0.6004\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6584 - accuracy: 0.6221 - val_loss: 0.6748 - val_accuracy: 0.6168\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6548 - accuracy: 0.6274 - val_loss: 0.6729 - val_accuracy: 0.6189\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6525 - accuracy: 0.6305 - val_loss: 0.6689 - val_accuracy: 0.6263\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6491 - accuracy: 0.6383 - val_loss: 0.6670 - val_accuracy: 0.6286\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6457 - accuracy: 0.6428 - val_loss: 0.6643 - val_accuracy: 0.6302\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6428 - accuracy: 0.6434 - val_loss: 0.6597 - val_accuracy: 0.6357\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6396 - accuracy: 0.6485 - val_loss: 0.6548 - val_accuracy: 0.6420\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6372 - accuracy: 0.6510 - val_loss: 0.6515 - val_accuracy: 0.6445\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6343 - accuracy: 0.6564 - val_loss: 0.6500 - val_accuracy: 0.6447\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6311 - accuracy: 0.6567 - val_loss: 0.6470 - val_accuracy: 0.6471\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6292 - accuracy: 0.6574 - val_loss: 0.6451 - val_accuracy: 0.6470\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6277 - accuracy: 0.6577 - val_loss: 0.6440 - val_accuracy: 0.6461\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6248 - accuracy: 0.6636 - val_loss: 0.6407 - val_accuracy: 0.6497\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6221 - accuracy: 0.6660 - val_loss: 0.6375 - val_accuracy: 0.6535\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6202 - accuracy: 0.6664 - val_loss: 0.6390 - val_accuracy: 0.6487\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6179 - accuracy: 0.6671 - val_loss: 0.6313 - val_accuracy: 0.6598\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6161 - accuracy: 0.6673 - val_loss: 0.6305 - val_accuracy: 0.6598\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6144 - accuracy: 0.6688 - val_loss: 0.6325 - val_accuracy: 0.6558\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6114 - accuracy: 0.6739 - val_loss: 0.6278 - val_accuracy: 0.6603\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6098 - accuracy: 0.6736 - val_loss: 0.6247 - val_accuracy: 0.6625\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6076 - accuracy: 0.6745 - val_loss: 0.6223 - val_accuracy: 0.6637\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6060 - accuracy: 0.6768 - val_loss: 0.6235 - val_accuracy: 0.6602\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6036 - accuracy: 0.6776 - val_loss: 0.6239 - val_accuracy: 0.6581\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6019 - accuracy: 0.6783 - val_loss: 0.6189 - val_accuracy: 0.6629\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5999 - accuracy: 0.6785 - val_loss: 0.6160 - val_accuracy: 0.6653\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5985 - accuracy: 0.6821 - val_loss: 0.6152 - val_accuracy: 0.6650\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5975 - accuracy: 0.6809 - val_loss: 0.6140 - val_accuracy: 0.6659\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5949 - accuracy: 0.6850 - val_loss: 0.6141 - val_accuracy: 0.6645\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5927 - accuracy: 0.6853 - val_loss: 0.6127 - val_accuracy: 0.6648\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5921 - accuracy: 0.6864 - val_loss: 0.6079 - val_accuracy: 0.6701\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5895 - accuracy: 0.6898 - val_loss: 0.6141 - val_accuracy: 0.6604\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5888 - accuracy: 0.6891 - val_loss: 0.6124 - val_accuracy: 0.6623\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5867 - accuracy: 0.6913 - val_loss: 0.6118 - val_accuracy: 0.6623\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5853 - accuracy: 0.6899 - val_loss: 0.6099 - val_accuracy: 0.6646\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5841 - accuracy: 0.6912 - val_loss: 0.6026 - val_accuracy: 0.6736\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5824 - accuracy: 0.6944 - val_loss: 0.6066 - val_accuracy: 0.6684\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5816 - accuracy: 0.6939 - val_loss: 0.6060 - val_accuracy: 0.6686\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5794 - accuracy: 0.6946 - val_loss: 0.6088 - val_accuracy: 0.6638\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5786 - accuracy: 0.6955 - val_loss: 0.6116 - val_accuracy: 0.6589\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5773 - accuracy: 0.6979 - val_loss: 0.6043 - val_accuracy: 0.6683\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5770 - accuracy: 0.6966 - val_loss: 0.5998 - val_accuracy: 0.6742\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.5743 - accuracy: 0.6983 - val_loss: 0.6080 - val_accuracy: 0.6619\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5739 - accuracy: 0.7002 - val_loss: 0.6024 - val_accuracy: 0.6680\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5729 - accuracy: 0.7010 - val_loss: 0.6031 - val_accuracy: 0.6665\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.7182 - accuracy: 0.4840 - val_loss: 0.7061 - val_accuracy: 0.4443\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.7014 - accuracy: 0.5147 - val_loss: 0.7199 - val_accuracy: 0.3418\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6937 - accuracy: 0.5300 - val_loss: 0.7147 - val_accuracy: 0.3590\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6859 - accuracy: 0.5501 - val_loss: 0.7113 - val_accuracy: 0.4004\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6808 - accuracy: 0.5627 - val_loss: 0.7034 - val_accuracy: 0.4758\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6767 - accuracy: 0.5728 - val_loss: 0.6972 - val_accuracy: 0.5189\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6709 - accuracy: 0.5857 - val_loss: 0.6918 - val_accuracy: 0.5342\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6686 - accuracy: 0.5932 - val_loss: 0.6886 - val_accuracy: 0.5402\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6653 - accuracy: 0.5988 - val_loss: 0.6827 - val_accuracy: 0.5662\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6614 - accuracy: 0.6082 - val_loss: 0.6809 - val_accuracy: 0.5674\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6589 - accuracy: 0.6097 - val_loss: 0.6823 - val_accuracy: 0.5600\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6557 - accuracy: 0.6166 - val_loss: 0.6780 - val_accuracy: 0.5733\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6526 - accuracy: 0.6233 - val_loss: 0.6776 - val_accuracy: 0.5701\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6508 - accuracy: 0.6257 - val_loss: 0.6715 - val_accuracy: 0.5845\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6484 - accuracy: 0.6276 - val_loss: 0.6691 - val_accuracy: 0.5893\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6457 - accuracy: 0.6317 - val_loss: 0.6650 - val_accuracy: 0.5996\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6421 - accuracy: 0.6351 - val_loss: 0.6661 - val_accuracy: 0.5924\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6405 - accuracy: 0.6377 - val_loss: 0.6629 - val_accuracy: 0.6001\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6384 - accuracy: 0.6396 - val_loss: 0.6592 - val_accuracy: 0.6048\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6361 - accuracy: 0.6394 - val_loss: 0.6539 - val_accuracy: 0.6114\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6336 - accuracy: 0.6431 - val_loss: 0.6545 - val_accuracy: 0.6075\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6310 - accuracy: 0.6445 - val_loss: 0.6480 - val_accuracy: 0.6173\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6290 - accuracy: 0.6482 - val_loss: 0.6508 - val_accuracy: 0.6109\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6268 - accuracy: 0.6477 - val_loss: 0.6504 - val_accuracy: 0.6090\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6253 - accuracy: 0.6498 - val_loss: 0.6432 - val_accuracy: 0.6174\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6227 - accuracy: 0.6509 - val_loss: 0.6467 - val_accuracy: 0.6102\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6209 - accuracy: 0.6534 - val_loss: 0.6452 - val_accuracy: 0.6112\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6183 - accuracy: 0.6552 - val_loss: 0.6415 - val_accuracy: 0.6143\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6169 - accuracy: 0.6556 - val_loss: 0.6427 - val_accuracy: 0.6113\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6141 - accuracy: 0.6597 - val_loss: 0.6440 - val_accuracy: 0.6094\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6143 - accuracy: 0.6577 - val_loss: 0.6334 - val_accuracy: 0.6176\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6120 - accuracy: 0.6597 - val_loss: 0.6355 - val_accuracy: 0.6141\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6098 - accuracy: 0.6609 - val_loss: 0.6347 - val_accuracy: 0.6143\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6076 - accuracy: 0.6642 - val_loss: 0.6392 - val_accuracy: 0.6115\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6056 - accuracy: 0.6642 - val_loss: 0.6305 - val_accuracy: 0.6166\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6054 - accuracy: 0.6635 - val_loss: 0.6274 - val_accuracy: 0.6194\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6022 - accuracy: 0.6687 - val_loss: 0.6233 - val_accuracy: 0.6239\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6007 - accuracy: 0.6707 - val_loss: 0.6300 - val_accuracy: 0.6182\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5999 - accuracy: 0.6715 - val_loss: 0.6214 - val_accuracy: 0.6258\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5976 - accuracy: 0.6723 - val_loss: 0.6289 - val_accuracy: 0.6199\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5971 - accuracy: 0.6729 - val_loss: 0.6275 - val_accuracy: 0.6220\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5947 - accuracy: 0.6738 - val_loss: 0.6217 - val_accuracy: 0.6253\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.5938 - accuracy: 0.6772 - val_loss: 0.6262 - val_accuracy: 0.6231\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.5923 - accuracy: 0.6787 - val_loss: 0.6235 - val_accuracy: 0.6242\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5898 - accuracy: 0.6784 - val_loss: 0.6233 - val_accuracy: 0.6249\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.5894 - accuracy: 0.6791 - val_loss: 0.6265 - val_accuracy: 0.6224\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5884 - accuracy: 0.6800 - val_loss: 0.6222 - val_accuracy: 0.6255\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.5865 - accuracy: 0.6809 - val_loss: 0.6174 - val_accuracy: 0.6294\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5867 - accuracy: 0.6809 - val_loss: 0.6179 - val_accuracy: 0.6298\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5844 - accuracy: 0.6817 - val_loss: 0.6250 - val_accuracy: 0.6252\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.7335 - accuracy: 0.5233 - val_loss: 0.8026 - val_accuracy: 0.1690\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6949 - accuracy: 0.5257 - val_loss: 0.7360 - val_accuracy: 0.3017\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6883 - accuracy: 0.5414 - val_loss: 0.7204 - val_accuracy: 0.3808\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6843 - accuracy: 0.5543 - val_loss: 0.7160 - val_accuracy: 0.3995\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6799 - accuracy: 0.5704 - val_loss: 0.7103 - val_accuracy: 0.4316\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6754 - accuracy: 0.5825 - val_loss: 0.7060 - val_accuracy: 0.4507\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6702 - accuracy: 0.5997 - val_loss: 0.7010 - val_accuracy: 0.4799\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6677 - accuracy: 0.6054 - val_loss: 0.6967 - val_accuracy: 0.5069\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6639 - accuracy: 0.6189 - val_loss: 0.6960 - val_accuracy: 0.5142\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6603 - accuracy: 0.6263 - val_loss: 0.6903 - val_accuracy: 0.5357\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6569 - accuracy: 0.6338 - val_loss: 0.6867 - val_accuracy: 0.5514\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6547 - accuracy: 0.6393 - val_loss: 0.6845 - val_accuracy: 0.5586\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6524 - accuracy: 0.6431 - val_loss: 0.6810 - val_accuracy: 0.5684\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6487 - accuracy: 0.6487 - val_loss: 0.6788 - val_accuracy: 0.5751\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6453 - accuracy: 0.6539 - val_loss: 0.6742 - val_accuracy: 0.5850\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6427 - accuracy: 0.6567 - val_loss: 0.6741 - val_accuracy: 0.5863\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6410 - accuracy: 0.6610 - val_loss: 0.6698 - val_accuracy: 0.5963\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6377 - accuracy: 0.6644 - val_loss: 0.6645 - val_accuracy: 0.6054\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6354 - accuracy: 0.6685 - val_loss: 0.6647 - val_accuracy: 0.6047\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6322 - accuracy: 0.6706 - val_loss: 0.6599 - val_accuracy: 0.6110\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6290 - accuracy: 0.6750 - val_loss: 0.6553 - val_accuracy: 0.6178\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6265 - accuracy: 0.6762 - val_loss: 0.6520 - val_accuracy: 0.6239\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6247 - accuracy: 0.6767 - val_loss: 0.6533 - val_accuracy: 0.6197\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6225 - accuracy: 0.6786 - val_loss: 0.6486 - val_accuracy: 0.6258\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6197 - accuracy: 0.6854 - val_loss: 0.6486 - val_accuracy: 0.6246\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6176 - accuracy: 0.6854 - val_loss: 0.6455 - val_accuracy: 0.6295\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6158 - accuracy: 0.6871 - val_loss: 0.6470 - val_accuracy: 0.6257\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6135 - accuracy: 0.6875 - val_loss: 0.6427 - val_accuracy: 0.6308\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6114 - accuracy: 0.6904 - val_loss: 0.6422 - val_accuracy: 0.6307\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.6095 - accuracy: 0.6932 - val_loss: 0.6412 - val_accuracy: 0.6312\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6078 - accuracy: 0.6929 - val_loss: 0.6347 - val_accuracy: 0.6389\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6059 - accuracy: 0.6920 - val_loss: 0.6345 - val_accuracy: 0.6388\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6039 - accuracy: 0.6962 - val_loss: 0.6328 - val_accuracy: 0.6405\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6019 - accuracy: 0.6956 - val_loss: 0.6354 - val_accuracy: 0.6364\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5998 - accuracy: 0.6976 - val_loss: 0.6302 - val_accuracy: 0.6435\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5994 - accuracy: 0.6994 - val_loss: 0.6298 - val_accuracy: 0.6428\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5973 - accuracy: 0.6984 - val_loss: 0.6275 - val_accuracy: 0.6446\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5960 - accuracy: 0.7007 - val_loss: 0.6262 - val_accuracy: 0.6448\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5940 - accuracy: 0.7006 - val_loss: 0.6244 - val_accuracy: 0.6462\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.5930 - accuracy: 0.7017 - val_loss: 0.6257 - val_accuracy: 0.6444\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5899 - accuracy: 0.7053 - val_loss: 0.6248 - val_accuracy: 0.6454\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.5895 - accuracy: 0.7043 - val_loss: 0.6243 - val_accuracy: 0.6462\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5876 - accuracy: 0.7058 - val_loss: 0.6173 - val_accuracy: 0.6542\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.5858 - accuracy: 0.7078 - val_loss: 0.6156 - val_accuracy: 0.6559\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5844 - accuracy: 0.7093 - val_loss: 0.6193 - val_accuracy: 0.6499\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.5838 - accuracy: 0.7104 - val_loss: 0.6148 - val_accuracy: 0.6547\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5826 - accuracy: 0.7088 - val_loss: 0.6160 - val_accuracy: 0.6524\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.5800 - accuracy: 0.7131 - val_loss: 0.6122 - val_accuracy: 0.6552\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5789 - accuracy: 0.7125 - val_loss: 0.6224 - val_accuracy: 0.6448\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5770 - accuracy: 0.7148 - val_loss: 0.6134 - val_accuracy: 0.6532\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.7053 - accuracy: 0.5010 - val_loss: 0.6381 - val_accuracy: 0.7647\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6834 - accuracy: 0.5556 - val_loss: 0.6785 - val_accuracy: 0.5831\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6775 - accuracy: 0.5800 - val_loss: 0.6904 - val_accuracy: 0.5466\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6743 - accuracy: 0.5867 - val_loss: 0.6920 - val_accuracy: 0.5389\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6721 - accuracy: 0.5946 - val_loss: 0.6890 - val_accuracy: 0.5475\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6697 - accuracy: 0.6006 - val_loss: 0.6899 - val_accuracy: 0.5436\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6675 - accuracy: 0.6055 - val_loss: 0.6873 - val_accuracy: 0.5515\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6654 - accuracy: 0.6072 - val_loss: 0.6864 - val_accuracy: 0.5558\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6626 - accuracy: 0.6151 - val_loss: 0.6848 - val_accuracy: 0.5592\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6618 - accuracy: 0.6146 - val_loss: 0.6833 - val_accuracy: 0.5631\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6595 - accuracy: 0.6204 - val_loss: 0.6850 - val_accuracy: 0.5594\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6578 - accuracy: 0.6230 - val_loss: 0.6797 - val_accuracy: 0.5730\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6565 - accuracy: 0.6244 - val_loss: 0.6772 - val_accuracy: 0.5819\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6549 - accuracy: 0.6280 - val_loss: 0.6775 - val_accuracy: 0.5829\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6531 - accuracy: 0.6307 - val_loss: 0.6752 - val_accuracy: 0.5872\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6513 - accuracy: 0.6345 - val_loss: 0.6720 - val_accuracy: 0.5944\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6490 - accuracy: 0.6368 - val_loss: 0.6729 - val_accuracy: 0.5926\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6475 - accuracy: 0.6385 - val_loss: 0.6714 - val_accuracy: 0.5964\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6463 - accuracy: 0.6416 - val_loss: 0.6683 - val_accuracy: 0.6023\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6442 - accuracy: 0.6439 - val_loss: 0.6674 - val_accuracy: 0.6041\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6426 - accuracy: 0.6454 - val_loss: 0.6679 - val_accuracy: 0.6015\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6405 - accuracy: 0.6482 - val_loss: 0.6658 - val_accuracy: 0.6053\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6394 - accuracy: 0.6480 - val_loss: 0.6637 - val_accuracy: 0.6085\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6376 - accuracy: 0.6519 - val_loss: 0.6630 - val_accuracy: 0.6077\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.6359 - accuracy: 0.6541 - val_loss: 0.6621 - val_accuracy: 0.6081\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6340 - accuracy: 0.6560 - val_loss: 0.6598 - val_accuracy: 0.6130\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6324 - accuracy: 0.6568 - val_loss: 0.6556 - val_accuracy: 0.6224\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6305 - accuracy: 0.6605 - val_loss: 0.6526 - val_accuracy: 0.6263\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6296 - accuracy: 0.6609 - val_loss: 0.6522 - val_accuracy: 0.6256\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6279 - accuracy: 0.6637 - val_loss: 0.6519 - val_accuracy: 0.6246\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6261 - accuracy: 0.6651 - val_loss: 0.6519 - val_accuracy: 0.6236\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6250 - accuracy: 0.6679 - val_loss: 0.6493 - val_accuracy: 0.6262\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6235 - accuracy: 0.6662 - val_loss: 0.6469 - val_accuracy: 0.6289\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6220 - accuracy: 0.6683 - val_loss: 0.6454 - val_accuracy: 0.6311\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6208 - accuracy: 0.6678 - val_loss: 0.6428 - val_accuracy: 0.6336\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6190 - accuracy: 0.6707 - val_loss: 0.6432 - val_accuracy: 0.6316\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6172 - accuracy: 0.6731 - val_loss: 0.6433 - val_accuracy: 0.6292\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6155 - accuracy: 0.6742 - val_loss: 0.6410 - val_accuracy: 0.6315\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6139 - accuracy: 0.6757 - val_loss: 0.6403 - val_accuracy: 0.6312\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6125 - accuracy: 0.6780 - val_loss: 0.6372 - val_accuracy: 0.6362\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6113 - accuracy: 0.6799 - val_loss: 0.6347 - val_accuracy: 0.6370\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6104 - accuracy: 0.6804 - val_loss: 0.6339 - val_accuracy: 0.6377\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6087 - accuracy: 0.6808 - val_loss: 0.6335 - val_accuracy: 0.6374\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6067 - accuracy: 0.6858 - val_loss: 0.6309 - val_accuracy: 0.6389\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.6059 - accuracy: 0.6844 - val_loss: 0.6330 - val_accuracy: 0.6344\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.6047 - accuracy: 0.6849 - val_loss: 0.6306 - val_accuracy: 0.6353\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6025 - accuracy: 0.6888 - val_loss: 0.6301 - val_accuracy: 0.6356\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6012 - accuracy: 0.6882 - val_loss: 0.6291 - val_accuracy: 0.6357\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.5999 - accuracy: 0.6901 - val_loss: 0.6332 - val_accuracy: 0.6314\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5987 - accuracy: 0.6923 - val_loss: 0.6288 - val_accuracy: 0.6332\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.7119 - accuracy: 0.4852 - val_loss: 0.7108 - val_accuracy: 0.3340\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.7020 - accuracy: 0.5081 - val_loss: 0.7165 - val_accuracy: 0.3196\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.6950 - accuracy: 0.5236 - val_loss: 0.7128 - val_accuracy: 0.3818\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6905 - accuracy: 0.5377 - val_loss: 0.7041 - val_accuracy: 0.4696\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6859 - accuracy: 0.5511 - val_loss: 0.7001 - val_accuracy: 0.5071\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6828 - accuracy: 0.5622 - val_loss: 0.6981 - val_accuracy: 0.5189\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6778 - accuracy: 0.5766 - val_loss: 0.6930 - val_accuracy: 0.5432\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6732 - accuracy: 0.5877 - val_loss: 0.6917 - val_accuracy: 0.5500\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6707 - accuracy: 0.5977 - val_loss: 0.6869 - val_accuracy: 0.5649\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6667 - accuracy: 0.6061 - val_loss: 0.6824 - val_accuracy: 0.5749\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6640 - accuracy: 0.6134 - val_loss: 0.6793 - val_accuracy: 0.5806\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6606 - accuracy: 0.6201 - val_loss: 0.6763 - val_accuracy: 0.5858\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6571 - accuracy: 0.6279 - val_loss: 0.6744 - val_accuracy: 0.5884\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6556 - accuracy: 0.6300 - val_loss: 0.6706 - val_accuracy: 0.5936\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6517 - accuracy: 0.6399 - val_loss: 0.6695 - val_accuracy: 0.5939\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6486 - accuracy: 0.6436 - val_loss: 0.6667 - val_accuracy: 0.5988\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6466 - accuracy: 0.6456 - val_loss: 0.6634 - val_accuracy: 0.6057\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6432 - accuracy: 0.6520 - val_loss: 0.6610 - val_accuracy: 0.6101\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6398 - accuracy: 0.6579 - val_loss: 0.6599 - val_accuracy: 0.6101\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6383 - accuracy: 0.6570 - val_loss: 0.6578 - val_accuracy: 0.6133\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.6358 - accuracy: 0.6608 - val_loss: 0.6552 - val_accuracy: 0.6172\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6324 - accuracy: 0.6664 - val_loss: 0.6523 - val_accuracy: 0.6211\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6315 - accuracy: 0.6676 - val_loss: 0.6509 - val_accuracy: 0.6229\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6283 - accuracy: 0.6698 - val_loss: 0.6490 - val_accuracy: 0.6272\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6254 - accuracy: 0.6737 - val_loss: 0.6460 - val_accuracy: 0.6331\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6231 - accuracy: 0.6767 - val_loss: 0.6491 - val_accuracy: 0.6250\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6225 - accuracy: 0.6743 - val_loss: 0.6476 - val_accuracy: 0.6253\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6197 - accuracy: 0.6784 - val_loss: 0.6455 - val_accuracy: 0.6281\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6179 - accuracy: 0.6802 - val_loss: 0.6389 - val_accuracy: 0.6373\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6156 - accuracy: 0.6819 - val_loss: 0.6368 - val_accuracy: 0.6383\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6132 - accuracy: 0.6819 - val_loss: 0.6401 - val_accuracy: 0.6315\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6107 - accuracy: 0.6838 - val_loss: 0.6376 - val_accuracy: 0.6328\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6090 - accuracy: 0.6874 - val_loss: 0.6378 - val_accuracy: 0.6307\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6080 - accuracy: 0.6874 - val_loss: 0.6360 - val_accuracy: 0.6326\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6053 - accuracy: 0.6906 - val_loss: 0.6357 - val_accuracy: 0.6323\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6044 - accuracy: 0.6890 - val_loss: 0.6318 - val_accuracy: 0.6353\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6021 - accuracy: 0.6920 - val_loss: 0.6354 - val_accuracy: 0.6311\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5999 - accuracy: 0.6934 - val_loss: 0.6326 - val_accuracy: 0.6336\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5983 - accuracy: 0.6945 - val_loss: 0.6297 - val_accuracy: 0.6366\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.5971 - accuracy: 0.6961 - val_loss: 0.6270 - val_accuracy: 0.6403\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.5951 - accuracy: 0.6966 - val_loss: 0.6232 - val_accuracy: 0.6445\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.5935 - accuracy: 0.6984 - val_loss: 0.6251 - val_accuracy: 0.6418\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.5908 - accuracy: 0.7004 - val_loss: 0.6263 - val_accuracy: 0.6401\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5906 - accuracy: 0.6992 - val_loss: 0.6210 - val_accuracy: 0.6447\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.5892 - accuracy: 0.7001 - val_loss: 0.6232 - val_accuracy: 0.6430\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5879 - accuracy: 0.7017 - val_loss: 0.6208 - val_accuracy: 0.6439\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5866 - accuracy: 0.7014 - val_loss: 0.6270 - val_accuracy: 0.6386\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.5844 - accuracy: 0.7041 - val_loss: 0.6191 - val_accuracy: 0.6447\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5834 - accuracy: 0.7044 - val_loss: 0.6204 - val_accuracy: 0.6434\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5827 - accuracy: 0.7061 - val_loss: 0.6205 - val_accuracy: 0.6431\n",
      "\n",
      "Entrenando modelo con num_microbatches=16...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.7123 - accuracy: 0.5064 - val_loss: 0.7350 - val_accuracy: 0.2004\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.7035 - accuracy: 0.5084 - val_loss: 0.7227 - val_accuracy: 0.3063\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6977 - accuracy: 0.5207 - val_loss: 0.7161 - val_accuracy: 0.3758\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6916 - accuracy: 0.5347 - val_loss: 0.7132 - val_accuracy: 0.4055\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6894 - accuracy: 0.5433 - val_loss: 0.7082 - val_accuracy: 0.4389\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6848 - accuracy: 0.5564 - val_loss: 0.7025 - val_accuracy: 0.4768\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6802 - accuracy: 0.5656 - val_loss: 0.6989 - val_accuracy: 0.5011\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.6782 - accuracy: 0.5728 - val_loss: 0.6998 - val_accuracy: 0.5011\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6752 - accuracy: 0.5837 - val_loss: 0.6940 - val_accuracy: 0.5280\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6720 - accuracy: 0.5928 - val_loss: 0.6862 - val_accuracy: 0.5588\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6697 - accuracy: 0.5974 - val_loss: 0.6894 - val_accuracy: 0.5475\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6667 - accuracy: 0.6047 - val_loss: 0.6872 - val_accuracy: 0.5544\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6640 - accuracy: 0.6114 - val_loss: 0.6823 - val_accuracy: 0.5677\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6616 - accuracy: 0.6148 - val_loss: 0.6795 - val_accuracy: 0.5761\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6601 - accuracy: 0.6191 - val_loss: 0.6770 - val_accuracy: 0.5820\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6566 - accuracy: 0.6255 - val_loss: 0.6762 - val_accuracy: 0.5833\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6545 - accuracy: 0.6318 - val_loss: 0.6749 - val_accuracy: 0.5849\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6530 - accuracy: 0.6311 - val_loss: 0.6738 - val_accuracy: 0.5869\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6503 - accuracy: 0.6366 - val_loss: 0.6693 - val_accuracy: 0.5962\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6470 - accuracy: 0.6425 - val_loss: 0.6633 - val_accuracy: 0.6098\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6455 - accuracy: 0.6426 - val_loss: 0.6658 - val_accuracy: 0.6032\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6435 - accuracy: 0.6464 - val_loss: 0.6651 - val_accuracy: 0.6031\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6411 - accuracy: 0.6471 - val_loss: 0.6610 - val_accuracy: 0.6109\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6395 - accuracy: 0.6478 - val_loss: 0.6641 - val_accuracy: 0.6035\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6372 - accuracy: 0.6527 - val_loss: 0.6563 - val_accuracy: 0.6159\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6341 - accuracy: 0.6574 - val_loss: 0.6545 - val_accuracy: 0.6188\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6328 - accuracy: 0.6577 - val_loss: 0.6538 - val_accuracy: 0.6193\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6306 - accuracy: 0.6610 - val_loss: 0.6506 - val_accuracy: 0.6237\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6294 - accuracy: 0.6608 - val_loss: 0.6535 - val_accuracy: 0.6166\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6277 - accuracy: 0.6620 - val_loss: 0.6514 - val_accuracy: 0.6193\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6259 - accuracy: 0.6640 - val_loss: 0.6490 - val_accuracy: 0.6213\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6244 - accuracy: 0.6656 - val_loss: 0.6469 - val_accuracy: 0.6236\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6216 - accuracy: 0.6690 - val_loss: 0.6459 - val_accuracy: 0.6240\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6199 - accuracy: 0.6708 - val_loss: 0.6464 - val_accuracy: 0.6216\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6183 - accuracy: 0.6714 - val_loss: 0.6438 - val_accuracy: 0.6227\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6165 - accuracy: 0.6723 - val_loss: 0.6439 - val_accuracy: 0.6209\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6140 - accuracy: 0.6754 - val_loss: 0.6337 - val_accuracy: 0.6354\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6130 - accuracy: 0.6754 - val_loss: 0.6367 - val_accuracy: 0.6302\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6112 - accuracy: 0.6771 - val_loss: 0.6369 - val_accuracy: 0.6287\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6097 - accuracy: 0.6791 - val_loss: 0.6325 - val_accuracy: 0.6345\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6085 - accuracy: 0.6803 - val_loss: 0.6343 - val_accuracy: 0.6310\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6064 - accuracy: 0.6811 - val_loss: 0.6341 - val_accuracy: 0.6303\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6043 - accuracy: 0.6843 - val_loss: 0.6356 - val_accuracy: 0.6269\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6024 - accuracy: 0.6859 - val_loss: 0.6294 - val_accuracy: 0.6337\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6004 - accuracy: 0.6855 - val_loss: 0.6325 - val_accuracy: 0.6291\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.5999 - accuracy: 0.6871 - val_loss: 0.6246 - val_accuracy: 0.6377\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5989 - accuracy: 0.6890 - val_loss: 0.6298 - val_accuracy: 0.6298\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.5968 - accuracy: 0.6890 - val_loss: 0.6246 - val_accuracy: 0.6350\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5954 - accuracy: 0.6902 - val_loss: 0.6267 - val_accuracy: 0.6314\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5931 - accuracy: 0.6932 - val_loss: 0.6245 - val_accuracy: 0.6331\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.7648 - accuracy: 0.5206 - val_loss: 0.7686 - val_accuracy: 0.1829\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.7037 - accuracy: 0.5240 - val_loss: 0.7318 - val_accuracy: 0.3273\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6966 - accuracy: 0.5322 - val_loss: 0.7194 - val_accuracy: 0.3920\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.7180 - val_accuracy: 0.4281\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6865 - accuracy: 0.5566 - val_loss: 0.7119 - val_accuracy: 0.4588\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6841 - accuracy: 0.5602 - val_loss: 0.7126 - val_accuracy: 0.4617\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6798 - accuracy: 0.5686 - val_loss: 0.7061 - val_accuracy: 0.4840\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6772 - accuracy: 0.5754 - val_loss: 0.7077 - val_accuracy: 0.4808\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6741 - accuracy: 0.5828 - val_loss: 0.7036 - val_accuracy: 0.4898\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6715 - accuracy: 0.5908 - val_loss: 0.7023 - val_accuracy: 0.4950\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6676 - accuracy: 0.5984 - val_loss: 0.7028 - val_accuracy: 0.4943\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6670 - accuracy: 0.5987 - val_loss: 0.6997 - val_accuracy: 0.5040\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6645 - accuracy: 0.6057 - val_loss: 0.6957 - val_accuracy: 0.5159\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6615 - accuracy: 0.6119 - val_loss: 0.6934 - val_accuracy: 0.5214\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6595 - accuracy: 0.6133 - val_loss: 0.6939 - val_accuracy: 0.5210\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6558 - accuracy: 0.6193 - val_loss: 0.6892 - val_accuracy: 0.5314\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6544 - accuracy: 0.6230 - val_loss: 0.6872 - val_accuracy: 0.5347\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6513 - accuracy: 0.6309 - val_loss: 0.6832 - val_accuracy: 0.5429\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6492 - accuracy: 0.6286 - val_loss: 0.6812 - val_accuracy: 0.5476\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6460 - accuracy: 0.6339 - val_loss: 0.6794 - val_accuracy: 0.5517\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6447 - accuracy: 0.6365 - val_loss: 0.6764 - val_accuracy: 0.5581\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6431 - accuracy: 0.6363 - val_loss: 0.6773 - val_accuracy: 0.5567\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6402 - accuracy: 0.6440 - val_loss: 0.6711 - val_accuracy: 0.5671\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6397 - accuracy: 0.6415 - val_loss: 0.6677 - val_accuracy: 0.5734\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6376 - accuracy: 0.6442 - val_loss: 0.6632 - val_accuracy: 0.5847\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6351 - accuracy: 0.6462 - val_loss: 0.6642 - val_accuracy: 0.5814\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6331 - accuracy: 0.6493 - val_loss: 0.6637 - val_accuracy: 0.5820\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6311 - accuracy: 0.6514 - val_loss: 0.6629 - val_accuracy: 0.5831\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6302 - accuracy: 0.6532 - val_loss: 0.6603 - val_accuracy: 0.5889\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6276 - accuracy: 0.6555 - val_loss: 0.6583 - val_accuracy: 0.5932\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6265 - accuracy: 0.6565 - val_loss: 0.6567 - val_accuracy: 0.5955\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6239 - accuracy: 0.6597 - val_loss: 0.6585 - val_accuracy: 0.5921\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6220 - accuracy: 0.6595 - val_loss: 0.6533 - val_accuracy: 0.6020\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6207 - accuracy: 0.6618 - val_loss: 0.6540 - val_accuracy: 0.6001\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6198 - accuracy: 0.6628 - val_loss: 0.6516 - val_accuracy: 0.6048\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6174 - accuracy: 0.6656 - val_loss: 0.6521 - val_accuracy: 0.6031\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6159 - accuracy: 0.6671 - val_loss: 0.6433 - val_accuracy: 0.6145\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6153 - accuracy: 0.6685 - val_loss: 0.6492 - val_accuracy: 0.6060\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6124 - accuracy: 0.6725 - val_loss: 0.6496 - val_accuracy: 0.6047\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6113 - accuracy: 0.6704 - val_loss: 0.6376 - val_accuracy: 0.6228\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6099 - accuracy: 0.6719 - val_loss: 0.6403 - val_accuracy: 0.6175\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6084 - accuracy: 0.6747 - val_loss: 0.6483 - val_accuracy: 0.6048\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6074 - accuracy: 0.6760 - val_loss: 0.6419 - val_accuracy: 0.6144\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6058 - accuracy: 0.6779 - val_loss: 0.6400 - val_accuracy: 0.6159\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6035 - accuracy: 0.6797 - val_loss: 0.6405 - val_accuracy: 0.6150\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6016 - accuracy: 0.6811 - val_loss: 0.6377 - val_accuracy: 0.6192\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6016 - accuracy: 0.6818 - val_loss: 0.6317 - val_accuracy: 0.6283\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5998 - accuracy: 0.6840 - val_loss: 0.6383 - val_accuracy: 0.6164\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5988 - accuracy: 0.6862 - val_loss: 0.6302 - val_accuracy: 0.6282\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5966 - accuracy: 0.6883 - val_loss: 0.6291 - val_accuracy: 0.6301\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.7488 - accuracy: 0.4648 - val_loss: 0.7488 - val_accuracy: 0.2443\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.7153 - accuracy: 0.4972 - val_loss: 0.7411 - val_accuracy: 0.2584\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.7008 - accuracy: 0.5195 - val_loss: 0.7327 - val_accuracy: 0.2878\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6895 - accuracy: 0.5427 - val_loss: 0.7154 - val_accuracy: 0.4036\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6814 - accuracy: 0.5635 - val_loss: 0.7079 - val_accuracy: 0.4413\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6726 - accuracy: 0.5826 - val_loss: 0.6982 - val_accuracy: 0.4884\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6651 - accuracy: 0.6005 - val_loss: 0.6935 - val_accuracy: 0.5119\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6602 - accuracy: 0.6133 - val_loss: 0.6887 - val_accuracy: 0.5353\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6565 - accuracy: 0.6180 - val_loss: 0.6817 - val_accuracy: 0.5573\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6518 - accuracy: 0.6284 - val_loss: 0.6723 - val_accuracy: 0.5810\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6471 - accuracy: 0.6347 - val_loss: 0.6722 - val_accuracy: 0.5810\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6432 - accuracy: 0.6399 - val_loss: 0.6721 - val_accuracy: 0.5817\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6395 - accuracy: 0.6476 - val_loss: 0.6591 - val_accuracy: 0.6018\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6358 - accuracy: 0.6497 - val_loss: 0.6583 - val_accuracy: 0.6022\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6329 - accuracy: 0.6532 - val_loss: 0.6587 - val_accuracy: 0.6010\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.6301 - accuracy: 0.6565 - val_loss: 0.6521 - val_accuracy: 0.6114\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6271 - accuracy: 0.6597 - val_loss: 0.6515 - val_accuracy: 0.6116\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6242 - accuracy: 0.6624 - val_loss: 0.6488 - val_accuracy: 0.6151\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6216 - accuracy: 0.6656 - val_loss: 0.6419 - val_accuracy: 0.6249\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6185 - accuracy: 0.6685 - val_loss: 0.6425 - val_accuracy: 0.6230\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6170 - accuracy: 0.6672 - val_loss: 0.6428 - val_accuracy: 0.6218\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6147 - accuracy: 0.6725 - val_loss: 0.6380 - val_accuracy: 0.6297\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6120 - accuracy: 0.6716 - val_loss: 0.6411 - val_accuracy: 0.6246\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6104 - accuracy: 0.6734 - val_loss: 0.6378 - val_accuracy: 0.6298\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6088 - accuracy: 0.6737 - val_loss: 0.6325 - val_accuracy: 0.6359\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6058 - accuracy: 0.6751 - val_loss: 0.6361 - val_accuracy: 0.6312\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6040 - accuracy: 0.6775 - val_loss: 0.6352 - val_accuracy: 0.6323\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6029 - accuracy: 0.6774 - val_loss: 0.6329 - val_accuracy: 0.6346\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6011 - accuracy: 0.6808 - val_loss: 0.6237 - val_accuracy: 0.6446\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5990 - accuracy: 0.6799 - val_loss: 0.6243 - val_accuracy: 0.6435\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5972 - accuracy: 0.6826 - val_loss: 0.6283 - val_accuracy: 0.6377\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5961 - accuracy: 0.6839 - val_loss: 0.6247 - val_accuracy: 0.6429\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5946 - accuracy: 0.6849 - val_loss: 0.6233 - val_accuracy: 0.6438\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5935 - accuracy: 0.6853 - val_loss: 0.6291 - val_accuracy: 0.6376\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.5906 - accuracy: 0.6874 - val_loss: 0.6210 - val_accuracy: 0.6468\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.5897 - accuracy: 0.6881 - val_loss: 0.6169 - val_accuracy: 0.6502\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5884 - accuracy: 0.6901 - val_loss: 0.6166 - val_accuracy: 0.6493\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.5881 - accuracy: 0.6899 - val_loss: 0.6152 - val_accuracy: 0.6511\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5852 - accuracy: 0.6916 - val_loss: 0.6156 - val_accuracy: 0.6503\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5839 - accuracy: 0.6925 - val_loss: 0.6165 - val_accuracy: 0.6497\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5820 - accuracy: 0.6946 - val_loss: 0.6175 - val_accuracy: 0.6485\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5818 - accuracy: 0.6923 - val_loss: 0.6144 - val_accuracy: 0.6507\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5807 - accuracy: 0.6940 - val_loss: 0.6167 - val_accuracy: 0.6483\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.5786 - accuracy: 0.6977 - val_loss: 0.6100 - val_accuracy: 0.6539\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.5775 - accuracy: 0.6970 - val_loss: 0.6124 - val_accuracy: 0.6502\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.5773 - accuracy: 0.6975 - val_loss: 0.6142 - val_accuracy: 0.6483\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5769 - accuracy: 0.6982 - val_loss: 0.6140 - val_accuracy: 0.6483\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5750 - accuracy: 0.6980 - val_loss: 0.6074 - val_accuracy: 0.6554\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5727 - accuracy: 0.6998 - val_loss: 0.6059 - val_accuracy: 0.6562\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5732 - accuracy: 0.7000 - val_loss: 0.6097 - val_accuracy: 0.6506\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6929 - accuracy: 0.5275 - val_loss: 0.6949 - val_accuracy: 0.5309\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6832 - accuracy: 0.5521 - val_loss: 0.6959 - val_accuracy: 0.5298\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6774 - accuracy: 0.5714 - val_loss: 0.6879 - val_accuracy: 0.5686\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6706 - accuracy: 0.5870 - val_loss: 0.6796 - val_accuracy: 0.5997\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6654 - accuracy: 0.5997 - val_loss: 0.6781 - val_accuracy: 0.5943\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6604 - accuracy: 0.6101 - val_loss: 0.6741 - val_accuracy: 0.6017\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6572 - accuracy: 0.6198 - val_loss: 0.6681 - val_accuracy: 0.6150\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6522 - accuracy: 0.6267 - val_loss: 0.6563 - val_accuracy: 0.6443\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6467 - accuracy: 0.6354 - val_loss: 0.6529 - val_accuracy: 0.6466\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6424 - accuracy: 0.6386 - val_loss: 0.6516 - val_accuracy: 0.6490\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6391 - accuracy: 0.6425 - val_loss: 0.6459 - val_accuracy: 0.6552\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.6368 - accuracy: 0.6460 - val_loss: 0.6410 - val_accuracy: 0.6608\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6346 - accuracy: 0.6509 - val_loss: 0.6442 - val_accuracy: 0.6535\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6322 - accuracy: 0.6517 - val_loss: 0.6392 - val_accuracy: 0.6611\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6290 - accuracy: 0.6563 - val_loss: 0.6397 - val_accuracy: 0.6562\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6271 - accuracy: 0.6596 - val_loss: 0.6361 - val_accuracy: 0.6633\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6245 - accuracy: 0.6598 - val_loss: 0.6302 - val_accuracy: 0.6687\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6222 - accuracy: 0.6629 - val_loss: 0.6310 - val_accuracy: 0.6666\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6207 - accuracy: 0.6627 - val_loss: 0.6327 - val_accuracy: 0.6617\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6184 - accuracy: 0.6660 - val_loss: 0.6246 - val_accuracy: 0.6709\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6163 - accuracy: 0.6674 - val_loss: 0.6219 - val_accuracy: 0.6728\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6141 - accuracy: 0.6695 - val_loss: 0.6254 - val_accuracy: 0.6671\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6129 - accuracy: 0.6698 - val_loss: 0.6192 - val_accuracy: 0.6734\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6104 - accuracy: 0.6747 - val_loss: 0.6257 - val_accuracy: 0.6603\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6084 - accuracy: 0.6757 - val_loss: 0.6165 - val_accuracy: 0.6729\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6075 - accuracy: 0.6781 - val_loss: 0.6235 - val_accuracy: 0.6596\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6060 - accuracy: 0.6776 - val_loss: 0.6156 - val_accuracy: 0.6695\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6039 - accuracy: 0.6818 - val_loss: 0.6171 - val_accuracy: 0.6652\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6027 - accuracy: 0.6815 - val_loss: 0.6177 - val_accuracy: 0.6625\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6002 - accuracy: 0.6828 - val_loss: 0.6100 - val_accuracy: 0.6710\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5993 - accuracy: 0.6834 - val_loss: 0.6147 - val_accuracy: 0.6633\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5975 - accuracy: 0.6874 - val_loss: 0.6092 - val_accuracy: 0.6690\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5962 - accuracy: 0.6877 - val_loss: 0.6114 - val_accuracy: 0.6652\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5954 - accuracy: 0.6889 - val_loss: 0.6131 - val_accuracy: 0.6624\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5932 - accuracy: 0.6924 - val_loss: 0.6085 - val_accuracy: 0.6674\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5922 - accuracy: 0.6927 - val_loss: 0.6157 - val_accuracy: 0.6553\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.5906 - accuracy: 0.6926 - val_loss: 0.6048 - val_accuracy: 0.6700\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.5882 - accuracy: 0.6945 - val_loss: 0.6035 - val_accuracy: 0.6695\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5878 - accuracy: 0.6967 - val_loss: 0.6067 - val_accuracy: 0.6655\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5860 - accuracy: 0.6988 - val_loss: 0.6081 - val_accuracy: 0.6640\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.5846 - accuracy: 0.6995 - val_loss: 0.6037 - val_accuracy: 0.6662\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5834 - accuracy: 0.7008 - val_loss: 0.6050 - val_accuracy: 0.6645\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5825 - accuracy: 0.7027 - val_loss: 0.6080 - val_accuracy: 0.6614\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 872us/step - loss: 0.5806 - accuracy: 0.7037 - val_loss: 0.6016 - val_accuracy: 0.6658\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 898us/step - loss: 0.5782 - accuracy: 0.7034 - val_loss: 0.6028 - val_accuracy: 0.6631\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 768us/step - loss: 0.5780 - accuracy: 0.7056 - val_loss: 0.6011 - val_accuracy: 0.6658\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.5765 - accuracy: 0.7065 - val_loss: 0.5994 - val_accuracy: 0.6665\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5761 - accuracy: 0.7079 - val_loss: 0.5960 - val_accuracy: 0.6721\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.5759 - accuracy: 0.7074 - val_loss: 0.6048 - val_accuracy: 0.6608\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.5726 - accuracy: 0.7105 - val_loss: 0.6001 - val_accuracy: 0.6670\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.7320 - accuracy: 0.5213 - val_loss: 0.7991 - val_accuracy: 0.1205\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 776us/step - loss: 0.6964 - accuracy: 0.5246 - val_loss: 0.7359 - val_accuracy: 0.1846\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.6925 - accuracy: 0.5311 - val_loss: 0.7203 - val_accuracy: 0.2897\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6896 - accuracy: 0.5378 - val_loss: 0.7169 - val_accuracy: 0.3364\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6869 - accuracy: 0.5460 - val_loss: 0.7145 - val_accuracy: 0.3669\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6839 - accuracy: 0.5570 - val_loss: 0.7122 - val_accuracy: 0.3950\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6816 - accuracy: 0.5625 - val_loss: 0.7089 - val_accuracy: 0.4273\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6814 - accuracy: 0.5638 - val_loss: 0.7081 - val_accuracy: 0.4392\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6781 - accuracy: 0.5733 - val_loss: 0.7058 - val_accuracy: 0.4511\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6765 - accuracy: 0.5779 - val_loss: 0.7038 - val_accuracy: 0.4657\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6743 - accuracy: 0.5868 - val_loss: 0.7005 - val_accuracy: 0.4837\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6726 - accuracy: 0.5917 - val_loss: 0.7002 - val_accuracy: 0.4866\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.6703 - accuracy: 0.5974 - val_loss: 0.6996 - val_accuracy: 0.4904\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6690 - accuracy: 0.6025 - val_loss: 0.6990 - val_accuracy: 0.4933\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.6661 - accuracy: 0.6088 - val_loss: 0.6952 - val_accuracy: 0.5108\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6639 - accuracy: 0.6139 - val_loss: 0.6965 - val_accuracy: 0.5079\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6624 - accuracy: 0.6170 - val_loss: 0.6961 - val_accuracy: 0.5132\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6590 - accuracy: 0.6252 - val_loss: 0.6919 - val_accuracy: 0.5248\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6567 - accuracy: 0.6286 - val_loss: 0.6909 - val_accuracy: 0.5241\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6546 - accuracy: 0.6320 - val_loss: 0.6872 - val_accuracy: 0.5309\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6517 - accuracy: 0.6372 - val_loss: 0.6852 - val_accuracy: 0.5358\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6493 - accuracy: 0.6404 - val_loss: 0.6797 - val_accuracy: 0.5462\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6476 - accuracy: 0.6398 - val_loss: 0.6789 - val_accuracy: 0.5472\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6449 - accuracy: 0.6425 - val_loss: 0.6751 - val_accuracy: 0.5544\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6426 - accuracy: 0.6436 - val_loss: 0.6738 - val_accuracy: 0.5565\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6410 - accuracy: 0.6449 - val_loss: 0.6738 - val_accuracy: 0.5573\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6394 - accuracy: 0.6465 - val_loss: 0.6680 - val_accuracy: 0.5675\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6367 - accuracy: 0.6497 - val_loss: 0.6657 - val_accuracy: 0.5714\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6341 - accuracy: 0.6530 - val_loss: 0.6651 - val_accuracy: 0.5716\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6330 - accuracy: 0.6527 - val_loss: 0.6663 - val_accuracy: 0.5694\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6308 - accuracy: 0.6550 - val_loss: 0.6619 - val_accuracy: 0.5766\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6302 - accuracy: 0.6530 - val_loss: 0.6614 - val_accuracy: 0.5769\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6261 - accuracy: 0.6591 - val_loss: 0.6633 - val_accuracy: 0.5732\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6260 - accuracy: 0.6567 - val_loss: 0.6594 - val_accuracy: 0.5780\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6240 - accuracy: 0.6611 - val_loss: 0.6580 - val_accuracy: 0.5810\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6217 - accuracy: 0.6625 - val_loss: 0.6572 - val_accuracy: 0.5840\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6200 - accuracy: 0.6653 - val_loss: 0.6564 - val_accuracy: 0.5860\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6195 - accuracy: 0.6617 - val_loss: 0.6529 - val_accuracy: 0.5928\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6159 - accuracy: 0.6682 - val_loss: 0.6545 - val_accuracy: 0.5902\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6150 - accuracy: 0.6684 - val_loss: 0.6493 - val_accuracy: 0.5974\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6131 - accuracy: 0.6684 - val_loss: 0.6486 - val_accuracy: 0.5981\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6108 - accuracy: 0.6707 - val_loss: 0.6463 - val_accuracy: 0.6000\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6101 - accuracy: 0.6709 - val_loss: 0.6459 - val_accuracy: 0.5999\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6083 - accuracy: 0.6722 - val_loss: 0.6456 - val_accuracy: 0.6001\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6061 - accuracy: 0.6747 - val_loss: 0.6421 - val_accuracy: 0.6044\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6047 - accuracy: 0.6738 - val_loss: 0.6406 - val_accuracy: 0.6077\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6028 - accuracy: 0.6775 - val_loss: 0.6385 - val_accuracy: 0.6112\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6013 - accuracy: 0.6804 - val_loss: 0.6386 - val_accuracy: 0.6103\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.5999 - accuracy: 0.6794 - val_loss: 0.6432 - val_accuracy: 0.6042\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5972 - accuracy: 0.6809 - val_loss: 0.6373 - val_accuracy: 0.6124\n",
      "\n",
      "Entrenando modelo con num_microbatches=32...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.7276 - accuracy: 0.5125 - val_loss: 0.7598 - val_accuracy: 0.2354\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.7066 - accuracy: 0.5144 - val_loss: 0.7339 - val_accuracy: 0.2945\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6952 - accuracy: 0.5346 - val_loss: 0.7248 - val_accuracy: 0.3376\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6881 - accuracy: 0.5434 - val_loss: 0.7138 - val_accuracy: 0.4063\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6815 - accuracy: 0.5581 - val_loss: 0.7112 - val_accuracy: 0.4337\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6738 - accuracy: 0.5743 - val_loss: 0.7044 - val_accuracy: 0.4881\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6717 - accuracy: 0.5771 - val_loss: 0.6937 - val_accuracy: 0.5494\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6654 - accuracy: 0.5935 - val_loss: 0.6950 - val_accuracy: 0.5403\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6613 - accuracy: 0.5985 - val_loss: 0.6926 - val_accuracy: 0.5472\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6566 - accuracy: 0.6105 - val_loss: 0.6898 - val_accuracy: 0.5569\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6523 - accuracy: 0.6186 - val_loss: 0.6831 - val_accuracy: 0.5748\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6502 - accuracy: 0.6210 - val_loss: 0.6813 - val_accuracy: 0.5797\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6459 - accuracy: 0.6299 - val_loss: 0.6747 - val_accuracy: 0.5965\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6430 - accuracy: 0.6334 - val_loss: 0.6699 - val_accuracy: 0.6060\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6405 - accuracy: 0.6347 - val_loss: 0.6696 - val_accuracy: 0.6040\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6355 - accuracy: 0.6461 - val_loss: 0.6622 - val_accuracy: 0.6197\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6340 - accuracy: 0.6442 - val_loss: 0.6567 - val_accuracy: 0.6290\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6307 - accuracy: 0.6495 - val_loss: 0.6585 - val_accuracy: 0.6237\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6272 - accuracy: 0.6544 - val_loss: 0.6594 - val_accuracy: 0.6201\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6249 - accuracy: 0.6551 - val_loss: 0.6535 - val_accuracy: 0.6295\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6211 - accuracy: 0.6611 - val_loss: 0.6492 - val_accuracy: 0.6353\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6189 - accuracy: 0.6630 - val_loss: 0.6500 - val_accuracy: 0.6323\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6160 - accuracy: 0.6645 - val_loss: 0.6465 - val_accuracy: 0.6371\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6149 - accuracy: 0.6675 - val_loss: 0.6481 - val_accuracy: 0.6324\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6133 - accuracy: 0.6657 - val_loss: 0.6402 - val_accuracy: 0.6425\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6091 - accuracy: 0.6734 - val_loss: 0.6389 - val_accuracy: 0.6429\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6086 - accuracy: 0.6717 - val_loss: 0.6441 - val_accuracy: 0.6356\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6051 - accuracy: 0.6757 - val_loss: 0.6411 - val_accuracy: 0.6377\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6033 - accuracy: 0.6772 - val_loss: 0.6372 - val_accuracy: 0.6412\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6018 - accuracy: 0.6783 - val_loss: 0.6346 - val_accuracy: 0.6444\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5990 - accuracy: 0.6806 - val_loss: 0.6333 - val_accuracy: 0.6441\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5974 - accuracy: 0.6815 - val_loss: 0.6304 - val_accuracy: 0.6487\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5965 - accuracy: 0.6839 - val_loss: 0.6267 - val_accuracy: 0.6534\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5935 - accuracy: 0.6856 - val_loss: 0.6292 - val_accuracy: 0.6496\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5912 - accuracy: 0.6867 - val_loss: 0.6246 - val_accuracy: 0.6545\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5908 - accuracy: 0.6876 - val_loss: 0.6238 - val_accuracy: 0.6550\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5878 - accuracy: 0.6902 - val_loss: 0.6268 - val_accuracy: 0.6522\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5864 - accuracy: 0.6895 - val_loss: 0.6330 - val_accuracy: 0.6470\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5845 - accuracy: 0.6928 - val_loss: 0.6236 - val_accuracy: 0.6554\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.5831 - accuracy: 0.6931 - val_loss: 0.6234 - val_accuracy: 0.6559\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5824 - accuracy: 0.6933 - val_loss: 0.6217 - val_accuracy: 0.6571\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5791 - accuracy: 0.6967 - val_loss: 0.6238 - val_accuracy: 0.6543\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5774 - accuracy: 0.6984 - val_loss: 0.6183 - val_accuracy: 0.6593\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5769 - accuracy: 0.6963 - val_loss: 0.6191 - val_accuracy: 0.6589\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5752 - accuracy: 0.6986 - val_loss: 0.6177 - val_accuracy: 0.6594\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5743 - accuracy: 0.6988 - val_loss: 0.6280 - val_accuracy: 0.6521\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5717 - accuracy: 0.7019 - val_loss: 0.6115 - val_accuracy: 0.6645\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.5706 - accuracy: 0.7044 - val_loss: 0.6137 - val_accuracy: 0.6629\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5694 - accuracy: 0.7021 - val_loss: 0.6138 - val_accuracy: 0.6628\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5683 - accuracy: 0.7049 - val_loss: 0.6128 - val_accuracy: 0.6634\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.7052 - accuracy: 0.5151 - val_loss: 0.7231 - val_accuracy: 0.3792\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.7003 - accuracy: 0.5290 - val_loss: 0.7180 - val_accuracy: 0.4203\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6949 - accuracy: 0.5432 - val_loss: 0.7152 - val_accuracy: 0.4466\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6892 - accuracy: 0.5558 - val_loss: 0.7040 - val_accuracy: 0.4914\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6837 - accuracy: 0.5736 - val_loss: 0.6999 - val_accuracy: 0.5102\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6794 - accuracy: 0.5834 - val_loss: 0.6945 - val_accuracy: 0.5271\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6751 - accuracy: 0.5947 - val_loss: 0.6922 - val_accuracy: 0.5339\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6719 - accuracy: 0.6050 - val_loss: 0.6902 - val_accuracy: 0.5379\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6674 - accuracy: 0.6121 - val_loss: 0.6870 - val_accuracy: 0.5466\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6641 - accuracy: 0.6203 - val_loss: 0.6816 - val_accuracy: 0.5618\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6611 - accuracy: 0.6289 - val_loss: 0.6771 - val_accuracy: 0.5702\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6573 - accuracy: 0.6363 - val_loss: 0.6789 - val_accuracy: 0.5660\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6547 - accuracy: 0.6387 - val_loss: 0.6737 - val_accuracy: 0.5734\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6516 - accuracy: 0.6448 - val_loss: 0.6697 - val_accuracy: 0.5792\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6489 - accuracy: 0.6475 - val_loss: 0.6697 - val_accuracy: 0.5774\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6458 - accuracy: 0.6525 - val_loss: 0.6679 - val_accuracy: 0.5791\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6442 - accuracy: 0.6560 - val_loss: 0.6627 - val_accuracy: 0.5868\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.6403 - accuracy: 0.6604 - val_loss: 0.6616 - val_accuracy: 0.5877\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6380 - accuracy: 0.6623 - val_loss: 0.6560 - val_accuracy: 0.5954\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6355 - accuracy: 0.6651 - val_loss: 0.6521 - val_accuracy: 0.5986\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6321 - accuracy: 0.6709 - val_loss: 0.6484 - val_accuracy: 0.6030\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6301 - accuracy: 0.6721 - val_loss: 0.6479 - val_accuracy: 0.6026\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6278 - accuracy: 0.6742 - val_loss: 0.6493 - val_accuracy: 0.5997\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6254 - accuracy: 0.6753 - val_loss: 0.6489 - val_accuracy: 0.5991\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6248 - accuracy: 0.6754 - val_loss: 0.6492 - val_accuracy: 0.5978\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6227 - accuracy: 0.6787 - val_loss: 0.6449 - val_accuracy: 0.6028\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6199 - accuracy: 0.6805 - val_loss: 0.6408 - val_accuracy: 0.6098\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6183 - accuracy: 0.6830 - val_loss: 0.6389 - val_accuracy: 0.6117\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6163 - accuracy: 0.6824 - val_loss: 0.6408 - val_accuracy: 0.6077\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6145 - accuracy: 0.6841 - val_loss: 0.6362 - val_accuracy: 0.6142\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6132 - accuracy: 0.6849 - val_loss: 0.6400 - val_accuracy: 0.6079\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6109 - accuracy: 0.6888 - val_loss: 0.6337 - val_accuracy: 0.6172\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6091 - accuracy: 0.6916 - val_loss: 0.6337 - val_accuracy: 0.6162\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6076 - accuracy: 0.6886 - val_loss: 0.6325 - val_accuracy: 0.6180\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6056 - accuracy: 0.6921 - val_loss: 0.6320 - val_accuracy: 0.6184\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.6037 - accuracy: 0.6921 - val_loss: 0.6311 - val_accuracy: 0.6197\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6030 - accuracy: 0.6922 - val_loss: 0.6300 - val_accuracy: 0.6205\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6010 - accuracy: 0.6939 - val_loss: 0.6322 - val_accuracy: 0.6166\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5986 - accuracy: 0.6965 - val_loss: 0.6306 - val_accuracy: 0.6187\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5976 - accuracy: 0.6963 - val_loss: 0.6261 - val_accuracy: 0.6246\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5975 - accuracy: 0.6950 - val_loss: 0.6319 - val_accuracy: 0.6154\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.5954 - accuracy: 0.6968 - val_loss: 0.6247 - val_accuracy: 0.6265\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5949 - accuracy: 0.6975 - val_loss: 0.6215 - val_accuracy: 0.6300\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5916 - accuracy: 0.7013 - val_loss: 0.6189 - val_accuracy: 0.6328\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5914 - accuracy: 0.6986 - val_loss: 0.6257 - val_accuracy: 0.6228\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.5904 - accuracy: 0.6990 - val_loss: 0.6183 - val_accuracy: 0.6329\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5889 - accuracy: 0.7023 - val_loss: 0.6257 - val_accuracy: 0.6229\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5869 - accuracy: 0.7020 - val_loss: 0.6195 - val_accuracy: 0.6307\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5862 - accuracy: 0.7039 - val_loss: 0.6183 - val_accuracy: 0.6302\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5855 - accuracy: 0.7012 - val_loss: 0.6159 - val_accuracy: 0.6330\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.7288 - accuracy: 0.4719 - val_loss: 0.6405 - val_accuracy: 0.8097\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.7000 - accuracy: 0.4870 - val_loss: 0.6843 - val_accuracy: 0.5374\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6941 - accuracy: 0.5064 - val_loss: 0.6945 - val_accuracy: 0.4804\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6895 - accuracy: 0.5212 - val_loss: 0.6972 - val_accuracy: 0.4754\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6864 - accuracy: 0.5360 - val_loss: 0.6968 - val_accuracy: 0.4915\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6820 - accuracy: 0.5483 - val_loss: 0.6924 - val_accuracy: 0.5231\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6789 - accuracy: 0.5604 - val_loss: 0.6898 - val_accuracy: 0.5442\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6759 - accuracy: 0.5671 - val_loss: 0.6879 - val_accuracy: 0.5562\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.6735 - accuracy: 0.5757 - val_loss: 0.6828 - val_accuracy: 0.5770\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6703 - accuracy: 0.5902 - val_loss: 0.6820 - val_accuracy: 0.5832\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6683 - accuracy: 0.5935 - val_loss: 0.6807 - val_accuracy: 0.5854\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6662 - accuracy: 0.5993 - val_loss: 0.6771 - val_accuracy: 0.5962\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6630 - accuracy: 0.6101 - val_loss: 0.6755 - val_accuracy: 0.6007\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6613 - accuracy: 0.6147 - val_loss: 0.6742 - val_accuracy: 0.6036\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6588 - accuracy: 0.6210 - val_loss: 0.6712 - val_accuracy: 0.6110\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6567 - accuracy: 0.6236 - val_loss: 0.6693 - val_accuracy: 0.6146\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6544 - accuracy: 0.6291 - val_loss: 0.6687 - val_accuracy: 0.6138\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6526 - accuracy: 0.6347 - val_loss: 0.6669 - val_accuracy: 0.6146\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6502 - accuracy: 0.6380 - val_loss: 0.6618 - val_accuracy: 0.6228\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6486 - accuracy: 0.6434 - val_loss: 0.6596 - val_accuracy: 0.6261\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6461 - accuracy: 0.6465 - val_loss: 0.6575 - val_accuracy: 0.6279\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6445 - accuracy: 0.6495 - val_loss: 0.6582 - val_accuracy: 0.6244\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6427 - accuracy: 0.6538 - val_loss: 0.6535 - val_accuracy: 0.6329\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6400 - accuracy: 0.6586 - val_loss: 0.6524 - val_accuracy: 0.6335\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.6376 - accuracy: 0.6599 - val_loss: 0.6502 - val_accuracy: 0.6356\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6360 - accuracy: 0.6623 - val_loss: 0.6487 - val_accuracy: 0.6367\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6347 - accuracy: 0.6655 - val_loss: 0.6473 - val_accuracy: 0.6377\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6329 - accuracy: 0.6676 - val_loss: 0.6458 - val_accuracy: 0.6388\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6303 - accuracy: 0.6725 - val_loss: 0.6460 - val_accuracy: 0.6364\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6292 - accuracy: 0.6730 - val_loss: 0.6433 - val_accuracy: 0.6381\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6273 - accuracy: 0.6731 - val_loss: 0.6436 - val_accuracy: 0.6363\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6250 - accuracy: 0.6772 - val_loss: 0.6434 - val_accuracy: 0.6353\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6252 - accuracy: 0.6768 - val_loss: 0.6365 - val_accuracy: 0.6467\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6220 - accuracy: 0.6782 - val_loss: 0.6384 - val_accuracy: 0.6415\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6209 - accuracy: 0.6812 - val_loss: 0.6363 - val_accuracy: 0.6448\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6193 - accuracy: 0.6808 - val_loss: 0.6319 - val_accuracy: 0.6529\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6177 - accuracy: 0.6848 - val_loss: 0.6336 - val_accuracy: 0.6491\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6155 - accuracy: 0.6840 - val_loss: 0.6321 - val_accuracy: 0.6502\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6143 - accuracy: 0.6876 - val_loss: 0.6299 - val_accuracy: 0.6520\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6124 - accuracy: 0.6866 - val_loss: 0.6301 - val_accuracy: 0.6517\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6115 - accuracy: 0.6900 - val_loss: 0.6307 - val_accuracy: 0.6501\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.6097 - accuracy: 0.6889 - val_loss: 0.6255 - val_accuracy: 0.6550\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6080 - accuracy: 0.6914 - val_loss: 0.6219 - val_accuracy: 0.6584\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.6059 - accuracy: 0.6940 - val_loss: 0.6238 - val_accuracy: 0.6559\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6049 - accuracy: 0.6946 - val_loss: 0.6253 - val_accuracy: 0.6527\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6038 - accuracy: 0.6957 - val_loss: 0.6240 - val_accuracy: 0.6532\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6015 - accuracy: 0.6980 - val_loss: 0.6179 - val_accuracy: 0.6590\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.6007 - accuracy: 0.6993 - val_loss: 0.6243 - val_accuracy: 0.6518\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.5998 - accuracy: 0.6972 - val_loss: 0.6186 - val_accuracy: 0.6575\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.5983 - accuracy: 0.7003 - val_loss: 0.6212 - val_accuracy: 0.6537\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.7088 - accuracy: 0.5110 - val_loss: 0.7340 - val_accuracy: 0.3348\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6995 - accuracy: 0.5250 - val_loss: 0.7165 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6935 - accuracy: 0.5399 - val_loss: 0.7136 - val_accuracy: 0.4194\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6865 - accuracy: 0.5520 - val_loss: 0.7066 - val_accuracy: 0.4692\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6814 - accuracy: 0.5651 - val_loss: 0.7022 - val_accuracy: 0.4964\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6779 - accuracy: 0.5699 - val_loss: 0.6958 - val_accuracy: 0.5249\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.6724 - accuracy: 0.5841 - val_loss: 0.6893 - val_accuracy: 0.5621\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6704 - accuracy: 0.5886 - val_loss: 0.6866 - val_accuracy: 0.5733\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6652 - accuracy: 0.5965 - val_loss: 0.6851 - val_accuracy: 0.5765\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6629 - accuracy: 0.6025 - val_loss: 0.6807 - val_accuracy: 0.5882\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.6591 - accuracy: 0.6096 - val_loss: 0.6803 - val_accuracy: 0.5911\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6574 - accuracy: 0.6120 - val_loss: 0.6778 - val_accuracy: 0.5986\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6527 - accuracy: 0.6220 - val_loss: 0.6724 - val_accuracy: 0.6136\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6508 - accuracy: 0.6228 - val_loss: 0.6749 - val_accuracy: 0.6104\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6484 - accuracy: 0.6261 - val_loss: 0.6700 - val_accuracy: 0.6231\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6455 - accuracy: 0.6316 - val_loss: 0.6645 - val_accuracy: 0.6350\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6420 - accuracy: 0.6360 - val_loss: 0.6660 - val_accuracy: 0.6336\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6401 - accuracy: 0.6377 - val_loss: 0.6668 - val_accuracy: 0.6332\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6375 - accuracy: 0.6401 - val_loss: 0.6638 - val_accuracy: 0.6393\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6346 - accuracy: 0.6459 - val_loss: 0.6582 - val_accuracy: 0.6464\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6316 - accuracy: 0.6495 - val_loss: 0.6557 - val_accuracy: 0.6492\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6301 - accuracy: 0.6520 - val_loss: 0.6511 - val_accuracy: 0.6569\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6278 - accuracy: 0.6522 - val_loss: 0.6520 - val_accuracy: 0.6523\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6253 - accuracy: 0.6548 - val_loss: 0.6541 - val_accuracy: 0.6479\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6240 - accuracy: 0.6571 - val_loss: 0.6490 - val_accuracy: 0.6569\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6229 - accuracy: 0.6571 - val_loss: 0.6429 - val_accuracy: 0.6669\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6194 - accuracy: 0.6642 - val_loss: 0.6454 - val_accuracy: 0.6611\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6182 - accuracy: 0.6631 - val_loss: 0.6424 - val_accuracy: 0.6646\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6154 - accuracy: 0.6669 - val_loss: 0.6413 - val_accuracy: 0.6644\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6151 - accuracy: 0.6657 - val_loss: 0.6374 - val_accuracy: 0.6685\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6131 - accuracy: 0.6693 - val_loss: 0.6346 - val_accuracy: 0.6719\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6104 - accuracy: 0.6718 - val_loss: 0.6398 - val_accuracy: 0.6590\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6096 - accuracy: 0.6732 - val_loss: 0.6335 - val_accuracy: 0.6692\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6074 - accuracy: 0.6739 - val_loss: 0.6343 - val_accuracy: 0.6654\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6055 - accuracy: 0.6754 - val_loss: 0.6345 - val_accuracy: 0.6624\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6050 - accuracy: 0.6752 - val_loss: 0.6312 - val_accuracy: 0.6691\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6033 - accuracy: 0.6768 - val_loss: 0.6306 - val_accuracy: 0.6690\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6014 - accuracy: 0.6802 - val_loss: 0.6303 - val_accuracy: 0.6674\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5998 - accuracy: 0.6814 - val_loss: 0.6297 - val_accuracy: 0.6669\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5980 - accuracy: 0.6809 - val_loss: 0.6285 - val_accuracy: 0.6675\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5959 - accuracy: 0.6853 - val_loss: 0.6338 - val_accuracy: 0.6534\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5952 - accuracy: 0.6831 - val_loss: 0.6312 - val_accuracy: 0.6577\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.5928 - accuracy: 0.6863 - val_loss: 0.6291 - val_accuracy: 0.6600\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5933 - accuracy: 0.6860 - val_loss: 0.6233 - val_accuracy: 0.6694\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5915 - accuracy: 0.6876 - val_loss: 0.6216 - val_accuracy: 0.6689\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5896 - accuracy: 0.6899 - val_loss: 0.6198 - val_accuracy: 0.6691\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5882 - accuracy: 0.6915 - val_loss: 0.6175 - val_accuracy: 0.6696\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5875 - accuracy: 0.6917 - val_loss: 0.6174 - val_accuracy: 0.6684\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5849 - accuracy: 0.6977 - val_loss: 0.6157 - val_accuracy: 0.6691\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5838 - accuracy: 0.6965 - val_loss: 0.6143 - val_accuracy: 0.6687\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.7248 - accuracy: 0.4977 - val_loss: 0.6864 - val_accuracy: 0.5098\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6962 - accuracy: 0.5297 - val_loss: 0.7025 - val_accuracy: 0.4534\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6930 - accuracy: 0.5390 - val_loss: 0.6980 - val_accuracy: 0.4852\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6868 - accuracy: 0.5534 - val_loss: 0.6961 - val_accuracy: 0.4995\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6831 - accuracy: 0.5613 - val_loss: 0.6895 - val_accuracy: 0.5290\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6798 - accuracy: 0.5687 - val_loss: 0.6876 - val_accuracy: 0.5400\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6752 - accuracy: 0.5844 - val_loss: 0.6810 - val_accuracy: 0.5681\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6714 - accuracy: 0.5938 - val_loss: 0.6864 - val_accuracy: 0.5495\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6680 - accuracy: 0.6023 - val_loss: 0.6818 - val_accuracy: 0.5664\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6648 - accuracy: 0.6096 - val_loss: 0.6730 - val_accuracy: 0.5988\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6608 - accuracy: 0.6197 - val_loss: 0.6804 - val_accuracy: 0.5760\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6579 - accuracy: 0.6273 - val_loss: 0.6737 - val_accuracy: 0.5994\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6563 - accuracy: 0.6308 - val_loss: 0.6693 - val_accuracy: 0.6109\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6518 - accuracy: 0.6393 - val_loss: 0.6702 - val_accuracy: 0.6048\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6478 - accuracy: 0.6494 - val_loss: 0.6657 - val_accuracy: 0.6100\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6462 - accuracy: 0.6505 - val_loss: 0.6597 - val_accuracy: 0.6195\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6423 - accuracy: 0.6563 - val_loss: 0.6597 - val_accuracy: 0.6158\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6401 - accuracy: 0.6612 - val_loss: 0.6582 - val_accuracy: 0.6167\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6384 - accuracy: 0.6622 - val_loss: 0.6548 - val_accuracy: 0.6205\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6353 - accuracy: 0.6651 - val_loss: 0.6520 - val_accuracy: 0.6232\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6332 - accuracy: 0.6694 - val_loss: 0.6542 - val_accuracy: 0.6157\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6304 - accuracy: 0.6742 - val_loss: 0.6516 - val_accuracy: 0.6187\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6281 - accuracy: 0.6759 - val_loss: 0.6472 - val_accuracy: 0.6242\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6259 - accuracy: 0.6767 - val_loss: 0.6453 - val_accuracy: 0.6257\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6232 - accuracy: 0.6792 - val_loss: 0.6443 - val_accuracy: 0.6253\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6222 - accuracy: 0.6815 - val_loss: 0.6436 - val_accuracy: 0.6247\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6195 - accuracy: 0.6851 - val_loss: 0.6420 - val_accuracy: 0.6259\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6180 - accuracy: 0.6861 - val_loss: 0.6389 - val_accuracy: 0.6279\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6160 - accuracy: 0.6851 - val_loss: 0.6377 - val_accuracy: 0.6286\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6132 - accuracy: 0.6887 - val_loss: 0.6358 - val_accuracy: 0.6308\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6116 - accuracy: 0.6921 - val_loss: 0.6356 - val_accuracy: 0.6292\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6105 - accuracy: 0.6895 - val_loss: 0.6303 - val_accuracy: 0.6362\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6086 - accuracy: 0.6910 - val_loss: 0.6311 - val_accuracy: 0.6341\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6070 - accuracy: 0.6927 - val_loss: 0.6306 - val_accuracy: 0.6329\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6046 - accuracy: 0.6955 - val_loss: 0.6286 - val_accuracy: 0.6354\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6024 - accuracy: 0.6981 - val_loss: 0.6317 - val_accuracy: 0.6278\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6009 - accuracy: 0.6987 - val_loss: 0.6277 - val_accuracy: 0.6357\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5997 - accuracy: 0.6968 - val_loss: 0.6210 - val_accuracy: 0.6417\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5980 - accuracy: 0.6992 - val_loss: 0.6251 - val_accuracy: 0.6381\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5967 - accuracy: 0.7000 - val_loss: 0.6234 - val_accuracy: 0.6387\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5943 - accuracy: 0.7041 - val_loss: 0.6182 - val_accuracy: 0.6436\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5921 - accuracy: 0.7039 - val_loss: 0.6143 - val_accuracy: 0.6476\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5922 - accuracy: 0.7030 - val_loss: 0.6218 - val_accuracy: 0.6387\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5895 - accuracy: 0.7061 - val_loss: 0.6181 - val_accuracy: 0.6413\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5891 - accuracy: 0.7030 - val_loss: 0.6180 - val_accuracy: 0.6409\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5867 - accuracy: 0.7077 - val_loss: 0.6184 - val_accuracy: 0.6403\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5846 - accuracy: 0.7098 - val_loss: 0.6127 - val_accuracy: 0.6460\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.5844 - accuracy: 0.7082 - val_loss: 0.6181 - val_accuracy: 0.6399\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5830 - accuracy: 0.7107 - val_loss: 0.6129 - val_accuracy: 0.6459\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5819 - accuracy: 0.7098 - val_loss: 0.6195 - val_accuracy: 0.6377\n"
     ]
    }
   ],
   "source": [
    "# 1. Variar num_microbatches\n",
    "results_num_microbatches = {}\n",
    "eps_num_microbatches = {}\n",
    "for nm in num_microbatches_values:\n",
    "    print(f\"\\nEntrenando modelo con num_microbatches={nm}...\")\n",
    "    eps = compute_privacy_budget(n, batch_size, default_noise_multiplier, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "        batch_size, epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=nm, l2_norm_clip=default_l2_norm_clip,\n",
    "        noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_num_microbatches[nm] = compute_statistics(results)\n",
    "    eps_num_microbatches[nm] = eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b0a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo con l2_norm_clip=0.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.7128 - accuracy: 0.5278 - val_loss: 0.7158 - val_accuracy: 0.4483\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6946 - accuracy: 0.5413 - val_loss: 0.6999 - val_accuracy: 0.5145\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6868 - accuracy: 0.5527 - val_loss: 0.6903 - val_accuracy: 0.5469\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6819 - accuracy: 0.5635 - val_loss: 0.6970 - val_accuracy: 0.5232\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6759 - accuracy: 0.5737 - val_loss: 0.6880 - val_accuracy: 0.5535\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6737 - accuracy: 0.5793 - val_loss: 0.6793 - val_accuracy: 0.5813\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6682 - accuracy: 0.5887 - val_loss: 0.6790 - val_accuracy: 0.5819\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6641 - accuracy: 0.5972 - val_loss: 0.6752 - val_accuracy: 0.5938\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6609 - accuracy: 0.6000 - val_loss: 0.6765 - val_accuracy: 0.5865\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6568 - accuracy: 0.6106 - val_loss: 0.6705 - val_accuracy: 0.6001\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6523 - accuracy: 0.6169 - val_loss: 0.6694 - val_accuracy: 0.6009\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6502 - accuracy: 0.6196 - val_loss: 0.6633 - val_accuracy: 0.6137\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6449 - accuracy: 0.6312 - val_loss: 0.6634 - val_accuracy: 0.6098\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6430 - accuracy: 0.6346 - val_loss: 0.6586 - val_accuracy: 0.6183\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6392 - accuracy: 0.6391 - val_loss: 0.6577 - val_accuracy: 0.6180\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.6357 - accuracy: 0.6426 - val_loss: 0.6555 - val_accuracy: 0.6196\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6332 - accuracy: 0.6475 - val_loss: 0.6503 - val_accuracy: 0.6256\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6305 - accuracy: 0.6512 - val_loss: 0.6476 - val_accuracy: 0.6289\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6276 - accuracy: 0.6529 - val_loss: 0.6415 - val_accuracy: 0.6404\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.6260 - accuracy: 0.6550 - val_loss: 0.6428 - val_accuracy: 0.6354\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.6214 - accuracy: 0.6603 - val_loss: 0.6411 - val_accuracy: 0.6370\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6199 - accuracy: 0.6616 - val_loss: 0.6414 - val_accuracy: 0.6356\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.6172 - accuracy: 0.6666 - val_loss: 0.6445 - val_accuracy: 0.6278\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6148 - accuracy: 0.6693 - val_loss: 0.6327 - val_accuracy: 0.6458\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6130 - accuracy: 0.6719 - val_loss: 0.6348 - val_accuracy: 0.6402\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6112 - accuracy: 0.6722 - val_loss: 0.6358 - val_accuracy: 0.6372\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6080 - accuracy: 0.6752 - val_loss: 0.6288 - val_accuracy: 0.6455\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6063 - accuracy: 0.6764 - val_loss: 0.6286 - val_accuracy: 0.6441\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.6044 - accuracy: 0.6774 - val_loss: 0.6258 - val_accuracy: 0.6468\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6013 - accuracy: 0.6825 - val_loss: 0.6272 - val_accuracy: 0.6430\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.6002 - accuracy: 0.6823 - val_loss: 0.6235 - val_accuracy: 0.6467\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.5983 - accuracy: 0.6849 - val_loss: 0.6166 - val_accuracy: 0.6547\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5965 - accuracy: 0.6859 - val_loss: 0.6228 - val_accuracy: 0.6460\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.5945 - accuracy: 0.6890 - val_loss: 0.6186 - val_accuracy: 0.6487\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5927 - accuracy: 0.6906 - val_loss: 0.6239 - val_accuracy: 0.6410\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5916 - accuracy: 0.6919 - val_loss: 0.6180 - val_accuracy: 0.6489\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5889 - accuracy: 0.6944 - val_loss: 0.6161 - val_accuracy: 0.6496\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5870 - accuracy: 0.6951 - val_loss: 0.6171 - val_accuracy: 0.6470\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5869 - accuracy: 0.6951 - val_loss: 0.6069 - val_accuracy: 0.6601\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5833 - accuracy: 0.7007 - val_loss: 0.6189 - val_accuracy: 0.6419\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5817 - accuracy: 0.7002 - val_loss: 0.6119 - val_accuracy: 0.6513\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5804 - accuracy: 0.7019 - val_loss: 0.6103 - val_accuracy: 0.6537\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5795 - accuracy: 0.7013 - val_loss: 0.6136 - val_accuracy: 0.6478\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5773 - accuracy: 0.7056 - val_loss: 0.6127 - val_accuracy: 0.6486\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5760 - accuracy: 0.7074 - val_loss: 0.6132 - val_accuracy: 0.6477\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5743 - accuracy: 0.7066 - val_loss: 0.6105 - val_accuracy: 0.6499\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5717 - accuracy: 0.7130 - val_loss: 0.6181 - val_accuracy: 0.6424\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5706 - accuracy: 0.7093 - val_loss: 0.6112 - val_accuracy: 0.6476\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5695 - accuracy: 0.7125 - val_loss: 0.6121 - val_accuracy: 0.6474\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5673 - accuracy: 0.7120 - val_loss: 0.6077 - val_accuracy: 0.6518\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.7222 - accuracy: 0.5094 - val_loss: 0.6995 - val_accuracy: 0.4338\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.7002 - accuracy: 0.5303 - val_loss: 0.7115 - val_accuracy: 0.3471\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6918 - accuracy: 0.5450 - val_loss: 0.7057 - val_accuracy: 0.4202\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6837 - accuracy: 0.5639 - val_loss: 0.7055 - val_accuracy: 0.4421\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6768 - accuracy: 0.5763 - val_loss: 0.6988 - val_accuracy: 0.5004\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6723 - accuracy: 0.5864 - val_loss: 0.6886 - val_accuracy: 0.5503\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6685 - accuracy: 0.5963 - val_loss: 0.6872 - val_accuracy: 0.5562\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6629 - accuracy: 0.6087 - val_loss: 0.6823 - val_accuracy: 0.5692\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6585 - accuracy: 0.6163 - val_loss: 0.6740 - val_accuracy: 0.5860\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6547 - accuracy: 0.6232 - val_loss: 0.6785 - val_accuracy: 0.5750\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6515 - accuracy: 0.6316 - val_loss: 0.6713 - val_accuracy: 0.5895\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6483 - accuracy: 0.6362 - val_loss: 0.6726 - val_accuracy: 0.5861\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6454 - accuracy: 0.6414 - val_loss: 0.6682 - val_accuracy: 0.5939\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6421 - accuracy: 0.6466 - val_loss: 0.6624 - val_accuracy: 0.6049\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6379 - accuracy: 0.6523 - val_loss: 0.6623 - val_accuracy: 0.6049\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6355 - accuracy: 0.6542 - val_loss: 0.6600 - val_accuracy: 0.6073\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6317 - accuracy: 0.6587 - val_loss: 0.6594 - val_accuracy: 0.6073\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6293 - accuracy: 0.6637 - val_loss: 0.6548 - val_accuracy: 0.6145\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6268 - accuracy: 0.6688 - val_loss: 0.6506 - val_accuracy: 0.6178\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6249 - accuracy: 0.6672 - val_loss: 0.6435 - val_accuracy: 0.6286\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6222 - accuracy: 0.6699 - val_loss: 0.6496 - val_accuracy: 0.6178\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6205 - accuracy: 0.6733 - val_loss: 0.6491 - val_accuracy: 0.6176\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 701us/step - loss: 0.6168 - accuracy: 0.6775 - val_loss: 0.6395 - val_accuracy: 0.6307\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6151 - accuracy: 0.6793 - val_loss: 0.6388 - val_accuracy: 0.6308\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6127 - accuracy: 0.6804 - val_loss: 0.6408 - val_accuracy: 0.6278\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6101 - accuracy: 0.6841 - val_loss: 0.6444 - val_accuracy: 0.6227\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6081 - accuracy: 0.6849 - val_loss: 0.6366 - val_accuracy: 0.6295\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6072 - accuracy: 0.6867 - val_loss: 0.6385 - val_accuracy: 0.6265\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6048 - accuracy: 0.6881 - val_loss: 0.6334 - val_accuracy: 0.6325\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6021 - accuracy: 0.6904 - val_loss: 0.6292 - val_accuracy: 0.6380\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6008 - accuracy: 0.6897 - val_loss: 0.6272 - val_accuracy: 0.6394\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5995 - accuracy: 0.6925 - val_loss: 0.6330 - val_accuracy: 0.6295\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5972 - accuracy: 0.6944 - val_loss: 0.6328 - val_accuracy: 0.6282\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5953 - accuracy: 0.6941 - val_loss: 0.6241 - val_accuracy: 0.6410\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5930 - accuracy: 0.6985 - val_loss: 0.6226 - val_accuracy: 0.6422\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5923 - accuracy: 0.6976 - val_loss: 0.6208 - val_accuracy: 0.6449\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5904 - accuracy: 0.6987 - val_loss: 0.6240 - val_accuracy: 0.6389\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5884 - accuracy: 0.7000 - val_loss: 0.6242 - val_accuracy: 0.6386\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5871 - accuracy: 0.7026 - val_loss: 0.6221 - val_accuracy: 0.6424\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5845 - accuracy: 0.7043 - val_loss: 0.6157 - val_accuracy: 0.6501\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5848 - accuracy: 0.7029 - val_loss: 0.6192 - val_accuracy: 0.6445\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5821 - accuracy: 0.7072 - val_loss: 0.6192 - val_accuracy: 0.6455\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 701us/step - loss: 0.5797 - accuracy: 0.7083 - val_loss: 0.6238 - val_accuracy: 0.6409\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.5791 - accuracy: 0.7088 - val_loss: 0.6176 - val_accuracy: 0.6471\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5779 - accuracy: 0.7092 - val_loss: 0.6197 - val_accuracy: 0.6444\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5761 - accuracy: 0.7109 - val_loss: 0.6126 - val_accuracy: 0.6514\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.5753 - accuracy: 0.7106 - val_loss: 0.6085 - val_accuracy: 0.6542\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5740 - accuracy: 0.7109 - val_loss: 0.6139 - val_accuracy: 0.6504\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5727 - accuracy: 0.7106 - val_loss: 0.6132 - val_accuracy: 0.6509\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5712 - accuracy: 0.7143 - val_loss: 0.6127 - val_accuracy: 0.6511\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.7307 - accuracy: 0.4808 - val_loss: 0.7284 - val_accuracy: 0.3496\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.7176 - accuracy: 0.5001 - val_loss: 0.7232 - val_accuracy: 0.3703\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.7090 - accuracy: 0.5096 - val_loss: 0.7096 - val_accuracy: 0.4593\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6980 - accuracy: 0.5296 - val_loss: 0.7082 - val_accuracy: 0.4790\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6901 - accuracy: 0.5451 - val_loss: 0.7020 - val_accuracy: 0.5121\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6821 - accuracy: 0.5641 - val_loss: 0.6939 - val_accuracy: 0.5452\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6741 - accuracy: 0.5793 - val_loss: 0.6828 - val_accuracy: 0.5823\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6678 - accuracy: 0.5951 - val_loss: 0.6800 - val_accuracy: 0.5911\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6641 - accuracy: 0.6024 - val_loss: 0.6782 - val_accuracy: 0.5946\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6575 - accuracy: 0.6174 - val_loss: 0.6795 - val_accuracy: 0.5898\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6529 - accuracy: 0.6251 - val_loss: 0.6692 - val_accuracy: 0.6085\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6494 - accuracy: 0.6356 - val_loss: 0.6662 - val_accuracy: 0.6107\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6446 - accuracy: 0.6435 - val_loss: 0.6612 - val_accuracy: 0.6144\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6426 - accuracy: 0.6467 - val_loss: 0.6589 - val_accuracy: 0.6169\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6374 - accuracy: 0.6561 - val_loss: 0.6549 - val_accuracy: 0.6203\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6354 - accuracy: 0.6591 - val_loss: 0.6559 - val_accuracy: 0.6171\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6324 - accuracy: 0.6648 - val_loss: 0.6468 - val_accuracy: 0.6311\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6276 - accuracy: 0.6693 - val_loss: 0.6532 - val_accuracy: 0.6199\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6263 - accuracy: 0.6707 - val_loss: 0.6517 - val_accuracy: 0.6216\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6227 - accuracy: 0.6760 - val_loss: 0.6524 - val_accuracy: 0.6194\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6208 - accuracy: 0.6779 - val_loss: 0.6449 - val_accuracy: 0.6289\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6190 - accuracy: 0.6809 - val_loss: 0.6431 - val_accuracy: 0.6301\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6151 - accuracy: 0.6830 - val_loss: 0.6494 - val_accuracy: 0.6199\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6122 - accuracy: 0.6875 - val_loss: 0.6423 - val_accuracy: 0.6288\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6111 - accuracy: 0.6892 - val_loss: 0.6408 - val_accuracy: 0.6300\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6094 - accuracy: 0.6911 - val_loss: 0.6310 - val_accuracy: 0.6382\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6063 - accuracy: 0.6926 - val_loss: 0.6362 - val_accuracy: 0.6318\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6048 - accuracy: 0.6911 - val_loss: 0.6350 - val_accuracy: 0.6322\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6031 - accuracy: 0.6965 - val_loss: 0.6211 - val_accuracy: 0.6459\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6014 - accuracy: 0.6958 - val_loss: 0.6332 - val_accuracy: 0.6325\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5996 - accuracy: 0.6996 - val_loss: 0.6329 - val_accuracy: 0.6333\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.5980 - accuracy: 0.6975 - val_loss: 0.6282 - val_accuracy: 0.6396\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5952 - accuracy: 0.6999 - val_loss: 0.6266 - val_accuracy: 0.6403\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5941 - accuracy: 0.7027 - val_loss: 0.6229 - val_accuracy: 0.6426\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5924 - accuracy: 0.7034 - val_loss: 0.6214 - val_accuracy: 0.6433\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5908 - accuracy: 0.7063 - val_loss: 0.6263 - val_accuracy: 0.6395\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5896 - accuracy: 0.7044 - val_loss: 0.6200 - val_accuracy: 0.6436\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5880 - accuracy: 0.7067 - val_loss: 0.6214 - val_accuracy: 0.6419\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5860 - accuracy: 0.7064 - val_loss: 0.6205 - val_accuracy: 0.6422\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5832 - accuracy: 0.7091 - val_loss: 0.6225 - val_accuracy: 0.6403\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.5824 - accuracy: 0.7093 - val_loss: 0.6131 - val_accuracy: 0.6466\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5807 - accuracy: 0.7102 - val_loss: 0.6182 - val_accuracy: 0.6429\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5788 - accuracy: 0.7137 - val_loss: 0.6239 - val_accuracy: 0.6387\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.5788 - accuracy: 0.7124 - val_loss: 0.6165 - val_accuracy: 0.6436\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5773 - accuracy: 0.7119 - val_loss: 0.6145 - val_accuracy: 0.6451\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5762 - accuracy: 0.7134 - val_loss: 0.6146 - val_accuracy: 0.6446\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5750 - accuracy: 0.7128 - val_loss: 0.6171 - val_accuracy: 0.6423\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5722 - accuracy: 0.7159 - val_loss: 0.6129 - val_accuracy: 0.6453\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.5714 - accuracy: 0.7154 - val_loss: 0.6064 - val_accuracy: 0.6532\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.5706 - accuracy: 0.7164 - val_loss: 0.6148 - val_accuracy: 0.6434\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.7441 - accuracy: 0.5091 - val_loss: 0.7622 - val_accuracy: 0.3602\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.7045 - accuracy: 0.5188 - val_loss: 0.7379 - val_accuracy: 0.4594\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6914 - accuracy: 0.5426 - val_loss: 0.7235 - val_accuracy: 0.5216\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6830 - accuracy: 0.5657 - val_loss: 0.7171 - val_accuracy: 0.5375\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6747 - accuracy: 0.5812 - val_loss: 0.7019 - val_accuracy: 0.5699\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6679 - accuracy: 0.5924 - val_loss: 0.6977 - val_accuracy: 0.5709\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6633 - accuracy: 0.6029 - val_loss: 0.6978 - val_accuracy: 0.5697\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6578 - accuracy: 0.6130 - val_loss: 0.6879 - val_accuracy: 0.5833\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6536 - accuracy: 0.6183 - val_loss: 0.6843 - val_accuracy: 0.5886\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6476 - accuracy: 0.6311 - val_loss: 0.6782 - val_accuracy: 0.5981\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6445 - accuracy: 0.6325 - val_loss: 0.6748 - val_accuracy: 0.6027\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.6399 - accuracy: 0.6399 - val_loss: 0.6719 - val_accuracy: 0.6082\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6356 - accuracy: 0.6503 - val_loss: 0.6730 - val_accuracy: 0.6074\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6329 - accuracy: 0.6520 - val_loss: 0.6666 - val_accuracy: 0.6184\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6291 - accuracy: 0.6558 - val_loss: 0.6644 - val_accuracy: 0.6171\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6268 - accuracy: 0.6573 - val_loss: 0.6616 - val_accuracy: 0.6185\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6227 - accuracy: 0.6645 - val_loss: 0.6591 - val_accuracy: 0.6201\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6206 - accuracy: 0.6665 - val_loss: 0.6561 - val_accuracy: 0.6227\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6175 - accuracy: 0.6675 - val_loss: 0.6502 - val_accuracy: 0.6291\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6147 - accuracy: 0.6712 - val_loss: 0.6453 - val_accuracy: 0.6357\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6131 - accuracy: 0.6730 - val_loss: 0.6539 - val_accuracy: 0.6226\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6115 - accuracy: 0.6738 - val_loss: 0.6516 - val_accuracy: 0.6242\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6083 - accuracy: 0.6776 - val_loss: 0.6496 - val_accuracy: 0.6270\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6062 - accuracy: 0.6790 - val_loss: 0.6490 - val_accuracy: 0.6274\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6033 - accuracy: 0.6829 - val_loss: 0.6471 - val_accuracy: 0.6297\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6023 - accuracy: 0.6837 - val_loss: 0.6439 - val_accuracy: 0.6335\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5994 - accuracy: 0.6873 - val_loss: 0.6458 - val_accuracy: 0.6284\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5973 - accuracy: 0.6868 - val_loss: 0.6438 - val_accuracy: 0.6289\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.5956 - accuracy: 0.6888 - val_loss: 0.6389 - val_accuracy: 0.6347\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5944 - accuracy: 0.6892 - val_loss: 0.6332 - val_accuracy: 0.6420\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5923 - accuracy: 0.6930 - val_loss: 0.6371 - val_accuracy: 0.6360\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5891 - accuracy: 0.6945 - val_loss: 0.6394 - val_accuracy: 0.6322\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.5882 - accuracy: 0.6950 - val_loss: 0.6223 - val_accuracy: 0.6531\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.5866 - accuracy: 0.6966 - val_loss: 0.6335 - val_accuracy: 0.6391\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5858 - accuracy: 0.6966 - val_loss: 0.6336 - val_accuracy: 0.6388\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5837 - accuracy: 0.6994 - val_loss: 0.6357 - val_accuracy: 0.6350\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.5825 - accuracy: 0.7013 - val_loss: 0.6209 - val_accuracy: 0.6517\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.5814 - accuracy: 0.7018 - val_loss: 0.6312 - val_accuracy: 0.6389\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.5800 - accuracy: 0.7015 - val_loss: 0.6362 - val_accuracy: 0.6336\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5779 - accuracy: 0.7040 - val_loss: 0.6281 - val_accuracy: 0.6420\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5769 - accuracy: 0.7030 - val_loss: 0.6273 - val_accuracy: 0.6424\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.5754 - accuracy: 0.7045 - val_loss: 0.6205 - val_accuracy: 0.6500\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5743 - accuracy: 0.7048 - val_loss: 0.6270 - val_accuracy: 0.6409\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5727 - accuracy: 0.7044 - val_loss: 0.6296 - val_accuracy: 0.6392\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5715 - accuracy: 0.7084 - val_loss: 0.6239 - val_accuracy: 0.6450\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5705 - accuracy: 0.7075 - val_loss: 0.6256 - val_accuracy: 0.6422\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5693 - accuracy: 0.7104 - val_loss: 0.6309 - val_accuracy: 0.6376\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5678 - accuracy: 0.7111 - val_loss: 0.6286 - val_accuracy: 0.6394\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5674 - accuracy: 0.7111 - val_loss: 0.6205 - val_accuracy: 0.6477\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5658 - accuracy: 0.7101 - val_loss: 0.6284 - val_accuracy: 0.6391\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.7241 - accuracy: 0.5022 - val_loss: 0.6752 - val_accuracy: 0.5915\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6903 - accuracy: 0.5358 - val_loss: 0.6946 - val_accuracy: 0.5375\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6819 - accuracy: 0.5559 - val_loss: 0.6868 - val_accuracy: 0.5717\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6755 - accuracy: 0.5742 - val_loss: 0.6830 - val_accuracy: 0.5890\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6705 - accuracy: 0.5863 - val_loss: 0.6844 - val_accuracy: 0.5864\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6656 - accuracy: 0.6016 - val_loss: 0.6766 - val_accuracy: 0.6012\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6597 - accuracy: 0.6138 - val_loss: 0.6733 - val_accuracy: 0.6025\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6550 - accuracy: 0.6209 - val_loss: 0.6682 - val_accuracy: 0.6113\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6496 - accuracy: 0.6334 - val_loss: 0.6666 - val_accuracy: 0.6169\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6441 - accuracy: 0.6390 - val_loss: 0.6636 - val_accuracy: 0.6229\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6401 - accuracy: 0.6451 - val_loss: 0.6584 - val_accuracy: 0.6321\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6383 - accuracy: 0.6493 - val_loss: 0.6524 - val_accuracy: 0.6386\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6345 - accuracy: 0.6514 - val_loss: 0.6525 - val_accuracy: 0.6386\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6309 - accuracy: 0.6587 - val_loss: 0.6518 - val_accuracy: 0.6375\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6282 - accuracy: 0.6637 - val_loss: 0.6456 - val_accuracy: 0.6427\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6253 - accuracy: 0.6667 - val_loss: 0.6476 - val_accuracy: 0.6363\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6220 - accuracy: 0.6678 - val_loss: 0.6435 - val_accuracy: 0.6420\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6196 - accuracy: 0.6708 - val_loss: 0.6433 - val_accuracy: 0.6422\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6179 - accuracy: 0.6735 - val_loss: 0.6433 - val_accuracy: 0.6416\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6158 - accuracy: 0.6755 - val_loss: 0.6377 - val_accuracy: 0.6480\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6128 - accuracy: 0.6774 - val_loss: 0.6404 - val_accuracy: 0.6446\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6115 - accuracy: 0.6785 - val_loss: 0.6339 - val_accuracy: 0.6518\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6087 - accuracy: 0.6809 - val_loss: 0.6323 - val_accuracy: 0.6522\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6061 - accuracy: 0.6848 - val_loss: 0.6351 - val_accuracy: 0.6488\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6048 - accuracy: 0.6847 - val_loss: 0.6394 - val_accuracy: 0.6438\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6027 - accuracy: 0.6862 - val_loss: 0.6291 - val_accuracy: 0.6523\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6016 - accuracy: 0.6878 - val_loss: 0.6325 - val_accuracy: 0.6499\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.5989 - accuracy: 0.6892 - val_loss: 0.6282 - val_accuracy: 0.6511\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.5972 - accuracy: 0.6892 - val_loss: 0.6286 - val_accuracy: 0.6489\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.5955 - accuracy: 0.6906 - val_loss: 0.6313 - val_accuracy: 0.6458\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.5933 - accuracy: 0.6919 - val_loss: 0.6246 - val_accuracy: 0.6514\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.5918 - accuracy: 0.6935 - val_loss: 0.6208 - val_accuracy: 0.6585\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.5900 - accuracy: 0.6951 - val_loss: 0.6247 - val_accuracy: 0.6541\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.5897 - accuracy: 0.6966 - val_loss: 0.6192 - val_accuracy: 0.6597\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5864 - accuracy: 0.7002 - val_loss: 0.6199 - val_accuracy: 0.6583\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.5852 - accuracy: 0.6980 - val_loss: 0.6177 - val_accuracy: 0.6592\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.5836 - accuracy: 0.7000 - val_loss: 0.6205 - val_accuracy: 0.6587\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5827 - accuracy: 0.7003 - val_loss: 0.6168 - val_accuracy: 0.6592\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5815 - accuracy: 0.7012 - val_loss: 0.6180 - val_accuracy: 0.6587\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5792 - accuracy: 0.7037 - val_loss: 0.6109 - val_accuracy: 0.6626\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5775 - accuracy: 0.7045 - val_loss: 0.6078 - val_accuracy: 0.6645\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5766 - accuracy: 0.7053 - val_loss: 0.6145 - val_accuracy: 0.6607\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5755 - accuracy: 0.7054 - val_loss: 0.6181 - val_accuracy: 0.6580\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5739 - accuracy: 0.7055 - val_loss: 0.6148 - val_accuracy: 0.6603\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5731 - accuracy: 0.7077 - val_loss: 0.6139 - val_accuracy: 0.6605\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5715 - accuracy: 0.7078 - val_loss: 0.6139 - val_accuracy: 0.6612\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5702 - accuracy: 0.7088 - val_loss: 0.6112 - val_accuracy: 0.6626\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5695 - accuracy: 0.7085 - val_loss: 0.6102 - val_accuracy: 0.6642\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5685 - accuracy: 0.7111 - val_loss: 0.6110 - val_accuracy: 0.6636\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.5664 - accuracy: 0.7119 - val_loss: 0.6090 - val_accuracy: 0.6648\n",
      "\n",
      "Entrenando modelo con l2_norm_clip=1.0...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.7210 - accuracy: 0.5042 - val_loss: 0.7032 - val_accuracy: 0.4596\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.7041 - accuracy: 0.5282 - val_loss: 0.6963 - val_accuracy: 0.4977\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6935 - accuracy: 0.5432 - val_loss: 0.6894 - val_accuracy: 0.5285\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6856 - accuracy: 0.5600 - val_loss: 0.6819 - val_accuracy: 0.5521\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6783 - accuracy: 0.5757 - val_loss: 0.6796 - val_accuracy: 0.5605\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6726 - accuracy: 0.5836 - val_loss: 0.6710 - val_accuracy: 0.5822\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6651 - accuracy: 0.5993 - val_loss: 0.6721 - val_accuracy: 0.5811\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6602 - accuracy: 0.6094 - val_loss: 0.6647 - val_accuracy: 0.5967\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6551 - accuracy: 0.6187 - val_loss: 0.6615 - val_accuracy: 0.6041\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6503 - accuracy: 0.6261 - val_loss: 0.6590 - val_accuracy: 0.6085\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6446 - accuracy: 0.6366 - val_loss: 0.6539 - val_accuracy: 0.6177\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6406 - accuracy: 0.6417 - val_loss: 0.6543 - val_accuracy: 0.6154\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6367 - accuracy: 0.6460 - val_loss: 0.6487 - val_accuracy: 0.6237\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6329 - accuracy: 0.6536 - val_loss: 0.6483 - val_accuracy: 0.6219\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6313 - accuracy: 0.6562 - val_loss: 0.6505 - val_accuracy: 0.6168\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6273 - accuracy: 0.6607 - val_loss: 0.6439 - val_accuracy: 0.6268\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6229 - accuracy: 0.6656 - val_loss: 0.6461 - val_accuracy: 0.6225\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6213 - accuracy: 0.6676 - val_loss: 0.6402 - val_accuracy: 0.6303\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6185 - accuracy: 0.6702 - val_loss: 0.6383 - val_accuracy: 0.6325\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6158 - accuracy: 0.6717 - val_loss: 0.6359 - val_accuracy: 0.6349\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6142 - accuracy: 0.6759 - val_loss: 0.6365 - val_accuracy: 0.6339\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6108 - accuracy: 0.6787 - val_loss: 0.6292 - val_accuracy: 0.6408\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6085 - accuracy: 0.6813 - val_loss: 0.6345 - val_accuracy: 0.6341\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6070 - accuracy: 0.6833 - val_loss: 0.6264 - val_accuracy: 0.6450\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6045 - accuracy: 0.6841 - val_loss: 0.6278 - val_accuracy: 0.6405\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6023 - accuracy: 0.6875 - val_loss: 0.6254 - val_accuracy: 0.6447\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6002 - accuracy: 0.6884 - val_loss: 0.6248 - val_accuracy: 0.6461\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.5979 - accuracy: 0.6918 - val_loss: 0.6266 - val_accuracy: 0.6434\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5959 - accuracy: 0.6922 - val_loss: 0.6184 - val_accuracy: 0.6506\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5955 - accuracy: 0.6952 - val_loss: 0.6237 - val_accuracy: 0.6461\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5938 - accuracy: 0.6945 - val_loss: 0.6224 - val_accuracy: 0.6474\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5924 - accuracy: 0.6943 - val_loss: 0.6220 - val_accuracy: 0.6462\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5896 - accuracy: 0.6967 - val_loss: 0.6173 - val_accuracy: 0.6496\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5890 - accuracy: 0.6989 - val_loss: 0.6191 - val_accuracy: 0.6461\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5875 - accuracy: 0.6985 - val_loss: 0.6152 - val_accuracy: 0.6498\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5847 - accuracy: 0.7017 - val_loss: 0.6174 - val_accuracy: 0.6468\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5841 - accuracy: 0.7014 - val_loss: 0.6165 - val_accuracy: 0.6472\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5825 - accuracy: 0.7015 - val_loss: 0.6141 - val_accuracy: 0.6498\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5803 - accuracy: 0.7047 - val_loss: 0.6196 - val_accuracy: 0.6430\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5797 - accuracy: 0.7048 - val_loss: 0.6181 - val_accuracy: 0.6439\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5773 - accuracy: 0.7078 - val_loss: 0.6170 - val_accuracy: 0.6441\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5767 - accuracy: 0.7099 - val_loss: 0.6129 - val_accuracy: 0.6475\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5755 - accuracy: 0.7087 - val_loss: 0.6079 - val_accuracy: 0.6534\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5752 - accuracy: 0.7089 - val_loss: 0.6081 - val_accuracy: 0.6541\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5723 - accuracy: 0.7122 - val_loss: 0.6221 - val_accuracy: 0.6401\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5716 - accuracy: 0.7103 - val_loss: 0.6101 - val_accuracy: 0.6521\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5705 - accuracy: 0.7131 - val_loss: 0.6096 - val_accuracy: 0.6533\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5689 - accuracy: 0.7135 - val_loss: 0.6109 - val_accuracy: 0.6528\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5678 - accuracy: 0.7137 - val_loss: 0.6101 - val_accuracy: 0.6537\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.5671 - accuracy: 0.7151 - val_loss: 0.6068 - val_accuracy: 0.6575\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.7119 - accuracy: 0.5104 - val_loss: 0.7019 - val_accuracy: 0.5110\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6949 - accuracy: 0.5343 - val_loss: 0.6932 - val_accuracy: 0.5445\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6857 - accuracy: 0.5536 - val_loss: 0.6901 - val_accuracy: 0.5542\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6799 - accuracy: 0.5653 - val_loss: 0.6803 - val_accuracy: 0.5838\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6724 - accuracy: 0.5804 - val_loss: 0.6689 - val_accuracy: 0.6116\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6671 - accuracy: 0.5875 - val_loss: 0.6693 - val_accuracy: 0.6078\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6624 - accuracy: 0.5994 - val_loss: 0.6630 - val_accuracy: 0.6178\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6584 - accuracy: 0.6030 - val_loss: 0.6609 - val_accuracy: 0.6190\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6556 - accuracy: 0.6085 - val_loss: 0.6531 - val_accuracy: 0.6315\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6513 - accuracy: 0.6166 - val_loss: 0.6573 - val_accuracy: 0.6208\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6468 - accuracy: 0.6259 - val_loss: 0.6529 - val_accuracy: 0.6279\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6439 - accuracy: 0.6295 - val_loss: 0.6541 - val_accuracy: 0.6249\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6425 - accuracy: 0.6342 - val_loss: 0.6527 - val_accuracy: 0.6263\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6377 - accuracy: 0.6397 - val_loss: 0.6512 - val_accuracy: 0.6291\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6355 - accuracy: 0.6441 - val_loss: 0.6368 - val_accuracy: 0.6479\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6323 - accuracy: 0.6501 - val_loss: 0.6422 - val_accuracy: 0.6370\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6297 - accuracy: 0.6541 - val_loss: 0.6350 - val_accuracy: 0.6462\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6270 - accuracy: 0.6569 - val_loss: 0.6323 - val_accuracy: 0.6487\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6252 - accuracy: 0.6605 - val_loss: 0.6316 - val_accuracy: 0.6482\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6223 - accuracy: 0.6632 - val_loss: 0.6379 - val_accuracy: 0.6361\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6200 - accuracy: 0.6675 - val_loss: 0.6301 - val_accuracy: 0.6457\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6157 - accuracy: 0.6733 - val_loss: 0.6329 - val_accuracy: 0.6401\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6153 - accuracy: 0.6735 - val_loss: 0.6384 - val_accuracy: 0.6326\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6132 - accuracy: 0.6746 - val_loss: 0.6265 - val_accuracy: 0.6444\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6099 - accuracy: 0.6796 - val_loss: 0.6216 - val_accuracy: 0.6500\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.6083 - accuracy: 0.6816 - val_loss: 0.6239 - val_accuracy: 0.6451\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6056 - accuracy: 0.6823 - val_loss: 0.6274 - val_accuracy: 0.6419\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6038 - accuracy: 0.6867 - val_loss: 0.6249 - val_accuracy: 0.6444\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6014 - accuracy: 0.6893 - val_loss: 0.6267 - val_accuracy: 0.6414\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5996 - accuracy: 0.6903 - val_loss: 0.6192 - val_accuracy: 0.6501\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.5984 - accuracy: 0.6914 - val_loss: 0.6183 - val_accuracy: 0.6522\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5966 - accuracy: 0.6912 - val_loss: 0.6247 - val_accuracy: 0.6416\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.5948 - accuracy: 0.6949 - val_loss: 0.6234 - val_accuracy: 0.6420\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5916 - accuracy: 0.6995 - val_loss: 0.6205 - val_accuracy: 0.6464\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5903 - accuracy: 0.7001 - val_loss: 0.6194 - val_accuracy: 0.6483\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5893 - accuracy: 0.7023 - val_loss: 0.6156 - val_accuracy: 0.6512\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5871 - accuracy: 0.7035 - val_loss: 0.6145 - val_accuracy: 0.6506\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.5857 - accuracy: 0.7045 - val_loss: 0.6114 - val_accuracy: 0.6542\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5828 - accuracy: 0.7061 - val_loss: 0.6143 - val_accuracy: 0.6491\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5811 - accuracy: 0.7074 - val_loss: 0.6089 - val_accuracy: 0.6544\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.5803 - accuracy: 0.7083 - val_loss: 0.6067 - val_accuracy: 0.6561\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5786 - accuracy: 0.7104 - val_loss: 0.6029 - val_accuracy: 0.6590\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5762 - accuracy: 0.7134 - val_loss: 0.6135 - val_accuracy: 0.6469\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5753 - accuracy: 0.7132 - val_loss: 0.6042 - val_accuracy: 0.6569\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.5748 - accuracy: 0.7133 - val_loss: 0.6040 - val_accuracy: 0.6568\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5713 - accuracy: 0.7172 - val_loss: 0.6033 - val_accuracy: 0.6583\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.5697 - accuracy: 0.7166 - val_loss: 0.6075 - val_accuracy: 0.6529\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5693 - accuracy: 0.7165 - val_loss: 0.6006 - val_accuracy: 0.6605\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5672 - accuracy: 0.7188 - val_loss: 0.6100 - val_accuracy: 0.6496\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5665 - accuracy: 0.7208 - val_loss: 0.6159 - val_accuracy: 0.6428\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.7134 - accuracy: 0.5040 - val_loss: 0.7326 - val_accuracy: 0.2790\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.7010 - accuracy: 0.5141 - val_loss: 0.7091 - val_accuracy: 0.3762\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.6936 - accuracy: 0.5288 - val_loss: 0.7003 - val_accuracy: 0.4355\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6866 - accuracy: 0.5441 - val_loss: 0.6953 - val_accuracy: 0.4907\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6817 - accuracy: 0.5575 - val_loss: 0.6897 - val_accuracy: 0.5244\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6783 - accuracy: 0.5677 - val_loss: 0.6886 - val_accuracy: 0.5281\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6745 - accuracy: 0.5765 - val_loss: 0.6826 - val_accuracy: 0.5677\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.6697 - accuracy: 0.5891 - val_loss: 0.6844 - val_accuracy: 0.5645\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6662 - accuracy: 0.5985 - val_loss: 0.6805 - val_accuracy: 0.5848\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6637 - accuracy: 0.6048 - val_loss: 0.6776 - val_accuracy: 0.5926\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6598 - accuracy: 0.6083 - val_loss: 0.6791 - val_accuracy: 0.5883\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6564 - accuracy: 0.6183 - val_loss: 0.6739 - val_accuracy: 0.6016\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6542 - accuracy: 0.6231 - val_loss: 0.6730 - val_accuracy: 0.6027\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6511 - accuracy: 0.6280 - val_loss: 0.6720 - val_accuracy: 0.6052\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6476 - accuracy: 0.6377 - val_loss: 0.6695 - val_accuracy: 0.6116\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6451 - accuracy: 0.6395 - val_loss: 0.6696 - val_accuracy: 0.6104\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6431 - accuracy: 0.6425 - val_loss: 0.6671 - val_accuracy: 0.6229\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6413 - accuracy: 0.6457 - val_loss: 0.6616 - val_accuracy: 0.6353\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6388 - accuracy: 0.6466 - val_loss: 0.6578 - val_accuracy: 0.6405\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6358 - accuracy: 0.6520 - val_loss: 0.6594 - val_accuracy: 0.6347\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6332 - accuracy: 0.6583 - val_loss: 0.6586 - val_accuracy: 0.6333\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6307 - accuracy: 0.6602 - val_loss: 0.6531 - val_accuracy: 0.6418\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6286 - accuracy: 0.6632 - val_loss: 0.6496 - val_accuracy: 0.6472\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6257 - accuracy: 0.6659 - val_loss: 0.6495 - val_accuracy: 0.6436\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6238 - accuracy: 0.6659 - val_loss: 0.6441 - val_accuracy: 0.6540\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6213 - accuracy: 0.6688 - val_loss: 0.6426 - val_accuracy: 0.6550\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6186 - accuracy: 0.6715 - val_loss: 0.6426 - val_accuracy: 0.6510\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6170 - accuracy: 0.6732 - val_loss: 0.6409 - val_accuracy: 0.6523\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6149 - accuracy: 0.6744 - val_loss: 0.6415 - val_accuracy: 0.6483\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6122 - accuracy: 0.6783 - val_loss: 0.6413 - val_accuracy: 0.6465\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6101 - accuracy: 0.6790 - val_loss: 0.6389 - val_accuracy: 0.6507\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6075 - accuracy: 0.6836 - val_loss: 0.6356 - val_accuracy: 0.6541\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6056 - accuracy: 0.6849 - val_loss: 0.6325 - val_accuracy: 0.6571\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6035 - accuracy: 0.6862 - val_loss: 0.6315 - val_accuracy: 0.6562\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6019 - accuracy: 0.6865 - val_loss: 0.6334 - val_accuracy: 0.6528\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5992 - accuracy: 0.6884 - val_loss: 0.6265 - val_accuracy: 0.6600\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.5986 - accuracy: 0.6877 - val_loss: 0.6270 - val_accuracy: 0.6568\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5957 - accuracy: 0.6910 - val_loss: 0.6235 - val_accuracy: 0.6585\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.5945 - accuracy: 0.6927 - val_loss: 0.6264 - val_accuracy: 0.6540\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5924 - accuracy: 0.6954 - val_loss: 0.6230 - val_accuracy: 0.6561\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.5905 - accuracy: 0.6961 - val_loss: 0.6235 - val_accuracy: 0.6551\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.5885 - accuracy: 0.7003 - val_loss: 0.6227 - val_accuracy: 0.6545\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5865 - accuracy: 0.6994 - val_loss: 0.6174 - val_accuracy: 0.6570\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5847 - accuracy: 0.7028 - val_loss: 0.6216 - val_accuracy: 0.6519\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5837 - accuracy: 0.7030 - val_loss: 0.6179 - val_accuracy: 0.6544\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.5817 - accuracy: 0.7044 - val_loss: 0.6180 - val_accuracy: 0.6538\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5800 - accuracy: 0.7081 - val_loss: 0.6056 - val_accuracy: 0.6618\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5779 - accuracy: 0.7065 - val_loss: 0.6168 - val_accuracy: 0.6521\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5769 - accuracy: 0.7073 - val_loss: 0.6125 - val_accuracy: 0.6550\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.5750 - accuracy: 0.7095 - val_loss: 0.6067 - val_accuracy: 0.6577\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.7114 - accuracy: 0.5188 - val_loss: 0.6910 - val_accuracy: 0.5028\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.6933 - accuracy: 0.5418 - val_loss: 0.7097 - val_accuracy: 0.4341\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6869 - accuracy: 0.5591 - val_loss: 0.7036 - val_accuracy: 0.4594\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6817 - accuracy: 0.5696 - val_loss: 0.7007 - val_accuracy: 0.4771\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6764 - accuracy: 0.5832 - val_loss: 0.6991 - val_accuracy: 0.4902\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6725 - accuracy: 0.5920 - val_loss: 0.6918 - val_accuracy: 0.5134\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6684 - accuracy: 0.6005 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6635 - accuracy: 0.6143 - val_loss: 0.6893 - val_accuracy: 0.5242\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6610 - accuracy: 0.6190 - val_loss: 0.6874 - val_accuracy: 0.5300\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6565 - accuracy: 0.6296 - val_loss: 0.6813 - val_accuracy: 0.5448\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6529 - accuracy: 0.6363 - val_loss: 0.6837 - val_accuracy: 0.5386\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6518 - accuracy: 0.6352 - val_loss: 0.6769 - val_accuracy: 0.5518\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6474 - accuracy: 0.6417 - val_loss: 0.6772 - val_accuracy: 0.5525\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6453 - accuracy: 0.6474 - val_loss: 0.6726 - val_accuracy: 0.5611\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6422 - accuracy: 0.6505 - val_loss: 0.6717 - val_accuracy: 0.5628\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6395 - accuracy: 0.6547 - val_loss: 0.6667 - val_accuracy: 0.5725\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6373 - accuracy: 0.6562 - val_loss: 0.6672 - val_accuracy: 0.5704\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6343 - accuracy: 0.6617 - val_loss: 0.6697 - val_accuracy: 0.5656\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6321 - accuracy: 0.6636 - val_loss: 0.6632 - val_accuracy: 0.5756\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6298 - accuracy: 0.6649 - val_loss: 0.6597 - val_accuracy: 0.5802\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6280 - accuracy: 0.6683 - val_loss: 0.6592 - val_accuracy: 0.5802\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6257 - accuracy: 0.6693 - val_loss: 0.6610 - val_accuracy: 0.5762\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6241 - accuracy: 0.6702 - val_loss: 0.6568 - val_accuracy: 0.5830\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6205 - accuracy: 0.6751 - val_loss: 0.6578 - val_accuracy: 0.5804\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6194 - accuracy: 0.6759 - val_loss: 0.6487 - val_accuracy: 0.5942\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6167 - accuracy: 0.6788 - val_loss: 0.6508 - val_accuracy: 0.5916\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6144 - accuracy: 0.6782 - val_loss: 0.6483 - val_accuracy: 0.5943\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6122 - accuracy: 0.6820 - val_loss: 0.6442 - val_accuracy: 0.6009\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6107 - accuracy: 0.6844 - val_loss: 0.6449 - val_accuracy: 0.6004\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6093 - accuracy: 0.6840 - val_loss: 0.6464 - val_accuracy: 0.6001\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6066 - accuracy: 0.6884 - val_loss: 0.6437 - val_accuracy: 0.6025\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6066 - accuracy: 0.6859 - val_loss: 0.6359 - val_accuracy: 0.6099\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6041 - accuracy: 0.6866 - val_loss: 0.6369 - val_accuracy: 0.6086\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6015 - accuracy: 0.6897 - val_loss: 0.6388 - val_accuracy: 0.6061\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6000 - accuracy: 0.6934 - val_loss: 0.6294 - val_accuracy: 0.6140\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5985 - accuracy: 0.6905 - val_loss: 0.6343 - val_accuracy: 0.6081\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5964 - accuracy: 0.6932 - val_loss: 0.6296 - val_accuracy: 0.6105\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.5948 - accuracy: 0.6948 - val_loss: 0.6318 - val_accuracy: 0.6080\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5939 - accuracy: 0.6958 - val_loss: 0.6286 - val_accuracy: 0.6104\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.5913 - accuracy: 0.6967 - val_loss: 0.6277 - val_accuracy: 0.6132\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.5908 - accuracy: 0.6965 - val_loss: 0.6326 - val_accuracy: 0.6069\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.5885 - accuracy: 0.7011 - val_loss: 0.6364 - val_accuracy: 0.6039\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.5874 - accuracy: 0.7005 - val_loss: 0.6326 - val_accuracy: 0.6085\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.5861 - accuracy: 0.7017 - val_loss: 0.6245 - val_accuracy: 0.6194\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5847 - accuracy: 0.7019 - val_loss: 0.6236 - val_accuracy: 0.6207\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5827 - accuracy: 0.7044 - val_loss: 0.6203 - val_accuracy: 0.6270\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.5818 - accuracy: 0.7046 - val_loss: 0.6208 - val_accuracy: 0.6278\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.5804 - accuracy: 0.7051 - val_loss: 0.6220 - val_accuracy: 0.6262\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5789 - accuracy: 0.7055 - val_loss: 0.6206 - val_accuracy: 0.6323\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5779 - accuracy: 0.7057 - val_loss: 0.6237 - val_accuracy: 0.6263\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.7181 - accuracy: 0.4824 - val_loss: 0.7389 - val_accuracy: 0.2703\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.7067 - accuracy: 0.5000 - val_loss: 0.7206 - val_accuracy: 0.3629\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6953 - accuracy: 0.5236 - val_loss: 0.7091 - val_accuracy: 0.4113\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6892 - accuracy: 0.5427 - val_loss: 0.7053 - val_accuracy: 0.4368\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6839 - accuracy: 0.5586 - val_loss: 0.6971 - val_accuracy: 0.4873\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6788 - accuracy: 0.5697 - val_loss: 0.6917 - val_accuracy: 0.5165\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6760 - accuracy: 0.5820 - val_loss: 0.6856 - val_accuracy: 0.5483\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6720 - accuracy: 0.5902 - val_loss: 0.6841 - val_accuracy: 0.5546\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6692 - accuracy: 0.5965 - val_loss: 0.6809 - val_accuracy: 0.5630\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6646 - accuracy: 0.6067 - val_loss: 0.6781 - val_accuracy: 0.5698\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6628 - accuracy: 0.6107 - val_loss: 0.6778 - val_accuracy: 0.5707\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6599 - accuracy: 0.6173 - val_loss: 0.6753 - val_accuracy: 0.5759\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6567 - accuracy: 0.6237 - val_loss: 0.6751 - val_accuracy: 0.5759\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6546 - accuracy: 0.6274 - val_loss: 0.6664 - val_accuracy: 0.5975\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6527 - accuracy: 0.6312 - val_loss: 0.6686 - val_accuracy: 0.5902\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6494 - accuracy: 0.6390 - val_loss: 0.6684 - val_accuracy: 0.5896\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6473 - accuracy: 0.6412 - val_loss: 0.6609 - val_accuracy: 0.6040\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6459 - accuracy: 0.6449 - val_loss: 0.6637 - val_accuracy: 0.5963\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6429 - accuracy: 0.6468 - val_loss: 0.6601 - val_accuracy: 0.6022\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6404 - accuracy: 0.6499 - val_loss: 0.6594 - val_accuracy: 0.6027\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6380 - accuracy: 0.6554 - val_loss: 0.6553 - val_accuracy: 0.6057\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6365 - accuracy: 0.6567 - val_loss: 0.6536 - val_accuracy: 0.6081\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6356 - accuracy: 0.6564 - val_loss: 0.6511 - val_accuracy: 0.6105\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6331 - accuracy: 0.6602 - val_loss: 0.6530 - val_accuracy: 0.6067\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6304 - accuracy: 0.6602 - val_loss: 0.6482 - val_accuracy: 0.6142\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6279 - accuracy: 0.6669 - val_loss: 0.6485 - val_accuracy: 0.6128\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6259 - accuracy: 0.6701 - val_loss: 0.6455 - val_accuracy: 0.6172\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6238 - accuracy: 0.6710 - val_loss: 0.6494 - val_accuracy: 0.6084\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6224 - accuracy: 0.6718 - val_loss: 0.6413 - val_accuracy: 0.6247\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6206 - accuracy: 0.6738 - val_loss: 0.6434 - val_accuracy: 0.6197\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6192 - accuracy: 0.6752 - val_loss: 0.6395 - val_accuracy: 0.6256\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.6171 - accuracy: 0.6762 - val_loss: 0.6380 - val_accuracy: 0.6267\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6155 - accuracy: 0.6773 - val_loss: 0.6362 - val_accuracy: 0.6283\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6133 - accuracy: 0.6795 - val_loss: 0.6375 - val_accuracy: 0.6263\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6123 - accuracy: 0.6798 - val_loss: 0.6345 - val_accuracy: 0.6299\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6104 - accuracy: 0.6826 - val_loss: 0.6357 - val_accuracy: 0.6279\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6086 - accuracy: 0.6841 - val_loss: 0.6361 - val_accuracy: 0.6266\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6074 - accuracy: 0.6867 - val_loss: 0.6276 - val_accuracy: 0.6340\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6058 - accuracy: 0.6854 - val_loss: 0.6277 - val_accuracy: 0.6336\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6034 - accuracy: 0.6882 - val_loss: 0.6338 - val_accuracy: 0.6261\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6019 - accuracy: 0.6872 - val_loss: 0.6318 - val_accuracy: 0.6273\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6005 - accuracy: 0.6904 - val_loss: 0.6275 - val_accuracy: 0.6298\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5982 - accuracy: 0.6927 - val_loss: 0.6270 - val_accuracy: 0.6293\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5984 - accuracy: 0.6902 - val_loss: 0.6230 - val_accuracy: 0.6336\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5959 - accuracy: 0.6916 - val_loss: 0.6228 - val_accuracy: 0.6332\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5946 - accuracy: 0.6931 - val_loss: 0.6284 - val_accuracy: 0.6270\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5926 - accuracy: 0.6951 - val_loss: 0.6240 - val_accuracy: 0.6309\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5930 - accuracy: 0.6947 - val_loss: 0.6217 - val_accuracy: 0.6328\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5904 - accuracy: 0.6977 - val_loss: 0.6190 - val_accuracy: 0.6346\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5887 - accuracy: 0.6983 - val_loss: 0.6259 - val_accuracy: 0.6284\n",
      "\n",
      "Entrenando modelo con l2_norm_clip=1.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.7071 - accuracy: 0.5390 - val_loss: 0.7549 - val_accuracy: 0.2935\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6836 - accuracy: 0.5560 - val_loss: 0.7181 - val_accuracy: 0.4459\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6749 - accuracy: 0.5767 - val_loss: 0.7029 - val_accuracy: 0.5076\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6679 - accuracy: 0.5915 - val_loss: 0.6983 - val_accuracy: 0.5254\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6629 - accuracy: 0.6017 - val_loss: 0.6927 - val_accuracy: 0.5403\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6586 - accuracy: 0.6109 - val_loss: 0.6854 - val_accuracy: 0.5590\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6531 - accuracy: 0.6201 - val_loss: 0.6787 - val_accuracy: 0.5734\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6494 - accuracy: 0.6263 - val_loss: 0.6737 - val_accuracy: 0.5822\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6463 - accuracy: 0.6299 - val_loss: 0.6677 - val_accuracy: 0.5945\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6423 - accuracy: 0.6356 - val_loss: 0.6727 - val_accuracy: 0.5851\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.6395 - accuracy: 0.6382 - val_loss: 0.6622 - val_accuracy: 0.6039\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6364 - accuracy: 0.6451 - val_loss: 0.6587 - val_accuracy: 0.6102\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6334 - accuracy: 0.6465 - val_loss: 0.6591 - val_accuracy: 0.6093\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.6303 - accuracy: 0.6504 - val_loss: 0.6549 - val_accuracy: 0.6134\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6281 - accuracy: 0.6527 - val_loss: 0.6529 - val_accuracy: 0.6164\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6248 - accuracy: 0.6570 - val_loss: 0.6495 - val_accuracy: 0.6201\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6224 - accuracy: 0.6587 - val_loss: 0.6451 - val_accuracy: 0.6242\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6204 - accuracy: 0.6617 - val_loss: 0.6432 - val_accuracy: 0.6263\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6184 - accuracy: 0.6607 - val_loss: 0.6422 - val_accuracy: 0.6267\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6160 - accuracy: 0.6647 - val_loss: 0.6429 - val_accuracy: 0.6244\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6158 - accuracy: 0.6633 - val_loss: 0.6382 - val_accuracy: 0.6326\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6116 - accuracy: 0.6675 - val_loss: 0.6396 - val_accuracy: 0.6294\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6100 - accuracy: 0.6712 - val_loss: 0.6373 - val_accuracy: 0.6318\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6075 - accuracy: 0.6725 - val_loss: 0.6338 - val_accuracy: 0.6356\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6064 - accuracy: 0.6720 - val_loss: 0.6338 - val_accuracy: 0.6350\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6042 - accuracy: 0.6759 - val_loss: 0.6350 - val_accuracy: 0.6326\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6011 - accuracy: 0.6788 - val_loss: 0.6357 - val_accuracy: 0.6310\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5993 - accuracy: 0.6803 - val_loss: 0.6298 - val_accuracy: 0.6381\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5980 - accuracy: 0.6812 - val_loss: 0.6330 - val_accuracy: 0.6314\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.5966 - accuracy: 0.6787 - val_loss: 0.6307 - val_accuracy: 0.6351\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5946 - accuracy: 0.6833 - val_loss: 0.6326 - val_accuracy: 0.6332\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5924 - accuracy: 0.6855 - val_loss: 0.6280 - val_accuracy: 0.6419\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5911 - accuracy: 0.6854 - val_loss: 0.6272 - val_accuracy: 0.6427\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5897 - accuracy: 0.6865 - val_loss: 0.6256 - val_accuracy: 0.6446\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5877 - accuracy: 0.6903 - val_loss: 0.6241 - val_accuracy: 0.6467\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5880 - accuracy: 0.6915 - val_loss: 0.6260 - val_accuracy: 0.6455\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5856 - accuracy: 0.6937 - val_loss: 0.6191 - val_accuracy: 0.6511\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5836 - accuracy: 0.6958 - val_loss: 0.6193 - val_accuracy: 0.6499\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5826 - accuracy: 0.6970 - val_loss: 0.6183 - val_accuracy: 0.6500\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5811 - accuracy: 0.6994 - val_loss: 0.6193 - val_accuracy: 0.6487\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.5799 - accuracy: 0.6982 - val_loss: 0.6203 - val_accuracy: 0.6471\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5781 - accuracy: 0.7010 - val_loss: 0.6190 - val_accuracy: 0.6477\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5770 - accuracy: 0.7009 - val_loss: 0.6146 - val_accuracy: 0.6500\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.5755 - accuracy: 0.7030 - val_loss: 0.6113 - val_accuracy: 0.6537\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5742 - accuracy: 0.7047 - val_loss: 0.6132 - val_accuracy: 0.6518\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5726 - accuracy: 0.7055 - val_loss: 0.6062 - val_accuracy: 0.6605\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5720 - accuracy: 0.7059 - val_loss: 0.6139 - val_accuracy: 0.6510\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5705 - accuracy: 0.7062 - val_loss: 0.6143 - val_accuracy: 0.6501\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.5693 - accuracy: 0.7080 - val_loss: 0.6193 - val_accuracy: 0.6420\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5674 - accuracy: 0.7112 - val_loss: 0.6188 - val_accuracy: 0.6425\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.7007 - accuracy: 0.5073 - val_loss: 0.7305 - val_accuracy: 0.1769\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6940 - accuracy: 0.5186 - val_loss: 0.7238 - val_accuracy: 0.3138\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6877 - accuracy: 0.5399 - val_loss: 0.7148 - val_accuracy: 0.4259\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6822 - accuracy: 0.5552 - val_loss: 0.7148 - val_accuracy: 0.4472\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6782 - accuracy: 0.5705 - val_loss: 0.7077 - val_accuracy: 0.5014\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6753 - accuracy: 0.5772 - val_loss: 0.7038 - val_accuracy: 0.5206\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6709 - accuracy: 0.5920 - val_loss: 0.6979 - val_accuracy: 0.5463\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.6674 - accuracy: 0.5994 - val_loss: 0.6953 - val_accuracy: 0.5527\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6642 - accuracy: 0.6102 - val_loss: 0.6945 - val_accuracy: 0.5558\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6623 - accuracy: 0.6107 - val_loss: 0.6927 - val_accuracy: 0.5602\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6594 - accuracy: 0.6183 - val_loss: 0.6872 - val_accuracy: 0.5758\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6564 - accuracy: 0.6248 - val_loss: 0.6852 - val_accuracy: 0.5792\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6540 - accuracy: 0.6302 - val_loss: 0.6814 - val_accuracy: 0.5858\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6510 - accuracy: 0.6343 - val_loss: 0.6796 - val_accuracy: 0.5894\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6481 - accuracy: 0.6401 - val_loss: 0.6793 - val_accuracy: 0.5901\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6447 - accuracy: 0.6440 - val_loss: 0.6749 - val_accuracy: 0.5991\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6429 - accuracy: 0.6472 - val_loss: 0.6692 - val_accuracy: 0.6100\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6408 - accuracy: 0.6488 - val_loss: 0.6700 - val_accuracy: 0.6089\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6385 - accuracy: 0.6532 - val_loss: 0.6692 - val_accuracy: 0.6088\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6360 - accuracy: 0.6550 - val_loss: 0.6654 - val_accuracy: 0.6154\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6343 - accuracy: 0.6568 - val_loss: 0.6632 - val_accuracy: 0.6194\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6319 - accuracy: 0.6590 - val_loss: 0.6601 - val_accuracy: 0.6234\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6298 - accuracy: 0.6613 - val_loss: 0.6587 - val_accuracy: 0.6241\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6275 - accuracy: 0.6634 - val_loss: 0.6544 - val_accuracy: 0.6284\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6264 - accuracy: 0.6654 - val_loss: 0.6557 - val_accuracy: 0.6267\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6241 - accuracy: 0.6682 - val_loss: 0.6511 - val_accuracy: 0.6316\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6224 - accuracy: 0.6682 - val_loss: 0.6507 - val_accuracy: 0.6312\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6205 - accuracy: 0.6717 - val_loss: 0.6496 - val_accuracy: 0.6324\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6193 - accuracy: 0.6706 - val_loss: 0.6512 - val_accuracy: 0.6300\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6181 - accuracy: 0.6700 - val_loss: 0.6525 - val_accuracy: 0.6269\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6157 - accuracy: 0.6754 - val_loss: 0.6432 - val_accuracy: 0.6443\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6140 - accuracy: 0.6750 - val_loss: 0.6469 - val_accuracy: 0.6377\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6128 - accuracy: 0.6754 - val_loss: 0.6426 - val_accuracy: 0.6443\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6108 - accuracy: 0.6773 - val_loss: 0.6439 - val_accuracy: 0.6415\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6098 - accuracy: 0.6802 - val_loss: 0.6417 - val_accuracy: 0.6435\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6077 - accuracy: 0.6793 - val_loss: 0.6445 - val_accuracy: 0.6393\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6069 - accuracy: 0.6795 - val_loss: 0.6402 - val_accuracy: 0.6430\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6043 - accuracy: 0.6832 - val_loss: 0.6345 - val_accuracy: 0.6487\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6037 - accuracy: 0.6827 - val_loss: 0.6365 - val_accuracy: 0.6464\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6022 - accuracy: 0.6851 - val_loss: 0.6374 - val_accuracy: 0.6439\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6008 - accuracy: 0.6861 - val_loss: 0.6324 - val_accuracy: 0.6470\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5994 - accuracy: 0.6867 - val_loss: 0.6374 - val_accuracy: 0.6431\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.5980 - accuracy: 0.6889 - val_loss: 0.6372 - val_accuracy: 0.6414\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5970 - accuracy: 0.6895 - val_loss: 0.6355 - val_accuracy: 0.6416\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5953 - accuracy: 0.6899 - val_loss: 0.6388 - val_accuracy: 0.6382\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5939 - accuracy: 0.6911 - val_loss: 0.6320 - val_accuracy: 0.6417\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5930 - accuracy: 0.6905 - val_loss: 0.6292 - val_accuracy: 0.6435\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5920 - accuracy: 0.6922 - val_loss: 0.6297 - val_accuracy: 0.6427\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.5900 - accuracy: 0.6935 - val_loss: 0.6317 - val_accuracy: 0.6397\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.5893 - accuracy: 0.6934 - val_loss: 0.6293 - val_accuracy: 0.6408\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.6994 - accuracy: 0.5156 - val_loss: 0.6938 - val_accuracy: 0.5114\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6862 - accuracy: 0.5452 - val_loss: 0.6999 - val_accuracy: 0.4968\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6795 - accuracy: 0.5630 - val_loss: 0.6876 - val_accuracy: 0.5499\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6743 - accuracy: 0.5778 - val_loss: 0.6841 - val_accuracy: 0.5577\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6678 - accuracy: 0.5924 - val_loss: 0.6782 - val_accuracy: 0.5789\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6651 - accuracy: 0.5970 - val_loss: 0.6779 - val_accuracy: 0.5750\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6614 - accuracy: 0.6066 - val_loss: 0.6713 - val_accuracy: 0.5886\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6568 - accuracy: 0.6114 - val_loss: 0.6667 - val_accuracy: 0.5985\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6526 - accuracy: 0.6223 - val_loss: 0.6652 - val_accuracy: 0.5958\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6484 - accuracy: 0.6264 - val_loss: 0.6587 - val_accuracy: 0.6111\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6431 - accuracy: 0.6331 - val_loss: 0.6484 - val_accuracy: 0.6314\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6393 - accuracy: 0.6374 - val_loss: 0.6451 - val_accuracy: 0.6356\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6353 - accuracy: 0.6467 - val_loss: 0.6396 - val_accuracy: 0.6435\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6330 - accuracy: 0.6474 - val_loss: 0.6428 - val_accuracy: 0.6345\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6297 - accuracy: 0.6540 - val_loss: 0.6414 - val_accuracy: 0.6343\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6279 - accuracy: 0.6518 - val_loss: 0.6365 - val_accuracy: 0.6399\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6238 - accuracy: 0.6563 - val_loss: 0.6351 - val_accuracy: 0.6419\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6223 - accuracy: 0.6614 - val_loss: 0.6389 - val_accuracy: 0.6343\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6198 - accuracy: 0.6601 - val_loss: 0.6363 - val_accuracy: 0.6376\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6174 - accuracy: 0.6634 - val_loss: 0.6316 - val_accuracy: 0.6458\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6155 - accuracy: 0.6685 - val_loss: 0.6284 - val_accuracy: 0.6506\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6148 - accuracy: 0.6693 - val_loss: 0.6294 - val_accuracy: 0.6474\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6111 - accuracy: 0.6728 - val_loss: 0.6254 - val_accuracy: 0.6529\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6100 - accuracy: 0.6740 - val_loss: 0.6242 - val_accuracy: 0.6535\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6073 - accuracy: 0.6753 - val_loss: 0.6234 - val_accuracy: 0.6529\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6056 - accuracy: 0.6763 - val_loss: 0.6191 - val_accuracy: 0.6582\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6034 - accuracy: 0.6792 - val_loss: 0.6205 - val_accuracy: 0.6544\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6015 - accuracy: 0.6818 - val_loss: 0.6173 - val_accuracy: 0.6574\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5998 - accuracy: 0.6839 - val_loss: 0.6143 - val_accuracy: 0.6592\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5983 - accuracy: 0.6861 - val_loss: 0.6144 - val_accuracy: 0.6580\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5966 - accuracy: 0.6869 - val_loss: 0.6166 - val_accuracy: 0.6538\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5945 - accuracy: 0.6891 - val_loss: 0.6120 - val_accuracy: 0.6597\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.5937 - accuracy: 0.6911 - val_loss: 0.6091 - val_accuracy: 0.6627\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.5914 - accuracy: 0.6955 - val_loss: 0.6140 - val_accuracy: 0.6541\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5907 - accuracy: 0.6962 - val_loss: 0.6109 - val_accuracy: 0.6575\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5878 - accuracy: 0.6985 - val_loss: 0.6087 - val_accuracy: 0.6582\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.5876 - accuracy: 0.6994 - val_loss: 0.6061 - val_accuracy: 0.6606\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.5861 - accuracy: 0.7008 - val_loss: 0.6116 - val_accuracy: 0.6532\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5849 - accuracy: 0.7026 - val_loss: 0.6055 - val_accuracy: 0.6586\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5835 - accuracy: 0.7037 - val_loss: 0.6033 - val_accuracy: 0.6598\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.5811 - accuracy: 0.7065 - val_loss: 0.6073 - val_accuracy: 0.6561\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.5801 - accuracy: 0.7059 - val_loss: 0.6086 - val_accuracy: 0.6544\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.5787 - accuracy: 0.7074 - val_loss: 0.6040 - val_accuracy: 0.6577\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.5774 - accuracy: 0.7089 - val_loss: 0.6065 - val_accuracy: 0.6552\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.5759 - accuracy: 0.7086 - val_loss: 0.6006 - val_accuracy: 0.6601\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5757 - accuracy: 0.7098 - val_loss: 0.6061 - val_accuracy: 0.6521\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5730 - accuracy: 0.7131 - val_loss: 0.6050 - val_accuracy: 0.6531\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5724 - accuracy: 0.7130 - val_loss: 0.6014 - val_accuracy: 0.6571\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5714 - accuracy: 0.7145 - val_loss: 0.6019 - val_accuracy: 0.6556\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.5710 - accuracy: 0.7132 - val_loss: 0.6013 - val_accuracy: 0.6555\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 940us/step - loss: 0.7469 - accuracy: 0.5040 - val_loss: 0.7591 - val_accuracy: 0.1989\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.7132 - accuracy: 0.4987 - val_loss: 0.7377 - val_accuracy: 0.2595\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.7058 - accuracy: 0.5093 - val_loss: 0.7228 - val_accuracy: 0.3490\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6985 - accuracy: 0.5226 - val_loss: 0.7181 - val_accuracy: 0.3963\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6944 - accuracy: 0.5338 - val_loss: 0.7154 - val_accuracy: 0.4235\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6859 - accuracy: 0.5531 - val_loss: 0.7070 - val_accuracy: 0.4720\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6811 - accuracy: 0.5666 - val_loss: 0.7082 - val_accuracy: 0.4788\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6766 - accuracy: 0.5749 - val_loss: 0.6995 - val_accuracy: 0.5191\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6723 - accuracy: 0.5824 - val_loss: 0.6973 - val_accuracy: 0.5300\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6681 - accuracy: 0.5935 - val_loss: 0.6895 - val_accuracy: 0.5538\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6647 - accuracy: 0.6026 - val_loss: 0.6903 - val_accuracy: 0.5500\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6616 - accuracy: 0.6084 - val_loss: 0.6878 - val_accuracy: 0.5570\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.6564 - accuracy: 0.6177 - val_loss: 0.6843 - val_accuracy: 0.5691\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6541 - accuracy: 0.6229 - val_loss: 0.6818 - val_accuracy: 0.5792\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6511 - accuracy: 0.6280 - val_loss: 0.6771 - val_accuracy: 0.5928\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6474 - accuracy: 0.6348 - val_loss: 0.6732 - val_accuracy: 0.6035\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6458 - accuracy: 0.6378 - val_loss: 0.6692 - val_accuracy: 0.6154\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6424 - accuracy: 0.6424 - val_loss: 0.6713 - val_accuracy: 0.6075\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6394 - accuracy: 0.6476 - val_loss: 0.6652 - val_accuracy: 0.6245\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6380 - accuracy: 0.6485 - val_loss: 0.6665 - val_accuracy: 0.6182\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6351 - accuracy: 0.6518 - val_loss: 0.6630 - val_accuracy: 0.6239\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6328 - accuracy: 0.6541 - val_loss: 0.6603 - val_accuracy: 0.6288\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6297 - accuracy: 0.6574 - val_loss: 0.6597 - val_accuracy: 0.6281\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.6276 - accuracy: 0.6598 - val_loss: 0.6619 - val_accuracy: 0.6228\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 867us/step - loss: 0.6263 - accuracy: 0.6621 - val_loss: 0.6539 - val_accuracy: 0.6362\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6229 - accuracy: 0.6651 - val_loss: 0.6527 - val_accuracy: 0.6367\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6210 - accuracy: 0.6674 - val_loss: 0.6501 - val_accuracy: 0.6384\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.6183 - accuracy: 0.6712 - val_loss: 0.6493 - val_accuracy: 0.6378\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6172 - accuracy: 0.6693 - val_loss: 0.6489 - val_accuracy: 0.6381\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.6141 - accuracy: 0.6721 - val_loss: 0.6546 - val_accuracy: 0.6263\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.6120 - accuracy: 0.6740 - val_loss: 0.6476 - val_accuracy: 0.6378\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6102 - accuracy: 0.6764 - val_loss: 0.6468 - val_accuracy: 0.6370\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.6071 - accuracy: 0.6789 - val_loss: 0.6394 - val_accuracy: 0.6471\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.6048 - accuracy: 0.6817 - val_loss: 0.6354 - val_accuracy: 0.6516\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.6033 - accuracy: 0.6821 - val_loss: 0.6423 - val_accuracy: 0.6385\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6015 - accuracy: 0.6830 - val_loss: 0.6381 - val_accuracy: 0.6430\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.5996 - accuracy: 0.6852 - val_loss: 0.6319 - val_accuracy: 0.6508\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5972 - accuracy: 0.6866 - val_loss: 0.6459 - val_accuracy: 0.6301\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5968 - accuracy: 0.6859 - val_loss: 0.6298 - val_accuracy: 0.6506\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5938 - accuracy: 0.6896 - val_loss: 0.6283 - val_accuracy: 0.6514\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5929 - accuracy: 0.6904 - val_loss: 0.6311 - val_accuracy: 0.6454\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5918 - accuracy: 0.6888 - val_loss: 0.6338 - val_accuracy: 0.6409\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.5901 - accuracy: 0.6913 - val_loss: 0.6352 - val_accuracy: 0.6380\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5881 - accuracy: 0.6939 - val_loss: 0.6277 - val_accuracy: 0.6485\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5869 - accuracy: 0.6959 - val_loss: 0.6265 - val_accuracy: 0.6495\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5857 - accuracy: 0.6957 - val_loss: 0.6243 - val_accuracy: 0.6514\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5836 - accuracy: 0.6985 - val_loss: 0.6269 - val_accuracy: 0.6468\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5821 - accuracy: 0.6984 - val_loss: 0.6275 - val_accuracy: 0.6447\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5803 - accuracy: 0.6998 - val_loss: 0.6317 - val_accuracy: 0.6371\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5791 - accuracy: 0.7013 - val_loss: 0.6188 - val_accuracy: 0.6559\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.7056 - accuracy: 0.5174 - val_loss: 0.7254 - val_accuracy: 0.3599\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6955 - accuracy: 0.5391 - val_loss: 0.7121 - val_accuracy: 0.4351\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6888 - accuracy: 0.5540 - val_loss: 0.7059 - val_accuracy: 0.4682\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6846 - accuracy: 0.5651 - val_loss: 0.7025 - val_accuracy: 0.4829\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.6805 - accuracy: 0.5753 - val_loss: 0.6965 - val_accuracy: 0.5144\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.6758 - accuracy: 0.5857 - val_loss: 0.6948 - val_accuracy: 0.5241\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6731 - accuracy: 0.5913 - val_loss: 0.6921 - val_accuracy: 0.5336\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6684 - accuracy: 0.6021 - val_loss: 0.6846 - val_accuracy: 0.5591\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6649 - accuracy: 0.6113 - val_loss: 0.6809 - val_accuracy: 0.5714\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6612 - accuracy: 0.6188 - val_loss: 0.6790 - val_accuracy: 0.5760\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6587 - accuracy: 0.6234 - val_loss: 0.6762 - val_accuracy: 0.5826\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6558 - accuracy: 0.6272 - val_loss: 0.6757 - val_accuracy: 0.5860\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6524 - accuracy: 0.6337 - val_loss: 0.6756 - val_accuracy: 0.5863\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6482 - accuracy: 0.6393 - val_loss: 0.6725 - val_accuracy: 0.5906\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6445 - accuracy: 0.6443 - val_loss: 0.6644 - val_accuracy: 0.6027\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6414 - accuracy: 0.6497 - val_loss: 0.6646 - val_accuracy: 0.6026\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6383 - accuracy: 0.6520 - val_loss: 0.6616 - val_accuracy: 0.6051\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6357 - accuracy: 0.6570 - val_loss: 0.6584 - val_accuracy: 0.6063\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6325 - accuracy: 0.6584 - val_loss: 0.6556 - val_accuracy: 0.6072\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.6305 - accuracy: 0.6612 - val_loss: 0.6553 - val_accuracy: 0.6058\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6274 - accuracy: 0.6629 - val_loss: 0.6492 - val_accuracy: 0.6116\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6252 - accuracy: 0.6687 - val_loss: 0.6509 - val_accuracy: 0.6073\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6231 - accuracy: 0.6695 - val_loss: 0.6440 - val_accuracy: 0.6175\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6206 - accuracy: 0.6726 - val_loss: 0.6444 - val_accuracy: 0.6143\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6190 - accuracy: 0.6737 - val_loss: 0.6453 - val_accuracy: 0.6119\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6168 - accuracy: 0.6759 - val_loss: 0.6426 - val_accuracy: 0.6155\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.6148 - accuracy: 0.6782 - val_loss: 0.6381 - val_accuracy: 0.6218\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6121 - accuracy: 0.6790 - val_loss: 0.6339 - val_accuracy: 0.6283\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6098 - accuracy: 0.6819 - val_loss: 0.6330 - val_accuracy: 0.6298\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6084 - accuracy: 0.6828 - val_loss: 0.6341 - val_accuracy: 0.6288\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6062 - accuracy: 0.6852 - val_loss: 0.6345 - val_accuracy: 0.6273\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6035 - accuracy: 0.6894 - val_loss: 0.6339 - val_accuracy: 0.6290\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6014 - accuracy: 0.6913 - val_loss: 0.6351 - val_accuracy: 0.6267\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6009 - accuracy: 0.6908 - val_loss: 0.6337 - val_accuracy: 0.6276\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5987 - accuracy: 0.6938 - val_loss: 0.6279 - val_accuracy: 0.6355\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5975 - accuracy: 0.6912 - val_loss: 0.6282 - val_accuracy: 0.6355\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5946 - accuracy: 0.6959 - val_loss: 0.6239 - val_accuracy: 0.6419\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5941 - accuracy: 0.6958 - val_loss: 0.6292 - val_accuracy: 0.6334\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5919 - accuracy: 0.6983 - val_loss: 0.6244 - val_accuracy: 0.6405\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5894 - accuracy: 0.7013 - val_loss: 0.6178 - val_accuracy: 0.6492\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5880 - accuracy: 0.7005 - val_loss: 0.6205 - val_accuracy: 0.6472\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5867 - accuracy: 0.7022 - val_loss: 0.6213 - val_accuracy: 0.6454\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5850 - accuracy: 0.7037 - val_loss: 0.6195 - val_accuracy: 0.6491\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5839 - accuracy: 0.7029 - val_loss: 0.6296 - val_accuracy: 0.6328\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5818 - accuracy: 0.7047 - val_loss: 0.6145 - val_accuracy: 0.6573\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5797 - accuracy: 0.7076 - val_loss: 0.6166 - val_accuracy: 0.6541\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5787 - accuracy: 0.7087 - val_loss: 0.6127 - val_accuracy: 0.6589\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.5775 - accuracy: 0.7097 - val_loss: 0.6062 - val_accuracy: 0.6671\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5761 - accuracy: 0.7110 - val_loss: 0.6162 - val_accuracy: 0.6533\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.5733 - accuracy: 0.7127 - val_loss: 0.6108 - val_accuracy: 0.6607\n",
      "\n",
      "Entrenando modelo con l2_norm_clip=2.0...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.7268 - accuracy: 0.5332 - val_loss: 0.7746 - val_accuracy: 0.1637\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6758 - accuracy: 0.5604 - val_loss: 0.7074 - val_accuracy: 0.4595\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6685 - accuracy: 0.5802 - val_loss: 0.6953 - val_accuracy: 0.5288\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6634 - accuracy: 0.5949 - val_loss: 0.6881 - val_accuracy: 0.5571\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6596 - accuracy: 0.6012 - val_loss: 0.6862 - val_accuracy: 0.5611\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6554 - accuracy: 0.6124 - val_loss: 0.6797 - val_accuracy: 0.5783\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6500 - accuracy: 0.6243 - val_loss: 0.6734 - val_accuracy: 0.5946\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6465 - accuracy: 0.6277 - val_loss: 0.6698 - val_accuracy: 0.6010\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6438 - accuracy: 0.6343 - val_loss: 0.6665 - val_accuracy: 0.6105\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6397 - accuracy: 0.6385 - val_loss: 0.6660 - val_accuracy: 0.6104\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6370 - accuracy: 0.6436 - val_loss: 0.6626 - val_accuracy: 0.6157\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6334 - accuracy: 0.6488 - val_loss: 0.6569 - val_accuracy: 0.6251\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6306 - accuracy: 0.6511 - val_loss: 0.6583 - val_accuracy: 0.6205\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6266 - accuracy: 0.6552 - val_loss: 0.6544 - val_accuracy: 0.6258\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6245 - accuracy: 0.6568 - val_loss: 0.6496 - val_accuracy: 0.6331\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6212 - accuracy: 0.6603 - val_loss: 0.6448 - val_accuracy: 0.6428\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6183 - accuracy: 0.6635 - val_loss: 0.6453 - val_accuracy: 0.6378\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6156 - accuracy: 0.6638 - val_loss: 0.6411 - val_accuracy: 0.6454\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6137 - accuracy: 0.6669 - val_loss: 0.6461 - val_accuracy: 0.6330\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6108 - accuracy: 0.6675 - val_loss: 0.6364 - val_accuracy: 0.6502\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6088 - accuracy: 0.6691 - val_loss: 0.6356 - val_accuracy: 0.6487\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6070 - accuracy: 0.6715 - val_loss: 0.6355 - val_accuracy: 0.6467\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6044 - accuracy: 0.6754 - val_loss: 0.6364 - val_accuracy: 0.6441\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6017 - accuracy: 0.6765 - val_loss: 0.6336 - val_accuracy: 0.6491\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6014 - accuracy: 0.6775 - val_loss: 0.6275 - val_accuracy: 0.6569\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5987 - accuracy: 0.6792 - val_loss: 0.6251 - val_accuracy: 0.6594\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5971 - accuracy: 0.6795 - val_loss: 0.6284 - val_accuracy: 0.6545\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5947 - accuracy: 0.6813 - val_loss: 0.6233 - val_accuracy: 0.6605\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5926 - accuracy: 0.6857 - val_loss: 0.6299 - val_accuracy: 0.6516\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5914 - accuracy: 0.6847 - val_loss: 0.6262 - val_accuracy: 0.6563\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5895 - accuracy: 0.6877 - val_loss: 0.6215 - val_accuracy: 0.6619\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.5884 - accuracy: 0.6896 - val_loss: 0.6241 - val_accuracy: 0.6571\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5867 - accuracy: 0.6888 - val_loss: 0.6256 - val_accuracy: 0.6550\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5857 - accuracy: 0.6913 - val_loss: 0.6246 - val_accuracy: 0.6545\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5837 - accuracy: 0.6930 - val_loss: 0.6171 - val_accuracy: 0.6631\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5831 - accuracy: 0.6936 - val_loss: 0.6259 - val_accuracy: 0.6508\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5817 - accuracy: 0.6935 - val_loss: 0.6160 - val_accuracy: 0.6626\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5800 - accuracy: 0.6974 - val_loss: 0.6228 - val_accuracy: 0.6543\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5785 - accuracy: 0.6966 - val_loss: 0.6151 - val_accuracy: 0.6633\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5773 - accuracy: 0.6996 - val_loss: 0.6141 - val_accuracy: 0.6640\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5750 - accuracy: 0.7006 - val_loss: 0.6241 - val_accuracy: 0.6534\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.5755 - accuracy: 0.7006 - val_loss: 0.6145 - val_accuracy: 0.6640\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.5740 - accuracy: 0.7009 - val_loss: 0.6093 - val_accuracy: 0.6673\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.5722 - accuracy: 0.7023 - val_loss: 0.6110 - val_accuracy: 0.6657\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5711 - accuracy: 0.7048 - val_loss: 0.6176 - val_accuracy: 0.6590\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.5705 - accuracy: 0.7056 - val_loss: 0.6129 - val_accuracy: 0.6635\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5689 - accuracy: 0.7060 - val_loss: 0.6157 - val_accuracy: 0.6602\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.5681 - accuracy: 0.7080 - val_loss: 0.6136 - val_accuracy: 0.6626\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5668 - accuracy: 0.7099 - val_loss: 0.6146 - val_accuracy: 0.6612\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5660 - accuracy: 0.7080 - val_loss: 0.6116 - val_accuracy: 0.6634\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.8621 - accuracy: 0.4062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.7265 - accuracy: 0.4977 - val_loss: 0.6820 - val_accuracy: 0.6388\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6983 - accuracy: 0.5262 - val_loss: 0.7024 - val_accuracy: 0.4629\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6932 - accuracy: 0.5389 - val_loss: 0.6937 - val_accuracy: 0.5176\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6878 - accuracy: 0.5525 - val_loss: 0.6943 - val_accuracy: 0.5174\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6829 - accuracy: 0.5638 - val_loss: 0.6919 - val_accuracy: 0.5287\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6783 - accuracy: 0.5734 - val_loss: 0.6866 - val_accuracy: 0.5508\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6757 - accuracy: 0.5819 - val_loss: 0.6835 - val_accuracy: 0.5607\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6705 - accuracy: 0.5946 - val_loss: 0.6809 - val_accuracy: 0.5665\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6687 - accuracy: 0.5977 - val_loss: 0.6794 - val_accuracy: 0.5676\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6639 - accuracy: 0.6087 - val_loss: 0.6764 - val_accuracy: 0.5723\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6612 - accuracy: 0.6146 - val_loss: 0.6737 - val_accuracy: 0.5748\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6583 - accuracy: 0.6203 - val_loss: 0.6672 - val_accuracy: 0.5837\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6537 - accuracy: 0.6285 - val_loss: 0.6594 - val_accuracy: 0.5974\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6500 - accuracy: 0.6338 - val_loss: 0.6605 - val_accuracy: 0.5918\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6473 - accuracy: 0.6394 - val_loss: 0.6591 - val_accuracy: 0.5935\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6430 - accuracy: 0.6456 - val_loss: 0.6518 - val_accuracy: 0.6058\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6399 - accuracy: 0.6519 - val_loss: 0.6515 - val_accuracy: 0.6046\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6369 - accuracy: 0.6521 - val_loss: 0.6491 - val_accuracy: 0.6074\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6341 - accuracy: 0.6573 - val_loss: 0.6415 - val_accuracy: 0.6203\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6315 - accuracy: 0.6592 - val_loss: 0.6408 - val_accuracy: 0.6211\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6287 - accuracy: 0.6622 - val_loss: 0.6350 - val_accuracy: 0.6321\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 856us/step - loss: 0.6258 - accuracy: 0.6657 - val_loss: 0.6360 - val_accuracy: 0.6273\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 793us/step - loss: 0.6222 - accuracy: 0.6707 - val_loss: 0.6351 - val_accuracy: 0.6271\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 796us/step - loss: 0.6209 - accuracy: 0.6704 - val_loss: 0.6319 - val_accuracy: 0.6305\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.6185 - accuracy: 0.6735 - val_loss: 0.6312 - val_accuracy: 0.6303\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.6162 - accuracy: 0.6766 - val_loss: 0.6326 - val_accuracy: 0.6259\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.6138 - accuracy: 0.6797 - val_loss: 0.6266 - val_accuracy: 0.6346\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6115 - accuracy: 0.6805 - val_loss: 0.6240 - val_accuracy: 0.6363\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6096 - accuracy: 0.6827 - val_loss: 0.6268 - val_accuracy: 0.6293\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6076 - accuracy: 0.6837 - val_loss: 0.6263 - val_accuracy: 0.6289\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6067 - accuracy: 0.6819 - val_loss: 0.6213 - val_accuracy: 0.6356\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.6041 - accuracy: 0.6853 - val_loss: 0.6217 - val_accuracy: 0.6340\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6023 - accuracy: 0.6864 - val_loss: 0.6230 - val_accuracy: 0.6294\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6010 - accuracy: 0.6877 - val_loss: 0.6183 - val_accuracy: 0.6331\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.5983 - accuracy: 0.6909 - val_loss: 0.6157 - val_accuracy: 0.6343\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.5970 - accuracy: 0.6923 - val_loss: 0.6198 - val_accuracy: 0.6274\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.5948 - accuracy: 0.6955 - val_loss: 0.6146 - val_accuracy: 0.6337\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.5942 - accuracy: 0.6936 - val_loss: 0.6107 - val_accuracy: 0.6375\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.5920 - accuracy: 0.6979 - val_loss: 0.6098 - val_accuracy: 0.6381\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.5911 - accuracy: 0.6961 - val_loss: 0.6136 - val_accuracy: 0.6323\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.5900 - accuracy: 0.6983 - val_loss: 0.6113 - val_accuracy: 0.6340\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.5882 - accuracy: 0.7016 - val_loss: 0.6152 - val_accuracy: 0.6288\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.5866 - accuracy: 0.7021 - val_loss: 0.6091 - val_accuracy: 0.6361\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5846 - accuracy: 0.7026 - val_loss: 0.6067 - val_accuracy: 0.6370\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5831 - accuracy: 0.7023 - val_loss: 0.6150 - val_accuracy: 0.6267\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5819 - accuracy: 0.7042 - val_loss: 0.6049 - val_accuracy: 0.6378\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.5812 - accuracy: 0.7048 - val_loss: 0.6001 - val_accuracy: 0.6439\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.5786 - accuracy: 0.7065 - val_loss: 0.6059 - val_accuracy: 0.6343\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.5771 - accuracy: 0.7078 - val_loss: 0.6091 - val_accuracy: 0.6302\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5783 - accuracy: 0.7058 - val_loss: 0.6065 - val_accuracy: 0.6329\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.7349 - accuracy: 0.4062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1650/1672 [============================>.] - ETA: 0s - loss: 0.7067 - accuracy: 0.5002WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.7066 - accuracy: 0.5005 - val_loss: 0.7196 - val_accuracy: 0.3366\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.6997 - accuracy: 0.5180 - val_loss: 0.7178 - val_accuracy: 0.3440\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.6969 - accuracy: 0.5263 - val_loss: 0.7111 - val_accuracy: 0.3813\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.6907 - accuracy: 0.5379 - val_loss: 0.7062 - val_accuracy: 0.4426\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6853 - accuracy: 0.5525 - val_loss: 0.7009 - val_accuracy: 0.4716\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 781us/step - loss: 0.6819 - accuracy: 0.5643 - val_loss: 0.6983 - val_accuracy: 0.4829\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6772 - accuracy: 0.5763 - val_loss: 0.6974 - val_accuracy: 0.4891\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.6731 - accuracy: 0.5856 - val_loss: 0.6912 - val_accuracy: 0.5302\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6696 - accuracy: 0.5924 - val_loss: 0.6906 - val_accuracy: 0.5386\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6666 - accuracy: 0.6020 - val_loss: 0.6872 - val_accuracy: 0.5504\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.6626 - accuracy: 0.6086 - val_loss: 0.6868 - val_accuracy: 0.5504\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.6591 - accuracy: 0.6195 - val_loss: 0.6816 - val_accuracy: 0.5697\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.6578 - accuracy: 0.6200 - val_loss: 0.6775 - val_accuracy: 0.5823\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.6536 - accuracy: 0.6327 - val_loss: 0.6788 - val_accuracy: 0.5725\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6503 - accuracy: 0.6372 - val_loss: 0.6718 - val_accuracy: 0.5953\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6483 - accuracy: 0.6405 - val_loss: 0.6711 - val_accuracy: 0.5938\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.6457 - accuracy: 0.6433 - val_loss: 0.6672 - val_accuracy: 0.6011\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6427 - accuracy: 0.6497 - val_loss: 0.6674 - val_accuracy: 0.5975\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6404 - accuracy: 0.6519 - val_loss: 0.6641 - val_accuracy: 0.6037\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6369 - accuracy: 0.6582 - val_loss: 0.6653 - val_accuracy: 0.5987\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.6353 - accuracy: 0.6575 - val_loss: 0.6593 - val_accuracy: 0.6107\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6324 - accuracy: 0.6641 - val_loss: 0.6585 - val_accuracy: 0.6110\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6300 - accuracy: 0.6674 - val_loss: 0.6539 - val_accuracy: 0.6166\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.6270 - accuracy: 0.6686 - val_loss: 0.6528 - val_accuracy: 0.6180\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 753us/step - loss: 0.6249 - accuracy: 0.6724 - val_loss: 0.6534 - val_accuracy: 0.6168\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6228 - accuracy: 0.6743 - val_loss: 0.6457 - val_accuracy: 0.6245\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6200 - accuracy: 0.6756 - val_loss: 0.6440 - val_accuracy: 0.6258\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6173 - accuracy: 0.6783 - val_loss: 0.6392 - val_accuracy: 0.6312\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6150 - accuracy: 0.6793 - val_loss: 0.6376 - val_accuracy: 0.6328\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.6130 - accuracy: 0.6823 - val_loss: 0.6399 - val_accuracy: 0.6288\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.6107 - accuracy: 0.6834 - val_loss: 0.6375 - val_accuracy: 0.6305\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6089 - accuracy: 0.6846 - val_loss: 0.6364 - val_accuracy: 0.6309\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6066 - accuracy: 0.6862 - val_loss: 0.6328 - val_accuracy: 0.6331\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.6049 - accuracy: 0.6864 - val_loss: 0.6305 - val_accuracy: 0.6342\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.6022 - accuracy: 0.6884 - val_loss: 0.6393 - val_accuracy: 0.6261\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.6003 - accuracy: 0.6917 - val_loss: 0.6273 - val_accuracy: 0.6376\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5979 - accuracy: 0.6926 - val_loss: 0.6309 - val_accuracy: 0.6330\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5958 - accuracy: 0.6928 - val_loss: 0.6252 - val_accuracy: 0.6408\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.5941 - accuracy: 0.6942 - val_loss: 0.6253 - val_accuracy: 0.6394\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.5931 - accuracy: 0.6945 - val_loss: 0.6204 - val_accuracy: 0.6453\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.5910 - accuracy: 0.6980 - val_loss: 0.6260 - val_accuracy: 0.6355\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.5887 - accuracy: 0.6981 - val_loss: 0.6214 - val_accuracy: 0.6426\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5878 - accuracy: 0.6992 - val_loss: 0.6201 - val_accuracy: 0.6431\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.5844 - accuracy: 0.7013 - val_loss: 0.6130 - val_accuracy: 0.6483\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5828 - accuracy: 0.7042 - val_loss: 0.6157 - val_accuracy: 0.6464\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.5816 - accuracy: 0.7042 - val_loss: 0.6249 - val_accuracy: 0.6375\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.5799 - accuracy: 0.7059 - val_loss: 0.6215 - val_accuracy: 0.6405\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.5781 - accuracy: 0.7084 - val_loss: 0.6183 - val_accuracy: 0.6422\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.5765 - accuracy: 0.7067 - val_loss: 0.6166 - val_accuracy: 0.6427\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.5744 - accuracy: 0.7097 - val_loss: 0.6125 - val_accuracy: 0.6445\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.7279 - accuracy: 0.4582 - val_loss: 0.7237 - val_accuracy: 0.2546\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.7126 - accuracy: 0.4836 - val_loss: 0.7304 - val_accuracy: 0.2099\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.7055 - accuracy: 0.5024 - val_loss: 0.7274 - val_accuracy: 0.2375\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6977 - accuracy: 0.5225 - val_loss: 0.7232 - val_accuracy: 0.2862\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6923 - accuracy: 0.5383 - val_loss: 0.7165 - val_accuracy: 0.3500\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6877 - accuracy: 0.5538 - val_loss: 0.7106 - val_accuracy: 0.4110\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6821 - accuracy: 0.5673 - val_loss: 0.7052 - val_accuracy: 0.4549\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6783 - accuracy: 0.5780 - val_loss: 0.7021 - val_accuracy: 0.4763\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6729 - accuracy: 0.5926 - val_loss: 0.6986 - val_accuracy: 0.4997\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6703 - accuracy: 0.5994 - val_loss: 0.6934 - val_accuracy: 0.5235\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6667 - accuracy: 0.6079 - val_loss: 0.6904 - val_accuracy: 0.5370\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6624 - accuracy: 0.6189 - val_loss: 0.6914 - val_accuracy: 0.5370\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6598 - accuracy: 0.6246 - val_loss: 0.6866 - val_accuracy: 0.5517\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6571 - accuracy: 0.6278 - val_loss: 0.6833 - val_accuracy: 0.5599\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6540 - accuracy: 0.6366 - val_loss: 0.6788 - val_accuracy: 0.5696\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6503 - accuracy: 0.6423 - val_loss: 0.6797 - val_accuracy: 0.5664\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6473 - accuracy: 0.6467 - val_loss: 0.6768 - val_accuracy: 0.5724\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6459 - accuracy: 0.6500 - val_loss: 0.6727 - val_accuracy: 0.5822\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6424 - accuracy: 0.6565 - val_loss: 0.6721 - val_accuracy: 0.5816\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6396 - accuracy: 0.6600 - val_loss: 0.6702 - val_accuracy: 0.5838\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6366 - accuracy: 0.6620 - val_loss: 0.6645 - val_accuracy: 0.5941\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6341 - accuracy: 0.6631 - val_loss: 0.6659 - val_accuracy: 0.5891\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6327 - accuracy: 0.6673 - val_loss: 0.6608 - val_accuracy: 0.5985\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6299 - accuracy: 0.6680 - val_loss: 0.6582 - val_accuracy: 0.6021\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6273 - accuracy: 0.6701 - val_loss: 0.6571 - val_accuracy: 0.6032\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6244 - accuracy: 0.6739 - val_loss: 0.6582 - val_accuracy: 0.6009\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6218 - accuracy: 0.6759 - val_loss: 0.6553 - val_accuracy: 0.6053\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6196 - accuracy: 0.6786 - val_loss: 0.6505 - val_accuracy: 0.6101\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6176 - accuracy: 0.6795 - val_loss: 0.6469 - val_accuracy: 0.6145\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6150 - accuracy: 0.6782 - val_loss: 0.6445 - val_accuracy: 0.6158\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6130 - accuracy: 0.6834 - val_loss: 0.6449 - val_accuracy: 0.6151\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6103 - accuracy: 0.6848 - val_loss: 0.6452 - val_accuracy: 0.6120\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6084 - accuracy: 0.6855 - val_loss: 0.6356 - val_accuracy: 0.6270\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6063 - accuracy: 0.6844 - val_loss: 0.6363 - val_accuracy: 0.6245\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6043 - accuracy: 0.6870 - val_loss: 0.6357 - val_accuracy: 0.6248\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6019 - accuracy: 0.6889 - val_loss: 0.6389 - val_accuracy: 0.6193\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6009 - accuracy: 0.6870 - val_loss: 0.6356 - val_accuracy: 0.6242\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5983 - accuracy: 0.6902 - val_loss: 0.6349 - val_accuracy: 0.6241\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5969 - accuracy: 0.6919 - val_loss: 0.6287 - val_accuracy: 0.6328\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5965 - accuracy: 0.6920 - val_loss: 0.6303 - val_accuracy: 0.6301\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5944 - accuracy: 0.6928 - val_loss: 0.6315 - val_accuracy: 0.6277\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5944 - accuracy: 0.6923 - val_loss: 0.6199 - val_accuracy: 0.6412\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5923 - accuracy: 0.6956 - val_loss: 0.6287 - val_accuracy: 0.6318\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5907 - accuracy: 0.6937 - val_loss: 0.6270 - val_accuracy: 0.6332\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.5890 - accuracy: 0.6971 - val_loss: 0.6272 - val_accuracy: 0.6324\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5889 - accuracy: 0.6971 - val_loss: 0.6206 - val_accuracy: 0.6381\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5871 - accuracy: 0.6945 - val_loss: 0.6262 - val_accuracy: 0.6324\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5869 - accuracy: 0.6965 - val_loss: 0.6244 - val_accuracy: 0.6341\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5842 - accuracy: 0.7015 - val_loss: 0.6217 - val_accuracy: 0.6365\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5833 - accuracy: 0.7019 - val_loss: 0.6287 - val_accuracy: 0.6278\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.7015 - accuracy: 0.5164 - val_loss: 0.7471 - val_accuracy: 0.1706\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6931 - accuracy: 0.5252 - val_loss: 0.7247 - val_accuracy: 0.2669\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6872 - accuracy: 0.5409 - val_loss: 0.7199 - val_accuracy: 0.3410\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6809 - accuracy: 0.5582 - val_loss: 0.7113 - val_accuracy: 0.4190\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6771 - accuracy: 0.5705 - val_loss: 0.7076 - val_accuracy: 0.4591\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6722 - accuracy: 0.5821 - val_loss: 0.7045 - val_accuracy: 0.4907\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6679 - accuracy: 0.5942 - val_loss: 0.6968 - val_accuracy: 0.5341\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6640 - accuracy: 0.6044 - val_loss: 0.6964 - val_accuracy: 0.5401\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6613 - accuracy: 0.6057 - val_loss: 0.6914 - val_accuracy: 0.5610\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6576 - accuracy: 0.6168 - val_loss: 0.6872 - val_accuracy: 0.5751\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6545 - accuracy: 0.6233 - val_loss: 0.6860 - val_accuracy: 0.5787\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6510 - accuracy: 0.6267 - val_loss: 0.6869 - val_accuracy: 0.5779\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6481 - accuracy: 0.6337 - val_loss: 0.6838 - val_accuracy: 0.5874\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6449 - accuracy: 0.6385 - val_loss: 0.6766 - val_accuracy: 0.6069\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 940us/step - loss: 0.6420 - accuracy: 0.6416 - val_loss: 0.6746 - val_accuracy: 0.6112\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6401 - accuracy: 0.6427 - val_loss: 0.6752 - val_accuracy: 0.6091\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 828us/step - loss: 0.6364 - accuracy: 0.6491 - val_loss: 0.6723 - val_accuracy: 0.6125\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.6340 - accuracy: 0.6496 - val_loss: 0.6664 - val_accuracy: 0.6246\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 873us/step - loss: 0.6317 - accuracy: 0.6524 - val_loss: 0.6638 - val_accuracy: 0.6287\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6299 - accuracy: 0.6511 - val_loss: 0.6650 - val_accuracy: 0.6239\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6262 - accuracy: 0.6595 - val_loss: 0.6607 - val_accuracy: 0.6304\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6239 - accuracy: 0.6630 - val_loss: 0.6597 - val_accuracy: 0.6309\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6218 - accuracy: 0.6620 - val_loss: 0.6588 - val_accuracy: 0.6324\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.6190 - accuracy: 0.6676 - val_loss: 0.6547 - val_accuracy: 0.6388\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6172 - accuracy: 0.6681 - val_loss: 0.6571 - val_accuracy: 0.6335\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6154 - accuracy: 0.6696 - val_loss: 0.6531 - val_accuracy: 0.6417\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6125 - accuracy: 0.6711 - val_loss: 0.6504 - val_accuracy: 0.6453\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6109 - accuracy: 0.6698 - val_loss: 0.6446 - val_accuracy: 0.6531\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6085 - accuracy: 0.6773 - val_loss: 0.6457 - val_accuracy: 0.6516\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6062 - accuracy: 0.6772 - val_loss: 0.6480 - val_accuracy: 0.6477\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6045 - accuracy: 0.6777 - val_loss: 0.6341 - val_accuracy: 0.6635\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6020 - accuracy: 0.6799 - val_loss: 0.6351 - val_accuracy: 0.6605\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6005 - accuracy: 0.6828 - val_loss: 0.6370 - val_accuracy: 0.6549\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5989 - accuracy: 0.6817 - val_loss: 0.6344 - val_accuracy: 0.6562\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5974 - accuracy: 0.6840 - val_loss: 0.6321 - val_accuracy: 0.6572\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5951 - accuracy: 0.6861 - val_loss: 0.6366 - val_accuracy: 0.6514\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5936 - accuracy: 0.6867 - val_loss: 0.6312 - val_accuracy: 0.6565\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5916 - accuracy: 0.6879 - val_loss: 0.6334 - val_accuracy: 0.6521\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5909 - accuracy: 0.6878 - val_loss: 0.6321 - val_accuracy: 0.6528\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5890 - accuracy: 0.6904 - val_loss: 0.6322 - val_accuracy: 0.6524\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5872 - accuracy: 0.6927 - val_loss: 0.6304 - val_accuracy: 0.6537\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5855 - accuracy: 0.6929 - val_loss: 0.6298 - val_accuracy: 0.6530\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5847 - accuracy: 0.6940 - val_loss: 0.6267 - val_accuracy: 0.6559\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5825 - accuracy: 0.6960 - val_loss: 0.6311 - val_accuracy: 0.6507\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5807 - accuracy: 0.6981 - val_loss: 0.6204 - val_accuracy: 0.6612\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5794 - accuracy: 0.6986 - val_loss: 0.6240 - val_accuracy: 0.6559\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5779 - accuracy: 0.7011 - val_loss: 0.6252 - val_accuracy: 0.6535\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5771 - accuracy: 0.7009 - val_loss: 0.6201 - val_accuracy: 0.6582\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5752 - accuracy: 0.7042 - val_loss: 0.6198 - val_accuracy: 0.6580\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5751 - accuracy: 0.7030 - val_loss: 0.6208 - val_accuracy: 0.6560\n"
     ]
    }
   ],
   "source": [
    "# 2. Variar l2_norm_clip\n",
    "results_l2_norm_clip = {}\n",
    "eps_l2_norm_clip = {}\n",
    "for l2 in l2_norm_clip_values:\n",
    "    print(f\"\\nEntrenando modelo con l2_norm_clip={l2}...\")\n",
    "    eps = compute_privacy_budget(n, batch_size, default_noise_multiplier, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "        batch_size, epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=default_num_microbatches, l2_norm_clip=l2,\n",
    "        noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_l2_norm_clip[l2] = compute_statistics(results)\n",
    "    eps_l2_norm_clip[l2] = eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7828fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo con noise_multiplier=1.1...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7683 - accuracy: 0.5300 - val_loss: 0.7930 - val_accuracy: 0.1406\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6776 - accuracy: 0.5782 - val_loss: 0.7175 - val_accuracy: 0.4419\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6678 - accuracy: 0.6075 - val_loss: 0.7064 - val_accuracy: 0.4884\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 993us/step - loss: 0.6610 - accuracy: 0.6209 - val_loss: 0.6929 - val_accuracy: 0.5294\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6561 - accuracy: 0.6289 - val_loss: 0.6884 - val_accuracy: 0.5427\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6517 - accuracy: 0.6334 - val_loss: 0.6855 - val_accuracy: 0.5513\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6477 - accuracy: 0.6391 - val_loss: 0.6762 - val_accuracy: 0.5740\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6450 - accuracy: 0.6450 - val_loss: 0.6757 - val_accuracy: 0.5768\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6418 - accuracy: 0.6464 - val_loss: 0.6705 - val_accuracy: 0.5882\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6381 - accuracy: 0.6499 - val_loss: 0.6647 - val_accuracy: 0.6015\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6344 - accuracy: 0.6558 - val_loss: 0.6634 - val_accuracy: 0.6026\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6323 - accuracy: 0.6580 - val_loss: 0.6610 - val_accuracy: 0.6084\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6301 - accuracy: 0.6583 - val_loss: 0.6572 - val_accuracy: 0.6126\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6277 - accuracy: 0.6615 - val_loss: 0.6594 - val_accuracy: 0.6079\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6265 - accuracy: 0.6629 - val_loss: 0.6533 - val_accuracy: 0.6158\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6244 - accuracy: 0.6642 - val_loss: 0.6549 - val_accuracy: 0.6125\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6215 - accuracy: 0.6681 - val_loss: 0.6505 - val_accuracy: 0.6194\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6190 - accuracy: 0.6702 - val_loss: 0.6477 - val_accuracy: 0.6227\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6171 - accuracy: 0.6704 - val_loss: 0.6439 - val_accuracy: 0.6272\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6155 - accuracy: 0.6702 - val_loss: 0.6491 - val_accuracy: 0.6190\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6145 - accuracy: 0.6736 - val_loss: 0.6431 - val_accuracy: 0.6263\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6123 - accuracy: 0.6735 - val_loss: 0.6393 - val_accuracy: 0.6316\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 966us/step - loss: 0.6103 - accuracy: 0.6782 - val_loss: 0.6435 - val_accuracy: 0.6262\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 930us/step - loss: 0.6092 - accuracy: 0.6797 - val_loss: 0.6388 - val_accuracy: 0.6321\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 898us/step - loss: 0.6073 - accuracy: 0.6810 - val_loss: 0.6411 - val_accuracy: 0.6292\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6058 - accuracy: 0.6810 - val_loss: 0.6429 - val_accuracy: 0.6268\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 952us/step - loss: 0.6036 - accuracy: 0.6849 - val_loss: 0.6336 - val_accuracy: 0.6392\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 985us/step - loss: 0.6026 - accuracy: 0.6863 - val_loss: 0.6345 - val_accuracy: 0.6373\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6008 - accuracy: 0.6873 - val_loss: 0.6373 - val_accuracy: 0.6335\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 944us/step - loss: 0.5993 - accuracy: 0.6884 - val_loss: 0.6397 - val_accuracy: 0.6304\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5968 - accuracy: 0.6916 - val_loss: 0.6289 - val_accuracy: 0.6441\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5965 - accuracy: 0.6899 - val_loss: 0.6338 - val_accuracy: 0.6370\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5951 - accuracy: 0.6925 - val_loss: 0.6308 - val_accuracy: 0.6407\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 937us/step - loss: 0.5937 - accuracy: 0.6931 - val_loss: 0.6306 - val_accuracy: 0.6403\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5919 - accuracy: 0.6953 - val_loss: 0.6315 - val_accuracy: 0.6393\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5903 - accuracy: 0.6964 - val_loss: 0.6303 - val_accuracy: 0.6402\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 995us/step - loss: 0.5888 - accuracy: 0.6962 - val_loss: 0.6297 - val_accuracy: 0.6401\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5876 - accuracy: 0.6985 - val_loss: 0.6264 - val_accuracy: 0.6433\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 972us/step - loss: 0.5856 - accuracy: 0.7001 - val_loss: 0.6326 - val_accuracy: 0.6362\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 935us/step - loss: 0.5859 - accuracy: 0.6997 - val_loss: 0.6285 - val_accuracy: 0.6403\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5838 - accuracy: 0.7023 - val_loss: 0.6302 - val_accuracy: 0.6389\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5826 - accuracy: 0.7020 - val_loss: 0.6231 - val_accuracy: 0.6468\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 925us/step - loss: 0.5809 - accuracy: 0.7036 - val_loss: 0.6255 - val_accuracy: 0.6448\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 979us/step - loss: 0.5801 - accuracy: 0.7037 - val_loss: 0.6233 - val_accuracy: 0.6459\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 990us/step - loss: 0.5791 - accuracy: 0.7045 - val_loss: 0.6264 - val_accuracy: 0.6435\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5772 - accuracy: 0.7058 - val_loss: 0.6207 - val_accuracy: 0.6476\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5765 - accuracy: 0.7082 - val_loss: 0.6221 - val_accuracy: 0.6462\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5751 - accuracy: 0.7071 - val_loss: 0.6188 - val_accuracy: 0.6490\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5739 - accuracy: 0.7066 - val_loss: 0.6172 - val_accuracy: 0.6514\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5725 - accuracy: 0.7083 - val_loss: 0.6224 - val_accuracy: 0.6468\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7060 - accuracy: 0.5163 - val_loss: 0.7347 - val_accuracy: 0.3554\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 974us/step - loss: 0.6995 - accuracy: 0.5241 - val_loss: 0.7227 - val_accuracy: 0.3912\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6952 - accuracy: 0.5360 - val_loss: 0.7220 - val_accuracy: 0.4005\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6910 - accuracy: 0.5455 - val_loss: 0.7173 - val_accuracy: 0.4294\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 944us/step - loss: 0.6864 - accuracy: 0.5529 - val_loss: 0.7120 - val_accuracy: 0.4543\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6834 - accuracy: 0.5637 - val_loss: 0.7107 - val_accuracy: 0.4657\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 999us/step - loss: 0.6801 - accuracy: 0.5713 - val_loss: 0.7093 - val_accuracy: 0.4765\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 974us/step - loss: 0.6766 - accuracy: 0.5782 - val_loss: 0.7024 - val_accuracy: 0.5071\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 968us/step - loss: 0.6744 - accuracy: 0.5844 - val_loss: 0.7011 - val_accuracy: 0.5169\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6719 - accuracy: 0.5910 - val_loss: 0.7001 - val_accuracy: 0.5216\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6689 - accuracy: 0.5989 - val_loss: 0.6988 - val_accuracy: 0.5265\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6670 - accuracy: 0.6017 - val_loss: 0.6945 - val_accuracy: 0.5436\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6649 - accuracy: 0.6079 - val_loss: 0.6975 - val_accuracy: 0.5349\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6622 - accuracy: 0.6148 - val_loss: 0.6943 - val_accuracy: 0.5463\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6611 - accuracy: 0.6174 - val_loss: 0.6918 - val_accuracy: 0.5560\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6586 - accuracy: 0.6232 - val_loss: 0.6885 - val_accuracy: 0.5644\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6570 - accuracy: 0.6266 - val_loss: 0.6905 - val_accuracy: 0.5590\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6550 - accuracy: 0.6290 - val_loss: 0.6893 - val_accuracy: 0.5616\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6529 - accuracy: 0.6346 - val_loss: 0.6902 - val_accuracy: 0.5584\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6512 - accuracy: 0.6358 - val_loss: 0.6835 - val_accuracy: 0.5774\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6487 - accuracy: 0.6383 - val_loss: 0.6837 - val_accuracy: 0.5760\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6473 - accuracy: 0.6426 - val_loss: 0.6805 - val_accuracy: 0.5868\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6446 - accuracy: 0.6497 - val_loss: 0.6780 - val_accuracy: 0.5931\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6433 - accuracy: 0.6464 - val_loss: 0.6740 - val_accuracy: 0.6042\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6409 - accuracy: 0.6503 - val_loss: 0.6739 - val_accuracy: 0.6041\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6400 - accuracy: 0.6526 - val_loss: 0.6782 - val_accuracy: 0.5916\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6379 - accuracy: 0.6546 - val_loss: 0.6712 - val_accuracy: 0.6096\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6350 - accuracy: 0.6602 - val_loss: 0.6684 - val_accuracy: 0.6173\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6341 - accuracy: 0.6593 - val_loss: 0.6701 - val_accuracy: 0.6117\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6324 - accuracy: 0.6616 - val_loss: 0.6663 - val_accuracy: 0.6207\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6300 - accuracy: 0.6650 - val_loss: 0.6637 - val_accuracy: 0.6249\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6276 - accuracy: 0.6671 - val_loss: 0.6668 - val_accuracy: 0.6168\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6264 - accuracy: 0.6676 - val_loss: 0.6592 - val_accuracy: 0.6301\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6246 - accuracy: 0.6694 - val_loss: 0.6601 - val_accuracy: 0.6277\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6223 - accuracy: 0.6710 - val_loss: 0.6595 - val_accuracy: 0.6276\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6211 - accuracy: 0.6758 - val_loss: 0.6602 - val_accuracy: 0.6239\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6184 - accuracy: 0.6772 - val_loss: 0.6501 - val_accuracy: 0.6436\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6175 - accuracy: 0.6770 - val_loss: 0.6540 - val_accuracy: 0.6339\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6154 - accuracy: 0.6808 - val_loss: 0.6511 - val_accuracy: 0.6375\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6130 - accuracy: 0.6816 - val_loss: 0.6531 - val_accuracy: 0.6305\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6119 - accuracy: 0.6832 - val_loss: 0.6497 - val_accuracy: 0.6345\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6102 - accuracy: 0.6840 - val_loss: 0.6473 - val_accuracy: 0.6380\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6077 - accuracy: 0.6856 - val_loss: 0.6498 - val_accuracy: 0.6303\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6067 - accuracy: 0.6878 - val_loss: 0.6499 - val_accuracy: 0.6274\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6045 - accuracy: 0.6903 - val_loss: 0.6462 - val_accuracy: 0.6333\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6029 - accuracy: 0.6918 - val_loss: 0.6448 - val_accuracy: 0.6349\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6010 - accuracy: 0.6938 - val_loss: 0.6462 - val_accuracy: 0.6297\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5992 - accuracy: 0.6947 - val_loss: 0.6412 - val_accuracy: 0.6377\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5978 - accuracy: 0.6958 - val_loss: 0.6397 - val_accuracy: 0.6386\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5952 - accuracy: 0.6980 - val_loss: 0.6365 - val_accuracy: 0.6430\n",
      "Epoch 1/50\n",
      "1666/1672 [============================>.] - ETA: 0s - loss: 0.7198 - accuracy: 0.4741WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7198 - accuracy: 0.4741 - val_loss: 0.7253 - val_accuracy: 0.3013\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7109 - accuracy: 0.4920 - val_loss: 0.7201 - val_accuracy: 0.3362\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7027 - accuracy: 0.5082 - val_loss: 0.7146 - val_accuracy: 0.3751\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6977 - accuracy: 0.5220 - val_loss: 0.7095 - val_accuracy: 0.4183\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6911 - accuracy: 0.5397 - val_loss: 0.7016 - val_accuracy: 0.4695\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6868 - accuracy: 0.5509 - val_loss: 0.6998 - val_accuracy: 0.4799\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6816 - accuracy: 0.5633 - val_loss: 0.6947 - val_accuracy: 0.5081\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6778 - accuracy: 0.5747 - val_loss: 0.6870 - val_accuracy: 0.5378\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6723 - accuracy: 0.5874 - val_loss: 0.6833 - val_accuracy: 0.5504\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6684 - accuracy: 0.5978 - val_loss: 0.6793 - val_accuracy: 0.5607\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6647 - accuracy: 0.6079 - val_loss: 0.6785 - val_accuracy: 0.5652\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6618 - accuracy: 0.6147 - val_loss: 0.6737 - val_accuracy: 0.5760\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6581 - accuracy: 0.6249 - val_loss: 0.6730 - val_accuracy: 0.5723\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6551 - accuracy: 0.6292 - val_loss: 0.6711 - val_accuracy: 0.5762\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6514 - accuracy: 0.6376 - val_loss: 0.6698 - val_accuracy: 0.5797\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6493 - accuracy: 0.6408 - val_loss: 0.6637 - val_accuracy: 0.5966\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6457 - accuracy: 0.6442 - val_loss: 0.6614 - val_accuracy: 0.5996\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6435 - accuracy: 0.6488 - val_loss: 0.6604 - val_accuracy: 0.5989\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6414 - accuracy: 0.6521 - val_loss: 0.6604 - val_accuracy: 0.5962\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6372 - accuracy: 0.6587 - val_loss: 0.6555 - val_accuracy: 0.6067\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6340 - accuracy: 0.6622 - val_loss: 0.6543 - val_accuracy: 0.6068\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6321 - accuracy: 0.6629 - val_loss: 0.6512 - val_accuracy: 0.6158\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6290 - accuracy: 0.6704 - val_loss: 0.6502 - val_accuracy: 0.6159\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6266 - accuracy: 0.6701 - val_loss: 0.6482 - val_accuracy: 0.6190\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6236 - accuracy: 0.6741 - val_loss: 0.6497 - val_accuracy: 0.6143\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6228 - accuracy: 0.6727 - val_loss: 0.6430 - val_accuracy: 0.6287\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6193 - accuracy: 0.6781 - val_loss: 0.6439 - val_accuracy: 0.6260\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6163 - accuracy: 0.6802 - val_loss: 0.6436 - val_accuracy: 0.6249\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6135 - accuracy: 0.6825 - val_loss: 0.6446 - val_accuracy: 0.6222\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6117 - accuracy: 0.6846 - val_loss: 0.6353 - val_accuracy: 0.6373\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6087 - accuracy: 0.6853 - val_loss: 0.6351 - val_accuracy: 0.6371\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6061 - accuracy: 0.6902 - val_loss: 0.6360 - val_accuracy: 0.6342\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6045 - accuracy: 0.6901 - val_loss: 0.6397 - val_accuracy: 0.6267\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6024 - accuracy: 0.6908 - val_loss: 0.6355 - val_accuracy: 0.6315\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6000 - accuracy: 0.6928 - val_loss: 0.6285 - val_accuracy: 0.6416\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5974 - accuracy: 0.6956 - val_loss: 0.6315 - val_accuracy: 0.6346\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5962 - accuracy: 0.6969 - val_loss: 0.6227 - val_accuracy: 0.6457\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5943 - accuracy: 0.6969 - val_loss: 0.6265 - val_accuracy: 0.6385\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5908 - accuracy: 0.7020 - val_loss: 0.6219 - val_accuracy: 0.6438\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5893 - accuracy: 0.7035 - val_loss: 0.6233 - val_accuracy: 0.6422\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5881 - accuracy: 0.7019 - val_loss: 0.6216 - val_accuracy: 0.6431\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5854 - accuracy: 0.7055 - val_loss: 0.6208 - val_accuracy: 0.6436\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5841 - accuracy: 0.7048 - val_loss: 0.6200 - val_accuracy: 0.6444\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5826 - accuracy: 0.7070 - val_loss: 0.6180 - val_accuracy: 0.6469\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5810 - accuracy: 0.7082 - val_loss: 0.6209 - val_accuracy: 0.6422\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5803 - accuracy: 0.7086 - val_loss: 0.6187 - val_accuracy: 0.6449\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5773 - accuracy: 0.7109 - val_loss: 0.6126 - val_accuracy: 0.6527\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5755 - accuracy: 0.7116 - val_loss: 0.6195 - val_accuracy: 0.6446\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5748 - accuracy: 0.7125 - val_loss: 0.6153 - val_accuracy: 0.6495\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5720 - accuracy: 0.7148 - val_loss: 0.6188 - val_accuracy: 0.6446\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7124 - accuracy: 0.5152 - val_loss: 0.7430 - val_accuracy: 0.2754\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7008 - accuracy: 0.5282 - val_loss: 0.7293 - val_accuracy: 0.3376\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6932 - accuracy: 0.5393 - val_loss: 0.7204 - val_accuracy: 0.3753\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6855 - accuracy: 0.5532 - val_loss: 0.7181 - val_accuracy: 0.3938\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6784 - accuracy: 0.5676 - val_loss: 0.7049 - val_accuracy: 0.4709\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6715 - accuracy: 0.5802 - val_loss: 0.7017 - val_accuracy: 0.4830\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6661 - accuracy: 0.5949 - val_loss: 0.6927 - val_accuracy: 0.5218\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6595 - accuracy: 0.6081 - val_loss: 0.6947 - val_accuracy: 0.5162\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6568 - accuracy: 0.6131 - val_loss: 0.6903 - val_accuracy: 0.5374\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6522 - accuracy: 0.6211 - val_loss: 0.6854 - val_accuracy: 0.5580\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6476 - accuracy: 0.6299 - val_loss: 0.6768 - val_accuracy: 0.5812\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6436 - accuracy: 0.6335 - val_loss: 0.6827 - val_accuracy: 0.5681\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6402 - accuracy: 0.6410 - val_loss: 0.6734 - val_accuracy: 0.5860\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6367 - accuracy: 0.6447 - val_loss: 0.6737 - val_accuracy: 0.5832\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6332 - accuracy: 0.6493 - val_loss: 0.6672 - val_accuracy: 0.5941\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6299 - accuracy: 0.6559 - val_loss: 0.6641 - val_accuracy: 0.5988\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6268 - accuracy: 0.6579 - val_loss: 0.6652 - val_accuracy: 0.5953\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6245 - accuracy: 0.6592 - val_loss: 0.6621 - val_accuracy: 0.5992\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6214 - accuracy: 0.6653 - val_loss: 0.6536 - val_accuracy: 0.6134\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6185 - accuracy: 0.6677 - val_loss: 0.6480 - val_accuracy: 0.6210\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6161 - accuracy: 0.6688 - val_loss: 0.6563 - val_accuracy: 0.6091\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6134 - accuracy: 0.6688 - val_loss: 0.6572 - val_accuracy: 0.6072\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6113 - accuracy: 0.6735 - val_loss: 0.6494 - val_accuracy: 0.6194\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6087 - accuracy: 0.6746 - val_loss: 0.6432 - val_accuracy: 0.6295\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6059 - accuracy: 0.6770 - val_loss: 0.6439 - val_accuracy: 0.6281\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6038 - accuracy: 0.6797 - val_loss: 0.6398 - val_accuracy: 0.6319\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6014 - accuracy: 0.6831 - val_loss: 0.6421 - val_accuracy: 0.6282\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6000 - accuracy: 0.6816 - val_loss: 0.6413 - val_accuracy: 0.6287\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5973 - accuracy: 0.6842 - val_loss: 0.6437 - val_accuracy: 0.6248\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5947 - accuracy: 0.6869 - val_loss: 0.6369 - val_accuracy: 0.6355\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5938 - accuracy: 0.6867 - val_loss: 0.6311 - val_accuracy: 0.6424\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5916 - accuracy: 0.6883 - val_loss: 0.6318 - val_accuracy: 0.6404\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5898 - accuracy: 0.6904 - val_loss: 0.6305 - val_accuracy: 0.6422\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5882 - accuracy: 0.6917 - val_loss: 0.6201 - val_accuracy: 0.6560\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5863 - accuracy: 0.6930 - val_loss: 0.6296 - val_accuracy: 0.6428\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5854 - accuracy: 0.6937 - val_loss: 0.6224 - val_accuracy: 0.6535\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5821 - accuracy: 0.6961 - val_loss: 0.6245 - val_accuracy: 0.6498\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5813 - accuracy: 0.6969 - val_loss: 0.6271 - val_accuracy: 0.6460\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5804 - accuracy: 0.6973 - val_loss: 0.6238 - val_accuracy: 0.6496\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5789 - accuracy: 0.6986 - val_loss: 0.6257 - val_accuracy: 0.6471\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5774 - accuracy: 0.6995 - val_loss: 0.6258 - val_accuracy: 0.6465\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5760 - accuracy: 0.6999 - val_loss: 0.6177 - val_accuracy: 0.6547\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5748 - accuracy: 0.7000 - val_loss: 0.6291 - val_accuracy: 0.6420\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5728 - accuracy: 0.7038 - val_loss: 0.6207 - val_accuracy: 0.6503\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5715 - accuracy: 0.7042 - val_loss: 0.6122 - val_accuracy: 0.6584\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5705 - accuracy: 0.7066 - val_loss: 0.6145 - val_accuracy: 0.6550\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5693 - accuracy: 0.7054 - val_loss: 0.6167 - val_accuracy: 0.6527\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5685 - accuracy: 0.7065 - val_loss: 0.6218 - val_accuracy: 0.6480\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5668 - accuracy: 0.7076 - val_loss: 0.6217 - val_accuracy: 0.6479\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5656 - accuracy: 0.7100 - val_loss: 0.6213 - val_accuracy: 0.6481\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.7572 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0014s). Check your callbacks.\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7382 - accuracy: 0.4888 - val_loss: 0.6337 - val_accuracy: 0.8460\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6901 - accuracy: 0.5312 - val_loss: 0.6895 - val_accuracy: 0.5339\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6818 - accuracy: 0.5512 - val_loss: 0.7010 - val_accuracy: 0.4777\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6766 - accuracy: 0.5643 - val_loss: 0.7006 - val_accuracy: 0.4962\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6712 - accuracy: 0.5778 - val_loss: 0.6956 - val_accuracy: 0.5277\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6669 - accuracy: 0.5878 - val_loss: 0.6898 - val_accuracy: 0.5557\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6619 - accuracy: 0.6001 - val_loss: 0.6855 - val_accuracy: 0.5735\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6580 - accuracy: 0.6071 - val_loss: 0.6812 - val_accuracy: 0.5844\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6548 - accuracy: 0.6144 - val_loss: 0.6777 - val_accuracy: 0.5936\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6512 - accuracy: 0.6209 - val_loss: 0.6752 - val_accuracy: 0.5967\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6489 - accuracy: 0.6224 - val_loss: 0.6723 - val_accuracy: 0.6032\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6461 - accuracy: 0.6260 - val_loss: 0.6681 - val_accuracy: 0.6122\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6425 - accuracy: 0.6337 - val_loss: 0.6666 - val_accuracy: 0.6143\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6402 - accuracy: 0.6329 - val_loss: 0.6603 - val_accuracy: 0.6280\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6379 - accuracy: 0.6370 - val_loss: 0.6576 - val_accuracy: 0.6329\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6356 - accuracy: 0.6400 - val_loss: 0.6545 - val_accuracy: 0.6385\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6331 - accuracy: 0.6462 - val_loss: 0.6542 - val_accuracy: 0.6367\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6313 - accuracy: 0.6447 - val_loss: 0.6509 - val_accuracy: 0.6416\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 1ms/step - loss: 0.6271 - accuracy: 0.6485 - val_loss: 0.6507 - val_accuracy: 0.6399\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6259 - accuracy: 0.6484 - val_loss: 0.6487 - val_accuracy: 0.6405\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6229 - accuracy: 0.6525 - val_loss: 0.6453 - val_accuracy: 0.6453\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6207 - accuracy: 0.6538 - val_loss: 0.6428 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6190 - accuracy: 0.6577 - val_loss: 0.6428 - val_accuracy: 0.6434\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6172 - accuracy: 0.6574 - val_loss: 0.6434 - val_accuracy: 0.6409\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6143 - accuracy: 0.6620 - val_loss: 0.6380 - val_accuracy: 0.6456\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6132 - accuracy: 0.6604 - val_loss: 0.6351 - val_accuracy: 0.6480\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6110 - accuracy: 0.6643 - val_loss: 0.6368 - val_accuracy: 0.6450\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6096 - accuracy: 0.6659 - val_loss: 0.6324 - val_accuracy: 0.6501\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6066 - accuracy: 0.6691 - val_loss: 0.6332 - val_accuracy: 0.6482\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6050 - accuracy: 0.6714 - val_loss: 0.6342 - val_accuracy: 0.6461\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6039 - accuracy: 0.6714 - val_loss: 0.6268 - val_accuracy: 0.6568\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6023 - accuracy: 0.6733 - val_loss: 0.6266 - val_accuracy: 0.6550\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6004 - accuracy: 0.6749 - val_loss: 0.6231 - val_accuracy: 0.6598\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5981 - accuracy: 0.6787 - val_loss: 0.6261 - val_accuracy: 0.6550\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5976 - accuracy: 0.6803 - val_loss: 0.6232 - val_accuracy: 0.6581\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5960 - accuracy: 0.6824 - val_loss: 0.6136 - val_accuracy: 0.6669\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5933 - accuracy: 0.6851 - val_loss: 0.6202 - val_accuracy: 0.6581\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5928 - accuracy: 0.6864 - val_loss: 0.6240 - val_accuracy: 0.6535\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5906 - accuracy: 0.6878 - val_loss: 0.6239 - val_accuracy: 0.6527\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5892 - accuracy: 0.6887 - val_loss: 0.6209 - val_accuracy: 0.6543\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5880 - accuracy: 0.6911 - val_loss: 0.6194 - val_accuracy: 0.6551\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 1ms/step - loss: 0.5861 - accuracy: 0.6931 - val_loss: 0.6143 - val_accuracy: 0.6571\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5845 - accuracy: 0.6952 - val_loss: 0.6161 - val_accuracy: 0.6552\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5836 - accuracy: 0.6961 - val_loss: 0.6139 - val_accuracy: 0.6571\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5816 - accuracy: 0.6993 - val_loss: 0.6182 - val_accuracy: 0.6535\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5802 - accuracy: 0.7008 - val_loss: 0.6134 - val_accuracy: 0.6574\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5786 - accuracy: 0.7028 - val_loss: 0.6132 - val_accuracy: 0.6571\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5772 - accuracy: 0.7025 - val_loss: 0.6099 - val_accuracy: 0.6593\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5759 - accuracy: 0.7031 - val_loss: 0.6112 - val_accuracy: 0.6584\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5757 - accuracy: 0.7049 - val_loss: 0.6154 - val_accuracy: 0.6549\n",
      "\n",
      "Entrenando modelo con noise_multiplier=1.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.5 iterated over 83600 steps satisfies differential privacy with eps = 0.643 and delta = 1e-05.\n",
      "The optimal RDP order is 32.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6883 - accuracy: 0.5543 - val_loss: 0.6985 - val_accuracy: 0.4789\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6790 - accuracy: 0.5745 - val_loss: 0.6981 - val_accuracy: 0.4974\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6735 - accuracy: 0.5866 - val_loss: 0.6998 - val_accuracy: 0.4961\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6690 - accuracy: 0.5959 - val_loss: 0.6956 - val_accuracy: 0.5152\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6650 - accuracy: 0.6041 - val_loss: 0.6930 - val_accuracy: 0.5321\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6611 - accuracy: 0.6134 - val_loss: 0.6864 - val_accuracy: 0.5577\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6568 - accuracy: 0.6212 - val_loss: 0.6837 - val_accuracy: 0.5646\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6538 - accuracy: 0.6284 - val_loss: 0.6810 - val_accuracy: 0.5708\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6504 - accuracy: 0.6328 - val_loss: 0.6794 - val_accuracy: 0.5698\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6470 - accuracy: 0.6378 - val_loss: 0.6750 - val_accuracy: 0.5790\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6433 - accuracy: 0.6443 - val_loss: 0.6689 - val_accuracy: 0.5885\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6402 - accuracy: 0.6498 - val_loss: 0.6655 - val_accuracy: 0.5927\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6373 - accuracy: 0.6513 - val_loss: 0.6619 - val_accuracy: 0.5967\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6339 - accuracy: 0.6536 - val_loss: 0.6602 - val_accuracy: 0.5998\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6307 - accuracy: 0.6581 - val_loss: 0.6561 - val_accuracy: 0.6077\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6272 - accuracy: 0.6625 - val_loss: 0.6548 - val_accuracy: 0.6079\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6247 - accuracy: 0.6649 - val_loss: 0.6532 - val_accuracy: 0.6092\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6224 - accuracy: 0.6647 - val_loss: 0.6501 - val_accuracy: 0.6136\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6190 - accuracy: 0.6699 - val_loss: 0.6442 - val_accuracy: 0.6261\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6172 - accuracy: 0.6699 - val_loss: 0.6464 - val_accuracy: 0.6180\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6147 - accuracy: 0.6719 - val_loss: 0.6412 - val_accuracy: 0.6295\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6126 - accuracy: 0.6730 - val_loss: 0.6425 - val_accuracy: 0.6262\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6097 - accuracy: 0.6764 - val_loss: 0.6367 - val_accuracy: 0.6351\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6082 - accuracy: 0.6770 - val_loss: 0.6356 - val_accuracy: 0.6347\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6056 - accuracy: 0.6809 - val_loss: 0.6382 - val_accuracy: 0.6320\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6031 - accuracy: 0.6811 - val_loss: 0.6313 - val_accuracy: 0.6387\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6009 - accuracy: 0.6834 - val_loss: 0.6344 - val_accuracy: 0.6365\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5997 - accuracy: 0.6841 - val_loss: 0.6262 - val_accuracy: 0.6420\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5977 - accuracy: 0.6854 - val_loss: 0.6254 - val_accuracy: 0.6416\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5966 - accuracy: 0.6868 - val_loss: 0.6238 - val_accuracy: 0.6425\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5936 - accuracy: 0.6898 - val_loss: 0.6206 - val_accuracy: 0.6443\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5917 - accuracy: 0.6882 - val_loss: 0.6213 - val_accuracy: 0.6435\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5901 - accuracy: 0.6918 - val_loss: 0.6246 - val_accuracy: 0.6408\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5894 - accuracy: 0.6919 - val_loss: 0.6203 - val_accuracy: 0.6436\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5874 - accuracy: 0.6943 - val_loss: 0.6187 - val_accuracy: 0.6448\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5857 - accuracy: 0.6949 - val_loss: 0.6181 - val_accuracy: 0.6449\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5834 - accuracy: 0.6960 - val_loss: 0.6142 - val_accuracy: 0.6495\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5830 - accuracy: 0.6973 - val_loss: 0.6148 - val_accuracy: 0.6485\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5810 - accuracy: 0.6997 - val_loss: 0.6170 - val_accuracy: 0.6456\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5791 - accuracy: 0.6982 - val_loss: 0.6113 - val_accuracy: 0.6514\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5779 - accuracy: 0.7008 - val_loss: 0.6129 - val_accuracy: 0.6483\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5761 - accuracy: 0.7031 - val_loss: 0.6129 - val_accuracy: 0.6469\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5748 - accuracy: 0.7037 - val_loss: 0.6146 - val_accuracy: 0.6439\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5727 - accuracy: 0.7069 - val_loss: 0.6119 - val_accuracy: 0.6466\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5719 - accuracy: 0.7052 - val_loss: 0.6141 - val_accuracy: 0.6451\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5716 - accuracy: 0.7043 - val_loss: 0.6121 - val_accuracy: 0.6472\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5690 - accuracy: 0.7082 - val_loss: 0.6117 - val_accuracy: 0.6504\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5677 - accuracy: 0.7097 - val_loss: 0.6009 - val_accuracy: 0.6638\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5660 - accuracy: 0.7116 - val_loss: 0.6032 - val_accuracy: 0.6614\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5651 - accuracy: 0.7122 - val_loss: 0.6045 - val_accuracy: 0.6593\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.7185 - accuracy: 0.5204 - val_loss: 0.7260 - val_accuracy: 0.3749\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6994 - accuracy: 0.5477 - val_loss: 0.7042 - val_accuracy: 0.5058\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6862 - accuracy: 0.5657 - val_loss: 0.6928 - val_accuracy: 0.5544\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6776 - accuracy: 0.5846 - val_loss: 0.6807 - val_accuracy: 0.5871\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6682 - accuracy: 0.5989 - val_loss: 0.6802 - val_accuracy: 0.5854\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6616 - accuracy: 0.6100 - val_loss: 0.6730 - val_accuracy: 0.5986\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6535 - accuracy: 0.6228 - val_loss: 0.6698 - val_accuracy: 0.6026\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6495 - accuracy: 0.6284 - val_loss: 0.6614 - val_accuracy: 0.6145\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6434 - accuracy: 0.6388 - val_loss: 0.6491 - val_accuracy: 0.6330\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6385 - accuracy: 0.6440 - val_loss: 0.6548 - val_accuracy: 0.6218\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6361 - accuracy: 0.6469 - val_loss: 0.6539 - val_accuracy: 0.6222\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6303 - accuracy: 0.6575 - val_loss: 0.6431 - val_accuracy: 0.6381\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6269 - accuracy: 0.6598 - val_loss: 0.6378 - val_accuracy: 0.6426\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6249 - accuracy: 0.6617 - val_loss: 0.6355 - val_accuracy: 0.6427\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6216 - accuracy: 0.6694 - val_loss: 0.6349 - val_accuracy: 0.6410\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6175 - accuracy: 0.6733 - val_loss: 0.6270 - val_accuracy: 0.6509\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6144 - accuracy: 0.6757 - val_loss: 0.6340 - val_accuracy: 0.6398\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6125 - accuracy: 0.6785 - val_loss: 0.6261 - val_accuracy: 0.6491\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6100 - accuracy: 0.6824 - val_loss: 0.6278 - val_accuracy: 0.6461\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6079 - accuracy: 0.6835 - val_loss: 0.6258 - val_accuracy: 0.6491\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6054 - accuracy: 0.6854 - val_loss: 0.6278 - val_accuracy: 0.6459\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6023 - accuracy: 0.6897 - val_loss: 0.6205 - val_accuracy: 0.6555\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6012 - accuracy: 0.6937 - val_loss: 0.6224 - val_accuracy: 0.6523\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5989 - accuracy: 0.6931 - val_loss: 0.6173 - val_accuracy: 0.6575\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5966 - accuracy: 0.6954 - val_loss: 0.6239 - val_accuracy: 0.6474\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5946 - accuracy: 0.6970 - val_loss: 0.6133 - val_accuracy: 0.6595\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5937 - accuracy: 0.6986 - val_loss: 0.6128 - val_accuracy: 0.6603\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5914 - accuracy: 0.6988 - val_loss: 0.6084 - val_accuracy: 0.6631\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5889 - accuracy: 0.7016 - val_loss: 0.6155 - val_accuracy: 0.6545\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5876 - accuracy: 0.7025 - val_loss: 0.6224 - val_accuracy: 0.6445\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5854 - accuracy: 0.7065 - val_loss: 0.6128 - val_accuracy: 0.6551\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5834 - accuracy: 0.7066 - val_loss: 0.6150 - val_accuracy: 0.6499\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5827 - accuracy: 0.7071 - val_loss: 0.6073 - val_accuracy: 0.6570\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5798 - accuracy: 0.7109 - val_loss: 0.6170 - val_accuracy: 0.6456\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5791 - accuracy: 0.7113 - val_loss: 0.6092 - val_accuracy: 0.6531\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5776 - accuracy: 0.7108 - val_loss: 0.6045 - val_accuracy: 0.6559\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5761 - accuracy: 0.7129 - val_loss: 0.6078 - val_accuracy: 0.6532\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5744 - accuracy: 0.7143 - val_loss: 0.6025 - val_accuracy: 0.6560\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5738 - accuracy: 0.7138 - val_loss: 0.6079 - val_accuracy: 0.6520\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5715 - accuracy: 0.7167 - val_loss: 0.6005 - val_accuracy: 0.6555\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5705 - accuracy: 0.7163 - val_loss: 0.6081 - val_accuracy: 0.6499\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5693 - accuracy: 0.7180 - val_loss: 0.6089 - val_accuracy: 0.6486\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5688 - accuracy: 0.7181 - val_loss: 0.6110 - val_accuracy: 0.6462\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5671 - accuracy: 0.7199 - val_loss: 0.6091 - val_accuracy: 0.6470\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5647 - accuracy: 0.7220 - val_loss: 0.6028 - val_accuracy: 0.6529\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5646 - accuracy: 0.7206 - val_loss: 0.6066 - val_accuracy: 0.6498\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5623 - accuracy: 0.7229 - val_loss: 0.6051 - val_accuracy: 0.6508\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5624 - accuracy: 0.7220 - val_loss: 0.6084 - val_accuracy: 0.6487\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5600 - accuracy: 0.7236 - val_loss: 0.5978 - val_accuracy: 0.6577\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5586 - accuracy: 0.7250 - val_loss: 0.6074 - val_accuracy: 0.6496\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7147 - accuracy: 0.5307 - val_loss: 0.6746 - val_accuracy: 0.6145\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6843 - accuracy: 0.5651 - val_loss: 0.6886 - val_accuracy: 0.5580\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6772 - accuracy: 0.5774 - val_loss: 0.6830 - val_accuracy: 0.5750\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6728 - accuracy: 0.5843 - val_loss: 0.6764 - val_accuracy: 0.5901\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6670 - accuracy: 0.5956 - val_loss: 0.6720 - val_accuracy: 0.5950\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6600 - accuracy: 0.6094 - val_loss: 0.6683 - val_accuracy: 0.6000\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6562 - accuracy: 0.6130 - val_loss: 0.6618 - val_accuracy: 0.6140\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6514 - accuracy: 0.6221 - val_loss: 0.6628 - val_accuracy: 0.6052\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6464 - accuracy: 0.6298 - val_loss: 0.6593 - val_accuracy: 0.6107\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6420 - accuracy: 0.6354 - val_loss: 0.6572 - val_accuracy: 0.6150\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6385 - accuracy: 0.6406 - val_loss: 0.6520 - val_accuracy: 0.6220\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6343 - accuracy: 0.6439 - val_loss: 0.6481 - val_accuracy: 0.6267\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6307 - accuracy: 0.6508 - val_loss: 0.6444 - val_accuracy: 0.6344\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6281 - accuracy: 0.6536 - val_loss: 0.6442 - val_accuracy: 0.6335\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6251 - accuracy: 0.6562 - val_loss: 0.6410 - val_accuracy: 0.6388\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6223 - accuracy: 0.6585 - val_loss: 0.6380 - val_accuracy: 0.6420\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6202 - accuracy: 0.6592 - val_loss: 0.6353 - val_accuracy: 0.6479\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6179 - accuracy: 0.6631 - val_loss: 0.6382 - val_accuracy: 0.6407\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6157 - accuracy: 0.6620 - val_loss: 0.6330 - val_accuracy: 0.6489\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6128 - accuracy: 0.6674 - val_loss: 0.6315 - val_accuracy: 0.6495\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6100 - accuracy: 0.6695 - val_loss: 0.6283 - val_accuracy: 0.6510\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6083 - accuracy: 0.6718 - val_loss: 0.6320 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6073 - accuracy: 0.6715 - val_loss: 0.6263 - val_accuracy: 0.6520\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6042 - accuracy: 0.6738 - val_loss: 0.6243 - val_accuracy: 0.6537\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6016 - accuracy: 0.6771 - val_loss: 0.6261 - val_accuracy: 0.6512\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6007 - accuracy: 0.6763 - val_loss: 0.6264 - val_accuracy: 0.6497\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5990 - accuracy: 0.6802 - val_loss: 0.6268 - val_accuracy: 0.6486\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5965 - accuracy: 0.6822 - val_loss: 0.6219 - val_accuracy: 0.6522\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5954 - accuracy: 0.6815 - val_loss: 0.6217 - val_accuracy: 0.6521\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5933 - accuracy: 0.6855 - val_loss: 0.6234 - val_accuracy: 0.6490\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5918 - accuracy: 0.6870 - val_loss: 0.6239 - val_accuracy: 0.6475\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5895 - accuracy: 0.6893 - val_loss: 0.6233 - val_accuracy: 0.6475\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5883 - accuracy: 0.6884 - val_loss: 0.6161 - val_accuracy: 0.6537\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5868 - accuracy: 0.6897 - val_loss: 0.6199 - val_accuracy: 0.6496\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5849 - accuracy: 0.6935 - val_loss: 0.6170 - val_accuracy: 0.6504\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5831 - accuracy: 0.6947 - val_loss: 0.6172 - val_accuracy: 0.6492\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5816 - accuracy: 0.6965 - val_loss: 0.6119 - val_accuracy: 0.6551\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5802 - accuracy: 0.6956 - val_loss: 0.6095 - val_accuracy: 0.6570\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5788 - accuracy: 0.6974 - val_loss: 0.6131 - val_accuracy: 0.6516\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5782 - accuracy: 0.6980 - val_loss: 0.6106 - val_accuracy: 0.6527\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5761 - accuracy: 0.6993 - val_loss: 0.6135 - val_accuracy: 0.6486\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5749 - accuracy: 0.6994 - val_loss: 0.6096 - val_accuracy: 0.6525\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5722 - accuracy: 0.7022 - val_loss: 0.6109 - val_accuracy: 0.6511\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5716 - accuracy: 0.7050 - val_loss: 0.6093 - val_accuracy: 0.6531\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5689 - accuracy: 0.7072 - val_loss: 0.6084 - val_accuracy: 0.6538\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5692 - accuracy: 0.7051 - val_loss: 0.6091 - val_accuracy: 0.6530\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5674 - accuracy: 0.7074 - val_loss: 0.6036 - val_accuracy: 0.6574\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5649 - accuracy: 0.7096 - val_loss: 0.6083 - val_accuracy: 0.6540\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5650 - accuracy: 0.7085 - val_loss: 0.6064 - val_accuracy: 0.6549\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5623 - accuracy: 0.7105 - val_loss: 0.6027 - val_accuracy: 0.6576\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7382 - accuracy: 0.4861 - val_loss: 0.6963 - val_accuracy: 0.4698\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7032 - accuracy: 0.5215 - val_loss: 0.7143 - val_accuracy: 0.3413\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6924 - accuracy: 0.5440 - val_loss: 0.7104 - val_accuracy: 0.3916\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6826 - accuracy: 0.5681 - val_loss: 0.6998 - val_accuracy: 0.4590\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6736 - accuracy: 0.5888 - val_loss: 0.6975 - val_accuracy: 0.4880\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6678 - accuracy: 0.6004 - val_loss: 0.6911 - val_accuracy: 0.5254\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6614 - accuracy: 0.6174 - val_loss: 0.6844 - val_accuracy: 0.5468\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6558 - accuracy: 0.6341 - val_loss: 0.6798 - val_accuracy: 0.5610\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6512 - accuracy: 0.6370 - val_loss: 0.6756 - val_accuracy: 0.5697\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6478 - accuracy: 0.6489 - val_loss: 0.6711 - val_accuracy: 0.5819\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6433 - accuracy: 0.6551 - val_loss: 0.6621 - val_accuracy: 0.6026\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6379 - accuracy: 0.6626 - val_loss: 0.6588 - val_accuracy: 0.6101\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6348 - accuracy: 0.6681 - val_loss: 0.6638 - val_accuracy: 0.5964\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6306 - accuracy: 0.6753 - val_loss: 0.6547 - val_accuracy: 0.6196\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6280 - accuracy: 0.6758 - val_loss: 0.6547 - val_accuracy: 0.6193\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6246 - accuracy: 0.6807 - val_loss: 0.6534 - val_accuracy: 0.6219\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6217 - accuracy: 0.6833 - val_loss: 0.6484 - val_accuracy: 0.6297\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6189 - accuracy: 0.6847 - val_loss: 0.6406 - val_accuracy: 0.6404\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6164 - accuracy: 0.6873 - val_loss: 0.6423 - val_accuracy: 0.6361\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6124 - accuracy: 0.6927 - val_loss: 0.6359 - val_accuracy: 0.6448\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6108 - accuracy: 0.6925 - val_loss: 0.6402 - val_accuracy: 0.6362\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6084 - accuracy: 0.6951 - val_loss: 0.6353 - val_accuracy: 0.6427\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6072 - accuracy: 0.6923 - val_loss: 0.6281 - val_accuracy: 0.6516\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6033 - accuracy: 0.6971 - val_loss: 0.6323 - val_accuracy: 0.6446\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6012 - accuracy: 0.6989 - val_loss: 0.6311 - val_accuracy: 0.6450\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5985 - accuracy: 0.7007 - val_loss: 0.6229 - val_accuracy: 0.6547\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5980 - accuracy: 0.7021 - val_loss: 0.6222 - val_accuracy: 0.6542\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5951 - accuracy: 0.7035 - val_loss: 0.6281 - val_accuracy: 0.6447\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5943 - accuracy: 0.7026 - val_loss: 0.6218 - val_accuracy: 0.6529\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5911 - accuracy: 0.7066 - val_loss: 0.6186 - val_accuracy: 0.6552\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5888 - accuracy: 0.7079 - val_loss: 0.6241 - val_accuracy: 0.6486\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5878 - accuracy: 0.7073 - val_loss: 0.6186 - val_accuracy: 0.6539\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5860 - accuracy: 0.7074 - val_loss: 0.6167 - val_accuracy: 0.6551\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5850 - accuracy: 0.7090 - val_loss: 0.6161 - val_accuracy: 0.6550\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5821 - accuracy: 0.7106 - val_loss: 0.6161 - val_accuracy: 0.6549\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5802 - accuracy: 0.7123 - val_loss: 0.6092 - val_accuracy: 0.6615\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5799 - accuracy: 0.7113 - val_loss: 0.6091 - val_accuracy: 0.6612\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5772 - accuracy: 0.7144 - val_loss: 0.6081 - val_accuracy: 0.6623\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5755 - accuracy: 0.7151 - val_loss: 0.6103 - val_accuracy: 0.6580\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5741 - accuracy: 0.7159 - val_loss: 0.6139 - val_accuracy: 0.6527\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5729 - accuracy: 0.7155 - val_loss: 0.6035 - val_accuracy: 0.6645\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5714 - accuracy: 0.7182 - val_loss: 0.6063 - val_accuracy: 0.6615\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5691 - accuracy: 0.7193 - val_loss: 0.6077 - val_accuracy: 0.6597\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5687 - accuracy: 0.7192 - val_loss: 0.6096 - val_accuracy: 0.6564\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5682 - accuracy: 0.7175 - val_loss: 0.6060 - val_accuracy: 0.6600\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5674 - accuracy: 0.7198 - val_loss: 0.6051 - val_accuracy: 0.6597\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5648 - accuracy: 0.7228 - val_loss: 0.6041 - val_accuracy: 0.6600\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5637 - accuracy: 0.7198 - val_loss: 0.5960 - val_accuracy: 0.6677\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5630 - accuracy: 0.7214 - val_loss: 0.6015 - val_accuracy: 0.6623\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5628 - accuracy: 0.7221 - val_loss: 0.6030 - val_accuracy: 0.6611\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6910 - accuracy: 0.5527 - val_loss: 0.7037 - val_accuracy: 0.5156\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6834 - accuracy: 0.5648 - val_loss: 0.6942 - val_accuracy: 0.5490\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6765 - accuracy: 0.5754 - val_loss: 0.6922 - val_accuracy: 0.5547\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6728 - accuracy: 0.5849 - val_loss: 0.6809 - val_accuracy: 0.5824\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6663 - accuracy: 0.5963 - val_loss: 0.6819 - val_accuracy: 0.5781\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6617 - accuracy: 0.6049 - val_loss: 0.6822 - val_accuracy: 0.5750\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6600 - accuracy: 0.6091 - val_loss: 0.6735 - val_accuracy: 0.5915\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6565 - accuracy: 0.6137 - val_loss: 0.6704 - val_accuracy: 0.5970\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6519 - accuracy: 0.6225 - val_loss: 0.6680 - val_accuracy: 0.6007\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6493 - accuracy: 0.6279 - val_loss: 0.6648 - val_accuracy: 0.6049\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6460 - accuracy: 0.6342 - val_loss: 0.6638 - val_accuracy: 0.6051\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6439 - accuracy: 0.6386 - val_loss: 0.6610 - val_accuracy: 0.6068\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6400 - accuracy: 0.6438 - val_loss: 0.6620 - val_accuracy: 0.6039\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6386 - accuracy: 0.6443 - val_loss: 0.6584 - val_accuracy: 0.6082\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6362 - accuracy: 0.6464 - val_loss: 0.6529 - val_accuracy: 0.6164\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6347 - accuracy: 0.6504 - val_loss: 0.6536 - val_accuracy: 0.6123\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6316 - accuracy: 0.6551 - val_loss: 0.6515 - val_accuracy: 0.6163\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6290 - accuracy: 0.6589 - val_loss: 0.6448 - val_accuracy: 0.6259\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6270 - accuracy: 0.6604 - val_loss: 0.6488 - val_accuracy: 0.6203\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6258 - accuracy: 0.6602 - val_loss: 0.6453 - val_accuracy: 0.6242\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6237 - accuracy: 0.6660 - val_loss: 0.6441 - val_accuracy: 0.6259\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6211 - accuracy: 0.6660 - val_loss: 0.6440 - val_accuracy: 0.6257\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6198 - accuracy: 0.6681 - val_loss: 0.6405 - val_accuracy: 0.6287\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6176 - accuracy: 0.6717 - val_loss: 0.6425 - val_accuracy: 0.6265\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6154 - accuracy: 0.6739 - val_loss: 0.6407 - val_accuracy: 0.6286\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6135 - accuracy: 0.6762 - val_loss: 0.6356 - val_accuracy: 0.6357\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6123 - accuracy: 0.6773 - val_loss: 0.6377 - val_accuracy: 0.6324\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6101 - accuracy: 0.6798 - val_loss: 0.6380 - val_accuracy: 0.6333\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6073 - accuracy: 0.6823 - val_loss: 0.6299 - val_accuracy: 0.6448\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6062 - accuracy: 0.6847 - val_loss: 0.6299 - val_accuracy: 0.6453\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6041 - accuracy: 0.6862 - val_loss: 0.6250 - val_accuracy: 0.6516\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6015 - accuracy: 0.6902 - val_loss: 0.6297 - val_accuracy: 0.6450\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6008 - accuracy: 0.6888 - val_loss: 0.6297 - val_accuracy: 0.6455\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5980 - accuracy: 0.6906 - val_loss: 0.6269 - val_accuracy: 0.6490\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5970 - accuracy: 0.6943 - val_loss: 0.6243 - val_accuracy: 0.6517\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5959 - accuracy: 0.6947 - val_loss: 0.6250 - val_accuracy: 0.6509\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5935 - accuracy: 0.6973 - val_loss: 0.6219 - val_accuracy: 0.6547\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5924 - accuracy: 0.6969 - val_loss: 0.6202 - val_accuracy: 0.6555\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5897 - accuracy: 0.7008 - val_loss: 0.6270 - val_accuracy: 0.6467\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5892 - accuracy: 0.6995 - val_loss: 0.6195 - val_accuracy: 0.6553\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5877 - accuracy: 0.7025 - val_loss: 0.6199 - val_accuracy: 0.6541\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5851 - accuracy: 0.7051 - val_loss: 0.6216 - val_accuracy: 0.6529\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5833 - accuracy: 0.7048 - val_loss: 0.6140 - val_accuracy: 0.6627\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5822 - accuracy: 0.7073 - val_loss: 0.6142 - val_accuracy: 0.6628\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5802 - accuracy: 0.7090 - val_loss: 0.6210 - val_accuracy: 0.6519\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5788 - accuracy: 0.7097 - val_loss: 0.6119 - val_accuracy: 0.6670\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5778 - accuracy: 0.7113 - val_loss: 0.6211 - val_accuracy: 0.6521\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5765 - accuracy: 0.7112 - val_loss: 0.6112 - val_accuracy: 0.6673\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5749 - accuracy: 0.7129 - val_loss: 0.6101 - val_accuracy: 0.6679\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5723 - accuracy: 0.7155 - val_loss: 0.6114 - val_accuracy: 0.6663\n",
      "\n",
      "Entrenando modelo con noise_multiplier=2.0...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.0 iterated over 83600 steps satisfies differential privacy with eps = 0.449 and delta = 1e-05.\n",
      "The optimal RDP order is 53.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.7381 - accuracy: 0.4966 - val_loss: 0.6419 - val_accuracy: 0.7827\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6909 - accuracy: 0.5414 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6863 - accuracy: 0.5590 - val_loss: 0.6955 - val_accuracy: 0.5054\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6827 - accuracy: 0.5687 - val_loss: 0.6917 - val_accuracy: 0.5221\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5768 - val_loss: 0.6881 - val_accuracy: 0.5311\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6738 - accuracy: 0.5885 - val_loss: 0.6868 - val_accuracy: 0.5331\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6717 - accuracy: 0.5921 - val_loss: 0.6813 - val_accuracy: 0.5509\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6676 - accuracy: 0.6015 - val_loss: 0.6805 - val_accuracy: 0.5546\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 1ms/step - loss: 0.6648 - accuracy: 0.6093 - val_loss: 0.6791 - val_accuracy: 0.5629\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6629 - accuracy: 0.6112 - val_loss: 0.6788 - val_accuracy: 0.5643\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6597 - accuracy: 0.6200 - val_loss: 0.6721 - val_accuracy: 0.5783\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6569 - accuracy: 0.6268 - val_loss: 0.6720 - val_accuracy: 0.5767\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6548 - accuracy: 0.6296 - val_loss: 0.6655 - val_accuracy: 0.5896\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6521 - accuracy: 0.6353 - val_loss: 0.6669 - val_accuracy: 0.5853\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6501 - accuracy: 0.6398 - val_loss: 0.6655 - val_accuracy: 0.5883\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6473 - accuracy: 0.6436 - val_loss: 0.6635 - val_accuracy: 0.5924\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6436 - accuracy: 0.6498 - val_loss: 0.6556 - val_accuracy: 0.6086\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6416 - accuracy: 0.6544 - val_loss: 0.6589 - val_accuracy: 0.5994\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6396 - accuracy: 0.6579 - val_loss: 0.6527 - val_accuracy: 0.6109\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6371 - accuracy: 0.6582 - val_loss: 0.6529 - val_accuracy: 0.6091\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6338 - accuracy: 0.6647 - val_loss: 0.6466 - val_accuracy: 0.6196\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6320 - accuracy: 0.6638 - val_loss: 0.6436 - val_accuracy: 0.6221\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6299 - accuracy: 0.6661 - val_loss: 0.6461 - val_accuracy: 0.6154\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6278 - accuracy: 0.6681 - val_loss: 0.6429 - val_accuracy: 0.6188\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6248 - accuracy: 0.6709 - val_loss: 0.6400 - val_accuracy: 0.6204\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6231 - accuracy: 0.6750 - val_loss: 0.6370 - val_accuracy: 0.6227\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6207 - accuracy: 0.6757 - val_loss: 0.6336 - val_accuracy: 0.6263\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6180 - accuracy: 0.6787 - val_loss: 0.6296 - val_accuracy: 0.6299\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6161 - accuracy: 0.6799 - val_loss: 0.6221 - val_accuracy: 0.6416\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6136 - accuracy: 0.6820 - val_loss: 0.6254 - val_accuracy: 0.6351\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6125 - accuracy: 0.6832 - val_loss: 0.6277 - val_accuracy: 0.6312\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6096 - accuracy: 0.6854 - val_loss: 0.6245 - val_accuracy: 0.6357\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6081 - accuracy: 0.6868 - val_loss: 0.6178 - val_accuracy: 0.6425\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6060 - accuracy: 0.6880 - val_loss: 0.6218 - val_accuracy: 0.6354\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6041 - accuracy: 0.6898 - val_loss: 0.6167 - val_accuracy: 0.6418\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6020 - accuracy: 0.6917 - val_loss: 0.6196 - val_accuracy: 0.6365\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5999 - accuracy: 0.6930 - val_loss: 0.6208 - val_accuracy: 0.6329\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5991 - accuracy: 0.6928 - val_loss: 0.6149 - val_accuracy: 0.6402\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5979 - accuracy: 0.6936 - val_loss: 0.6147 - val_accuracy: 0.6401\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5958 - accuracy: 0.6960 - val_loss: 0.6128 - val_accuracy: 0.6413\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5944 - accuracy: 0.6977 - val_loss: 0.6139 - val_accuracy: 0.6387\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5918 - accuracy: 0.6992 - val_loss: 0.6119 - val_accuracy: 0.6393\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5906 - accuracy: 0.6989 - val_loss: 0.6107 - val_accuracy: 0.6393\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5903 - accuracy: 0.6966 - val_loss: 0.6120 - val_accuracy: 0.6382\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5889 - accuracy: 0.7001 - val_loss: 0.6132 - val_accuracy: 0.6350\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5870 - accuracy: 0.7031 - val_loss: 0.6082 - val_accuracy: 0.6388\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5851 - accuracy: 0.7025 - val_loss: 0.6082 - val_accuracy: 0.6377\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5837 - accuracy: 0.7041 - val_loss: 0.6048 - val_accuracy: 0.6394\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5833 - accuracy: 0.7043 - val_loss: 0.6104 - val_accuracy: 0.6355\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5817 - accuracy: 0.7045 - val_loss: 0.6036 - val_accuracy: 0.6389\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.7529 - accuracy: 0.4636 - val_loss: 0.7272 - val_accuracy: 0.3499\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.7226 - accuracy: 0.4741 - val_loss: 0.7427 - val_accuracy: 0.3108\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.7184 - accuracy: 0.4819 - val_loss: 0.7366 - val_accuracy: 0.3319\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 5s 3ms/step - loss: 0.7120 - accuracy: 0.4917 - val_loss: 0.7338 - val_accuracy: 0.3532\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.7062 - accuracy: 0.5036 - val_loss: 0.7260 - val_accuracy: 0.3888\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7018 - accuracy: 0.5139 - val_loss: 0.7216 - val_accuracy: 0.4025\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6975 - accuracy: 0.5247 - val_loss: 0.7191 - val_accuracy: 0.4204\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6938 - accuracy: 0.5340 - val_loss: 0.7177 - val_accuracy: 0.4296\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6907 - accuracy: 0.5417 - val_loss: 0.7111 - val_accuracy: 0.4564\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6868 - accuracy: 0.5499 - val_loss: 0.7039 - val_accuracy: 0.4981\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6836 - accuracy: 0.5604 - val_loss: 0.7063 - val_accuracy: 0.4898\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5641 - val_loss: 0.7017 - val_accuracy: 0.5107\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6784 - accuracy: 0.5755 - val_loss: 0.6981 - val_accuracy: 0.5248\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6756 - accuracy: 0.5813 - val_loss: 0.6976 - val_accuracy: 0.5270\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6734 - accuracy: 0.5867 - val_loss: 0.6945 - val_accuracy: 0.5350\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6696 - accuracy: 0.5941 - val_loss: 0.6948 - val_accuracy: 0.5326\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6681 - accuracy: 0.6003 - val_loss: 0.6907 - val_accuracy: 0.5403\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6655 - accuracy: 0.6053 - val_loss: 0.6883 - val_accuracy: 0.5450\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6624 - accuracy: 0.6095 - val_loss: 0.6860 - val_accuracy: 0.5492\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6608 - accuracy: 0.6138 - val_loss: 0.6827 - val_accuracy: 0.5559\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6583 - accuracy: 0.6176 - val_loss: 0.6801 - val_accuracy: 0.5619\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6552 - accuracy: 0.6230 - val_loss: 0.6797 - val_accuracy: 0.5624\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6525 - accuracy: 0.6290 - val_loss: 0.6761 - val_accuracy: 0.5698\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6508 - accuracy: 0.6309 - val_loss: 0.6750 - val_accuracy: 0.5725\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6499 - accuracy: 0.6308 - val_loss: 0.6759 - val_accuracy: 0.5695\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6471 - accuracy: 0.6386 - val_loss: 0.6749 - val_accuracy: 0.5701\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6445 - accuracy: 0.6410 - val_loss: 0.6725 - val_accuracy: 0.5743\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6435 - accuracy: 0.6415 - val_loss: 0.6718 - val_accuracy: 0.5741\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6416 - accuracy: 0.6440 - val_loss: 0.6707 - val_accuracy: 0.5758\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6395 - accuracy: 0.6458 - val_loss: 0.6682 - val_accuracy: 0.5792\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6379 - accuracy: 0.6477 - val_loss: 0.6670 - val_accuracy: 0.5801\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6356 - accuracy: 0.6518 - val_loss: 0.6657 - val_accuracy: 0.5819\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6335 - accuracy: 0.6537 - val_loss: 0.6599 - val_accuracy: 0.5911\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6323 - accuracy: 0.6557 - val_loss: 0.6629 - val_accuracy: 0.5840\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6299 - accuracy: 0.6593 - val_loss: 0.6650 - val_accuracy: 0.5779\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6290 - accuracy: 0.6602 - val_loss: 0.6631 - val_accuracy: 0.5804\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6272 - accuracy: 0.6599 - val_loss: 0.6589 - val_accuracy: 0.5887\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6264 - accuracy: 0.6639 - val_loss: 0.6542 - val_accuracy: 0.5952\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6233 - accuracy: 0.6657 - val_loss: 0.6546 - val_accuracy: 0.5935\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6222 - accuracy: 0.6688 - val_loss: 0.6544 - val_accuracy: 0.5915\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6200 - accuracy: 0.6678 - val_loss: 0.6478 - val_accuracy: 0.6039\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6191 - accuracy: 0.6702 - val_loss: 0.6479 - val_accuracy: 0.6013\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6171 - accuracy: 0.6725 - val_loss: 0.6496 - val_accuracy: 0.5955\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6152 - accuracy: 0.6745 - val_loss: 0.6446 - val_accuracy: 0.6046\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6144 - accuracy: 0.6739 - val_loss: 0.6441 - val_accuracy: 0.6052\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6115 - accuracy: 0.6769 - val_loss: 0.6469 - val_accuracy: 0.5973\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6102 - accuracy: 0.6785 - val_loss: 0.6423 - val_accuracy: 0.6028\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6085 - accuracy: 0.6819 - val_loss: 0.6411 - val_accuracy: 0.6032\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6073 - accuracy: 0.6812 - val_loss: 0.6435 - val_accuracy: 0.5978\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6052 - accuracy: 0.6830 - val_loss: 0.6404 - val_accuracy: 0.6015\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7426 - accuracy: 0.4927 - val_loss: 0.6805 - val_accuracy: 0.5966\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6937 - accuracy: 0.5329 - val_loss: 0.7102 - val_accuracy: 0.4344\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6875 - accuracy: 0.5531 - val_loss: 0.7081 - val_accuracy: 0.4541\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6827 - accuracy: 0.5663 - val_loss: 0.7071 - val_accuracy: 0.4726\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6760 - accuracy: 0.5857 - val_loss: 0.7042 - val_accuracy: 0.4857\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6725 - accuracy: 0.5948 - val_loss: 0.7008 - val_accuracy: 0.5001\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6669 - accuracy: 0.6091 - val_loss: 0.6937 - val_accuracy: 0.5286\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 1ms/step - loss: 0.6645 - accuracy: 0.6122 - val_loss: 0.6881 - val_accuracy: 0.5441\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6603 - accuracy: 0.6213 - val_loss: 0.6887 - val_accuracy: 0.5437\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6584 - accuracy: 0.6257 - val_loss: 0.6839 - val_accuracy: 0.5519\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6559 - accuracy: 0.6341 - val_loss: 0.6822 - val_accuracy: 0.5550\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6543 - accuracy: 0.6365 - val_loss: 0.6825 - val_accuracy: 0.5553\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6510 - accuracy: 0.6433 - val_loss: 0.6762 - val_accuracy: 0.5604\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6494 - accuracy: 0.6431 - val_loss: 0.6772 - val_accuracy: 0.5590\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6459 - accuracy: 0.6483 - val_loss: 0.6733 - val_accuracy: 0.5638\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6454 - accuracy: 0.6497 - val_loss: 0.6685 - val_accuracy: 0.5687\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6434 - accuracy: 0.6551 - val_loss: 0.6673 - val_accuracy: 0.5698\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6412 - accuracy: 0.6577 - val_loss: 0.6680 - val_accuracy: 0.5693\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6390 - accuracy: 0.6602 - val_loss: 0.6681 - val_accuracy: 0.5682\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6362 - accuracy: 0.6629 - val_loss: 0.6640 - val_accuracy: 0.5723\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6355 - accuracy: 0.6656 - val_loss: 0.6642 - val_accuracy: 0.5717\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6331 - accuracy: 0.6692 - val_loss: 0.6626 - val_accuracy: 0.5737\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6310 - accuracy: 0.6699 - val_loss: 0.6602 - val_accuracy: 0.5786\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6301 - accuracy: 0.6716 - val_loss: 0.6592 - val_accuracy: 0.5802\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6283 - accuracy: 0.6712 - val_loss: 0.6538 - val_accuracy: 0.5866\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6255 - accuracy: 0.6756 - val_loss: 0.6555 - val_accuracy: 0.5849\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6246 - accuracy: 0.6764 - val_loss: 0.6537 - val_accuracy: 0.5871\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6226 - accuracy: 0.6799 - val_loss: 0.6506 - val_accuracy: 0.5923\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6202 - accuracy: 0.6802 - val_loss: 0.6482 - val_accuracy: 0.5949\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6189 - accuracy: 0.6811 - val_loss: 0.6439 - val_accuracy: 0.5989\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6175 - accuracy: 0.6831 - val_loss: 0.6438 - val_accuracy: 0.5979\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6169 - accuracy: 0.6824 - val_loss: 0.6424 - val_accuracy: 0.5985\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6132 - accuracy: 0.6879 - val_loss: 0.6403 - val_accuracy: 0.6013\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6120 - accuracy: 0.6876 - val_loss: 0.6383 - val_accuracy: 0.6044\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6106 - accuracy: 0.6885 - val_loss: 0.6459 - val_accuracy: 0.5929\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6088 - accuracy: 0.6905 - val_loss: 0.6391 - val_accuracy: 0.6018\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6075 - accuracy: 0.6905 - val_loss: 0.6363 - val_accuracy: 0.6062\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6053 - accuracy: 0.6934 - val_loss: 0.6393 - val_accuracy: 0.6033\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6042 - accuracy: 0.6938 - val_loss: 0.6341 - val_accuracy: 0.6099\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6035 - accuracy: 0.6942 - val_loss: 0.6328 - val_accuracy: 0.6116\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6015 - accuracy: 0.6945 - val_loss: 0.6310 - val_accuracy: 0.6147\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5999 - accuracy: 0.6967 - val_loss: 0.6320 - val_accuracy: 0.6140\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5990 - accuracy: 0.6987 - val_loss: 0.6351 - val_accuracy: 0.6092\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5977 - accuracy: 0.6970 - val_loss: 0.6298 - val_accuracy: 0.6164\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5956 - accuracy: 0.6999 - val_loss: 0.6275 - val_accuracy: 0.6200\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5951 - accuracy: 0.6998 - val_loss: 0.6318 - val_accuracy: 0.6136\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5930 - accuracy: 0.7037 - val_loss: 0.6242 - val_accuracy: 0.6221\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5918 - accuracy: 0.7029 - val_loss: 0.6261 - val_accuracy: 0.6197\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5898 - accuracy: 0.7053 - val_loss: 0.6244 - val_accuracy: 0.6204\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5892 - accuracy: 0.7042 - val_loss: 0.6269 - val_accuracy: 0.6164\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6918 - accuracy: 0.5405 - val_loss: 0.7116 - val_accuracy: 0.4226\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6840 - accuracy: 0.5690 - val_loss: 0.7090 - val_accuracy: 0.4356\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6797 - accuracy: 0.5883 - val_loss: 0.7051 - val_accuracy: 0.4622\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6748 - accuracy: 0.6063 - val_loss: 0.7011 - val_accuracy: 0.4879\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6707 - accuracy: 0.6204 - val_loss: 0.6960 - val_accuracy: 0.5112\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6669 - accuracy: 0.6298 - val_loss: 0.6920 - val_accuracy: 0.5361\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6633 - accuracy: 0.6395 - val_loss: 0.6882 - val_accuracy: 0.5534\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6585 - accuracy: 0.6506 - val_loss: 0.6864 - val_accuracy: 0.5623\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6558 - accuracy: 0.6544 - val_loss: 0.6843 - val_accuracy: 0.5674\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6524 - accuracy: 0.6595 - val_loss: 0.6813 - val_accuracy: 0.5757\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6486 - accuracy: 0.6645 - val_loss: 0.6739 - val_accuracy: 0.5897\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6459 - accuracy: 0.6664 - val_loss: 0.6749 - val_accuracy: 0.5865\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6438 - accuracy: 0.6679 - val_loss: 0.6658 - val_accuracy: 0.6007\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6402 - accuracy: 0.6717 - val_loss: 0.6677 - val_accuracy: 0.5954\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6373 - accuracy: 0.6759 - val_loss: 0.6613 - val_accuracy: 0.6043\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6345 - accuracy: 0.6784 - val_loss: 0.6584 - val_accuracy: 0.6072\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6320 - accuracy: 0.6794 - val_loss: 0.6562 - val_accuracy: 0.6091\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6299 - accuracy: 0.6821 - val_loss: 0.6532 - val_accuracy: 0.6117\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6274 - accuracy: 0.6838 - val_loss: 0.6559 - val_accuracy: 0.6041\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6240 - accuracy: 0.6868 - val_loss: 0.6466 - val_accuracy: 0.6168\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6220 - accuracy: 0.6859 - val_loss: 0.6506 - val_accuracy: 0.6099\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6198 - accuracy: 0.6866 - val_loss: 0.6482 - val_accuracy: 0.6112\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6174 - accuracy: 0.6911 - val_loss: 0.6451 - val_accuracy: 0.6150\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6156 - accuracy: 0.6905 - val_loss: 0.6420 - val_accuracy: 0.6159\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6126 - accuracy: 0.6924 - val_loss: 0.6340 - val_accuracy: 0.6248\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6108 - accuracy: 0.6931 - val_loss: 0.6370 - val_accuracy: 0.6189\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6097 - accuracy: 0.6925 - val_loss: 0.6352 - val_accuracy: 0.6195\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6079 - accuracy: 0.6920 - val_loss: 0.6302 - val_accuracy: 0.6245\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6054 - accuracy: 0.6951 - val_loss: 0.6265 - val_accuracy: 0.6269\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6037 - accuracy: 0.6970 - val_loss: 0.6310 - val_accuracy: 0.6189\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6024 - accuracy: 0.6960 - val_loss: 0.6275 - val_accuracy: 0.6217\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5994 - accuracy: 0.7004 - val_loss: 0.6254 - val_accuracy: 0.6225\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5973 - accuracy: 0.6988 - val_loss: 0.6223 - val_accuracy: 0.6255\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5960 - accuracy: 0.7013 - val_loss: 0.6269 - val_accuracy: 0.6185\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5951 - accuracy: 0.7012 - val_loss: 0.6281 - val_accuracy: 0.6156\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5925 - accuracy: 0.7040 - val_loss: 0.6241 - val_accuracy: 0.6203\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.5916 - accuracy: 0.7039 - val_loss: 0.6183 - val_accuracy: 0.6258\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.5900 - accuracy: 0.7049 - val_loss: 0.6157 - val_accuracy: 0.6295\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5884 - accuracy: 0.7068 - val_loss: 0.6241 - val_accuracy: 0.6193\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7068 - val_loss: 0.6217 - val_accuracy: 0.6220\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5863 - accuracy: 0.7052 - val_loss: 0.6090 - val_accuracy: 0.6393\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5843 - accuracy: 0.7078 - val_loss: 0.6122 - val_accuracy: 0.6344\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5818 - accuracy: 0.7102 - val_loss: 0.6159 - val_accuracy: 0.6300\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5806 - accuracy: 0.7090 - val_loss: 0.6124 - val_accuracy: 0.6335\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5799 - accuracy: 0.7095 - val_loss: 0.6162 - val_accuracy: 0.6294\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5789 - accuracy: 0.7118 - val_loss: 0.6151 - val_accuracy: 0.6312\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5767 - accuracy: 0.7117 - val_loss: 0.6034 - val_accuracy: 0.6404\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5764 - accuracy: 0.7117 - val_loss: 0.6108 - val_accuracy: 0.6344\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5753 - accuracy: 0.7126 - val_loss: 0.6111 - val_accuracy: 0.6336\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5739 - accuracy: 0.7128 - val_loss: 0.6099 - val_accuracy: 0.6350\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.7114 - accuracy: 0.5210 - val_loss: 0.7186 - val_accuracy: 0.4647\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6916 - accuracy: 0.5393 - val_loss: 0.7039 - val_accuracy: 0.5156\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6830 - accuracy: 0.5604 - val_loss: 0.6956 - val_accuracy: 0.5405\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.6776 - accuracy: 0.5738 - val_loss: 0.6887 - val_accuracy: 0.5619\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.6725 - accuracy: 0.5839 - val_loss: 0.6877 - val_accuracy: 0.5673\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6675 - accuracy: 0.5984 - val_loss: 0.6831 - val_accuracy: 0.5780\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6619 - accuracy: 0.6082 - val_loss: 0.6780 - val_accuracy: 0.5900\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6588 - accuracy: 0.6133 - val_loss: 0.6794 - val_accuracy: 0.5844\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6551 - accuracy: 0.6218 - val_loss: 0.6715 - val_accuracy: 0.6035\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6499 - accuracy: 0.6317 - val_loss: 0.6739 - val_accuracy: 0.5950\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6465 - accuracy: 0.6374 - val_loss: 0.6626 - val_accuracy: 0.6186\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.6435 - accuracy: 0.6448 - val_loss: 0.6614 - val_accuracy: 0.6189\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6404 - accuracy: 0.6465 - val_loss: 0.6595 - val_accuracy: 0.6213\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6378 - accuracy: 0.6483 - val_loss: 0.6566 - val_accuracy: 0.6234\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6342 - accuracy: 0.6565 - val_loss: 0.6551 - val_accuracy: 0.6241\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.6316 - accuracy: 0.6592 - val_loss: 0.6506 - val_accuracy: 0.6311\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.6282 - accuracy: 0.6627 - val_loss: 0.6452 - val_accuracy: 0.6378\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.6261 - accuracy: 0.6647 - val_loss: 0.6459 - val_accuracy: 0.6354\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6232 - accuracy: 0.6681 - val_loss: 0.6425 - val_accuracy: 0.6387\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6210 - accuracy: 0.6709 - val_loss: 0.6430 - val_accuracy: 0.6351\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6184 - accuracy: 0.6739 - val_loss: 0.6433 - val_accuracy: 0.6323\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6163 - accuracy: 0.6759 - val_loss: 0.6394 - val_accuracy: 0.6383\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6139 - accuracy: 0.6763 - val_loss: 0.6383 - val_accuracy: 0.6368\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6116 - accuracy: 0.6796 - val_loss: 0.6383 - val_accuracy: 0.6347\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6102 - accuracy: 0.6812 - val_loss: 0.6344 - val_accuracy: 0.6386\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6076 - accuracy: 0.6833 - val_loss: 0.6390 - val_accuracy: 0.6321\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6064 - accuracy: 0.6837 - val_loss: 0.6279 - val_accuracy: 0.6433\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6043 - accuracy: 0.6852 - val_loss: 0.6243 - val_accuracy: 0.6469\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6023 - accuracy: 0.6884 - val_loss: 0.6347 - val_accuracy: 0.6345\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6000 - accuracy: 0.6899 - val_loss: 0.6293 - val_accuracy: 0.6377\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5979 - accuracy: 0.6908 - val_loss: 0.6292 - val_accuracy: 0.6375\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5970 - accuracy: 0.6904 - val_loss: 0.6257 - val_accuracy: 0.6403\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5950 - accuracy: 0.6955 - val_loss: 0.6232 - val_accuracy: 0.6427\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5939 - accuracy: 0.6940 - val_loss: 0.6195 - val_accuracy: 0.6482\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5922 - accuracy: 0.6963 - val_loss: 0.6201 - val_accuracy: 0.6471\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5901 - accuracy: 0.6976 - val_loss: 0.6260 - val_accuracy: 0.6370\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5878 - accuracy: 0.6999 - val_loss: 0.6186 - val_accuracy: 0.6461\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5870 - accuracy: 0.6996 - val_loss: 0.6215 - val_accuracy: 0.6422\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5847 - accuracy: 0.7014 - val_loss: 0.6177 - val_accuracy: 0.6454\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5833 - accuracy: 0.7040 - val_loss: 0.6207 - val_accuracy: 0.6393\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5822 - accuracy: 0.7055 - val_loss: 0.6173 - val_accuracy: 0.6425\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5815 - accuracy: 0.7067 - val_loss: 0.6195 - val_accuracy: 0.6392\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5793 - accuracy: 0.7073 - val_loss: 0.6101 - val_accuracy: 0.6499\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5778 - accuracy: 0.7101 - val_loss: 0.6203 - val_accuracy: 0.6371\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5759 - accuracy: 0.7105 - val_loss: 0.6070 - val_accuracy: 0.6521\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5749 - accuracy: 0.7106 - val_loss: 0.6104 - val_accuracy: 0.6472\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5731 - accuracy: 0.7116 - val_loss: 0.6115 - val_accuracy: 0.6460\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5720 - accuracy: 0.7115 - val_loss: 0.6139 - val_accuracy: 0.6424\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5706 - accuracy: 0.7140 - val_loss: 0.6110 - val_accuracy: 0.6443\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5698 - accuracy: 0.7124 - val_loss: 0.6087 - val_accuracy: 0.6471\n",
      "\n",
      "Entrenando modelo con noise_multiplier=2.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.5 iterated over 83600 steps satisfies differential privacy with eps = 0.35 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6905 - accuracy: 0.5511 - val_loss: 0.7079 - val_accuracy: 0.4508\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6853 - accuracy: 0.5584 - val_loss: 0.7032 - val_accuracy: 0.4827\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5743 - val_loss: 0.6989 - val_accuracy: 0.5166\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6723 - accuracy: 0.5879 - val_loss: 0.6946 - val_accuracy: 0.5379\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6675 - accuracy: 0.5946 - val_loss: 0.6849 - val_accuracy: 0.5645\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6622 - accuracy: 0.6080 - val_loss: 0.6825 - val_accuracy: 0.5678\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6592 - accuracy: 0.6140 - val_loss: 0.6799 - val_accuracy: 0.5728\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6550 - accuracy: 0.6199 - val_loss: 0.6744 - val_accuracy: 0.5827\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6505 - accuracy: 0.6274 - val_loss: 0.6740 - val_accuracy: 0.5810\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6462 - accuracy: 0.6328 - val_loss: 0.6693 - val_accuracy: 0.5881\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6429 - accuracy: 0.6357 - val_loss: 0.6663 - val_accuracy: 0.5925\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6399 - accuracy: 0.6402 - val_loss: 0.6635 - val_accuracy: 0.5960\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6371 - accuracy: 0.6427 - val_loss: 0.6608 - val_accuracy: 0.6011\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6334 - accuracy: 0.6461 - val_loss: 0.6574 - val_accuracy: 0.6093\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6324 - accuracy: 0.6485 - val_loss: 0.6601 - val_accuracy: 0.6025\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6294 - accuracy: 0.6516 - val_loss: 0.6497 - val_accuracy: 0.6231\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6272 - accuracy: 0.6525 - val_loss: 0.6528 - val_accuracy: 0.6171\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6253 - accuracy: 0.6545 - val_loss: 0.6517 - val_accuracy: 0.6176\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6221 - accuracy: 0.6606 - val_loss: 0.6468 - val_accuracy: 0.6248\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6205 - accuracy: 0.6622 - val_loss: 0.6437 - val_accuracy: 0.6292\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6180 - accuracy: 0.6620 - val_loss: 0.6419 - val_accuracy: 0.6323\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6169 - accuracy: 0.6643 - val_loss: 0.6433 - val_accuracy: 0.6290\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6137 - accuracy: 0.6675 - val_loss: 0.6349 - val_accuracy: 0.6413\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6117 - accuracy: 0.6701 - val_loss: 0.6390 - val_accuracy: 0.6335\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6106 - accuracy: 0.6699 - val_loss: 0.6386 - val_accuracy: 0.6337\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6086 - accuracy: 0.6713 - val_loss: 0.6362 - val_accuracy: 0.6389\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6071 - accuracy: 0.6733 - val_loss: 0.6360 - val_accuracy: 0.6384\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6046 - accuracy: 0.6749 - val_loss: 0.6321 - val_accuracy: 0.6455\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6035 - accuracy: 0.6777 - val_loss: 0.6319 - val_accuracy: 0.6443\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6020 - accuracy: 0.6794 - val_loss: 0.6323 - val_accuracy: 0.6427\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6006 - accuracy: 0.6803 - val_loss: 0.6281 - val_accuracy: 0.6475\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5978 - accuracy: 0.6824 - val_loss: 0.6265 - val_accuracy: 0.6482\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5969 - accuracy: 0.6824 - val_loss: 0.6300 - val_accuracy: 0.6418\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5950 - accuracy: 0.6854 - val_loss: 0.6301 - val_accuracy: 0.6409\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5926 - accuracy: 0.6874 - val_loss: 0.6203 - val_accuracy: 0.6521\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5917 - accuracy: 0.6899 - val_loss: 0.6230 - val_accuracy: 0.6469\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5907 - accuracy: 0.6888 - val_loss: 0.6262 - val_accuracy: 0.6429\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5901 - accuracy: 0.6906 - val_loss: 0.6249 - val_accuracy: 0.6419\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5877 - accuracy: 0.6937 - val_loss: 0.6195 - val_accuracy: 0.6460\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5867 - accuracy: 0.6931 - val_loss: 0.6227 - val_accuracy: 0.6425\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5851 - accuracy: 0.6960 - val_loss: 0.6204 - val_accuracy: 0.6439\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5845 - accuracy: 0.6983 - val_loss: 0.6160 - val_accuracy: 0.6474\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5829 - accuracy: 0.6971 - val_loss: 0.6139 - val_accuracy: 0.6483\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5818 - accuracy: 0.7002 - val_loss: 0.6209 - val_accuracy: 0.6406\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5802 - accuracy: 0.7011 - val_loss: 0.6200 - val_accuracy: 0.6403\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5789 - accuracy: 0.7017 - val_loss: 0.6150 - val_accuracy: 0.6445\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5773 - accuracy: 0.7038 - val_loss: 0.6158 - val_accuracy: 0.6418\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5765 - accuracy: 0.7051 - val_loss: 0.6141 - val_accuracy: 0.6446\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5755 - accuracy: 0.7053 - val_loss: 0.6090 - val_accuracy: 0.6506\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5739 - accuracy: 0.7066 - val_loss: 0.6185 - val_accuracy: 0.6382\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.8652 - accuracy: 0.4904 - val_loss: 0.5887 - val_accuracy: 0.8729\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6969 - accuracy: 0.5409 - val_loss: 0.6746 - val_accuracy: 0.5931\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6868 - accuracy: 0.5596 - val_loss: 0.6875 - val_accuracy: 0.5389\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6827 - accuracy: 0.5687 - val_loss: 0.6893 - val_accuracy: 0.5332\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6792 - accuracy: 0.5765 - val_loss: 0.6862 - val_accuracy: 0.5438\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6771 - accuracy: 0.5829 - val_loss: 0.6873 - val_accuracy: 0.5395\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6733 - accuracy: 0.5908 - val_loss: 0.6865 - val_accuracy: 0.5406\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6700 - accuracy: 0.5978 - val_loss: 0.6850 - val_accuracy: 0.5438\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6684 - accuracy: 0.6027 - val_loss: 0.6804 - val_accuracy: 0.5577\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6655 - accuracy: 0.6065 - val_loss: 0.6797 - val_accuracy: 0.5595\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6626 - accuracy: 0.6164 - val_loss: 0.6740 - val_accuracy: 0.5736\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6586 - accuracy: 0.6224 - val_loss: 0.6719 - val_accuracy: 0.5795\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6559 - accuracy: 0.6299 - val_loss: 0.6708 - val_accuracy: 0.5814\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6527 - accuracy: 0.6342 - val_loss: 0.6679 - val_accuracy: 0.5874\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6499 - accuracy: 0.6391 - val_loss: 0.6654 - val_accuracy: 0.5922\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6477 - accuracy: 0.6431 - val_loss: 0.6641 - val_accuracy: 0.5935\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6454 - accuracy: 0.6442 - val_loss: 0.6612 - val_accuracy: 0.5988\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6433 - accuracy: 0.6502 - val_loss: 0.6611 - val_accuracy: 0.5958\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6408 - accuracy: 0.6534 - val_loss: 0.6589 - val_accuracy: 0.5991\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6385 - accuracy: 0.6545 - val_loss: 0.6613 - val_accuracy: 0.5927\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6350 - accuracy: 0.6624 - val_loss: 0.6529 - val_accuracy: 0.6069\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6327 - accuracy: 0.6652 - val_loss: 0.6518 - val_accuracy: 0.6063\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6306 - accuracy: 0.6670 - val_loss: 0.6517 - val_accuracy: 0.6060\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 3s 1ms/step - loss: 0.6282 - accuracy: 0.6695 - val_loss: 0.6493 - val_accuracy: 0.6095\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6253 - accuracy: 0.6735 - val_loss: 0.6404 - val_accuracy: 0.6216\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6230 - accuracy: 0.6754 - val_loss: 0.6446 - val_accuracy: 0.6135\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6211 - accuracy: 0.6756 - val_loss: 0.6414 - val_accuracy: 0.6172\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6185 - accuracy: 0.6799 - val_loss: 0.6400 - val_accuracy: 0.6180\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6163 - accuracy: 0.6799 - val_loss: 0.6416 - val_accuracy: 0.6161\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6141 - accuracy: 0.6821 - val_loss: 0.6387 - val_accuracy: 0.6190\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6124 - accuracy: 0.6859 - val_loss: 0.6361 - val_accuracy: 0.6215\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6110 - accuracy: 0.6866 - val_loss: 0.6395 - val_accuracy: 0.6174\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6083 - accuracy: 0.6880 - val_loss: 0.6385 - val_accuracy: 0.6182\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6056 - accuracy: 0.6901 - val_loss: 0.6280 - val_accuracy: 0.6300\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6046 - accuracy: 0.6904 - val_loss: 0.6304 - val_accuracy: 0.6261\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6042 - accuracy: 0.6892 - val_loss: 0.6196 - val_accuracy: 0.6382\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6018 - accuracy: 0.6917 - val_loss: 0.6254 - val_accuracy: 0.6311\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5994 - accuracy: 0.6961 - val_loss: 0.6211 - val_accuracy: 0.6357\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5971 - accuracy: 0.6965 - val_loss: 0.6227 - val_accuracy: 0.6326\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5958 - accuracy: 0.6975 - val_loss: 0.6214 - val_accuracy: 0.6325\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5935 - accuracy: 0.6994 - val_loss: 0.6214 - val_accuracy: 0.6323\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5924 - accuracy: 0.6973 - val_loss: 0.6225 - val_accuracy: 0.6300\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5911 - accuracy: 0.7009 - val_loss: 0.6184 - val_accuracy: 0.6345\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5893 - accuracy: 0.7013 - val_loss: 0.6149 - val_accuracy: 0.6373\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5884 - accuracy: 0.7027 - val_loss: 0.6154 - val_accuracy: 0.6357\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5869 - accuracy: 0.7021 - val_loss: 0.6175 - val_accuracy: 0.6326\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5850 - accuracy: 0.7035 - val_loss: 0.6116 - val_accuracy: 0.6384\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5838 - accuracy: 0.7059 - val_loss: 0.6205 - val_accuracy: 0.6292\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5824 - accuracy: 0.7066 - val_loss: 0.6143 - val_accuracy: 0.6346\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5811 - accuracy: 0.7084 - val_loss: 0.6151 - val_accuracy: 0.6334\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.7332 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.7052 - accuracy: 0.5226 - val_loss: 0.7597 - val_accuracy: 0.1621\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6918 - accuracy: 0.5399 - val_loss: 0.7369 - val_accuracy: 0.2591\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6861 - accuracy: 0.5567 - val_loss: 0.7344 - val_accuracy: 0.3066\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6817 - accuracy: 0.5709 - val_loss: 0.7279 - val_accuracy: 0.3724\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6782 - accuracy: 0.5776 - val_loss: 0.7221 - val_accuracy: 0.4081\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6747 - accuracy: 0.5888 - val_loss: 0.7192 - val_accuracy: 0.4276\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6701 - accuracy: 0.5993 - val_loss: 0.7137 - val_accuracy: 0.4539\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6685 - accuracy: 0.6050 - val_loss: 0.7139 - val_accuracy: 0.4575\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6639 - accuracy: 0.6147 - val_loss: 0.7109 - val_accuracy: 0.4675\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6612 - accuracy: 0.6190 - val_loss: 0.7038 - val_accuracy: 0.4890\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6588 - accuracy: 0.6272 - val_loss: 0.7016 - val_accuracy: 0.4975\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6559 - accuracy: 0.6324 - val_loss: 0.6963 - val_accuracy: 0.5135\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6540 - accuracy: 0.6370 - val_loss: 0.6981 - val_accuracy: 0.5107\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6518 - accuracy: 0.6407 - val_loss: 0.6943 - val_accuracy: 0.5210\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6489 - accuracy: 0.6448 - val_loss: 0.6938 - val_accuracy: 0.5245\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6470 - accuracy: 0.6461 - val_loss: 0.6917 - val_accuracy: 0.5306\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6442 - accuracy: 0.6546 - val_loss: 0.6835 - val_accuracy: 0.5518\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6425 - accuracy: 0.6548 - val_loss: 0.6869 - val_accuracy: 0.5442\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6408 - accuracy: 0.6522 - val_loss: 0.6831 - val_accuracy: 0.5537\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6383 - accuracy: 0.6597 - val_loss: 0.6778 - val_accuracy: 0.5660\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6363 - accuracy: 0.6598 - val_loss: 0.6841 - val_accuracy: 0.5518\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6337 - accuracy: 0.6637 - val_loss: 0.6755 - val_accuracy: 0.5707\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6328 - accuracy: 0.6641 - val_loss: 0.6738 - val_accuracy: 0.5751\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6297 - accuracy: 0.6702 - val_loss: 0.6729 - val_accuracy: 0.5764\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6284 - accuracy: 0.6691 - val_loss: 0.6673 - val_accuracy: 0.5865\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6261 - accuracy: 0.6710 - val_loss: 0.6693 - val_accuracy: 0.5811\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6238 - accuracy: 0.6736 - val_loss: 0.6661 - val_accuracy: 0.5868\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6221 - accuracy: 0.6760 - val_loss: 0.6681 - val_accuracy: 0.5829\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6206 - accuracy: 0.6758 - val_loss: 0.6629 - val_accuracy: 0.5912\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6183 - accuracy: 0.6802 - val_loss: 0.6590 - val_accuracy: 0.5981\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6167 - accuracy: 0.6809 - val_loss: 0.6603 - val_accuracy: 0.5956\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6141 - accuracy: 0.6799 - val_loss: 0.6525 - val_accuracy: 0.6073\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6117 - accuracy: 0.6839 - val_loss: 0.6535 - val_accuracy: 0.6054\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6110 - accuracy: 0.6838 - val_loss: 0.6590 - val_accuracy: 0.5975\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6093 - accuracy: 0.6855 - val_loss: 0.6551 - val_accuracy: 0.6037\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6080 - accuracy: 0.6870 - val_loss: 0.6557 - val_accuracy: 0.6028\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6051 - accuracy: 0.6877 - val_loss: 0.6491 - val_accuracy: 0.6110\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6035 - accuracy: 0.6886 - val_loss: 0.6467 - val_accuracy: 0.6142\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6027 - accuracy: 0.6881 - val_loss: 0.6423 - val_accuracy: 0.6204\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6004 - accuracy: 0.6921 - val_loss: 0.6410 - val_accuracy: 0.6225\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5989 - accuracy: 0.6910 - val_loss: 0.6487 - val_accuracy: 0.6114\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5959 - accuracy: 0.6942 - val_loss: 0.6426 - val_accuracy: 0.6195\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5955 - accuracy: 0.6936 - val_loss: 0.6404 - val_accuracy: 0.6228\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5943 - accuracy: 0.6959 - val_loss: 0.6444 - val_accuracy: 0.6164\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5926 - accuracy: 0.6951 - val_loss: 0.6396 - val_accuracy: 0.6221\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5908 - accuracy: 0.6964 - val_loss: 0.6409 - val_accuracy: 0.6207\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5891 - accuracy: 0.6982 - val_loss: 0.6384 - val_accuracy: 0.6235\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5867 - accuracy: 0.7011 - val_loss: 0.6432 - val_accuracy: 0.6178\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5855 - accuracy: 0.7002 - val_loss: 0.6341 - val_accuracy: 0.6286\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5838 - accuracy: 0.7029 - val_loss: 0.6305 - val_accuracy: 0.6325\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.7359 - accuracy: 0.4558 - val_loss: 0.6751 - val_accuracy: 0.6699\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7070 - accuracy: 0.4819 - val_loss: 0.7135 - val_accuracy: 0.2784\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6978 - accuracy: 0.5064 - val_loss: 0.7186 - val_accuracy: 0.3122\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6925 - accuracy: 0.5277 - val_loss: 0.7154 - val_accuracy: 0.3898\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6882 - accuracy: 0.5452 - val_loss: 0.7096 - val_accuracy: 0.4386\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 1ms/step - loss: 0.6836 - accuracy: 0.5603 - val_loss: 0.7033 - val_accuracy: 0.4858\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5785 - val_loss: 0.6964 - val_accuracy: 0.5276\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6747 - accuracy: 0.5909 - val_loss: 0.6954 - val_accuracy: 0.5307\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6709 - accuracy: 0.6003 - val_loss: 0.6910 - val_accuracy: 0.5523\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6684 - accuracy: 0.6069 - val_loss: 0.6865 - val_accuracy: 0.5768\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6654 - accuracy: 0.6141 - val_loss: 0.6863 - val_accuracy: 0.5778\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6624 - accuracy: 0.6201 - val_loss: 0.6790 - val_accuracy: 0.5998\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6585 - accuracy: 0.6295 - val_loss: 0.6800 - val_accuracy: 0.5923\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6559 - accuracy: 0.6326 - val_loss: 0.6784 - val_accuracy: 0.5944\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6535 - accuracy: 0.6402 - val_loss: 0.6728 - val_accuracy: 0.6063\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6510 - accuracy: 0.6397 - val_loss: 0.6724 - val_accuracy: 0.6056\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6484 - accuracy: 0.6452 - val_loss: 0.6695 - val_accuracy: 0.6107\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6461 - accuracy: 0.6478 - val_loss: 0.6667 - val_accuracy: 0.6134\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6434 - accuracy: 0.6519 - val_loss: 0.6678 - val_accuracy: 0.6119\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6402 - accuracy: 0.6558 - val_loss: 0.6620 - val_accuracy: 0.6167\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6401 - accuracy: 0.6546 - val_loss: 0.6577 - val_accuracy: 0.6231\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6374 - accuracy: 0.6574 - val_loss: 0.6564 - val_accuracy: 0.6225\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6349 - accuracy: 0.6610 - val_loss: 0.6553 - val_accuracy: 0.6240\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6329 - accuracy: 0.6613 - val_loss: 0.6584 - val_accuracy: 0.6207\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6308 - accuracy: 0.6646 - val_loss: 0.6503 - val_accuracy: 0.6304\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6290 - accuracy: 0.6663 - val_loss: 0.6525 - val_accuracy: 0.6261\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6259 - accuracy: 0.6715 - val_loss: 0.6466 - val_accuracy: 0.6337\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6241 - accuracy: 0.6720 - val_loss: 0.6485 - val_accuracy: 0.6301\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6216 - accuracy: 0.6738 - val_loss: 0.6496 - val_accuracy: 0.6290\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6203 - accuracy: 0.6743 - val_loss: 0.6422 - val_accuracy: 0.6368\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6188 - accuracy: 0.6763 - val_loss: 0.6356 - val_accuracy: 0.6464\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6166 - accuracy: 0.6790 - val_loss: 0.6435 - val_accuracy: 0.6345\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6142 - accuracy: 0.6789 - val_loss: 0.6421 - val_accuracy: 0.6359\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6123 - accuracy: 0.6821 - val_loss: 0.6349 - val_accuracy: 0.6441\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6098 - accuracy: 0.6836 - val_loss: 0.6376 - val_accuracy: 0.6413\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6089 - accuracy: 0.6832 - val_loss: 0.6331 - val_accuracy: 0.6464\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6063 - accuracy: 0.6885 - val_loss: 0.6297 - val_accuracy: 0.6503\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6050 - accuracy: 0.6868 - val_loss: 0.6325 - val_accuracy: 0.6449\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6025 - accuracy: 0.6904 - val_loss: 0.6293 - val_accuracy: 0.6490\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6014 - accuracy: 0.6905 - val_loss: 0.6314 - val_accuracy: 0.6468\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6003 - accuracy: 0.6925 - val_loss: 0.6260 - val_accuracy: 0.6528\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5989 - accuracy: 0.6911 - val_loss: 0.6273 - val_accuracy: 0.6506\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5968 - accuracy: 0.6957 - val_loss: 0.6241 - val_accuracy: 0.6550\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5954 - accuracy: 0.6948 - val_loss: 0.6233 - val_accuracy: 0.6549\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5928 - accuracy: 0.6991 - val_loss: 0.6233 - val_accuracy: 0.6539\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5923 - accuracy: 0.6981 - val_loss: 0.6265 - val_accuracy: 0.6492\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5903 - accuracy: 0.7022 - val_loss: 0.6247 - val_accuracy: 0.6509\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5887 - accuracy: 0.7031 - val_loss: 0.6213 - val_accuracy: 0.6553\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5867 - accuracy: 0.7043 - val_loss: 0.6216 - val_accuracy: 0.6531\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5861 - accuracy: 0.7043 - val_loss: 0.6195 - val_accuracy: 0.6549\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.7267 - accuracy: 0.4922 - val_loss: 0.6859 - val_accuracy: 0.5142\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.7010 - accuracy: 0.5259 - val_loss: 0.7010 - val_accuracy: 0.4552\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6871 - accuracy: 0.5573 - val_loss: 0.6977 - val_accuracy: 0.5075\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5756 - val_loss: 0.6851 - val_accuracy: 0.5499\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6721 - accuracy: 0.5915 - val_loss: 0.6816 - val_accuracy: 0.5600\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6658 - accuracy: 0.6088 - val_loss: 0.6759 - val_accuracy: 0.5776\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6624 - accuracy: 0.6129 - val_loss: 0.6744 - val_accuracy: 0.5750\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6567 - accuracy: 0.6229 - val_loss: 0.6706 - val_accuracy: 0.5831\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6519 - accuracy: 0.6327 - val_loss: 0.6671 - val_accuracy: 0.5929\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6473 - accuracy: 0.6400 - val_loss: 0.6602 - val_accuracy: 0.6070\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6443 - accuracy: 0.6430 - val_loss: 0.6582 - val_accuracy: 0.6101\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6401 - accuracy: 0.6494 - val_loss: 0.6601 - val_accuracy: 0.6043\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6369 - accuracy: 0.6546 - val_loss: 0.6513 - val_accuracy: 0.6193\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6337 - accuracy: 0.6583 - val_loss: 0.6477 - val_accuracy: 0.6222\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6302 - accuracy: 0.6639 - val_loss: 0.6443 - val_accuracy: 0.6259\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6270 - accuracy: 0.6652 - val_loss: 0.6409 - val_accuracy: 0.6280\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6237 - accuracy: 0.6697 - val_loss: 0.6388 - val_accuracy: 0.6282\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6205 - accuracy: 0.6733 - val_loss: 0.6282 - val_accuracy: 0.6409\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6169 - accuracy: 0.6750 - val_loss: 0.6283 - val_accuracy: 0.6394\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6141 - accuracy: 0.6802 - val_loss: 0.6310 - val_accuracy: 0.6339\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6125 - accuracy: 0.6795 - val_loss: 0.6302 - val_accuracy: 0.6328\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6087 - accuracy: 0.6835 - val_loss: 0.6302 - val_accuracy: 0.6312\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6065 - accuracy: 0.6861 - val_loss: 0.6274 - val_accuracy: 0.6322\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6042 - accuracy: 0.6881 - val_loss: 0.6257 - val_accuracy: 0.6342\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 3s 1ms/step - loss: 0.6014 - accuracy: 0.6888 - val_loss: 0.6167 - val_accuracy: 0.6460\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6004 - accuracy: 0.6913 - val_loss: 0.6204 - val_accuracy: 0.6378\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5979 - accuracy: 0.6915 - val_loss: 0.6166 - val_accuracy: 0.6430\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5959 - accuracy: 0.6932 - val_loss: 0.6139 - val_accuracy: 0.6469\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5940 - accuracy: 0.6934 - val_loss: 0.6081 - val_accuracy: 0.6525\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5920 - accuracy: 0.6973 - val_loss: 0.6110 - val_accuracy: 0.6470\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5908 - accuracy: 0.6958 - val_loss: 0.6127 - val_accuracy: 0.6450\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5891 - accuracy: 0.6991 - val_loss: 0.6101 - val_accuracy: 0.6471\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5865 - accuracy: 0.7003 - val_loss: 0.6094 - val_accuracy: 0.6479\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5861 - accuracy: 0.7002 - val_loss: 0.6099 - val_accuracy: 0.6458\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5833 - accuracy: 0.7021 - val_loss: 0.6059 - val_accuracy: 0.6500\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5830 - accuracy: 0.7041 - val_loss: 0.6017 - val_accuracy: 0.6541\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5807 - accuracy: 0.7042 - val_loss: 0.6044 - val_accuracy: 0.6511\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5798 - accuracy: 0.7041 - val_loss: 0.5978 - val_accuracy: 0.6592\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5782 - accuracy: 0.7076 - val_loss: 0.6030 - val_accuracy: 0.6520\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5765 - accuracy: 0.7090 - val_loss: 0.6007 - val_accuracy: 0.6544\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 3s 1ms/step - loss: 0.5756 - accuracy: 0.7067 - val_loss: 0.6012 - val_accuracy: 0.6537\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5739 - accuracy: 0.7084 - val_loss: 0.6058 - val_accuracy: 0.6499\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5723 - accuracy: 0.7107 - val_loss: 0.5971 - val_accuracy: 0.6576\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5710 - accuracy: 0.7110 - val_loss: 0.6011 - val_accuracy: 0.6550\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5712 - accuracy: 0.7106 - val_loss: 0.5917 - val_accuracy: 0.6625\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5684 - accuracy: 0.7121 - val_loss: 0.6014 - val_accuracy: 0.6544\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5687 - accuracy: 0.7127 - val_loss: 0.5976 - val_accuracy: 0.6580\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5658 - accuracy: 0.7142 - val_loss: 0.5928 - val_accuracy: 0.6611\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5643 - accuracy: 0.7161 - val_loss: 0.5960 - val_accuracy: 0.6569\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5639 - accuracy: 0.7161 - val_loss: 0.5926 - val_accuracy: 0.6604\n"
     ]
    }
   ],
   "source": [
    "# 3. Variar noise_multiplier\n",
    "results_noise_multiplier = {}\n",
    "eps_noise_multiplier = {}\n",
    "for noise in noise_multiplier_values:\n",
    "    print(f\"\\nEntrenando modelo con noise_multiplier={noise}...\")\n",
    "    eps = compute_privacy_budget(n, batch_size, noise, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "        batch_size, epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=default_num_microbatches, l2_norm_clip=default_l2_norm_clip,\n",
    "        noise_multiplier=noise\n",
    "    )\n",
    "    results_noise_multiplier[noise] = compute_statistics(results)\n",
    "    eps_noise_multiplier[noise] = eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3e7267",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2772\\740446212.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstats_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{param}={value} (ε={eps_num_microbatches.get(value, eps_l2_norm_clip.get(value, eps_noise_multiplier[value])):.2f})'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{model} (mean)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{model} (min)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "# Guardar resultados en un CSV\n",
    "results_stats = {\n",
    "    'num_microbatches': results_num_microbatches,\n",
    "    'l2_norm_clip': results_l2_norm_clip,\n",
    "    'noise_multiplier': results_noise_multiplier\n",
    "}\n",
    "data = {}\n",
    "for param, stats_dict in results_stats.items():\n",
    "    for value, stats in stats_dict.items():\n",
    "        model = f'{param}={value} (ε={eps_num_microbatches.get(value, eps_l2_norm_clip.get(value, eps_noise_multiplier[value])):.2f})'\n",
    "        data[f'{model} (mean)'] = stats['mean']\n",
    "        data[f'{model} (min)'] = stats['min']\n",
    "        data[f'{model} (max)'] = stats['max']\n",
    "results_df = pd.DataFrame(data).round(4)\n",
    "results_df.to_csv('results/CDP_parameter_results.csv')\n",
    "print(\"\\nResultados guardados en 'results/CDP_parameter_results.csv'\")\n",
    "print(\"\\nResultados (Promedios):\\n\", results_df[[col for col in results_df.columns if 'mean' in col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2ee373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar resultados, incluyendo el modelo sin DP\n",
    "def plot_parameter_results(stats_dict, eps_dict, param_name, colors, no_dp_stats):\n",
    "    metrics = list(no_dp_stats['mean'].keys())\n",
    "    values = list(stats_dict.keys())\n",
    "    n_metrics = len(metrics)\n",
    "    n_values = len(values) + 1  # +1 para incluir No DP\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x_positions = np.arange(n_metrics)\n",
    "    \n",
    "    # Primero, graficar el modelo sin DP (No DP)\n",
    "    means = []\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    for metric in metrics:\n",
    "        means.append(no_dp_stats['mean'][metric])\n",
    "        mins.append(no_dp_stats['min'][metric])\n",
    "        maxs.append(no_dp_stats['max'][metric])\n",
    "    \n",
    "    plt.scatter(x_positions + (0 - (n_values-1)/2) * 0.15, means, \n",
    "                color=colors[0], label='No DP', s=100)\n",
    "    for metric_idx in range(n_metrics):\n",
    "        plt.vlines(x_positions[metric_idx] + (0 - (n_values-1)/2) * 0.15, \n",
    "                   mins[metric_idx], maxs[metric_idx], \n",
    "                   color=colors[0], linestyle='-', linewidth=1)\n",
    "    \n",
    "    # Luego, graficar los resultados variando el parámetro\n",
    "    for value_idx, value in enumerate(values, start=1):  # start=1 para saltar el color azul\n",
    "        means = []\n",
    "        mins = []\n",
    "        maxs = []\n",
    "        for metric in metrics:\n",
    "            means.append(stats_dict[value]['mean'][metric])\n",
    "            mins.append(stats_dict[value]['min'][metric])\n",
    "            maxs.append(stats_dict[value]['max'][metric])\n",
    "        \n",
    "        plt.scatter(x_positions + (value_idx - (n_values-1)/2) * 0.15, means, \n",
    "                    color=colors[value_idx], label=f'{param_name}={value} (ε={eps_dict[value]:.2f})', s=100)\n",
    "        for metric_idx in range(n_metrics):\n",
    "            plt.vlines(x_positions[metric_idx] + (value_idx - (n_values-1)/2) * 0.15, \n",
    "                       mins[metric_idx], maxs[metric_idx], \n",
    "                       color=colors[value_idx], linestyle='-', linewidth=1)\n",
    "    \n",
    "    plt.xticks(x_positions, metrics, rotation=45)\n",
    "    plt.title(f'Effect of Varying {param_name} on Model Performance')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(title=f'{param_name} Values', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/Effect_of_{param_name}_with_No_DP.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f31c0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAAJOCAYAAAD2/c3/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3xN9//A8dfNvtmJkAQRkQThZ8QOYoao0aUoasYWo6pIEatFtdQqaY0SNVrVVova42tTJFqJiBm1K0hCJJJ7fn+kOXVl3UQI+n4+HvfR5nPO+Xze59wR953P5300iqIoCCGEEEIIIYQQQghRyIyKOgAhhBBCCCGEEEII8WqSxJMQQgghhBBCCCGEeCYk8SSEEEIIIYQQQgghnglJPAkhhBBCCCGEEEKIZ0IST0IIIYQQQgghhBDimZDEkxBCCCGEEEIIIYR4JiTxJIQQQgghhBBCCCGeCUk8CSGEEEIIIYQQQohnQhJPQgghhBBCCCGEEOKZkMSTEEUgKSmJPn364OLigkajYfjw4QDcuHGDd955h2LFiqHRaJg9e3aRxpkfOZ3Ty6Js2bL07NmzqMP4z7h48SIajYZly5Y997HLli1L27Ztn/u4OenZsyfW1tZFHcZ/wsSJE9FoNAU6tmfPnpQtW7ZwA3pKL/PvDCGEEEL8d0jiSYhCsmzZMjQaTY6PQ4cOqftOnTqVZcuWMXDgQFasWEG3bt0AeP/999myZQshISGsWLGCVq1aFXqcU6dO5eeff34m/WZ3To87fvw4Go2GcePG5dhPbGwsGo2GESNGFHqMQjwLV69eZeLEiURERBR1KC+NsmXLotFoCAgIyHb7okWL1M/O33///TlH93SaNGmi99nv6OhI7dq1Wbp0KTqdrlDHeh6/M4QQQgghnpZJUQcgxKtm8uTJeHh4ZGn38vJS/3/nzp3Uq1ePCRMm6O2zc+dO3njjDUaOHPnM4ps6dSrvvPMOb775ZqH2m9M5Pa5GjRpUrFiR1atX8/HHH2e7z6pVqwB47733CjW+vMTExGBkJLn458Xd3Z3k5GRMTU2LOpSndvXqVSZNmkTZsmWpXr16UYfz0rCwsGDXrl1cv34dFxcXvW0rV67EwsKChw8fFlF0T6d06dJMmzYNgFu3bhEeHk5QUBBnzpxh+vTphTbO8/idIYQQQgjxtORblhCF7LXXXuO9997L8nByclL3uXnzJvb29lmOzan9ZWBo7F27duX8+fN6M8Aet3r1aipWrEiNGjWeKp4HDx7ka39zc/NXIgnystBoNFhYWGBsbPzUfd2/f78QIhLPW4MGDbC2tua7777Ta//rr7/Yu3cvbdq0KaLInp6dnZ362f/++++zf/9+Spcuzfz583n06NFT9Z2WlkZqaipQ+L8zHj58WOizsoQQQgghJPEkxHO0e/duNBoNFy5cYOPGjepSjMxleoqi8OWXX6rtme7evcvw4cNxc3PD3NwcLy8vPv300yxfEHQ6HXPmzKFKlSpYWFhQvHhxWrVqpS5V0Wg03L9/n+XLl6tj5FXX6ObNmwQFBeHs7IyFhQXVqlVj+fLleZ7TxYsXs+2va9euwL8zmx537NgxYmJi1H3Wr19PmzZtKFmyJObm5nh6ejJlyhTS09P1jmvSpAn/93//x7Fjx2jUqBGWlpZ89NFH9OjRAycnp2y/6LVs2ZIKFSqoPz9Z4ynzOdm/fz8jRoygePHiWFlZ8dZbb3Hr1i29vnQ6HRMnTqRkyZJYWlrStGlToqKiDKoblVnr6PPPP+frr7/G09MTc3NzateuzdGjR7OcZ5MmTbL08WTtmcf7/PLLLylXrhyWlpa0bNmSy5cvoygKU6ZMoXTp0mi1Wt544w3i4+NzjfNJmbVyzpw5w3vvvYednR3Fixdn/PjxKIrC5cuXeeONN7C1tcXFxYWZM2dme95P1ng6ffo0HTt2pHjx4mi1WipUqMDYsWOzjBsVFUWXLl1wcHCgYcOGQMYX8ilTpqjXsGzZsnz00UekpKRkew5bt26levXqWFhYUKlSJX788Ue97fHx8YwcOZIqVapgbW2Nra0tr732GpGRkeo+u3fvpnbt2gD06tVL7z2d6fDhw7Ru3RoHBwesrKyoWrUqc+bMyRLPlStXePPNN7G2tqZ48eKMHDkyy2tdp9Mxe/ZsKleujIWFBc7OzvTv3587d+7o7ff7778TGBiIk5MTWq0WDw8Pevfune11eNKCBQuoXLky5ubmlCxZksGDB3P37l29fTLfc1FRUTRt2hRLS0tKlSrFjBkzDBoDMmY8vf3221k+C1avXo2DgwOBgYHZHrdz5078/f2xsrLC3t6eN954g+jo6Cz77du3j9q1a2NhYYGnpydfffVVjrF8++231KxZE61Wi6OjI++++y6XL182+FzyYmlpSb169bh//776+WHI5/rj7+XZs2err+0FCxbk+jvj/PnzdOjQAUdHR3XsjRs36sWU+dm9Zs0axo0bR6lSpbC0tCQhIUGtOxYXF0fbtm2xtramVKlSfPnllwD88ccfNGvWDCsrK9zd3bM8h4a8dx6P4fvvv+eTTz6hdOnSWFhY0Lx5c86ePZvlOhryXjp9+jTvvPMOjo6OWFhYUKtWLX755ZcCPGtCCCGEKCyy1E6IQnbv3j3+/vtvvTaNRkOxYsXw8fFhxYoVvP/++5QuXZoPPvgAAF9fX7UuUosWLejevbt67IMHD2jcuDFXrlyhf//+lClThgMHDhASEsK1a9f0iskGBQWxbNkyXnvtNfr06UNaWhp79+7l0KFD1KpVixUrVtCnTx/q1KlDv379APD09MzxXJKTk2nSpAlnz54lODgYDw8P1q5dS8+ePbl79y7Dhg3L8ZyKFy+ebZ8eHh7Ur1+f77//ni+++EJvxkvml5cuXboAGckfa2trRowYgbW1NTt37iQ0NJSEhAQ+++wzvX5v377Na6+9xrvvvst7772Hs7MzVlZWhIeHs2XLFr1i0tevX2fnzp25LgvMNGTIEBwcHJgwYQIXL15k9uzZBAcH683SCAkJYcaMGbRr147AwEAiIyMJDAzM1zKhVatWkZiYSP/+/dFoNMyYMYO3336b8+fPF3gm1sqVK0lNTWXIkCHEx8czY8YMOnbsSLNmzdi9ezejR4/m7NmzzJs3j5EjR7J06dJ8j9GpUyd8fHyYPn06Gzdu5OOPP8bR0ZGvvvqKZs2a8emnn7Jy5UpGjhxJ7dq1adSoUY59nTx5En9/f0xNTenXrx9ly5bl3Llz/Prrr3zyySd6+3bo0AFvb2+mTp2KoigA9OnTh+XLl/POO+/wwQcfcPjwYaZNm0Z0dDQ//fST3vGxsbF06tSJAQMG0KNHD7755hs6dOjA5s2badGiBZDx5f3nn3+mQ4cOeHh4cOPGDb766isaN25MVFQUJUuWxMfHh8mTJxMaGkq/fv3w9/cHoH79+gBs27aNtm3b4urqyrBhw3BxcSE6OpoNGzYwbNgwNZ709HQCAwOpW7cun3/+Odu3b2fmzJl4enoycOBAdb/+/fuzbNkyevXqxdChQ7lw4QLz58/nxIkT7N+/H1NTU27evEnLli0pXrw4Y8aMwd7enosXL2ZJrGVn4sSJTJo0iYCAAAYOHEhMTAwLFy7k6NGjav+Z7ty5Q6tWrXj77bfp2LEjP/zwA6NHj6ZKlSq89tpreY4FGe/1li1bcu7cOfWzaNWqVbzzzjvZvu63b9/Oa6+9Rrly5Zg4cSLJycnMmzePBg0acPz4cTUB+8cff6jXYOLEiaSlpTFhwgScnZ2z9PnJJ58wfvx4OnbsSJ8+fbh16xbz5s2jUaNGnDhxotBmFJ0/fx5jY2Ps7e3z9bkO8M033/Dw4UP69euHubk5NWrUyPF3xo0bN6hfvz4PHjxg6NChFCtWjOXLl/P666/zww8/8NZbb+n1PWXKFMzMzBg5ciQpKSmYmZkBGa/J1157jUaNGjFjxgxWrlxJcHAwVlZWjB07lq5du/L2228TFhZG9+7d8fPzU5eZG/Leedz06dMxMjJi5MiR3Lt3jxkzZtC1a1cOHz6s7mPIe+nUqVM0aNCAUqVKMWbMGKysrPj+++958803WbduXZZzF0IIIcRzogghCsU333yjANk+zM3N9fZ1d3dX2rRpk6UPQBk8eLBe25QpUxQrKyvlzJkzeu1jxoxRjI2Nlbi4OEVRFGXnzp0KoAwdOjRLvzqdTv1/KysrpUePHgad0+zZsxVA+fbbb9W21NRUxc/PT7G2tlYSEhLyPKfsfPnllwqgbNmyRW1LT09XSpUqpfj5+altDx48yHJs//79FUtLS+Xhw4dqW+PGjRVACQsL09s3PT1dKV26tNKpUye99lmzZikajUY5f/68XvyPX5fM5zMgIEDv+r3//vuKsbGxcvfuXUVRFOX69euKiYmJ8uabb+qNMXHiRAXI81pfuHBBAZRixYop8fHxavv69esVQPn111/1zrNx48ZZ+ujRo4fi7u6epc/ixYurcSqKooSEhCiAUq1aNeXRo0dqe+fOnRUzMzO9a5qXCRMmKIDSr18/tS0tLU0pXbq0otFolOnTp6vtd+7cUbRard61yIzxm2++UdsaNWqk2NjYKJcuXdIb6/Hrnzlu586d9faJiIhQAKVPnz567SNHjlQAZefOnWqbu7u7Aijr1q1T2+7du6e4uroqvr6+atvDhw+V9PR0vf4uXLigmJubK5MnT1bbjh49muVcMq+Hh4eH4u7urty5cyfHc+rRo4cC6PWpKIri6+ur1KxZU/157969CqCsXLlSb7/Nmzfrtf/0008KoBw9elTJj5s3bypmZmZKy5Yt9c57/vz5CqAsXbpUbct8z4WHh6ttKSkpiouLi9K+ffs8x8r8vEhLS1NcXFyUKVOmKIqiKFFRUQqg7NmzR30PPn4e1atXV0qUKKHcvn1bbYuMjFSMjIyU7t27q21vvvmmYmFhofdaioqKUoyNjZXH/+lz8eJFxdjYWPnkk0/04vvjjz8UExMTvfYn32c5ady4sVKxYkXl1q1byq1bt5To6Ghl6NChCqC0a9dOURTDP9cz3ye2trbKzZs3s4yV3e+M4cOHK4Cyd+9etS0xMVHx8PBQypYtqz63u3btUgClXLlyWT5rM1+TU6dOVdsy38cajUZZs2aN2n769GkFUCZMmKC2GfreyYzBx8dHSUlJUdvnzJmjAMoff/yhKIrh76XmzZsrVapU0fss0+l0Sv369RVvb+8s108IIYQQz4cstROikH355Zds27ZN7/Hbb78VuL+1a9fi7++Pg4MDf//9t/oICAggPT2d//3vfwCsW7cOjUaT7Syegt4+fNOmTbi4uNC5c2e1zdTUlKFDh5KUlMSePXsK1G+nTp0wNTXVW56xZ88erly5oi6zA9Bqter/JyYm8vfff+Pv78+DBw84ffq0Xp/m5ub06tVLr83IyIiuXbvyyy+/kJiYqLavXLmS+vXrZ1sE/kn9+vXTu37+/v6kp6dz6dIlAHbs2EFaWhqDBg3SO27IkCF59v24Tp064eDgoDcOZMwcKKgOHTpgZ2en/ly3bl0go3C7iYmJXntqaipXrlzJ9xh9+vRR/9/Y2JhatWqhKApBQUFqu729PRUqVMj1XG7dusX//vc/evfuTZkyZfS2Zff6HTBggN7PmzZtAshyN8TMGXhPLjMqWbKk3uwHW1tbunfvzokTJ7h+/TqQ8ZrKLDifnp7O7du3sba2pkKFChw/fjzHc8l04sQJLly4wPDhw7PMmjHknPz9/fWu2dq1a7Gzs6NFixZ6nwU1a9bE2tqaXbt2AahjbdiwIV/1hLZv305qairDhw/XK7Tft29fbG1ts1xDa2trvZsAmJmZUadOnXy9Zo2NjenYsSOrV68GMt6bbm5u6uv/cdeuXSMiIoKePXvi6OiotletWpUWLVqor4H09HS2bNnCm2++qfda8vHxybJ878cff0Sn09GxY0e9a+ri4oK3t7d6TfPr9OnTFC9enOLFi+Pj48O8efNo06aNOqvQ0M/1TO3bt89xFumTNm3aRJ06ddQlqJDxXPXr14+LFy8SFRWlt3+PHj30Pmsf9/j7O/N9bGVlRceOHdX2ChUqYG9vr/e85/e906tXL3WmFWT9/DPkvRQfH8/OnTvp2LGj+vvi77//5vbt2wQGBhIbG1ugzzghhBBCPD1ZaidEIatTpw61atUqtP5iY2M5efJkjl86bt68CcC5c+coWbKk3heyp3Xp0iW8vb2z3O3Nx8dH3V4QxYoVIzAwkJ9++omwsDAsLCxYtWoVJiYmel9oTp06xbhx49i5cycJCQl6fdy7d0/v51KlSul9ccnUvXt3Pv30U3766Se6d+9OTEwMx44dIywszKBYn0yCZCaHMmvqZF6Dx+9aCODo6KiXSHracQriyT4zk1Bubm7ZthdkrOzGsLCw0Cumn9l++/btHPvJ/IL5f//3fwaN+2TS8NKlSxgZGWV5HlxcXLC3t8/yWvXy8sqS/ClfvjyQUVfHxcVFrZm2YMECLly4oFdvqVixYnnGeO7cOYPPKbMm2+McHBz0npPY2Fju3btHiRIlsu0j87OgcePGtG/fnkmTJvHFF1/QpEkT3nzzTbp06YK5uXmOMWReo8drn0FGQqlcuXJZrmHp0qWzXEMHBwdOnjyZx9nq69KlC3PnziUyMpJVq1bx7rvvZpuYyyk+yPhM2rJlC/fv3ycxMZHk5GS8vb2z7FehQgU1QQUZ11RRlGz3BQq8zLVs2bIsWrRILaLv7e2t97wZ+rmeyZAkeaZLly6pSebHPf65/fhrMqe+s3tN2tnZZfu829nZ6b1W8/veyevzz5D30tmzZ1EUhfHjxzN+/Phs97l58yalSpXKsQ8hhBBCPBuSeBLiBafT6WjRogWjRo3Kdnvml+WXzXvvvceGDRvYsGEDr7/+OuvWrVNrskBG4d3GjRtja2vL5MmT8fT0xMLCguPHjzN69OgshdVz+ot9pUqVqFmzJt9++y3du3fn22+/xczMTC/BlZuc7rqm/FNXqLAYMk5mMeEnPVmAOq8+C/OcsuvreVyznJ7vgs7uy87UqVMZP348vXv3ZsqUKTg6OmJkZMTw4cML/c5fhtzdT6fTUaJECVauXJnt9sz3jkaj4YcffuDQoUP8+uuvbNmyhd69ezNz5kwOHTqEtbX1M405v89z3bp18fT0ZPjw4Vy4cEGt8fY86HQ6NBoNv/32W7bnU9BrZWVlRUBAQK7j5udzPafXe2HIqe+n+fzI73unMF5Lmf2OHDkyx8L0TyamhRBCCPF8SOJJiBecp6cnSUlJuX6Jydxvy5YtxMfH5zrrKT9fzN3d3Tl58iQ6nU5v1lPmMjd3d3eD+3rS66+/jo2NDatWrcLU1JQ7d+7oLbPbvXs3t2/f5scff9QrSH3hwoV8j9W9e3dGjBjBtWvXWLVqFW3atMnXbKTcZF6Ds2fP6s0cuH379lPNVsqOg4NDtsuYCjrz7EVSrlw5AP78888CHe/u7o5OpyM2Nlad2QEZhZbv3r2b5bWaOTvi8ffDmTNnANQC1T/88ANNmzZlyZIlesfevXtXb0ZXTu+pzGLZf/75Z57vX0N4enqyfft2GjRoYFAiol69etSrV49PPvmEVatW0bVrV9asWaO3fOpxmdcoJiZGfT4AUlNTuXDhQqGcQ046d+7Mxx9/jI+PD9WrV88zviedPn0aJycnrKyssLCwQKvVEhsbm2W/J4/19PREURQ8PDyeaxLf0M/1gnB3d8/xGmVuf9YMfe8YypD3UuZr1tTU9Jm+VoUQQgiRf1LjSYgXXMeOHTl48CBbtmzJsu3u3bukpaUBGTVAFEVh0qRJWfZ7/K/GVlZWWW6NnpPWrVtz/fp1vTu4paWlMW/ePKytrWncuHE+z+ZfWq2Wt956i02bNrFw4UKsrKx444031O2ZfwF/PPbU1FQWLFiQ77E6d+6MRqNh2LBhnD9/Xq8uzdNq3rw5JiYmLFy4UK99/vz5hTZGJk9PT06fPq3ejh0gMjKS/fv3F/pYz1vx4sVp1KgRS5cuJS4uTm+bIbMeWrduDZDlbmCzZs0CoE2bNnrtV69e1bvTXUJCAuHh4VSvXh0XFxcg4zX45Nhr167NUifGysoKIMv7qkaNGnh4eDB79uws2woy+6tjx46kp6czZcqULNvS0tLUMe7cuZOl/8xkTkpKSo79BwQEYGZmxty5c/WOX7JkCffu3ctyDQtTnz59mDBhAjNnzsxxH1dXV6pXr87y5cv1rueff/7J1q1b1deAsbExgYGB/Pzzz3qvpejo6Cyfo2+//TbGxsZMmjQpyzVTFCXX5aFPw9DP9YJo3bo1R44c4eDBg2rb/fv3+frrrylbtiyVKlUqcN+GMvS9YyhD3kslSpSgSZMmfPXVV1y7di1LH49/bgohhBDi+ZIZT0IUst9++y1L4WvIuL3647MIDPXhhx/yyy+/0LZtW3r27EnNmjW5f/8+f/zxBz/88AMXL17EycmJpk2b0q1bN+bOnUtsbCytWrVCp9Oxd+9emjZtSnBwMAA1a9Zk+/btzJo1i5IlS+Lh4ZFtPRDIKKz91Vdf0bNnT44dO0bZsmX54Ycf2L9/P7Nnz8bGxibf5/O49957j/DwcLZs2ULXrl3VL/CQcb0cHBzo0aMHQ4cORaPRsGLFigJ9YS9evDitWrVi7dq12NvbF+oXaGdnZ4YNG8bMmTN5/fXXadWqFZGRkfz22284OTkV6tKv3r17M2vWLAIDAwkKCuLmzZuEhYVRuXLlLDWwXkZz586lYcOG1KhRg379+uHh4cHFixfZuHEjERERuR5brVo1evTowddff60u0zxy5AjLly/nzTffpGnTpnr7ly9fnqCgII4ePYqzszNLly7lxo0bfPPNN+o+bdu2ZfLkyfTq1Yv69evzxx9/sHLlyizvY09PT+zt7QkLC8PGxgYrKyvq1q2Lh4cHCxcupF27dlSvXp1evXrh6urK6dOnOXXqVLZJh9w0btyY/v37M23aNCIiImjZsiWmpqbExsaydu1a5syZwzvvvMPy5ctZsGABb731Fp6eniQmJrJo0SJsbW3V5Ex2ihcvTkhICJMmTaJVq1a8/vrrxMTEsGDBAmrXrl2oCdsnubu7M3HixDz3++yzz3jttdfw8/MjKCiI5ORk5s2bh52dnd7xkyZNYvPmzfj7+zNo0CA1YV65cmW9GlSenp58/PHHhISEcPHiRd58801sbGy4cOECP/30E/369WPkyJGFfr6Gfq4XxJgxY1i9ejWvvfYaQ4cOxdHRkeXLl3PhwgXWrVuXpWbfs2Doe8dQRkZGBr2XvvzySxo2bEiVKlXo27cv5cqV48aNGxw8eJC//vqLyMjIwjxNIYQQQhhIEk9CFLLQ0NBs27/55psC/aPb0tKSPXv2MHXqVNauXUt4eDi2traUL1+eSZMm6d217JtvvqFq1aosWbKEDz/8EDs7O2rVqkX9+vXVfWbNmkW/fv0YN24cycnJ9OjRI8fEk1arZffu3YwZM4bly5eTkJBAhQoV+Oabb+jZs2e+z+VJzZo1w9XVlWvXrukts4OMArQbNmzggw8+YNy4cTg4OPDee+/RvHnzHOt35KZ79+5s2LCBjh075lpguSA+/fRTLC0tWbRoEdu3b8fPz4+tW7fSsGFDLCwsCm0cHx8fwsPDCQ0NZcSIEVSqVIkVK1awatUqdu/eXWjjFJVq1apx6NAhxo8fz8KFC3n48CHu7u4G1+NavHgx5cqVY9myZfz000+4uLgQEhKS7Z0evb29mTdvHh9++CExMTF4eHjw3Xff6b22PvroI+7fv8+qVav47rvvqFGjBhs3bmTMmDF6fZmamrJ8+XJCQkIYMGAAaWlpfPPNN3h4eBAYGMiuXbuYNGkSM2fORKfT4enpSd++fQt0jcLCwqhZsyZfffUVH330ESYmJpQtW5b33nuPBg0aAKhJtzVr1nDjxg3s7OyoU6cOK1euzLNI9cSJEylevDjz58/n/fffx9HRkX79+jF16tQCF9ouTAEBAWzevJkJEyYQGhqKqakpjRs35tNPP9U7t6pVq7JlyxZGjBhBaGgopUuXZtKkSVy7di1L8fMxY8ZQvnx5vvjiC3XGqJubGy1btuT1119/JueRn8/1/HJ2dubAgQOMHj2aefPm8fDhQ6pWrcqvv/76TGetPc7Q905+GPJeqlSpEr///juTJk1i2bJl3L59mxIlSuDr65vj72YhhBBCPHsapbAr5AohxAto/fr1vPnmm/zvf//L9lbthe3u3bs4ODjw8ccfM3bs2Gc+nhBCCCGEEEK8iKTGkxDiP2HRokWUK1eOhg0bFnrfycnJWdoyaw01adKk0McTQgghhBBCiJeFLLUTQrzS1qxZw8mTJ9m4cSNz5swp1JpLmb777juWLVtG69atsba2Zt++faxevZqWLVuqy59eFklJSSQlJeW6T/HixXO8/bkQQgghhBBCPE6W2gkhXmkajQZra2s6depEWFgYJiaFn28/fvw4o0aNIiIigoSEBJydnWnfvj0ff/wx1tbWhT7eszRx4sRs74z4uAsXLlC2bNnnE5AQQgghhBDipSaJJyGEEKrz589z/vz5XPcp7KLpQgghhBBCiFeXJJ6EEEIIIYQQQgghxDMhxcWFEEIIIYQQQgghxDPxnysurtPpuHr1KjY2Ns+kyLAQQgghhBDi1aYoComJiZQsWRIjI/lbvhBC5OY/l3i6evUqbm5uRR2GEEIIIYQQ4iV3+fJlSpcuXdRhCCHEC+0/l3iysbEBMn5J2NraFnE0QgghhBBCiJdNQkICbm5u6ncLIYQQOfvPJZ4yl9fZ2tpK4kkIIYQQQghRYFK6Qwgh8iYLkoUQQgghhBBCCCHEMyGJJyGEEEIIIYQQQgjxTEjiSQghhBBCCCGEEEI8E/+5Gk9CCCGEEEII8V+Xnp7Oo0ePijoMIcRLytTUFGNjY4P2lcSTEEIIIYQQQvxHKIrC9evXuXv3blGHIoR4ydnb2+Pi4pLnjRYk8SSEEEIIIYQQ/xGZSacSJUpgaWkpd+YTQuSboig8ePCAmzdvAuDq6prr/pJ4EkIIIYQQQoj/gPT0dDXpVKxYsaIORwjxEtNqtQDcvHmTEiVK5LrsToqLCyGEEEIIIcR/QGZNJ0tLyyKORAjxKsj8LMmrXpwknoQQQgghhBDiP0SW1wkhCoOhnyWSeBJCCCGEEEIIIYQQz4QknoqQoijcTnjIpRuJ3E54iKIoRR2SEEIIIYQQQojnZPfu3Wg0mmd+l8EmTZowfPjwZzpGdi5evIhGoyEiIuK5j/00li1bhr29fVGH8cqQxFMRuJuUwoJfT1F9wDo8uq2mSr8f8Oi2muoD1rHg11PcTUop6hCFEEIIIYQQQjxj9evX59q1a9jZ2RV1KHl6Xkmyp7Fu3TqMjY25cuVKttu9vb0ZMWLEc45KSOLpOdt+/Ao+Qd8TsuQIF28k6m27eCORkCVH8An6nu3Hs3+jCCGEEEIIIYR4NZiZmeHi4lLgulupqamFHNHL7fXXX6dYsWIsX748y7b//e9/nD17lqCgoCKI7L9NEk/P0fbjV+gwZRvJKWkoCjy5si6zLTkljQ5TtknySQghhBBCCCGe0KRJE4YOHcqoUaNwdHTExcWFiRMnqtuzW9519+5dNBoNu3fvBv6dvbNlyxZ8fX3RarU0a9aMmzdv8ttvv+Hj44OtrS1dunThwYMHBsc1ZMgQhg8fjoODA87OzixatIj79+/Tq1cvbGxs8PLy4rffflOPyW4W0f79+2nSpAmWlpY4ODgQGBjInTt31DGCg4MZPnw4Tk5OBAYGArBnzx7q1KmDubk5rq6ujBkzhrS0NL340tLSCA4Oxs7ODicnJ8aPH69X7mXFihXUqlULGxsbXFxc6NKlCzdv3lSvadOmTQFwcHBAo9HQs2dPAHQ6HTNmzMDLywtzc3PKlCnDJ598ojf2+fPnadq0KZaWllSrVo2DBw/qbd+3bx/+/v5otVrc3NwYOnQo9+/fV7cvWLAAb29vLCwscHZ25p133sn2OTA1NaVbt24sW7Ysy7alS5dSt25dKleuzKxZs6hSpQpWVla4ubkxaNAgkpKSsu0ToGfPnrz55pt6bcOHD6dJkybqzzqdjmnTpuHh4YFWq6VatWr88MMP6vY7d+7QtWtXihcvjlarxdvbm2+++SbHMV8lRZ54+vLLLylbtiwWFhbUrVuXI0eO5Ljvo0ePmDx5Mp6enlhYWFCtWjU2b978HKMtuLtJKXT7dCeKoqDLo5STTsmo/9Tt052y7E4IIYQQQgghnrB8+XKsrKw4fPgwM2bMYPLkyWzbti3f/UycOJH58+dz4MABLl++TMeOHZk9ezarVq1i48aNbN26lXnz5uUrLicnJ44cOcKQIUMYOHAgHTp0oH79+hw/fpyWLVvSrVu3HJNZERERNG/enEqVKnHw4EH27dtHu3btSE9P1xvDzMyM/fv3ExYWxpUrV2jdujW1a9cmMjKShQsXsmTJEj7++OMssZmYmHDkyBHmzJnDrFmzWLx4sbr90aNHTJkyhcjISH7++WcuXryoJpfc3NxYt24dADExMVy7do05c+YAEBISwvTp0xk/fjxRUVGsWrUKZ2dnvbHHjh3LyJEjiYiIoHz58nTu3FlNjJ07d45WrVrRvn17Tp48yXfffce+ffsIDg4G4Pfff2fo0KFMnjyZmJgYNm/eTKNGjXJ8DoKCgoiNjeV///uf2paUlMQPP/ygznYyMjJi7ty5nDp1iuXLl7Nz505GjRqV8xNrgGnTphEeHk5YWBinTp3i/fff57333mPPnj0A6vX57bffiI6OZuHChTg5OT3VmC8NpQitWbNGMTMzU5YuXaqcOnVK6du3r2Jvb6/cuHEj2/1HjRqllCxZUtm4caNy7tw5ZcGCBYqFhYVy/Phxg8e8d++eAij37t0rrNMwyJe//KnYvrFUsXnd8IftG0uVBb+ceq5xCiGEEEIIIXJXVN8pnlZycrISFRWlJCcnF3UoT6Vx48ZKw4YN9dpq166tjB49WlEURblw4YICKCdOnFC337lzRwGUXbt2KYqiKLt27VIAZfv27eo+06ZNUwDl3Llzalv//v2VwMDAAsWVlpamWFlZKd26dVPbrl27pgDKwYMH9eK4c+eOoiiK0rlzZ6VBgwa5juHr66vX9tFHHykVKlRQdDqd2vbll18q1tbWSnp6unqcj4+P3j6jR49WfHx8chzr6NGjCqAkJiZmG6uiKEpCQoJibm6uLFq0KNs+Mp+LxYsXq22nTp1SACU6OlpRFEUJCgpS+vXrp3fc3r17FSMjIyU5OVlZt26dYmtrqyQkJOQY65Pq1aun9OjRQ/15yZIliqWlZY59rF27VilWrJj68zfffKPY2dmpP/fo0UN544039I4ZNmyY0rhxY0VRFOXhw4eKpaWlcuDAAb19goKClM6dOyuKoijt2rVTevXqZfA5vAwM/Uwp0hlPs2bNom/fvvTq1YtKlSoRFhaGpaUlS5cuzXb/FStW8NFHH9G6dWvKlSvHwIEDad26NTNnznzOkeePoih8tSEaCnDTurANUXK3OyGEEEIIIYR4TNWqVfV+dnV1VZeFFbQfZ2dnLC0tKVeunF5bfvp9vD9jY2OKFStGlSpV9PoDcuwzc8ZTbmrWrKn3c3R0NH5+fnp1oho0aEBSUhJ//fWX2lavXj29ffz8/IiNjVVnUx07dox27dpRpkwZbGxsaNy4MQBxcXE5xhIdHU1KSkqeMT9+XVxdXYF/r0FkZCTLli3D2tpafQQGBqLT6bhw4QItWrTA3d2dcuXK0a1bN1auXJnn8sfevXvzww8/kJiYUVd56dKldOjQARsbGwC2b99O8+bNKVWqFDY2NnTr1o3bt28bvKzySWfPnuXBgwe0aNFC7zzCw8M5d+4cAAMHDmTNmjVUr16dUaNGceDAgQKN9TIqssRTamoqx44dIyAg4N9gjIwICAjIst4zU0pKChYWFnptWq2Wffv2PdNYn1Z8YgoXrifmO++kKHDheiLxibLcTgghhBBCCCEymZqa6v2s0WjQ6XRAxvdKQO8P+I8ePcqzH41Gk2u/BY3ryTGAHPvUarV5jmFlZWVwPIa6f/8+gYGB2NrasnLlSo4ePcpPP/0E5F7A3JB4Iet1hn+vQVJSEv379yciIkJ9REZGEhsbi6enJzY2Nhw/fpzVq1fj6upKaGgo1apVy/Xueu+++y4A33//PbGxsezfv19dZnfx4kXatm1L1apVWbduHceOHePLL7/M9VyNjIyyTAh5/DWVWR9q48aNeucRFRWl1nl67bXXuHTpEu+//z5Xr16lefPmjBw50qDr97IrssTT33//TXp6epa1n87Ozly/fj3bYwIDA5k1axaxsbHodDq2bdvGjz/+yLVr13IcJyUlhYSEBL3H85aUnP2H3PM6XgghhBBCCCH+K4oXLw6g9z3x8ULjL7KqVauyY8eOfB3j4+PDwYMH9RIj+/fvx8bGhtKlS6tthw8f1jvu0KFDeHt7Y2xszOnTp7l9+zbTp0/H39+fihUrZpmVZWZmBqBXb8rb2xutVpvvmB9Xo0YNoqKi8PLyyvLIHNPExISAgABmzJjByZMnuXjxIjt37syxTxsbGzp06MDSpUv55ptvKF++PP7+/kDGzC6dTsfMmTOpV68e5cuX5+rVq7nGWLx48Sx5h8dfU5UqVcLc3Jy4uLgs5+Dm5qbXT48ePfj222+ZPXs2X3/9dX4v10upyIuL58ecOXPw9vamYsWKmJmZERwcTK9evdSMdnamTZuGnZ2d+nj8SX9erLWmee/0DI8XQgghhBBCiP8KrVZLvXr1mD59OtHR0ezZs4dx48YVdVgGCQkJ4ejRowwaNIiTJ09y+vRpFi5cyN9//53jMYMGDeLy5csMGTKE06dPs379eiZMmMCIESP0vivHxcUxYsQIYmJiWL16NfPmzWPYsGEAlClTBjMzM+bNm8f58+f55ZdfmDJlit447u7uaDQaNmzYwK1bt0hKSsLCwoLRo0czatQodVnZoUOHWLJkicHnPHr0aA4cOEBwcDARERHExsayfv16tbj4hg0bmDt3LhEREVy6dInw8HB0Oh0VKlTItd+goCAOHDhAWFgYvXv3Vtu9vLx49OiReq4rVqwgLCws176aNWvG77//Tnh4OLGxsUyYMIE///xT3W5jY8PIkSN5//33Wb58OefOneP48ePMmzeP5cuXAxAaGsr69es5e/Ysp06dYsOGDfj4+Bh8nV5mRZZ4cnJywtjYmBs3bui137hxAxcXl2yPKV68OD///DP379/n0qVLnD59Gmtra701uE8KCQnh3r176uPy5cuFeh6GcLQxx8PFhseW0xpEowEPFxscbcyfTWBCCCGEEEII8QpaunQpaWlp1KxZk+HDh2e5w9uLqnz58mzdupXIyEjq1KmDn58f69evx8TEJMdjSpUqxaZNmzhy5AjVqlVjwIABBAUFZUm2de/eneTkZOrUqcPgwYMZNmwY/fr1AzK+ay9btoy1a9dSqVIlpk+fzueff55lnEmTJjFmzBicnZ3VxND48eP54IMPCA0NxcfHh06dOuW7LtaePXs4c+YM/v7++Pr6EhoaSsmSJQGwt7fnxx9/pFmzZvj4+BAWFsbq1aupXLlyrv02bNiQChUqkJCQQPfu3dX2atWqMWvWLD799FP+7//+j5UrVzJt2rRc+woMDGT8+PGMGjWK2rVrk5iYqNcnwJQpUxg/fjzTpk3Dx8eHVq1asXHjRjw8PICMGWMhISFUrVqVRo0aYWxszJo1awy+Ti8zjVKElavr1q1LnTp11NtT6nQ6ypQpQ3BwMGPGjMnz+EePHuHj40PHjh2ZOnWqQWMmJCRgZ2fHvXv3sLW1far482PBr6cIWXKE/FxtjQamB9VlYLtKzy4wIYQQQgghRL4U1XeKp/Xw4UMuXLiAh4dHltq5QgiRX4Z+phTpUrsRI0awaNEili9fTnR0NAMHDuT+/fv06tULyMjIhoSEqPsfPnyYH3/8kfPnz7N3715atWqFTqdj1KhRRXUKBuvS1AtLcxOMDJz1ZKQBS3MTOjf1fLaBCSGEEEIIIYQQQjwjOc/Xew46derErVu3CA0N5fr161SvXp3NmzerBcfj4uL01qQ+fPiQcePGcf78eaytrWndujUrVqzA3t6+iM7AcPbW5qwY3YwOU7ZhhIIul5lPRpqMSv/fjmmGvbUssxNCCCGEEEKIohQXF0elSjmvRImKiqJMmTLPMSIhXh5FutSuKBT1tNjtx6/Q7dOdPEhJA9BbepdZA8rS3IRvxzSjuW+p5x6fEEIIIYQQIndF/Z2ioGSpXcGlpaVx8eLFHLeXLVs21zpMQryKDP1MkXfGcxZQoxTRSzqyetc5wjZEceF6orqtrLMNA9pWokszL+yszIowSiGEEEIIIYQQmUxMTPDy8irqMIR4KUniqQjYW5szsF0lBrT1IT4xhaTkR1hrTXG0MUeT31vfCSGEEEIIIYQQQrygJPFUhDQaDcVsLShmK9NchRBCCCGEEEII8eop0rvaCSGEEK+imzdvMnfeXG7evFnUoQghhBBCCFGkJPEkhBBCFLJbt24xb/48bt26VdShCCGEEEIIUaRkqZ0QQgghhBBCiHxRFEXq1QohDCKJJyGEEC+U6/EPWLolht6BFXBxtCzqcIQQQgjxmLtJKazadZavNkTr3aHbw8WG/m196NLUC3tr8yKMUAjxopGldkIIIV4o1+88YPqaCK7feVDUoQghhBDiMduPX8En6HtClhzh4o1EvW0XbyQSsuQIPkHfs/34lUIfu2fPnmg0GqZPn67X/vPPPz/1TKtly5ah0WjQaDQYGxvj4OBA3bp1mTx5Mvfu3cs2Do1Gg5mZGV5eXkyePJm0tLSnikGIV5kknoQQQgghhBBC5Gr78St0mLKN5JQ0FAUURX97ZltyShodpmx7JsknCwsLPv30U+7cuVPofdva2nLt2jX++usvDhw4QL9+/QgPD6d69epcvXpVb99WrVpx7do1YmNj+eCDD5g4cSKfffZZocckxKtCEk9CCCGEEEIIIXJ0NymFbp/uRFEUdEru++qUjPpP3T7dyd2klEKNIyAgABcXF6ZNm5brfuvWraNy5cqYm5tTtmxZZs6cmWffGo0GFxcXXF1d8fHxISgoiAMHDpCUlMSoUaP09jU3N8fFxQV3d3cGDhxIQEAAv/zyy1OdmxCvMkk8CSGEEE9IfPCAHccjSHwgy/2EEEKIVbvO8iAlLc+kUyadAg9S0li961yhxmFsbMzUqVOZN28ef/31V7b7HDt2jI4dO/Luu+/yxx9/MHHiRMaPH8+yZcvyPV6JEiXo2rUrv/zyC+np6Tnup9VqSU1NzXf/QvxXSOJJCCHEC0NRFO7dz/iH2737qShPzuM3ROpNiJud8d8CSnyQzK4TkSQ+SC5wH0IIIcSrQFEUvtoQDQX4lRy2Iapgv8tz8dZbb1G9enUmTJiQ7fZZs2bRvHlzxo8fT/ny5enZsyfBwcEFXgpXsWJFEhMTuX37dpZtiqKwfft2tmzZQrNmzQrUvxD/BZJ4EkIIUeTuJqWw4NdTVB+wjnbjtwDQbvwWqg9Yx4JfT+Vvqn7qTfhrzlMlnp6GoijcS8goRHov4V6h/4NbCCGEeJ7iE1O4cD0x33knRYEL1xOJTyzc5XYAn376KcuXLyc6OjrLtujoaBo0aKDX1qBBA2JjY3OdtZSTzN/jjxcw37BhA9bW1lhYWPDaa6/RqVMnJk6cmO++hfivkMSTEEKIIlWUd8gpTAkJCSxbvoyAlgH06NkDgB49exDQMoBly5eRkJBgUD+KopB2P4GUOzdIu58giSshhBBFKin5UZEen51GjRoRGBhISEhIoff9pOjoaGxtbSlWrJja1rRpUyIiIoiNjSU5OZnly5djZWX1zGMR4mVlUtQBCCGE+O/KvEOOoihZ7o4D/94xJ/MOOWvHtyCgRqlnGpOiKCSnZvx1Njk1BUVR8rxN8969ewkeGkxyctaleZcvX2bqtKl8MfsL5s+dj7+/f7Z9pCUncfvELm4d2khK/HW13dzRheL12lDMtykmWuunODMhhBAi/6y1pkV6fE6mT59O9erVqVChgl67j48P+/fv12vbv38/5cuXx9jYOF9j3Lx5k1WrVvHmm29iZPTvnA0rKyu8vLwKHrwQ/zGSeBJCCFEk8nuHHCMy7pATvaQj9tbmhR5PckoqJ2LPcijqNPGJGTOvvvltG442NtSrVBFfby+05mZZjtu7dy99+vX5J3mW9UQy25KTk+nTrw+Lv16cJfl0L/YE51d/ii4163KElPgb/LVpKVe3r6Rc59HYefsWxukKIYQQBnG0McfDxYaLNxKz/SNRTjQaKOtsg6NN4f/OBqhSpQpdu3Zl7ty5eu0ffPABtWvXZsqUKXTq1ImDBw8yf/58FixYkGt/iqJw/fp1FEXh7t27HDx4kKlTp2JnZ8f06dOfyTkI8V8hS+2EEEIUiRflDjkAsX9d4bM1a9l0+KiadMoUn5jIpsNH+WzNWmL/0l/ul5CQQPDQ4ByTTo/L3Cd4aLDesrt7sSc4Gz4F3aMUMiq3PtlPRpvuUQpnw6dwL/ZEwU9UCCGEyCeNRkP/tj4FOnZA20p5zhp+GpMnT0an0+m11ahRg++//541a9bwf//3f4SGhjJ58mR69uyZa18JCQm4urpSqlQp/Pz8+Oqrr+jRowcnTpzA1dX1mZ2DEP8FGuU/VjwiISEBOzs77t27h62tbVGHI4QQ/0mKolB9wDou5rNYaeZfTyPC2mf/D1lFgXsHIOo9qPQt2NXPOCgXsX9dIXzrDlCUXGPR/BNA95bN8S6dsdxv2fJlTJ02NV91mDQaDWM/GkuP7j1IS07ij8/6ZCSdDOlDo8HI1JwqHy6WZXdCCFGEXtbvFA8fPuTChQt4eHhgYWFh8HF3k1LwCfqeZAP/YGSkAa25yTObpSyEeDEY+pkiM56EEEI8d4V+h5y0BLj6DRxvkpF0goz/Hm+S0Z6WfWHv5JRUVu/YnWfSCf6Zh6QorN6xm+SUVBRFYcW3K/J5BhnCV4SjKAq3T+zKWF5naOJKUdClphAfsbtA4wohhBAFYW9tzorRzdBoNBjlMYHJSJPxR5ZvxzSTpJMQApDEkxBCiCJQqHfIubMHfveDi1Mg5bL+jimXM9p/98vY7wknYs+SmpZmcAJMAVLT0og4e447d+4QFxeX77vOKYpCXFwcd+7c4dahjWRdWpe3mwc3yN3uhBBCPFcBNUqxdnwLtOYmaDRZJxRntmnNTfghtAXNfZ/tzUCEEC8PSTwJIYR47grtDjl39kB0b9Alk1t9JHTJGfs9lnxSFIVDUacLNP7BU9Hcv3+/QMdmSrp9U+/udYZTSIm/TnpyYt67CiGEEIUooEYpopd0ZHpQXco62+htK+tsw/Sgupxe2kmSTkIIPXJXOyGEEM9dodwhJy0BYgaRfcLpSf9sjxkEtQ6CiS0PUlKyFBI3VHxiIkYmT/cr1MI0f7d0flJ6SjImli9PXREhhBCvBntrcwa2q8SAtj7EJ6aQlPwIa60pjjbmz7SQuBDi5SUznoQQQjx3hXKHnJvrHpvpZIh/Zj7dWgdA6qO0Ao2fSWtlTZkyZfL9j2yNRkOZMmVwcCrxVOMbm2uf6nghhBDiaWg0GorZWuDubEMxWwtJOgkhciSJJyGEEEWiS1MvLM1N8ixSmslIA5bmJnRu6plRjPvasoINfHUZKApmpk85Y8nMlG7vdSvQsd27dcfEyhZzRxf+uV9ePmgwd3TBWGuT965CCCGEEEIUMUk8CSGEKBJPdYectDuQEkf+C3MrGcel3cXS3BxHm4IlbxxtbNCam/P2W2+j1WoN/iuvkZERWq2Wt958C41GQ/F6bQo0fgm/tvKXZSGEEEII8VKQxJMQQogiU+A75KQ/eLqB0++j0WioV6ligQ73q+yDRqPB1taW+XPno9Fo8kwEZW6fP28+trYZtZmK+TbFyMw864nn3AlGZuY4Vm9SoLiFEEIIIYR43iTxJIQQokgV6A45xpZPN6ixFQC+3l6YmZgYvNhNA5iZmFDdy1Nt8/f3Z/HXi9WZT08moDLbtFotixctxr+hv7rNRGtNuc6jM3rOK/mk0QAaPDuPxkRrbWDEQgghxDOiKPAoHh7+lfHf/NwtRAjxnyKJJyGEEEUu8w45EWHt+XVKIAC/TgkkIqw9A9tVws7KTP8AEwcwL0NB6iNhXgZM7AHQmpvRuXkT0Gjy7EkDoNHQuXkTtOb68fj7+7N3z17GfjQWNzc3vW1ubm6M/Wgs+/63Ty/plMnO2xev7uMxMjX/Z5QnI8loMzI1x7v7eGy9fQ0+WyGEEKLQpSXA1W/geBM4WhOO+//z3yYZ7WkJRR3hC2/37t1oNBru3r37TMdp0qQJw4cPf6ZjZOfixYtoNBoiIiKe+9iFbceOHfj4+JCenl7UoRSqsLAw2rVr99zGk8STEEKIF4ZGo1GTTHZWZjkvX9NowLVnwQYp2VNvdpF36VJ0b9kcU5Pci42bmpjQvWVzvEuXyna7ra0tPbr3YPvW7YQvCwcgfFk427dup0f3HtjkUk/KztuXKh8uxq1NEOaOznrbzB2dcWsTRNVRSyTpJIQQomjd2QO/+8HFKZByWX9byuWM9t/9MvYTOapfvz7Xrl3Dzs6uqEPJ0/NKkj0vKSkpVK9e3eDE2KhRoxg3bhzGxsaFHsvDhw/p2bMnVapUwcTEhDfffNOg4+Lj4+natSu2trbY29sTFBREUlKS3j6KovD5559Tvnx5zM3NKVWqFJ988om6vXfv3hw/fpy9e/cW5inl6Olu6SOEEEIUMhcHS8a8Wx0XhzyW05VoD3Gfgy4Zw4qMG4GRBRRvn2WLd+lSfPhuByLOnuPgqWjiExPVbY42NvhV9sHX2xMLM7Msxz5Jo9Hg6enJkOAheHp6GlwE3ERrTQm/thSv14bEC38QuzQU796TsfGoIoXEhRBCFL07eyC6Nxm/c7P7vftPmy45Yz+fpeDQ+DkG+PIwMzPDxcWlwMenpqZiZsC/SURWo0aNomTJkkRGRua57759+zh37hzt22f9t2NhSE9PR6vVMnToUNatW2fwcV27duXatWts27aNR48e0atXL/r168eqVavUfYYNG8bWrVv5/PPPqVKlCvHx8cTHx6vbzczM6NKlC3PnzsXfP+uM/MImM56EEEK8UFwcLfmosy8ujnkknkxsocICsl+e9qR/tldcmHFcNrTmZvhV9uH9Dm/R+7UWAPR+rQXvd3gLv8o+BiWdMpUoUYKhQ4ZSokQJg49RI9VoMLHIqEFlYmElSSchhBBFLy0BYgaRc9Lpcf/sEzOoUJfdNWnShKFDhzJq1CgcHR1xcXFh4sSJ6vbslnfdvXsXjUbD7t27gX9n72zZsgVfX1+0Wi3NmjXj5s2b/Pbbb/j4+GBra0uXLl148MCwG5k0adKEIUOGMHz4cBwcHHB2dmbRokXcv3+fXr16YWNjg5eXF7/99pt6THaziPbv30+TJk2wtLTEwcGBwMBA7ty5o44RHBzM8OHDcXJyIjAwoyzBnj17qFOnDubm5ri6ujJmzBjS0tL04ktLSyM4OBg7OzucnJwYP348ymP1uFasWEGtWrWwsbHBxcWFLl26cPPmTfWaNm3aFAAHBwc0Gg09e/YEQKfTMWPGDLy8vDA3N6dMmTJ6M2oAzp8/T9OmTbG0tKRatWocPHhQb/u+ffvw9/dHq9Xi5ubG0KFDuX//vrp9wYIFeHt7Y2FhgbOzM++8845Bz0lOfvvtNzUZY4g1a9bQokULLCws1LabN2/SoUMHihUrhoWFBeXKlWPRokUFisfKyoqFCxfSt29fgxOR0dHRbN68mcWLF1O3bl0aNmzIvHnzWLNmDVevXlX3WbhwIevXr+f111/Hw8ODmjVr0qJFC72+2rVrxy+//EJycnKB4s8PSTwJIYR4eTk0zviLqpGW3OojYaSFSt+AfaM8u9RoNFiYmQNgYWYuiR8hhBDi5rp8zDAmYz9dMtwyfBaHIZYvX46VlRWHDx9mxowZTJ48mW3btuW7n4kTJzJ//nwOHDjA5cuX6dixI7Nnz2bVqlVs3LiRrVu3Mm/evHzF5eTkxJEjRxgyZAgDBw6kQ4cO1K9fn+PHj9OyZUu6deuWYzIrIiKC5s2bU6lSJQ4ePMi+ffto166dXl2h5cuXY2Zmxv79+wkLC+PKlSu0bt2a2rVrExkZycKFC1myZAkff/xxlthMTEw4cuQIc+bMYdasWSxevFjd/ujRI6ZMmUJkZCQ///wzFy9eVJNLbm5u6kycmJgYrl27xpw5cwAICQlh+vTpjB8/nqioKFatWoWzs365gLFjxzJy5EgiIiIoX748nTt3VhNj586do1WrVrRv356TJ0/y3XffsW/fPoKDgwH4/fffGTp0KJMnTyYmJobNmzfTqNG//46bOnUq1tbWuT7i4uLU/W/cuEHfvn1ZsWIFlpaG3aRm79691KpVS69tzJgxnDt3jk2bNnHmzBlWr15N9erV1e2vvfZarjFVrlzZoLFzcvDgQezt7fXiCggIwMjIiMOHDwPw66+/Uq5cOTZs2ICHhwdly5alT58+ejOeAGrVqkVaWpp63LMkS+2EyAdFUYhPTCEp+RHWWlMcbeRLqRBFzqEx1DqY8Y/bq8sg5d9/ZGDullHTqXj7HGc6vYhMbRxwbdoJUxuHog5FCCHEf52iwLVlBTv26jJw6Zn3nVsNVLVqVSZMmACAt7c38+fPZ8eOHVlmcuTl448/pkGDBgAEBQUREhLCuXPnKFeuHADvvPMOu3btYvTo0Qb1V61aNcaNGwf8m5BxcnKib9++AISGhrJw4UJOnjxJvXr1shw/Y8YMatWqxYIFC9S2JxMU3t7ezJgxQ/157NiMG5rMnz8fjUZDxYoVuXr1KqNHjyY0NBQjo4w5Jm5ubnzxxRdoNBoqVKjAH3/8wRdffKHG1rt3b7XPcuXKMXfuXGrXrk1SUhLW1tY4OjoCGbO57e3tAUhMTGTOnDnMnz+fHj16AODp6UnDhg31Yh45ciRt2rQBYNKkSVSuXJmzZ89SsWJFpk2bRteuXdXi597e3sydO5fGjRuzcOFC4uLisLKyom3bttjY2ODu7o6v77+1LgcMGEDHjh1zfV5KliwJZHyH69mzJwMGDKBWrVpcvHgx1+MyXbp0Se0jU1paGsWKFaNChQrY29tTpkwZve2LFy/OdQaRqampQWPn5Pr161lm1JuYmODo6Mj169eBjJlmly5dYu3atYSHh5Oens7777/PO++8w86dO9XjLC0tsbOz49KlS08VkyEk8SSEAe4mpbBq11m+2hDNhev/1n7xcLGhf1sfujT1wt7avAgjFOI/zsQWXHtl/OP23kGI6gqVVoKdX6H9Y/d5MrVxpGTzzkUdhhBCCAFpd/T/qGMwJeO4tLtgWjh/SKlatarez66uruqysIL24+zsjKWlpZp0ymw7cuRIgfozNjamWLFiVKlSRa8/IMdYIyIi6NChQ65j1KxZU+/n6Oho/Pz89P4I3qBBA5KSkvjrr7/UhEi9evX09vHz82PmzJmkp6djbGzMsWPHmDhxIpGRkdy5cwedTgdAXFwclSpVyjaW6OhoUlJSaN68ea4xP35dXF1dgYxrULFiRSIjIzl58iQrV65U91EUBZ1Ox4ULF2jRogXu7u6UK1eOVq1a0apVK9566y11tpKjo6OaFMvLvHnzSExMJCQkxKD9MyUnJ+stswOYNWsWb731Fg4ODlhZWbFmzRratm2rbi9VKvub0DxPOp2OlJQUwsPDKV++PABLliyhZs2axMTEUKFCBXVfrVZr8LLSpyFL7YTIw/bjV/AJ+p6QJUe4eCNRb9vFG4mELDmCT9D3bD9+pYgiFEKoNBqw9ILSwzL++xImnYQQQogXSvpTfilNv5/3PgZ6craIRqNREyWZM3wer1/06NGjPPvRaDS59lvQuJ4cA8ixT61Wm+cYVlZWBsdjqPv37xMYGIitrS0rV67k6NGj/PTTT0BGAfOcGBIvZL3O8O81SEpKon///kRERKiPyMhIYmNj8fT0xMbGhuPHj7N69WpcXV0JDQ2lWrVqal2s/Cy127lzJwcPHsTc3BwTExO8vLyAjKVmmTO2suPk5KTW2coUFhZGfHw827Zt48SJE2oNrEzPeqmdi4tLlgRmWloa8fHxap0oV1dXTExM1KQTgI+PD4De8kPIuENe8eLFnyomQ8iMJyFysf34FTpM2YaiKCjZLGnPbEtOSaPDlG2sHd+CgBpFn+UW4j/NrASUGV7UUQghhBCvBmPD6uHkfHzhJ0yyk/nl+dq1a+qSrMcLjb/Iqlatyo4dO5g0aZLBx/j4+LBu3ToURVGTOvv378fGxobSpUur+z1Zv+fQoUN4e3tjbGzM6dOnuX37NtOnT8fNzQ3IqK30uMy75z1eb8rb2xutVsuOHTvo06dP/k72HzVq1CAqKkpNAmXHxMSEgIAAAgICmDBhAvb29uzcuZO33347X0vt5s6dq1f76urVqwQGBvLdd99Rt27dHI/39fUlKipKr23NmjX069ePgICAbI951kvt/Pz8uHv3LseOHVNnwe3cuROdTqeeS4MGDUhLS+PcuXN4enoCcObMGQDc3d3Vvs6dO8fDhw/1ljA+K5J4EiIHd5NS6Pbpzowpn3nUUdQpYIRCt093Er2koyy7E0IIIYQQrwYTBzAvAymXMby4OIAmo9aiif0zCkyfVqulXr16TJ8+HQ8PD27evKnWXXrRhYSEUKVKFQYNGsSAAQMwMzNj165ddOjQAScnp2yPGTRoELNnz2bIkCEEBwcTExPDhAkTGDFihDr7CzJmuIwYMYL+/ftz/Phx5s2bx8yZMwEoU6YMZmZmzJs3jwEDBvDnn38yZcoUvXHc3d3RaDRs2LCB1q1bo9Vqsba2ZvTo0YwaNQozMzMaNGjArVu3OHXqFEFBQQad8+jRo6lXrx7BwcH06dMHKysroqKi2LZtG/Pnz2fDhg2cP3+eRo0a4eDgwKZNm9DpdOoysfwstXuyDpO1tTWQUZfq8STdkwIDA1m+fLleW40aNQgLC6Ny5cqUL1+eW7duERUVRbdu3YD8L7WLiooiNTWV+Ph4EhMT1WRpZsHyI0eO0L17d3bs2EGpUqXw8fGhVatW9O3bl7CwMB49ekRwcDDvvvuummgLCAigRo0a9O7dm9mzZ6PT6Rg8eDAtWrTQmwW1d+9eypUrpyanniVZaidEDlbtOsuDlLQ8k06ZdAo8SElj9a5zzzYwIYQQQgghnheNBlx7FuzYkj2f67L3pUuXkpaWRs2aNRk+fHiWO7y9qMqXL8/WrVuJjIykTp06+Pn5sX79ekxMcp4nUqpUKTZt2sSRI0eoVq0aAwYMICgoKEuyrXv37iQnJ1OnTh0GDx7MsGHD6NevH5AxS2zZsmWsXbuWSpUqMX36dD7//PMs40yaNIkxY8bg7Oys3nVu/PjxfPDBB4SGhuLj40OnTp3yVW+ratWq7NmzhzNnzuDv74+vry+hoaFq8sTe3p4ff/yRZs2a4ePjQ1hYGKtXr37qpWr50bVrV06dOkVMTIzaNm/ePBo3bkzPnj3x8vKibdu2nDhxosBjtG7dGl9fX3799Vd2796Nr6+v3gykBw8eEBMTo7dsdOXKlVSsWJHmzZvTunVrGjZsyNdff61uNzIy4tdff8XJyYlGjRrRpk0bfHx8WLNmjd7Yq1evVovMP2saRcluAdGrKyEhATs7O+7du4et7ctzhyPxfCmKQvUB67h4PTF/f9fRQFlnGyLC2svd7oR4iV39+zYL1m9g0BttKelUrKjDEUII8YJ5Wb9TPHz4kAsXLuDh4ZGlaHKu0hLgdz/QJWPYrCcjMLLIuOvsS3RXWSGe9OGHH5KQkMBXX31V1KEUqlOnTtGsWTPOnDmDnZ1dgfsx9DNFZjwJkY34xBQu5DPpBBk1ny5cTyQ+MeWZxCWEeD5sLLU09a2GjaVhxTOFEEKIV5qJLVRYAGj+eeTmn+0VF0rSSbz0xo4di7u7e76Kzb8Mrl27Rnh4+FMlnfJDajwJkY2k5OzvgJGf44vZ5uOvSEKIF4qNpSXNa1Qv6jCEEEKIF4dDY/BZCjGD/pn5BPqzn/5JOBlpM5JO9o2ed4SFLi4ujkqVKuW4PSoqKkv9IPFqsbe356OPPirqMApdTsXRnxVJPAmRDWvt091t4GmPF0IIIYQQ4oXj0Dhj+dytdXB1GaQ8dmt2c7eMmk7F278yM51KliyZ653xMusRCSFyV+RL7b788kvKli2LhYUFdevW5ciRI7nuP3v2bCpUqIBWq8XNzY3333+fhw8fPqdoxX+Fo405Hi42+a6FqNGAh4sNjjZyVzshhBBCCPEKMrEF115QYzfUPg419v7z390Z7a9I0gnAxMQELy+vHB+5Ff8WQvyrSBNP3333HSNGjGDChAkcP36catWqERgYmGM1/FWrVjFmzBgmTJhAdHQ0S5Ys4bvvvnslp76JoqXRaOjf1qdAxw5oW0kKiwshhBBCiFebRgOmDmBROuO/8u9fIUQOijTxNGvWLPr27UuvXr2oVKkSYWFhWFpasnTp0mz3P3DgAA0aNKBLly6ULVuWli1b0rlz5zxnSQlREF2aemFpboKRgb9DjTRgaW5C56aezzYwIYQQQgghhBDiJVFkiafU1FSOHTumV9TKyMiIgIAADh48mO0x9evX59ixY2qi6fz582zatInWrVvnOE5KSgoJCQl6DyEMYW9tzorRzdBoNHkmn4w0GbOkvh3TDHtrWWYnhBBCCCGEEEJAESae/v77b9LT03F2dtZrd3Z25vr169ke06VLFyZPnkzDhg0xNTXF09OTJk2a5LrUbtq0adjZ2akPNze3Qj0P8WoLqFGKteNboDU3QaPJOoM4s01rbsIPoS1o7luqaAIVQgghhBBCCCFeQEVeXDw/du/ezdSpU1mwYAHHjx/nxx9/ZOPGjUyZMiXHY0JCQrh37576uHz58nOMWLwKAmqUInpJR6YH1aWss43etrLONkwPqsvppZ0k6SSEEEIIIf4zFEXh/sOH3ElM4v7DhyiKUtQhCSFeUEVWht/JyQljY2Nu3Lih137jxg1cXFyyPWb8+PF069aNPn36AFClShXu379Pv379GDt2LEZGWfNo5ubmmJvL0ifxdOytzRnYrhID2vrwvz+u0W78Fn6dEkijKq5SSFwIIYQQQvxnJKekciL2LIeiThOfmKi2O9rYUK9SRXy9vdCamxVhhC++3bt307RpU+7cuYO9vf0zG6dJkyZUr16d2bNnP7MxsnPx4kU8PDw4ceIE1atXf65jF7aYmBgaN25MbGwsNjY2eR/wkti8eTNjxozh+PHj2eZRCluRzXgyMzOjZs2a7NixQ23T6XTs2LEDPz+/bI958OBBlotibGwMIBl28VxoNBoqlLZnzLvVqVDaXpJOQgghhBDiPyP2ryt8tmYtmw4f1Us6AcQnJrLp8FE+W7OW2L+uFFGEL4f69etz7do17OzsijqUPO3evRuNRsPdu3eLOpSncubMGd544w2cnJywtbWlYcOG7Nq1K8/jQkJCGDJkyDNLOg0dOpSaNWtibm5ucJLu4cOHDB48mGLFimFtbU379u2zTOgBWLZsGVWrVsXCwoISJUowePBgdVurVq0wNTVl5cqVhXUquSrSpXYjRoxg0aJFLF++nOjoaAYOHMj9+/fp1asXAN27dyckJETdv127dixcuJA1a9Zw4cIFtm3bxvjx42nXrp2agBLiWXNxtOSjzr64OFoWdShCCCGEEEI8F7F/XSF86w4epaXlut+jtDTCt+6Q5FMuzMzMcHFxKfAfsVNTUws5oldf27ZtSUtLY+fOnRw7doxq1arRtm3bHOtLA8TFxbFhwwZ69uz5TGPr3bs3nTp1Mnj/999/n19//ZW1a9eyZ88erl69yttvv623z6xZsxg7dixjxozh1KlTbN++ncDAQL19evbsydy5cwvlHPJSpImnTp068fnnnxMaGkr16tWJiIhg8+bNasHxuLg4rl27pu4/btw4PvjgA8aNG0elSpUICgoiMDCQr776qqhOQQghhBBCCCFeackpqazesRsUhbzWmSgAisLqHbtJTim8BEmTJk0YOnQoo0aNwtHRERcXFyZOnKhuv3jxIhqNhoiICLXt7t27aDQadu/eDfw7e2fLli34+vqi1Wpp1qwZN2/e5LfffsPHxwdbW1u6dOnCgwcPDI5ryJAhDB8+HAcHB5ydnVm0aJE6ocLGxgYvLy9+++039ZjsZhHt37+fJk2aYGlpiYODA4GBgdy5c0cdIzg4mOHDh+Pk5KQmEPbs2UOdOnUwNzfH1dWVMWPGkPZEYjAtLY3g4GDs7OxwcnJi/PjxequFVqxYQa1atbCxscHFxYUuXbpw8+ZN9Zo2bdoUAAcHBzQajZqE0el0zJgxAy8vL8zNzSlTpgyffPKJ3tjnz5+nadOmWFpaUq1atSx3r9+3bx/+/v5otVrc3NwYOnQo9+/fV7cvWLAAb29vLCwscHZ25p133jHoOXnS33//TWxsLGPGjKFq1ap4e3szffp0Hjx4wJ9//pnjcd9//z3VqlWjVKl/a/k+ePCAvn374uzsjJmZGW5ubkyePLlAcQHMnTuXwYMHU65cOYP2v3fvHkuWLGHWrFk0a9aMmjVr8s0333DgwAEOHToEwJ07dxg3bhzh4eF06dIFT09Pqlatyuuvv67XV7t27fj99985d+5cgeM3VJEXFw8ODubSpUukpKRw+PBh6tatq27bvXs3y5YtU382MTFhwoQJnD17luTkZOLi4vjyyy+f6bpYIYQQQgghhPgvOxF7ltS0tDyTTpkUIDUtjYizhfuFdvny5VhZWXH48GFmzJjB5MmT2bZtW777mThxIvPnz+fAgQNcvnyZjh07Mnv2bFatWsXGjRvZunUr8+bNy1dcTk5OHDlyhCFDhjBw4EA6dOhA/fr1OX78OC1btqRbt245JrMiIiJo3rw5lSpV4uDBg+zbt4927dqRnp6uN4aZmRn79+8nLCyMK1eu0Lp1a2rXrk1kZCQLFy5kyZIlfPzxx1liMzEx4ciRI8yZM4dZs2axePFidfujR4+YMmUKkZGR/Pzzz1y8eFFNLrm5ubFu3Togo9bRtWvXmDNnDpCxBG369OmMHz+eqKgoVq1aleWO9WPHjmXkyJFERERQvnx5OnfurCbGzp07R6tWrWjfvj0nT57ku+++Y9++fQQHBwPw+++/M3ToUCZPnkxMTAybN2+mUaNGat9Tp07F2to610dcXBwAxYoVo0KFCoSHh3P//n3S0tL46quvKFGiBDVr1szxed27dy+1atXSa/v888/ZunUra9as4dy5c6xfv54mTZqo2wcMGJBnXE/j2LFjPHr0iICAALWtYsWKlClTRk3sbdu2DZ1Ox5UrV/Dx8aF06dJ07Ngxy43WypQpg7OzM3v37n2qmAxRZMXFhRBCCCGEEEK82BRF4VDU6QIde/BUNPUqVSy0uqhVq1ZlwoQJAHh7ezN//nx27NhBixYt8tXPxx9/TIMGDQAICgoiJCSEc+fOqbNO3nnnHXbt2sXo0aMN6q9atWqMGzcO+Dch4+TkRN++fQEIDQ1l4cKFnDx5knr16mU5fsaMGdSqVYsFCxaobZUrV9bbx9vbmxkzZqg/jx07Fjc3N+bPn49Go6FixYpcvXqV0aNHExoaqtZGdnNz44svvsioVVuhAn/88QdffPGFGlvv3r3VPsuVK8fcuXOpXbs2SUlJWFtb4+joCECJEiXUCR+JiYnMmTOH+fPn06NHDwA8PT1p2LChXswjR46kTZs2AEyaNInKlStz9uxZKlasyLRp0+jatSvDhw9Xz2/u3Lk0btyYhQsXEhcXh5WVFW3btsXGxgZ3d3d8fX3VvgcMGEDHjh1zfV5KliwJZNTp3b59O2+++SY2NjYYGRlRokQJNm/ejIODQ47HX7p0KUviKS0tDTs7OypWrIirqytubm562ydPnszIkSNzjetpXL9+HTMzsyyTb5ydndVlg+fPn0en0zF16lTmzJmDnZ0d48aNo0WLFpw8eRIzs3+L/5csWZJLly49s3gzSeJJCCGEEEIIIUS2HqSkZCkkbqj4xESSU1KwtLAolFiqVq2q97Orq6u6LKyg/Tg7O2Npaam31MnZ2ZkjR44UqD9jY2OKFStGlSpV9PoDcow1IiKCDh065DrGkzNzoqOj8fPz00vqNWjQgKSkJP766y/KlCkDQL169fT28fPzY+bMmaSnp2NsbMyxY8eYOHEikZGR3LlzB51OB2SUvalUqVK2sURHR5OSkkLz5s1zjfnx6+Lq6gpkXIOKFSsSGRnJyZMn9YpbK4qCTqfjwoULtGjRAnd3d8qVK0erVq1o1aoVb731FpaWGXV2HR0d1aRYXhRFYfDgwZQoUYK9e/ei1WpZvHgx7dq14+jRo2psT0pOTsbiidfumDFjiIqKomTJklhaWvLZZ58xaNAgdXuJEiUoUaKEQXE9KzqdjkePHjF37lxatmwJwOrVq3FxcWHXrl16tZ60Wq3By0qfRpEvtRNCCCGEEEII8WJKfZR7MfG8pDzl8Y8zNTXV+1mj0aiJkswZPo/XL3r06FGe/Wg0mlz7LWhcT44B5NinVqvNcwwrKyuD4zHU/fv3CQwMxNbWlpUrV3L06FF++uknIPcC5obEC1mvM/x7DZKSkujfvz8RERHqIzIyktjYWDw9PbGxseH48eOsXr0aV1dXQkNDqVatmloXKz9L7Xbu3MmGDRtYs2YNDRo0oEaNGixYsACtVsvy5ctzjN/JyUmts5Xphx9+4NChQ/zyyy+cOHGCrl276m1/1kvtXFxcSE1NzXKXwRs3buDi4gL8m+R7PHFYvHhxnJyc1GuSKT4+nuLFiz9VTIaQGU9CCCGEEEIIIbJlZvp0XxnNn/J4Q2V+eb527Zq6JOvxQuMvsqpVq7Jjxw4mTZpk8DE+Pj6sW7cORVHUpM7+/fuxsbGhdOnS6n6HDx/WO+7QoUN4e3tjbGzM6dOnuX37NtOnT1eXjP3+++96+2cuy3q83pS3tzdarZYdO3bQp0+f/J3sP2rUqEFUVBReXl457mNiYkJAQAABAQFMmDABe3t7du7cydtvv52vpXaZM3oyk5OZjIyMck0w+vr6EhUVpdf2/fff06FDB9q1a5ftMc96qV3NmjUxNTVlx44dtG/fHsiovxUXF4efnx+Auow0JiZGfS3Ex8fz999/4+7urvb18OFDzp07p7eE8VmRxJMQQgghhBBCiGxZmpvjaGNToOV2jjY2aM3Nn0FUWWm1WurVq8f06dPx8PDg5s2bat2lF11ISAhVqlRh0KBBDBgwADMzM3bt2kWHDh1wcnLK9phBgwYxe/ZshgwZQnBwMDExMUyYMIERI0boJVji4uIYMWIE/fv35/jx48ybN4+ZM2cCGcWlzczMmDdvHgMGDODPP/9kypQpeuO4u7uj0WjYsGEDrVu3RqvVYm1tzejRoxk1ahRmZmY0aNCAW7ducerUKYKCggw659GjR1OvXj2Cg4Pp06cPVlZWREVFsW3bNubPn8+GDRs4f/48jRo1wsHBgU2bNqHT6ahQoQKQv6V2fn5+ODg40KNHD0JDQ9FqtSxatIgLFy6oNaiyExgYSJ8+fdRliZCRMPv6669p0qQJ1atX5969exw6dIh+/foB+V9qd/bsWZKSkrh+/TrJyclqsrRSpUqYmZlx5coVmjdvTnh4OHXq1MHOzo6goCBGjBiBo6Mjtra2DBkyBD8/P7V+WPny5XnjjTcYNmwYX3/9Nba2toSEhFCxYkX1LoWQkYQ0NzdXE1bPkiy1E0IIIYQQQgiRLY1GQ71KFQt0rF9ln0IrLG6IpUuXkpaWRs2aNRk+fHiWO7y9qMqXL8/WrVuJjIykTp06+Pn5sX79ekxMcp4nUqpUKTZt2sSRI0eoVq0aAwYMICgoKEuyrXv37iQnJ1OnTh0GDx7MsGHD1CRJ8eLFWbZsGWvXrqVSpUpMnz6dzz//PMs4kyZNYsyYMTg7O6t3nRs/fjwffPABoaGh+Pj40KlTp3zV26patSp79uzhzJkz+Pv74+vrS2hoqDpLyd7enh9//JFmzZrh4+NDWFgYq1evzlJ03RBOTk5s3ryZpKQkmjVrRq1atdi3bx/r16+nWrVqOR732muvYWJiwvbt29W2cePG0aNHD4YPH0758uVp3rw5O3bsyHdMmfr06YOvry9fffUVZ86cwdfXF19fX65evQpkLBeNiYnRq8P0xRdf0LZtW9q3b0+jRo1wcXHhxx9/1Os3PDycunXr0qZNGxo3boypqSmbN2/WW/64evVqunbtqtbNepY0yuOLYP8DEhISsLOz4969e9ja2hZ1OEIIIYQQQoiXzMv6neLhw4dcuHABDw+PLEWTc5Ockspna9byKC0NQ748agBTExM+fLcDWnOzPPcX4kX15Zdf8ssvv7Bly5aiDqVQ/f3331SoUIHff/8dDw+PAvdj6GeKzHgSQgghhBBCCJEjrbkZnZs3AY2GvOYvaQA0Gjo3byJJJ/HS69+/P40aNSKxgHd2fFFdvHiRBQsWPFXSKT9kxpMQQgghhBBC5MPL+p2ioDOeMsX+dYXVO3aTmpbznerMTEzo3LwJ3qVLPU2oL4S4uDi9O4M9KSoqijJlyjzHiIR4sRj6mSLFxYUQQgghhBBC5Mm7dCk+fLcDEWfPcfBUtF7BcUcbG/wq++Dr7YmF2asx06lkyZK53hkvsx6RECJ3kngSQgghhBBCCGEQrbkZfpV9qFepIskpKaQ8SsPc1AStuflzLST+PJiYmODl5VXUYQjx0pPEkxBCCCGEEEKIfNFoNFhaWGCZ/xV7Qoj/GCkuLoQQQgghhBBCCCGeCUk8CSGEEEIIIYQQQohnQhJPQgghhBBCCCGEEOKZkBpPQgghhBBCCCHyRVEU7ty5w4MHD7C0tMTBweGVKy4uhCgcMuNJCCGEEEIIIYRBEhISWLZ8GQEtA6jrV5emzZtS168uAS0DWLZ8GQkJCUUd4gtv9+7daDQa7t69+0zHadKkCcOHD3+mY2Tn4sWLaDQaIiIinvvYRWHHjh34+PiQnp5e1KEUqrCwMNq1a1cofUniSQghhBBCCCFEnvbu3Yt/Y3+mTpvK5cuX9bZdvnyZqdOm4t/Yn7179xZRhC+H+vXrc+3aNezs7Io6lDw9ryTZs/bJJ59Qv359LC0tsbe3z3G/ZcuWUbVqVSwsLChRogSDBw/Os+9Ro0Yxbtw4jI2NCzHiDA8fPqRnz55UqVIFExMT3nzzTYOOi4+Pp2vXrtja2mJvb09QUBBJSUl6+yiKwueff0758uUxNzenVKlSfPLJJ+r23r17c/z48UJ5P0viSQghhBBCCCFErvbu3Uuffn1ITk5GURQURdHbntmWnJxMn359JPmUCzMzM1xcXAq8NDE1NbWQI3r1paam0qFDBwYOHJjjPrNmzWLs2LGMGTOGU6dOsX37dgIDA3Ptd9++fZw7d4727dsXdsgApKeno9VqGTp0KAEBAQYf17VrV06dOsW2bdvYsGED//vf/+jXr5/ePsOGDWPx4sV8/vnnnD59ml9++YU6deqo283MzOjSpQtz58596vOQxJMQQgghhBBCiBwlJCQQPDQ424TTkzL3CR4aXKjL7po0acLQoUMZNWoUjo6OuLi4MHHiRHV7dsu77t69i0ajYffu3cC/s3e2bNmCr68vWq2WZs2acfPmTX777Td8fHywtbWlS5cuPHjwwOC4hgwZwvDhw3FwcMDZ2ZlFixZx//59evXqhY2NDV5eXvz222/qMdnNItq/fz9NmjRR62UFBgZy584ddYzg4GCGDx+Ok5OTmgzZs2cPderUwdzcHFdXV8aMGUNaWppefGlpaQQHB2NnZ4eTkxPjx4/Xew5XrFhBrVq1sLGxwcXFhS5dunDz5k31mjZt2hRAreHVs2dPAHQ6HTNmzMDLywtzc3PKlCmjN1sG4Pz58zRt2hRLS0uqVavGwYMH9bbv27cPf39/tFotbm5uDB06lPv376vbFyxYgLe3NxYWFjg7O/POO+8Y9JxkZ9KkSbz//vtUqVIl2+137txh3LhxhIeH06VLFzw9PalatSqvv/56rv2uWbOGFi1aYGFhobbdvHmTDh06UKxYMSwsLChXrhyLFi0qUNxWVlYsXLiQvn374uLiYtAx0dHRbN68mcWLF1O3bl0aNmzIvHnzWLNmDVevXlX3WbhwIevXr+f111/Hw8ODmjVr0qJFC72+2rVrxy+//EJycnKB4s8kiaeXmaLAo3h4+FfGf/P4JSCEEEIIIYQQ+fXjTz+qM50MkTnz6aeffyrUOJYvX46VlRWHDx9mxowZTJ48mW3btuW7n4kTJzJ//nwOHDjA5cuX6dixI7Nnz2bVqlVs3LiRrVu3Mm/evHzF5eTkxJEjRxgyZAgDBw6kQ4cO1K9fn+PHj9OyZUu6deuWYzIrIiKC5s2bU6lSJQ4ePMi+ffto166dXs2g5cuXY2Zmxv79+wkLC+PKlSu0bt2a2rVrExkZycKFC1myZAkff/xxlthMTEw4cuQIc+bMYdasWSxevFjd/ujRI6ZMmUJkZCQ///wzFy9eVJNLbm5urFu3DoCYmBiuXbvGnDlzAAgJCWH69OmMHz+eqKgoVq1ahbOzs97YY8eOZeTIkURERFC+fHk6d+6sJsbOnTtHq1ataN++PSdPnuS7775j3759BAcHA/D7778zdOhQJk+eTExMDJs3b6ZRo0Zq31OnTsXa2jrXR1xcnMHP4bZt29DpdFy5cgUfHx9Kly5Nx44dsywpfdLevXupVauWXtuYMWM4d+4cmzZt4syZM6xevZrq1aur21977bVc465cubLBcWfn4MGD2Nvb68UVEBCAkZERhw8fBuDXX3+lXLlybNiwAQ8PD8qWLUufPn2Ij4/X66tWrVqkpaWpxxWU3NXuZZSWADfXwbVlkPLYm8m8DLj2hBLtwcS2qKITQgghhBBCvCIURWHFtysKdGz4inC6d+teaHe7q1q1KhMmTADA29ub+fPns2PHjiyzNPLy8ccf06BBAwCCgoIICQnh3LlzlCtXDoB33nmHXbt2MXr0aIP6q1atGuPGjQP+Tcg4OTnRt29fAEJDQ1m4cCEnT56kXr16WY6fMWMGtWrVYsGCBWrbk8kHb29vZsyYof48duxY3NzcmD9/PhqNhooVK3L16lVGjx5NaGgoRkYZc0zc3Nz44osv0Gg0VKhQgT/++IMvvvhCja13795qn+XKlWPu3LnUrl2bpKQkrK2tcXR0BKBEiRJqbaTExETmzJnD/Pnz6dGjBwCenp40bNhQL+aRI0fSpk0bIGPGUeXKlTl79iwVK1Zk2rRpdO3aVS1+7u3tzdy5c2ncuDELFy4kLi4OKysr2rZti42NDe7u7vj6+qp9DxgwgI4dO+b6vJQsWTLX7Y87f/48Op2OqVOnMmfOHOzs7Bg3bhwtWrTg5MmTmJmZZXvcpUuXsoyTlpZGsWLFqFChAvb29pQpU0Zv++LFi3OdQWRqampw3Nm5fv06JUqU0GszMTHB0dGR69evAxnne+nSJdauXUt4eDjp6em8//77vPPOO+zcuVM9ztLSEjs7Oy5duvRUMUni6WVzZw/EDAJdNi/UlMtwcQrEfQ4VFoBD4+cfnxBCCCGEEOKVcefOnXzNHMmkKApxcXHcvXsXBweHQomlatWqej+7urqqy8IK2o+zszOWlpZq0imz7ciRIwXqz9jYmGLFiukt6cqcCZRTrBEREXTo0CHXMWrWrKn3c3R0NH5+fnpJvQYNGpCUlMRff/2lJjvq1aunt4+fnx8zZ84kPT0dY2Njjh07xsSJE4mMjOTOnTvodDoA4uLiqFSpUraxREdHk5KSQvPmzXON+fHr4urqCmRcg4oVKxIZGcnJkydZuXKluo+iKOh0Oi5cuECLFi1wd3enXLlytGrVilatWvHWW29haWkJgKOjo5oUKww6nY5Hjx4xd+5cWrZsCcDq1atxcXFh165dOdZ6Sk5O1ltmBxm1ot566y0cHBywsrJizZo1tG3bVt1eqlSpQou7oHQ6HSkpKYSHh1O+fHkAlixZQs2aNYmJiaFChQrqvlqt1uClpzmRpXYvkzt7ILr3P0kn5Z/H4/5p0yVn7Hdnz/OPUQghhBBCCPHKeNovnI/X7HlaT84E0Wg0aqIkc4bP48sBHz16lGc/Go0m134LGteTYwA59qnVavMcw8rKyuB4DHX//n0CAwOxtbVl5cqVHD16lJ9+ylgemVsBc0PihazXGf69BklJSfTv35+IiAj1ERkZSWxsLJ6entjY2HD8+HFWr16Nq6sroaGhVKtWTa2LVdhL7TITY48n24oXL46Tk1Ou/Tg5Oam1uDKFhYURHx/Ptm3bOHHihFonK9OzXmrn4uKSJcmZlpZGfHy8WifK1dUVExMTNekE4OPjA5DlfOPj4ylevPhTxSQznl4WaQkZM52yTTg96Z/tMYOg1sFcl90pisKDlBRSH6VhZmqCpbl5oU2FNYSiKKQ/SCQ9NRljMy3GljbPdXwhhBBCCCFEzjJnmBTUs0iYZCfzi/G1a9fUJVmPFxp/kVWtWpUdO3YwadIkg4/x8fFh3bp1KIqifn/av38/NjY2lC5dWt3vydo8hw4dwtvbG2NjY06fPs3t27eZPn06bm5uQEZtpcdlLjF7vN6Ut7c3Wq2WHTt20KdPn/yd7D9q1KhBVFQUXl5eOe5jYmJCQEAAAQEBTJgwAXt7e3bu3Mnbb79d6EvtMpdexsTEqNcvPj6ev//+G3d39xyP8/X1JSoqSq9tzZo19OvXL8e70D3rpXZ+fn7cvXuXY8eOqTPldu7ciU6no27dukDG+aalpXHu3Dk8PT0BOHPmDIDe+Z47d46HDx/qLXMsCEk8vSxurntsppMh/pn5dGsduPbKsjU5JZUTsWc5FHWa+MREtd3RxoZ6lSri6+2F1jz7dayFIS05idsndnHr0EZS4q+r7eaOLhSv14Zivk0x0Vo/s/GFEEIIIYQQeXNwcKBMmTJcvnzZ4OLikDHDxc3NTa0L9KxptVrq1avH9OnT8fDw4ObNm2rdpRddSEgIVapUYdCgQQwYMAAzMzN27dpFhw4dcHJyyvaYQYMGMXv2bIYMGUJwcDAxMTFMmDCBESNGqLO/IGP2yogRI+jfvz/Hjx9n3rx5zJw5E4AyZcpgZmbGvHnzGDBgAH/++SdTpkzRG8fd3R2NRsOGDRto3bo1Wq0Wa2trRo8ezahRozAzM6NBgwbcunWLU6dOERQUZNA5jx49mnr16hEcHEyfPn2wsrIiKiqKbdu2MX/+fDZs2MD58+dp1KgRDg4ObNq0CZ1Opy4By+9Su7i4OOLj44mLiyM9PV1NSnp5eWFtbU358uV54403GDZsGF9//TW2traEhIRQsWLFLDOWHhcYGMjy5cv12mrUqEFYWBiVK1emfPny3Lp1i6ioKLp16wbkf6ldVFQUqampxMfHk5iYqMaeWbD8yJEjdO/enR07dlCqVCl8fHxo1aoVffv2JSwsjEePHhEcHMy7776rJuMCAgKoUaMGvXv3Zvbs2eh0OgYPHkyLFi30ZkHt3buXcuXKqcmpgpKldi8DRckoJF4QV5dludtd7F9X+GzNWjYdPqqXdAKIT0xk0+GjfLZmLbF/XTEgNIX4+Hj++usv4uPjDfpldC/2BH981oe/Ni0lJf6G3raU+Bv8tWkpf3zWh3uxJ/I+PyGEEEIIIcQzo9Fo6PZetwIdW5iFxQ2xdOlS0tLSqFmzJsOHD89yh7cXVfny5dm6dSuRkZHUqVMHPz8/1q9fj4lJzvNESpUqxaZNmzhy5AjVqlVjwIABBAUFZUm2de/eneTkZOrUqcPgwYMZNmwY/fr1AzJmiS1btoy1a9dSqVIlpk+fzueff55lnEmTJjFmzBicnZ3Vu86NHz+eDz74gNDQUHx8fOjUqVO+6m1VrVqVPXv2cObMGfz9/fH19SU0NFRNjNjb2/Pjjz/SrFkzfHx8CAsLY/Xq1QVehhYaGoqvry8TJkwgKSkJX19ffH199WZ4hYeHU7duXdq0aUPjxo0xNTVl8+bNuc5A6tq1K6dOnSImJkZtmzdvHo0bN6Znz554eXnRtm1bTpwo+Hfb1q1b4+vry6+//sru3bvV2DM9ePCAmJgYvaWlK1eupGLFijRv3pzWrVvTsGFDvv76a3W7kZERv/76K05OTjRq1Ig2bdrg4+PDmjVr9MZevXq1Woj+aWiU/KStXwEJCQnY2dlx7949bG1fkju/PYqHozXz3i8ntY+DaUZBv9i/rhC+dQcoSq5zpzQAGg3dWzbHu3TWjGxCQgI//vQjK75dobcGtEyZMnR7rxtvv/V2ttf3XuwJzoZPAZQsCTH9ADSABq/u47HzfrppfUIIIYQQQhSml/I7BfDw4UMuXLiAh4dHloLIuUlISMC/sT/JyckG/aHZyMgICwsL9u7Z+1JdHyEK4sMPPyQhIYGvvvqqqEMpVKdOnaJZs2acOXMGOzu7bPcx9DNFZjy9DNKfrqAf6RkF/ZJTUlm9Y3eeSSf4Z0GforB6x26SU/QLy+3duxf/xv5MnTaVy5cv6227fPkyU6dNxb+xP3v37tXblpacxPnVn5Jn0umfsUHh/OpPSUtOyusMhRBCCCGEEM+Ira0t8+fOR6PR5DmDKXP7/HnzJekk/hPGjh2Lu7t7vgrSvwyuXbtGeHh4jkmn/JDE08vA+OkK+mGcUdDvROxZUtPS8lMlitS0NCLOnlPb9u7dS59+fdS/djz5F4/MtuTkZPr066OXfLp9Yhe61JS8k07/doYuNYX4iN0GRiyEEEIIIYR4Fvz9/Vn89WK0Wm22CajMNq1Wy+JFi/Fv6F9EkRaeuLi4Qrtrmnh12dvb89FHH+nV1noVBAQEEBgYWCh9SXHxl4GJA5iXgZTLGF5cHEAD5m5gYo+iKByKOl2g4Q+eiqZepYokJiYSPDQ424TTkzK3Bw8NZu+evdjY2HDr0MZ8xp/h5sENFK/XRu52J4QQQgghRBHy9/dn7569/PTzT4SvCNdLvLi5udG9W3fefuttbGxsijDKwlOyZMlc74yXn7umCfFfJomnl4FGA6494eKUPHfNomRP0Gh48PBhlkLihopPTCQ5JYUff/rR4HXdgDrz6aeff6Jr+7f07l5nOIWU+OukJydiYilTdYUQQgghhChKtra29Ojeg+7dunP37l3u37+PlZUV9vb2r9wfik1MTPDy8irqMIR46b1ac8FeZSXag5GWf8p+G8AoY//i7QFIfZT2VMM/TH3Eim9XFOjY8BXhpKUkP9X46U95vBBCCCGEEKLwaDQaHBwcKF26NA4ODq9c0kkIUXgk8fSyMLGFCgvISDzl9aH+z/aKCzOOA8xMn25yW/L9JOLi4gye7ZRJURTi4uJISk55qvGNzbVPdbwQQgghhBBCCCGeP0k8vUwcGoPP0sdmPj2ZgPqnzUgLlb4B+0bqFktzcxwLuNba0cYGXdrTzZhK1mkwd3TB8BlbmTKOM9a+GuvEhRBCCCGEEEKI/xJJPL1sHBpDrYPgMT6jcPjjzN0y2msd1Es6QcZU2HqVKhZoSL/KPlhZWRU0YgCsra0pXq9NgY4t4ddWpu4KIYQQQgghhBAvISku/jIysQXXXuDSE9LuQvp9MLYCE/uMQuQ58PX2YvuxEzxKSzPo3nIawNTEhOpenliYmVKmTBkuX76cr+V2Go0GNzc37O3tSfdtytXtK9E9SgFD+tBoMDI1x7F6E4PHE0IIIYQQQjx7iqKQ/iCR9NRkjM20GFvayB+LhRDZkhlPLzONBkwdwKJ0xn/z+KDXmpvRuXkT0GgMqxKl0dC5eRO05mZoNBq6vdetQGF279YdjUaDidaacp1HZ/Se1y8lTcayQc/OozHRWhdoXCGEEEIIIUThSktO4saBXzn1xUAip3Xnz5n9iZzWnVNfDOTGgV9JS04q6hBfeLt370aj0XD37t1nOk6TJk0YPnz4Mx0jOxcvXkSj0RAREfHcxy4K48ePp1+/fkUdRqF79913mTlzZqH0JYmn/xjv0qXo3rI5pia5T3YzNTGhe8vmeJcupba9/dbbaLVag/+SYWRkhFar5a0331Lb7Lx98eo+HiNTc3KrU2Vkao539/HYevsadmJCCCGEEEKIZ+pe7An++KwPf21aSkr8Db1tKfE3+GvTUv74rA/3Yk8UUYQvh/r163Pt2jXs7OyKOpQ8Pa8k2bP2+uuvU6ZMGSwsLHB1daVbt25cvXpV3b57927eeOMNXF1dsbKyonr16qxcuTLPfq9fv86cOXMYO3bsM4n71KlTtG/fnrJly6LRaJg9e7ZBx508eRJ/f38sLCxwc3NjxowZWfa5e/cugwcPxtXVFXNzc8qXL8+mTZvU7ePGjeOTTz7h3r17T30eknj6D/IuXYoP3+1Am3p1shQcd7SxoU29Oozq3EEv6QRga2vL/Lnz0Wg0eSafMrfPnzcfW1tbvW123r5U+XAxbm2CMHd01ttm7uiMW5sgqo5aIkknIYQQQgghXhD3Yk9wNnxKRtkMlH8ej8to0z1K4Wz4FEk+5cLMzAwXF5cCL01MTU0t5IhefU2bNuX7778nJiaGdevWce7cOd555x11+4EDB6hatSrr1q3j5MmT9OrVi+7du7Nhw4Zc+128eDH169fH3d39mcT94MEDypUrx/Tp03FxcTHomISEBFq2bIm7uzvHjh3js88+Y+LEiXz99dfqPqmpqbRo0YKLFy/yww8/EBMTw6JFiyhV6t8cwP/93//h6enJt99++9TnIYmn/yituRl+lX14v8NbfNS1Ex90bM9HXTvxfoe38Kvsg4WZWbbH+fv7s/jrxerMpyc/LDPbtFotixctxr+hf7b9mGitKeHXlsrvL6TS0LkU92tLpaFzqfz+Qkr4tcXY4umKmQshhBBCCCEKR1pyEudXfwooeddqVTISUOdXf1qoy+6aNGnC0KFDGTVqFI6Ojri4uDBx4kR1e3bLu+7evYtGo2H37t3Av7N3tmzZgq+vL1qtlmbNmnHz5k1+++03fHx8sLW1pUuXLjx48MDguIYMGcLw4cNxcHDA2dmZRYsWcf/+fXr16oWNjQ1eXl789ttv6jHZzSLav38/TZo0wdLSEgcHBwIDA7lz5446RnBwMMOHD8fJyYnAwEAA9uzZQ506dTA3N8fV1ZUxY8aQ9sTdyNPS0ggODsbOzg4nJyfGjx+vV7N3xYoV1KpVCxsbG1xcXOjSpQs3b95Ur2nTpk0BcHBwQKPR0LNnTwB0Oh0zZszAy8sLc3NzypQpwyeffKI39vnz52natCmWlpZUq1aNgwcP6m3ft28f/v7+aLVa3NzcGDp0KPfv31e3L1iwAG9vbywsLHB2dtZLFOXX+++/T7169XB3d6d+/fqMGTOGQ4cO8ejRIwA++ugjpkyZQv369fH09GTYsGG0atWKH3/8Mdd+16xZQ7t27fTajhw5gr+/PzY2NlhZWVGlShWOHj1aoLhr167NZ599xrvvvou5ublBx6xcuZLU1FSWLl1K5cqVeffddxk6dCizZs1S91m6dCnx8fH8/PPPNGjQgLJly9K4cWOqVaum11e7du1Ys2ZNgWJ/3AuRePryyy8pW7YsFhYW1K1blyNHjuS4b5MmTdTkxuOPNm0Kdse0/zqNRoOlhQUONtZYWlgYlHX39/dn7569jP1oLG5u+nfWc3NzY+xHY9n3v305Jp2eHF9bogxl2vRBW6KMFCQUQgghhBDiBXP7xC50qQbeIAhAUdClphAfsbtQ41i+fDlWVlYcPnyYGTNmMHnyZLZt25bvfiZOnMj8+fM5cOAAly9fpmPHjsyePZtVq1axceNGtm7dyrx58/IVl5OTE0eOHGHIkCEMHDiQDh06UL9+fY4fP07Lli3p1q1bjsmsiIgImjdvTqVKlTh48CD79u2jXbt2pKen641hZmbG/v37CQsL48qVK7Ru3ZratWsTGRnJwoULWbJkCR9//HGW2ExMTDhy5Ahz5sxh1qxZLF68WN3+6NEjpkyZQmRkJD///DMXL15Uk0tubm6sW7cOgJiYGK5du8acOXMACAkJYfr06YwfP56oqChWrVqFs7P+apaxY8cycuRIIiIiKF++PJ07d1YTY+fOnaNVq1a0b9+ekydP8t1337Fv3z6Cg4MB+P333xk6dCiTJ08mJiaGzZs306jRv3dunzp1KtbW1rk+4uLisr3e8fHxrFy5kvr162Nqaprj83rv3j0cHR1z3B4fH09UVBS1atXSa3/33Xdxd3fnyJEj/Pnnn8yePVvv2uQV94ABA3Ic0xAHDx6kUaNGmD02mSQwMJCYmBg1mfnLL7/g5+fH4MGDcXZ25v/+7/+YOnWq3msOoE6dOhw5coSUlJSnigmliK1Zs0YxMzNTli5dqpw6dUrp27evYm9vr9y4cSPb/W/fvq1cu3ZNffz555+KsbGx8s033xg03r179xRAuXfvXiGexX+XTqdT4uPjlcuXLyvx8fGKTqcr6pCEEEIIIYR4pl7W7xTJyclKVFSUkpycbPAxOp1O+WNmf+X3sW/k8/Gm8sfM/oX2/aBx48ZKw4YN9dpq166tjB49WlEURblw4YICKCdOnFC337lzRwGUXbt2KYqiKLt27VIAZfv27eo+06ZNUwDl3Llzalv//v2VwMDAAsWVlpamWFlZKd26dVPbrl27pgDKwYMH9eK4c+eOoiiK0rlzZ6VBgwa5juHr66vX9tFHHykVKlTQu75ffvmlYm1traSnp6vH+fj46O0zevRoxcfHJ8exjh49qgBKYmJitrEqiqIkJCQo5ubmyqJFi7LtI/O5WLx4sdp26tQpBVCio6MVRVGUoKAgpV+/fnrH7d27VzEyMlKSk5OVdevWKba2tkpCQkK2Y9y+fVuJjY3N9fHo0SO9Y0aNGqVYWloqgFKvXj3l77//zvE6fPfdd4qZmZny559/5rjPiRMnFECJi4vTa3dzc1NCQkKU1NTUbI/LK+6cciHu7u7KF198kWM8mVq0aJHl2mZe/6ioKEVRFKVChQqKubm50rt3b+X3339X1qxZozg6OioTJ07UOy4yMlIBlIsXL2Y7lqGfKUU+42nWrFn07duXXr16UalSJcLCwrC0tGTp0qXZ7p85rTLzsW3bNiwtLenQocNzjlxAxowlBwcHSpcurU6/FEIIIYQQQrwa0h8kkhJ/vQBHKqTEXyc9ObHQYqlatarez66uruqysIL24+zsjKWlJeXKldNry0+/j/dnbGxMsWLFqFKlil5/QI59Zs54yk3NmjX1fo6OjsbPz0/v+1eDBg1ISkrir7/+Utvq1aunt4+fnx+xsbHqzJZjx47Rrl07ypQpg42NDY0bNwbIcbZQ5tgpKSl5xvz4dXF1dQX+vQaRkZEsW7ZMb6ZPYGAgOp2OCxcu0KJFC9zd3SlXrhzdunVj5cqVejPGHB0d8fLyyvVh8sQNtT788ENOnDjB1q1bMTY2pnv37nrLDjPt2rWLXr16sWjRIipXrpzj+SUnJwNgYWGh1/7jjz+yYsUKtFot1tbWWYpz5xV3iRIlcr2uhUGn01GiRAm+/vpratasSadOnRg7dixhYWF6+2m1WgCDl57mpEgTT6mpqRw7doyAgAC1zcjIiICAgCzrP3OyZMkS3n33Xayssq8JlJKSQkJCgt5DCCGEEEIIIUTe0lOTn+74lKc7/nFPLovSaDTodDog43skoJdIyKzfk1s/Go0m134LGteTYwA59pn55T43OX3ffRr3798nMDAQW1tbVq5cydGjR/npp5+A3AuYGxIvZL3O8O81SEpKon///kRERKiPyMhIYmNj8fT0xMbGhuPHj7N69WpcXV0JDQ2lWrVqal2sgiy1c3Jyonz58rRo0YI1a9awadMmDh06pLfPnj17aNeuHV988QXdu3fP9fycnJwA1OVrmUJCQqhduzYHDhwgIiICmydu6PWsl9q5uLhw44b+XSczf84sUO7q6kr58uUxNjZW9/Hx8eH69et6z318fDwAxYsXf6qYTPLe5dn5+++/SU9Pz7IW1NnZmdOnT+d5fOaaySVLluS4z7Rp05g0adJTxyqEEEIIIYQQ/zXGZoYlGXI83vzpjjdU5hfja9eu4eubcXfsxwuNv8iqVq3Kjh078vW91cfHh3Xr1qEoiprU2b9/PzY2NpQuXVrd7/Dhw3rHHTp0CG9vb4yNjTl9+jS3b99m+vTpau3e33//XW//zDpBj9f+8fb2RqvVsmPHDvr06ZO/k/1HjRo1iIqKwsvLK8d9TExMCAgIICAggAkTJmBvb8/OnTt5++23GTBgAB07dsx1jJIlS+a4LTMB9njtot27d9O2bVs+/fRT+vXrl+c5eHp6YmtrS1RUFOXLlwcychzbt28nIiIiS6HuTHm9Lp+8K3x++fn5MXbsWB49eqQm/7Zt20aFChVwcHAAMmbHrVq1Cp1OpyZtz5w5g6urq15tqD///JPSpUurSbaCKvKldk9jyZIlVKlShTp16uS4T0hICPfu3VMfly9ffo4RCiGEEEIIIcTLy9jSBnNHFyC/JTU0mDu6YKy1yXvXQqDVaqlXrx7Tp08nOjqaPXv2MG7cuOcy9tMKCQnh6NGjDBo0iJMnT3L69GkWLlzI33//neMxgwYN4vLlywwZMoTTp0+zfv16JkyYwIgRI9REAmQsmRsxYgQxMTGsXr2aefPmMWzYMADKlCmDmZkZ8+bN4/z58/zyyy9MmTJFbxx3d3c0Gg0bNmzg1q1bJCUlYWFhwejRoxk1ahTh4eGcO3eOQ4cO5Toh5EmjR4/mwIEDBAcHExERQWxsLOvXr1eLi2/YsIG5c+cSERHBpUuXCA8PR6fTUaFCBSB/S+0OHz7M/Pnz1b527txJ586d8fT0xM/PD8hYXtemTRuGDh1K+/btuX79OtevX1dn/GQnc7XWvn371DYnJyfc3NwIDQ3l2LFjXLp0id27d7N161Z1n/wstUtNTVVnhKWmpnLlyhUiIiI4e/asus/8+fP1lj126dIFMzMzgoKCOHXqFN999x1z5sxhxIgR6j4DBw4kPj6eYcOGcebMGTZu3MjUqVMZPHiw3jnu3buXli1bGvy85nitnrqHp+Dk5ISxsXG208Ayp4Dl5P79+6xZs4agoKBc9zM3N8fW1lbvIYQQQgghhBAibxqNhuL1CnYH8RJ+bZ9rDdilS5eSlpZGzZo1GT58eJY7vL2oypcvz9atW4mMjKROnTr4+fmxfv36LDWKHleqVCk2bdrEkSNHqFatGgMGDCAoKChLsq179+4kJydTp04dBg8ezLBhw9TZPP/P3n1HR1H2bRy/Jm1JIAkJQoKBCApKUQTp+oBSFAVUioighCIoSlMeFJD2IkpAkCZVBBFUEAR8pIgiAtJRiig1oJhQQjGkh03Zef8IWRNqAmw25fs5Jwdzz8zOL87JZubau5QsWVLz5s3TkiVLVKVKFY0ZM0bjx4+/4jwjR47UoEGDFBAQYA+Ghg0bpv/+978aPny4KleurPbt2+d4XqyNGzfqyJEjatCggWrUqKHhw4fbeykVL15cy5YtU+PGjVW5cmXNnDlTCxcuvO6cS9fi5eWlZcuWqUmTJrrvvvv08ssv289vsVgkpa/+l5iYqNDQUJUuXdr+1aZNm+u+dvfu3bVo0aIswyi/++472Ww2NWvWTPfee6969OhxReaRXadOnVKNGjVUo0YNnT59WuPHj1eNGjWy9DQ7f/68jh07Zv/e19dXP/zwg/766y/VrFnTfp0y9+IqW7asvv/+e/3yyy+qVq2a+vbtq379+mnQoEH2fS5evKhvvvlGPXr0uKnaMzPMq82mlYvq1q2rOnXq2JertNlsCg4OVu/evbP80JebN2+eevbsqZMnT6pEiRLZPl9sbKx8fX0VExNDCAUAAAAgx/LrM8XFixf1119/qXz58ldMiHw9qUnx+n1cd9lSrFJ2Hh8NQy7uFj3w1idy8yx2CxUDeZtpmqpbt67efPNNdejQwdnl3FYzZszQ8uXLs/TWulx231OcPtSuf//+mj17tj777DMdPHhQr732mhISEtS1a1dJ6Qnt4MGDrzhuzpw5atWqVY5CJwAAAABAzrh5FtPdHQZKMqQb9WAyDEmG7ukwkNAJBZ5hGPr444+Vmprq7FJuO3d3d3sHoVvl1MnFJal9+/Y6d+6chg8frsjISFWvXl1r1qyxTzgeHh6eZYyqJB0+fFibN2++bvIGAAAAALg9fCvWUIWQYfpz4VjZkjMmZM7c+yk9kHJxt+ieDgPlU7FGrtd4u4WHh6tKlSrX3H7gwAEFBwfnYkXIi6pXr67q1as7u4zb7mYnjr8apw+1y235tVssAAAAgLwhvz5T3OxQu8xSk+IVtXeDzm5bKWtUpL3d4h+oUvVbqkSNRnItUvR2lexUqampOn78+DW3lytX7rrzMAEFXXbfU/gtAQAAAABki5tnMZWq31Il67VQWlKc0qxJcrV4ytXTO1cnEs8Nbm5uqlChgrPLAPI9gicAAAAAQI4YhiE3Lx+5eeWfHl8AnMPpk4sDAAAAAHJPIZttBYCDZPe9hOAJAAAAAAoBd3d3SVJiYqKTKwFQEGS8l2S8t1wLQ+0AAAAAoBBwdXVV8eLFdfbsWUmSl5dXgZuXCYDjmaapxMREnT17VsWLF5erq+t19yd4AgAAAIBCIjAwUJLs4RMA3KzixYvb31Ouh+AJAAAAAAoJwzBUunRplSpVSikpKc4uB0A+5e7ufsOeThkIngAAAACgkHF1dc32QyMA3AomFwcAAAAAAIBDEDwBAAAAAADAIQieAAAAAAAA4BAETwAAAAAAAHAIgicAAAAAAAA4BMETAAAAAAAAHILgCQAAAAAAAA5B8AQAAAAAAACHIHgCAAAAAACAQxA8AQAAAAAAwCEIngAAAAAAAOAQBE8AAAAAAABwCIInAAAAAAAAOATBEwAAAAAAAByC4AkAAAAAAAAOQfAEAACAfOXs2bOa8tEUnT171tmlAACAGyB4AgAAQL5y7tw5fTT1I507d87ZpQAAgBsgeAIAAAAAAIBDEDwBAAAAAADAIQieAAAAAAAA4BAETwAAAAAAAHAIgicAAAAAAAA4BMETAAAAAAAAHILgCQAAAAAAAA5B8AQAAAAAAACHIHgCAAAAAACAQxA8AQAAAAAAwCEIngAAAJCr4hITtW73XsUlJjq7FAAA4GAETwAAAMhVcYlJWr/nN8UlJjm7FAAA4GAETwAAAAAAAHAIgicAAAAAAAA4BMETAAAAAAAAHILgCQAAAAAAAA7h9OBp2rRpKleunIoUKaK6detq586d190/OjpavXr1UunSpWWxWHTvvfdq9erVuVQtAAAAAAAAssvNmSf/6quv1L9/f82cOVN169bVpEmT1KxZMx0+fFilSpW6Yv/k5GQ9/vjjKlWqlL7++msFBQXp77//VvHixXO/eAAAAAAAAFyXU4OnCRMmqEePHurataskaebMmVq1apXmzp2rQYMGXbH/3LlzFRUVpa1bt8rd3V2SVK5cudwsGQAAAAAAANnktKF2ycnJ2rVrl5o2bfpvMS4uatq0qbZt23bVY7799lvVr19fvXr1UkBAgO6//36NHj1aaWlp1zyP1WpVbGxsli8AAAAAAAA4ntOCp/PnzystLU0BAQFZ2gMCAhQZGXnVY/788099/fXXSktL0+rVqzVs2DB9+OGHeu+99655ntDQUPn6+tq/ypYte1t/DgAAAAAAAFyd0ycXzwmbzaZSpUrp448/Vs2aNdW+fXsNGTJEM2fOvOYxgwcPVkxMjP0rIiIiFysGAADA7WSapmJiYyRJMbExMk0zx6+REhelU+sWKiUu6naXBwAALuO0OZ7uuOMOubq66syZM1naz5w5o8DAwKseU7p0abm7u8vV1dXeVrlyZUVGRio5OVkeHh5XHGOxWGSxWG5v8QAAAMhVsbGxWrZ8mRZ8vkDh4eGSpM5dOis4OFidXuqkNq3byMfHJ1uvlRJ3QafXf6XilevI3dvfkWUDAFDoOa3Hk4eHh2rWrKl169bZ22w2m9atW6f69etf9ZhHHnlER48elc1ms7cdOXJEpUuXvmroBAAAgPxv06ZNavBoA40OHX1F7/WIiAiNDh2tBo820KZNm5xUIQAAuBanDrXr37+/Zs+erc8++0wHDx7Ua6+9poSEBPsqdyEhIRo8eLB9/9dee01RUVHq16+fjhw5olWrVmn06NHq1auXs34EAAAAONCmTZvU/ZXuSkpKkmmaVwyty2hLSkpS91e63zB8Mk1TqUkJkqTUpISbGqoHAACyz2lD7SSpffv2OnfunIYPH67IyEhVr15da9assU84Hh4eLheXf7OxsmXL6vvvv9ebb76patWqKSgoSP369dPAgQOd9SMAAADAQWJjY9W7b++rBk6Xy9jeu29vbdq46Yphd6lJ8fpnz3qd275K1qj0hWzCPh0ui3+gStZroRI1GsnNs5hjfhAAAAoxwyxkH/PExsbK19dXMTEx2Z4HAAAAALfPqfP/aPr/Vur1Z1vqzjtKXHO/eZ/N0+jQ0TnqlWQYhoa8M0SdQzrb22LC9ujPhWNlS7Zeasn8eoYkycXDors7DJRvxRo5+VFQSPFMAQDZl69WtQMAAEDhYJqmFny+4KaOnb9gvj2signbo6PzR8mWYlV64HR5iJXeZkux6uj8UYoJ23MrZQMAgMsQPAEAACDPuXDhgsLDw3M8B5NpmgoPD1d0dLRSk+L158KxkkzpRq9jpgdQfy4cq9Sk+JuuGwAAZEXwBAAAgFxjmqaSLg15S0q2XjNYSkxMvKXzJCQk6J8969OH12U3vDJN2ZKtitq74ZbODQAA/uXUycUBAACQDyWflSK/lAI7Sh6lsnVIkjVZe8KOavuBQ4qKi5MkffrdWvl7e6telUqqUbGCPC0e9v29vLxuqUQvLy+d2r5KVw6tu7Gz21aqZL0WMgzjlmoAAAD0eAIAAEBOJZ+VTkxO/zcbwk6c1LhFS7R6xy/20ClDVFycVu/4ReMWLVHYiZP2dj8/PwUHB+c4/DEMQ8HBwfL2cLWvXpczpqxRkUpLirvxrgAA4IYIngAAAOAwYSdOav4P65SSmnrd/VJSUzX/h3X28MkwDHV6qdNNnTOkU4hsKRdv6tgMadakWzoeAACkI3gCAACAQyRZk7Vw3QbJNG844M2UJNPUwnUblGRNliS1ad1Gnp6e2e715OLiIk9PT7Vu1VquHp63UrpcLbd2PAAASEfwBAAAgOwzTSk1Jv2/U2OuO3H3nrCjSk5NzfYsS6ak5NRU7T16TJLk4+OjqVOmyjCMG4ZPGdunfjRVPj4+cvXylsU/UFJO52kyZPEPlKundw6PAwAAV0PwBAAAgBtLjZVOfSrtfkw68FJ624GX0r8/9Wn69kxM09T2A4du6lTb9h+0r3bXoEEDffLxJ/aeT5cHUBltnp6e+mT2J2rwnwb29pL1WtzU+UvVb8nE4gAA3CYETwAAALi+CxulX+tLx0dJ1ois26wR6e2/1k/f75JEq/WKicSzKyouTklWq/37Bg0aaNPGTRryzhCVLVs2y75ly5bVkHeGaPPPm+2hU4YSNRrJxcMiZTdEMgy5eFjkX/2xm6obAABcieAJAAAA13Zho3Swm2RLUvpguMsHzl1qsyWl73cpfEpOuf5k4jdivex4Hx8fdQ7prB9/+FHz582XJM2fN18//vCjOod0lrf3lUPj3DyL6e4OAyUZNw6fDEOSoXs6DJSbZ7Fbqh0AAPyL4AkAAABXlxorHX5dVw+cLndpn8OvS6mx8nB3u6VTW65xvGEY8vHxkZQeRt1oSJxvxRqqEDJMLu4Wpc/3dPn+6W0u7hZVDBkmn4o1bqluAACQ1a3dEQAAAKDgOrs0U0+n7LjU8+ncUnkFdpG/t/dNDbfz9/aWp8WS4+OuxbdiDT3w1ieK2rtBZ7etlDUq0r7N4h+gUvVbqkSNRnItUvS2nRMAAKQjeAIAAMCVTFM6Pe/mjj01T0ZgF9WrUkmrd/yS48PrV6182yf3dvMsplL1W6pkvRaK++t3hc0drord3pV3+QeYSBwAAAdiqB0AAACulHpBsoYr+72dMpjpx6VGq0bFCvJwc7ticNu1GJI83NxUvcI9OTxn9hmGIbdLPZvcihQldAIAwMEIngAAAHCltMRbPD5BnhYPdWjymGQYNwyfDEkyDHVo8pg8LR63dm4AAJBnEDwBAADgSq5et3h8eq+iimWCFPJEE7m7XX+GB3c3N4U80UQVywTd2nkBAECewhxPAAAAuJKbn2QJlqwRytlwO0OylJXcittbKpYJ0lsvtNPeo8e0bf/BLBOO+3t7q37VyqpR8R4V8aCnEwAABQ3BEwAAAK5kGFLpLtLxUTk/9s4u6cdn4mnxUP2qlVWvSiX9dfq05n63Vt2eelzlS5dmniUAAAowhtoBAADg6kq1lVw8pWxPD+6Svn/JttfcwzAMFfGwSJKKeFgInQAAKOAIngAAAHB1bj7SfdOVHjxla3pwqdKM9OMAAABE8AQAAIDr8XtUqjw3U8+nywOoS20unlKVT6XiDXO/RgAAkGcxxxMAAACuz+9RqdY26dxS6dQ8yRr+7zZL2fQ5nUq2pacTAAC4wk0FT6mpqdqwYYOOHTumjh07ytvbW6dOnZKPj4+KFSt2u2sEAACAs7n5SKW7SoFdpJht0oEXpSpfSL71r5hIHAAAIEOOg6e///5bTz75pMLDw2W1WvX444/L29tbY8eOldVq1cyZMx1RJwAAAPICw/i3Z5ObD6ETAAC4rhzP8dSvXz/VqlVLFy5ckKenp729devWWrdu3W0tDgAAALjd3L39VLpRe7l7+zm7FAAACrwc93jatGmTtm7dKg8Pjyzt5cqV08mTJ29bYQAAAIAjuHv7684mHZxdBgAAhUKOezzZbDalpaVd0X7ixAl5e3vflqIAAAAAAACQ/+U4eHriiSc0adIk+/eGYSg+Pl4jRoxQ8+bNb2dtAAAAwBVKliypPr37qGTJks4uBQAA3ECOh9p9+OGHatasmapUqaKLFy+qY8eOCgsL0x133KGFCxc6okYAAADArlSpUurbp6+zywAAANmQ4+CpTJky+u2337Ro0SLt27dP8fHxevnll/Xiiy9mmWwcAAAAAAAAhVuOgydJcnNz00svvXS7awEAAPmMaZqKirMqPilFxTzd5e9tkWEYzi4LAAAAeUSOg6f58+dfd3tISMhNFwMAAPKH6Hirvlx/VLNWHtRfkXH29vKB3nq1ZWV1bFRBxYtZnFghHMqjlFSmX/q/AAAA12GYpmnm5AA/P78s36ekpCgxMVEeHh7y8vJSVFTUbS3wdouNjZWvr69iYmLk4+Pj7HIAAMh3ftx9Up3G/qREa6okKfOdREZnJy+LmxYMbKymDwU5oULkdXGJidp56IjqVLpX3l5ezi4HyDGeKQAg+3K8qt2FCxeyfMXHx+vw4cP6z3/+w+TiAAAUcD/uPql2o9YqyZoq08waOkmytyVZU9Vu1Fr9uPukcwpFnubt5aUmD1UndAIAoBDIcfB0NRUrVtSYMWPUr1+/2/FyAAAgD4qOt6rT2J9kmqZsN+gvbTPT53/qNPYnRcdbc6dAAAAA5Dm3JXiS0iccP3Xq1O16OQAAkMd8uf6oEq2pNwydMthMKdGaqoXrjzm2MAAAAORZOZ5c/Ntvv83yvWmaOn36tKZOnapHHnnkthUGFFjJZ6XIL6XAjjc1KSvzYgBwBtM0NWvlQSlHM0Omm7nygHq2rMxqdwAAAIVQjoOnVq1aZfneMAyVLFlSjRs31ocffni76gIKruSz0onJkn/TmwyekrR+z2+qHFyW4AlAromKs2ZZvS67TFP6KzJOUXFWlfAp4oDKAAAAkJflOHiy2WyOqAMAAORh8Ukpt3w8wRMAAEDhc9vmeAKQf5w9e1ZTPpqis2fPOrsUAPlEMU93px4PAACA/ClbPZ769++f7RecMGFCjouYNm2axo0bp8jISD344IP66KOPVKdOnavuO2/ePHXt2jVLm8Vi0cWLF3N8XqCwOnfunD6a+pGaNG6iUqVyPtwPQOHj721R+UBvHT8TJzMH8zwZhlQuwFv+3hbHFQcAAIA8K1vB0549e7L1YjczaehXX32l/v37a+bMmapbt64mTZqkZs2a6fDhw9d8IPbx8dHhw4dv6bwAACD7DMPQqy0ra/CcnTk+tmfLKvytBgAAKKSyFTytX7/eYQVMmDBBPXr0sPdimjlzplatWqW5c+dq0KBBVz3GMAwFBgY6rCbAYUxTSo1J/+/UmPTveRgDkE90bFRBoz7frSRrqmzZ6PXkYkieFjd1aHSP44sDAABAnuTUOZ6Sk5O1a9cuNW3a1N7m4uKipk2batu2bdc8Lj4+XnfddZfKli2rZ599Vvv377/mvlarVbGxsVm+gFyXGiud+lTa/Zh04KX0tgMvpX9/6tP07flISlyUTq1bqJS4KGeXAiAXFS9m0YKBjWUYhlxukJm7GOkfFH0+qLGKF2OYHQAAQGGV41XtJOnXX3/V4sWLFR4eruTk5Czbli1blu3XOX/+vNLS0hQQEJClPSAgQIcOHbrqMffdd5/mzp2ratWqKSYmRuPHj9fDDz+s/fv3q0yZMlfsHxoaqpEjR2a7JuC2u7BROvy6ZEu6cps1Qjo+SgofL903XfJ7NPfruwkpcRd0ev1XKl65jty9/Z1dDoBc1PShIC0Z9rg6jf1JidZUScoy51NGJ05Pi5s+H9RYTWoEOaFKAAAA5BU57vG0aNEiPfzwwzp48KCWL1+ulJQU7d+/Xz/99JN8fX0dUWMW9evXV0hIiKpXr65HH31Uy5YtU8mSJTVr1qyr7j948GDFxMTYvyIiIhxeI2B3YaN0sNul0Mm89JXZpTZbUvp+Fzbmfo0AkENNHwrSwTnPa8zLdVUuwDvLtnIB3hrzcl0dmtue0AkAAAA57/E0evRoTZw4Ub169ZK3t7cmT56s8uXL69VXX1Xp0qVz9Fp33HGHXF1ddebMmSztZ86cyfYcTu7u7qpRo4aOHj161e0Wi0UWC1384QSpsek9na4aOF3u0vbDr0u1tkluPg4uDgBuTfFiFr32dBX1bFlZUXFWxSelqJinu/y9LUwkDgAAALsc93g6duyYWrRoIUny8PBQQkKCDMPQm2++qY8//jhHr+Xh4aGaNWtq3bp19jabzaZ169apfv362XqNtLQ0/f777zkOvQCHO7s0U0+n7LjU8+nc0mvvYZpKSrZKkpKSrTJzsqY5ADiAYRgq4VNEdwV4q4RPEUInAAAAZJHjHk9+fn6Ki4uTJAUFBemPP/7QAw88oOjoaCUmJua4gP79+6tz586qVauW6tSpo0mTJikhIcG+yl1ISIiCgoIUGhoqSXr33XdVr149VahQQdHR0Ro3bpz+/vtvde/ePcfnBhzGNKXT827u2FPzpMAuWVa7S7Ima0/YUW0/cEhRl37/Pv1urfy9vVWvSiXVqFhBnhaPWy4bAAAAAIDbKdvB0x9//KH7779fDRs21Nq1a/XAAw+oXbt26tevn3766SetXbtWTZo0yXEB7du317lz5zR8+HBFRkaqevXqWrNmjX3C8fDwcLm4/Nsx68KFC+rRo4ciIyPl5+enmjVrauvWrapSpUqOzw04TOoFyRp+Ewea6celRkvufpKksBMntXDdBiWnpl6xd1RcnFbv+EU/7tqjDk0eU8UyzKcCAAAAAMg7sh08VatWTbVr11arVq3Url07SdKQIUPk7u6urVu3qm3btho6dOhNFdG7d2/17t37qts2bNiQ5fuJEydq4sSJN3UeINek5bz3X9bjEyR3P4WdOKn5P6zLumTUVaSkpmr+D+sU8kQTwicAAAAAQJ6R7TmeNm7cqKpVqyo0NFSVK1dW586dtWXLFg0aNEjffvutPvzwQ/n5+TmyViD/cPW6xeOLKsmarIXrNkimmb2pyU1TC9dtUJI1+dbOfaNzmaZSkxIkSalJCcwzBQAAAAC4pmwHTw0aNNDcuXN1+vRpffTRRzp+/LgeffRR3XvvvRo7dqwiIyMdWSeQv7j5SZZgSTmdZNdIP86tuPaEHVVyampOpiZXcmqq9h49lsNzZk9qUrzObF2h/RNfU9inwyVJYZ8O1/6Jr+nM1hVKTYp3yHkBAAAAAPlXjle1K1q0qLp27aqNGzfqyJEjateunaZNm6bg4GA988wzjqgRyH8MQyrd5eaOvbOLTEnbDxy6qcO37T9423shxYTt0e/juuvE6rmyRp3Jss0adUYnVs/V7+O6KyZsz209LwAAAAAgf8tx8JRZhQoV9M4772jo0KHy9vbWqlWrblddQP5Xqq3k4qns93pySd+/ZFslWq321etyKiouTklW6zW3m6apmNgYSVJMbMwNQ6qYsD06On+UbClWpferunz/9DZbilVH548ifAIAAAAA2N108PTzzz+rS5cuCgwM1FtvvaU2bdpoy5Ytt7M2IH9z85Hum6704OlG4dOl7ZVmSG4+Sk65cgW7nLBe5fjY2FjN+2yemj7RVJ27dJYkde7SWU2faKp5n81TbGzsFcekJsXrz4VjJZk3nOA8fbupPxeOZdgdAAAAAEBSDoOnU6dOafTo0br33nv12GOP6ejRo5oyZYpOnTql2bNnq169eo6qE8if/B6VKs/N1PPp8gDqUpuLp1TlU6l4Q0mSh3u2F5y8Kstlx2/atEkNHm2g0aGjFRERkWVbRESERoeOVoNHG2jTpk1Ztv2zZ71sydYbh04ZTFO2ZKui9m64lfIBAAAAAAVEtoOnp556SnfddZc++ugjtW7dWgcPHtTmzZvVtWtXFS1a1JE1Avmb36NSrW1S+WGSpWzWbZay6e21ttlDJ0nysljk7+19U6fz9/aWp8Vi/37Tpk3q/kp3JSUlyTTNK4bWZbQlJSWp+yvd7eGTaZo6t32Vrhxad2Nnt61ktTsAAAAAgLLdrcLd3V1ff/21WrZsKVdXV0fWBBQ8bj5S6a5SYBcpZpt04EWpyheSb/30icgvYxiG6lWppNU7fsnxqepXrSzj0mvGxsaqd9/eVw2cLpexvXff3tq0cZO8XCVr1M2sVmnKGhWptKQ4uXn53MTxAAAAAICCIts9nr799ls9++yzhE7ArTCM9BBKSv/3KqFThhoVK8jDzS3bU5Mbkjzc3FS9wj32tmXLl9l7OmVHRs+n5d8sV1pyUjbPfHVp1ls7HgAAAACQ/93SqnYAHMfT4qEOTR6TDCN7U5Mbhjo0eUyeFg9J6SHSgs8X3NS55y+YLxf3Ijd1bAZXi+ctHQ8AAAAAyP8InoDc5lFKKtMv/d8bqFgmSCFPNJG72/VHxbq7uSnkiSaqWCbI3nbhwgWFh4fneK4l0zQVHh6uuOQ0WfwDdeMV+S5nyOIfKFfPm5ujCgAAAABQcNza0lkAcs6jlBT8RrZ3r1gmSG+90E57jx7Ttv0HFRUXZ9/m7+2t+lUrq0bFe1TEwyPLcYmJibdUZmJiokrWa6ETq+fm+NhS9Vva55kCAAAAABReBE9APuBp8VD9qpVVr0ol/XX6tOZ+t1bdnnpc5UuXvmbA4+XldUvnLFq0qLxrNNKpH7+QLcUqZafnlGHIxd0i/+qP3dK5AQAAAAAFA0PtgHzEMAwV8bBIkop4WK7bq8jPz0/BwcE57nlkGIaCg4NVvHhxuXkW090dBkoyrjsR+qUDJRm6p8NAuXkWy9E5AQAAAAAFE8ETUEAZhqFOL3W6qWNDOoXYAyvfijVUIWSYXNwtSp/v6fIAKr3Nxd2iiiHD5FOxxq2UDQAAAAAoQAiegAKsTes28vT0zHavJxcXF3l6eqp1q9ZZ2n0r1tADb32isi1elsU/IMs2i3+AyrZ4WdXenkPoBAAAAADIgjmegALMx8dHU6dMVfdXukvSdVe4ywinpn40VT4+Pldsd/MsplL1W6pkvRaK++t3hc0drord3pV3+QeYSBwAAAAAcFX0eAIKuAYNGuiTjz+x93y6PCTKaPP09NQnsz9Rg/80uO7rGYYhz5JlVLpRe3mWLEPoBAAAAAC4Jno8AYVAgwYNtGnjJi3/ZrnmL5iv8PBw+7ayZcsqpFOI2rRuI29v72y9nru3v+5s0sFR5QIAAAAACgiCJ6CQ8PHxUeeQzgrpFKLt27crpEuI5s+br3r16tFrCQAAAADgEAy1AwoZwzDsczj5+PgQOgEAAAAAHIbgCQAAAAAAAA5B8AQAAAAAAACHIHgCAAAAAACAQxA8AQAAAAAAwCEIngAAAAAAAOAQBE9APuPt5alGNR6Ut5ens0sBAAAAAOC63JxdAICc8fbyUpOHqju7DAAAAAAAbogeTwAAAAAAAHAIgicAAAAAAAA4BMETAAAAAAAAHILgCQAAAAAAAA5B8AQAAAAAAACHIHgCAAAAAACAQxA8AQAAAAAAwCEIngAAAAAAAOAQBE9AIVSyZEn16d1HJUuWdHYpAAAAAIACzDBN03R2EbkpNjZWvr6+iomJkY+Pj7PLAQAAAJDP8EwBANlHjycAAAAAAAA4BMETAAAAAAAAHILgCQAAAAAAAA6RJ4KnadOmqVy5cipSpIjq1q2rnTt3Zuu4RYsWyTAMtWrVyrEFAgAAAAAAIMecHjx99dVX6t+/v0aMGKHdu3frwQcfVLNmzXT27NnrHnf8+HENGDBADRo0yKVKAQAAAAAAkBNOD54mTJigHj16qGvXrqpSpYpmzpwpLy8vzZ0795rHpKWl6cUXX9TIkSN1991352K1AAAAAAAAyC6nBk/JycnatWuXmjZtam9zcXFR06ZNtW3btmse9+6776pUqVJ6+eWXb3gOq9Wq2NjYLF8AAAAAAABwPKcGT+fPn1daWpoCAgKytAcEBCgyMvKqx2zevFlz5szR7Nmzs3WO0NBQ+fr62r/Kli17y3UDAAAAAADgxpw+1C4n4uLi1KlTJ82ePVt33HFHto4ZPHiwYmJi7F8REREOrhIAAAAAAACS5ObMk99xxx1ydXXVmTNnsrSfOXNGgYGBV+x/7NgxHT9+XE8//bS9zWazSZLc3Nx0+PBh3XPPPVmOsVgsslgsDqgeAAAAAAAA1+PUHk8eHh6qWbOm1q1bZ2+z2Wxat26d6tevf8X+lSpV0u+//669e/fav5555hk1atRIe/fuZRgdAAAAAABAHuLUHk+S1L9/f3Xu3Fm1atVSnTp1NGnSJCUkJKhr166SpJCQEAUFBSk0NFRFihTR/fffn+X44sWLS9IV7QAAAAAAAHAupwdP7du317lz5zR8+HBFRkaqevXqWrNmjX3C8fDwcLm45KupqAAAAAAAACDJME3TdHYRuSk2Nla+vr6KiYmRj4+Ps8sBAAAAkM/wTAEA2UdXIgAAAAAAADgEwRMAAAAAAAAcwulzPAGAo5imqag4q+KTUlTM013+3hYZhuHssgAAAACg0CB4AlDgRMdb9eX6o5q18qD+ioyzt5cP9NarLSurY6MKKl7M4sQKAQAAAKBwYHJxAAXKj7tPqtPYn5RoTZUkZX6Hy+js5GVx04KBjdX0oSAnVAgAAPI7nikAIPuY4wlAgfHj7pNqN2qtkqypMs2soZMke1uSNVXtRq3Vj7tPOqdQAAAAACgkCJ4AFAjR8VZ1GvuTTNOU7Qb9OG1m+vxPncb+pOh4a+4UCAAAAACFEMETgALhy/VHlWhNvWHolMFmSonWVC1cf8yxhQEAAABAIUbwBCDfM01Ts1YelG5ixrqZKw+okE11BwAAAAC5huAJQL4XFWfVX5FxOc6dTFP6KzJOUXEMtwMAAAAARyB4ApDvxSelOPV4AAAAAMDVETwByPeKebo79XgAAAAAwNURPAHI9/y9LSof6C3DyNlxhiGVD/SWv7fFMYUBAAAAQCFH8AQg3zMMQ6+2rHxTx/ZsWUVGThMrAAAAAEC2EDwBKBA6NqogL4ubXLKZIbkYkpfFTR0a3ePYwgAAAACgECN4AlAgFC9m0YKBjWUYxg3DJxcjvZfU54Maq3gxhtkBAAAAgKMQPAEoMJo+FKQlwx6Xp8VNhqEr5nzKaPO0uOnr4Y+rSY0g5xQKAAAAAIWEm7MLAIDbqelDQTo453ktXH9MM1ce0F+RcfZt5QK81bNlFXVsXEG+RT2cWCUAAAAAFA6GaZqms4vITbGxsfL19VVMTIx8fHycXQ4ABzJNUz//flpPD/teK0Y1U8MHSjOROAAAuGU8UwBA9jHUDkCBZRiGvWeTb1EPQicAAAAAyGUETwAKtEA/Lw16oboC/bycXQoAAAAAFDrM8QSgQAv099I7HWo4uwwAAAAAKJTo8QQAAAAAAACHIHgCAAAAAACAQxA8AQAAAAAAwCEIngAAAAAAAOAQBE8AAAAAAABwCIInAAAAAAAAOATBEwAAAAAAAByC4AkAAAAAAAAOQfAEAAAAAAAAhyB4AgAAAAAAgEMQPAEAAAAAAMAhCJ4AAAAAAADgEARPAAAAAAAAcAiCJwAAAAAAADgEwRMAAAAAAAAcguAJAAAAAAAADkHwBAAAAAAAAIcgeAIAAAAAAIBDEDwBAAAAAADAIfJE8DRt2jSVK1dORYoUUd26dbVz585r7rts2TLVqlVLxYsXV9GiRVW9enUtWLAgF6sFAAAAAABAdjg9ePrqq6/Uv39/jRgxQrt379aDDz6oZs2a6ezZs1fd39/fX0OGDNG2bdu0b98+de3aVV27dtX333+fy5UDAAAAAADgegzTNE1nFlC3bl3Vrl1bU6dOlSTZbDaVLVtWffr00aBBg7L1Gg899JBatGihUaNG3XDf2NhY+fr6KiYmRj4+PrdUOwAAAIDCh2cKAMg+p/Z4Sk5O1q5du9S0aVN7m4uLi5o2bapt27bd8HjTNLVu3TodPnxYDRs2dGSpAAAAAAAAyCE3Z578/PnzSktLU0BAQJb2gIAAHTp06JrHxcTEKCgoSFarVa6urpo+fboef/zxq+5rtVpltVrt38fGxt6e4gEAAAAAAHBdTg2ebpa3t7f27t2r+Ph4rVu3Tv3799fdd9+txx577Ip9Q0NDNXLkyNwvEgAAAAAAoJBzavB0xx13yNXVVWfOnMnSfubMGQUGBl7zOBcXF1WoUEGSVL16dR08eFChoaFXDZ4GDx6s/v3727+PjY1V2bJlb88PAAAAAAAAgGty6hxPHh4eqlmzptatW2dvs9lsWrdunerXr5/t17HZbFmG02VmsVjk4+OT5QsAAAAAAACO5/Shdv3791fnzp1Vq1Yt1alTR5MmTVJCQoK6du0qSQoJCVFQUJBCQ0MlpQ+dq1Wrlu655x5ZrVatXr1aCxYs0IwZM5z5YwAAgJthmlLqBSktUXL1ktz8JMNwdlUAAAC4TZwePLVv317nzp3T8OHDFRkZqerVq2vNmjX2CcfDw8Pl4vJvx6yEhAS9/vrrOnHihDw9PVWpUiV9/vnnat++vbN+BAAAkFOpsdLZpdLpeZI1/N92S7BUuotUqq3kduNeyqZpKtFqVXJKqjzc3eRlscgguAIAAMgzDNM0TWcXkZtiY2Pl6+urmJgYht0BAOAMFzZKh1+XbEmXGjLfilwKjVw8pfumS36PXvUlkqzJ2hN2VNsPHFJUXJy93d/bW/WqVFKNihXkafFwTP2XMU1TaYlxSktOkquHp1y9vAm/gAKOZwoAyD6CJwAAkHsubJQOdlN62HS9WxAj/avy3CvCp7ATJ7Vw3QYlp6Ze82gPNzd1aPKYKpYJumFJpmnqwoULSkxMlJeXl/z8/LIVHKUmxeufPet1bvsqWaMi7e0W/0CVrNdCJWo0kptnsRu+DoD8h2cKAMg+gicAAJA7UmOlX+tf6umUndsPI73nU61t9mF3YSdOav4P6yTTvGFsJcNQyBNNrhk+xcbGatnyZVrw+QKFh/873C84OFidXuqkNq3bXPNeISZsj/5cOFa25IzFTa7steXiYdHdHQbKt2KNbPysAPITnikAIPucuqodAAAoRM4uzUHopPT9bEnSuaWS0ofXLVy34YahkzLOYJpauG6DkqzJV2zftGmTGjzaQKNDRysiIiLLtoiICI0OHa0GjzbQpk2brjg2JmyPjs4fJVuKVVfvuZXeZkux6uj8UYoJ25O9HxcAAKAAIngCAACOZ5rpE4nfjFPzJNPUnrCjSk5NzUlspeTUVO09eixL+6ZNm9T9le5KSkqSaZq6vPN3RltSUpK6v9I9S/iUmhSvPxeOTX/1G3UaN9MDqD8XjlVqUnw2qwYAAChYCJ4AAIDjpV64tHpdTkf4m5I1XGbKBW0/cOimTr1t/0F7uBQbG6vefXtfNXC64syX9undt7diY2MlSf/sWZ8+vC67MxWYpmzJVkXt3XBTtQMAAOR3BE8AAMDx0hJv6fDExOgsq9flRFRcnJKs6XMxLVu+zN7TKTsyej4t/2a5TNPUue2rlPPwTDq7bWW2zwkAAFCQEDwBAADHc/W6pcOTTcstHW9NSZVpmlrw+YKbOn7+gvlKTYjNsnpd9pmyRkUqLenmgjMAAID8jOAJAAA4npufZAlWxopv2WdIlmB5FPG/pdNb3N104cIFhYeH57jnkWmaCg8P14XzZ2+phjRr0i0dDwAAkB8RPAEAAMczDKl0l5s79s4u8ipSRP7e3jd1uL+3tzwtFiUm3tpwv4spabd0vKvF85aOBwAAyI8IngAAQO4o1VZy8VT2ez25pO9fsq0Mw1C9KpVu6rT1q1aWYRjy8rq14X7FSpSSxT9QN9Nry+IfKFfPmwvOAAAA8jOCJwAAkDvcfKT7pis9uLlReHNpe6UZ6cdJqlGxgjzc3LId+xiSPNzcVL3CPZIkPz8/BQcHyzByFhwZhqHg4GD5+fmpZL0WOTo2Q6n6LXN8XgAAgIKA4AkAAOQev0elynMz9Xy6PIy51ObiKVX5VCre0L7F0+KhDk0ekwwje7GVYahDk8fkafFIbzMMdXqp002VHdIpRIZhqESNRnLxsKQPHcwOw5CLh0X+1R+7qfMCAADkdwRPAAAgd/k9KtXaJpUfJlnKZt1mKZveXmtbltApQ8UyQQp5oonc3dyuewp3NzeFPNFEFcsEZWlv07qNPD09s937yMXFRZ6enmrdqrUkyc2zmO7uMFCScePwyUgP0e7pMFBunsWydT4AAICCxjBzurRLPhcbGytfX1/FxMTIx8fH2eUAAFC4maaUGi2lJUiuRSW34tnqTZRkTdbeo8e0bf9BRcXF2dv9vb1Vv2pl1ah4j4p4eFz12E2bNqn7K91lmuZ1V7gzDEOGYeiT2Z+owX8aZNkWE7ZHfy4cK1uyNeMHyXykJMnFw6J7OgyUT8UaN/x5AOQvPFMAQPYRPAEAgHzLNE0lWa2ypqTK4u4mT4slW72ZNm3apN59eyspKcn+Ohkyjvf09NTUj6ZeETplSE2KV9TeDTq7baWsUZH2dot/oErVb6kSNRrJtUjRW/nxAORRPFMAQPYRPAEAgEIpNjZWy79ZrvkL5is8PNzeHhwcrJBOIWrTuo28vW+8Ep1pmkpLilOaNUmuFk+5enozkThQwPFMAQDZR/AEAAAKNdM0FR0drYSEBBUtWlTFixcnOAJwXTxTAED2XX9mTgAAgALOMAz5+fnJz8/P2aUAAAAUOKxqBwAAAAAAAIcgeAIAAAAAAIBDEDwBAAAAAADAIQieAAAAAAAA4BAETwAAAAAAAHAIgicAAAAAAAA4BMETAAAAAAAAHILgCQAAAAAAAA5B8AQAAAAAAACHIHgCAAAAAACAQxA8AQAAAAAAwCEIngAAAAAAAOAQBE8AAAAAAABwCIInAAAAAAAAOATBEwAAAAAAAByC4AkAAAAAAAAOQfAEAAAAAAAAhyB4AgAAAAAAgEMQPAEAAAAAAMAhCJ4AAAAKkcioRI1euEeRUYnOLgUAABQCBE8AAACFSOSFRI1ZtFeRFwieAACA4xE8AQAAAAAAwCEIngAAAAoJ0zQVk5AsSYpJSJZpmk6uCAAAFHR5IniaNm2aypUrpyJFiqhu3brauXPnNfedPXu2GjRoID8/P/n5+alp06bX3R8AAKCwi463avqK/arec6meHva9JOnpYd+res+lmr5iv6LjrU6uEAAAFFROD56++uor9e/fXyNGjNDu3bv14IMPqlmzZjp79uxV99+wYYM6dOig9evXa9u2bSpbtqyeeOIJnTx5MpcrBwAAyPt+3H1SlV9erMFzdur4mbgs246fidPgOTtV+eXF+nE391IAAOD2M0wn97GuW7euateuralTp0qSbDabypYtqz59+mjQoEE3PD4tLU1+fn6aOnWqQkJCbrh/bGysfH19FRMTIx8fn1uuHwAAIK/6cfdJtRu1VqZpynadOz4XQzIMQ0uGPa6mDwXlXoFAPsUzBQBkn1N7PCUnJ2vXrl1q2rSpvc3FxUVNmzbVtm3bsvUaiYmJSklJkb+/v6PKBAAAyHei463qNPanG4ZOkmQz0+d/6jT2J4bdAQCA28qpwdP58+eVlpamgICALO0BAQGKjIzM1msMHDhQd955Z5bwKjOr1arY2NgsXwAAAAXdl+uPKtGaesPQKYPNlBKtqVq4/phjCwMAAIWK0+d4uhVjxozRokWLtHz5chUpUuSq+4SGhsrX19f+VbZs2VyuEgAAIHeZpqlZKw9KNzGhwsyVB1jtDgAA3DZODZ7uuOMOubq66syZM1naz5w5o8DAwOseO378eI0ZM0Y//PCDqlWrds39Bg8erJiYGPtXRETEbakdAAAgr4qKs+qvyLgc506mKf0VGaeoOIbbAQCA28OpwZOHh4dq1qypdevW2dtsNpvWrVun+vXrX/O4Dz74QKNGjdKaNWtUq1at657DYrHIx8cnyxcAAEBBFp+U4tTjAQAAMrg5u4D+/furc+fOqlWrlurUqaNJkyYpISFBXbt2lSSFhIQoKChIoaGhkqSxY8dq+PDh+vLLL1WuXDn7XFDFihVTsWLFnPZzAAAA5BXFPN2dejwAAEAGpwdP7du317lz5zR8+HBFRkaqevXqWrNmjX3C8fDwcLm4/Nsxa8aMGUpOTtZzzz2X5XVGjBih//u//8vN0gEAAPIkf2+Lygd66/iZOOVkuibDkMoFeMvf2+K44gAAQKFimIVs9sjY2Fj5+voqJiaGYXcAAKDAmr5ivwbP2Znj4GnMy3X12tNVHFcYUADwTAEA2ZevV7UDAADA1XVsVEFeFje5GNnb38WQvCxu6tDoHscWBgAAChWCJwAAgAKoeDGLFgxsLMMwbhg+uRiSYRj6fFBjFS/GMDtkFZeYqHW79youMdHZpQAA8iGCJwAAgAKq6UNBWjLscXla3GQY6UPpMsto87S46evhj6tJjSDnFIo8LS4xSev3/Ka4xCRnlwIAyIecPrk4AORppimlXpDSEiVXL8nN78onNwDIw5o+FKSDc57XwvXHNHPlAf0VGWffVi7AWz1bVlHHxhXkW9TDiVUCAICCiuAJAK4mNVY6u1Q6PU+yhv/bbgmWSneRSrWV3G48mahpmkq0WpWckioPdzd5WSwyCK4A5LLixSx67ekq6tmysg5FRGve94fVpdl9qlS2OO9JAADAoQieAOByFzZKh1+XbFcZUmCNkI6PksLHS/dNl/wevepLJFmTtSfsqLYfOKSouH97F/h7e6telUqqUbGCPC2507vANE2lJcYpLTlJrh6ecvXy5kETKKQMw1DlYD+N7VHP2aUAAIBCguAJADK7sFE62E2SeenrcpfabEnp+1Wee0X4FHbipBau26Dk1NQrjo6Ki9PqHb/ox1171KHJY6pY5vrzqZimqQsXLigxMVFeXl7y8/PLdmiUmhSvf/as17ntq2SNirS3W/wDVbJeC5Wo0UhunsWy9VoAgHws+awU+aUU2FHyKOXsagAAhQzBEwBkSI1N7+l0zdAps0vbD78u1dpmH3YXduKk5v+wLn1uqOtISU3V/B/WKeSJJlcNn2JjY7Vs+TIt+HyBwsP/HeoXHBysTi91UpvWbeTjc+2hfjFhe/TnwrGyJVuv2GaNOqMTq+fq1I9f6O4OA+VbscYNflYAQL5lmlJimHRisuRTW3IvyVyFAIBcxap2AJDh7NJLw+tuFDplMNP3P7dUUvrwuoXrNkimmb3YyjS1cN0GJVmTs2zbtGmTGjzaQKNDRysiIiLLtoiICI0OHa0GjzbQpk2brvraMWF7dHT+KNlSrLp6iJbeZkux6uj8UYoJ25O9HxcAkH+kxkqnPpV2PyYdeCm97cBL6d+f+jR9ez6SEhelU+sWKiUuytmlAAByiOAJAKT0T4RPz7u5Y0/Nk0xTe8KOKjk1NSexlZJTU7X36DF726ZNm9T9le5KSkqSaZoyL+s5ldGWlJSk7q90vyJ8Sk2K158Lx6a/+g16XaVvN/XnwrFKTYrPZtUAgDzvwkbp1/rpcxJas36AYZ+r8Nf66fvlEylxF3R6/VdKibvg7FIAADlE8AQAkpR64dLqddmNjTKYkjVcZsoFbT9w6KZOvW3/QZmmqdjYWPXu2/uqgdMVZ720T+++vRUb+++n1v/sWZ8+vO5GodO/LyRbslVRezfcVO0AgDwmY65Cew/eq/d6tc9VeIPwyTRNJV0atp2UbL3h3ycAAC5H8AQAkpSWeEuHJyZGZ1m9Liei4uKUZLVq2fJl9p5O2ZHR82n5N8vt35/bvko5D8+ks9tW8jABAHlUZFSiRi/co8ioG/ytyvFchWb6/lcZdpdkTdbWPw5o4pLl+vS7tZKkT79bq4lLlmvrHweuGCZ+3TOZpo4cOaL33n9PR44cyfHfG9M0lZqUIElKTUrg7xUA5DNMLg4AkuTqdUuHJ5uWWzr+YnKKFny+4KaOnb9gvkI6hSgtMS7L6nXZZ8oaFam0pDi5eV17wnIAgHNEXkjUmEV71bxOWQX6X+fv1a3MVVi6q731dq3OerWFMj6b/1m2F8q42uqsYZ8OZ3VWAMhn6PEEAJLk5idZgiXldKUfQ7IEy6OI/y2dPikhXuHh4Tf1KXB4eLiio6OVlpx0SzWkWW/teADA7WeapmIS0nsXxSQkX/vvxG2Yq1D6d3XWlKuETpllrM4aduLkVbffjoUyfh/XXSdWz5U16kyWbRmrs/4+rjsLZABAPkDwBABS+tLSpbvc3LF3dpFXkSLy9/a+qcP9vb1lu8EN/o0kJCTI1cPzll7D1XJrxwMAbp/oeKumr9iv6j2X6ulh30uSnh72var3XKrpK/YrOt6a9YBbnKtQqdG3dXXWW1kog9VZAaBgIXgCgAyl2kounsp+ryeX9P1LtpVhGKpXpdJNnbZ+1coqWrToTR2boWjRonL18pbFP1A302vL4h8oV8+bC84AALfXj7tPqvLLizV4zk4dP5N1/sDjZ+I0eM5OVX55sX7cnam30S3OVai0hNuyOuutLpTB6qwAUPAQPAFABjcf6b7pSg9ubhTeXNpeaUb6cZJqVKwgDze3bMc+hiQPNzdVr3CP/Pz8FBwcLMPIWWhkGIaCg4NVvHhxGYahkvVa5Oj4DKXqt8zxuQEAt9+Pu0+q3ai1SrKmyrxK9pLRlmRNVbtRa/8Nn25xrkLTxeuWV2eVdMsLZbA6KwAUPARPAJCZ36NS5bmZej5dHsZcanPxlKp8KhVvaN/iafFQhyaPSYaRvdjKMNShyWPytHjIMAx1eqnTTZUc0inEHhqVqNFILh6W9KGD2WEYcvGwyL/6Yzd1bgDA7RMdb1WnsT/JNE3ZbpC72Mz00KbT2J/Sh93d4lyFiWmet7w6q2mat7RQhs1mY3VWACiACJ4A4HJ+j0q1tknlh0mWslm3Wcqmt9faliV0ylCxTJBCnmgid7frLxrq7uamkCeaZFkNqE3rNvL09Mx2zyMXFxd5enqqdavW9jY3z2K6u8NAScaNwycjPUS7p8NAVgUCgDzgy/VHlWhNvWHolMFmSonWVC1cf+yW5ypMTk27uWMvsaak6sKFC7e0UEbU6RO3vDorACDvIXgCgKtx80lfWvqhDVLt3dJDmy79uyG93e3ayz9XLBOkt15opxb16lwx4bi/t7da1Kujtzu0u2IJah8fH02dMlWGYdwwfMrYPvWjqVcsRe1bsYYqhAyTi7tF1+u15eJuUcWQYfKpWOO65wIAOJ5pmpq18uDNdPbRzJUH0sOeW5ir0MP9+h+Y3IjF3U2Jibc2z1RCzIVbOp7VWQEgb7q1vzAAUNAZhuTul/6VA54WD9WvWln1qlRSktUqa0qqLO5u8rRYrhsqNWjQQJ98/Il69+2tpKT0G+jMnxxnHOvp6ampH01Vg/80uOrr+FasoQfe+kRRezfo7LaVWT5BtvgHqFT9lipRo5Fci9zapOYAgNsjKs6qvyJz3mPHNKW/IuMUFWdVCZ9LcxUe7Jax9TpHZp2r0MvVlL+3900Nt/P39panxSIvr1ubZ6qor5/O38LxrM4KAHkTwRMAOJBhGPIqUkReRbJ/TIMGDbRp4yYt/2a55i+Yr/DwcPu2smXLKqRTiNq0biNv7+uvQufmWUyl6rdUyXotlJYUpzRrklwtnnL19GYicQDIY+KTUm75+BI+Rf6dq/Dw65ItowdQ5gDq0vu/i2d66HRp2HjG6qyrd/yS43PXr1pZhmHYF8qIiIjI0XA7wzBUtmxZ+Zcuo0j/QFmjzihnXb8MWfwDWJ0VAPIogicAyIN8fHzUOaSzQjqFKDo6WgkJCSpatKh99bqcMAxDbl4+cvO69vBAAIBzFfN0v33HZ8xVeG6pdGqeZP33AwxZykp3dpFKtr1i2HiNihX04649SklNzVbsYyh9zsLqFe5J//7SQhmjQ0fnuP6QTiFycXFRyXotdGL13Bwfz+qsAJB3MccTAORhGZ8glylTRn5+ftxUA0AB5e9tUflA72wvSprBMKTygd7y97Zk3ZB5rsIqX6S3VfniunMV3srqrBludaEMVmcFgIKH4AkAAABwMsMw9GrLyjd1bM+WVa4d9BjGvyGTm88NA51bWZ1VuvWFMlidFQAKHoInAAAAIA/o2KiCvCxucslmZx8XQ/KyuKlDo3tuax03uzprhoyFMjJ6Pl0eQGW0eXp66pPZn1yxUAarswJAwWKYOZn5rwCIjY2Vr6+vYmJirliCHAAAAHCmH3efVLtRa2WapmzXuUt3MdIDnK+HP64mNa4eANnF/yHte1qqtkIqdn+O6jFNU3+dPq25361Vt6ceV/nSpbM9jC42NvaqC2UEBwdna6GM1KT4a6zOGuj01Vl5pgCA7GNycQAAACCPaPpQkJYMe1ydxv6kRGuqJCnzx8QZmY+nxU2fD2p849DpFhmGoSIe6fNHFfGw5GiuwcwLZWzfvl0hXUI0f9581atXL1uvw+qsAFAwEDwBAAAAeUjTh4J0cM7zWrj+mGauPKC/IuPs28oFeKtnyyrq2LiCfIt6XOdVMvEoJZXpl/6vExiGYe8V5OPjw+qsAFDIEDwBAAAAeUzxYha99nQV9WxZWT//flpPD/teK0Y1U8MHsj/Uzc6jlBT8xk3X4u3lqUY1HpS3l+dNvwYAoPAieAIAAADyKMMw7D2bfIt6OGWImbeXl5o8VD3XzwsAKBhY1Q4AAAAAAAAOQfAEAAAAAAAAhyB4AgAAAPKwQD8vDXqhugL9vJxdCgAAOcYcTwAAAEAeFujvpXc61HB2GQAA3BR6PAEAAAAAAMAhCJ4AAAAAAADgEARPAAAAAByqZMmS6tO7j0qWLOnsUgAAucwwTdN0dhG5KTY2Vr6+voqJiZGPj4+zywEAAACQz/BMAQDZR48nAAAAAAAAOATBEwAAAAAAABzC6cHTtGnTVK5cORUpUkR169bVzp07r7nv/v371bZtW5UrV06GYWjSpEm5VygAAAAAAAByxKnB01dffaX+/ftrxIgR2r17tx588EE1a9ZMZ8+ever+iYmJuvvuuzVmzBgFBgbmcrUAAAAAAADICacGTxMmTFCPHj3UtWtXValSRTNnzpSXl5fmzp171f1r166tcePG6YUXXpDFYsnlagEAAAAAAJATTguekpOTtWvXLjVt2vTfYlxc1LRpU23bts1ZZQEAAAAAAOA2cXPWic+fP6+0tDQFBARkaQ8ICNChQ4du23msVqusVqv9+9jY2Nv22gAAAAAAALg2p08u7mihoaHy9fW1f5UtW9bZJQEAAAAAABQKTgue7rjjDrm6uurMmTNZ2s+cOXNbJw4fPHiwYmJi7F8RERG37bUBAAAAAABwbU4Lnjw8PFSzZk2tW7fO3maz2bRu3TrVr1//tp3HYrHIx8cnyxcAAAAAAAAcz2lzPElS//791blzZ9WqVUt16tTRpEmTlJCQoK5du0qSQkJCFBQUpNDQUEnpE5IfOHDA/t8nT57U3r17VaxYMVWoUMFpPwcAAAAAAACu5NTgqX379jp37pyGDx+uyMhIVa9eXWvWrLFPOB4eHi4Xl387ZZ06dUo1atSwfz9+/HiNHz9ejz76qDZs2JDb5QMAAAAAAOA6DNM0TWcXkZtiY2Pl6+urmJgYht0BAAAAyDGeKQAg+wr8qnYAAAAAAABwDoInAAAAAAAAOATBEwAAAAAAAByC4AkAAAAAAAAO4dRV7ZwhYy712NhYJ1cCAAAAID/KeJYoZOs0AcBNKXTBU1xcnCSpbNmyTq4EAAAAQH4WFxcnX19fZ5cBAHmaYRaymN5ms+nUqVPy9vaWYRjOLidPiI2NVdmyZRUREcFysPkA1yv/4ZrlP1yz/IXrlf9wzfIXrteVTNNUXFyc7rzzTrm4MHsJAFxPoevx5OLiojJlyji7jDzJx8eHm4l8hOuV/3DN8h+uWf7C9cp/uGb5C9crK3o6AUD2EM8DAAAAAADAIQieAAAAAAAA4BAET5DFYtGIESNksVicXQqygeuV/3DN8h+uWf7C9cp/uGb5C9cLAHArCt3k4gAAAAAAAMgd9HgCAAAAAACAQxA8AQAAAAAAwCEIngAAAAAAAOAQBE8AAAAAAABwCIIn3BbMUQ8AAPIC7knyH5vNZv/vtLQ0J1YCAHAEgifcsuPHj2vKlCkaOnSoTp486exykA0ZN3jcnAM3Z8uWLVkelFCw8N6Yf9lsNhmGIUk6deqUk6tBdrm4pD+SDBo0SG+//Ta/gwBQwBA84Zb8/vvvevzxx/X7778rLi5OJUuWdHZJyIaMG7yIiAgnVwLkP3v37lWDBg00atQowqcCIOMB959//lF0dLSSkpLswQXyF9M07X/f3n77bXXr1k2xsbFOrgrXkzlgWrNmjf73v/+pXbt2/A4CQAFD8ISbduTIETVu3Fjt2rXTrFmzNHnyZHl4ePApVT6xcuVKPfzwwzpx4oSzS0E28HuVd1SvXl0zZ87U6NGjNXr0aMKnfMw0TRmGoRUrVqh58+Z69NFHdf/99+uTTz7R6dOnnV0eciDjWkrS5s2btXnzZr377rvy8fFxcmW4noxrtmrVKi1btkytW7dWvXr1GG4HAAUMwRNuSkpKij788EM9+eSTGjp0qFxdXe3b+JQqf/D09JSPj499KAIPz3lTRuCUlJR01XbkntmzZ2vr1q2y2Wx65ZVXNG3aNI0YMYLwKR8zDEPff/+9XnjhBbVv314rVqzQk08+qV69eungwYPOLg85kHHv8dVXX2nGjBmqUKGC6tSpo9TUVCdXhhuJjIzU8OHDtWDBAntPbFdXV95XAaAAIXjCTXF3d9e2bdt0zz33yMvL64rtGTcLFy9ezO3ScBVXu3lr0qSJ7rrrLr311luS/h1+h7zFMAx99913at++vdq2bauZM2cqISFBhmEQPuUi0zQ1cuRIdevWTbt375bNZlP37t01a9Yswqd8Ki0tTampqZo/f75ef/119e/fX66urlq7dq26dOmixo0bO7tE5JBpmlqxYoVWrlyp33//XTabTW5ubvxu5jEZf7sy/g0MDNTcuXPVoEEDbdu2TUuWLJGUfl/C3zkAKBh40kSOpaamKjIyUidOnFCFChXsbZllhBiTJk3SP//8k+s1IquM65GYmJilfdiwYYqPj9ePP/4oiV40edHWrVv17LPPqkKFCoqKitJnn32m3r17Ky4ujvApl2QM4fnrr7/k6empLl26aNeuXYRP+VTG78zFixfl5uamv//+W0888YQSEhJUp04dNWrUSLNmzZIkff755zp8+LAzy8V1XP7+ZxiG5s2bp+7du+v8+fMaNWqU4uPjCTDykMyTv0dHR8tqterixYt68MEHNXbsWAUHB2vu3LlasWKFpPRryvsqAOR/BE/ItnPnzkmS3NzcVKpUKVWrVk0ff/yxzp49Kzc3tytu6vbt26dvv/1WFy5ccEa5uMysWbNUsWJFvfvuu/YHqQceeEDu7u5avny5JIZJ5jVhYWHaunWrxowZo4kTJ+rHH39Ux44ddfjwYfXq1csePnFT7liGYSg1NVXu7u7auXOnDMNQ165dCZ/yKcMwtGjRIjVp0kSSVLFiRY0bN05VqlRRq1at9NFHH0lKD+qXLl2qFStWcE3zoMwBxrFjx3Tq1CmFh4fLzc1NY8aM0dNPP62VK1dqxowZSkxM5L0yD8g8+XtoaKhat26t//znP2rTpo0OHTqkGjVq6MMPP5TVatWMGTO0cuVKSfTIBoCCgHdyZEtcXJyqV6+uV155RVL6TUDTpk21Z88eTZ8+Xf/8888VocXSpUvl4+PDSndOkvkG++LFi2rbtq06deqkHTt2qGbNmho4cKCOHDmicePGaenSpdqxY4cTq8XlwsLC1L17d02ZMkV+fn6S0ue8ePXVV9WxY0eFhYWpb9++io2N5aY8F7i5uSklJUXu7u7avXv3NcOn9957T0OGDOEBNw/K+HAkIiJC06dP14svvihJateunU6fPi0fHx999NFH8vDwkCS9//772rdvn9q0acPvWB6TOcAYNmyY2rRpo9q1a+uJJ57QpEmT5O7ursmTJ6tmzZr6+uuvNX36dHvPJzhPxn3isGHD9OGHH6p9+/Z6+umnlZaWprp162rDhg2qUaOGxo4dq5SUFL377rvasmWLk6sGANwWJpANqamp5ty5c81ixYqZffv2tbc//fTTpoeHh9mnTx8zLCzMNE3TPHDggNm3b1/T39/f3Ldvn7NKLtTS0tLs//3BBx+YQ4YMMf/66y/TNE0zPj7eXLBggdmyZUvzrrvuMmvXrm0GBQWZkyZNMk0z/VrD+WJjY80BAwaYd955p/ncc8+ZNpvNvi05OdmcPn26WalSJbNnz55ZtuH2utb/2+TkZLNq1apm1apVzZ07d9p/56ZMmWKWKFHCPHfuXG6WiWzatWuX2b17d7N169ZmdHS0aZqmmZSUZL733nvmAw88YNarV8/s3bu32aZNG9Pf39/cvXu3kyvG9bz//vumv7+/uXLlSnPx4sXmqFGjTFdXV/Odd94xTTP99/S1114zy5UrZ37xxRdOrrbwyvw+GhERYVarVs1ctGiRvS0+Pt7s0qWL6evra548edI0TdPcsWOH2adPnyz3MwCA/MswTQa9I3vS0tK0ePFide3aVT169LAPR3jppZf0008/KSYmRoGBgfL29lZaWpoWLFig6tWrO7foQm7gwIGaN2+eQkND9eSTT+rOO++0b4uKitKpU6c0atQo7dixQ6Zp6rffflPx4sWdV3AhZmZaCjxDfHy8xo0bp//973968sknNWrUKLm7u0tKX1ly3rx5evzxx1WuXDknVFzwZVyTjRs3atOmTTp+/Li6d++ue++9V/7+/kpJSVGNGjUkSfPmzdNDDz0kFxcXRUdH83uUB6WkpOitt97S119/raJFi2aZuykpKUnr16/X4sWLFR0drYoVK6p79+667777nFgxLpf5fTIpKUnPPPOMmjdvrjfffNO+zxdffKFOnTrp888/V8eOHZWSkqLJkyfrzTffzLICL3KHzWaz9zSLiYlRSkqKypUrp1WrVunRRx+1bz937pyaNWum5557ToMGDcrSOy3zawAA8ieCJ1xTxg1eWlqa/WYtLS1NX331lV5++WW9/PLLmjp1qiRp3bp1Onz4sM6ePavatWvroYceUunSpZ1ZfqH33Xff6ZVXXtGyZctUu3Zte/vlN3A2m027du3SG2+8oY4dO6pXr15XDUHgOBn/v3fs2KHt27crLS1NDz30kB577DElJCQoNDRUa9euVaNGjfTee+/Jzc3N2SUXGsuXL1e3bt3UsGFDpaSkaOfOnRo4cKDatWuncuXKKSUlRbVr19a5c+e0YsUKPfTQQ84uGZfJ/H527tw5TZw4UbNmzVK3bt30wQcf8F6XT2S+jvv371fVqlUVFBSk3r17a/DgwZL+HWLeqVMnubq66uOPP1aRIkXsr5H5fgaOl/mavf322zpx4oTmzZunxo0bq3Llypo6daosFotM01RaWpoee+wxPfzww/rggw+cXDkA4Hbj4wNcVXh4uAYOHKjo6Gi5uroqLS1NUvocM+3bt9fcuXM1e/ZsDR06VJLUpEkTvf766/q///s/tWjRgtApDzhz5owCAwNVqVIl+/UzL82LkXkVQhcXF3tQ+Msvv0hikvHcZhiGli5dqieeeEKLFi3SggUL1LhxYw0dOlSenp4aPHiwmjZtqs2bN+uNN964YhVJOMaOHTvUp08fTZgwQf/73/+0cuVKxcbGasKECZo3b54iIiLsE47fdddd9HLKYzI+V7tw4YIuXryoqKgolSxZUgMGDFC3bt20ceNGvfvuu/b9U1JSrjgWeUPmAGPQoEHq3Lmz4uPj9dxzz2nVqlU6cOCApPS/Zy4uLvL29lZMTEyW0EkSoVMuynzNNmzYoHXr1qlv375yd3dXy5YtdeDAAU2ePFmSsqzQmjGnIQCgYOFjc1zV8uXLtWLFCl28eFHvvfeefHx87J8Uurq6qnXr1jp37pw++OADtWzZUvXq1XN2ybjMyZMnFRERIW9vb0lSamqq3NzcZLPZtHnzZnsoZZqmXF1dVapUKR07dkxWq1UeHh6ET7noyJEj6tu3rz788EN169ZNqamp9p6Frq6uGjlypAYOHKiEhATt379fUVFRKlWqlLPLLtBsNpvCw8P10ksvqWvXrvrrr7/UqFEjvfbaaypRooRGjhwpd3d3tW/fXhUqVNDWrVudXTIyyXjo/fbbb/XBBx8oNjZWbm5uGjBggDp27KghQ4bINE2tXr1arq6uGjp0qH0Yq0T4ntdkXI8dO3Zo165dmjp1qooVK6amTZtq9+7d9qF0lSpVUkJCgo4eParKlSs7uerCK3PotHz5cn3zzTeqW7eu/V6xb9++OnXqlBYtWqRvv/1WjzzyiDZv3qzo6Gi99dZbziwdAOAg9HjCVfXq1Utdu3bVL7/8osGDBys2NjZLz6ciRYqoefPmMk1Tp0+fdnK1hdu1Vs9q1aqVihYtqv79+8s0TfvwrLi4OI0ePVrbtm2TlH5Dv3fvXu3YsUNjx46VxWLhocuBpkyZooMHD2Zpi42NVbFixdSkSRMZhiEPDw916tRJH3/8sd577z1t27ZNPj4+ev/99/Xll18SOjlIxifuqampcnFxUb169RQSEqKLFy/qtddeU9OmTTVx4kQNHz5cQUFBGjt2rJYtW6bU1FR6yOQxhmFozZo1ateunZ5++mn16NFDjz32mF566SWNHDlSxYsX16BBg9SwYUMtWLCAoT15VOa/b19++aU++OADeXp62oe0Pv300+rSpYsOHTqkpk2b6vHHH1fDhg0VGRmpiRMnSqL3Wm6z2Wz2e4hjx45pxowZWrZsmQ4dOmTfx8vLS2PHjtWgQYNUvnx5hYWFqUaNGvrtt9/k5uZmv9cEABQc9HjCFTJ6xvTv3182m03/+9//NHjwYIWGhsrHx8e+3c/PT+XKlVPRokWdXXKhlXm+pl27diklJUX+/v669957dffdd+ull17Sd999p27duumdd95ReHi4Jk6cqPPnz6tTp07216levbp++OEHlShRwlk/SoFnmqYSExM1ffp0PfXUU1m2paSkKCwsTFFRUSpfvrz9d6xVq1YKDQ3V4cOHVb9+fRUtWpTfNwfJ+IR+7dq12rJli7p166bg4GBJ6UOPT58+rd69e8vFxUWRkZF67LHHVLZsWbVp04Y5t/Igm82m+fPnq0uXLho4cKC9/f7771f37t1VtWpVPffcc3rrrbdUpEgRPf/8806sFleTMTRckg4dOqTdu3dr69atcnd319mzZ1WmTBlJ0ssvv6zq1atr79692rdvn8qWLas33nhDbm5u9vdS5I7M1+z111+XJE2dOlXvv/++1q9frylTptjfRz09PfX888/r+eefz3IvwzUDgIKJHk+QlL7SSHR0tCTZP23KGJbwzDPPaPfu3RowYIASEhLsNwQTJkzQ+fPndf/99zux8sIr8w3e0KFD1bZtW4WEhKhatWqaOHGiXFxcNGDAAHXt2lW7d+9WtWrV1KdPH1mtVu3YscN+nTM+USZ0cryiRYtq//79qlixorZv364//vhDpmmqfv36atmypd5++20dOnTI/jtWpEgReXl5sZpPLjAMQ8uWLVPbtm0VHx+vxMRE+7aoqCidO3dOp0+f1p9//qlZs2bp6NGjGjJkiCpUqODEqnEtycnJOn78uHx8fCSlTyqdlpambt266dVXX9WUKVMUFxenUqVKaeTIkawMmcdk7jXTt29fvfTSSxo6dKgGDRokV1dXhYaGKiIiwr5/zZo19fLLL2vy5MkaMGBAlvsY5I7Mw+tOnDihHTt26Pnnn9e9996riRMnqn79+lqyZInmzJmTpXeppCx/47hmAFAwsaoddPz4cT388MNq3LixqlWrprfffvuKT58mTZqkr7/+WlarVU2aNFFkZKTWr1+vVatWqXr16s79AQq59957T9OnT9cXX3yhRo0aqVevXpozZ44GDBigIUOGyNPTU5K0c+dOlSpVSsHBwfYJxrnBy30Zw7LuuusuBQQE6IsvvlCVKlW0YsUKffTRR7JarXr//fdVrFgxLVmyRJ988ol27NjBg7GDHThwQM2aNdOIESPUvXv3K7b37dtXc+fOVWBgoOLi4vTdd9+xgl0ekvHQe+7cOZUsWVKS9N///lcrV67UTz/9pKCgIPs8he+++65++OEHbd682clV40YuXLig119/Xd27d1eTJk0kSWPHjtVXX32lxo0b64033lCZMmVYidXJUlJS7HOkhYaG6tdff5WXl5dmz55tH75/7tw59erVS6dPn1aXLl3UrVs3rhkAFCJ8jA7t3r1bMTExeuaZZzR37ly1bt1ab7/9tqKiouyfGL7xxhsaOXKkatWqpf3796tEiRL66aefCJ2cIPOcF0eOHNHWrVs1Y8YMNWrUSN98840WLlyo5557TqNHj9bo0aPtc3DVqVNH5cqVk4uLi2w2G6FTLsv8Ca+7u7v27NmjmJgYde/eXWFhYXr66af1xhtv6I477lDDhg3VoUMHLVmyRGvWrCF0ygWRkZEqUaKEWrRoYZ9fJPPv2pQpU7R8+XJNmzZNO3fuJHTKQzJCh5UrV6p79+6aP3++JOnZZ59VUFCQBgwYoFOnTtlXNDt37px8fX2VmJjI/D95TEbPa0maNm2aqlatqoiICFWsWNHePnDgQD3//PP2oVt///03AYYTLVq0SLNnz1ZqaqrS0tJksVi0evVq/fbbb3JxcZFhGEpJSVHJkiU1bdo0lSlTRuPGjdPKlSudXToAIDeZgGma9erVMydMmGBevHjRnDZtmtmmTRuzXLly5tChQ83169dn2Tc1NdU5RcK02Wz2/z58+LBpmqb52WefmUlJSebmzZvNoKAgc8qUKaZpmubLL79senl5mW+88YYZHR3tlHqRLuO6rV+/3hw1apR59OhR0zRN8+zZs2aZMmXM+vXrm0eOHLHv/9tvv5lHjhwxz5w545R6C6PPPvvMtFgsZnx8vGmaWd/nfvnlFzMiIsJZpSEbvvnmG9NisZgTJkww//jjD3v7p59+aj722GPmXXfdZXbr1s1s1aqVWaxYMfO3335zYrW4mk8++cTs06ePGRcXZ5qmaW7ZssWsWbOm6ePjY3/PtFqt9v3HjBljBgUFmVOnTnVKvTDNWbNmmYZhmGvXrrW3JSQkmLNnzzbd3NzM4cOH29tTUlJM0zTNM2fOmMOGDeNeEgAKGYbaFXIZQw8WLFig//3vf5o/f768vLwkSeXLl5dpmjp79qw6d+6s+++/X7169XJyxYVX5uGPffv21Zw5c3T27FnZbDZ5e3urX79++ueffzRnzhxZLBa9/fbb2rZtm2w2mzZv3swnwk5iXuqNsXTpUnXt2lVvvfWWnnnmGVWrVk2GYejs2bN66KGHFBwcrNmzZ6tKlSpcKyf4+++/9eSTT+qZZ57RO++8I19fX/v7Y9euXVWpUiW99dZbzLeVB0VGRqpVq1Zq166d/vvf/16xfefOnVq5cqV+++03lSlTRr169VKVKlWcUCmuZfbs2Xr11Vf1v//9T08//bSk9L95u3btUseOHVWqVClt3LhRbm5uWYZ1LViwQB07drT3ZkPumTVrlnr37q0lS5aoVatWWbalpKTo448/Vt++ffXee+9p8ODB9vaMayf9ew8KACj4GGtTyGX8wa9bt67efvttrVq1Su3atVPXrl118eJFrVy5UtHR0Ro2bJh27Nih1q1b684773Ry1YVTxgNvWFiY4uPj9d1336lo0aIyTVOpqak6fPiwSpcubb+pO3LkiMaPH6+6detKEnNg5KLMN9eGYWjHjh169dVXNWHChCzzB50/f16lSpXS7t27VadOHb3wwgtasmSJKlWq5KzSC7yM34Nff/1VBw4cUGxsrOrWravatWurXbt2+uGHH5ScnKwhQ4bon3/+0YIFC7Rq1Sq9/fbbhE55xOXz01mtVp08eVKVK1e2t2V+v6tTp47q1KnDQ24eNWvWLPXq1UvLli2zh05SevBUu3Ztffnll2rfvr2aNm2qdevWyd3dXcnJyfLw8LCvzsq1zV3z5s1Tr1699O2336p58+b29qFDh6pDhw6qWrWqevToIUl644035OLiooEDB2YJnSRxzQCgECF4gkzT1L333qtBgwZp3rx5mjdvnnbt2qXvvvtONWrUkCQ9+OCDcnFxkb+/v5OrLdwWLlyo4cOHy8/PT1WqVLH3gnJzc1PLli3Vt29fRUVF6fjx40pLS1PNmjUlETrlpv/+97+qXr26OnXqZP//vmPHDvsy7gkJCfrxxx81f/58HTt2TL169VKPHj20fft2NW3aVEWKFHH2j1CgZfQ+e+WVV9SgQQOFh4dr7ty5atu2rUaMGCEXFxetXLlSAQEBqly5spKSkvT9999nCTXgPMePH9fy5ctVq1YtNWjQQJKUkJAgwzCyzKOWEUz98ssv2r9/v7p06cJDbh702WefqVevXlqxYoWeeuope3tISIjatm2rZ599VrVr19ZXX32lF154QY8//rjWrl0rDw+PLK/Dtc09v/zyi7p166bevXtnCZ2ee+457dixQ71795YkeXh4qEePHnJxcVGvXr1055132oNCAEDhw8e3sAcSdevW1e+//66jR49qy5Yt9tDJNE3dcccdhE5OkDG5cca/SUlJCgwMVFhYmFJTU+Xi4qKUlBRJUu/evTVjxgz5+/urcePG2rt3r31JaUKn3GOxWPTAAw9I+ve6lSxZUuHh4Ro1apTatGmjOXPmyDAMPfnkk3r11Vf122+/KTAwUPv27WMicQf7/fff1bdvX40ePVrffPON5syZo4MHDyo+Pl6urq4aPny4fvrpJ33zzTf69NNPtXnzZvt7IZzr999/1+OPP65du3bZF02QpCpVqqhy5cr2RTEy94ZasmSJ1q5dq/j4eGeUjGswTVPHjx9Xt27d1Lx5c9WpU8e+7fnnn9fPP/+cZQL/2rVra9GiRdq2bZv69evnjJJxSe3atfX0009ry5YtWrJkiSSpffv2OnLkiDZv3qzAwED73z4PDw+99tprWrx4sTp06ODMsgEATsYcT4VExifAmecJuprXX39dP//8s/744w9J9JTJK3bt2qWaNWvKZrNp+fLlGjFihPz8/PT1118rICAgyyf8ma/x5UNS4DiX/66sWbNGJ0+eVOfOnXXy5ElNmTJFa9eu1cMPP6xOnTrpkUceUVhYmF588UV9/vnnuvfee/l9u42u9V63dOlSjR8/Xtu2bdNff/2lRo0aqVmzZpo1a5Yk6Y8//tD999+f2+XiBg4ePKhHHnlEr7zyivr166fSpUtn2f7333/r6aefVlJSkkaNGiXTNLV9+3Z9+umn2rJliz0MRt4yefJkTZo0SZ07d1a/fv3Us2dPHThwQCtWrFC5cuWueE88dOiQKlasSA8nJ8k8pLFt27Y6duyYLBaLvSdvYGBglms2Z84ctWnTRn5+fpK4JwGAwox3/0Lg2LFjmjt3rmJjY9W8efMs3dkzZDykde/eXTt37tSiRYv0wgsv8BCcB2zevFkNGzbU5MmT1adPH7Vp00apqamaNm2aQkJCNH/+fAUEBNjnFcr8sM0NXu65/Hflu+++00cffSQXFxd17dpVH374oaKjo1W8eHH7Pp999pkSExPtbfy+3R4Z72cRERH64YcfZLPZVKlSJTVo0EDu7u4KCAhQRESEGjZsqObNm2v69OmSpE2bNumHH35QiRIlrgg24DwXL17Ue++9pxdffFFjxoyxtyclJSkqKkpnzpzRQw89pI0bN+rll1/WqFGjZLVaVaZMGW3atInQKQ/K+B3t16+fDMPQuHHjtHDhQrm4uGjDhg0KCAjIEh6PHDlSzz77rKpXry6JOZ2cxdXV1f7/funSpXrxxRe1ePFijR8/XiVLlpT079+xxx9/XAkJCeratav9eO5JAKDw4i9AAff777+refPmeuaZZ3TvvfeqSZMmV90v4+aucuXKunjxopYvX6527dpxY5cHVK1aVcOHD1f//v3tcyU8//zzMk1TM2bMUJcuXTR37lwelJ0s41PeyMhIBQYGavLkyfLw8NCrr74qm82mDh062AOmDRs2aPHixVq0aJF++uknlSpVyrnFFyAZD6v79u3TM888o4CAAB07dkzFixfXhAkTVK1aNa1evVrfffedevbsqcmTJ9uPXbx4sY4fP25f2RN5g5ubm44dO6aqVava29asWaPVq1dr/vz5kqRGjRppyZIlWrZsmU6cOCGLxSKLxSIfHx9nlY3rcHFxsf+u9u3bV0WKFNGAAQMUEhJiH6bl4uIi0zTVrFkznTp1SkOHDrUfz72J82QOn7744gslJydrzpw5KlGihF544QW5ubmpefPmCg8P1x9//GG/jnywAgCFG8FTAXbs2DE9+eST6tSpU5ZPia91A2Cz2eTp6alPP/1UxYoV48bOCa52bfz8/OyrwvTp00eGYej1119X+/btZRiGRo4cqQ8++EATJ050UtXIuG4rV67U5MmT9eKLL6pLly4aN26cTNPU66+/LsMw9MILLygpKUnr1q3T6dOn9fPPPzOs6zbKHDrVr19fffv21bBhw7R161Z17txZM2fO1OrVqzVjxgy99tprKlOmjMLDw5WSkqJZs2bpiy++0KZNm+Tr6+vsHwWXmKap+Ph4+fv7KyIiQtu3b9fGjRs1d+5c1axZU++++67uvfdevfjii3r77bc1YcIElSlTxtll4xoy92LKHD698sorSk5O1pgxY+Tj46M+ffqodOnSatGihSIiIrRv3z65urrecLoA3F5hYWGqWLHiFe2Zw6clS5aobdu2GjdunFxcXPTZZ5/p+PHj+uOPP+Tu7s7wOgBAOhMFks1mM4cPH24+88wz5j///OPscpBD48ePNxctWpSl7cKFC+bIkSNNwzDMTz75xDRN00xLSzPXrl1rpqamOqNMZPLNN9+YFovFnDRpkrl79+4s2/773/+aHh4e5ty5c03TNM3o6GgzOjraGWUWeOHh4eYdd9xhtmvXLkt77dq1zYoVK5rR0dFmfHy8OWfOHLNIkSLmXXfdZVauXNmsUqXKFdcNeccXX3xhVqxY0QwODjb9/PzM2bNnm8eOHbNvb9++vdm6dWsnVojr2bhxo/2/09LSsmzL/P3kyZPNMmXKmEOHDjUbNmxo3nvvvWZycrJpmqaZkpKSO8XCNE3TPHz4sGkYhjlu3Lhr7pP53qNdu3amYRhmtWrVuGYAgCvwEUQBZRiGNm7cqODg4KuuRpfxqWFCQoIsFgufRjmZmamnU3x8vPbu3athw4apSJEievbZZyVJxYsX12uvvaaff/5ZPXr0UFxcnN544w01bdpUEnNeONO5c+c0ZswYjRw5MsuKS8nJyfLw8ND48eNlGIZefvllubu766WXXnJitQVbWlqaypcvL6vVqi1btuiRRx5RaGiofv31V9WqVUshISEqUaKEWrZsqVWrVikpKUl33XWXSpYsqYCAAGeXj8tkvDd27NhRNWvWVEpKikqXLq0SJUrY90lLS1NycrIqVarkxEpxLf/8849at26tBx54QBs2bMjS00m6cthdxr/VqlWj14wTBQUF6f3339eQIUPk7u5+1dUEM/d8Wrx4sd5//30NHDhQbm5uXDMAQBb8RSiATNNUQkKCLl68aH+QyngAzpBxwzdhwgQ1bNhQjz76qFNqRdahB0ePHlW5cuU0btw4+fn5KSQkRPPmzVPr1q0lSSVLllTlypUVHR2tpUuX2m8EDcMgdHKihIQEhYeHXzGJsYeHh/3Bedy4cXJ3d1fNmjWdVGXhUK5cOX3xxRfq27evPvjgA5UqVUr/+9//tHjxYtWpU0e7du3SH3/8oZ49e6po0aJ66KGHtHTpUmeXjWswDMP+O3TfffddsT05OVnvvvuuduzYobFjxzqhQtxIiRIltHz5cnXu3FlPPvmk1qxZc93wqXfv3ipfvryaNWtGgOEEP//8sxo2bKiiRYuqb9++8vDw0JtvvilJ1wyfMq7RkCFDJLF6HQDgSgyUL2AybtCLFSumBx54QHPnztWZM2fk4eFhn7Azw59//qnt27czka4TZb7xHj58uN544w19++23CgwM1JtvvqlOnTqpa9eu+vbbbyWlr+50/vx5DRs2TJs2bWKyTiczTVNS+nUsWrSoLly4cMW2rVu3au7cuZKk0aNHq3LlyrlfaCFTsWJFTZ48WUlJSfr888/19ttv67nnnlNwcLBat26tYcOG6eDBgxo3blyW+e+QN13rfW7ZsmXq27evPvnkE61cufKqc9Egb2jYsKE+//xz/fHHH3ryyScl/Rs2Zcj8fYsWLQidnCCjd1rGh5FFixZVz549NW7cOL355ptZFmPI7PJrxDUDAFyO4KmASEtLk5Te8yLDCy+8IHd3d3Xp0kWnTp26YkLO+fPnKzY2VnfddVeu1op/ZVyTYcOGafr06Xr99df1yCOPSJLKly+vt956S127dlWrVq3UuHFj1a5dW4cOHVLLli0lXXuieDhORqCU2d13363y5ctr7Nix+vPPPyX9+7C8YsUKrVixQnFxcblaZ2F37733asaMGWrYsKF++uknbd682b4tJSVFJUqU0HPPPUdYkUfExcVl+ft1Izt37tQnn3yimJgYrV+/XjVq1HBgdbgdHnnkEX311Vc3DJ8yI8DIXRm908LDw9WsWTNJ2Q+fAAC4HsO82lMU8pWwsDDNnDlTO3fu1MWLF1WrVi298MILevTRRzV27FhNmDBBd911lz766CP7Kk6ff/65vvzyS23cuFHVqlVz9o9QqO3fv1/t27fXhx9+aL/RyywpKUmrV6/Wjz/+qDvuuEMjRoyQm5sbczo5QUbQ9+OPP2rx4sWKiIhQrVq19MYbb0iSHn30Ufuqg8WLF9eWLVs0f/58bdmy5YpheMgdYWFh6tu3r0zT1LBhw+zBLvKOAwcO6MUXX1SfPn3UsWNHFSlSJFvHnThxQj4+PvLx8XFwhbidtmzZovbt2+v+++/XmjVrJInV6vKYjGtUtWpVff/995LSP9icOXOmBg4cqAkTJqhv375OrhIAkJ8QPOVz+/btU+PGjfXUU0/J29tbnp6emjNnjooWLar+/fvrv//9r2bMmKHp06dr//798vb2VtmyZVWsWDF9/PHHhE55wJ49e/TUU09pxYoVql27dpZtycnJSklJUdGiRbMETQw/cJ5vvvlGISEhevHFF3X//ffrnXfeUZ06dfTll1+qWLFievHFF/X3338rJiZGd911lyZMmKAHH3zQ2WUXamFhYerfv7/Onz+viRMnql69es4uCZdERESoRYsWOnXqlNLS0vTRRx/pueeeu274RE/P/G/Lli164YUXVK1aNa1atcrZ5eAqrhU+zZo1SwMGDNCiRYv0/PPPO7lKAEB+QfCUj504cUINGzZUhw4d9P7772dp79atm/bt26f33ntP3bt3V1RUlLZu3aro6GhVqlRJ5cqV0x133OHE6gunq32q+/PPP6tly5b6/vvvVb9+/SwTwa9fv14RERF64YUXskwOD+c4deqUWrRooa5du6pv375KS0tTYGCgOnXqpPHjx9uv7YULF5ScnKyiRYuqWLFiTq4aknTo0CENGzZMH374oYKDg51dDpQ+RPzTTz/VihUrNHPmTL333nuaO3euZs+efcPwCXlPTnstbd26VQ0bNlS/fv304YcfOrAy3KyrhU/x8fFasWKF2rVrxwdgAIBsI3jKx5YsWaKZM2dq8eLFKl68uFxdXZWSkiJ3d3dFRETo2Weflc1m04YNG1S8eHFnl1voZb4pnzp1quLj4zVo0CBJUqtWrbR792798ssv9pUIk5KS1Lp1a91///0aP3680+ou7DL3rjh79qyeeuop/fzzzzp37pweeeQRtWjRQh9//LEkadOmTXrkkUcYMpJHXb66J5xv7969ioiI0NNPPy1Jev311/Xpp59q9uzZatu2rTw9PbPsT2+nvCnz37edO3fKNE3ZbDbVr1//usf9/vvvqlKlCsPG87CM3mkPPPCAVq9enWUbva8BANnF01E+tmvXLv3111/y9/e337S5u7vLZrOpbNmymjJlivbt26etW7c6uVJI/06a+tZbb2ns2LGyWq0KDw+XJP3f//2fypcvr8qVK2vixIkKDQ3Vs88+q5MnT7LqlpMZhqHFixdr9uzZcnNz0/nz57Vs2TI9/vjjatmypaZPny5JOnz4sEJDQ7Vjxw4nV4xrIXTKG3bv3q13331XklS9enV76CRJ06dPV7du3dSjRw8tXbpUFy9elCQtXrxYp0+fJnTKg0zTtP99e+edd/TSSy+pe/fuatGihV555RX9/fff1zz2gQcekKurq32BFOSOy1c5vp6MSeF/+OEH9e/fP8s2QicAQHbxFyMfy5j3JyEhQcWKFbN/4phxA1iuXDn5+voqKirKyZUiw+LFi7VgwYIr5nOqXr26Fi9erNDQUH3xxRfy9PRUhQoVtGrVKpaUdoLMvSr++OMPvfLKKxo5cqT8/f3Vpk0bvfLKK2rcuLFmzZplP2b+/Pk6e/Ysq0QC17Fv3z7Vrl1bb775Zpb2jB4yrq6umjZtmiSpR48estls+vnnn7VmzRpt27bNGSXjBjLeKydMmKDZs2dr5cqVqlu3rkaNGqURI0aoR48eN3xfpMdT7rmZ3mkPP/yw9uzZoypVquRWmQCAAoYn2XysRYsWGjFihCZMmKDhw4fLxcVFaWlpcnFxkWEYunjxosqVK6dy5co5u1RccujQIf3nP/9R7dq17ZOFZ4RKAQEBmjRpkqKiouTr68tE4rks88145tBpyZIlevXVV9WvXz9J0vPPP68jR47o5MmTWrBggSwWizZv3qzPPvtMP//8s+68806n/QxAXvbbb7+pfv36GjRoUJZ5CaX037mMni+Zw6cuXbqoWLFiWr9+vcqWLeuMspFNe/fu1YgRI1S3bl19/fXXmjBhgqZNm6batWszzDWPuLx32tdffy2LxaKTJ0/queee05AhQ64ZEmaszMqKugCAm8FQu3zin3/+0YEDB/T777/b24KDg9W1a1e9//779jmAXF1d7Q/Nc+bMUVpamu69916n1FzYZXRlz9yl/Z9//tHx48ftn+ybpik3NzdZrVb7yj6Zh05mbIdjZYROJ0+e1FdffaUvv/xSK1asUGhoqKZNm6bo6Gj7vvXr19eAAQP0yCOPqG/fvgoNDdWRI0e0adMmVq8DruHo0aOqV6+e/vvf/+r9999XxvSSCxYs0KZNm+z7ZR525eXlJT8/P+3YsUM1a9Z0St24MdM0lZSUpO3btysgIEBbt25V165dFRoaqtdee00pKSkaMmSI1q9f7+xSC73Le6ctWLBAv//+u95880198sknOnv27A1fg9AJAHAzeKLNB/744w9169ZN586dk2maeuKJJ/Txxx/rjjvuUJ8+fRQTE6OBAwdq165dat68uQzD0LZt27RgwQL9/PPPKlWqlLN/hEJn0aJF+uGHHzRo0CAFBQWpaNGiktI/Mfzmm2+0evVqNW3a1L5qU2JiokJDQ5WUlKTnnnvO/jrMZ+J4GaHTvn371Lp1axUpUkRhYWGqVq2agoKCVKdOHX333Xfau3evqlevLklq1KiRGjVqpP/7v/+Tj4+PUlNT7dcYQFY2m01z586Vt7e3SpQoISn9ve29997TlClT7KF7BldXVy1ZskQffvihdu7cqcqVKzujbFzD5avXGYYhT09PvfTSSxo/frx+++03zZgxQ127dpUkxcXFae/evbrzzjvVqFEjZ5WNTOidBgDIbaxql8f99ttveuSRR9SzZ0+1bNlSX3/9tWbPnq2JEyfq9ddfl5Q+qfGqVas0adIkJSUl6Y477lClSpU0atQo3X///U7+CQqf2NhYPfTQQ4qNjVVgYKDq1Kmj//znP+rSpYskqWXLljp8+LCGDh2qRx55RCkpKRowYID++ecfbdmyhU8Tc1Hm0Kl+/frq3bu3+vXrp19//VXTp09XXFycWrVqpW+//Vb+/v4aNWqUqlWrlmU+GgA3durUKX3wwQfavn27unTpotjYWI0fP16fffaZnnrqqSv2P336tGw2m4KCgpxQLa4lc+j0119/6eLFi/ZgcPPmzerTp4+8vb01d+5cVahQQWfOnFG3bt0UHR2tn3/+mfdMJzNNUxcvXtSDDz6o999/X0FBQWrWrJnGjRunnj17KiUlRe+8846aN29OSAgAuK0InvKwo0eP6oEHHtCAAQM0atQoSek3epUqVVKfPn3sw+syxMbG6uzZs/Lz85OXl9cVy1Ajd6SlpWnYsGG66667VLt2bf300096//339fjjj6tRo0Z65ZVX1KFDB504cULbt2/Xgw8+qCJFiujnn3+Wu7s78yfksoiICD300ENq1KiRFi9ebG+fOXOmBg8erN9++027d+/W1KlTVaxYMY0aNco+1wWA7IuMjNT777+vtWvX6tixY/r+++/VuHFj3vPyoUGDBmnRokWKiorSPffco5CQEPXq1UsrVqzQBx98oBMnTqh06dL2OYW2bt3K3zcnuLx3WoZ3331Xq1atuqJ3WlRUlNq3b6/mzZtfsQAAAAC3gqF2edTVhiZI6UO4UlJSFBYWpkmTJsnf31/PP/+83Nzc5OPjIx8fHydWDSl9mEiDBg3Uvn17bd68WQMGDFDv3r01evRo9erVS4sXL1bz5s313HPPqVSpUvL09FTt2rXl4uLCROJOkJaWpvLly8tqtWrz5s36z3/+I0m65557ZBiGEhIS1KpVK1mtVs2dO1f9+vXTRx99pKpVqzq5ciB/CQwM1NChQ+Xi4qINGzZoz549aty4cZZJxZE3ZQ4wPv/8cy1YsEBTpkxRcHCwZs+erYULF+r06dMaM2aMqlSpot27dysiIkJ333232rZtm2UhDeSO6/VOa9y4sZYvX646deqoQYMGkmTvnZaYmKi+ffs6rW4AQMFEj6c8LPPQhM6dOysuLk5jxoxRr169VL16dX3xxReKiIjQmTNnVLFiRfXv318tWrRwdtm4pFevXpJkX52patWquvfee1WuXDkdPnxYa9as0YIFC/Tiiy9KuvYnk3C8sLAw9e3bVzabTZMmTVLZsmV19913q2vXrho7dqx9v/nz52vp0qWaNm2aypQp48SKgfwro+fTL7/8otatW2vgwIGSeA/MD7755hv99ddfcnV1zRJOjB49WgsXLtSoUaPUqlWrK44jWHQeeqcBAPICgqc87lpDEyTZPz2cOnWqdu/erQEDBqhKlSpOrhgZ5syZo08//VQrVqxQkyZN5OXlpdWrV8vHx0cnT57Upk2b9Nxzz/EJcB4RFhamfv36KTExUfv27VPnzp01ceJESVJKSorc3d0lpU+U6+3t7cxSgXwv42/bnj171KRJE40cOdLZJeEqMsJA0zR1/vx53XXXXbp48aL69etnf3/M0KhRI/n6+uqbb75xTrGQdGXvtIEDB2bpnbZ371499thjGjNmjA4fPkzvNABAriB4ygfOnDmj0aNHa8OGDQoJCdF///tfScqy8gg3CXlTnTp19Ouvv6phw4ZatmyZ/P39r9iHa5d3hIWFqWfPnjp27Jjmz5+vhg0bSpJ96XdWGQRun8jISA0ePFgnTpzQokWLsgwrR97yyy+/qHbt2tq/f7/at28vd3d3LV++XOXKlbPv83//93/avn27VqxYYQ/q4Tz0TgMA5CUET/nEtYYmEFrkTaZpyjAMff755xo7dqzmzZunmjVr2tuRdx09elR9+vSRaZoaNmyYHnnkEWeXBBRYZ86ckSQFBAQ4uRJcy/bt2/Xwww9r8+bNevjhh3XgwAE1a9ZM9913nyZPnqxy5crJMAw1adJEd999t7744gtnl1wo0TsNAJCXMZlCPhEYGKghQ4aodu3aWrFihUaMGCFJhE55VEa41KhRI/3zzz9au3ZtlnbkXRUqVNCUKVPk7u6uAQMGaPv27c4uCSiwAgICCJ3ymMTExCzf33nnnWrYsKH27t0rSapSpYrWrFmjI0eOqHHjxnrqqafUuXNnWa1Wffrpp5L+7SWK3JMxvO7XX39VyZIl9csvv6hKlSrasGGDjh8/nmXfRx99VBcvXlRKSooTKgUAFEYET/lIRvhUsWJFbd26Vf/884+zS8INBAUFafDgwRo/frwOHDjg7HKQTRUrVtS4ceNUpkwZ3Xnnnc4uBwByxbx58zRu3DhZrVZ7W3BwsOrVq6f33nvPHkpVrVpVa9asUUBAgI4ePar+/ftr165d8vDwUEpKCh+yOMn27dtVt25dbd26VVWrVtXixYt1/vx5de/eXfv371dCQoISExP1/fffq0SJEgyJBADkGoba5UMMTchfjh07pnfffVeffvopKzblM5nnUQOAguzjjz9Wz5499csvvygoKEheXl7y8fGRJEVHR6tp06bq2LGj3nzzTfsKaAcOHFDTpk314IMPauHChfL19SV0ykWJiYny8vKyfx8eHq6QkBA9//zzev311yVJ+/fv11NPPSWr1ar77rtPAQEBOnbsmLZv3y4PKY9YPAAACQVJREFUDw+mAAAA5AqegvMhhibkL/fcc4/mzZsnFxcXpaWlObsc5AChE4DCYMGCBerVq5dWrFih8+fP65577tHLL7+sb7/9VmlpaSpevLjq1q2rH374QYZhyMXFRTabTVWqVNHatWt18OBBNW/eXBcuXHD2j1Jo0DsNAJCfEDwBuSDjxo6VYgAAecm8efPUuXNnNWrUSC1atFCzZs00efJkBQUFqV27dmrfvr0++eQT9e3bV1u2bNGiRYsk/TunUNWqVfXtt98qOjpa8fHxzvxRCo2PP/5Y3bp1U8uWLXXhwgXFxsbatw0aNEh33nmnZs6cKdM07QFhxnV79913FRMTI9M0GWoHAMg1DLUDAAAohGbPnq2ePXuqW7duWr16tVq1aqVp06bZt//yyy9atmyZFi9erGLFiunkyZN66qmn7EPHMw8fZ2hy7liwYIG6deumb775Rm5ubmrTpo2aN2+uTp06qUWLFnJ1dVWvXr107NgxrVmzRtK/K97t379fLVq00J133qmVK1fK39/fyT8NAKCwIHgCAAAoZCZNmqT+/ftr1apVeuqppzRr1iwNHTpUL7zwgj766CP7fjabTSkpKfrggw+0fft2/fTTT9qxY4eqVavmxOoLp3nz5qlbt25q2rSpfvjhB0nSJ598oj/++EMzZszQ008/rSeffFINGjRQrVq1NHv2bL3wwgtZXmPfvn164YUXtGbNGgUHBzvjxwAAFEIETwAAAIXMxo0bdfr0aXswERMTo6+++kpDhgxRx44dNXnyZElZezJFR0erW7du8vf314wZM+Tm5sYcQbmE3mkAgPyM4AkAAKCQyryqWWxsrBYtWnRF+JSSkmKfD2jUqFH6+eeftXbtWqfVXNjQOw0AkN+5ObsAAAAAOEfmHkv/3979hES193Ec/xzPo4NMTpPoNCCjWSoZVEy2CQITipwU+oeRKWESVDRQRkFhUhJktImKqBZlUgyzSIloCKTFJA0RhtimCEoaEVpIIWRNWeldXO65d+6t+xhP59Gx9wvcnN/MOb8zyzffc3S5XNYE1NGjR5WWlqYzZ84oPT3dClSJREJDQ0N69+6dZs2axcTT/4Hf71coFFIgEJAkbd26VYZhqLm5WWlpaVYg/PLlixwOh1paWqzptHPnzjGdBgCYcoQnAAAASPozPhmGoV27dmnevHnat2+fDMNQPB7XwMCAQqGQsrKypnqrv4zy8nJJf06nzZ492wqEzc3NkqSzZ88qIyPDmk5zu93y+/3q6enhv9cBAKYc4QkAAAAWl8ulmpoaeTweVVdXW8cLCgp05coVOZ3OKdzdr4vpNABAqiI8AQAAIInb7db69esl/f4Il2maMgyD6DSNMJ0GAEgVvFwcAAAASFEjIyO6f/++qqurZZqmdfz9+/eEQgDAtEB4AgAAAGaAv06nAQAwXRCeAAAAAAAAYIu0qd4AAAAAAAAAZibCEwAAAAAAAGxBeAIAAAAAAIAtCE8AAAAAAACwBeEJAAAAAAAAtiA8AQAAAAAAwBaEJwAAAAAAANiC8AQAAAAAAABbEJ4AAPhBhmHo1q1bU70NAAAAYNojPAEAUlJDQ4MMw9Du3bv/sbZ3714ZhqGGhoZJnSsajcowDI2MjEzq869fv1YgEPiB3QIAAAC/JsITACBl+Xw+hcNhJRIJ69jHjx8VCoWUn5//0683NjYmSfJ6vXI4HD/9/AAAAMBMQ3gCAKSsZcuWyefzqauryzrW1dWl/Px8+f1+69j4+Lja2tpUWFiozMxMLV26VDdv3pQkvXr1ShUVFZKkOXPmJE1KrVq1SsFgUPv371dOTo7Wrl0r6Z+P2g0NDam2tlbZ2dlyOp1avny5Hj16JEl68uSJKioqlJWVJZfLpbKyMj1+/NjOnwUAAACYNv4z1RsAAOB/0djYqPb2dtXV1UmSrl69qh07digajVqfaWtr040bN3Tp0iUVFxerp6dH9fX1ys3N1cqVK9XZ2anNmzfr+fPncrlcyszMtL7b0dGhPXv2KBaLffP6o6OjKi8vV15enm7fvi2v16u+vj6Nj49Lkurq6uT3+3Xx4kWZpqn+/n6lp6fb94MAAAAA0wjhCQCQ0urr63XkyBHF43FJUiwWUzgctsLTp0+fdPLkSd27d08rVqyQJM2fP18PHjzQ5cuXVV5eruzsbEmSx+OR2+1OOn9xcbFOnz793euHQiENDw+rt7fXOk9RUZG1Pjg4qEOHDmnhwoXW+QAAAIBfBeEJAJDScnNzVVVVpWvXrmliYkJVVVXKycmx1l+8eKEPHz5ozZo1Sd8bGxtLehzve8rKyv51vb+/X36/34pOf3fgwAHt3LlT169f1+rVq1VTU6MFCxZM4s4AAACA1Ed4AgCkvMbGRgWDQUnShQsXktZGR0clSZFIRHl5eUlrk3lBuNPp/Nf1vz6W9y3Hjx/Xtm3bFIlEdPfuXR07dkzhcFgbN278r9cGAAAAUh0vFwcApLzKykqNjY3p8+fP1gvA/7Bo0SI5HA4NDg6qqKgo6c/n80mSMjIyJElfv3794WsvWbJE/f39evv27Xc/U1JSoqamJnV3d2vTpk1qb2//4esAAAAAqYjwBABIeaZp6tmzZ3r69KlM00xay8rK0sGDB9XU1KSOjg69fPlSfX19On/+vDo6OiRJBQUFMgxDd+7c0fDwsDUlNRm1tbXyer3asGGDYrGYBgYG1NnZqYcPHyqRSCgYDCoajSoejysWi6m3t1elpaU/9f4BAACA6YrwBACYEVwul1wu1zfXTpw4oZaWFrW1tam0tFSVlZWKRCIqLCyUJOXl5am1tVWHDx/W3Llzrcf2JiMjI0Pd3d3yeDxat26dFi9erFOnTsk0TZmmqTdv3mj79u0qKSnRli1bFAgE1Nra+lPuGQAAAJjujImJiYmp3gQAAAAAAABmHiaeAAAAAAAAYAvCEwAAAAAAAGxBeAIAAAAAAIAtCE8AAAAAAACwBeEJAAAAAAAAtiA8AQAAAAAAwBaEJwAAAAAAANiC8AQAAAAAAABbEJ4AAAAAAABgC8ITAAAAAAAAbEF4AgAAAAAAgC0ITwAAAAAAALDFb33lp1B2eqs7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir colores para cada valor de los parámetros\n",
    "colors = ['#0d4e9e', '#ffc520', '#7b9ca0', '#242624', '#cc7b4f'] #, '#7764B4'\n",
    "\n",
    "# Graficar resultados para cada parámetro\n",
    "plot_parameter_results(results_num_microbatches, eps_num_microbatches, 'num_microbatches', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_l2_norm_clip, eps_l2_norm_clip, 'l2_norm_clip', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_noise_multiplier, eps_noise_multiplier, 'noise_multiplier', colors, results_no_dp_stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
