{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b36324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e24fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 33)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "data_path = 'C:/Users/danie/OneDrive/Documentos/1 UNIANDES/10 semestre/Tesis/differential-privacy-banking-sector/data/processed/bank-processed.csv'\n",
    "data = pd.read_csv(data_path, sep=',')\n",
    "print(data.shape)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y']\n",
    "\n",
    "# Define numeric columns\n",
    "numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Scale numeric columns\n",
    "scale = MinMaxScaler()\n",
    "X[numeric_cols] = scale.fit_transform(X[numeric_cols])\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752f6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply SMOTEENN for class balancing\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_resample, y_resample = smoteenn.fit_resample(X_train, y_train)\n",
    "X_resample = pd.DataFrame(X_resample, columns=X.columns)\n",
    "y_resample = pd.Series(y_resample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5300aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 26\n"
     ]
    }
   ],
   "source": [
    "# Feature selection with BorutaPy\n",
    "rf = xgb.XGBClassifier(eval_metric='logloss')\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
    "feat_selector.fit(X_resample.values, y_resample.values.ravel())\n",
    "X_filtered = X.columns[feat_selector.support_].tolist()\n",
    "print(f\"Selected features: {len(X_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cacdacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data with selected features\n",
    "X_train_filtered = X_resample[X_filtered].values\n",
    "X_test_filtered = X_test[X_filtered].values\n",
    "y_train_filtered = y_resample.values\n",
    "y_test_filtered = y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e653b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neural network parameters\n",
    "input_size = len(X_filtered)\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n",
    "n_iterations = 5\n",
    "num_microbatches = 16\n",
    "l2_norm_clip = 1.0\n",
    "\n",
    "# Define parameter values to test\n",
    "batch_size_values = [16, 32, 64, 128]\n",
    "sample_size_ratio_values = [1, 0.5, 0.1, 0.05]\n",
    "noise_multiplier_values = [1.1, 1.5, 2.0, 2.5]\n",
    "\n",
    "# Fixed default values\n",
    "default_noise_multiplier = 1.1\n",
    "default_batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f9916dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute privacy budget\n",
    "def compute_privacy_budget(n, batch_size, noise_multiplier, epochs, delta=1e-5):\n",
    "    try:\n",
    "        eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "            n=n, batch_size=batch_size, noise_multiplier=noise_multiplier,\n",
    "            epochs=epochs, delta=delta\n",
    "        )[0]\n",
    "        return eps\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing privacy budget: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Define neural network model\n",
    "def create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=False,\n",
    "                 num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                 noise_multiplier=1.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation='relu', input_shape=(input_size,)))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if use_dp:\n",
    "        optimizer = DPKerasSGDOptimizer(\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "            num_microbatches=num_microbatches,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to train model\n",
    "def train_model(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=False,\n",
    "                num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                noise_multiplier=1.1):\n",
    "    model = create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=use_dp,\n",
    "                         num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                         noise_multiplier=noise_multiplier)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    \n",
    "    y_pred_prob_test = model.predict(X_test, batch_size=batch_size).flatten()\n",
    "    y_pred_test = (y_pred_prob_test > 0.4).astype(int)\n",
    "    \n",
    "    return y_pred_prob_test, y_pred_test\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(y_true, y_pred, y_pred_prob):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    actual_negatives, actual_positives = conf_matrix[0].sum(), conf_matrix[1].sum()\n",
    "    false_positive_rate = conf_matrix[0][1] / actual_negatives if actual_negatives > 0 else 0\n",
    "    false_negative_rate = conf_matrix[1][0] / actual_positives if actual_positives > 0 else 0\n",
    "    return {\n",
    "        'ROC AUC': roc_auc_score(y_true, y_pred_prob),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Type I Error': false_positive_rate,\n",
    "        'Type II Error': false_negative_rate\n",
    "    }\n",
    "\n",
    "# Function to run multiple iterations\n",
    "def run_iterations(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp, n_iterations,\n",
    "                   num_microbatches, l2_norm_clip, noise_multiplier):\n",
    "    results = []\n",
    "    for _ in range(n_iterations):\n",
    "        y_pred_prob_test, y_pred_test = train_model(\n",
    "            X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=use_dp,\n",
    "            num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier\n",
    "        )\n",
    "        result = evaluate_model(y_test, y_pred_test, y_pred_prob_test)\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to compute statistics\n",
    "def compute_statistics(df):\n",
    "    stats = {\n",
    "        'mean': df.mean(),\n",
    "        'min': df.min(),\n",
    "        'max': df.max()\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "# Function to subsample training data\n",
    "def subsample_data(X, y, sample_size_ratio, random_state=42):\n",
    "    if sample_size_ratio >= 1.0:\n",
    "        return X, y\n",
    "    n_samples = int(len(X) * sample_size_ratio)\n",
    "    idx = np.random.choice(len(X), n_samples, replace=False)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1690fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model without DP...\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5677 - accuracy: 0.7011 - val_loss: 0.6152 - val_accuracy: 0.6638\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.4359 - accuracy: 0.7988 - val_loss: 0.5264 - val_accuracy: 0.7471\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 905us/step - loss: 0.3577 - accuracy: 0.8528 - val_loss: 0.4776 - val_accuracy: 0.8111\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.3112 - accuracy: 0.8797 - val_loss: 0.4699 - val_accuracy: 0.8238\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2892 - accuracy: 0.8895 - val_loss: 0.4773 - val_accuracy: 0.8224\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 918us/step - loss: 0.2782 - accuracy: 0.8947 - val_loss: 0.5026 - val_accuracy: 0.8137\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2709 - accuracy: 0.8976 - val_loss: 0.5108 - val_accuracy: 0.8095\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 884us/step - loss: 0.2664 - accuracy: 0.8991 - val_loss: 0.4797 - val_accuracy: 0.8213\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2625 - accuracy: 0.9007 - val_loss: 0.4634 - val_accuracy: 0.8262\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2588 - accuracy: 0.9022 - val_loss: 0.4872 - val_accuracy: 0.8168\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 987us/step - loss: 0.2554 - accuracy: 0.9034 - val_loss: 0.4383 - val_accuracy: 0.8337\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2532 - accuracy: 0.9042 - val_loss: 0.4521 - val_accuracy: 0.8279\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 862us/step - loss: 0.2496 - accuracy: 0.9060 - val_loss: 0.4754 - val_accuracy: 0.8200\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2472 - accuracy: 0.9066 - val_loss: 0.4672 - val_accuracy: 0.8202\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 845us/step - loss: 0.2447 - accuracy: 0.9070 - val_loss: 0.4273 - val_accuracy: 0.8358\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2424 - accuracy: 0.9072 - val_loss: 0.4862 - val_accuracy: 0.8134\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2401 - accuracy: 0.9094 - val_loss: 0.4556 - val_accuracy: 0.8226\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 871us/step - loss: 0.2378 - accuracy: 0.9101 - val_loss: 0.4674 - val_accuracy: 0.8182\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 987us/step - loss: 0.2356 - accuracy: 0.9109 - val_loss: 0.4602 - val_accuracy: 0.8216\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.2333 - accuracy: 0.9116 - val_loss: 0.4975 - val_accuracy: 0.8096\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 806us/step - loss: 0.2315 - accuracy: 0.9122 - val_loss: 0.5162 - val_accuracy: 0.7980\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.2295 - accuracy: 0.9131 - val_loss: 0.4617 - val_accuracy: 0.8247\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.2269 - accuracy: 0.9129 - val_loss: 0.4490 - val_accuracy: 0.8290\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.2253 - accuracy: 0.9154 - val_loss: 0.4840 - val_accuracy: 0.8118\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.2242 - accuracy: 0.9155 - val_loss: 0.4467 - val_accuracy: 0.8299\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 708us/step - loss: 0.2226 - accuracy: 0.9151 - val_loss: 0.4296 - val_accuracy: 0.8326\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.2215 - accuracy: 0.9164 - val_loss: 0.4579 - val_accuracy: 0.8252\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.2201 - accuracy: 0.9155 - val_loss: 0.4765 - val_accuracy: 0.8189\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 782us/step - loss: 0.2185 - accuracy: 0.9176 - val_loss: 0.4354 - val_accuracy: 0.8318\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.2166 - accuracy: 0.9167 - val_loss: 0.4653 - val_accuracy: 0.8255\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 736us/step - loss: 0.2164 - accuracy: 0.9182 - val_loss: 0.4543 - val_accuracy: 0.8244\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.2146 - accuracy: 0.9189 - val_loss: 0.4959 - val_accuracy: 0.8137\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.2141 - accuracy: 0.9189 - val_loss: 0.4532 - val_accuracy: 0.8270\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.2132 - accuracy: 0.9194 - val_loss: 0.4422 - val_accuracy: 0.8278\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.2117 - accuracy: 0.9194 - val_loss: 0.4524 - val_accuracy: 0.8272\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.2107 - accuracy: 0.9198 - val_loss: 0.5126 - val_accuracy: 0.8081\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.2103 - accuracy: 0.9204 - val_loss: 0.4449 - val_accuracy: 0.8313\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.2089 - accuracy: 0.9214 - val_loss: 0.4640 - val_accuracy: 0.8267\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.2084 - accuracy: 0.9208 - val_loss: 0.4406 - val_accuracy: 0.8329\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 753us/step - loss: 0.2066 - accuracy: 0.9219 - val_loss: 0.4563 - val_accuracy: 0.8304\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.2064 - accuracy: 0.9209 - val_loss: 0.4850 - val_accuracy: 0.8199\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 774us/step - loss: 0.2061 - accuracy: 0.9218 - val_loss: 0.4720 - val_accuracy: 0.8240\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2050 - accuracy: 0.9214 - val_loss: 0.4314 - val_accuracy: 0.8350\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 898us/step - loss: 0.2048 - accuracy: 0.9221 - val_loss: 0.4665 - val_accuracy: 0.8240\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 872us/step - loss: 0.2031 - accuracy: 0.9223 - val_loss: 0.4862 - val_accuracy: 0.8160\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 920us/step - loss: 0.2030 - accuracy: 0.9224 - val_loss: 0.4530 - val_accuracy: 0.8293\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 896us/step - loss: 0.2029 - accuracy: 0.9226 - val_loss: 0.4955 - val_accuracy: 0.8128\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 888us/step - loss: 0.2007 - accuracy: 0.9225 - val_loss: 0.4634 - val_accuracy: 0.8258\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 883us/step - loss: 0.2004 - accuracy: 0.9241 - val_loss: 0.4554 - val_accuracy: 0.8311\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 885us/step - loss: 0.2003 - accuracy: 0.9240 - val_loss: 0.4408 - val_accuracy: 0.8373\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 972us/step - loss: 0.5802 - accuracy: 0.6861 - val_loss: 0.5962 - val_accuracy: 0.6692\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 907us/step - loss: 0.4510 - accuracy: 0.7893 - val_loss: 0.5627 - val_accuracy: 0.7167\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 897us/step - loss: 0.3694 - accuracy: 0.8438 - val_loss: 0.4770 - val_accuracy: 0.8075\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 892us/step - loss: 0.3145 - accuracy: 0.8774 - val_loss: 0.5077 - val_accuracy: 0.8028\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2878 - accuracy: 0.8895 - val_loss: 0.4899 - val_accuracy: 0.8161\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2746 - accuracy: 0.8955 - val_loss: 0.4876 - val_accuracy: 0.8186\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 947us/step - loss: 0.2679 - accuracy: 0.8982 - val_loss: 0.4676 - val_accuracy: 0.8245\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2624 - accuracy: 0.8998 - val_loss: 0.4220 - val_accuracy: 0.8424\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 906us/step - loss: 0.2579 - accuracy: 0.9014 - val_loss: 0.4856 - val_accuracy: 0.8174\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2542 - accuracy: 0.9025 - val_loss: 0.5618 - val_accuracy: 0.7855\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2518 - accuracy: 0.9034 - val_loss: 0.4468 - val_accuracy: 0.8303\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 907us/step - loss: 0.2484 - accuracy: 0.9053 - val_loss: 0.4977 - val_accuracy: 0.8091\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2461 - accuracy: 0.9064 - val_loss: 0.4395 - val_accuracy: 0.8324\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2437 - accuracy: 0.9070 - val_loss: 0.4644 - val_accuracy: 0.8215\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 939us/step - loss: 0.2410 - accuracy: 0.9070 - val_loss: 0.4849 - val_accuracy: 0.8119\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2382 - accuracy: 0.9091 - val_loss: 0.4614 - val_accuracy: 0.8203\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2365 - accuracy: 0.9097 - val_loss: 0.4748 - val_accuracy: 0.8125\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 958us/step - loss: 0.2337 - accuracy: 0.9105 - val_loss: 0.4639 - val_accuracy: 0.8200\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2324 - accuracy: 0.9106 - val_loss: 0.4831 - val_accuracy: 0.8138\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 940us/step - loss: 0.2303 - accuracy: 0.9121 - val_loss: 0.4646 - val_accuracy: 0.8189\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2279 - accuracy: 0.9125 - val_loss: 0.4281 - val_accuracy: 0.8295\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2261 - accuracy: 0.9137 - val_loss: 0.4403 - val_accuracy: 0.8280\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2247 - accuracy: 0.9137 - val_loss: 0.4815 - val_accuracy: 0.8127\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 922us/step - loss: 0.2235 - accuracy: 0.9147 - val_loss: 0.4348 - val_accuracy: 0.8308\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2221 - accuracy: 0.9151 - val_loss: 0.4433 - val_accuracy: 0.8255\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 887us/step - loss: 0.2207 - accuracy: 0.9161 - val_loss: 0.4359 - val_accuracy: 0.8299\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2196 - accuracy: 0.9162 - val_loss: 0.4844 - val_accuracy: 0.8123\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2176 - accuracy: 0.9171 - val_loss: 0.4285 - val_accuracy: 0.8319\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 911us/step - loss: 0.2168 - accuracy: 0.9171 - val_loss: 0.4932 - val_accuracy: 0.8092\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2150 - accuracy: 0.9181 - val_loss: 0.4443 - val_accuracy: 0.8263\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 884us/step - loss: 0.2135 - accuracy: 0.9187 - val_loss: 0.4186 - val_accuracy: 0.8381\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2123 - accuracy: 0.9186 - val_loss: 0.4401 - val_accuracy: 0.8280\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 972us/step - loss: 0.2119 - accuracy: 0.9189 - val_loss: 0.4913 - val_accuracy: 0.8100\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 972us/step - loss: 0.2107 - accuracy: 0.9197 - val_loss: 0.4980 - val_accuracy: 0.8091\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2089 - accuracy: 0.9205 - val_loss: 0.4507 - val_accuracy: 0.8266\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 896us/step - loss: 0.2086 - accuracy: 0.9202 - val_loss: 0.4449 - val_accuracy: 0.8297\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2079 - accuracy: 0.9212 - val_loss: 0.4548 - val_accuracy: 0.8256\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 865us/step - loss: 0.2068 - accuracy: 0.9203 - val_loss: 0.4823 - val_accuracy: 0.8203\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2059 - accuracy: 0.9221 - val_loss: 0.4878 - val_accuracy: 0.8127\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2048 - accuracy: 0.9217 - val_loss: 0.4701 - val_accuracy: 0.8213\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2049 - accuracy: 0.9212 - val_loss: 0.4544 - val_accuracy: 0.8248\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2033 - accuracy: 0.9221 - val_loss: 0.4699 - val_accuracy: 0.8202\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 919us/step - loss: 0.2027 - accuracy: 0.9224 - val_loss: 0.4824 - val_accuracy: 0.8165\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 939us/step - loss: 0.2022 - accuracy: 0.9228 - val_loss: 0.3902 - val_accuracy: 0.8516\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 886us/step - loss: 0.2008 - accuracy: 0.9225 - val_loss: 0.4093 - val_accuracy: 0.8416\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 894us/step - loss: 0.2009 - accuracy: 0.9236 - val_loss: 0.4657 - val_accuracy: 0.8192\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 899us/step - loss: 0.2005 - accuracy: 0.9238 - val_loss: 0.4510 - val_accuracy: 0.8296\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 914us/step - loss: 0.1984 - accuracy: 0.9242 - val_loss: 0.4330 - val_accuracy: 0.8394\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 846us/step - loss: 0.1988 - accuracy: 0.9239 - val_loss: 0.4410 - val_accuracy: 0.8310\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 864us/step - loss: 0.1973 - accuracy: 0.9238 - val_loss: 0.4615 - val_accuracy: 0.8256\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 926us/step - loss: 0.5947 - accuracy: 0.6764 - val_loss: 0.5484 - val_accuracy: 0.7000\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 900us/step - loss: 0.4542 - accuracy: 0.7878 - val_loss: 0.5321 - val_accuracy: 0.7366\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 896us/step - loss: 0.3770 - accuracy: 0.8381 - val_loss: 0.4984 - val_accuracy: 0.7882\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 874us/step - loss: 0.3238 - accuracy: 0.8720 - val_loss: 0.5145 - val_accuracy: 0.7949\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 829us/step - loss: 0.2926 - accuracy: 0.8883 - val_loss: 0.5031 - val_accuracy: 0.8100\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 932us/step - loss: 0.2764 - accuracy: 0.8952 - val_loss: 0.5061 - val_accuracy: 0.8077\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.2666 - accuracy: 0.8998 - val_loss: 0.5096 - val_accuracy: 0.8091\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.2613 - accuracy: 0.9003 - val_loss: 0.5273 - val_accuracy: 0.7965\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.2562 - accuracy: 0.9024 - val_loss: 0.4882 - val_accuracy: 0.8129\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.2527 - accuracy: 0.9041 - val_loss: 0.4511 - val_accuracy: 0.8252\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 813us/step - loss: 0.2488 - accuracy: 0.9051 - val_loss: 0.4841 - val_accuracy: 0.8152\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.2458 - accuracy: 0.9059 - val_loss: 0.4709 - val_accuracy: 0.8183\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.2437 - accuracy: 0.9062 - val_loss: 0.4512 - val_accuracy: 0.8240\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.2407 - accuracy: 0.9085 - val_loss: 0.4373 - val_accuracy: 0.8293\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 794us/step - loss: 0.2378 - accuracy: 0.9097 - val_loss: 0.4727 - val_accuracy: 0.8188\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.2364 - accuracy: 0.9098 - val_loss: 0.4746 - val_accuracy: 0.8168\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.2336 - accuracy: 0.9111 - val_loss: 0.5141 - val_accuracy: 0.8031\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.2318 - accuracy: 0.9117 - val_loss: 0.4622 - val_accuracy: 0.8202\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.2302 - accuracy: 0.9114 - val_loss: 0.4579 - val_accuracy: 0.8225\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.2278 - accuracy: 0.9128 - val_loss: 0.4852 - val_accuracy: 0.8139\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.2258 - accuracy: 0.9137 - val_loss: 0.4627 - val_accuracy: 0.8222\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.2240 - accuracy: 0.9144 - val_loss: 0.4423 - val_accuracy: 0.8301\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.2214 - accuracy: 0.9147 - val_loss: 0.4608 - val_accuracy: 0.8211\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.2205 - accuracy: 0.9154 - val_loss: 0.4621 - val_accuracy: 0.8205\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.2197 - accuracy: 0.9166 - val_loss: 0.4547 - val_accuracy: 0.8262\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 742us/step - loss: 0.2178 - accuracy: 0.9168 - val_loss: 0.4662 - val_accuracy: 0.8181\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 937us/step - loss: 0.2166 - accuracy: 0.9165 - val_loss: 0.4566 - val_accuracy: 0.8255\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 816us/step - loss: 0.2147 - accuracy: 0.9183 - val_loss: 0.4405 - val_accuracy: 0.8319\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 945us/step - loss: 0.2135 - accuracy: 0.9185 - val_loss: 0.4702 - val_accuracy: 0.8200\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 744us/step - loss: 0.2124 - accuracy: 0.9195 - val_loss: 0.4262 - val_accuracy: 0.8327\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 964us/step - loss: 0.2111 - accuracy: 0.9190 - val_loss: 0.4395 - val_accuracy: 0.8320\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 935us/step - loss: 0.2096 - accuracy: 0.9194 - val_loss: 0.4450 - val_accuracy: 0.8307\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.2084 - accuracy: 0.9206 - val_loss: 0.4318 - val_accuracy: 0.8338\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 930us/step - loss: 0.2071 - accuracy: 0.9216 - val_loss: 0.4462 - val_accuracy: 0.8248\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.2071 - accuracy: 0.9202 - val_loss: 0.4772 - val_accuracy: 0.8196\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 980us/step - loss: 0.2049 - accuracy: 0.9217 - val_loss: 0.5159 - val_accuracy: 0.8000\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.2045 - accuracy: 0.9221 - val_loss: 0.4674 - val_accuracy: 0.8242\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 963us/step - loss: 0.2033 - accuracy: 0.9223 - val_loss: 0.4649 - val_accuracy: 0.8230\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 964us/step - loss: 0.2029 - accuracy: 0.9225 - val_loss: 0.5147 - val_accuracy: 0.8043\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 835us/step - loss: 0.2018 - accuracy: 0.9230 - val_loss: 0.4622 - val_accuracy: 0.8240\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 949us/step - loss: 0.2009 - accuracy: 0.9230 - val_loss: 0.4779 - val_accuracy: 0.8162\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 797us/step - loss: 0.2001 - accuracy: 0.9232 - val_loss: 0.4469 - val_accuracy: 0.8315\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 957us/step - loss: 0.1993 - accuracy: 0.9246 - val_loss: 0.4572 - val_accuracy: 0.8259\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 875us/step - loss: 0.1984 - accuracy: 0.9235 - val_loss: 0.4732 - val_accuracy: 0.8205\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 845us/step - loss: 0.1974 - accuracy: 0.9250 - val_loss: 0.4671 - val_accuracy: 0.8222\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 862us/step - loss: 0.1967 - accuracy: 0.9250 - val_loss: 0.5007 - val_accuracy: 0.8108\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 924us/step - loss: 0.1959 - accuracy: 0.9248 - val_loss: 0.4586 - val_accuracy: 0.8287\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 809us/step - loss: 0.1958 - accuracy: 0.9257 - val_loss: 0.4729 - val_accuracy: 0.8267\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 959us/step - loss: 0.1948 - accuracy: 0.9264 - val_loss: 0.4673 - val_accuracy: 0.8240\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.1945 - accuracy: 0.9259 - val_loss: 0.4628 - val_accuracy: 0.8269\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 977us/step - loss: 0.5820 - accuracy: 0.6821 - val_loss: 0.5678 - val_accuracy: 0.6873\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 882us/step - loss: 0.4648 - accuracy: 0.7764 - val_loss: 0.5423 - val_accuracy: 0.7239\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 825us/step - loss: 0.3902 - accuracy: 0.8294 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 867us/step - loss: 0.3321 - accuracy: 0.8680 - val_loss: 0.4838 - val_accuracy: 0.8142\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 788us/step - loss: 0.2967 - accuracy: 0.8869 - val_loss: 0.4813 - val_accuracy: 0.8219\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 921us/step - loss: 0.2784 - accuracy: 0.8947 - val_loss: 0.4974 - val_accuracy: 0.8165\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 783us/step - loss: 0.2681 - accuracy: 0.8977 - val_loss: 0.4910 - val_accuracy: 0.8186\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 915us/step - loss: 0.2621 - accuracy: 0.8997 - val_loss: 0.4908 - val_accuracy: 0.8186\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 849us/step - loss: 0.2585 - accuracy: 0.9026 - val_loss: 0.4728 - val_accuracy: 0.8256\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2547 - accuracy: 0.9040 - val_loss: 0.4672 - val_accuracy: 0.8251\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.2502 - accuracy: 0.9055 - val_loss: 0.5002 - val_accuracy: 0.8138\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2484 - accuracy: 0.9063 - val_loss: 0.4184 - val_accuracy: 0.8424\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2449 - accuracy: 0.9074 - val_loss: 0.4178 - val_accuracy: 0.8420\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 956us/step - loss: 0.2423 - accuracy: 0.9087 - val_loss: 0.4915 - val_accuracy: 0.8159\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2403 - accuracy: 0.9093 - val_loss: 0.5003 - val_accuracy: 0.8106\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 897us/step - loss: 0.2378 - accuracy: 0.9103 - val_loss: 0.4850 - val_accuracy: 0.8202\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2349 - accuracy: 0.9110 - val_loss: 0.4766 - val_accuracy: 0.8217\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 914us/step - loss: 0.2334 - accuracy: 0.9123 - val_loss: 0.4813 - val_accuracy: 0.8184\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 880us/step - loss: 0.2314 - accuracy: 0.9134 - val_loss: 0.4823 - val_accuracy: 0.8214\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 889us/step - loss: 0.2300 - accuracy: 0.9137 - val_loss: 0.4403 - val_accuracy: 0.8327\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 916us/step - loss: 0.2282 - accuracy: 0.9138 - val_loss: 0.4911 - val_accuracy: 0.8161\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 888us/step - loss: 0.2269 - accuracy: 0.9145 - val_loss: 0.5027 - val_accuracy: 0.8087\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 880us/step - loss: 0.2250 - accuracy: 0.9149 - val_loss: 0.4978 - val_accuracy: 0.8084\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 938us/step - loss: 0.2227 - accuracy: 0.9157 - val_loss: 0.4429 - val_accuracy: 0.8300\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 902us/step - loss: 0.2218 - accuracy: 0.9160 - val_loss: 0.4493 - val_accuracy: 0.8295\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 887us/step - loss: 0.2212 - accuracy: 0.9167 - val_loss: 0.5121 - val_accuracy: 0.8042\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 934us/step - loss: 0.2189 - accuracy: 0.9171 - val_loss: 0.4908 - val_accuracy: 0.8148\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 888us/step - loss: 0.2180 - accuracy: 0.9171 - val_loss: 0.4678 - val_accuracy: 0.8232\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 907us/step - loss: 0.2175 - accuracy: 0.9172 - val_loss: 0.4263 - val_accuracy: 0.8350\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 939us/step - loss: 0.2163 - accuracy: 0.9177 - val_loss: 0.4797 - val_accuracy: 0.8198\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 964us/step - loss: 0.2153 - accuracy: 0.9184 - val_loss: 0.4271 - val_accuracy: 0.8385\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 916us/step - loss: 0.2138 - accuracy: 0.9192 - val_loss: 0.4468 - val_accuracy: 0.8289\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 921us/step - loss: 0.2132 - accuracy: 0.9189 - val_loss: 0.4562 - val_accuracy: 0.8231\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 893us/step - loss: 0.2120 - accuracy: 0.9201 - val_loss: 0.4300 - val_accuracy: 0.8370\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 908us/step - loss: 0.2112 - accuracy: 0.9195 - val_loss: 0.4404 - val_accuracy: 0.8303\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 926us/step - loss: 0.2093 - accuracy: 0.9209 - val_loss: 0.4491 - val_accuracy: 0.8270\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 909us/step - loss: 0.2088 - accuracy: 0.9208 - val_loss: 0.4504 - val_accuracy: 0.8274\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 921us/step - loss: 0.2073 - accuracy: 0.9208 - val_loss: 0.4334 - val_accuracy: 0.8361\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2075 - accuracy: 0.9210 - val_loss: 0.4737 - val_accuracy: 0.8196\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2069 - accuracy: 0.9209 - val_loss: 0.4711 - val_accuracy: 0.8191\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2047 - accuracy: 0.9219 - val_loss: 0.4729 - val_accuracy: 0.8232\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2053 - accuracy: 0.9216 - val_loss: 0.4292 - val_accuracy: 0.8370\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2045 - accuracy: 0.9236 - val_loss: 0.4733 - val_accuracy: 0.8155\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 986us/step - loss: 0.2036 - accuracy: 0.9222 - val_loss: 0.4645 - val_accuracy: 0.8256\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 900us/step - loss: 0.2030 - accuracy: 0.9230 - val_loss: 0.4521 - val_accuracy: 0.8282\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 953us/step - loss: 0.2018 - accuracy: 0.9230 - val_loss: 0.4933 - val_accuracy: 0.8128\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 897us/step - loss: 0.2010 - accuracy: 0.9237 - val_loss: 0.4503 - val_accuracy: 0.8307\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 913us/step - loss: 0.2005 - accuracy: 0.9229 - val_loss: 0.4720 - val_accuracy: 0.8200\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2000 - accuracy: 0.9244 - val_loss: 0.4682 - val_accuracy: 0.8298\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 956us/step - loss: 0.1993 - accuracy: 0.9238 - val_loss: 0.4650 - val_accuracy: 0.8252\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5701 - accuracy: 0.6953 - val_loss: 0.5976 - val_accuracy: 0.6723\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.4354 - accuracy: 0.7959 - val_loss: 0.5110 - val_accuracy: 0.7555\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 987us/step - loss: 0.3584 - accuracy: 0.8478 - val_loss: 0.5264 - val_accuracy: 0.7751\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.3081 - accuracy: 0.8788 - val_loss: 0.4934 - val_accuracy: 0.8085\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2843 - accuracy: 0.8907 - val_loss: 0.4948 - val_accuracy: 0.8127\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2717 - accuracy: 0.8960 - val_loss: 0.4747 - val_accuracy: 0.8169\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2634 - accuracy: 0.8993 - val_loss: 0.4913 - val_accuracy: 0.8119\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 972us/step - loss: 0.2592 - accuracy: 0.9006 - val_loss: 0.4485 - val_accuracy: 0.8262\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2562 - accuracy: 0.9015 - val_loss: 0.4627 - val_accuracy: 0.8233\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2520 - accuracy: 0.9032 - val_loss: 0.4736 - val_accuracy: 0.8170\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 953us/step - loss: 0.2504 - accuracy: 0.9040 - val_loss: 0.4757 - val_accuracy: 0.8141\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2465 - accuracy: 0.9064 - val_loss: 0.4863 - val_accuracy: 0.8125\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2447 - accuracy: 0.9067 - val_loss: 0.4316 - val_accuracy: 0.8290\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 935us/step - loss: 0.2426 - accuracy: 0.9063 - val_loss: 0.5279 - val_accuracy: 0.7904\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2403 - accuracy: 0.9078 - val_loss: 0.4544 - val_accuracy: 0.8226\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 964us/step - loss: 0.2386 - accuracy: 0.9074 - val_loss: 0.4388 - val_accuracy: 0.8272\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 968us/step - loss: 0.2362 - accuracy: 0.9091 - val_loss: 0.4427 - val_accuracy: 0.8258\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2341 - accuracy: 0.9096 - val_loss: 0.4303 - val_accuracy: 0.8327\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2324 - accuracy: 0.9103 - val_loss: 0.4569 - val_accuracy: 0.8202\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 913us/step - loss: 0.2315 - accuracy: 0.9104 - val_loss: 0.4460 - val_accuracy: 0.8213\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2289 - accuracy: 0.9115 - val_loss: 0.5092 - val_accuracy: 0.8024\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 890us/step - loss: 0.2276 - accuracy: 0.9126 - val_loss: 0.4861 - val_accuracy: 0.8075\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2258 - accuracy: 0.9136 - val_loss: 0.4543 - val_accuracy: 0.8185\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 906us/step - loss: 0.2251 - accuracy: 0.9134 - val_loss: 0.4489 - val_accuracy: 0.8243\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2237 - accuracy: 0.9143 - val_loss: 0.4382 - val_accuracy: 0.8276\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 831us/step - loss: 0.2220 - accuracy: 0.9148 - val_loss: 0.4603 - val_accuracy: 0.8225\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 862us/step - loss: 0.2208 - accuracy: 0.9148 - val_loss: 0.4214 - val_accuracy: 0.8370\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 939us/step - loss: 0.2200 - accuracy: 0.9149 - val_loss: 0.4472 - val_accuracy: 0.8247\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 806us/step - loss: 0.2185 - accuracy: 0.9161 - val_loss: 0.4376 - val_accuracy: 0.8234\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 923us/step - loss: 0.2164 - accuracy: 0.9167 - val_loss: 0.4429 - val_accuracy: 0.8285\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 798us/step - loss: 0.2159 - accuracy: 0.9170 - val_loss: 0.4917 - val_accuracy: 0.8127\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 912us/step - loss: 0.2142 - accuracy: 0.9184 - val_loss: 0.4138 - val_accuracy: 0.8390\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 818us/step - loss: 0.2143 - accuracy: 0.9177 - val_loss: 0.4558 - val_accuracy: 0.8201\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 919us/step - loss: 0.2127 - accuracy: 0.9175 - val_loss: 0.4258 - val_accuracy: 0.8346\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 784us/step - loss: 0.2108 - accuracy: 0.9191 - val_loss: 0.4607 - val_accuracy: 0.8193\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 963us/step - loss: 0.2102 - accuracy: 0.9196 - val_loss: 0.4585 - val_accuracy: 0.8269\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.2103 - accuracy: 0.9196 - val_loss: 0.4625 - val_accuracy: 0.8248\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 919us/step - loss: 0.2089 - accuracy: 0.9205 - val_loss: 0.4652 - val_accuracy: 0.8191\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.2077 - accuracy: 0.9205 - val_loss: 0.4653 - val_accuracy: 0.8230\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.2070 - accuracy: 0.9195 - val_loss: 0.4728 - val_accuracy: 0.8193\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 783us/step - loss: 0.2065 - accuracy: 0.9215 - val_loss: 0.4279 - val_accuracy: 0.8361\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.2056 - accuracy: 0.9208 - val_loss: 0.4495 - val_accuracy: 0.8270\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 744us/step - loss: 0.2049 - accuracy: 0.9213 - val_loss: 0.4561 - val_accuracy: 0.8270\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.2049 - accuracy: 0.9206 - val_loss: 0.4802 - val_accuracy: 0.8171\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.2041 - accuracy: 0.9214 - val_loss: 0.4707 - val_accuracy: 0.8223\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.2031 - accuracy: 0.9224 - val_loss: 0.4477 - val_accuracy: 0.8285\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.2019 - accuracy: 0.9233 - val_loss: 0.4661 - val_accuracy: 0.8262\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.2021 - accuracy: 0.9226 - val_loss: 0.4219 - val_accuracy: 0.8393\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.2013 - accuracy: 0.9229 - val_loss: 0.4180 - val_accuracy: 0.8395\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 776us/step - loss: 0.2012 - accuracy: 0.9231 - val_loss: 0.4429 - val_accuracy: 0.8311\n"
     ]
    }
   ],
   "source": [
    "# Train model without DP\n",
    "print(\"Training model without DP...\")\n",
    "results_no_dp = run_iterations(\n",
    "    X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "    batch_size=default_batch_size, epochs=epochs, use_dp=False, n_iterations=n_iterations,\n",
    "    num_microbatches=None, l2_norm_clip=None, noise_multiplier=None\n",
    ")\n",
    "results_no_dp_stats = compute_statistics(results_no_dp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec3c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with batch_size=16...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.1 iterated over 167200 steps satisfies differential privacy with eps = 0.849 and delta = 1e-05.\n",
      "The optimal RDP order is 19.0.\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.7163 - accuracy: 0.5146 - val_loss: 0.6996 - val_accuracy: 0.4940\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.6867 - accuracy: 0.5481 - val_loss: 0.6975 - val_accuracy: 0.5113\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.6780 - accuracy: 0.5676 - val_loss: 0.6854 - val_accuracy: 0.5619\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.6693 - accuracy: 0.5851 - val_loss: 0.6826 - val_accuracy: 0.5663\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.6619 - accuracy: 0.6020 - val_loss: 0.6770 - val_accuracy: 0.5831\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.6568 - accuracy: 0.6118 - val_loss: 0.6724 - val_accuracy: 0.5973\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.6513 - accuracy: 0.6227 - val_loss: 0.6640 - val_accuracy: 0.6195\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.6455 - accuracy: 0.6320 - val_loss: 0.6696 - val_accuracy: 0.6018\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 601us/step - loss: 0.6412 - accuracy: 0.6373 - val_loss: 0.6574 - val_accuracy: 0.6267\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.6360 - accuracy: 0.6466 - val_loss: 0.6558 - val_accuracy: 0.6257\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 639us/step - loss: 0.6309 - accuracy: 0.6538 - val_loss: 0.6502 - val_accuracy: 0.6303\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 604us/step - loss: 0.6259 - accuracy: 0.6577 - val_loss: 0.6441 - val_accuracy: 0.6420\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.6222 - accuracy: 0.6629 - val_loss: 0.6356 - val_accuracy: 0.6510\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.6172 - accuracy: 0.6681 - val_loss: 0.6422 - val_accuracy: 0.6347\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 737us/step - loss: 0.6141 - accuracy: 0.6694 - val_loss: 0.6303 - val_accuracy: 0.6516\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 3s 798us/step - loss: 0.6096 - accuracy: 0.6732 - val_loss: 0.6399 - val_accuracy: 0.6319\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 3s 837us/step - loss: 0.6068 - accuracy: 0.6738 - val_loss: 0.6235 - val_accuracy: 0.6534\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 746us/step - loss: 0.6027 - accuracy: 0.6802 - val_loss: 0.6290 - val_accuracy: 0.6401\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 719us/step - loss: 0.5994 - accuracy: 0.6855 - val_loss: 0.6325 - val_accuracy: 0.6343\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 3s 857us/step - loss: 0.5966 - accuracy: 0.6851 - val_loss: 0.6322 - val_accuracy: 0.6326\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 3s 947us/step - loss: 0.5932 - accuracy: 0.6878 - val_loss: 0.6249 - val_accuracy: 0.6393\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 3s 840us/step - loss: 0.5906 - accuracy: 0.6902 - val_loss: 0.6166 - val_accuracy: 0.6465\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 3s 827us/step - loss: 0.5878 - accuracy: 0.6925 - val_loss: 0.6297 - val_accuracy: 0.6312\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 3s 830us/step - loss: 0.5851 - accuracy: 0.6946 - val_loss: 0.6228 - val_accuracy: 0.6362\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 3s 893us/step - loss: 0.5822 - accuracy: 0.6983 - val_loss: 0.6185 - val_accuracy: 0.6428\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 3s 827us/step - loss: 0.5798 - accuracy: 0.6995 - val_loss: 0.6187 - val_accuracy: 0.6428\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 3s 835us/step - loss: 0.5782 - accuracy: 0.7026 - val_loss: 0.6183 - val_accuracy: 0.6443\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 3s 852us/step - loss: 0.5748 - accuracy: 0.7036 - val_loss: 0.6138 - val_accuracy: 0.6475\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 3s 840us/step - loss: 0.5723 - accuracy: 0.7058 - val_loss: 0.6076 - val_accuracy: 0.6516\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 3s 823us/step - loss: 0.5704 - accuracy: 0.7092 - val_loss: 0.6153 - val_accuracy: 0.6448\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 3s 828us/step - loss: 0.5672 - accuracy: 0.7118 - val_loss: 0.6203 - val_accuracy: 0.6399\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 3s 846us/step - loss: 0.5654 - accuracy: 0.7136 - val_loss: 0.6005 - val_accuracy: 0.6590\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 3s 826us/step - loss: 0.5642 - accuracy: 0.7137 - val_loss: 0.6167 - val_accuracy: 0.6420\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 3s 828us/step - loss: 0.5612 - accuracy: 0.7156 - val_loss: 0.6081 - val_accuracy: 0.6503\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 3s 848us/step - loss: 0.5592 - accuracy: 0.7171 - val_loss: 0.6016 - val_accuracy: 0.6568\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 3s 793us/step - loss: 0.5575 - accuracy: 0.7194 - val_loss: 0.5991 - val_accuracy: 0.6585\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 721us/step - loss: 0.5549 - accuracy: 0.7205 - val_loss: 0.6069 - val_accuracy: 0.6501\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 740us/step - loss: 0.5540 - accuracy: 0.7218 - val_loss: 0.6058 - val_accuracy: 0.6519\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 713us/step - loss: 0.5519 - accuracy: 0.7226 - val_loss: 0.6153 - val_accuracy: 0.6412\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 723us/step - loss: 0.5500 - accuracy: 0.7228 - val_loss: 0.6182 - val_accuracy: 0.6382\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 725us/step - loss: 0.5487 - accuracy: 0.7230 - val_loss: 0.6095 - val_accuracy: 0.6476\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 743us/step - loss: 0.5463 - accuracy: 0.7257 - val_loss: 0.6036 - val_accuracy: 0.6538\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 718us/step - loss: 0.5457 - accuracy: 0.7252 - val_loss: 0.6006 - val_accuracy: 0.6570\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 735us/step - loss: 0.5428 - accuracy: 0.7283 - val_loss: 0.6038 - val_accuracy: 0.6544\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 739us/step - loss: 0.5419 - accuracy: 0.7276 - val_loss: 0.6029 - val_accuracy: 0.6558\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 730us/step - loss: 0.5409 - accuracy: 0.7281 - val_loss: 0.5983 - val_accuracy: 0.6597\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 732us/step - loss: 0.5395 - accuracy: 0.7289 - val_loss: 0.6192 - val_accuracy: 0.6388\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 728us/step - loss: 0.5372 - accuracy: 0.7307 - val_loss: 0.5919 - val_accuracy: 0.6653\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 3s 757us/step - loss: 0.5363 - accuracy: 0.7316 - val_loss: 0.5969 - val_accuracy: 0.6616\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 3s 798us/step - loss: 0.5352 - accuracy: 0.7323 - val_loss: 0.6099 - val_accuracy: 0.6496\n",
      "Epoch 1/50\n",
      "   1/3344 [..............................] - ETA: 0s - loss: 0.7483 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 3s 769us/step - loss: 0.7109 - accuracy: 0.5244 - val_loss: 0.7117 - val_accuracy: 0.3874\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 3s 787us/step - loss: 0.6819 - accuracy: 0.5614 - val_loss: 0.7095 - val_accuracy: 0.4369\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 720us/step - loss: 0.6728 - accuracy: 0.5850 - val_loss: 0.7011 - val_accuracy: 0.4959\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 3s 812us/step - loss: 0.6657 - accuracy: 0.6036 - val_loss: 0.6953 - val_accuracy: 0.5232\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 3s 816us/step - loss: 0.6591 - accuracy: 0.6195 - val_loss: 0.6841 - val_accuracy: 0.5612\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 3s 806us/step - loss: 0.6531 - accuracy: 0.6305 - val_loss: 0.6821 - val_accuracy: 0.5680\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 3s 824us/step - loss: 0.6463 - accuracy: 0.6455 - val_loss: 0.6712 - val_accuracy: 0.5896\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 717us/step - loss: 0.6412 - accuracy: 0.6520 - val_loss: 0.6660 - val_accuracy: 0.5998\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 707us/step - loss: 0.6358 - accuracy: 0.6592 - val_loss: 0.6548 - val_accuracy: 0.6195\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 724us/step - loss: 0.6304 - accuracy: 0.6634 - val_loss: 0.6510 - val_accuracy: 0.6207\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 705us/step - loss: 0.6263 - accuracy: 0.6677 - val_loss: 0.6570 - val_accuracy: 0.6100\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 713us/step - loss: 0.6216 - accuracy: 0.6728 - val_loss: 0.6521 - val_accuracy: 0.6112\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 714us/step - loss: 0.6170 - accuracy: 0.6761 - val_loss: 0.6426 - val_accuracy: 0.6237\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 727us/step - loss: 0.6130 - accuracy: 0.6777 - val_loss: 0.6389 - val_accuracy: 0.6274\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 669us/step - loss: 0.6085 - accuracy: 0.6840 - val_loss: 0.6409 - val_accuracy: 0.6231\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 728us/step - loss: 0.6048 - accuracy: 0.6854 - val_loss: 0.6350 - val_accuracy: 0.6288\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 684us/step - loss: 0.6002 - accuracy: 0.6907 - val_loss: 0.6281 - val_accuracy: 0.6365\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 704us/step - loss: 0.5973 - accuracy: 0.6906 - val_loss: 0.6304 - val_accuracy: 0.6324\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.5933 - accuracy: 0.6937 - val_loss: 0.6205 - val_accuracy: 0.6439\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 691us/step - loss: 0.5905 - accuracy: 0.6970 - val_loss: 0.6218 - val_accuracy: 0.6422\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 700us/step - loss: 0.5867 - accuracy: 0.6986 - val_loss: 0.6234 - val_accuracy: 0.6402\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 706us/step - loss: 0.5829 - accuracy: 0.7024 - val_loss: 0.6287 - val_accuracy: 0.6351\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 723us/step - loss: 0.5797 - accuracy: 0.7045 - val_loss: 0.6233 - val_accuracy: 0.6402\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 708us/step - loss: 0.5772 - accuracy: 0.7054 - val_loss: 0.6233 - val_accuracy: 0.6409\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 694us/step - loss: 0.5751 - accuracy: 0.7063 - val_loss: 0.5970 - val_accuracy: 0.6731\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 696us/step - loss: 0.5716 - accuracy: 0.7109 - val_loss: 0.6150 - val_accuracy: 0.6510\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 701us/step - loss: 0.5687 - accuracy: 0.7107 - val_loss: 0.6088 - val_accuracy: 0.6576\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.5658 - accuracy: 0.7119 - val_loss: 0.6192 - val_accuracy: 0.6466\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 692us/step - loss: 0.5636 - accuracy: 0.7152 - val_loss: 0.6215 - val_accuracy: 0.6439\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.5594 - accuracy: 0.7185 - val_loss: 0.6082 - val_accuracy: 0.6594\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.5594 - accuracy: 0.7170 - val_loss: 0.6069 - val_accuracy: 0.6626\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 595us/step - loss: 0.5560 - accuracy: 0.7207 - val_loss: 0.5985 - val_accuracy: 0.6701\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.5537 - accuracy: 0.7223 - val_loss: 0.6107 - val_accuracy: 0.6555\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.5519 - accuracy: 0.7234 - val_loss: 0.6027 - val_accuracy: 0.6643\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.5487 - accuracy: 0.7247 - val_loss: 0.6158 - val_accuracy: 0.6470\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.5474 - accuracy: 0.7245 - val_loss: 0.6086 - val_accuracy: 0.6574\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 601us/step - loss: 0.5451 - accuracy: 0.7266 - val_loss: 0.5957 - val_accuracy: 0.6716\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 601us/step - loss: 0.5445 - accuracy: 0.7270 - val_loss: 0.5845 - val_accuracy: 0.6830\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 634us/step - loss: 0.5429 - accuracy: 0.7275 - val_loss: 0.6033 - val_accuracy: 0.6613\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.5399 - accuracy: 0.7307 - val_loss: 0.5940 - val_accuracy: 0.6730\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 604us/step - loss: 0.5392 - accuracy: 0.7321 - val_loss: 0.5965 - val_accuracy: 0.6706\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.5367 - accuracy: 0.7331 - val_loss: 0.6029 - val_accuracy: 0.6639\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.5360 - accuracy: 0.7318 - val_loss: 0.6112 - val_accuracy: 0.6537\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5348 - accuracy: 0.7327 - val_loss: 0.6007 - val_accuracy: 0.6674\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 3s 815us/step - loss: 0.5327 - accuracy: 0.7344 - val_loss: 0.6097 - val_accuracy: 0.6576\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 737us/step - loss: 0.5312 - accuracy: 0.7347 - val_loss: 0.6150 - val_accuracy: 0.6523\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.5290 - accuracy: 0.7367 - val_loss: 0.6139 - val_accuracy: 0.6543\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 704us/step - loss: 0.5280 - accuracy: 0.7367 - val_loss: 0.6075 - val_accuracy: 0.6612\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 735us/step - loss: 0.5268 - accuracy: 0.7376 - val_loss: 0.5922 - val_accuracy: 0.6727\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 3s 763us/step - loss: 0.5254 - accuracy: 0.7401 - val_loss: 0.5838 - val_accuracy: 0.6795\n",
      "Epoch 1/50\n",
      "3333/3344 [============================>.] - ETA: 0s - loss: 0.6876 - accuracy: 0.5569WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 3s 962us/step - loss: 0.6876 - accuracy: 0.5571 - val_loss: 0.6943 - val_accuracy: 0.5250\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 3s 850us/step - loss: 0.6747 - accuracy: 0.5834 - val_loss: 0.6811 - val_accuracy: 0.5638\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 3s 855us/step - loss: 0.6680 - accuracy: 0.5968 - val_loss: 0.6843 - val_accuracy: 0.5539\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 3s 847us/step - loss: 0.6624 - accuracy: 0.6089 - val_loss: 0.6704 - val_accuracy: 0.5883\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 3s 876us/step - loss: 0.6563 - accuracy: 0.6187 - val_loss: 0.6685 - val_accuracy: 0.5980\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 3s 895us/step - loss: 0.6510 - accuracy: 0.6292 - val_loss: 0.6561 - val_accuracy: 0.6281\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 3s 873us/step - loss: 0.6459 - accuracy: 0.6397 - val_loss: 0.6557 - val_accuracy: 0.6228\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 3s 857us/step - loss: 0.6412 - accuracy: 0.6468 - val_loss: 0.6575 - val_accuracy: 0.6159\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 3s 861us/step - loss: 0.6359 - accuracy: 0.6529 - val_loss: 0.6473 - val_accuracy: 0.6331\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 3s 834us/step - loss: 0.6315 - accuracy: 0.6597 - val_loss: 0.6544 - val_accuracy: 0.6162\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 3s 917us/step - loss: 0.6268 - accuracy: 0.6660 - val_loss: 0.6423 - val_accuracy: 0.6330\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 4s 1ms/step - loss: 0.6214 - accuracy: 0.6707 - val_loss: 0.6480 - val_accuracy: 0.6193\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 3s 981us/step - loss: 0.6173 - accuracy: 0.6749 - val_loss: 0.6425 - val_accuracy: 0.6221\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 4s 1ms/step - loss: 0.6124 - accuracy: 0.6785 - val_loss: 0.6232 - val_accuracy: 0.6472\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 3s 962us/step - loss: 0.6080 - accuracy: 0.6850 - val_loss: 0.6302 - val_accuracy: 0.6362\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 3s 860us/step - loss: 0.6042 - accuracy: 0.6864 - val_loss: 0.6267 - val_accuracy: 0.6386\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 3s 972us/step - loss: 0.6012 - accuracy: 0.6910 - val_loss: 0.6259 - val_accuracy: 0.6376\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 3s 946us/step - loss: 0.5983 - accuracy: 0.6940 - val_loss: 0.6210 - val_accuracy: 0.6418\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 3s 1ms/step - loss: 0.5943 - accuracy: 0.6957 - val_loss: 0.6141 - val_accuracy: 0.6480\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 3s 894us/step - loss: 0.5908 - accuracy: 0.6997 - val_loss: 0.6116 - val_accuracy: 0.6483\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 3s 821us/step - loss: 0.5871 - accuracy: 0.7022 - val_loss: 0.6110 - val_accuracy: 0.6475\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 3s 829us/step - loss: 0.5860 - accuracy: 0.7020 - val_loss: 0.6124 - val_accuracy: 0.6424\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 3s 779us/step - loss: 0.5824 - accuracy: 0.7053 - val_loss: 0.6066 - val_accuracy: 0.6483\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 3s 803us/step - loss: 0.5801 - accuracy: 0.7073 - val_loss: 0.6128 - val_accuracy: 0.6418\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 3s 757us/step - loss: 0.5771 - accuracy: 0.7084 - val_loss: 0.6041 - val_accuracy: 0.6472\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 3s 755us/step - loss: 0.5743 - accuracy: 0.7096 - val_loss: 0.6062 - val_accuracy: 0.6446\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 710us/step - loss: 0.5725 - accuracy: 0.7131 - val_loss: 0.6105 - val_accuracy: 0.6405\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 3s 795us/step - loss: 0.5681 - accuracy: 0.7151 - val_loss: 0.5993 - val_accuracy: 0.6475\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 3s 806us/step - loss: 0.5655 - accuracy: 0.7173 - val_loss: 0.6079 - val_accuracy: 0.6392\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 3s 948us/step - loss: 0.5637 - accuracy: 0.7190 - val_loss: 0.6012 - val_accuracy: 0.6449\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.5615 - accuracy: 0.7204 - val_loss: 0.6102 - val_accuracy: 0.6366\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.5600 - accuracy: 0.7208 - val_loss: 0.6013 - val_accuracy: 0.6419\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.5564 - accuracy: 0.7222 - val_loss: 0.6102 - val_accuracy: 0.6363\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5549 - accuracy: 0.7248 - val_loss: 0.5920 - val_accuracy: 0.6485\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.5525 - accuracy: 0.7243 - val_loss: 0.5984 - val_accuracy: 0.6422\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.5515 - accuracy: 0.7239 - val_loss: 0.6111 - val_accuracy: 0.6309\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5498 - accuracy: 0.7271 - val_loss: 0.6073 - val_accuracy: 0.6326\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.5466 - accuracy: 0.7273 - val_loss: 0.6139 - val_accuracy: 0.6265\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.5459 - accuracy: 0.7272 - val_loss: 0.5937 - val_accuracy: 0.6429\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.5435 - accuracy: 0.7309 - val_loss: 0.5849 - val_accuracy: 0.6519\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.5407 - accuracy: 0.7324 - val_loss: 0.6110 - val_accuracy: 0.6267\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5397 - accuracy: 0.7330 - val_loss: 0.6015 - val_accuracy: 0.6339\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.5378 - accuracy: 0.7334 - val_loss: 0.5855 - val_accuracy: 0.6513\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.5355 - accuracy: 0.7348 - val_loss: 0.5938 - val_accuracy: 0.6430\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.5355 - accuracy: 0.7336 - val_loss: 0.5820 - val_accuracy: 0.6565\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.5325 - accuracy: 0.7364 - val_loss: 0.5936 - val_accuracy: 0.6425\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.5317 - accuracy: 0.7366 - val_loss: 0.5855 - val_accuracy: 0.6524\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.5310 - accuracy: 0.7353 - val_loss: 0.5958 - val_accuracy: 0.6396\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5290 - accuracy: 0.7373 - val_loss: 0.5900 - val_accuracy: 0.6466\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5279 - accuracy: 0.7382 - val_loss: 0.5934 - val_accuracy: 0.6425\n",
      "Epoch 1/50\n",
      "3313/3344 [============================>.] - ETA: 0s - loss: 0.7071 - accuracy: 0.5224WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.7068 - accuracy: 0.5231 - val_loss: 0.6986 - val_accuracy: 0.4974\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.6786 - accuracy: 0.5796 - val_loss: 0.6934 - val_accuracy: 0.5321\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.6711 - accuracy: 0.6021 - val_loss: 0.6869 - val_accuracy: 0.5541\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.6638 - accuracy: 0.6193 - val_loss: 0.6853 - val_accuracy: 0.5565\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.6575 - accuracy: 0.6324 - val_loss: 0.6816 - val_accuracy: 0.5597\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.6521 - accuracy: 0.6398 - val_loss: 0.6707 - val_accuracy: 0.5809\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.6476 - accuracy: 0.6487 - val_loss: 0.6680 - val_accuracy: 0.5802\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.6411 - accuracy: 0.6530 - val_loss: 0.6699 - val_accuracy: 0.5703\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.6362 - accuracy: 0.6614 - val_loss: 0.6614 - val_accuracy: 0.5844\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.6309 - accuracy: 0.6656 - val_loss: 0.6457 - val_accuracy: 0.6151\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.6231 - accuracy: 0.6743 - val_loss: 0.6458 - val_accuracy: 0.6116\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.6174 - accuracy: 0.6803 - val_loss: 0.6350 - val_accuracy: 0.6304\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.6123 - accuracy: 0.6833 - val_loss: 0.6338 - val_accuracy: 0.6295\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.6086 - accuracy: 0.6852 - val_loss: 0.6286 - val_accuracy: 0.6373\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.6044 - accuracy: 0.6888 - val_loss: 0.6243 - val_accuracy: 0.6425\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5996 - accuracy: 0.6897 - val_loss: 0.6312 - val_accuracy: 0.6330\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.5954 - accuracy: 0.6926 - val_loss: 0.6218 - val_accuracy: 0.6445\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.5925 - accuracy: 0.6945 - val_loss: 0.6103 - val_accuracy: 0.6572\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.5895 - accuracy: 0.6968 - val_loss: 0.6130 - val_accuracy: 0.6518\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.5854 - accuracy: 0.7000 - val_loss: 0.6305 - val_accuracy: 0.6281\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5827 - accuracy: 0.7022 - val_loss: 0.6196 - val_accuracy: 0.6391\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.5796 - accuracy: 0.7030 - val_loss: 0.5936 - val_accuracy: 0.6685\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.5770 - accuracy: 0.7049 - val_loss: 0.6157 - val_accuracy: 0.6385\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.5732 - accuracy: 0.7075 - val_loss: 0.6076 - val_accuracy: 0.6459\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5719 - accuracy: 0.7089 - val_loss: 0.5987 - val_accuracy: 0.6579\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.5690 - accuracy: 0.7093 - val_loss: 0.6071 - val_accuracy: 0.6448\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5664 - accuracy: 0.7120 - val_loss: 0.6043 - val_accuracy: 0.6479\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.5651 - accuracy: 0.7136 - val_loss: 0.6147 - val_accuracy: 0.6353\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.5634 - accuracy: 0.7138 - val_loss: 0.6075 - val_accuracy: 0.6428\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5603 - accuracy: 0.7159 - val_loss: 0.6089 - val_accuracy: 0.6399\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.5595 - accuracy: 0.7158 - val_loss: 0.5999 - val_accuracy: 0.6502\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.5558 - accuracy: 0.7192 - val_loss: 0.6062 - val_accuracy: 0.6431\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.5541 - accuracy: 0.7201 - val_loss: 0.6067 - val_accuracy: 0.6431\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.5527 - accuracy: 0.7211 - val_loss: 0.6045 - val_accuracy: 0.6437\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.5506 - accuracy: 0.7223 - val_loss: 0.6075 - val_accuracy: 0.6407\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.5493 - accuracy: 0.7230 - val_loss: 0.5962 - val_accuracy: 0.6518\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5469 - accuracy: 0.7239 - val_loss: 0.5952 - val_accuracy: 0.6527\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.5460 - accuracy: 0.7247 - val_loss: 0.5987 - val_accuracy: 0.6493\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.5434 - accuracy: 0.7262 - val_loss: 0.5941 - val_accuracy: 0.6553\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.5430 - accuracy: 0.7272 - val_loss: 0.5999 - val_accuracy: 0.6498\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5408 - accuracy: 0.7277 - val_loss: 0.6071 - val_accuracy: 0.6435\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.5393 - accuracy: 0.7285 - val_loss: 0.6000 - val_accuracy: 0.6521\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.5376 - accuracy: 0.7302 - val_loss: 0.5995 - val_accuracy: 0.6532\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.5354 - accuracy: 0.7306 - val_loss: 0.6100 - val_accuracy: 0.6424\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.5341 - accuracy: 0.7319 - val_loss: 0.5895 - val_accuracy: 0.6642\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5327 - accuracy: 0.7319 - val_loss: 0.5876 - val_accuracy: 0.6652\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.5311 - accuracy: 0.7335 - val_loss: 0.5896 - val_accuracy: 0.6629\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.5304 - accuracy: 0.7338 - val_loss: 0.5930 - val_accuracy: 0.6604\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5288 - accuracy: 0.7354 - val_loss: 0.5921 - val_accuracy: 0.6610\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.5273 - accuracy: 0.7354 - val_loss: 0.5927 - val_accuracy: 0.6616\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.7117 - accuracy: 0.5295 - val_loss: 0.7074 - val_accuracy: 0.4265\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.6784 - accuracy: 0.5810 - val_loss: 0.7004 - val_accuracy: 0.4835\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.6668 - accuracy: 0.6081 - val_loss: 0.6947 - val_accuracy: 0.5217\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.6560 - accuracy: 0.6251 - val_loss: 0.6845 - val_accuracy: 0.5582\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.6481 - accuracy: 0.6377 - val_loss: 0.6710 - val_accuracy: 0.5897\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.6417 - accuracy: 0.6459 - val_loss: 0.6702 - val_accuracy: 0.5898\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.6369 - accuracy: 0.6534 - val_loss: 0.6655 - val_accuracy: 0.5975\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.6317 - accuracy: 0.6600 - val_loss: 0.6549 - val_accuracy: 0.6173\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.6257 - accuracy: 0.6639 - val_loss: 0.6679 - val_accuracy: 0.5908\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.6217 - accuracy: 0.6692 - val_loss: 0.6498 - val_accuracy: 0.6205\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.6175 - accuracy: 0.6718 - val_loss: 0.6480 - val_accuracy: 0.6225\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.6139 - accuracy: 0.6730 - val_loss: 0.6492 - val_accuracy: 0.6196\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.6098 - accuracy: 0.6777 - val_loss: 0.6423 - val_accuracy: 0.6274\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.6064 - accuracy: 0.6803 - val_loss: 0.6486 - val_accuracy: 0.6192\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.6037 - accuracy: 0.6838 - val_loss: 0.6249 - val_accuracy: 0.6506\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.6004 - accuracy: 0.6862 - val_loss: 0.6413 - val_accuracy: 0.6257\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5978 - accuracy: 0.6878 - val_loss: 0.6362 - val_accuracy: 0.6309\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5948 - accuracy: 0.6896 - val_loss: 0.6356 - val_accuracy: 0.6318\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.5918 - accuracy: 0.6937 - val_loss: 0.6268 - val_accuracy: 0.6437\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.5881 - accuracy: 0.6962 - val_loss: 0.6343 - val_accuracy: 0.6334\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.5867 - accuracy: 0.6950 - val_loss: 0.6315 - val_accuracy: 0.6373\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5839 - accuracy: 0.6983 - val_loss: 0.6213 - val_accuracy: 0.6467\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.5814 - accuracy: 0.7003 - val_loss: 0.6188 - val_accuracy: 0.6485\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.5800 - accuracy: 0.7012 - val_loss: 0.6233 - val_accuracy: 0.6433\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.5779 - accuracy: 0.7012 - val_loss: 0.6171 - val_accuracy: 0.6504\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5745 - accuracy: 0.7059 - val_loss: 0.6187 - val_accuracy: 0.6471\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.5732 - accuracy: 0.7059 - val_loss: 0.6320 - val_accuracy: 0.6331\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.5697 - accuracy: 0.7075 - val_loss: 0.6059 - val_accuracy: 0.6606\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5688 - accuracy: 0.7078 - val_loss: 0.6113 - val_accuracy: 0.6547\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.5668 - accuracy: 0.7087 - val_loss: 0.6202 - val_accuracy: 0.6457\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.5646 - accuracy: 0.7102 - val_loss: 0.6136 - val_accuracy: 0.6519\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.5624 - accuracy: 0.7103 - val_loss: 0.6059 - val_accuracy: 0.6604\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5611 - accuracy: 0.7142 - val_loss: 0.6098 - val_accuracy: 0.6565\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.5590 - accuracy: 0.7158 - val_loss: 0.6161 - val_accuracy: 0.6502\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.5567 - accuracy: 0.7148 - val_loss: 0.6290 - val_accuracy: 0.6361\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5566 - accuracy: 0.7151 - val_loss: 0.6185 - val_accuracy: 0.6490\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.5541 - accuracy: 0.7166 - val_loss: 0.6117 - val_accuracy: 0.6551\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.5521 - accuracy: 0.7181 - val_loss: 0.5989 - val_accuracy: 0.6642\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.5504 - accuracy: 0.7194 - val_loss: 0.6152 - val_accuracy: 0.6513\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5504 - accuracy: 0.7189 - val_loss: 0.6010 - val_accuracy: 0.6633\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.5478 - accuracy: 0.7212 - val_loss: 0.6125 - val_accuracy: 0.6525\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.5470 - accuracy: 0.7195 - val_loss: 0.6109 - val_accuracy: 0.6537\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5464 - accuracy: 0.7216 - val_loss: 0.6022 - val_accuracy: 0.6637\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.5437 - accuracy: 0.7235 - val_loss: 0.6188 - val_accuracy: 0.6451\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.5421 - accuracy: 0.7247 - val_loss: 0.6103 - val_accuracy: 0.6532\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.5426 - accuracy: 0.7221 - val_loss: 0.5934 - val_accuracy: 0.6750\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5390 - accuracy: 0.7265 - val_loss: 0.5991 - val_accuracy: 0.6675\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5380 - accuracy: 0.7266 - val_loss: 0.6043 - val_accuracy: 0.6603\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.5369 - accuracy: 0.7288 - val_loss: 0.6048 - val_accuracy: 0.6605\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.5362 - accuracy: 0.7287 - val_loss: 0.6111 - val_accuracy: 0.6516\n",
      "\n",
      "Training model with batch_size=32...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.7295 - accuracy: 0.5081 - val_loss: 0.7711 - val_accuracy: 0.1308\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.7059 - accuracy: 0.5021 - val_loss: 0.7356 - val_accuracy: 0.2202\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.7018 - accuracy: 0.5078 - val_loss: 0.7338 - val_accuracy: 0.2343\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6980 - accuracy: 0.5208 - val_loss: 0.7266 - val_accuracy: 0.2782\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6940 - accuracy: 0.5250 - val_loss: 0.7238 - val_accuracy: 0.3153\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6911 - accuracy: 0.5397 - val_loss: 0.7198 - val_accuracy: 0.3562\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6881 - accuracy: 0.5463 - val_loss: 0.7194 - val_accuracy: 0.3759\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6847 - accuracy: 0.5576 - val_loss: 0.7200 - val_accuracy: 0.3858\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6816 - accuracy: 0.5680 - val_loss: 0.7142 - val_accuracy: 0.4221\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6788 - accuracy: 0.5754 - val_loss: 0.7109 - val_accuracy: 0.4428\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.6762 - accuracy: 0.5843 - val_loss: 0.7082 - val_accuracy: 0.4571\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6727 - accuracy: 0.5946 - val_loss: 0.7061 - val_accuracy: 0.4693\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6716 - accuracy: 0.6018 - val_loss: 0.7009 - val_accuracy: 0.4905\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6682 - accuracy: 0.6089 - val_loss: 0.6967 - val_accuracy: 0.5103\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6667 - accuracy: 0.6117 - val_loss: 0.6930 - val_accuracy: 0.5252\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6634 - accuracy: 0.6203 - val_loss: 0.6932 - val_accuracy: 0.5278\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6610 - accuracy: 0.6269 - val_loss: 0.6894 - val_accuracy: 0.5426\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6580 - accuracy: 0.6343 - val_loss: 0.6838 - val_accuracy: 0.5608\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6554 - accuracy: 0.6364 - val_loss: 0.6833 - val_accuracy: 0.5625\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6520 - accuracy: 0.6448 - val_loss: 0.6776 - val_accuracy: 0.5744\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6503 - accuracy: 0.6458 - val_loss: 0.6801 - val_accuracy: 0.5675\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6479 - accuracy: 0.6484 - val_loss: 0.6775 - val_accuracy: 0.5713\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6461 - accuracy: 0.6519 - val_loss: 0.6714 - val_accuracy: 0.5816\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.6441 - accuracy: 0.6568 - val_loss: 0.6740 - val_accuracy: 0.5750\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6413 - accuracy: 0.6581 - val_loss: 0.6680 - val_accuracy: 0.5851\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6390 - accuracy: 0.6623 - val_loss: 0.6675 - val_accuracy: 0.5843\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6372 - accuracy: 0.6625 - val_loss: 0.6671 - val_accuracy: 0.5839\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6354 - accuracy: 0.6647 - val_loss: 0.6613 - val_accuracy: 0.5952\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6330 - accuracy: 0.6692 - val_loss: 0.6564 - val_accuracy: 0.6037\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6311 - accuracy: 0.6695 - val_loss: 0.6648 - val_accuracy: 0.5844\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6284 - accuracy: 0.6732 - val_loss: 0.6622 - val_accuracy: 0.5894\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.6256 - accuracy: 0.6763 - val_loss: 0.6526 - val_accuracy: 0.6063\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.6236 - accuracy: 0.6770 - val_loss: 0.6541 - val_accuracy: 0.6010\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6209 - accuracy: 0.6814 - val_loss: 0.6487 - val_accuracy: 0.6091\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.6197 - accuracy: 0.6807 - val_loss: 0.6530 - val_accuracy: 0.6012\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6178 - accuracy: 0.6836 - val_loss: 0.6493 - val_accuracy: 0.6059\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6157 - accuracy: 0.6829 - val_loss: 0.6514 - val_accuracy: 0.6018\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6135 - accuracy: 0.6870 - val_loss: 0.6440 - val_accuracy: 0.6098\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6106 - accuracy: 0.6907 - val_loss: 0.6376 - val_accuracy: 0.6189\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6090 - accuracy: 0.6914 - val_loss: 0.6382 - val_accuracy: 0.6159\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6070 - accuracy: 0.6922 - val_loss: 0.6414 - val_accuracy: 0.6084\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6050 - accuracy: 0.6938 - val_loss: 0.6380 - val_accuracy: 0.6122\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6022 - accuracy: 0.6980 - val_loss: 0.6348 - val_accuracy: 0.6154\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6007 - accuracy: 0.6979 - val_loss: 0.6349 - val_accuracy: 0.6147\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5973 - accuracy: 0.7015 - val_loss: 0.6287 - val_accuracy: 0.6196\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5963 - accuracy: 0.6992 - val_loss: 0.6320 - val_accuracy: 0.6161\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5951 - accuracy: 0.7010 - val_loss: 0.6353 - val_accuracy: 0.6136\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5930 - accuracy: 0.7028 - val_loss: 0.6264 - val_accuracy: 0.6227\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5905 - accuracy: 0.7059 - val_loss: 0.6262 - val_accuracy: 0.6222\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5892 - accuracy: 0.7046 - val_loss: 0.6260 - val_accuracy: 0.6213\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.7124 - accuracy: 0.5332 - val_loss: 0.7724 - val_accuracy: 0.1603\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6778 - accuracy: 0.5647 - val_loss: 0.7157 - val_accuracy: 0.4042\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6720 - accuracy: 0.5842 - val_loss: 0.7035 - val_accuracy: 0.4902\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6684 - accuracy: 0.5974 - val_loss: 0.6960 - val_accuracy: 0.5358\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6645 - accuracy: 0.6054 - val_loss: 0.6914 - val_accuracy: 0.5608\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6613 - accuracy: 0.6147 - val_loss: 0.6853 - val_accuracy: 0.5793\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6583 - accuracy: 0.6194 - val_loss: 0.6844 - val_accuracy: 0.5839\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6539 - accuracy: 0.6270 - val_loss: 0.6784 - val_accuracy: 0.5967\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6513 - accuracy: 0.6322 - val_loss: 0.6764 - val_accuracy: 0.6009\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6484 - accuracy: 0.6339 - val_loss: 0.6710 - val_accuracy: 0.6133\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.6448 - accuracy: 0.6421 - val_loss: 0.6714 - val_accuracy: 0.6090\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6427 - accuracy: 0.6444 - val_loss: 0.6632 - val_accuracy: 0.6232\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6402 - accuracy: 0.6473 - val_loss: 0.6608 - val_accuracy: 0.6250\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6371 - accuracy: 0.6532 - val_loss: 0.6599 - val_accuracy: 0.6250\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6352 - accuracy: 0.6532 - val_loss: 0.6610 - val_accuracy: 0.6201\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6324 - accuracy: 0.6571 - val_loss: 0.6580 - val_accuracy: 0.6240\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6295 - accuracy: 0.6585 - val_loss: 0.6501 - val_accuracy: 0.6350\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6268 - accuracy: 0.6613 - val_loss: 0.6515 - val_accuracy: 0.6300\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6253 - accuracy: 0.6621 - val_loss: 0.6506 - val_accuracy: 0.6294\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6230 - accuracy: 0.6646 - val_loss: 0.6509 - val_accuracy: 0.6271\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6206 - accuracy: 0.6669 - val_loss: 0.6396 - val_accuracy: 0.6446\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6172 - accuracy: 0.6710 - val_loss: 0.6388 - val_accuracy: 0.6427\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6159 - accuracy: 0.6709 - val_loss: 0.6412 - val_accuracy: 0.6354\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6140 - accuracy: 0.6735 - val_loss: 0.6340 - val_accuracy: 0.6436\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6120 - accuracy: 0.6766 - val_loss: 0.6309 - val_accuracy: 0.6464\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6086 - accuracy: 0.6790 - val_loss: 0.6298 - val_accuracy: 0.6466\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6072 - accuracy: 0.6793 - val_loss: 0.6311 - val_accuracy: 0.6443\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6055 - accuracy: 0.6782 - val_loss: 0.6336 - val_accuracy: 0.6397\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6034 - accuracy: 0.6807 - val_loss: 0.6291 - val_accuracy: 0.6438\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6017 - accuracy: 0.6814 - val_loss: 0.6272 - val_accuracy: 0.6447\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5993 - accuracy: 0.6838 - val_loss: 0.6295 - val_accuracy: 0.6423\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5973 - accuracy: 0.6845 - val_loss: 0.6203 - val_accuracy: 0.6486\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.5952 - accuracy: 0.6874 - val_loss: 0.6272 - val_accuracy: 0.6423\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.5927 - accuracy: 0.6894 - val_loss: 0.6199 - val_accuracy: 0.6485\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5915 - accuracy: 0.6911 - val_loss: 0.6201 - val_accuracy: 0.6475\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5904 - accuracy: 0.6913 - val_loss: 0.6158 - val_accuracy: 0.6504\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5875 - accuracy: 0.6932 - val_loss: 0.6203 - val_accuracy: 0.6465\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5853 - accuracy: 0.6931 - val_loss: 0.6107 - val_accuracy: 0.6545\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5843 - accuracy: 0.6939 - val_loss: 0.6197 - val_accuracy: 0.6455\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5827 - accuracy: 0.6970 - val_loss: 0.6156 - val_accuracy: 0.6493\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5820 - accuracy: 0.6951 - val_loss: 0.6168 - val_accuracy: 0.6482\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5790 - accuracy: 0.6999 - val_loss: 0.6116 - val_accuracy: 0.6520\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5779 - accuracy: 0.7000 - val_loss: 0.6139 - val_accuracy: 0.6490\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5767 - accuracy: 0.7020 - val_loss: 0.6118 - val_accuracy: 0.6496\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5754 - accuracy: 0.7019 - val_loss: 0.6146 - val_accuracy: 0.6462\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5749 - accuracy: 0.7019 - val_loss: 0.6145 - val_accuracy: 0.6459\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.5729 - accuracy: 0.7037 - val_loss: 0.6094 - val_accuracy: 0.6511\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5711 - accuracy: 0.7044 - val_loss: 0.6066 - val_accuracy: 0.6525\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.5710 - accuracy: 0.7064 - val_loss: 0.6094 - val_accuracy: 0.6491\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.5691 - accuracy: 0.7049 - val_loss: 0.6132 - val_accuracy: 0.6449\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 998us/step - loss: 0.7149 - accuracy: 0.4816 - val_loss: 0.6350 - val_accuracy: 0.8704\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 841us/step - loss: 0.6966 - accuracy: 0.4988 - val_loss: 0.6706 - val_accuracy: 0.7678\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6900 - accuracy: 0.5277 - val_loss: 0.6863 - val_accuracy: 0.5789\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6864 - accuracy: 0.5515 - val_loss: 0.6944 - val_accuracy: 0.5017\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6834 - accuracy: 0.5673 - val_loss: 0.6985 - val_accuracy: 0.4834\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 814us/step - loss: 0.6804 - accuracy: 0.5750 - val_loss: 0.7001 - val_accuracy: 0.4900\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6771 - accuracy: 0.5860 - val_loss: 0.6983 - val_accuracy: 0.5144\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6742 - accuracy: 0.5948 - val_loss: 0.6962 - val_accuracy: 0.5320\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6714 - accuracy: 0.6031 - val_loss: 0.6949 - val_accuracy: 0.5404\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.6687 - accuracy: 0.6084 - val_loss: 0.6921 - val_accuracy: 0.5568\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6664 - accuracy: 0.6150 - val_loss: 0.6913 - val_accuracy: 0.5640\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6644 - accuracy: 0.6179 - val_loss: 0.6895 - val_accuracy: 0.5707\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.6619 - accuracy: 0.6195 - val_loss: 0.6871 - val_accuracy: 0.5821\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6595 - accuracy: 0.6264 - val_loss: 0.6884 - val_accuracy: 0.5730\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.6575 - accuracy: 0.6294 - val_loss: 0.6843 - val_accuracy: 0.5876\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6550 - accuracy: 0.6331 - val_loss: 0.6845 - val_accuracy: 0.5843\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.6532 - accuracy: 0.6344 - val_loss: 0.6805 - val_accuracy: 0.5969\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6517 - accuracy: 0.6367 - val_loss: 0.6776 - val_accuracy: 0.6038\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6493 - accuracy: 0.6427 - val_loss: 0.6780 - val_accuracy: 0.5962\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.6476 - accuracy: 0.6402 - val_loss: 0.6771 - val_accuracy: 0.5973\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6455 - accuracy: 0.6455 - val_loss: 0.6734 - val_accuracy: 0.6064\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6431 - accuracy: 0.6465 - val_loss: 0.6728 - val_accuracy: 0.6060\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6411 - accuracy: 0.6488 - val_loss: 0.6724 - val_accuracy: 0.6070\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6384 - accuracy: 0.6539 - val_loss: 0.6705 - val_accuracy: 0.6110\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 793us/step - loss: 0.6360 - accuracy: 0.6537 - val_loss: 0.6713 - val_accuracy: 0.6075\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6326 - accuracy: 0.6577 - val_loss: 0.6669 - val_accuracy: 0.6134\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6297 - accuracy: 0.6599 - val_loss: 0.6634 - val_accuracy: 0.6179\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6272 - accuracy: 0.6628 - val_loss: 0.6606 - val_accuracy: 0.6209\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6250 - accuracy: 0.6666 - val_loss: 0.6588 - val_accuracy: 0.6234\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6231 - accuracy: 0.6672 - val_loss: 0.6564 - val_accuracy: 0.6259\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6214 - accuracy: 0.6664 - val_loss: 0.6527 - val_accuracy: 0.6309\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6196 - accuracy: 0.6700 - val_loss: 0.6513 - val_accuracy: 0.6321\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6175 - accuracy: 0.6695 - val_loss: 0.6495 - val_accuracy: 0.6337\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.6160 - accuracy: 0.6701 - val_loss: 0.6492 - val_accuracy: 0.6331\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6140 - accuracy: 0.6731 - val_loss: 0.6469 - val_accuracy: 0.6361\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.6121 - accuracy: 0.6742 - val_loss: 0.6412 - val_accuracy: 0.6445\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6099 - accuracy: 0.6760 - val_loss: 0.6420 - val_accuracy: 0.6419\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6087 - accuracy: 0.6762 - val_loss: 0.6411 - val_accuracy: 0.6429\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.6069 - accuracy: 0.6795 - val_loss: 0.6431 - val_accuracy: 0.6374\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6052 - accuracy: 0.6769 - val_loss: 0.6350 - val_accuracy: 0.6499\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.6035 - accuracy: 0.6785 - val_loss: 0.6363 - val_accuracy: 0.6474\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6021 - accuracy: 0.6820 - val_loss: 0.6376 - val_accuracy: 0.6453\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6010 - accuracy: 0.6820 - val_loss: 0.6353 - val_accuracy: 0.6482\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5982 - accuracy: 0.6853 - val_loss: 0.6328 - val_accuracy: 0.6509\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5974 - accuracy: 0.6855 - val_loss: 0.6318 - val_accuracy: 0.6521\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.5950 - accuracy: 0.6852 - val_loss: 0.6298 - val_accuracy: 0.6535\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5939 - accuracy: 0.6865 - val_loss: 0.6252 - val_accuracy: 0.6577\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5931 - accuracy: 0.6892 - val_loss: 0.6282 - val_accuracy: 0.6535\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.5908 - accuracy: 0.6914 - val_loss: 0.6263 - val_accuracy: 0.6552\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5899 - accuracy: 0.6908 - val_loss: 0.6318 - val_accuracy: 0.6460\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.7107 - accuracy: 0.5427 - val_loss: 0.7086 - val_accuracy: 0.4642\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6900 - accuracy: 0.5607 - val_loss: 0.6853 - val_accuracy: 0.5490\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6793 - accuracy: 0.5771 - val_loss: 0.6890 - val_accuracy: 0.5425\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6684 - accuracy: 0.5972 - val_loss: 0.6711 - val_accuracy: 0.5902\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6593 - accuracy: 0.6123 - val_loss: 0.6699 - val_accuracy: 0.5946\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6522 - accuracy: 0.6255 - val_loss: 0.6607 - val_accuracy: 0.6153\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.6466 - accuracy: 0.6333 - val_loss: 0.6558 - val_accuracy: 0.6213\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 719us/step - loss: 0.6418 - accuracy: 0.6425 - val_loss: 0.6567 - val_accuracy: 0.6173\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6382 - accuracy: 0.6486 - val_loss: 0.6601 - val_accuracy: 0.6085\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6336 - accuracy: 0.6524 - val_loss: 0.6507 - val_accuracy: 0.6261\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6282 - accuracy: 0.6602 - val_loss: 0.6487 - val_accuracy: 0.6266\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6243 - accuracy: 0.6660 - val_loss: 0.6459 - val_accuracy: 0.6291\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6209 - accuracy: 0.6680 - val_loss: 0.6402 - val_accuracy: 0.6345\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6190 - accuracy: 0.6748 - val_loss: 0.6393 - val_accuracy: 0.6345\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6152 - accuracy: 0.6747 - val_loss: 0.6364 - val_accuracy: 0.6363\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6124 - accuracy: 0.6773 - val_loss: 0.6324 - val_accuracy: 0.6406\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6117 - accuracy: 0.6781 - val_loss: 0.6369 - val_accuracy: 0.6352\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6087 - accuracy: 0.6824 - val_loss: 0.6304 - val_accuracy: 0.6414\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6056 - accuracy: 0.6847 - val_loss: 0.6318 - val_accuracy: 0.6380\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6042 - accuracy: 0.6860 - val_loss: 0.6308 - val_accuracy: 0.6382\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6021 - accuracy: 0.6876 - val_loss: 0.6264 - val_accuracy: 0.6426\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6004 - accuracy: 0.6877 - val_loss: 0.6267 - val_accuracy: 0.6425\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5980 - accuracy: 0.6905 - val_loss: 0.6261 - val_accuracy: 0.6431\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5961 - accuracy: 0.6909 - val_loss: 0.6213 - val_accuracy: 0.6471\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.5946 - accuracy: 0.6928 - val_loss: 0.6271 - val_accuracy: 0.6419\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5920 - accuracy: 0.6966 - val_loss: 0.6296 - val_accuracy: 0.6387\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5909 - accuracy: 0.6962 - val_loss: 0.6261 - val_accuracy: 0.6420\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5889 - accuracy: 0.6982 - val_loss: 0.6225 - val_accuracy: 0.6468\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5875 - accuracy: 0.6986 - val_loss: 0.6224 - val_accuracy: 0.6462\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5871 - accuracy: 0.6970 - val_loss: 0.6187 - val_accuracy: 0.6504\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5851 - accuracy: 0.6997 - val_loss: 0.6207 - val_accuracy: 0.6475\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5819 - accuracy: 0.7042 - val_loss: 0.6249 - val_accuracy: 0.6427\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5820 - accuracy: 0.7029 - val_loss: 0.6100 - val_accuracy: 0.6604\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5808 - accuracy: 0.7028 - val_loss: 0.6160 - val_accuracy: 0.6545\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5785 - accuracy: 0.7045 - val_loss: 0.6145 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5774 - accuracy: 0.7057 - val_loss: 0.6159 - val_accuracy: 0.6535\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5770 - accuracy: 0.7068 - val_loss: 0.6188 - val_accuracy: 0.6499\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 805us/step - loss: 0.5753 - accuracy: 0.7068 - val_loss: 0.6139 - val_accuracy: 0.6539\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5735 - accuracy: 0.7076 - val_loss: 0.6143 - val_accuracy: 0.6531\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 792us/step - loss: 0.5742 - accuracy: 0.7069 - val_loss: 0.6066 - val_accuracy: 0.6586\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5723 - accuracy: 0.7085 - val_loss: 0.6207 - val_accuracy: 0.6472\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.5706 - accuracy: 0.7098 - val_loss: 0.6060 - val_accuracy: 0.6591\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.5692 - accuracy: 0.7113 - val_loss: 0.6154 - val_accuracy: 0.6509\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5679 - accuracy: 0.7119 - val_loss: 0.6133 - val_accuracy: 0.6522\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 800us/step - loss: 0.5675 - accuracy: 0.7119 - val_loss: 0.6088 - val_accuracy: 0.6560\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5659 - accuracy: 0.7157 - val_loss: 0.6112 - val_accuracy: 0.6540\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 803us/step - loss: 0.5647 - accuracy: 0.7132 - val_loss: 0.6177 - val_accuracy: 0.6483\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5643 - accuracy: 0.7130 - val_loss: 0.6115 - val_accuracy: 0.6537\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 775us/step - loss: 0.5629 - accuracy: 0.7156 - val_loss: 0.6158 - val_accuracy: 0.6503\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5632 - accuracy: 0.7139 - val_loss: 0.6024 - val_accuracy: 0.6601\n",
      "Epoch 1/50\n",
      "1615/1672 [===========================>..] - ETA: 0s - loss: 0.6928 - accuracy: 0.5346WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.6927 - accuracy: 0.5348 - val_loss: 0.7115 - val_accuracy: 0.4298\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6807 - accuracy: 0.5651 - val_loss: 0.7008 - val_accuracy: 0.4692\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.6726 - accuracy: 0.5875 - val_loss: 0.6928 - val_accuracy: 0.4981\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6655 - accuracy: 0.5994 - val_loss: 0.6925 - val_accuracy: 0.5093\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 814us/step - loss: 0.6590 - accuracy: 0.6114 - val_loss: 0.6820 - val_accuracy: 0.5328\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6541 - accuracy: 0.6193 - val_loss: 0.6802 - val_accuracy: 0.5361\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.6500 - accuracy: 0.6262 - val_loss: 0.6670 - val_accuracy: 0.5601\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6455 - accuracy: 0.6321 - val_loss: 0.6661 - val_accuracy: 0.5604\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.6414 - accuracy: 0.6354 - val_loss: 0.6647 - val_accuracy: 0.5645\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6373 - accuracy: 0.6420 - val_loss: 0.6589 - val_accuracy: 0.5768\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.6346 - accuracy: 0.6450 - val_loss: 0.6606 - val_accuracy: 0.5748\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6314 - accuracy: 0.6489 - val_loss: 0.6547 - val_accuracy: 0.5887\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 826us/step - loss: 0.6279 - accuracy: 0.6525 - val_loss: 0.6564 - val_accuracy: 0.5871\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6248 - accuracy: 0.6565 - val_loss: 0.6507 - val_accuracy: 0.5976\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 807us/step - loss: 0.6229 - accuracy: 0.6564 - val_loss: 0.6481 - val_accuracy: 0.6016\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6207 - accuracy: 0.6604 - val_loss: 0.6444 - val_accuracy: 0.6080\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.6188 - accuracy: 0.6627 - val_loss: 0.6412 - val_accuracy: 0.6117\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6154 - accuracy: 0.6670 - val_loss: 0.6420 - val_accuracy: 0.6116\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6137 - accuracy: 0.6682 - val_loss: 0.6422 - val_accuracy: 0.6101\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.6121 - accuracy: 0.6696 - val_loss: 0.6380 - val_accuracy: 0.6136\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6101 - accuracy: 0.6714 - val_loss: 0.6318 - val_accuracy: 0.6222\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.6073 - accuracy: 0.6744 - val_loss: 0.6335 - val_accuracy: 0.6185\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6050 - accuracy: 0.6773 - val_loss: 0.6336 - val_accuracy: 0.6172\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.6036 - accuracy: 0.6768 - val_loss: 0.6392 - val_accuracy: 0.6095\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6018 - accuracy: 0.6797 - val_loss: 0.6348 - val_accuracy: 0.6138\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.5998 - accuracy: 0.6815 - val_loss: 0.6319 - val_accuracy: 0.6173\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5975 - accuracy: 0.6839 - val_loss: 0.6270 - val_accuracy: 0.6231\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.5968 - accuracy: 0.6836 - val_loss: 0.6260 - val_accuracy: 0.6234\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5952 - accuracy: 0.6840 - val_loss: 0.6264 - val_accuracy: 0.6228\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5925 - accuracy: 0.6884 - val_loss: 0.6211 - val_accuracy: 0.6293\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.5919 - accuracy: 0.6903 - val_loss: 0.6276 - val_accuracy: 0.6205\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5906 - accuracy: 0.6889 - val_loss: 0.6213 - val_accuracy: 0.6289\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 912us/step - loss: 0.5885 - accuracy: 0.6925 - val_loss: 0.6203 - val_accuracy: 0.6307\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5871 - accuracy: 0.6914 - val_loss: 0.6236 - val_accuracy: 0.6246\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 795us/step - loss: 0.5860 - accuracy: 0.6937 - val_loss: 0.6220 - val_accuracy: 0.6261\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5848 - accuracy: 0.6946 - val_loss: 0.6258 - val_accuracy: 0.6217\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.5827 - accuracy: 0.6957 - val_loss: 0.6110 - val_accuracy: 0.6380\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5822 - accuracy: 0.6969 - val_loss: 0.6213 - val_accuracy: 0.6261\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5815 - accuracy: 0.6979 - val_loss: 0.6190 - val_accuracy: 0.6278\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5787 - accuracy: 0.6982 - val_loss: 0.6187 - val_accuracy: 0.6268\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5786 - accuracy: 0.6977 - val_loss: 0.6081 - val_accuracy: 0.6398\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.5762 - accuracy: 0.7007 - val_loss: 0.6125 - val_accuracy: 0.6337\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5757 - accuracy: 0.7008 - val_loss: 0.6202 - val_accuracy: 0.6247\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 821us/step - loss: 0.5743 - accuracy: 0.7030 - val_loss: 0.6183 - val_accuracy: 0.6261\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5736 - accuracy: 0.7020 - val_loss: 0.6133 - val_accuracy: 0.6315\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.5723 - accuracy: 0.7036 - val_loss: 0.6120 - val_accuracy: 0.6333\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 784us/step - loss: 0.5701 - accuracy: 0.7043 - val_loss: 0.6127 - val_accuracy: 0.6321\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.5707 - accuracy: 0.7036 - val_loss: 0.6147 - val_accuracy: 0.6308\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.5684 - accuracy: 0.7074 - val_loss: 0.6126 - val_accuracy: 0.6336\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.5679 - accuracy: 0.7058 - val_loss: 0.6163 - val_accuracy: 0.6300\n",
      "\n",
      "Training model with batch_size=64...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.1 iterated over 41800 steps satisfies differential privacy with eps = 1.42 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.7282 - accuracy: 0.5218 - val_loss: 0.8262 - val_accuracy: 0.1204\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.7001 - accuracy: 0.5244 - val_loss: 0.7510 - val_accuracy: 0.2150\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6940 - accuracy: 0.5324 - val_loss: 0.7245 - val_accuracy: 0.3493\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 708us/step - loss: 0.6910 - accuracy: 0.5360 - val_loss: 0.7120 - val_accuracy: 0.4041\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6881 - accuracy: 0.5438 - val_loss: 0.7079 - val_accuracy: 0.4215\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6861 - accuracy: 0.5490 - val_loss: 0.7046 - val_accuracy: 0.4407\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.6838 - accuracy: 0.5556 - val_loss: 0.7016 - val_accuracy: 0.4573\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.6808 - accuracy: 0.5588 - val_loss: 0.6976 - val_accuracy: 0.4767\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.6776 - accuracy: 0.5691 - val_loss: 0.6948 - val_accuracy: 0.4944\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.6757 - accuracy: 0.5741 - val_loss: 0.6929 - val_accuracy: 0.5043\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.6727 - accuracy: 0.5831 - val_loss: 0.6910 - val_accuracy: 0.5116\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6712 - accuracy: 0.5833 - val_loss: 0.6882 - val_accuracy: 0.5203\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6693 - accuracy: 0.5869 - val_loss: 0.6872 - val_accuracy: 0.5216\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6664 - accuracy: 0.5954 - val_loss: 0.6844 - val_accuracy: 0.5286\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 647us/step - loss: 0.6659 - accuracy: 0.5971 - val_loss: 0.6832 - val_accuracy: 0.5321\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6618 - accuracy: 0.6064 - val_loss: 0.6804 - val_accuracy: 0.5402\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6603 - accuracy: 0.6085 - val_loss: 0.6785 - val_accuracy: 0.5475\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6593 - accuracy: 0.6099 - val_loss: 0.6768 - val_accuracy: 0.5516\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6566 - accuracy: 0.6185 - val_loss: 0.6740 - val_accuracy: 0.5598\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6555 - accuracy: 0.6161 - val_loss: 0.6732 - val_accuracy: 0.5618\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6532 - accuracy: 0.6224 - val_loss: 0.6712 - val_accuracy: 0.5673\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.6513 - accuracy: 0.6259 - val_loss: 0.6687 - val_accuracy: 0.5733\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 672us/step - loss: 0.6499 - accuracy: 0.6289 - val_loss: 0.6675 - val_accuracy: 0.5750\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6482 - accuracy: 0.6298 - val_loss: 0.6661 - val_accuracy: 0.5786\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 667us/step - loss: 0.6451 - accuracy: 0.6362 - val_loss: 0.6635 - val_accuracy: 0.5865\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6447 - accuracy: 0.6353 - val_loss: 0.6620 - val_accuracy: 0.5905\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 698us/step - loss: 0.6427 - accuracy: 0.6387 - val_loss: 0.6615 - val_accuracy: 0.5917\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 671us/step - loss: 0.6416 - accuracy: 0.6394 - val_loss: 0.6588 - val_accuracy: 0.5974\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6399 - accuracy: 0.6422 - val_loss: 0.6568 - val_accuracy: 0.6006\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.6379 - accuracy: 0.6436 - val_loss: 0.6550 - val_accuracy: 0.6032\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6373 - accuracy: 0.6443 - val_loss: 0.6541 - val_accuracy: 0.6044\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 681us/step - loss: 0.6350 - accuracy: 0.6488 - val_loss: 0.6537 - val_accuracy: 0.6039\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6342 - accuracy: 0.6477 - val_loss: 0.6509 - val_accuracy: 0.6083\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.6322 - accuracy: 0.6532 - val_loss: 0.6497 - val_accuracy: 0.6098\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 629us/step - loss: 0.6313 - accuracy: 0.6525 - val_loss: 0.6484 - val_accuracy: 0.6117\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6306 - accuracy: 0.6531 - val_loss: 0.6473 - val_accuracy: 0.6134\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6294 - accuracy: 0.6539 - val_loss: 0.6468 - val_accuracy: 0.6145\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6276 - accuracy: 0.6562 - val_loss: 0.6448 - val_accuracy: 0.6166\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.6265 - accuracy: 0.6576 - val_loss: 0.6438 - val_accuracy: 0.6177\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6261 - accuracy: 0.6588 - val_loss: 0.6430 - val_accuracy: 0.6190\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6245 - accuracy: 0.6606 - val_loss: 0.6418 - val_accuracy: 0.6210\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6221 - accuracy: 0.6622 - val_loss: 0.6407 - val_accuracy: 0.6225\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 616us/step - loss: 0.6228 - accuracy: 0.6611 - val_loss: 0.6389 - val_accuracy: 0.6247\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6219 - accuracy: 0.6615 - val_loss: 0.6381 - val_accuracy: 0.6259\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.6198 - accuracy: 0.6679 - val_loss: 0.6376 - val_accuracy: 0.6279\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 670us/step - loss: 0.6189 - accuracy: 0.6647 - val_loss: 0.6371 - val_accuracy: 0.6292\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.6182 - accuracy: 0.6675 - val_loss: 0.6371 - val_accuracy: 0.6287\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6173 - accuracy: 0.6679 - val_loss: 0.6360 - val_accuracy: 0.6310\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6162 - accuracy: 0.6700 - val_loss: 0.6338 - val_accuracy: 0.6340\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6142 - accuracy: 0.6698 - val_loss: 0.6337 - val_accuracy: 0.6335\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.7319 - accuracy: 0.4950 - val_loss: 0.6166 - val_accuracy: 0.8663\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.6942 - accuracy: 0.5290 - val_loss: 0.6769 - val_accuracy: 0.6321\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6888 - accuracy: 0.5415 - val_loss: 0.6950 - val_accuracy: 0.4919\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6861 - accuracy: 0.5546 - val_loss: 0.6973 - val_accuracy: 0.4810\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 629us/step - loss: 0.6835 - accuracy: 0.5578 - val_loss: 0.6966 - val_accuracy: 0.4876\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6805 - accuracy: 0.5667 - val_loss: 0.6965 - val_accuracy: 0.4939\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6787 - accuracy: 0.5708 - val_loss: 0.6963 - val_accuracy: 0.5029\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6769 - accuracy: 0.5770 - val_loss: 0.6954 - val_accuracy: 0.5093\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 621us/step - loss: 0.6742 - accuracy: 0.5832 - val_loss: 0.6924 - val_accuracy: 0.5233\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.6720 - accuracy: 0.5883 - val_loss: 0.6930 - val_accuracy: 0.5224\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6703 - accuracy: 0.5911 - val_loss: 0.6881 - val_accuracy: 0.5437\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 629us/step - loss: 0.6691 - accuracy: 0.5975 - val_loss: 0.6872 - val_accuracy: 0.5454\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 619us/step - loss: 0.6673 - accuracy: 0.5993 - val_loss: 0.6843 - val_accuracy: 0.5540\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6655 - accuracy: 0.6034 - val_loss: 0.6844 - val_accuracy: 0.5531\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 711us/step - loss: 0.6636 - accuracy: 0.6085 - val_loss: 0.6835 - val_accuracy: 0.5579\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6609 - accuracy: 0.6137 - val_loss: 0.6799 - val_accuracy: 0.5727\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 647us/step - loss: 0.6605 - accuracy: 0.6158 - val_loss: 0.6802 - val_accuracy: 0.5712\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.6580 - accuracy: 0.6201 - val_loss: 0.6800 - val_accuracy: 0.5702\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6569 - accuracy: 0.6205 - val_loss: 0.6761 - val_accuracy: 0.5814\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.6563 - accuracy: 0.6203 - val_loss: 0.6755 - val_accuracy: 0.5816\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 668us/step - loss: 0.6543 - accuracy: 0.6258 - val_loss: 0.6738 - val_accuracy: 0.5842\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6519 - accuracy: 0.6314 - val_loss: 0.6723 - val_accuracy: 0.5855\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6509 - accuracy: 0.6313 - val_loss: 0.6729 - val_accuracy: 0.5826\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6491 - accuracy: 0.6370 - val_loss: 0.6702 - val_accuracy: 0.5893\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6478 - accuracy: 0.6354 - val_loss: 0.6680 - val_accuracy: 0.5935\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6456 - accuracy: 0.6401 - val_loss: 0.6684 - val_accuracy: 0.5921\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.6452 - accuracy: 0.6394 - val_loss: 0.6670 - val_accuracy: 0.5942\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6442 - accuracy: 0.6424 - val_loss: 0.6674 - val_accuracy: 0.5924\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.6432 - accuracy: 0.6435 - val_loss: 0.6643 - val_accuracy: 0.5975\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 620us/step - loss: 0.6409 - accuracy: 0.6470 - val_loss: 0.6638 - val_accuracy: 0.5979\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.6390 - accuracy: 0.6503 - val_loss: 0.6605 - val_accuracy: 0.6039\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6383 - accuracy: 0.6497 - val_loss: 0.6600 - val_accuracy: 0.6041\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.6377 - accuracy: 0.6518 - val_loss: 0.6599 - val_accuracy: 0.6030\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 664us/step - loss: 0.6348 - accuracy: 0.6552 - val_loss: 0.6587 - val_accuracy: 0.6037\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6344 - accuracy: 0.6533 - val_loss: 0.6572 - val_accuracy: 0.6039\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6328 - accuracy: 0.6561 - val_loss: 0.6555 - val_accuracy: 0.6046\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.6312 - accuracy: 0.6573 - val_loss: 0.6569 - val_accuracy: 0.6007\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 717us/step - loss: 0.6307 - accuracy: 0.6582 - val_loss: 0.6554 - val_accuracy: 0.6013\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6295 - accuracy: 0.6578 - val_loss: 0.6545 - val_accuracy: 0.6017\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6273 - accuracy: 0.6633 - val_loss: 0.6549 - val_accuracy: 0.6009\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6259 - accuracy: 0.6642 - val_loss: 0.6531 - val_accuracy: 0.6011\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6248 - accuracy: 0.6640 - val_loss: 0.6513 - val_accuracy: 0.6029\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6241 - accuracy: 0.6639 - val_loss: 0.6510 - val_accuracy: 0.6026\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.6218 - accuracy: 0.6679 - val_loss: 0.6497 - val_accuracy: 0.6035\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6213 - accuracy: 0.6670 - val_loss: 0.6491 - val_accuracy: 0.6040\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 701us/step - loss: 0.6202 - accuracy: 0.6685 - val_loss: 0.6457 - val_accuracy: 0.6070\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.6194 - accuracy: 0.6675 - val_loss: 0.6455 - val_accuracy: 0.6071\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 605us/step - loss: 0.6178 - accuracy: 0.6706 - val_loss: 0.6452 - val_accuracy: 0.6074\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 607us/step - loss: 0.6168 - accuracy: 0.6712 - val_loss: 0.6431 - val_accuracy: 0.6100\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6146 - accuracy: 0.6736 - val_loss: 0.6424 - val_accuracy: 0.6104\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.7124 - accuracy: 0.5009 - val_loss: 0.7072 - val_accuracy: 0.4458\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.7082 - accuracy: 0.5132 - val_loss: 0.7065 - val_accuracy: 0.4489\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.7057 - accuracy: 0.5165 - val_loss: 0.7055 - val_accuracy: 0.4513\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.7022 - accuracy: 0.5240 - val_loss: 0.7054 - val_accuracy: 0.4512\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.6966 - accuracy: 0.5339 - val_loss: 0.7028 - val_accuracy: 0.4678\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.6940 - accuracy: 0.5386 - val_loss: 0.7015 - val_accuracy: 0.4816\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6918 - accuracy: 0.5406 - val_loss: 0.6967 - val_accuracy: 0.5235\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6879 - accuracy: 0.5504 - val_loss: 0.6935 - val_accuracy: 0.5438\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6869 - accuracy: 0.5549 - val_loss: 0.6903 - val_accuracy: 0.5583\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.6844 - accuracy: 0.5568 - val_loss: 0.6903 - val_accuracy: 0.5610\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6834 - accuracy: 0.5575 - val_loss: 0.6891 - val_accuracy: 0.5663\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6816 - accuracy: 0.5636 - val_loss: 0.6868 - val_accuracy: 0.5793\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.6797 - accuracy: 0.5683 - val_loss: 0.6864 - val_accuracy: 0.5820\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.6775 - accuracy: 0.5699 - val_loss: 0.6850 - val_accuracy: 0.5874\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 721us/step - loss: 0.6756 - accuracy: 0.5762 - val_loss: 0.6835 - val_accuracy: 0.5925\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6721 - accuracy: 0.5822 - val_loss: 0.6841 - val_accuracy: 0.5841\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.6725 - accuracy: 0.5840 - val_loss: 0.6829 - val_accuracy: 0.5871\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.6715 - accuracy: 0.5853 - val_loss: 0.6817 - val_accuracy: 0.5889\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6694 - accuracy: 0.5911 - val_loss: 0.6810 - val_accuracy: 0.5897\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 954us/step - loss: 0.6670 - accuracy: 0.5957 - val_loss: 0.6812 - val_accuracy: 0.5868\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 717us/step - loss: 0.6646 - accuracy: 0.5992 - val_loss: 0.6798 - val_accuracy: 0.5914\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6629 - accuracy: 0.6023 - val_loss: 0.6794 - val_accuracy: 0.5910\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6602 - accuracy: 0.6039 - val_loss: 0.6758 - val_accuracy: 0.6013\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6589 - accuracy: 0.6089 - val_loss: 0.6728 - val_accuracy: 0.6081\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6565 - accuracy: 0.6112 - val_loss: 0.6729 - val_accuracy: 0.6029\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 685us/step - loss: 0.6534 - accuracy: 0.6174 - val_loss: 0.6691 - val_accuracy: 0.6134\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 902us/step - loss: 0.6528 - accuracy: 0.6152 - val_loss: 0.6681 - val_accuracy: 0.6133\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 745us/step - loss: 0.6507 - accuracy: 0.6210 - val_loss: 0.6662 - val_accuracy: 0.6157\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6489 - accuracy: 0.6231 - val_loss: 0.6631 - val_accuracy: 0.6208\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 599us/step - loss: 0.6476 - accuracy: 0.6235 - val_loss: 0.6626 - val_accuracy: 0.6192\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 949us/step - loss: 0.6467 - accuracy: 0.6246 - val_loss: 0.6620 - val_accuracy: 0.6189\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 801us/step - loss: 0.6439 - accuracy: 0.6286 - val_loss: 0.6596 - val_accuracy: 0.6237\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 618us/step - loss: 0.6425 - accuracy: 0.6322 - val_loss: 0.6583 - val_accuracy: 0.6256\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.6399 - accuracy: 0.6348 - val_loss: 0.6565 - val_accuracy: 0.6273\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6393 - accuracy: 0.6363 - val_loss: 0.6561 - val_accuracy: 0.6271\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 717us/step - loss: 0.6382 - accuracy: 0.6345 - val_loss: 0.6533 - val_accuracy: 0.6321\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 599us/step - loss: 0.6361 - accuracy: 0.6380 - val_loss: 0.6531 - val_accuracy: 0.6310\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6354 - accuracy: 0.6396 - val_loss: 0.6499 - val_accuracy: 0.6373\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.6343 - accuracy: 0.6434 - val_loss: 0.6493 - val_accuracy: 0.6372\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6317 - accuracy: 0.6430 - val_loss: 0.6460 - val_accuracy: 0.6418\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 595us/step - loss: 0.6296 - accuracy: 0.6469 - val_loss: 0.6462 - val_accuracy: 0.6403\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 942us/step - loss: 0.6287 - accuracy: 0.6472 - val_loss: 0.6434 - val_accuracy: 0.6449\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6269 - accuracy: 0.6500 - val_loss: 0.6438 - val_accuracy: 0.6433\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.6255 - accuracy: 0.6502 - val_loss: 0.6449 - val_accuracy: 0.6401\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6237 - accuracy: 0.6525 - val_loss: 0.6413 - val_accuracy: 0.6462\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6234 - accuracy: 0.6512 - val_loss: 0.6387 - val_accuracy: 0.6497\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6225 - accuracy: 0.6529 - val_loss: 0.6399 - val_accuracy: 0.6465\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.6203 - accuracy: 0.6554 - val_loss: 0.6385 - val_accuracy: 0.6475\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6184 - accuracy: 0.6544 - val_loss: 0.6388 - val_accuracy: 0.6454\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 955us/step - loss: 0.6176 - accuracy: 0.6549 - val_loss: 0.6363 - val_accuracy: 0.6490\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 806us/step - loss: 0.7481 - accuracy: 0.4595 - val_loss: 0.7508 - val_accuracy: 0.2529\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 605us/step - loss: 0.7401 - accuracy: 0.4625 - val_loss: 0.7429 - val_accuracy: 0.2685\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 954us/step - loss: 0.7360 - accuracy: 0.4627 - val_loss: 0.7413 - val_accuracy: 0.2633\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.7295 - accuracy: 0.4711 - val_loss: 0.7338 - val_accuracy: 0.2861\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.7263 - accuracy: 0.4770 - val_loss: 0.7310 - val_accuracy: 0.2922\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.7213 - accuracy: 0.4840 - val_loss: 0.7246 - val_accuracy: 0.3138\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 946us/step - loss: 0.7179 - accuracy: 0.4863 - val_loss: 0.7244 - val_accuracy: 0.3011\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.7141 - accuracy: 0.4915 - val_loss: 0.7210 - val_accuracy: 0.3139\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 600us/step - loss: 0.7114 - accuracy: 0.4963 - val_loss: 0.7178 - val_accuracy: 0.3301\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.7089 - accuracy: 0.5001 - val_loss: 0.7153 - val_accuracy: 0.3436\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.7060 - accuracy: 0.5058 - val_loss: 0.7144 - val_accuracy: 0.3595\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 608us/step - loss: 0.7027 - accuracy: 0.5127 - val_loss: 0.7100 - val_accuracy: 0.3959\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 957us/step - loss: 0.6998 - accuracy: 0.5199 - val_loss: 0.7088 - val_accuracy: 0.4111\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6985 - accuracy: 0.5244 - val_loss: 0.7092 - val_accuracy: 0.4158\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 617us/step - loss: 0.6963 - accuracy: 0.5289 - val_loss: 0.7066 - val_accuracy: 0.4386\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 607us/step - loss: 0.6933 - accuracy: 0.5336 - val_loss: 0.7029 - val_accuracy: 0.4637\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6900 - accuracy: 0.5443 - val_loss: 0.7013 - val_accuracy: 0.4759\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.6881 - accuracy: 0.5476 - val_loss: 0.7004 - val_accuracy: 0.4830\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 605us/step - loss: 0.6852 - accuracy: 0.5542 - val_loss: 0.6988 - val_accuracy: 0.4915\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6852 - accuracy: 0.5542 - val_loss: 0.6972 - val_accuracy: 0.4993\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6822 - accuracy: 0.5625 - val_loss: 0.6965 - val_accuracy: 0.5033\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 670us/step - loss: 0.6811 - accuracy: 0.5671 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.6782 - accuracy: 0.5720 - val_loss: 0.6917 - val_accuracy: 0.5214\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6776 - accuracy: 0.5762 - val_loss: 0.6892 - val_accuracy: 0.5271\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 985us/step - loss: 0.6757 - accuracy: 0.5798 - val_loss: 0.6880 - val_accuracy: 0.5316\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 685us/step - loss: 0.6729 - accuracy: 0.5843 - val_loss: 0.6860 - val_accuracy: 0.5359\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 683us/step - loss: 0.6720 - accuracy: 0.5882 - val_loss: 0.6826 - val_accuracy: 0.5442\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6693 - accuracy: 0.5921 - val_loss: 0.6817 - val_accuracy: 0.5458\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 969us/step - loss: 0.6671 - accuracy: 0.5963 - val_loss: 0.6772 - val_accuracy: 0.5594\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.6646 - accuracy: 0.6049 - val_loss: 0.6761 - val_accuracy: 0.5609\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.6621 - accuracy: 0.6082 - val_loss: 0.6746 - val_accuracy: 0.5670\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 601us/step - loss: 0.6601 - accuracy: 0.6135 - val_loss: 0.6738 - val_accuracy: 0.5707\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 948us/step - loss: 0.6588 - accuracy: 0.6128 - val_loss: 0.6709 - val_accuracy: 0.5800\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 790us/step - loss: 0.6565 - accuracy: 0.6191 - val_loss: 0.6681 - val_accuracy: 0.5860\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 691us/step - loss: 0.6547 - accuracy: 0.6226 - val_loss: 0.6669 - val_accuracy: 0.5883\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 601us/step - loss: 0.6540 - accuracy: 0.6235 - val_loss: 0.6657 - val_accuracy: 0.5907\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6523 - accuracy: 0.6262 - val_loss: 0.6648 - val_accuracy: 0.5915\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.6504 - accuracy: 0.6302 - val_loss: 0.6635 - val_accuracy: 0.5925\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 607us/step - loss: 0.6487 - accuracy: 0.6332 - val_loss: 0.6608 - val_accuracy: 0.5959\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6483 - accuracy: 0.6327 - val_loss: 0.6604 - val_accuracy: 0.5953\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6459 - accuracy: 0.6358 - val_loss: 0.6601 - val_accuracy: 0.5943\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.6446 - accuracy: 0.6374 - val_loss: 0.6578 - val_accuracy: 0.5971\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 603us/step - loss: 0.6429 - accuracy: 0.6414 - val_loss: 0.6579 - val_accuracy: 0.5965\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.6430 - accuracy: 0.6397 - val_loss: 0.6578 - val_accuracy: 0.5958\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 967us/step - loss: 0.6414 - accuracy: 0.6435 - val_loss: 0.6547 - val_accuracy: 0.5999\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6404 - accuracy: 0.6440 - val_loss: 0.6546 - val_accuracy: 0.5989\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.6393 - accuracy: 0.6460 - val_loss: 0.6504 - val_accuracy: 0.6049\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6377 - accuracy: 0.6486 - val_loss: 0.6513 - val_accuracy: 0.6027\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 967us/step - loss: 0.6378 - accuracy: 0.6462 - val_loss: 0.6507 - val_accuracy: 0.6029\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6357 - accuracy: 0.6517 - val_loss: 0.6485 - val_accuracy: 0.6052\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.7654 - accuracy: 0.4767 - val_loss: 0.6277 - val_accuracy: 0.8201\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 937us/step - loss: 0.7107 - accuracy: 0.4961 - val_loss: 0.6883 - val_accuracy: 0.5415\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 881us/step - loss: 0.7014 - accuracy: 0.5127 - val_loss: 0.7035 - val_accuracy: 0.4369\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6971 - accuracy: 0.5245 - val_loss: 0.7076 - val_accuracy: 0.4114\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6926 - accuracy: 0.5367 - val_loss: 0.7065 - val_accuracy: 0.4214\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 877us/step - loss: 0.6892 - accuracy: 0.5436 - val_loss: 0.7039 - val_accuracy: 0.4495\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.6858 - accuracy: 0.5524 - val_loss: 0.7023 - val_accuracy: 0.4610\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 607us/step - loss: 0.6836 - accuracy: 0.5605 - val_loss: 0.7001 - val_accuracy: 0.4814\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.6807 - accuracy: 0.5670 - val_loss: 0.6983 - val_accuracy: 0.4939\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6778 - accuracy: 0.5751 - val_loss: 0.6973 - val_accuracy: 0.5037\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 682us/step - loss: 0.6767 - accuracy: 0.5802 - val_loss: 0.6950 - val_accuracy: 0.5153\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6748 - accuracy: 0.5830 - val_loss: 0.6925 - val_accuracy: 0.5314\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6725 - accuracy: 0.5894 - val_loss: 0.6923 - val_accuracy: 0.5328\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6713 - accuracy: 0.5915 - val_loss: 0.6885 - val_accuracy: 0.5483\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6694 - accuracy: 0.5956 - val_loss: 0.6862 - val_accuracy: 0.5539\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6672 - accuracy: 0.6018 - val_loss: 0.6847 - val_accuracy: 0.5579\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6661 - accuracy: 0.6032 - val_loss: 0.6829 - val_accuracy: 0.5621\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6631 - accuracy: 0.6101 - val_loss: 0.6823 - val_accuracy: 0.5609\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.6616 - accuracy: 0.6143 - val_loss: 0.6808 - val_accuracy: 0.5644\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6607 - accuracy: 0.6153 - val_loss: 0.6793 - val_accuracy: 0.5666\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.6582 - accuracy: 0.6206 - val_loss: 0.6782 - val_accuracy: 0.5676\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6569 - accuracy: 0.6207 - val_loss: 0.6779 - val_accuracy: 0.5661\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.6568 - accuracy: 0.6231 - val_loss: 0.6766 - val_accuracy: 0.5685\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6530 - accuracy: 0.6255 - val_loss: 0.6757 - val_accuracy: 0.5703\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6525 - accuracy: 0.6283 - val_loss: 0.6743 - val_accuracy: 0.5726\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6513 - accuracy: 0.6311 - val_loss: 0.6716 - val_accuracy: 0.5786\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.6500 - accuracy: 0.6326 - val_loss: 0.6708 - val_accuracy: 0.5783\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6477 - accuracy: 0.6405 - val_loss: 0.6700 - val_accuracy: 0.5808\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6467 - accuracy: 0.6368 - val_loss: 0.6682 - val_accuracy: 0.5838\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6467 - accuracy: 0.6397 - val_loss: 0.6679 - val_accuracy: 0.5832\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6440 - accuracy: 0.6425 - val_loss: 0.6669 - val_accuracy: 0.5835\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.6426 - accuracy: 0.6433 - val_loss: 0.6657 - val_accuracy: 0.5855\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 667us/step - loss: 0.6411 - accuracy: 0.6454 - val_loss: 0.6635 - val_accuracy: 0.5902\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6409 - accuracy: 0.6474 - val_loss: 0.6634 - val_accuracy: 0.5886\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6379 - accuracy: 0.6502 - val_loss: 0.6623 - val_accuracy: 0.5897\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.6367 - accuracy: 0.6518 - val_loss: 0.6609 - val_accuracy: 0.5926\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.6361 - accuracy: 0.6517 - val_loss: 0.6616 - val_accuracy: 0.5890\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6343 - accuracy: 0.6524 - val_loss: 0.6583 - val_accuracy: 0.5966\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6336 - accuracy: 0.6532 - val_loss: 0.6571 - val_accuracy: 0.5981\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6321 - accuracy: 0.6528 - val_loss: 0.6557 - val_accuracy: 0.6007\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6308 - accuracy: 0.6583 - val_loss: 0.6550 - val_accuracy: 0.6012\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6300 - accuracy: 0.6573 - val_loss: 0.6548 - val_accuracy: 0.6006\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.6284 - accuracy: 0.6590 - val_loss: 0.6533 - val_accuracy: 0.6027\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6271 - accuracy: 0.6617 - val_loss: 0.6532 - val_accuracy: 0.6019\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 622us/step - loss: 0.6270 - accuracy: 0.6570 - val_loss: 0.6520 - val_accuracy: 0.6035\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6246 - accuracy: 0.6631 - val_loss: 0.6493 - val_accuracy: 0.6081\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6238 - accuracy: 0.6636 - val_loss: 0.6493 - val_accuracy: 0.6069\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.6229 - accuracy: 0.6638 - val_loss: 0.6495 - val_accuracy: 0.6056\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.6208 - accuracy: 0.6646 - val_loss: 0.6491 - val_accuracy: 0.6053\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 744us/step - loss: 0.6205 - accuracy: 0.6633 - val_loss: 0.6465 - val_accuracy: 0.6094\n",
      "\n",
      "Training model with batch_size=128...\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.1 iterated over 20900 steps satisfies differential privacy with eps = 2.01 and delta = 1e-05.\n",
      "The optimal RDP order is 12.0.\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 944us/step - loss: 0.7748 - accuracy: 0.4794 - val_loss: 0.5378 - val_accuracy: 0.8800\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 806us/step - loss: 0.7237 - accuracy: 0.4859 - val_loss: 0.5933 - val_accuracy: 0.8618\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 821us/step - loss: 0.7058 - accuracy: 0.4991 - val_loss: 0.6313 - val_accuracy: 0.8049\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 809us/step - loss: 0.6971 - accuracy: 0.5135 - val_loss: 0.6560 - val_accuracy: 0.7174\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 949us/step - loss: 0.6922 - accuracy: 0.5253 - val_loss: 0.6725 - val_accuracy: 0.6294\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.6900 - accuracy: 0.5330 - val_loss: 0.6832 - val_accuracy: 0.5598\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 816us/step - loss: 0.6877 - accuracy: 0.5401 - val_loss: 0.6902 - val_accuracy: 0.5197\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 817us/step - loss: 0.6866 - accuracy: 0.5444 - val_loss: 0.6940 - val_accuracy: 0.5020\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6840 - accuracy: 0.5529 - val_loss: 0.6962 - val_accuracy: 0.4964\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 873us/step - loss: 0.6821 - accuracy: 0.5575 - val_loss: 0.6976 - val_accuracy: 0.4924\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 910us/step - loss: 0.6816 - accuracy: 0.5594 - val_loss: 0.6979 - val_accuracy: 0.4920\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 822us/step - loss: 0.6800 - accuracy: 0.5646 - val_loss: 0.6972 - val_accuracy: 0.4989\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 813us/step - loss: 0.6776 - accuracy: 0.5757 - val_loss: 0.6964 - val_accuracy: 0.5037\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 809us/step - loss: 0.6777 - accuracy: 0.5743 - val_loss: 0.6952 - val_accuracy: 0.5089\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.6760 - accuracy: 0.5801 - val_loss: 0.6941 - val_accuracy: 0.5156\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 936us/step - loss: 0.6745 - accuracy: 0.5822 - val_loss: 0.6930 - val_accuracy: 0.5206\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6738 - accuracy: 0.5858 - val_loss: 0.6921 - val_accuracy: 0.5243\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 789us/step - loss: 0.6710 - accuracy: 0.5945 - val_loss: 0.6909 - val_accuracy: 0.5285\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 823us/step - loss: 0.6714 - accuracy: 0.5903 - val_loss: 0.6897 - val_accuracy: 0.5361\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 815us/step - loss: 0.6694 - accuracy: 0.5956 - val_loss: 0.6893 - val_accuracy: 0.5384\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 887us/step - loss: 0.6686 - accuracy: 0.6003 - val_loss: 0.6882 - val_accuracy: 0.5424\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 931us/step - loss: 0.6674 - accuracy: 0.6036 - val_loss: 0.6872 - val_accuracy: 0.5459\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 870us/step - loss: 0.6664 - accuracy: 0.6064 - val_loss: 0.6865 - val_accuracy: 0.5492\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 864us/step - loss: 0.6666 - accuracy: 0.6030 - val_loss: 0.6855 - val_accuracy: 0.5538\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 807us/step - loss: 0.6646 - accuracy: 0.6120 - val_loss: 0.6851 - val_accuracy: 0.5536\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 952us/step - loss: 0.6640 - accuracy: 0.6120 - val_loss: 0.6846 - val_accuracy: 0.5540\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.6626 - accuracy: 0.6141 - val_loss: 0.6832 - val_accuracy: 0.5589\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.6614 - accuracy: 0.6186 - val_loss: 0.6823 - val_accuracy: 0.5605\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 816us/step - loss: 0.6609 - accuracy: 0.6186 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 812us/step - loss: 0.6589 - accuracy: 0.6249 - val_loss: 0.6809 - val_accuracy: 0.5640\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6249 - val_loss: 0.6799 - val_accuracy: 0.5660\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 869us/step - loss: 0.6586 - accuracy: 0.6253 - val_loss: 0.6790 - val_accuracy: 0.5675\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 823us/step - loss: 0.6575 - accuracy: 0.6268 - val_loss: 0.6785 - val_accuracy: 0.5684\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.6565 - accuracy: 0.6306 - val_loss: 0.6785 - val_accuracy: 0.5674\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.6553 - accuracy: 0.6317 - val_loss: 0.6773 - val_accuracy: 0.5701\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 941us/step - loss: 0.6537 - accuracy: 0.6348 - val_loss: 0.6766 - val_accuracy: 0.5720\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.6537 - accuracy: 0.6362 - val_loss: 0.6757 - val_accuracy: 0.5733\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6527 - accuracy: 0.6386 - val_loss: 0.6750 - val_accuracy: 0.5729\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.6512 - accuracy: 0.6407 - val_loss: 0.6737 - val_accuracy: 0.5753\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 804us/step - loss: 0.6507 - accuracy: 0.6425 - val_loss: 0.6733 - val_accuracy: 0.5747\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 866us/step - loss: 0.6504 - accuracy: 0.6414 - val_loss: 0.6728 - val_accuracy: 0.5751\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.6498 - accuracy: 0.6423 - val_loss: 0.6722 - val_accuracy: 0.5749\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 816us/step - loss: 0.6488 - accuracy: 0.6458 - val_loss: 0.6715 - val_accuracy: 0.5755\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.6477 - accuracy: 0.6437 - val_loss: 0.6704 - val_accuracy: 0.5769\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 799us/step - loss: 0.6475 - accuracy: 0.6463 - val_loss: 0.6701 - val_accuracy: 0.5759\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6459 - accuracy: 0.6483 - val_loss: 0.6698 - val_accuracy: 0.5755\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6452 - accuracy: 0.6514 - val_loss: 0.6690 - val_accuracy: 0.5764\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 919us/step - loss: 0.6445 - accuracy: 0.6514 - val_loss: 0.6689 - val_accuracy: 0.5759\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 817us/step - loss: 0.6439 - accuracy: 0.6521 - val_loss: 0.6678 - val_accuracy: 0.5770\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 892us/step - loss: 0.6434 - accuracy: 0.6511 - val_loss: 0.6669 - val_accuracy: 0.5786\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7197 - accuracy: 0.5029 - val_loss: 0.7539 - val_accuracy: 0.2075\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.5070 - val_loss: 0.7439 - val_accuracy: 0.2374\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 928us/step - loss: 0.7116 - accuracy: 0.5153 - val_loss: 0.7376 - val_accuracy: 0.2626\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.7108 - accuracy: 0.5181 - val_loss: 0.7323 - val_accuracy: 0.2893\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 918us/step - loss: 0.7073 - accuracy: 0.5220 - val_loss: 0.7285 - val_accuracy: 0.3096\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 878us/step - loss: 0.7042 - accuracy: 0.5304 - val_loss: 0.7257 - val_accuracy: 0.3262\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7022 - accuracy: 0.5340 - val_loss: 0.7232 - val_accuracy: 0.3446\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5426 - val_loss: 0.7202 - val_accuracy: 0.3657\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 967us/step - loss: 0.6959 - accuracy: 0.5456 - val_loss: 0.7170 - val_accuracy: 0.3875\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6957 - accuracy: 0.5463 - val_loss: 0.7151 - val_accuracy: 0.4020\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6920 - accuracy: 0.5555 - val_loss: 0.7136 - val_accuracy: 0.4145\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6888 - accuracy: 0.5576 - val_loss: 0.7115 - val_accuracy: 0.4284\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5625 - val_loss: 0.7086 - val_accuracy: 0.4462\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.6832 - accuracy: 0.5681 - val_loss: 0.7070 - val_accuracy: 0.4600\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.6844 - accuracy: 0.5692 - val_loss: 0.7046 - val_accuracy: 0.4720\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 799us/step - loss: 0.6827 - accuracy: 0.5733 - val_loss: 0.7028 - val_accuracy: 0.4808\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 987us/step - loss: 0.6797 - accuracy: 0.5791 - val_loss: 0.7018 - val_accuracy: 0.4887\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5842 - val_loss: 0.7005 - val_accuracy: 0.4949\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 974us/step - loss: 0.6758 - accuracy: 0.5860 - val_loss: 0.6994 - val_accuracy: 0.4995\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 900us/step - loss: 0.6747 - accuracy: 0.5888 - val_loss: 0.6970 - val_accuracy: 0.5108\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 983us/step - loss: 0.6715 - accuracy: 0.5949 - val_loss: 0.6949 - val_accuracy: 0.5177\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.6722 - accuracy: 0.5931 - val_loss: 0.6924 - val_accuracy: 0.5249\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6684 - accuracy: 0.5992 - val_loss: 0.6917 - val_accuracy: 0.5278\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.6040 - val_loss: 0.6899 - val_accuracy: 0.5328\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.6018 - val_loss: 0.6885 - val_accuracy: 0.5377\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 920us/step - loss: 0.6630 - accuracy: 0.6118 - val_loss: 0.6874 - val_accuracy: 0.5398\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6617 - accuracy: 0.6131 - val_loss: 0.6852 - val_accuracy: 0.5463\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 823us/step - loss: 0.6618 - accuracy: 0.6128 - val_loss: 0.6844 - val_accuracy: 0.5488\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6589 - accuracy: 0.6158 - val_loss: 0.6825 - val_accuracy: 0.5551\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6184 - val_loss: 0.6806 - val_accuracy: 0.5614\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 930us/step - loss: 0.6557 - accuracy: 0.6240 - val_loss: 0.6800 - val_accuracy: 0.5616\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 876us/step - loss: 0.6553 - accuracy: 0.6237 - val_loss: 0.6792 - val_accuracy: 0.5635\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6532 - accuracy: 0.6278 - val_loss: 0.6769 - val_accuracy: 0.5694\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6300 - val_loss: 0.6759 - val_accuracy: 0.5715\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6505 - accuracy: 0.6329 - val_loss: 0.6748 - val_accuracy: 0.5738\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 977us/step - loss: 0.6491 - accuracy: 0.6355 - val_loss: 0.6724 - val_accuracy: 0.5804\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6490 - accuracy: 0.6348 - val_loss: 0.6706 - val_accuracy: 0.5838\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 911us/step - loss: 0.6466 - accuracy: 0.6387 - val_loss: 0.6690 - val_accuracy: 0.5864\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 829us/step - loss: 0.6459 - accuracy: 0.6413 - val_loss: 0.6678 - val_accuracy: 0.5887\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6456 - accuracy: 0.6366 - val_loss: 0.6666 - val_accuracy: 0.5904\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6420 - accuracy: 0.6438 - val_loss: 0.6655 - val_accuracy: 0.5922\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.6447 - val_loss: 0.6642 - val_accuracy: 0.5954\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.6414 - accuracy: 0.6435 - val_loss: 0.6615 - val_accuracy: 0.6000\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.6398 - accuracy: 0.6461 - val_loss: 0.6602 - val_accuracy: 0.6023\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6384 - accuracy: 0.6485 - val_loss: 0.6594 - val_accuracy: 0.6031\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6373 - accuracy: 0.6503 - val_loss: 0.6586 - val_accuracy: 0.6040\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.6518 - val_loss: 0.6578 - val_accuracy: 0.6060\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 906us/step - loss: 0.6349 - accuracy: 0.6526 - val_loss: 0.6569 - val_accuracy: 0.6059\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.6336 - accuracy: 0.6563 - val_loss: 0.6555 - val_accuracy: 0.6083\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 967us/step - loss: 0.6325 - accuracy: 0.6546 - val_loss: 0.6540 - val_accuracy: 0.6103\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7021 - accuracy: 0.5171 - val_loss: 0.7319 - val_accuracy: 0.3083\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 962us/step - loss: 0.6992 - accuracy: 0.5233 - val_loss: 0.7249 - val_accuracy: 0.3343\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 909us/step - loss: 0.6983 - accuracy: 0.5230 - val_loss: 0.7202 - val_accuracy: 0.3595\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 939us/step - loss: 0.6964 - accuracy: 0.5299 - val_loss: 0.7164 - val_accuracy: 0.3867\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6937 - accuracy: 0.5376 - val_loss: 0.7136 - val_accuracy: 0.4120\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 994us/step - loss: 0.6919 - accuracy: 0.5376 - val_loss: 0.7116 - val_accuracy: 0.4315\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5413 - val_loss: 0.7093 - val_accuracy: 0.4508\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5433 - val_loss: 0.7074 - val_accuracy: 0.4648\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 837us/step - loss: 0.6869 - accuracy: 0.5526 - val_loss: 0.7053 - val_accuracy: 0.4772\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5562 - val_loss: 0.7028 - val_accuracy: 0.4886\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 995us/step - loss: 0.6840 - accuracy: 0.5651 - val_loss: 0.7010 - val_accuracy: 0.4946\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5651 - val_loss: 0.7002 - val_accuracy: 0.4977\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.6801 - accuracy: 0.5737 - val_loss: 0.6992 - val_accuracy: 0.5028\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 804us/step - loss: 0.6797 - accuracy: 0.5763 - val_loss: 0.6979 - val_accuracy: 0.5083\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 821us/step - loss: 0.6787 - accuracy: 0.5789 - val_loss: 0.6961 - val_accuracy: 0.5145\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6765 - accuracy: 0.5875 - val_loss: 0.6947 - val_accuracy: 0.5215\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5866 - val_loss: 0.6930 - val_accuracy: 0.5285\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 926us/step - loss: 0.6735 - accuracy: 0.5933 - val_loss: 0.6916 - val_accuracy: 0.5340\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 813us/step - loss: 0.6722 - accuracy: 0.5964 - val_loss: 0.6901 - val_accuracy: 0.5396\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 892us/step - loss: 0.6715 - accuracy: 0.5957 - val_loss: 0.6891 - val_accuracy: 0.5438\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 895us/step - loss: 0.6703 - accuracy: 0.6011 - val_loss: 0.6878 - val_accuracy: 0.5477\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6689 - accuracy: 0.6033 - val_loss: 0.6863 - val_accuracy: 0.5514\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.6080 - val_loss: 0.6853 - val_accuracy: 0.5537\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.6140 - val_loss: 0.6843 - val_accuracy: 0.5558\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 813us/step - loss: 0.6654 - accuracy: 0.6117 - val_loss: 0.6831 - val_accuracy: 0.5570\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 809us/step - loss: 0.6645 - accuracy: 0.6168 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 810us/step - loss: 0.6625 - accuracy: 0.6201 - val_loss: 0.6817 - val_accuracy: 0.5654\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6231 - val_loss: 0.6806 - val_accuracy: 0.5712\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6599 - accuracy: 0.6279 - val_loss: 0.6790 - val_accuracy: 0.5765\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.6585 - accuracy: 0.6282 - val_loss: 0.6782 - val_accuracy: 0.5789\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6581 - accuracy: 0.6311 - val_loss: 0.6774 - val_accuracy: 0.5808\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 927us/step - loss: 0.6571 - accuracy: 0.6303 - val_loss: 0.6770 - val_accuracy: 0.5813\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 906us/step - loss: 0.6565 - accuracy: 0.6331 - val_loss: 0.6757 - val_accuracy: 0.5856\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6396 - val_loss: 0.6750 - val_accuracy: 0.5870\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6540 - accuracy: 0.6388 - val_loss: 0.6742 - val_accuracy: 0.5891\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6411 - val_loss: 0.6729 - val_accuracy: 0.5921\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 866us/step - loss: 0.6523 - accuracy: 0.6414 - val_loss: 0.6723 - val_accuracy: 0.5933\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 809us/step - loss: 0.6514 - accuracy: 0.6441 - val_loss: 0.6712 - val_accuracy: 0.5949\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.6502 - accuracy: 0.6453 - val_loss: 0.6697 - val_accuracy: 0.5959\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6459 - val_loss: 0.6693 - val_accuracy: 0.5970\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6484 - accuracy: 0.6516 - val_loss: 0.6689 - val_accuracy: 0.5970\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6471 - accuracy: 0.6516 - val_loss: 0.6684 - val_accuracy: 0.5975\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 906us/step - loss: 0.6456 - accuracy: 0.6540 - val_loss: 0.6672 - val_accuracy: 0.5991\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 942us/step - loss: 0.6444 - accuracy: 0.6538 - val_loss: 0.6670 - val_accuracy: 0.5985\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 811us/step - loss: 0.6445 - accuracy: 0.6540 - val_loss: 0.6662 - val_accuracy: 0.5995\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 799us/step - loss: 0.6432 - accuracy: 0.6563 - val_loss: 0.6655 - val_accuracy: 0.6001\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6420 - accuracy: 0.6586 - val_loss: 0.6640 - val_accuracy: 0.6026\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6592 - val_loss: 0.6629 - val_accuracy: 0.6031\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.6415 - accuracy: 0.6607 - val_loss: 0.6630 - val_accuracy: 0.6029\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 811us/step - loss: 0.6398 - accuracy: 0.6636 - val_loss: 0.6625 - val_accuracy: 0.6046\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7481 - accuracy: 0.5211 - val_loss: 0.8913 - val_accuracy: 0.1174\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7178 - accuracy: 0.5241 - val_loss: 0.8025 - val_accuracy: 0.1321\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.5290 - val_loss: 0.7575 - val_accuracy: 0.2048\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.5354 - val_loss: 0.7354 - val_accuracy: 0.2702\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.6965 - accuracy: 0.5400 - val_loss: 0.7219 - val_accuracy: 0.3597\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 983us/step - loss: 0.6921 - accuracy: 0.5442 - val_loss: 0.7148 - val_accuracy: 0.4194\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6898 - accuracy: 0.5481 - val_loss: 0.7101 - val_accuracy: 0.4449\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5564 - val_loss: 0.7067 - val_accuracy: 0.4579\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 909us/step - loss: 0.6839 - accuracy: 0.5632 - val_loss: 0.7034 - val_accuracy: 0.4678\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6815 - accuracy: 0.5666 - val_loss: 0.7010 - val_accuracy: 0.4767\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6793 - accuracy: 0.5709 - val_loss: 0.6969 - val_accuracy: 0.4933\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 801us/step - loss: 0.6777 - accuracy: 0.5742 - val_loss: 0.6943 - val_accuracy: 0.5107\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5774 - val_loss: 0.6926 - val_accuracy: 0.5221\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6720 - accuracy: 0.5832 - val_loss: 0.6902 - val_accuracy: 0.5322\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5847 - val_loss: 0.6884 - val_accuracy: 0.5390\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.6689 - accuracy: 0.5888 - val_loss: 0.6880 - val_accuracy: 0.5396\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.6697 - accuracy: 0.5878 - val_loss: 0.6864 - val_accuracy: 0.5447\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 948us/step - loss: 0.6676 - accuracy: 0.5908 - val_loss: 0.6852 - val_accuracy: 0.5483\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.5984 - val_loss: 0.6829 - val_accuracy: 0.5540\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.5970 - val_loss: 0.6823 - val_accuracy: 0.5556\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6016 - val_loss: 0.6810 - val_accuracy: 0.5592\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.6611 - accuracy: 0.6028 - val_loss: 0.6796 - val_accuracy: 0.5653\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 789us/step - loss: 0.6605 - accuracy: 0.6006 - val_loss: 0.6791 - val_accuracy: 0.5682\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.6579 - accuracy: 0.6077 - val_loss: 0.6784 - val_accuracy: 0.5709\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.6573 - accuracy: 0.6099 - val_loss: 0.6775 - val_accuracy: 0.5734\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6553 - accuracy: 0.6144 - val_loss: 0.6763 - val_accuracy: 0.5769\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 894us/step - loss: 0.6548 - accuracy: 0.6124 - val_loss: 0.6748 - val_accuracy: 0.5809\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.6528 - accuracy: 0.6172 - val_loss: 0.6741 - val_accuracy: 0.5817\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 914us/step - loss: 0.6535 - accuracy: 0.6161 - val_loss: 0.6730 - val_accuracy: 0.5831\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.6514 - accuracy: 0.6197 - val_loss: 0.6718 - val_accuracy: 0.5856\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6502 - accuracy: 0.6209 - val_loss: 0.6714 - val_accuracy: 0.5860\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6493 - accuracy: 0.6210 - val_loss: 0.6701 - val_accuracy: 0.5893\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6482 - accuracy: 0.6249 - val_loss: 0.6690 - val_accuracy: 0.5911\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.6472 - accuracy: 0.6251 - val_loss: 0.6684 - val_accuracy: 0.5918\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6463 - accuracy: 0.6263 - val_loss: 0.6671 - val_accuracy: 0.5949\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 908us/step - loss: 0.6444 - accuracy: 0.6276 - val_loss: 0.6666 - val_accuracy: 0.5955\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 921us/step - loss: 0.6434 - accuracy: 0.6291 - val_loss: 0.6657 - val_accuracy: 0.5966\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.6444 - accuracy: 0.6290 - val_loss: 0.6645 - val_accuracy: 0.5980\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6424 - accuracy: 0.6333 - val_loss: 0.6638 - val_accuracy: 0.5992\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 892us/step - loss: 0.6424 - accuracy: 0.6315 - val_loss: 0.6631 - val_accuracy: 0.6005\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 917us/step - loss: 0.6401 - accuracy: 0.6372 - val_loss: 0.6620 - val_accuracy: 0.6017\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.6396 - accuracy: 0.6347 - val_loss: 0.6617 - val_accuracy: 0.6019\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 821us/step - loss: 0.6394 - accuracy: 0.6380 - val_loss: 0.6603 - val_accuracy: 0.6054\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 849us/step - loss: 0.6376 - accuracy: 0.6385 - val_loss: 0.6593 - val_accuracy: 0.6069\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 992us/step - loss: 0.6369 - accuracy: 0.6389 - val_loss: 0.6583 - val_accuracy: 0.6084\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 977us/step - loss: 0.6365 - accuracy: 0.6384 - val_loss: 0.6579 - val_accuracy: 0.6091\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6368 - accuracy: 0.6385 - val_loss: 0.6579 - val_accuracy: 0.6075\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6343 - accuracy: 0.6431 - val_loss: 0.6569 - val_accuracy: 0.6092\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 986us/step - loss: 0.6345 - accuracy: 0.6448 - val_loss: 0.6558 - val_accuracy: 0.6101\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 849us/step - loss: 0.6329 - accuracy: 0.6447 - val_loss: 0.6543 - val_accuracy: 0.6125\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.7257 - accuracy: 0.5200 - val_loss: 0.8643 - val_accuracy: 0.1296\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.7085 - accuracy: 0.5243 - val_loss: 0.8074 - val_accuracy: 0.1713\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.7048 - accuracy: 0.5234 - val_loss: 0.7754 - val_accuracy: 0.2161\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.7006 - accuracy: 0.5248 - val_loss: 0.7560 - val_accuracy: 0.2529\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.6975 - accuracy: 0.5311 - val_loss: 0.7447 - val_accuracy: 0.2926\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 890us/step - loss: 0.6971 - accuracy: 0.5315 - val_loss: 0.7381 - val_accuracy: 0.3181\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6950 - accuracy: 0.5337 - val_loss: 0.7338 - val_accuracy: 0.3351\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6930 - accuracy: 0.5416 - val_loss: 0.7320 - val_accuracy: 0.3455\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6917 - accuracy: 0.5426 - val_loss: 0.7296 - val_accuracy: 0.3592\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 868us/step - loss: 0.6900 - accuracy: 0.5484 - val_loss: 0.7277 - val_accuracy: 0.3702\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 921us/step - loss: 0.6882 - accuracy: 0.5512 - val_loss: 0.7261 - val_accuracy: 0.3800\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.6881 - accuracy: 0.5503 - val_loss: 0.7247 - val_accuracy: 0.3904\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.6863 - accuracy: 0.5549 - val_loss: 0.7230 - val_accuracy: 0.4008\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 903us/step - loss: 0.6856 - accuracy: 0.5576 - val_loss: 0.7215 - val_accuracy: 0.4090\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 911us/step - loss: 0.6841 - accuracy: 0.5612 - val_loss: 0.7200 - val_accuracy: 0.4183\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6830 - accuracy: 0.5641 - val_loss: 0.7189 - val_accuracy: 0.4254\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6808 - accuracy: 0.5715 - val_loss: 0.7179 - val_accuracy: 0.4319\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6794 - accuracy: 0.5723 - val_loss: 0.7168 - val_accuracy: 0.4381\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 843us/step - loss: 0.6793 - accuracy: 0.5741 - val_loss: 0.7155 - val_accuracy: 0.4455\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 841us/step - loss: 0.6780 - accuracy: 0.5763 - val_loss: 0.7143 - val_accuracy: 0.4503\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 878us/step - loss: 0.6779 - accuracy: 0.5778 - val_loss: 0.7125 - val_accuracy: 0.4578\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 926us/step - loss: 0.6758 - accuracy: 0.5820 - val_loss: 0.7124 - val_accuracy: 0.4599\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6758 - accuracy: 0.5841 - val_loss: 0.7122 - val_accuracy: 0.4610\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 824us/step - loss: 0.6740 - accuracy: 0.5874 - val_loss: 0.7111 - val_accuracy: 0.4669\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.6733 - accuracy: 0.5873 - val_loss: 0.7104 - val_accuracy: 0.4715\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.6727 - accuracy: 0.5909 - val_loss: 0.7093 - val_accuracy: 0.4765\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 837us/step - loss: 0.6721 - accuracy: 0.5917 - val_loss: 0.7083 - val_accuracy: 0.4803\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 864us/step - loss: 0.6707 - accuracy: 0.5967 - val_loss: 0.7068 - val_accuracy: 0.4861\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 981us/step - loss: 0.6700 - accuracy: 0.5979 - val_loss: 0.7062 - val_accuracy: 0.4878\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 869us/step - loss: 0.6682 - accuracy: 0.6023 - val_loss: 0.7055 - val_accuracy: 0.4918\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.6684 - accuracy: 0.5986 - val_loss: 0.7044 - val_accuracy: 0.4968\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6668 - accuracy: 0.6065 - val_loss: 0.7043 - val_accuracy: 0.4975\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.6671 - accuracy: 0.6051 - val_loss: 0.7037 - val_accuracy: 0.5006\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.6661 - accuracy: 0.6078 - val_loss: 0.7024 - val_accuracy: 0.5050\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6649 - accuracy: 0.6112 - val_loss: 0.7016 - val_accuracy: 0.5071\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6643 - accuracy: 0.6086 - val_loss: 0.7009 - val_accuracy: 0.5090\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.6634 - accuracy: 0.6148 - val_loss: 0.7006 - val_accuracy: 0.5113\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 817us/step - loss: 0.6632 - accuracy: 0.6141 - val_loss: 0.6996 - val_accuracy: 0.5137\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 810us/step - loss: 0.6620 - accuracy: 0.6164 - val_loss: 0.6984 - val_accuracy: 0.5185\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 983us/step - loss: 0.6614 - accuracy: 0.6165 - val_loss: 0.6970 - val_accuracy: 0.5234\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 849us/step - loss: 0.6602 - accuracy: 0.6182 - val_loss: 0.6960 - val_accuracy: 0.5263\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 817us/step - loss: 0.6597 - accuracy: 0.6207 - val_loss: 0.6947 - val_accuracy: 0.5296\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 813us/step - loss: 0.6582 - accuracy: 0.6219 - val_loss: 0.6936 - val_accuracy: 0.5343\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 974us/step - loss: 0.6575 - accuracy: 0.6243 - val_loss: 0.6927 - val_accuracy: 0.5373\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 849us/step - loss: 0.6567 - accuracy: 0.6280 - val_loss: 0.6927 - val_accuracy: 0.5380\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6262 - val_loss: 0.6917 - val_accuracy: 0.5410\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6268 - val_loss: 0.6903 - val_accuracy: 0.5436\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 863us/step - loss: 0.6558 - accuracy: 0.6285 - val_loss: 0.6900 - val_accuracy: 0.5446\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 824us/step - loss: 0.6542 - accuracy: 0.6309 - val_loss: 0.6899 - val_accuracy: 0.5452\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 817us/step - loss: 0.6527 - accuracy: 0.6332 - val_loss: 0.6888 - val_accuracy: 0.5478\n"
     ]
    }
   ],
   "source": [
    "# Run experiments varying parameters\n",
    "delta = 1e-5\n",
    "\n",
    "# 1. Vary batch_size\n",
    "results_batch_size = {}\n",
    "eps_batch_size = {}\n",
    "for bs in batch_size_values:\n",
    "    print(f\"\\nTraining model with batch_size={bs}...\")\n",
    "    n = len(X_train_filtered)\n",
    "    eps = compute_privacy_budget(n, bs, default_noise_multiplier, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "        batch_size=bs, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_batch_size[bs] = compute_statistics(results)\n",
    "    eps_batch_size[bs] = eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae4efc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with sample_size_ratio=1...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.7145 - accuracy: 0.5214 - val_loss: 0.7018 - val_accuracy: 0.4810\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6980 - accuracy: 0.5418 - val_loss: 0.7062 - val_accuracy: 0.4726\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6895 - accuracy: 0.5539 - val_loss: 0.7004 - val_accuracy: 0.5040\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6817 - accuracy: 0.5686 - val_loss: 0.6966 - val_accuracy: 0.5218\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6764 - accuracy: 0.5801 - val_loss: 0.6947 - val_accuracy: 0.5307\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6702 - accuracy: 0.5915 - val_loss: 0.6908 - val_accuracy: 0.5433\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6658 - accuracy: 0.6014 - val_loss: 0.6860 - val_accuracy: 0.5568\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6614 - accuracy: 0.6108 - val_loss: 0.6810 - val_accuracy: 0.5677\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6571 - accuracy: 0.6197 - val_loss: 0.6784 - val_accuracy: 0.5732\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6520 - accuracy: 0.6289 - val_loss: 0.6771 - val_accuracy: 0.5754\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6472 - accuracy: 0.6376 - val_loss: 0.6767 - val_accuracy: 0.5747\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6437 - accuracy: 0.6432 - val_loss: 0.6669 - val_accuracy: 0.5937\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6403 - accuracy: 0.6488 - val_loss: 0.6689 - val_accuracy: 0.5869\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6366 - accuracy: 0.6577 - val_loss: 0.6688 - val_accuracy: 0.5866\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6337 - accuracy: 0.6594 - val_loss: 0.6638 - val_accuracy: 0.5946\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.6311 - accuracy: 0.6630 - val_loss: 0.6581 - val_accuracy: 0.6004\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6268 - accuracy: 0.6683 - val_loss: 0.6564 - val_accuracy: 0.6013\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6233 - accuracy: 0.6745 - val_loss: 0.6581 - val_accuracy: 0.5985\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6210 - accuracy: 0.6763 - val_loss: 0.6483 - val_accuracy: 0.6114\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 736us/step - loss: 0.6192 - accuracy: 0.6768 - val_loss: 0.6483 - val_accuracy: 0.6113\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6150 - accuracy: 0.6846 - val_loss: 0.6450 - val_accuracy: 0.6166\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.6128 - accuracy: 0.6854 - val_loss: 0.6499 - val_accuracy: 0.6086\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6097 - accuracy: 0.6895 - val_loss: 0.6388 - val_accuracy: 0.6228\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.6071 - accuracy: 0.6927 - val_loss: 0.6354 - val_accuracy: 0.6265\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6049 - accuracy: 0.6933 - val_loss: 0.6356 - val_accuracy: 0.6250\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.6022 - accuracy: 0.6936 - val_loss: 0.6306 - val_accuracy: 0.6311\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5993 - accuracy: 0.6997 - val_loss: 0.6331 - val_accuracy: 0.6270\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5971 - accuracy: 0.6987 - val_loss: 0.6264 - val_accuracy: 0.6359\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.5946 - accuracy: 0.7039 - val_loss: 0.6303 - val_accuracy: 0.6284\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5940 - accuracy: 0.7006 - val_loss: 0.6302 - val_accuracy: 0.6276\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.5912 - accuracy: 0.7055 - val_loss: 0.6248 - val_accuracy: 0.6355\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5884 - accuracy: 0.7065 - val_loss: 0.6285 - val_accuracy: 0.6299\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.5865 - accuracy: 0.7074 - val_loss: 0.6216 - val_accuracy: 0.6401\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5837 - accuracy: 0.7080 - val_loss: 0.6253 - val_accuracy: 0.6341\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.5826 - accuracy: 0.7107 - val_loss: 0.6170 - val_accuracy: 0.6435\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5801 - accuracy: 0.7127 - val_loss: 0.6191 - val_accuracy: 0.6399\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.5785 - accuracy: 0.7134 - val_loss: 0.6178 - val_accuracy: 0.6403\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.5766 - accuracy: 0.7151 - val_loss: 0.6243 - val_accuracy: 0.6332\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.5751 - accuracy: 0.7153 - val_loss: 0.6126 - val_accuracy: 0.6435\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.5730 - accuracy: 0.7156 - val_loss: 0.6098 - val_accuracy: 0.6458\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5710 - accuracy: 0.7186 - val_loss: 0.6143 - val_accuracy: 0.6399\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5695 - accuracy: 0.7205 - val_loss: 0.6132 - val_accuracy: 0.6403\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.5677 - accuracy: 0.7194 - val_loss: 0.6068 - val_accuracy: 0.6462\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.5659 - accuracy: 0.7205 - val_loss: 0.6116 - val_accuracy: 0.6387\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.5651 - accuracy: 0.7209 - val_loss: 0.6180 - val_accuracy: 0.6332\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.5629 - accuracy: 0.7241 - val_loss: 0.6117 - val_accuracy: 0.6373\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.5624 - accuracy: 0.7230 - val_loss: 0.6085 - val_accuracy: 0.6410\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5608 - accuracy: 0.7240 - val_loss: 0.6030 - val_accuracy: 0.6470\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.5586 - accuracy: 0.7243 - val_loss: 0.6034 - val_accuracy: 0.6467\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5577 - accuracy: 0.7250 - val_loss: 0.5988 - val_accuracy: 0.6527\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 797us/step - loss: 0.7038 - accuracy: 0.5187 - val_loss: 0.6652 - val_accuracy: 0.7113\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6851 - accuracy: 0.5649 - val_loss: 0.6914 - val_accuracy: 0.5027\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 812us/step - loss: 0.6801 - accuracy: 0.5816 - val_loss: 0.6914 - val_accuracy: 0.5068\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6751 - accuracy: 0.5953 - val_loss: 0.6875 - val_accuracy: 0.5174\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.6715 - accuracy: 0.6050 - val_loss: 0.6850 - val_accuracy: 0.5229\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.6677 - accuracy: 0.6174 - val_loss: 0.6808 - val_accuracy: 0.5414\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.6636 - accuracy: 0.6290 - val_loss: 0.6789 - val_accuracy: 0.5475\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6608 - accuracy: 0.6346 - val_loss: 0.6703 - val_accuracy: 0.5838\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.6570 - accuracy: 0.6432 - val_loss: 0.6675 - val_accuracy: 0.5965\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6524 - accuracy: 0.6539 - val_loss: 0.6656 - val_accuracy: 0.6018\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.6497 - accuracy: 0.6551 - val_loss: 0.6588 - val_accuracy: 0.6224\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6449 - accuracy: 0.6658 - val_loss: 0.6568 - val_accuracy: 0.6276\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6420 - accuracy: 0.6686 - val_loss: 0.6528 - val_accuracy: 0.6375\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6392 - accuracy: 0.6710 - val_loss: 0.6493 - val_accuracy: 0.6416\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6361 - accuracy: 0.6738 - val_loss: 0.6439 - val_accuracy: 0.6462\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6330 - accuracy: 0.6768 - val_loss: 0.6452 - val_accuracy: 0.6416\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6306 - accuracy: 0.6776 - val_loss: 0.6426 - val_accuracy: 0.6424\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6277 - accuracy: 0.6818 - val_loss: 0.6351 - val_accuracy: 0.6490\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.6245 - accuracy: 0.6830 - val_loss: 0.6371 - val_accuracy: 0.6447\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6219 - accuracy: 0.6865 - val_loss: 0.6332 - val_accuracy: 0.6472\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6195 - accuracy: 0.6847 - val_loss: 0.6307 - val_accuracy: 0.6487\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6161 - accuracy: 0.6898 - val_loss: 0.6280 - val_accuracy: 0.6493\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6146 - accuracy: 0.6900 - val_loss: 0.6272 - val_accuracy: 0.6469\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6120 - accuracy: 0.6915 - val_loss: 0.6279 - val_accuracy: 0.6450\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6106 - accuracy: 0.6931 - val_loss: 0.6239 - val_accuracy: 0.6481\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6080 - accuracy: 0.6941 - val_loss: 0.6231 - val_accuracy: 0.6471\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6053 - accuracy: 0.6941 - val_loss: 0.6185 - val_accuracy: 0.6545\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6047 - accuracy: 0.6936 - val_loss: 0.6172 - val_accuracy: 0.6540\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6016 - accuracy: 0.6955 - val_loss: 0.6179 - val_accuracy: 0.6507\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5995 - accuracy: 0.6988 - val_loss: 0.6216 - val_accuracy: 0.6394\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5986 - accuracy: 0.6980 - val_loss: 0.6192 - val_accuracy: 0.6416\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.5958 - accuracy: 0.7018 - val_loss: 0.6153 - val_accuracy: 0.6490\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5945 - accuracy: 0.7021 - val_loss: 0.6151 - val_accuracy: 0.6481\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5930 - accuracy: 0.7008 - val_loss: 0.6103 - val_accuracy: 0.6523\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5917 - accuracy: 0.7011 - val_loss: 0.6108 - val_accuracy: 0.6498\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5897 - accuracy: 0.7036 - val_loss: 0.6124 - val_accuracy: 0.6468\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5881 - accuracy: 0.7046 - val_loss: 0.6035 - val_accuracy: 0.6543\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5866 - accuracy: 0.7053 - val_loss: 0.6078 - val_accuracy: 0.6493\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5850 - accuracy: 0.7061 - val_loss: 0.6110 - val_accuracy: 0.6441\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5844 - accuracy: 0.7056 - val_loss: 0.6117 - val_accuracy: 0.6425\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5820 - accuracy: 0.7080 - val_loss: 0.6063 - val_accuracy: 0.6486\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5813 - accuracy: 0.7069 - val_loss: 0.6060 - val_accuracy: 0.6483\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5802 - accuracy: 0.7085 - val_loss: 0.6037 - val_accuracy: 0.6499\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5777 - accuracy: 0.7103 - val_loss: 0.6052 - val_accuracy: 0.6487\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.5773 - accuracy: 0.7113 - val_loss: 0.6052 - val_accuracy: 0.6496\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.5749 - accuracy: 0.7114 - val_loss: 0.6089 - val_accuracy: 0.6447\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5745 - accuracy: 0.7111 - val_loss: 0.6020 - val_accuracy: 0.6521\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5725 - accuracy: 0.7145 - val_loss: 0.6063 - val_accuracy: 0.6479\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5723 - accuracy: 0.7120 - val_loss: 0.6010 - val_accuracy: 0.6520\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5719 - accuracy: 0.7121 - val_loss: 0.6022 - val_accuracy: 0.6504\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6890 - accuracy: 0.5522 - val_loss: 0.7111 - val_accuracy: 0.4493\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6814 - accuracy: 0.5684 - val_loss: 0.7061 - val_accuracy: 0.4813\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6753 - accuracy: 0.5816 - val_loss: 0.6931 - val_accuracy: 0.5151\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6679 - accuracy: 0.5971 - val_loss: 0.6924 - val_accuracy: 0.5225\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6641 - accuracy: 0.6063 - val_loss: 0.6898 - val_accuracy: 0.5304\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6586 - accuracy: 0.6160 - val_loss: 0.6844 - val_accuracy: 0.5390\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.6535 - accuracy: 0.6207 - val_loss: 0.6766 - val_accuracy: 0.5529\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6500 - accuracy: 0.6324 - val_loss: 0.6757 - val_accuracy: 0.5553\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.6450 - accuracy: 0.6374 - val_loss: 0.6715 - val_accuracy: 0.5621\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6422 - accuracy: 0.6407 - val_loss: 0.6681 - val_accuracy: 0.5663\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.6385 - accuracy: 0.6473 - val_loss: 0.6627 - val_accuracy: 0.5735\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6361 - accuracy: 0.6490 - val_loss: 0.6659 - val_accuracy: 0.5706\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 774us/step - loss: 0.6316 - accuracy: 0.6552 - val_loss: 0.6603 - val_accuracy: 0.5774\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6293 - accuracy: 0.6575 - val_loss: 0.6612 - val_accuracy: 0.5775\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.6270 - accuracy: 0.6622 - val_loss: 0.6538 - val_accuracy: 0.5912\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6243 - accuracy: 0.6650 - val_loss: 0.6536 - val_accuracy: 0.5912\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.6218 - accuracy: 0.6666 - val_loss: 0.6485 - val_accuracy: 0.5960\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6196 - accuracy: 0.6686 - val_loss: 0.6518 - val_accuracy: 0.5945\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6169 - accuracy: 0.6717 - val_loss: 0.6434 - val_accuracy: 0.6023\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.6144 - accuracy: 0.6723 - val_loss: 0.6430 - val_accuracy: 0.6026\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6124 - accuracy: 0.6742 - val_loss: 0.6413 - val_accuracy: 0.6039\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6090 - accuracy: 0.6811 - val_loss: 0.6430 - val_accuracy: 0.6015\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6072 - accuracy: 0.6812 - val_loss: 0.6419 - val_accuracy: 0.6025\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.6047 - accuracy: 0.6839 - val_loss: 0.6395 - val_accuracy: 0.6041\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6022 - accuracy: 0.6854 - val_loss: 0.6391 - val_accuracy: 0.6042\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.6010 - accuracy: 0.6861 - val_loss: 0.6339 - val_accuracy: 0.6098\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5987 - accuracy: 0.6898 - val_loss: 0.6301 - val_accuracy: 0.6145\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5966 - accuracy: 0.6899 - val_loss: 0.6288 - val_accuracy: 0.6179\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5944 - accuracy: 0.6929 - val_loss: 0.6298 - val_accuracy: 0.6157\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.5932 - accuracy: 0.6938 - val_loss: 0.6271 - val_accuracy: 0.6205\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5914 - accuracy: 0.6926 - val_loss: 0.6218 - val_accuracy: 0.6277\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.5890 - accuracy: 0.6962 - val_loss: 0.6270 - val_accuracy: 0.6198\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5879 - accuracy: 0.6988 - val_loss: 0.6254 - val_accuracy: 0.6215\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.5864 - accuracy: 0.6978 - val_loss: 0.6254 - val_accuracy: 0.6208\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5839 - accuracy: 0.7008 - val_loss: 0.6216 - val_accuracy: 0.6249\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.5831 - accuracy: 0.6993 - val_loss: 0.6247 - val_accuracy: 0.6208\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.5811 - accuracy: 0.7040 - val_loss: 0.6202 - val_accuracy: 0.6278\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5798 - accuracy: 0.7023 - val_loss: 0.6243 - val_accuracy: 0.6210\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 775us/step - loss: 0.5794 - accuracy: 0.7038 - val_loss: 0.6232 - val_accuracy: 0.6229\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.5768 - accuracy: 0.7057 - val_loss: 0.6231 - val_accuracy: 0.6230\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 765us/step - loss: 0.5755 - accuracy: 0.7069 - val_loss: 0.6185 - val_accuracy: 0.6307\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5740 - accuracy: 0.7078 - val_loss: 0.6226 - val_accuracy: 0.6255\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.5726 - accuracy: 0.7105 - val_loss: 0.6133 - val_accuracy: 0.6374\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5714 - accuracy: 0.7090 - val_loss: 0.6136 - val_accuracy: 0.6368\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5698 - accuracy: 0.7088 - val_loss: 0.6162 - val_accuracy: 0.6347\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.5690 - accuracy: 0.7105 - val_loss: 0.6180 - val_accuracy: 0.6332\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5680 - accuracy: 0.7102 - val_loss: 0.6125 - val_accuracy: 0.6376\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.5662 - accuracy: 0.7134 - val_loss: 0.6159 - val_accuracy: 0.6342\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5649 - accuracy: 0.7141 - val_loss: 0.6181 - val_accuracy: 0.6322\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.5646 - accuracy: 0.7130 - val_loss: 0.6163 - val_accuracy: 0.6343\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6981 - accuracy: 0.5230 - val_loss: 0.7385 - val_accuracy: 0.2559\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 903us/step - loss: 0.6873 - accuracy: 0.5562 - val_loss: 0.7271 - val_accuracy: 0.3685\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6772 - accuracy: 0.5857 - val_loss: 0.7177 - val_accuracy: 0.4246\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 826us/step - loss: 0.6686 - accuracy: 0.6068 - val_loss: 0.7095 - val_accuracy: 0.4525\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6627 - accuracy: 0.6234 - val_loss: 0.7006 - val_accuracy: 0.4908\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6579 - accuracy: 0.6301 - val_loss: 0.6978 - val_accuracy: 0.5085\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6531 - accuracy: 0.6389 - val_loss: 0.6928 - val_accuracy: 0.5305\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6483 - accuracy: 0.6436 - val_loss: 0.6819 - val_accuracy: 0.5638\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6445 - accuracy: 0.6485 - val_loss: 0.6796 - val_accuracy: 0.5716\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6401 - accuracy: 0.6537 - val_loss: 0.6761 - val_accuracy: 0.5793\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6366 - accuracy: 0.6585 - val_loss: 0.6722 - val_accuracy: 0.5844\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6336 - accuracy: 0.6602 - val_loss: 0.6705 - val_accuracy: 0.5872\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6299 - accuracy: 0.6624 - val_loss: 0.6638 - val_accuracy: 0.5957\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6280 - accuracy: 0.6631 - val_loss: 0.6589 - val_accuracy: 0.6013\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6245 - accuracy: 0.6679 - val_loss: 0.6564 - val_accuracy: 0.6044\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6219 - accuracy: 0.6704 - val_loss: 0.6580 - val_accuracy: 0.6032\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6191 - accuracy: 0.6712 - val_loss: 0.6528 - val_accuracy: 0.6104\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6171 - accuracy: 0.6719 - val_loss: 0.6490 - val_accuracy: 0.6141\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6138 - accuracy: 0.6769 - val_loss: 0.6518 - val_accuracy: 0.6109\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6133 - accuracy: 0.6738 - val_loss: 0.6472 - val_accuracy: 0.6164\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6108 - accuracy: 0.6772 - val_loss: 0.6475 - val_accuracy: 0.6153\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6082 - accuracy: 0.6798 - val_loss: 0.6457 - val_accuracy: 0.6175\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6061 - accuracy: 0.6817 - val_loss: 0.6415 - val_accuracy: 0.6224\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6039 - accuracy: 0.6836 - val_loss: 0.6374 - val_accuracy: 0.6277\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6021 - accuracy: 0.6855 - val_loss: 0.6357 - val_accuracy: 0.6308\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6002 - accuracy: 0.6883 - val_loss: 0.6372 - val_accuracy: 0.6290\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5976 - accuracy: 0.6891 - val_loss: 0.6308 - val_accuracy: 0.6352\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5961 - accuracy: 0.6905 - val_loss: 0.6367 - val_accuracy: 0.6290\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5939 - accuracy: 0.6912 - val_loss: 0.6284 - val_accuracy: 0.6363\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5922 - accuracy: 0.6940 - val_loss: 0.6327 - val_accuracy: 0.6319\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.5904 - accuracy: 0.6944 - val_loss: 0.6304 - val_accuracy: 0.6341\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.5893 - accuracy: 0.6972 - val_loss: 0.6287 - val_accuracy: 0.6356\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5876 - accuracy: 0.6969 - val_loss: 0.6250 - val_accuracy: 0.6389\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5859 - accuracy: 0.6976 - val_loss: 0.6286 - val_accuracy: 0.6334\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5849 - accuracy: 0.6991 - val_loss: 0.6293 - val_accuracy: 0.6330\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5824 - accuracy: 0.6997 - val_loss: 0.6246 - val_accuracy: 0.6365\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5805 - accuracy: 0.7038 - val_loss: 0.6202 - val_accuracy: 0.6402\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5788 - accuracy: 0.7036 - val_loss: 0.6211 - val_accuracy: 0.6394\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5777 - accuracy: 0.7058 - val_loss: 0.6267 - val_accuracy: 0.6341\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5770 - accuracy: 0.7044 - val_loss: 0.6230 - val_accuracy: 0.6375\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.5751 - accuracy: 0.7081 - val_loss: 0.6240 - val_accuracy: 0.6364\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5742 - accuracy: 0.7070 - val_loss: 0.6189 - val_accuracy: 0.6408\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.5721 - accuracy: 0.7072 - val_loss: 0.6170 - val_accuracy: 0.6410\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5713 - accuracy: 0.7087 - val_loss: 0.6234 - val_accuracy: 0.6368\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5693 - accuracy: 0.7097 - val_loss: 0.6153 - val_accuracy: 0.6423\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5689 - accuracy: 0.7103 - val_loss: 0.6205 - val_accuracy: 0.6387\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5675 - accuracy: 0.7110 - val_loss: 0.6177 - val_accuracy: 0.6406\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5662 - accuracy: 0.7110 - val_loss: 0.6094 - val_accuracy: 0.6448\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5648 - accuracy: 0.7121 - val_loss: 0.6166 - val_accuracy: 0.6412\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5647 - accuracy: 0.7108 - val_loss: 0.6146 - val_accuracy: 0.6420\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.7105 - accuracy: 0.4977 - val_loss: 0.7621 - val_accuracy: 0.2277\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.7264 - val_accuracy: 0.3978\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6822 - accuracy: 0.5503 - val_loss: 0.7118 - val_accuracy: 0.4706\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6769 - accuracy: 0.5685 - val_loss: 0.7045 - val_accuracy: 0.5050\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6707 - accuracy: 0.5850 - val_loss: 0.6990 - val_accuracy: 0.5311\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6669 - accuracy: 0.5940 - val_loss: 0.6906 - val_accuracy: 0.5583\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6621 - accuracy: 0.6084 - val_loss: 0.6894 - val_accuracy: 0.5616\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6593 - accuracy: 0.6121 - val_loss: 0.6824 - val_accuracy: 0.5780\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6557 - accuracy: 0.6194 - val_loss: 0.6789 - val_accuracy: 0.5834\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6532 - accuracy: 0.6252 - val_loss: 0.6813 - val_accuracy: 0.5766\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6503 - accuracy: 0.6298 - val_loss: 0.6729 - val_accuracy: 0.5973\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6471 - accuracy: 0.6378 - val_loss: 0.6679 - val_accuracy: 0.6060\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6447 - accuracy: 0.6405 - val_loss: 0.6714 - val_accuracy: 0.5976\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6417 - accuracy: 0.6437 - val_loss: 0.6685 - val_accuracy: 0.5990\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6404 - accuracy: 0.6476 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6385 - accuracy: 0.6482 - val_loss: 0.6636 - val_accuracy: 0.6069\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6344 - accuracy: 0.6552 - val_loss: 0.6628 - val_accuracy: 0.6071\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6323 - accuracy: 0.6577 - val_loss: 0.6600 - val_accuracy: 0.6105\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6302 - accuracy: 0.6603 - val_loss: 0.6604 - val_accuracy: 0.6077\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6279 - accuracy: 0.6649 - val_loss: 0.6552 - val_accuracy: 0.6136\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6259 - accuracy: 0.6645 - val_loss: 0.6497 - val_accuracy: 0.6248\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6240 - accuracy: 0.6670 - val_loss: 0.6542 - val_accuracy: 0.6131\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6216 - accuracy: 0.6708 - val_loss: 0.6510 - val_accuracy: 0.6158\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6188 - accuracy: 0.6748 - val_loss: 0.6492 - val_accuracy: 0.6184\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6167 - accuracy: 0.6764 - val_loss: 0.6448 - val_accuracy: 0.6249\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6142 - accuracy: 0.6789 - val_loss: 0.6449 - val_accuracy: 0.6235\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6127 - accuracy: 0.6809 - val_loss: 0.6455 - val_accuracy: 0.6209\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6104 - accuracy: 0.6825 - val_loss: 0.6413 - val_accuracy: 0.6256\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6092 - accuracy: 0.6820 - val_loss: 0.6382 - val_accuracy: 0.6292\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6069 - accuracy: 0.6847 - val_loss: 0.6350 - val_accuracy: 0.6349\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6048 - accuracy: 0.6869 - val_loss: 0.6396 - val_accuracy: 0.6248\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6023 - accuracy: 0.6882 - val_loss: 0.6398 - val_accuracy: 0.6228\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6004 - accuracy: 0.6902 - val_loss: 0.6298 - val_accuracy: 0.6362\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5994 - accuracy: 0.6911 - val_loss: 0.6325 - val_accuracy: 0.6319\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5975 - accuracy: 0.6931 - val_loss: 0.6304 - val_accuracy: 0.6324\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5953 - accuracy: 0.6953 - val_loss: 0.6339 - val_accuracy: 0.6287\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5933 - accuracy: 0.6958 - val_loss: 0.6287 - val_accuracy: 0.6321\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5918 - accuracy: 0.6971 - val_loss: 0.6288 - val_accuracy: 0.6307\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5902 - accuracy: 0.6974 - val_loss: 0.6288 - val_accuracy: 0.6305\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.5887 - accuracy: 0.6991 - val_loss: 0.6250 - val_accuracy: 0.6345\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.5876 - accuracy: 0.7002 - val_loss: 0.6198 - val_accuracy: 0.6417\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5853 - accuracy: 0.7014 - val_loss: 0.6251 - val_accuracy: 0.6350\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5834 - accuracy: 0.7011 - val_loss: 0.6199 - val_accuracy: 0.6409\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5819 - accuracy: 0.7043 - val_loss: 0.6153 - val_accuracy: 0.6454\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5806 - accuracy: 0.7056 - val_loss: 0.6215 - val_accuracy: 0.6387\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5787 - accuracy: 0.7070 - val_loss: 0.6172 - val_accuracy: 0.6422\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5777 - accuracy: 0.7068 - val_loss: 0.6194 - val_accuracy: 0.6404\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5759 - accuracy: 0.7087 - val_loss: 0.6162 - val_accuracy: 0.6426\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5749 - accuracy: 0.7084 - val_loss: 0.6156 - val_accuracy: 0.6425\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5739 - accuracy: 0.7098 - val_loss: 0.6180 - val_accuracy: 0.6396\n",
      "\n",
      "Training model with sample_size_ratio=0.5...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.1 iterated over 41800 steps satisfies differential privacy with eps = 1.42 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "Epoch 1/50\n",
      "  1/836 [..............................] - ETA: 0s - loss: 0.8708 - accuracy: 0.3750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.7287 - accuracy: 0.4991 - val_loss: 0.6797 - val_accuracy: 0.5727\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.7132 - accuracy: 0.5168 - val_loss: 0.7076 - val_accuracy: 0.4515\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.7050 - accuracy: 0.5270 - val_loss: 0.7103 - val_accuracy: 0.4344\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.7032 - accuracy: 0.5337 - val_loss: 0.7123 - val_accuracy: 0.4223\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 664us/step - loss: 0.6981 - accuracy: 0.5438 - val_loss: 0.7054 - val_accuracy: 0.4444\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6957 - accuracy: 0.5471 - val_loss: 0.7042 - val_accuracy: 0.4537\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 667us/step - loss: 0.6897 - accuracy: 0.5552 - val_loss: 0.7021 - val_accuracy: 0.4722\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6878 - accuracy: 0.5615 - val_loss: 0.6978 - val_accuracy: 0.4971\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 669us/step - loss: 0.6844 - accuracy: 0.5678 - val_loss: 0.6940 - val_accuracy: 0.5221\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.6796 - accuracy: 0.5806 - val_loss: 0.6923 - val_accuracy: 0.5328\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 701us/step - loss: 0.6779 - accuracy: 0.5821 - val_loss: 0.6907 - val_accuracy: 0.5421\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.6754 - accuracy: 0.5879 - val_loss: 0.6913 - val_accuracy: 0.5412\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6767 - accuracy: 0.5883 - val_loss: 0.6903 - val_accuracy: 0.5455\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 682us/step - loss: 0.6702 - accuracy: 0.5961 - val_loss: 0.6898 - val_accuracy: 0.5484\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6708 - accuracy: 0.5989 - val_loss: 0.6869 - val_accuracy: 0.5594\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6665 - accuracy: 0.6049 - val_loss: 0.6847 - val_accuracy: 0.5665\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6667 - accuracy: 0.6076 - val_loss: 0.6840 - val_accuracy: 0.5699\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 672us/step - loss: 0.6630 - accuracy: 0.6149 - val_loss: 0.6789 - val_accuracy: 0.5894\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6626 - accuracy: 0.6172 - val_loss: 0.6767 - val_accuracy: 0.5976\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 675us/step - loss: 0.6599 - accuracy: 0.6214 - val_loss: 0.6793 - val_accuracy: 0.5900\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6596 - accuracy: 0.6234 - val_loss: 0.6759 - val_accuracy: 0.5986\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6571 - accuracy: 0.6254 - val_loss: 0.6758 - val_accuracy: 0.5974\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 675us/step - loss: 0.6549 - accuracy: 0.6309 - val_loss: 0.6763 - val_accuracy: 0.5949\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6551 - accuracy: 0.6285 - val_loss: 0.6728 - val_accuracy: 0.6029\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6520 - accuracy: 0.6348 - val_loss: 0.6702 - val_accuracy: 0.6105\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.6510 - accuracy: 0.6345 - val_loss: 0.6742 - val_accuracy: 0.5973\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 745us/step - loss: 0.6499 - accuracy: 0.6371 - val_loss: 0.6701 - val_accuracy: 0.6079\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 678us/step - loss: 0.6480 - accuracy: 0.6394 - val_loss: 0.6692 - val_accuracy: 0.6078\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6460 - accuracy: 0.6423 - val_loss: 0.6689 - val_accuracy: 0.6070\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6468 - accuracy: 0.6429 - val_loss: 0.6673 - val_accuracy: 0.6096\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6444 - accuracy: 0.6458 - val_loss: 0.6664 - val_accuracy: 0.6107\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 674us/step - loss: 0.6421 - accuracy: 0.6496 - val_loss: 0.6656 - val_accuracy: 0.6112\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6418 - accuracy: 0.6489 - val_loss: 0.6627 - val_accuracy: 0.6166\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 670us/step - loss: 0.6398 - accuracy: 0.6520 - val_loss: 0.6639 - val_accuracy: 0.6128\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6394 - accuracy: 0.6507 - val_loss: 0.6602 - val_accuracy: 0.6194\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.6384 - accuracy: 0.6515 - val_loss: 0.6611 - val_accuracy: 0.6161\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6369 - accuracy: 0.6536 - val_loss: 0.6600 - val_accuracy: 0.6179\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6362 - accuracy: 0.6543 - val_loss: 0.6570 - val_accuracy: 0.6241\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.6340 - accuracy: 0.6579 - val_loss: 0.6568 - val_accuracy: 0.6231\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6313 - accuracy: 0.6604 - val_loss: 0.6577 - val_accuracy: 0.6201\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6319 - accuracy: 0.6636 - val_loss: 0.6542 - val_accuracy: 0.6277\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6294 - accuracy: 0.6658 - val_loss: 0.6548 - val_accuracy: 0.6245\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6303 - accuracy: 0.6632 - val_loss: 0.6516 - val_accuracy: 0.6313\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6285 - accuracy: 0.6625 - val_loss: 0.6487 - val_accuracy: 0.6351\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6274 - accuracy: 0.6618 - val_loss: 0.6484 - val_accuracy: 0.6347\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6243 - accuracy: 0.6679 - val_loss: 0.6476 - val_accuracy: 0.6355\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6246 - accuracy: 0.6667 - val_loss: 0.6474 - val_accuracy: 0.6351\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6242 - accuracy: 0.6666 - val_loss: 0.6498 - val_accuracy: 0.6318\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 745us/step - loss: 0.6237 - accuracy: 0.6693 - val_loss: 0.6472 - val_accuracy: 0.6350\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6220 - accuracy: 0.6682 - val_loss: 0.6469 - val_accuracy: 0.6359\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.7262 - accuracy: 0.5240 - val_loss: 0.8254 - val_accuracy: 0.1180\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6980 - accuracy: 0.5313 - val_loss: 0.7537 - val_accuracy: 0.1730\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 687us/step - loss: 0.6931 - accuracy: 0.5399 - val_loss: 0.7279 - val_accuracy: 0.3134\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6865 - accuracy: 0.5563 - val_loss: 0.7171 - val_accuracy: 0.3774\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6840 - accuracy: 0.5583 - val_loss: 0.7097 - val_accuracy: 0.4144\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6802 - accuracy: 0.5720 - val_loss: 0.7061 - val_accuracy: 0.4453\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.6783 - accuracy: 0.5752 - val_loss: 0.7046 - val_accuracy: 0.4598\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6763 - accuracy: 0.5822 - val_loss: 0.7003 - val_accuracy: 0.4828\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6747 - accuracy: 0.5835 - val_loss: 0.6986 - val_accuracy: 0.4933\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6730 - accuracy: 0.5889 - val_loss: 0.6976 - val_accuracy: 0.4987\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 669us/step - loss: 0.6699 - accuracy: 0.5975 - val_loss: 0.6945 - val_accuracy: 0.5118\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 647us/step - loss: 0.6681 - accuracy: 0.6012 - val_loss: 0.6926 - val_accuracy: 0.5201\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6662 - accuracy: 0.6061 - val_loss: 0.6909 - val_accuracy: 0.5256\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6655 - accuracy: 0.6043 - val_loss: 0.6894 - val_accuracy: 0.5305\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 669us/step - loss: 0.6640 - accuracy: 0.6143 - val_loss: 0.6891 - val_accuracy: 0.5316\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6621 - accuracy: 0.6171 - val_loss: 0.6877 - val_accuracy: 0.5349\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6585 - accuracy: 0.6251 - val_loss: 0.6856 - val_accuracy: 0.5411\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6579 - accuracy: 0.6280 - val_loss: 0.6859 - val_accuracy: 0.5395\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6565 - accuracy: 0.6281 - val_loss: 0.6804 - val_accuracy: 0.5559\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 668us/step - loss: 0.6556 - accuracy: 0.6301 - val_loss: 0.6790 - val_accuracy: 0.5588\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6553 - accuracy: 0.6293 - val_loss: 0.6789 - val_accuracy: 0.5574\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 676us/step - loss: 0.6517 - accuracy: 0.6360 - val_loss: 0.6775 - val_accuracy: 0.5629\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6521 - accuracy: 0.6334 - val_loss: 0.6770 - val_accuracy: 0.5633\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6498 - accuracy: 0.6384 - val_loss: 0.6771 - val_accuracy: 0.5631\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6489 - accuracy: 0.6416 - val_loss: 0.6752 - val_accuracy: 0.5680\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 671us/step - loss: 0.6476 - accuracy: 0.6431 - val_loss: 0.6739 - val_accuracy: 0.5712\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6464 - accuracy: 0.6435 - val_loss: 0.6719 - val_accuracy: 0.5760\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6457 - accuracy: 0.6440 - val_loss: 0.6714 - val_accuracy: 0.5772\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6439 - accuracy: 0.6517 - val_loss: 0.6713 - val_accuracy: 0.5776\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 668us/step - loss: 0.6436 - accuracy: 0.6490 - val_loss: 0.6679 - val_accuracy: 0.5870\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6414 - accuracy: 0.6493 - val_loss: 0.6672 - val_accuracy: 0.5882\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6403 - accuracy: 0.6527 - val_loss: 0.6680 - val_accuracy: 0.5854\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.6399 - accuracy: 0.6552 - val_loss: 0.6667 - val_accuracy: 0.5885\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6398 - accuracy: 0.6527 - val_loss: 0.6629 - val_accuracy: 0.5974\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.6368 - accuracy: 0.6585 - val_loss: 0.6648 - val_accuracy: 0.5925\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.6356 - accuracy: 0.6623 - val_loss: 0.6667 - val_accuracy: 0.5863\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6355 - accuracy: 0.6558 - val_loss: 0.6639 - val_accuracy: 0.5939\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6342 - accuracy: 0.6635 - val_loss: 0.6616 - val_accuracy: 0.5992\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6331 - accuracy: 0.6604 - val_loss: 0.6613 - val_accuracy: 0.5999\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6311 - accuracy: 0.6666 - val_loss: 0.6617 - val_accuracy: 0.5975\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.6313 - accuracy: 0.6621 - val_loss: 0.6595 - val_accuracy: 0.6017\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.6293 - accuracy: 0.6647 - val_loss: 0.6597 - val_accuracy: 0.6007\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6290 - accuracy: 0.6689 - val_loss: 0.6606 - val_accuracy: 0.5987\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.6275 - accuracy: 0.6665 - val_loss: 0.6577 - val_accuracy: 0.6030\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6262 - accuracy: 0.6715 - val_loss: 0.6566 - val_accuracy: 0.6040\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6265 - accuracy: 0.6698 - val_loss: 0.6551 - val_accuracy: 0.6060\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.6251 - accuracy: 0.6729 - val_loss: 0.6542 - val_accuracy: 0.6068\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.6241 - accuracy: 0.6730 - val_loss: 0.6558 - val_accuracy: 0.6042\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6237 - accuracy: 0.6741 - val_loss: 0.6538 - val_accuracy: 0.6069\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6226 - accuracy: 0.6739 - val_loss: 0.6542 - val_accuracy: 0.6052\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6808 - accuracy: 0.5683 - val_loss: 0.6675 - val_accuracy: 0.6044\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 670us/step - loss: 0.6776 - accuracy: 0.5759 - val_loss: 0.6713 - val_accuracy: 0.5900\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6718 - accuracy: 0.5863 - val_loss: 0.6656 - val_accuracy: 0.6091\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6739 - accuracy: 0.5831 - val_loss: 0.6642 - val_accuracy: 0.6136\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6682 - accuracy: 0.5877 - val_loss: 0.6630 - val_accuracy: 0.6168\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.6663 - accuracy: 0.5944 - val_loss: 0.6607 - val_accuracy: 0.6286\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.6619 - accuracy: 0.6028 - val_loss: 0.6582 - val_accuracy: 0.6359\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6598 - accuracy: 0.6067 - val_loss: 0.6579 - val_accuracy: 0.6351\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6569 - accuracy: 0.6082 - val_loss: 0.6575 - val_accuracy: 0.6336\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6539 - accuracy: 0.6152 - val_loss: 0.6584 - val_accuracy: 0.6288\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 680us/step - loss: 0.6519 - accuracy: 0.6180 - val_loss: 0.6525 - val_accuracy: 0.6380\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6513 - accuracy: 0.6203 - val_loss: 0.6515 - val_accuracy: 0.6393\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6487 - accuracy: 0.6222 - val_loss: 0.6511 - val_accuracy: 0.6387\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.6457 - accuracy: 0.6296 - val_loss: 0.6524 - val_accuracy: 0.6337\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6443 - accuracy: 0.6309 - val_loss: 0.6458 - val_accuracy: 0.6450\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 676us/step - loss: 0.6427 - accuracy: 0.6333 - val_loss: 0.6475 - val_accuracy: 0.6407\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6419 - accuracy: 0.6359 - val_loss: 0.6461 - val_accuracy: 0.6423\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 680us/step - loss: 0.6405 - accuracy: 0.6346 - val_loss: 0.6469 - val_accuracy: 0.6414\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6393 - accuracy: 0.6376 - val_loss: 0.6475 - val_accuracy: 0.6403\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6377 - accuracy: 0.6385 - val_loss: 0.6415 - val_accuracy: 0.6467\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.6355 - accuracy: 0.6467 - val_loss: 0.6403 - val_accuracy: 0.6485\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6335 - accuracy: 0.6478 - val_loss: 0.6426 - val_accuracy: 0.6460\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6327 - accuracy: 0.6503 - val_loss: 0.6372 - val_accuracy: 0.6540\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 620us/step - loss: 0.6320 - accuracy: 0.6497 - val_loss: 0.6385 - val_accuracy: 0.6514\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6288 - accuracy: 0.6537 - val_loss: 0.6354 - val_accuracy: 0.6573\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.6270 - accuracy: 0.6568 - val_loss: 0.6352 - val_accuracy: 0.6572\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6264 - accuracy: 0.6547 - val_loss: 0.6364 - val_accuracy: 0.6548\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 617us/step - loss: 0.6249 - accuracy: 0.6566 - val_loss: 0.6316 - val_accuracy: 0.6596\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 620us/step - loss: 0.6244 - accuracy: 0.6570 - val_loss: 0.6319 - val_accuracy: 0.6585\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6225 - accuracy: 0.6622 - val_loss: 0.6322 - val_accuracy: 0.6571\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 664us/step - loss: 0.6231 - accuracy: 0.6604 - val_loss: 0.6319 - val_accuracy: 0.6558\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6199 - accuracy: 0.6637 - val_loss: 0.6255 - val_accuracy: 0.6619\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 669us/step - loss: 0.6202 - accuracy: 0.6619 - val_loss: 0.6314 - val_accuracy: 0.6538\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.6182 - accuracy: 0.6644 - val_loss: 0.6294 - val_accuracy: 0.6555\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6161 - accuracy: 0.6663 - val_loss: 0.6258 - val_accuracy: 0.6574\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6154 - accuracy: 0.6673 - val_loss: 0.6232 - val_accuracy: 0.6585\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.6134 - accuracy: 0.6722 - val_loss: 0.6265 - val_accuracy: 0.6554\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6142 - accuracy: 0.6697 - val_loss: 0.6228 - val_accuracy: 0.6575\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 678us/step - loss: 0.6103 - accuracy: 0.6732 - val_loss: 0.6228 - val_accuracy: 0.6572\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6100 - accuracy: 0.6757 - val_loss: 0.6235 - val_accuracy: 0.6551\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6110 - accuracy: 0.6706 - val_loss: 0.6225 - val_accuracy: 0.6562\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.6077 - accuracy: 0.6758 - val_loss: 0.6207 - val_accuracy: 0.6579\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.6076 - accuracy: 0.6757 - val_loss: 0.6203 - val_accuracy: 0.6579\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 721us/step - loss: 0.6076 - accuracy: 0.6761 - val_loss: 0.6187 - val_accuracy: 0.6597\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.6053 - accuracy: 0.6780 - val_loss: 0.6188 - val_accuracy: 0.6593\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6050 - accuracy: 0.6777 - val_loss: 0.6248 - val_accuracy: 0.6521\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6041 - accuracy: 0.6800 - val_loss: 0.6161 - val_accuracy: 0.6611\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6031 - accuracy: 0.6780 - val_loss: 0.6165 - val_accuracy: 0.6611\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 672us/step - loss: 0.6000 - accuracy: 0.6823 - val_loss: 0.6173 - val_accuracy: 0.6590\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6002 - accuracy: 0.6869 - val_loss: 0.6163 - val_accuracy: 0.6602\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.7531 - accuracy: 0.5187 - val_loss: 0.8754 - val_accuracy: 0.1173\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.7136 - accuracy: 0.5092 - val_loss: 0.7826 - val_accuracy: 0.1382\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.7049 - accuracy: 0.5090 - val_loss: 0.7484 - val_accuracy: 0.2049\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 707us/step - loss: 0.7001 - accuracy: 0.5108 - val_loss: 0.7359 - val_accuracy: 0.2473\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.6956 - accuracy: 0.5242 - val_loss: 0.7290 - val_accuracy: 0.3064\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6947 - accuracy: 0.5288 - val_loss: 0.7231 - val_accuracy: 0.3387\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 678us/step - loss: 0.6915 - accuracy: 0.5335 - val_loss: 0.7214 - val_accuracy: 0.3519\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 674us/step - loss: 0.6905 - accuracy: 0.5379 - val_loss: 0.7176 - val_accuracy: 0.3721\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6870 - accuracy: 0.5489 - val_loss: 0.7158 - val_accuracy: 0.3854\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.6869 - accuracy: 0.5454 - val_loss: 0.7137 - val_accuracy: 0.3988\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.6847 - accuracy: 0.5550 - val_loss: 0.7105 - val_accuracy: 0.4177\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6830 - accuracy: 0.5608 - val_loss: 0.7084 - val_accuracy: 0.4299\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6824 - accuracy: 0.5618 - val_loss: 0.7069 - val_accuracy: 0.4386\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.6791 - accuracy: 0.5724 - val_loss: 0.7063 - val_accuracy: 0.4472\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6776 - accuracy: 0.5793 - val_loss: 0.7015 - val_accuracy: 0.4712\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6766 - accuracy: 0.5795 - val_loss: 0.6994 - val_accuracy: 0.4852\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 685us/step - loss: 0.6736 - accuracy: 0.5851 - val_loss: 0.6977 - val_accuracy: 0.4959\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 736us/step - loss: 0.6727 - accuracy: 0.5912 - val_loss: 0.6941 - val_accuracy: 0.5128\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 667us/step - loss: 0.6715 - accuracy: 0.5977 - val_loss: 0.6946 - val_accuracy: 0.5120\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 674us/step - loss: 0.6700 - accuracy: 0.5977 - val_loss: 0.6929 - val_accuracy: 0.5187\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6685 - accuracy: 0.6043 - val_loss: 0.6921 - val_accuracy: 0.5254\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 670us/step - loss: 0.6677 - accuracy: 0.6028 - val_loss: 0.6950 - val_accuracy: 0.5169\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6660 - accuracy: 0.6084 - val_loss: 0.6895 - val_accuracy: 0.5342\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6643 - accuracy: 0.6088 - val_loss: 0.6897 - val_accuracy: 0.5321\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6642 - accuracy: 0.6121 - val_loss: 0.6875 - val_accuracy: 0.5380\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 671us/step - loss: 0.6617 - accuracy: 0.6173 - val_loss: 0.6882 - val_accuracy: 0.5372\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6621 - accuracy: 0.6174 - val_loss: 0.6854 - val_accuracy: 0.5451\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.6588 - accuracy: 0.6271 - val_loss: 0.6838 - val_accuracy: 0.5496\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6580 - accuracy: 0.6253 - val_loss: 0.6826 - val_accuracy: 0.5539\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6566 - accuracy: 0.6312 - val_loss: 0.6793 - val_accuracy: 0.5638\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.6553 - accuracy: 0.6331 - val_loss: 0.6783 - val_accuracy: 0.5682\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6549 - accuracy: 0.6326 - val_loss: 0.6802 - val_accuracy: 0.5643\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.6531 - accuracy: 0.6342 - val_loss: 0.6768 - val_accuracy: 0.5733\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6524 - accuracy: 0.6324 - val_loss: 0.6743 - val_accuracy: 0.5814\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.6501 - accuracy: 0.6408 - val_loss: 0.6742 - val_accuracy: 0.5840\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6496 - accuracy: 0.6436 - val_loss: 0.6705 - val_accuracy: 0.5943\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6480 - accuracy: 0.6391 - val_loss: 0.6698 - val_accuracy: 0.5968\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6465 - accuracy: 0.6456 - val_loss: 0.6725 - val_accuracy: 0.5904\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6446 - accuracy: 0.6498 - val_loss: 0.6685 - val_accuracy: 0.6008\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6443 - accuracy: 0.6500 - val_loss: 0.6676 - val_accuracy: 0.6032\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6428 - accuracy: 0.6544 - val_loss: 0.6660 - val_accuracy: 0.6063\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6422 - accuracy: 0.6493 - val_loss: 0.6662 - val_accuracy: 0.6054\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6409 - accuracy: 0.6542 - val_loss: 0.6644 - val_accuracy: 0.6102\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6398 - accuracy: 0.6551 - val_loss: 0.6647 - val_accuracy: 0.6094\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6393 - accuracy: 0.6549 - val_loss: 0.6638 - val_accuracy: 0.6110\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 685us/step - loss: 0.6360 - accuracy: 0.6628 - val_loss: 0.6626 - val_accuracy: 0.6132\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.6358 - accuracy: 0.6580 - val_loss: 0.6601 - val_accuracy: 0.6195\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6346 - accuracy: 0.6613 - val_loss: 0.6597 - val_accuracy: 0.6199\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.6334 - accuracy: 0.6627 - val_loss: 0.6590 - val_accuracy: 0.6198\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6325 - accuracy: 0.6648 - val_loss: 0.6566 - val_accuracy: 0.6253\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 720us/step - loss: 0.7437 - accuracy: 0.4508 - val_loss: 0.6801 - val_accuracy: 0.5614\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.7249 - accuracy: 0.4572 - val_loss: 0.7140 - val_accuracy: 0.3933\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.7203 - accuracy: 0.4652 - val_loss: 0.7207 - val_accuracy: 0.3403\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.7165 - accuracy: 0.4774 - val_loss: 0.7250 - val_accuracy: 0.3033\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 682us/step - loss: 0.7103 - accuracy: 0.4882 - val_loss: 0.7216 - val_accuracy: 0.3090\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 647us/step - loss: 0.7085 - accuracy: 0.4890 - val_loss: 0.7185 - val_accuracy: 0.3132\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 813us/step - loss: 0.7038 - accuracy: 0.5009 - val_loss: 0.7139 - val_accuracy: 0.3313\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.7021 - accuracy: 0.5060 - val_loss: 0.7144 - val_accuracy: 0.3314\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6997 - accuracy: 0.5114 - val_loss: 0.7137 - val_accuracy: 0.3385\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 681us/step - loss: 0.6964 - accuracy: 0.5181 - val_loss: 0.7080 - val_accuracy: 0.3791\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.6936 - accuracy: 0.5237 - val_loss: 0.7072 - val_accuracy: 0.3964\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6932 - accuracy: 0.5269 - val_loss: 0.7055 - val_accuracy: 0.4198\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.6902 - accuracy: 0.5317 - val_loss: 0.7041 - val_accuracy: 0.4385\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.6892 - accuracy: 0.5368 - val_loss: 0.7018 - val_accuracy: 0.4642\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6871 - accuracy: 0.5440 - val_loss: 0.7021 - val_accuracy: 0.4710\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 745us/step - loss: 0.6850 - accuracy: 0.5505 - val_loss: 0.7008 - val_accuracy: 0.4825\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 746us/step - loss: 0.6840 - accuracy: 0.5491 - val_loss: 0.6974 - val_accuracy: 0.5131\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.6822 - accuracy: 0.5548 - val_loss: 0.6975 - val_accuracy: 0.5158\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6812 - accuracy: 0.5576 - val_loss: 0.6947 - val_accuracy: 0.5368\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.6804 - accuracy: 0.5641 - val_loss: 0.6942 - val_accuracy: 0.5434\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6791 - accuracy: 0.5652 - val_loss: 0.6922 - val_accuracy: 0.5551\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6786 - accuracy: 0.5692 - val_loss: 0.6916 - val_accuracy: 0.5584\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6772 - accuracy: 0.5677 - val_loss: 0.6932 - val_accuracy: 0.5499\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6751 - accuracy: 0.5786 - val_loss: 0.6920 - val_accuracy: 0.5559\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6731 - accuracy: 0.5845 - val_loss: 0.6878 - val_accuracy: 0.5762\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.6734 - accuracy: 0.5871 - val_loss: 0.6888 - val_accuracy: 0.5708\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 744us/step - loss: 0.6717 - accuracy: 0.5909 - val_loss: 0.6863 - val_accuracy: 0.5811\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.6710 - accuracy: 0.5917 - val_loss: 0.6841 - val_accuracy: 0.5917\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 673us/step - loss: 0.6692 - accuracy: 0.5972 - val_loss: 0.6826 - val_accuracy: 0.5973\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6671 - accuracy: 0.6026 - val_loss: 0.6821 - val_accuracy: 0.5985\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 678us/step - loss: 0.6665 - accuracy: 0.6000 - val_loss: 0.6803 - val_accuracy: 0.6042\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.6653 - accuracy: 0.6105 - val_loss: 0.6802 - val_accuracy: 0.6035\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6648 - accuracy: 0.6062 - val_loss: 0.6824 - val_accuracy: 0.5926\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.6645 - accuracy: 0.6082 - val_loss: 0.6782 - val_accuracy: 0.6077\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.6627 - accuracy: 0.6149 - val_loss: 0.6770 - val_accuracy: 0.6123\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 690us/step - loss: 0.6611 - accuracy: 0.6188 - val_loss: 0.6772 - val_accuracy: 0.6093\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6598 - accuracy: 0.6212 - val_loss: 0.6749 - val_accuracy: 0.6157\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6594 - accuracy: 0.6219 - val_loss: 0.6753 - val_accuracy: 0.6131\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6570 - accuracy: 0.6266 - val_loss: 0.6755 - val_accuracy: 0.6089\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6564 - accuracy: 0.6318 - val_loss: 0.6744 - val_accuracy: 0.6117\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 668us/step - loss: 0.6546 - accuracy: 0.6321 - val_loss: 0.6717 - val_accuracy: 0.6210\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6554 - accuracy: 0.6308 - val_loss: 0.6734 - val_accuracy: 0.6125\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.6533 - accuracy: 0.6339 - val_loss: 0.6726 - val_accuracy: 0.6145\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 746us/step - loss: 0.6523 - accuracy: 0.6349 - val_loss: 0.6728 - val_accuracy: 0.6120\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 671us/step - loss: 0.6511 - accuracy: 0.6375 - val_loss: 0.6689 - val_accuracy: 0.6241\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.6510 - accuracy: 0.6416 - val_loss: 0.6679 - val_accuracy: 0.6257\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6502 - accuracy: 0.6435 - val_loss: 0.6661 - val_accuracy: 0.6299\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 678us/step - loss: 0.6483 - accuracy: 0.6472 - val_loss: 0.6629 - val_accuracy: 0.6376\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6479 - accuracy: 0.6433 - val_loss: 0.6650 - val_accuracy: 0.6298\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6460 - accuracy: 0.6474 - val_loss: 0.6636 - val_accuracy: 0.6313\n",
      "\n",
      "Training model with sample_size_ratio=0.1...\n",
      "DP-SGD with sampling rate = 0.598% and noise_multiplier = 1.1 iterated over 8360 steps satisfies differential privacy with eps = 3.3 and delta = 1e-05.\n",
      "The optimal RDP order is 8.0.\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.4856 - val_loss: 0.6839 - val_accuracy: 0.5407\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.4961 - val_loss: 0.6937 - val_accuracy: 0.4860\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.4950 - val_loss: 0.7002 - val_accuracy: 0.4601\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.4953 - val_loss: 0.7067 - val_accuracy: 0.4362\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.5024 - val_loss: 0.7117 - val_accuracy: 0.4163\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.4983 - val_loss: 0.7169 - val_accuracy: 0.4023\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.5121 - val_loss: 0.7203 - val_accuracy: 0.3909\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7075 - accuracy: 0.5140 - val_loss: 0.7227 - val_accuracy: 0.3803\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.5021 - val_loss: 0.7244 - val_accuracy: 0.3744\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7134 - accuracy: 0.4957 - val_loss: 0.7255 - val_accuracy: 0.3700\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.5159 - val_loss: 0.7262 - val_accuracy: 0.3666\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.5138 - val_loss: 0.7264 - val_accuracy: 0.3657\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.5213 - val_loss: 0.7258 - val_accuracy: 0.3688\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.5142 - val_loss: 0.7266 - val_accuracy: 0.3633\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.5125 - val_loss: 0.7279 - val_accuracy: 0.3576\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.5164 - val_loss: 0.7284 - val_accuracy: 0.3565\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7006 - accuracy: 0.5148 - val_loss: 0.7278 - val_accuracy: 0.3612\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.5185 - val_loss: 0.7273 - val_accuracy: 0.3663\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.5136 - val_loss: 0.7266 - val_accuracy: 0.3722\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5187 - val_loss: 0.7256 - val_accuracy: 0.3815\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.5125 - val_loss: 0.7251 - val_accuracy: 0.3858\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.5112 - val_loss: 0.7250 - val_accuracy: 0.3884\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5321 - val_loss: 0.7246 - val_accuracy: 0.3921\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5372 - val_loss: 0.7234 - val_accuracy: 0.4032\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.5351 - val_loss: 0.7226 - val_accuracy: 0.4110\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5327 - val_loss: 0.7216 - val_accuracy: 0.4189\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5237 - val_loss: 0.7217 - val_accuracy: 0.4204\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5350 - val_loss: 0.7212 - val_accuracy: 0.4236\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5305 - val_loss: 0.7207 - val_accuracy: 0.4254\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.5321 - val_loss: 0.7202 - val_accuracy: 0.4276\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5372 - val_loss: 0.7199 - val_accuracy: 0.4288\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5415 - val_loss: 0.7192 - val_accuracy: 0.4296\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5308 - val_loss: 0.7184 - val_accuracy: 0.4354\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5450 - val_loss: 0.7178 - val_accuracy: 0.4380\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5359 - val_loss: 0.7166 - val_accuracy: 0.4443\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5323 - val_loss: 0.7150 - val_accuracy: 0.4520\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5372 - val_loss: 0.7152 - val_accuracy: 0.4494\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5449 - val_loss: 0.7155 - val_accuracy: 0.4481\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5488 - val_loss: 0.7152 - val_accuracy: 0.4489\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5540 - val_loss: 0.7142 - val_accuracy: 0.4533\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5540 - val_loss: 0.7135 - val_accuracy: 0.4560\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5436 - val_loss: 0.7139 - val_accuracy: 0.4552\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5492 - val_loss: 0.7128 - val_accuracy: 0.4598\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5495 - val_loss: 0.7125 - val_accuracy: 0.4615\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5665 - val_loss: 0.7130 - val_accuracy: 0.4596\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5557 - val_loss: 0.7112 - val_accuracy: 0.4654\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5409 - val_loss: 0.7108 - val_accuracy: 0.4674\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5436 - val_loss: 0.7107 - val_accuracy: 0.4683\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5589 - val_loss: 0.7094 - val_accuracy: 0.4729\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5555 - val_loss: 0.7090 - val_accuracy: 0.4746\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.4955 - val_loss: 0.6149 - val_accuracy: 0.8087\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.5166 - val_loss: 0.6379 - val_accuracy: 0.7165\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.5279 - val_loss: 0.6564 - val_accuracy: 0.6491\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.5280 - val_loss: 0.6698 - val_accuracy: 0.5944\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.5327 - val_loss: 0.6779 - val_accuracy: 0.5584\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.5383 - val_loss: 0.6858 - val_accuracy: 0.5335\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5422 - val_loss: 0.6902 - val_accuracy: 0.5208\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5437 - val_loss: 0.6937 - val_accuracy: 0.5071\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5338 - val_loss: 0.6965 - val_accuracy: 0.4915\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5490 - val_loss: 0.6992 - val_accuracy: 0.4813\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5497 - val_loss: 0.7007 - val_accuracy: 0.4789\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5542 - val_loss: 0.7009 - val_accuracy: 0.4803\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5493 - val_loss: 0.7013 - val_accuracy: 0.4803\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5499 - val_loss: 0.7008 - val_accuracy: 0.4829\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5699 - val_loss: 0.6998 - val_accuracy: 0.4861\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5585 - val_loss: 0.7001 - val_accuracy: 0.4873\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5636 - val_loss: 0.6998 - val_accuracy: 0.4893\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5727 - val_loss: 0.6990 - val_accuracy: 0.4943\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5699 - val_loss: 0.6976 - val_accuracy: 0.4992\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5727 - val_loss: 0.6976 - val_accuracy: 0.5022\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5721 - val_loss: 0.6981 - val_accuracy: 0.5022\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5621 - val_loss: 0.6966 - val_accuracy: 0.5086\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5757 - val_loss: 0.6957 - val_accuracy: 0.5120\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5748 - val_loss: 0.6970 - val_accuracy: 0.5096\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.5807 - val_loss: 0.6966 - val_accuracy: 0.5119\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5770 - val_loss: 0.6946 - val_accuracy: 0.5165\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.5794 - val_loss: 0.6942 - val_accuracy: 0.5177\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.5811 - val_loss: 0.6937 - val_accuracy: 0.5181\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.5895 - val_loss: 0.6924 - val_accuracy: 0.5198\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.5920 - val_loss: 0.6922 - val_accuracy: 0.5203\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5892 - val_loss: 0.6913 - val_accuracy: 0.5220\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.5944 - val_loss: 0.6908 - val_accuracy: 0.5233\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6745 - accuracy: 0.5873 - val_loss: 0.6898 - val_accuracy: 0.5258\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5972 - val_loss: 0.6886 - val_accuracy: 0.5278\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.5951 - val_loss: 0.6872 - val_accuracy: 0.5307\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.5987 - val_loss: 0.6866 - val_accuracy: 0.5322\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.5966 - val_loss: 0.6872 - val_accuracy: 0.5323\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.5901 - val_loss: 0.6852 - val_accuracy: 0.5367\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.5920 - val_loss: 0.6848 - val_accuracy: 0.5377\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.5976 - val_loss: 0.6853 - val_accuracy: 0.5370\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.5912 - val_loss: 0.6854 - val_accuracy: 0.5379\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.6086 - val_loss: 0.6850 - val_accuracy: 0.5393\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.6093 - val_loss: 0.6847 - val_accuracy: 0.5409\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.6067 - val_loss: 0.6841 - val_accuracy: 0.5426\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6108 - val_loss: 0.6846 - val_accuracy: 0.5422\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.6095 - val_loss: 0.6847 - val_accuracy: 0.5422\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.6045 - val_loss: 0.6839 - val_accuracy: 0.5437\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.6092 - val_loss: 0.6842 - val_accuracy: 0.5427\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6060 - val_loss: 0.6833 - val_accuracy: 0.5447\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.6202 - val_loss: 0.6835 - val_accuracy: 0.5442\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7247 - accuracy: 0.4639 - val_loss: 0.8164 - val_accuracy: 0.1215\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.4615 - val_loss: 0.8024 - val_accuracy: 0.1320\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.4615 - val_loss: 0.7918 - val_accuracy: 0.1422\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.4673 - val_loss: 0.7840 - val_accuracy: 0.1480\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.4559 - val_loss: 0.7764 - val_accuracy: 0.1551\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7176 - accuracy: 0.4619 - val_loss: 0.7714 - val_accuracy: 0.1596\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.4561 - val_loss: 0.7668 - val_accuracy: 0.1652\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.4600 - val_loss: 0.7627 - val_accuracy: 0.1703\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7162 - accuracy: 0.4615 - val_loss: 0.7597 - val_accuracy: 0.1736\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.4774 - val_loss: 0.7570 - val_accuracy: 0.1764\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.4721 - val_loss: 0.7547 - val_accuracy: 0.1795\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.4718 - val_loss: 0.7524 - val_accuracy: 0.1833\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.4824 - val_loss: 0.7508 - val_accuracy: 0.1868\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.4809 - val_loss: 0.7490 - val_accuracy: 0.1903\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.4707 - val_loss: 0.7483 - val_accuracy: 0.1909\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.4834 - val_loss: 0.7458 - val_accuracy: 0.1997\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.4804 - val_loss: 0.7448 - val_accuracy: 0.2017\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.4923 - val_loss: 0.7428 - val_accuracy: 0.2096\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.4978 - val_loss: 0.7419 - val_accuracy: 0.2139\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.5000 - val_loss: 0.7408 - val_accuracy: 0.2205\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.4935 - val_loss: 0.7397 - val_accuracy: 0.2270\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.5022 - val_loss: 0.7386 - val_accuracy: 0.2351\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.5075 - val_loss: 0.7374 - val_accuracy: 0.2418\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.5045 - val_loss: 0.7362 - val_accuracy: 0.2506\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.5002 - val_loss: 0.7358 - val_accuracy: 0.2542\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.5069 - val_loss: 0.7349 - val_accuracy: 0.2616\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.4998 - val_loss: 0.7337 - val_accuracy: 0.2698\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.5071 - val_loss: 0.7324 - val_accuracy: 0.2818\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5084 - val_loss: 0.7317 - val_accuracy: 0.2904\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.5170 - val_loss: 0.7306 - val_accuracy: 0.2998\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5207 - val_loss: 0.7304 - val_accuracy: 0.3040\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5260 - val_loss: 0.7301 - val_accuracy: 0.3128\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.5204 - val_loss: 0.7289 - val_accuracy: 0.3235\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5256 - val_loss: 0.7282 - val_accuracy: 0.3313\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5262 - val_loss: 0.7274 - val_accuracy: 0.3390\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5279 - val_loss: 0.7263 - val_accuracy: 0.3501\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5406 - val_loss: 0.7248 - val_accuracy: 0.3601\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5404 - val_loss: 0.7247 - val_accuracy: 0.3637\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5479 - val_loss: 0.7240 - val_accuracy: 0.3702\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5505 - val_loss: 0.7223 - val_accuracy: 0.3833\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5479 - val_loss: 0.7213 - val_accuracy: 0.3914\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5531 - val_loss: 0.7203 - val_accuracy: 0.3983\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5570 - val_loss: 0.7188 - val_accuracy: 0.4086\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5533 - val_loss: 0.7182 - val_accuracy: 0.4145\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5578 - val_loss: 0.7183 - val_accuracy: 0.4161\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5520 - val_loss: 0.7174 - val_accuracy: 0.4225\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5544 - val_loss: 0.7167 - val_accuracy: 0.4282\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5649 - val_loss: 0.7165 - val_accuracy: 0.4313\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5643 - val_loss: 0.7161 - val_accuracy: 0.4349\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5716 - val_loss: 0.7152 - val_accuracy: 0.4421\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7289 - accuracy: 0.5036 - val_loss: 0.5731 - val_accuracy: 0.8736\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.5163 - val_loss: 0.5977 - val_accuracy: 0.8656\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.5185 - val_loss: 0.6192 - val_accuracy: 0.8293\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7116 - accuracy: 0.5275 - val_loss: 0.6376 - val_accuracy: 0.7750\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.5398 - val_loss: 0.6518 - val_accuracy: 0.7197\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.5325 - val_loss: 0.6642 - val_accuracy: 0.6705\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.5422 - val_loss: 0.6739 - val_accuracy: 0.6289\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5613 - val_loss: 0.6819 - val_accuracy: 0.5955\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5432 - val_loss: 0.6884 - val_accuracy: 0.5686\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5609 - val_loss: 0.6937 - val_accuracy: 0.5471\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5656 - val_loss: 0.6990 - val_accuracy: 0.5268\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5647 - val_loss: 0.7026 - val_accuracy: 0.5088\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5650 - val_loss: 0.7053 - val_accuracy: 0.4980\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5645 - val_loss: 0.7065 - val_accuracy: 0.4925\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5606 - val_loss: 0.7067 - val_accuracy: 0.4922\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5533 - val_loss: 0.7081 - val_accuracy: 0.4881\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5671 - val_loss: 0.7090 - val_accuracy: 0.4835\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5707 - val_loss: 0.7088 - val_accuracy: 0.4841\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5686 - val_loss: 0.7087 - val_accuracy: 0.4850\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5794 - val_loss: 0.7094 - val_accuracy: 0.4824\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5587 - val_loss: 0.7095 - val_accuracy: 0.4820\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5708 - val_loss: 0.7100 - val_accuracy: 0.4804\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5647 - val_loss: 0.7105 - val_accuracy: 0.4798\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5721 - val_loss: 0.7099 - val_accuracy: 0.4814\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5671 - val_loss: 0.7096 - val_accuracy: 0.4830\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5755 - val_loss: 0.7088 - val_accuracy: 0.4857\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5826 - val_loss: 0.7101 - val_accuracy: 0.4823\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5753 - val_loss: 0.7087 - val_accuracy: 0.4868\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5705 - val_loss: 0.7073 - val_accuracy: 0.4914\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5716 - val_loss: 0.7067 - val_accuracy: 0.4933\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5768 - val_loss: 0.7065 - val_accuracy: 0.4947\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.5791 - val_loss: 0.7065 - val_accuracy: 0.4949\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.5759 - val_loss: 0.7062 - val_accuracy: 0.4959\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5843 - val_loss: 0.7054 - val_accuracy: 0.4988\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5690 - val_loss: 0.7039 - val_accuracy: 0.5036\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5781 - val_loss: 0.7040 - val_accuracy: 0.5038\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.5959 - val_loss: 0.7035 - val_accuracy: 0.5051\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5796 - val_loss: 0.7033 - val_accuracy: 0.5062\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5800 - val_loss: 0.7022 - val_accuracy: 0.5091\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.5821 - val_loss: 0.7020 - val_accuracy: 0.5096\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.5882 - val_loss: 0.7015 - val_accuracy: 0.5110\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5871 - val_loss: 0.7014 - val_accuracy: 0.5122\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5946 - val_loss: 0.7007 - val_accuracy: 0.5164\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5888 - val_loss: 0.7007 - val_accuracy: 0.5164\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.5966 - val_loss: 0.7000 - val_accuracy: 0.5193\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.5895 - val_loss: 0.7000 - val_accuracy: 0.5193\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.6004 - val_loss: 0.7002 - val_accuracy: 0.5194\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.5983 - val_loss: 0.6993 - val_accuracy: 0.5229\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.5920 - val_loss: 0.6993 - val_accuracy: 0.5238\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.5920 - val_loss: 0.6987 - val_accuracy: 0.5268\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7337 - accuracy: 0.5136 - val_loss: 0.8885 - val_accuracy: 0.1173\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.5224 - val_loss: 0.8418 - val_accuracy: 0.1198\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.5275 - val_loss: 0.8102 - val_accuracy: 0.1235\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.5234 - val_loss: 0.7867 - val_accuracy: 0.1334\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.5282 - val_loss: 0.7690 - val_accuracy: 0.1518\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.5234 - val_loss: 0.7569 - val_accuracy: 0.1779\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.5221 - val_loss: 0.7489 - val_accuracy: 0.2030\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5359 - val_loss: 0.7410 - val_accuracy: 0.2323\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.5381 - val_loss: 0.7378 - val_accuracy: 0.2463\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.5312 - val_loss: 0.7337 - val_accuracy: 0.2658\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.5406 - val_loss: 0.7292 - val_accuracy: 0.2865\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5492 - val_loss: 0.7283 - val_accuracy: 0.2923\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5419 - val_loss: 0.7260 - val_accuracy: 0.3038\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5415 - val_loss: 0.7228 - val_accuracy: 0.3248\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5486 - val_loss: 0.7241 - val_accuracy: 0.3223\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5441 - val_loss: 0.7219 - val_accuracy: 0.3377\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5566 - val_loss: 0.7207 - val_accuracy: 0.3468\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5593 - val_loss: 0.7184 - val_accuracy: 0.3615\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5613 - val_loss: 0.7183 - val_accuracy: 0.3670\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5598 - val_loss: 0.7184 - val_accuracy: 0.3695\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5508 - val_loss: 0.7162 - val_accuracy: 0.3822\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5574 - val_loss: 0.7160 - val_accuracy: 0.3880\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5697 - val_loss: 0.7156 - val_accuracy: 0.3915\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5602 - val_loss: 0.7136 - val_accuracy: 0.4036\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5622 - val_loss: 0.7130 - val_accuracy: 0.4063\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5703 - val_loss: 0.7126 - val_accuracy: 0.4086\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5665 - val_loss: 0.7110 - val_accuracy: 0.4188\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.5650 - val_loss: 0.7096 - val_accuracy: 0.4263\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5632 - val_loss: 0.7097 - val_accuracy: 0.4277\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5826 - val_loss: 0.7085 - val_accuracy: 0.4349\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5772 - val_loss: 0.7074 - val_accuracy: 0.4408\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.5785 - val_loss: 0.7048 - val_accuracy: 0.4531\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.5755 - val_loss: 0.7054 - val_accuracy: 0.4522\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5802 - val_loss: 0.7061 - val_accuracy: 0.4502\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.5836 - val_loss: 0.7061 - val_accuracy: 0.4533\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5828 - val_loss: 0.7062 - val_accuracy: 0.4560\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6779 - accuracy: 0.5761 - val_loss: 0.7062 - val_accuracy: 0.4580\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.5779 - val_loss: 0.7055 - val_accuracy: 0.4632\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.5890 - val_loss: 0.7039 - val_accuracy: 0.4710\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5978 - val_loss: 0.7034 - val_accuracy: 0.4747\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5766 - val_loss: 0.7023 - val_accuracy: 0.4819\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.5809 - val_loss: 0.7016 - val_accuracy: 0.4841\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.5817 - val_loss: 0.7013 - val_accuracy: 0.4856\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.5860 - val_loss: 0.7004 - val_accuracy: 0.4910\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5836 - val_loss: 0.6997 - val_accuracy: 0.4936\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.5931 - val_loss: 0.6994 - val_accuracy: 0.4954\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5895 - val_loss: 0.6994 - val_accuracy: 0.4963\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.5809 - val_loss: 0.6987 - val_accuracy: 0.4993\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.5899 - val_loss: 0.6979 - val_accuracy: 0.5032\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.5914 - val_loss: 0.6985 - val_accuracy: 0.5023\n",
      "\n",
      "Training model with sample_size_ratio=0.05...\n",
      "DP-SGD with sampling rate = 1.2% and noise_multiplier = 1.1 iterated over 4180 steps satisfies differential privacy with eps = 4.84 and delta = 1e-05.\n",
      "The optimal RDP order is 6.0.\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.7756 - accuracy: 0.5073 - val_loss: 1.0356 - val_accuracy: 0.1177\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7638 - accuracy: 0.5069 - val_loss: 1.0011 - val_accuracy: 0.1180\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7568 - accuracy: 0.5047 - val_loss: 0.9700 - val_accuracy: 0.1192\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7456 - accuracy: 0.5103 - val_loss: 0.9421 - val_accuracy: 0.1197\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7412 - accuracy: 0.5013 - val_loss: 0.9171 - val_accuracy: 0.1200\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7334 - accuracy: 0.5047 - val_loss: 0.8953 - val_accuracy: 0.1205\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7256 - accuracy: 0.5043 - val_loss: 0.8756 - val_accuracy: 0.1219\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.5084 - val_loss: 0.8585 - val_accuracy: 0.1231\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7185 - accuracy: 0.5028 - val_loss: 0.8430 - val_accuracy: 0.1242\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.5103 - val_loss: 0.8289 - val_accuracy: 0.1258\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.4953 - val_loss: 0.8161 - val_accuracy: 0.1281\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.5088 - val_loss: 0.8049 - val_accuracy: 0.1316\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7112 - accuracy: 0.5114 - val_loss: 0.7949 - val_accuracy: 0.1371\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7073 - accuracy: 0.5148 - val_loss: 0.7856 - val_accuracy: 0.1431\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.5077 - val_loss: 0.7768 - val_accuracy: 0.1524\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.5121 - val_loss: 0.7694 - val_accuracy: 0.1624\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.5200 - val_loss: 0.7634 - val_accuracy: 0.1696\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.5155 - val_loss: 0.7567 - val_accuracy: 0.1785\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.5118 - val_loss: 0.7513 - val_accuracy: 0.1851\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.5170 - val_loss: 0.7462 - val_accuracy: 0.1962\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.5226 - val_loss: 0.7415 - val_accuracy: 0.2093\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.5200 - val_loss: 0.7370 - val_accuracy: 0.2236\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.5185 - val_loss: 0.7331 - val_accuracy: 0.2394\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.5159 - val_loss: 0.7299 - val_accuracy: 0.2549\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.5140 - val_loss: 0.7265 - val_accuracy: 0.2715\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.5193 - val_loss: 0.7234 - val_accuracy: 0.2892\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.5114 - val_loss: 0.7204 - val_accuracy: 0.3108\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5252 - val_loss: 0.7175 - val_accuracy: 0.3284\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.5226 - val_loss: 0.7151 - val_accuracy: 0.3440\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5166 - val_loss: 0.7128 - val_accuracy: 0.3561\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5372 - val_loss: 0.7110 - val_accuracy: 0.3686\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5477 - val_loss: 0.7093 - val_accuracy: 0.3785\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5301 - val_loss: 0.7080 - val_accuracy: 0.3881\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.5256 - val_loss: 0.7065 - val_accuracy: 0.3964\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5338 - val_loss: 0.7047 - val_accuracy: 0.4097\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5492 - val_loss: 0.7033 - val_accuracy: 0.4209\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5211 - val_loss: 0.7018 - val_accuracy: 0.4324\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5267 - val_loss: 0.7004 - val_accuracy: 0.4439\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5379 - val_loss: 0.6998 - val_accuracy: 0.4470\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5421 - val_loss: 0.6991 - val_accuracy: 0.4533\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5368 - val_loss: 0.6976 - val_accuracy: 0.4651\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5450 - val_loss: 0.6965 - val_accuracy: 0.4747\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5454 - val_loss: 0.6951 - val_accuracy: 0.4851\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5518 - val_loss: 0.6941 - val_accuracy: 0.4944\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5533 - val_loss: 0.6936 - val_accuracy: 0.4975\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5533 - val_loss: 0.6928 - val_accuracy: 0.5056\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5540 - val_loss: 0.6917 - val_accuracy: 0.5153\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5465 - val_loss: 0.6912 - val_accuracy: 0.5191\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5492 - val_loss: 0.6904 - val_accuracy: 0.5269\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5533 - val_loss: 0.6901 - val_accuracy: 0.5284\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.8771 - accuracy: 0.5050 - val_loss: 1.2522 - val_accuracy: 0.1188\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.8394 - accuracy: 0.5054 - val_loss: 1.1545 - val_accuracy: 0.1192\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.8017 - accuracy: 0.5043 - val_loss: 1.0737 - val_accuracy: 0.1198\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7800 - accuracy: 0.5054 - val_loss: 1.0071 - val_accuracy: 0.1210\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7603 - accuracy: 0.5054 - val_loss: 0.9546 - val_accuracy: 0.1219\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7447 - accuracy: 0.5002 - val_loss: 0.9111 - val_accuracy: 0.1240\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7341 - accuracy: 0.4979 - val_loss: 0.8767 - val_accuracy: 0.1262\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7307 - accuracy: 0.4849 - val_loss: 0.8478 - val_accuracy: 0.1318\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7266 - accuracy: 0.4897 - val_loss: 0.8242 - val_accuracy: 0.1441\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.5039 - val_loss: 0.8057 - val_accuracy: 0.1554\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.5047 - val_loss: 0.7890 - val_accuracy: 0.1720\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7170 - accuracy: 0.4942 - val_loss: 0.7752 - val_accuracy: 0.1953\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7125 - accuracy: 0.5006 - val_loss: 0.7633 - val_accuracy: 0.2243\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7085 - accuracy: 0.5054 - val_loss: 0.7533 - val_accuracy: 0.2502\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5193 - val_loss: 0.7445 - val_accuracy: 0.2731\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.5148 - val_loss: 0.7367 - val_accuracy: 0.2972\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.4890 - val_loss: 0.7301 - val_accuracy: 0.3281\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.5144 - val_loss: 0.7250 - val_accuracy: 0.3514\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.5204 - val_loss: 0.7211 - val_accuracy: 0.3760\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.4916 - val_loss: 0.7173 - val_accuracy: 0.3935\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.5013 - val_loss: 0.7142 - val_accuracy: 0.4110\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.4905 - val_loss: 0.7117 - val_accuracy: 0.4245\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.4998 - val_loss: 0.7087 - val_accuracy: 0.4421\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.5286 - val_loss: 0.7062 - val_accuracy: 0.4570\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.5047 - val_loss: 0.7046 - val_accuracy: 0.4668\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.5028 - val_loss: 0.7027 - val_accuracy: 0.4789\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.5204 - val_loss: 0.7023 - val_accuracy: 0.4803\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.5036 - val_loss: 0.7010 - val_accuracy: 0.4889\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.5095 - val_loss: 0.7004 - val_accuracy: 0.4926\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.5350 - val_loss: 0.6985 - val_accuracy: 0.5053\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.5103 - val_loss: 0.6972 - val_accuracy: 0.5133\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.5110 - val_loss: 0.6967 - val_accuracy: 0.5172\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.5234 - val_loss: 0.6956 - val_accuracy: 0.5252\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.5260 - val_loss: 0.6945 - val_accuracy: 0.5315\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.5204 - val_loss: 0.6937 - val_accuracy: 0.5372\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5364 - val_loss: 0.6930 - val_accuracy: 0.5412\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.5219 - val_loss: 0.6926 - val_accuracy: 0.5438\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.5271 - val_loss: 0.6919 - val_accuracy: 0.5479\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5241 - val_loss: 0.6911 - val_accuracy: 0.5535\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.5215 - val_loss: 0.6896 - val_accuracy: 0.5643\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.5148 - val_loss: 0.6891 - val_accuracy: 0.5660\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5286 - val_loss: 0.6888 - val_accuracy: 0.5671\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5447 - val_loss: 0.6893 - val_accuracy: 0.5622\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5327 - val_loss: 0.6892 - val_accuracy: 0.5628\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5394 - val_loss: 0.6884 - val_accuracy: 0.5674\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.5193 - val_loss: 0.6878 - val_accuracy: 0.5717\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5357 - val_loss: 0.6875 - val_accuracy: 0.5736\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5376 - val_loss: 0.6869 - val_accuracy: 0.5779\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5338 - val_loss: 0.6869 - val_accuracy: 0.5782\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5323 - val_loss: 0.6860 - val_accuracy: 0.5831\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.8424 - accuracy: 0.4886 - val_loss: 0.4793 - val_accuracy: 0.8808\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.8095 - accuracy: 0.4879 - val_loss: 0.4980 - val_accuracy: 0.8792\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7955 - accuracy: 0.4834 - val_loss: 0.5166 - val_accuracy: 0.8781\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7730 - accuracy: 0.4751 - val_loss: 0.5346 - val_accuracy: 0.8757\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7605 - accuracy: 0.4778 - val_loss: 0.5522 - val_accuracy: 0.8702\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7474 - accuracy: 0.4692 - val_loss: 0.5677 - val_accuracy: 0.8579\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7425 - accuracy: 0.4721 - val_loss: 0.5826 - val_accuracy: 0.8408\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7394 - accuracy: 0.4606 - val_loss: 0.5953 - val_accuracy: 0.8263\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7281 - accuracy: 0.4822 - val_loss: 0.6066 - val_accuracy: 0.8065\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7277 - accuracy: 0.4650 - val_loss: 0.6177 - val_accuracy: 0.7830\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.4740 - val_loss: 0.6270 - val_accuracy: 0.7587\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.4759 - val_loss: 0.6352 - val_accuracy: 0.7311\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7225 - accuracy: 0.4591 - val_loss: 0.6431 - val_accuracy: 0.7075\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.4684 - val_loss: 0.6499 - val_accuracy: 0.6896\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.4740 - val_loss: 0.6557 - val_accuracy: 0.6719\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.4662 - val_loss: 0.6603 - val_accuracy: 0.6595\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7162 - accuracy: 0.4654 - val_loss: 0.6646 - val_accuracy: 0.6445\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7147 - accuracy: 0.4692 - val_loss: 0.6686 - val_accuracy: 0.6265\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.4718 - val_loss: 0.6716 - val_accuracy: 0.6110\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.4811 - val_loss: 0.6740 - val_accuracy: 0.6015\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.4564 - val_loss: 0.6761 - val_accuracy: 0.5921\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.4796 - val_loss: 0.6783 - val_accuracy: 0.5819\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.4879 - val_loss: 0.6797 - val_accuracy: 0.5740\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.4830 - val_loss: 0.6807 - val_accuracy: 0.5695\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.4815 - val_loss: 0.6825 - val_accuracy: 0.5619\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.4621 - val_loss: 0.6840 - val_accuracy: 0.5552\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.4893 - val_loss: 0.6838 - val_accuracy: 0.5566\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.4822 - val_loss: 0.6850 - val_accuracy: 0.5516\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.4841 - val_loss: 0.6856 - val_accuracy: 0.5486\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.4856 - val_loss: 0.6859 - val_accuracy: 0.5468\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.4979 - val_loss: 0.6865 - val_accuracy: 0.5421\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.4931 - val_loss: 0.6866 - val_accuracy: 0.5412\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.4923 - val_loss: 0.6867 - val_accuracy: 0.5410\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.4871 - val_loss: 0.6865 - val_accuracy: 0.5422\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.5065 - val_loss: 0.6870 - val_accuracy: 0.5386\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.4946 - val_loss: 0.6877 - val_accuracy: 0.5356\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.5006 - val_loss: 0.6882 - val_accuracy: 0.5326\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.4968 - val_loss: 0.6881 - val_accuracy: 0.5319\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.5114 - val_loss: 0.6882 - val_accuracy: 0.5307\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.5080 - val_loss: 0.6881 - val_accuracy: 0.5305\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.4976 - val_loss: 0.6884 - val_accuracy: 0.5277\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.4968 - val_loss: 0.6882 - val_accuracy: 0.5285\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.5021 - val_loss: 0.6878 - val_accuracy: 0.5308\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.4998 - val_loss: 0.6876 - val_accuracy: 0.5326\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.5021 - val_loss: 0.6869 - val_accuracy: 0.5359\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5174 - val_loss: 0.6869 - val_accuracy: 0.5368\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5193 - val_loss: 0.6864 - val_accuracy: 0.5400\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5092 - val_loss: 0.6865 - val_accuracy: 0.5401\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5181 - val_loss: 0.6859 - val_accuracy: 0.5431\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5204 - val_loss: 0.6856 - val_accuracy: 0.5459\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7616 - accuracy: 0.5200 - val_loss: 0.9756 - val_accuracy: 0.1294\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7396 - accuracy: 0.5275 - val_loss: 0.9163 - val_accuracy: 0.1339\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.5301 - val_loss: 0.8702 - val_accuracy: 0.1371\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.5338 - val_loss: 0.8324 - val_accuracy: 0.1530\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.7141 - accuracy: 0.5237 - val_loss: 0.8035 - val_accuracy: 0.2084\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7075 - accuracy: 0.5450 - val_loss: 0.7771 - val_accuracy: 0.2692\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.5473 - val_loss: 0.7589 - val_accuracy: 0.3132\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.5555 - val_loss: 0.7431 - val_accuracy: 0.3504\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7020 - accuracy: 0.5447 - val_loss: 0.7306 - val_accuracy: 0.3814\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5750 - val_loss: 0.7214 - val_accuracy: 0.4057\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5548 - val_loss: 0.7132 - val_accuracy: 0.4304\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.5521 - val_loss: 0.7057 - val_accuracy: 0.4596\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5585 - val_loss: 0.7000 - val_accuracy: 0.4846\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5630 - val_loss: 0.6965 - val_accuracy: 0.5014\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5645 - val_loss: 0.6918 - val_accuracy: 0.5237\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5634 - val_loss: 0.6879 - val_accuracy: 0.5420\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5660 - val_loss: 0.6852 - val_accuracy: 0.5527\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5656 - val_loss: 0.6824 - val_accuracy: 0.5676\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5551 - val_loss: 0.6804 - val_accuracy: 0.5766\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5619 - val_loss: 0.6782 - val_accuracy: 0.5841\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5574 - val_loss: 0.6773 - val_accuracy: 0.5871\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5637 - val_loss: 0.6766 - val_accuracy: 0.5884\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5559 - val_loss: 0.6751 - val_accuracy: 0.5939\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5551 - val_loss: 0.6738 - val_accuracy: 0.5991\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5798 - val_loss: 0.6729 - val_accuracy: 0.6019\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5645 - val_loss: 0.6711 - val_accuracy: 0.6100\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5918 - val_loss: 0.6704 - val_accuracy: 0.6114\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.5626 - val_loss: 0.6687 - val_accuracy: 0.6189\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5768 - val_loss: 0.6674 - val_accuracy: 0.6240\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.5753 - val_loss: 0.6661 - val_accuracy: 0.6280\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.5578 - val_loss: 0.6646 - val_accuracy: 0.6324\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.5764 - val_loss: 0.6648 - val_accuracy: 0.6291\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5682 - val_loss: 0.6643 - val_accuracy: 0.6304\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5918 - val_loss: 0.6633 - val_accuracy: 0.6330\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5735 - val_loss: 0.6628 - val_accuracy: 0.6331\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5798 - val_loss: 0.6617 - val_accuracy: 0.6367\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.5892 - val_loss: 0.6611 - val_accuracy: 0.6373\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.5750 - val_loss: 0.6603 - val_accuracy: 0.6389\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6771 - accuracy: 0.5869 - val_loss: 0.6608 - val_accuracy: 0.6356\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.5731 - val_loss: 0.6594 - val_accuracy: 0.6391\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5888 - val_loss: 0.6594 - val_accuracy: 0.6372\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5824 - val_loss: 0.6588 - val_accuracy: 0.6380\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.5791 - val_loss: 0.6574 - val_accuracy: 0.6424\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5776 - val_loss: 0.6564 - val_accuracy: 0.6438\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.5910 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5850 - val_loss: 0.6570 - val_accuracy: 0.6399\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.5903 - val_loss: 0.6565 - val_accuracy: 0.6407\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.5918 - val_loss: 0.6571 - val_accuracy: 0.6372\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.5996 - val_loss: 0.6571 - val_accuracy: 0.6365\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.5929 - val_loss: 0.6562 - val_accuracy: 0.6385\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.0042 - accuracy: 0.5062 - val_loss: 1.5385 - val_accuracy: 0.1170\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.9527 - accuracy: 0.5062 - val_loss: 1.4487 - val_accuracy: 0.1170\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.9212 - accuracy: 0.5062 - val_loss: 1.3685 - val_accuracy: 0.1170\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.8951 - accuracy: 0.5058 - val_loss: 1.2975 - val_accuracy: 0.1170\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.8558 - accuracy: 0.5062 - val_loss: 1.2358 - val_accuracy: 0.1170\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.8307 - accuracy: 0.5065 - val_loss: 1.1811 - val_accuracy: 0.1170\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.8120 - accuracy: 0.5069 - val_loss: 1.1322 - val_accuracy: 0.1170\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.8014 - accuracy: 0.5050 - val_loss: 1.0894 - val_accuracy: 0.1170\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7878 - accuracy: 0.5047 - val_loss: 1.0509 - val_accuracy: 0.1170\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7766 - accuracy: 0.5050 - val_loss: 1.0171 - val_accuracy: 0.1170\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7678 - accuracy: 0.5080 - val_loss: 0.9870 - val_accuracy: 0.1170\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.5039 - val_loss: 0.9599 - val_accuracy: 0.1170\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7491 - accuracy: 0.5069 - val_loss: 0.9364 - val_accuracy: 0.1169\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 0.4994 - val_loss: 0.9150 - val_accuracy: 0.1171\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.4979 - val_loss: 0.8965 - val_accuracy: 0.1173\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.7275 - accuracy: 0.5006 - val_loss: 0.8791 - val_accuracy: 0.1174\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7284 - accuracy: 0.5039 - val_loss: 0.8634 - val_accuracy: 0.1179\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7240 - accuracy: 0.4927 - val_loss: 0.8494 - val_accuracy: 0.1187\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.4950 - val_loss: 0.8367 - val_accuracy: 0.1201\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7178 - accuracy: 0.5039 - val_loss: 0.8255 - val_accuracy: 0.1218\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7179 - accuracy: 0.5065 - val_loss: 0.8149 - val_accuracy: 0.1230\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.4935 - val_loss: 0.8060 - val_accuracy: 0.1251\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.5174 - val_loss: 0.7977 - val_accuracy: 0.1269\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7077 - accuracy: 0.5077 - val_loss: 0.7899 - val_accuracy: 0.1299\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7137 - accuracy: 0.4905 - val_loss: 0.7827 - val_accuracy: 0.1328\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.5028 - val_loss: 0.7765 - val_accuracy: 0.1370\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.7054 - accuracy: 0.5140 - val_loss: 0.7704 - val_accuracy: 0.1400\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.5024 - val_loss: 0.7651 - val_accuracy: 0.1430\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.5047 - val_loss: 0.7600 - val_accuracy: 0.1469\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.5073 - val_loss: 0.7560 - val_accuracy: 0.1538\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7055 - accuracy: 0.4957 - val_loss: 0.7519 - val_accuracy: 0.1633\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.5088 - val_loss: 0.7482 - val_accuracy: 0.1699\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7036 - accuracy: 0.5174 - val_loss: 0.7446 - val_accuracy: 0.1748\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.4968 - val_loss: 0.7412 - val_accuracy: 0.1822\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7080 - accuracy: 0.4953 - val_loss: 0.7384 - val_accuracy: 0.1934\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.5110 - val_loss: 0.7354 - val_accuracy: 0.2057\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.4953 - val_loss: 0.7334 - val_accuracy: 0.2173\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.7003 - accuracy: 0.5155 - val_loss: 0.7312 - val_accuracy: 0.2300\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.5275 - val_loss: 0.7290 - val_accuracy: 0.2417\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.5308 - val_loss: 0.7270 - val_accuracy: 0.2541\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5353 - val_loss: 0.7247 - val_accuracy: 0.2685\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.5357 - val_loss: 0.7229 - val_accuracy: 0.2790\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5305 - val_loss: 0.7210 - val_accuracy: 0.2922\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5320 - val_loss: 0.7193 - val_accuracy: 0.3110\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.5234 - val_loss: 0.7177 - val_accuracy: 0.3288\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5379 - val_loss: 0.7159 - val_accuracy: 0.3484\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5394 - val_loss: 0.7142 - val_accuracy: 0.3649\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5316 - val_loss: 0.7127 - val_accuracy: 0.3839\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5432 - val_loss: 0.7120 - val_accuracy: 0.3963\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.5279 - val_loss: 0.7110 - val_accuracy: 0.4090\n"
     ]
    }
   ],
   "source": [
    "# 2. Vary sample_size_ratio\n",
    "results_sample_size = {}\n",
    "eps_sample_size = {}\n",
    "for ssr in sample_size_ratio_values:\n",
    "    print(f\"\\nTraining model with sample_size_ratio={ssr}...\")\n",
    "    X_sub, y_sub = subsample_data(X_train_filtered, y_train_filtered, ssr)\n",
    "    n = len(X_sub)\n",
    "    eps = compute_privacy_budget(n, default_batch_size, default_noise_multiplier, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_sub, y_sub, X_test_filtered, y_test_filtered,\n",
    "        batch_size=default_batch_size, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_sample_size[ssr] = compute_statistics(results)\n",
    "    eps_sample_size[ssr] = eps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f3f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with noise_multiplier=1.1...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6924 - accuracy: 0.5417 - val_loss: 0.7103 - val_accuracy: 0.4890\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6860 - accuracy: 0.5578 - val_loss: 0.7079 - val_accuracy: 0.5047\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6791 - accuracy: 0.5764 - val_loss: 0.7018 - val_accuracy: 0.5351\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.6729 - accuracy: 0.5960 - val_loss: 0.6916 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6675 - accuracy: 0.6094 - val_loss: 0.6878 - val_accuracy: 0.5607\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6622 - accuracy: 0.6198 - val_loss: 0.6807 - val_accuracy: 0.5802\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6566 - accuracy: 0.6300 - val_loss: 0.6757 - val_accuracy: 0.5946\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 793us/step - loss: 0.6522 - accuracy: 0.6378 - val_loss: 0.6735 - val_accuracy: 0.6005\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6482 - accuracy: 0.6443 - val_loss: 0.6688 - val_accuracy: 0.6052\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.6445 - accuracy: 0.6501 - val_loss: 0.6674 - val_accuracy: 0.6048\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6411 - accuracy: 0.6554 - val_loss: 0.6655 - val_accuracy: 0.6048\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.6363 - accuracy: 0.6626 - val_loss: 0.6611 - val_accuracy: 0.6067\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6341 - accuracy: 0.6653 - val_loss: 0.6568 - val_accuracy: 0.6102\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6303 - accuracy: 0.6702 - val_loss: 0.6550 - val_accuracy: 0.6102\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.6276 - accuracy: 0.6700 - val_loss: 0.6477 - val_accuracy: 0.6192\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6241 - accuracy: 0.6762 - val_loss: 0.6506 - val_accuracy: 0.6127\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.6209 - accuracy: 0.6756 - val_loss: 0.6375 - val_accuracy: 0.6309\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6191 - accuracy: 0.6770 - val_loss: 0.6421 - val_accuracy: 0.6201\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6163 - accuracy: 0.6821 - val_loss: 0.6408 - val_accuracy: 0.6205\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6124 - accuracy: 0.6852 - val_loss: 0.6429 - val_accuracy: 0.6173\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6108 - accuracy: 0.6840 - val_loss: 0.6377 - val_accuracy: 0.6232\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6084 - accuracy: 0.6877 - val_loss: 0.6349 - val_accuracy: 0.6269\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6067 - accuracy: 0.6887 - val_loss: 0.6301 - val_accuracy: 0.6328\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 708us/step - loss: 0.6036 - accuracy: 0.6893 - val_loss: 0.6299 - val_accuracy: 0.6319\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6008 - accuracy: 0.6926 - val_loss: 0.6287 - val_accuracy: 0.6318\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.5994 - accuracy: 0.6944 - val_loss: 0.6254 - val_accuracy: 0.6355\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5964 - accuracy: 0.6942 - val_loss: 0.6237 - val_accuracy: 0.6382\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5956 - accuracy: 0.6953 - val_loss: 0.6258 - val_accuracy: 0.6349\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.5934 - accuracy: 0.6971 - val_loss: 0.6235 - val_accuracy: 0.6372\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5920 - accuracy: 0.7002 - val_loss: 0.6239 - val_accuracy: 0.6357\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5905 - accuracy: 0.6996 - val_loss: 0.6253 - val_accuracy: 0.6331\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5892 - accuracy: 0.7007 - val_loss: 0.6129 - val_accuracy: 0.6465\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5870 - accuracy: 0.7032 - val_loss: 0.6165 - val_accuracy: 0.6423\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5844 - accuracy: 0.7031 - val_loss: 0.6229 - val_accuracy: 0.6340\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5850 - accuracy: 0.7029 - val_loss: 0.6162 - val_accuracy: 0.6409\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5830 - accuracy: 0.7029 - val_loss: 0.6156 - val_accuracy: 0.6412\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5811 - accuracy: 0.7055 - val_loss: 0.6182 - val_accuracy: 0.6374\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5798 - accuracy: 0.7065 - val_loss: 0.6178 - val_accuracy: 0.6375\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5785 - accuracy: 0.7071 - val_loss: 0.6098 - val_accuracy: 0.6431\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5777 - accuracy: 0.7085 - val_loss: 0.6097 - val_accuracy: 0.6426\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5754 - accuracy: 0.7076 - val_loss: 0.6165 - val_accuracy: 0.6355\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5750 - accuracy: 0.7116 - val_loss: 0.6114 - val_accuracy: 0.6402\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5743 - accuracy: 0.7093 - val_loss: 0.6144 - val_accuracy: 0.6357\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5720 - accuracy: 0.7109 - val_loss: 0.6147 - val_accuracy: 0.6341\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5709 - accuracy: 0.7122 - val_loss: 0.6100 - val_accuracy: 0.6399\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5699 - accuracy: 0.7132 - val_loss: 0.6129 - val_accuracy: 0.6355\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5689 - accuracy: 0.7136 - val_loss: 0.6081 - val_accuracy: 0.6402\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5680 - accuracy: 0.7145 - val_loss: 0.6085 - val_accuracy: 0.6389\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5667 - accuracy: 0.7134 - val_loss: 0.6077 - val_accuracy: 0.6399\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.5660 - accuracy: 0.7154 - val_loss: 0.6130 - val_accuracy: 0.6342\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.7221 - accuracy: 0.5054 - val_loss: 0.7268 - val_accuracy: 0.4151\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.7067 - accuracy: 0.5262 - val_loss: 0.7217 - val_accuracy: 0.4361\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6980 - accuracy: 0.5427 - val_loss: 0.7150 - val_accuracy: 0.4618\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6909 - accuracy: 0.5542 - val_loss: 0.7049 - val_accuracy: 0.4962\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6828 - accuracy: 0.5705 - val_loss: 0.6955 - val_accuracy: 0.5316\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6775 - accuracy: 0.5815 - val_loss: 0.6973 - val_accuracy: 0.5269\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6729 - accuracy: 0.5886 - val_loss: 0.6880 - val_accuracy: 0.5531\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6656 - accuracy: 0.6037 - val_loss: 0.6840 - val_accuracy: 0.5608\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6612 - accuracy: 0.6118 - val_loss: 0.6777 - val_accuracy: 0.5736\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6572 - accuracy: 0.6183 - val_loss: 0.6757 - val_accuracy: 0.5782\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6525 - accuracy: 0.6262 - val_loss: 0.6732 - val_accuracy: 0.5830\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6490 - accuracy: 0.6318 - val_loss: 0.6706 - val_accuracy: 0.5880\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6450 - accuracy: 0.6384 - val_loss: 0.6662 - val_accuracy: 0.5962\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6404 - accuracy: 0.6460 - val_loss: 0.6606 - val_accuracy: 0.6053\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6388 - accuracy: 0.6471 - val_loss: 0.6616 - val_accuracy: 0.6017\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6348 - accuracy: 0.6513 - val_loss: 0.6543 - val_accuracy: 0.6148\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6305 - accuracy: 0.6591 - val_loss: 0.6558 - val_accuracy: 0.6092\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6281 - accuracy: 0.6618 - val_loss: 0.6486 - val_accuracy: 0.6180\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6257 - accuracy: 0.6646 - val_loss: 0.6468 - val_accuracy: 0.6169\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6212 - accuracy: 0.6660 - val_loss: 0.6459 - val_accuracy: 0.6154\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6186 - accuracy: 0.6695 - val_loss: 0.6441 - val_accuracy: 0.6157\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6158 - accuracy: 0.6728 - val_loss: 0.6356 - val_accuracy: 0.6298\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6133 - accuracy: 0.6757 - val_loss: 0.6379 - val_accuracy: 0.6237\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6117 - accuracy: 0.6770 - val_loss: 0.6358 - val_accuracy: 0.6266\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6100 - accuracy: 0.6802 - val_loss: 0.6365 - val_accuracy: 0.6250\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6076 - accuracy: 0.6799 - val_loss: 0.6363 - val_accuracy: 0.6246\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6043 - accuracy: 0.6857 - val_loss: 0.6356 - val_accuracy: 0.6253\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.6029 - accuracy: 0.6859 - val_loss: 0.6256 - val_accuracy: 0.6350\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6011 - accuracy: 0.6864 - val_loss: 0.6298 - val_accuracy: 0.6304\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 796us/step - loss: 0.5992 - accuracy: 0.6885 - val_loss: 0.6328 - val_accuracy: 0.6270\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5976 - accuracy: 0.6899 - val_loss: 0.6316 - val_accuracy: 0.6278\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.5956 - accuracy: 0.6903 - val_loss: 0.6266 - val_accuracy: 0.6316\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5944 - accuracy: 0.6923 - val_loss: 0.6232 - val_accuracy: 0.6352\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.5922 - accuracy: 0.6914 - val_loss: 0.6291 - val_accuracy: 0.6294\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5909 - accuracy: 0.6951 - val_loss: 0.6274 - val_accuracy: 0.6310\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 772us/step - loss: 0.5893 - accuracy: 0.6956 - val_loss: 0.6210 - val_accuracy: 0.6362\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5883 - accuracy: 0.6949 - val_loss: 0.6196 - val_accuracy: 0.6362\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.5858 - accuracy: 0.6978 - val_loss: 0.6256 - val_accuracy: 0.6318\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5842 - accuracy: 0.6983 - val_loss: 0.6190 - val_accuracy: 0.6361\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.5823 - accuracy: 0.7004 - val_loss: 0.6236 - val_accuracy: 0.6328\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5822 - accuracy: 0.6996 - val_loss: 0.6129 - val_accuracy: 0.6449\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 708us/step - loss: 0.5804 - accuracy: 0.7010 - val_loss: 0.6181 - val_accuracy: 0.6378\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.5798 - accuracy: 0.7025 - val_loss: 0.6107 - val_accuracy: 0.6481\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 719us/step - loss: 0.5782 - accuracy: 0.7036 - val_loss: 0.6174 - val_accuracy: 0.6382\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5760 - accuracy: 0.7033 - val_loss: 0.6114 - val_accuracy: 0.6469\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5747 - accuracy: 0.7054 - val_loss: 0.6149 - val_accuracy: 0.6419\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5734 - accuracy: 0.7053 - val_loss: 0.6130 - val_accuracy: 0.6455\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 765us/step - loss: 0.5727 - accuracy: 0.7073 - val_loss: 0.6155 - val_accuracy: 0.6428\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.5712 - accuracy: 0.7073 - val_loss: 0.6119 - val_accuracy: 0.6475\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.5703 - accuracy: 0.7088 - val_loss: 0.6134 - val_accuracy: 0.6469\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.7025 - accuracy: 0.5291 - val_loss: 0.7659 - val_accuracy: 0.1721\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 789us/step - loss: 0.6899 - accuracy: 0.5444 - val_loss: 0.7371 - val_accuracy: 0.2360\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6827 - accuracy: 0.5635 - val_loss: 0.7282 - val_accuracy: 0.2955\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.6776 - accuracy: 0.5808 - val_loss: 0.7216 - val_accuracy: 0.3773\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6740 - accuracy: 0.5904 - val_loss: 0.7166 - val_accuracy: 0.4340\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.6693 - accuracy: 0.6029 - val_loss: 0.7091 - val_accuracy: 0.4625\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6665 - accuracy: 0.6092 - val_loss: 0.7092 - val_accuracy: 0.4712\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.6624 - accuracy: 0.6186 - val_loss: 0.7031 - val_accuracy: 0.5080\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6585 - accuracy: 0.6280 - val_loss: 0.6970 - val_accuracy: 0.5306\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6556 - accuracy: 0.6330 - val_loss: 0.6919 - val_accuracy: 0.5467\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 818us/step - loss: 0.6526 - accuracy: 0.6396 - val_loss: 0.6914 - val_accuracy: 0.5525\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6500 - accuracy: 0.6454 - val_loss: 0.6898 - val_accuracy: 0.5619\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.6462 - accuracy: 0.6497 - val_loss: 0.6850 - val_accuracy: 0.5756\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6448 - accuracy: 0.6518 - val_loss: 0.6818 - val_accuracy: 0.5900\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6430 - accuracy: 0.6559 - val_loss: 0.6788 - val_accuracy: 0.6013\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6399 - accuracy: 0.6584 - val_loss: 0.6788 - val_accuracy: 0.5998\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.6362 - accuracy: 0.6637 - val_loss: 0.6747 - val_accuracy: 0.6113\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.6351 - accuracy: 0.6632 - val_loss: 0.6742 - val_accuracy: 0.6121\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.6323 - accuracy: 0.6672 - val_loss: 0.6697 - val_accuracy: 0.6197\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.6306 - accuracy: 0.6668 - val_loss: 0.6713 - val_accuracy: 0.6158\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 788us/step - loss: 0.6279 - accuracy: 0.6710 - val_loss: 0.6691 - val_accuracy: 0.6192\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.6258 - accuracy: 0.6725 - val_loss: 0.6644 - val_accuracy: 0.6237\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 732us/step - loss: 0.6234 - accuracy: 0.6749 - val_loss: 0.6608 - val_accuracy: 0.6260\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.6209 - accuracy: 0.6763 - val_loss: 0.6599 - val_accuracy: 0.6258\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6189 - accuracy: 0.6775 - val_loss: 0.6596 - val_accuracy: 0.6258\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6167 - accuracy: 0.6787 - val_loss: 0.6545 - val_accuracy: 0.6299\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6141 - accuracy: 0.6818 - val_loss: 0.6522 - val_accuracy: 0.6310\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6131 - accuracy: 0.6794 - val_loss: 0.6498 - val_accuracy: 0.6334\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6112 - accuracy: 0.6824 - val_loss: 0.6486 - val_accuracy: 0.6336\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6090 - accuracy: 0.6832 - val_loss: 0.6478 - val_accuracy: 0.6337\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6066 - accuracy: 0.6856 - val_loss: 0.6482 - val_accuracy: 0.6326\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6049 - accuracy: 0.6877 - val_loss: 0.6389 - val_accuracy: 0.6464\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6031 - accuracy: 0.6871 - val_loss: 0.6420 - val_accuracy: 0.6404\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6020 - accuracy: 0.6886 - val_loss: 0.6343 - val_accuracy: 0.6519\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6002 - accuracy: 0.6901 - val_loss: 0.6378 - val_accuracy: 0.6450\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.5973 - accuracy: 0.6934 - val_loss: 0.6373 - val_accuracy: 0.6443\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5970 - accuracy: 0.6931 - val_loss: 0.6410 - val_accuracy: 0.6393\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5947 - accuracy: 0.6953 - val_loss: 0.6372 - val_accuracy: 0.6439\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.5941 - accuracy: 0.6946 - val_loss: 0.6375 - val_accuracy: 0.6430\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5923 - accuracy: 0.6965 - val_loss: 0.6320 - val_accuracy: 0.6511\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5908 - accuracy: 0.6975 - val_loss: 0.6350 - val_accuracy: 0.6457\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5895 - accuracy: 0.6971 - val_loss: 0.6303 - val_accuracy: 0.6535\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5886 - accuracy: 0.6990 - val_loss: 0.6271 - val_accuracy: 0.6595\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5869 - accuracy: 0.6999 - val_loss: 0.6245 - val_accuracy: 0.6632\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.5858 - accuracy: 0.7013 - val_loss: 0.6240 - val_accuracy: 0.6635\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5845 - accuracy: 0.7023 - val_loss: 0.6233 - val_accuracy: 0.6644\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5832 - accuracy: 0.7024 - val_loss: 0.6285 - val_accuracy: 0.6579\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5813 - accuracy: 0.7040 - val_loss: 0.6237 - val_accuracy: 0.6638\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5800 - accuracy: 0.7039 - val_loss: 0.6225 - val_accuracy: 0.6647\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5783 - accuracy: 0.7064 - val_loss: 0.6210 - val_accuracy: 0.6665\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6904 - accuracy: 0.5342 - val_loss: 0.7064 - val_accuracy: 0.5019\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6819 - accuracy: 0.5629 - val_loss: 0.6934 - val_accuracy: 0.5402\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6741 - accuracy: 0.5854 - val_loss: 0.6818 - val_accuracy: 0.5748\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6673 - accuracy: 0.6037 - val_loss: 0.6704 - val_accuracy: 0.6026\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6618 - accuracy: 0.6157 - val_loss: 0.6664 - val_accuracy: 0.6109\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6576 - accuracy: 0.6219 - val_loss: 0.6590 - val_accuracy: 0.6257\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.6526 - accuracy: 0.6312 - val_loss: 0.6511 - val_accuracy: 0.6406\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6487 - accuracy: 0.6366 - val_loss: 0.6498 - val_accuracy: 0.6414\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6435 - accuracy: 0.6460 - val_loss: 0.6457 - val_accuracy: 0.6469\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6406 - accuracy: 0.6490 - val_loss: 0.6461 - val_accuracy: 0.6402\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6379 - accuracy: 0.6510 - val_loss: 0.6383 - val_accuracy: 0.6534\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6348 - accuracy: 0.6557 - val_loss: 0.6411 - val_accuracy: 0.6447\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6311 - accuracy: 0.6587 - val_loss: 0.6378 - val_accuracy: 0.6490\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6289 - accuracy: 0.6601 - val_loss: 0.6333 - val_accuracy: 0.6531\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6264 - accuracy: 0.6633 - val_loss: 0.6312 - val_accuracy: 0.6529\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6251 - accuracy: 0.6635 - val_loss: 0.6269 - val_accuracy: 0.6586\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6217 - accuracy: 0.6668 - val_loss: 0.6264 - val_accuracy: 0.6571\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6191 - accuracy: 0.6682 - val_loss: 0.6294 - val_accuracy: 0.6525\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6171 - accuracy: 0.6694 - val_loss: 0.6283 - val_accuracy: 0.6531\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6150 - accuracy: 0.6719 - val_loss: 0.6251 - val_accuracy: 0.6560\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6141 - accuracy: 0.6740 - val_loss: 0.6241 - val_accuracy: 0.6571\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6118 - accuracy: 0.6760 - val_loss: 0.6185 - val_accuracy: 0.6649\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6100 - accuracy: 0.6754 - val_loss: 0.6234 - val_accuracy: 0.6548\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6080 - accuracy: 0.6785 - val_loss: 0.6175 - val_accuracy: 0.6664\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6059 - accuracy: 0.6812 - val_loss: 0.6189 - val_accuracy: 0.6601\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6048 - accuracy: 0.6816 - val_loss: 0.6165 - val_accuracy: 0.6614\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6046 - accuracy: 0.6816 - val_loss: 0.6224 - val_accuracy: 0.6486\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6015 - accuracy: 0.6846 - val_loss: 0.6148 - val_accuracy: 0.6568\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5998 - accuracy: 0.6854 - val_loss: 0.6116 - val_accuracy: 0.6577\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5983 - accuracy: 0.6871 - val_loss: 0.6149 - val_accuracy: 0.6547\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5976 - accuracy: 0.6876 - val_loss: 0.6157 - val_accuracy: 0.6524\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5951 - accuracy: 0.6906 - val_loss: 0.6113 - val_accuracy: 0.6533\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5936 - accuracy: 0.6935 - val_loss: 0.6064 - val_accuracy: 0.6569\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5924 - accuracy: 0.6940 - val_loss: 0.6094 - val_accuracy: 0.6533\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5914 - accuracy: 0.6931 - val_loss: 0.6076 - val_accuracy: 0.6541\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5910 - accuracy: 0.6941 - val_loss: 0.6155 - val_accuracy: 0.6459\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5885 - accuracy: 0.6966 - val_loss: 0.6058 - val_accuracy: 0.6549\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5860 - accuracy: 0.6981 - val_loss: 0.6091 - val_accuracy: 0.6502\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5860 - accuracy: 0.6982 - val_loss: 0.6137 - val_accuracy: 0.6456\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5845 - accuracy: 0.6995 - val_loss: 0.6049 - val_accuracy: 0.6531\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5838 - accuracy: 0.7013 - val_loss: 0.6093 - val_accuracy: 0.6491\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5824 - accuracy: 0.7017 - val_loss: 0.6084 - val_accuracy: 0.6490\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5818 - accuracy: 0.7026 - val_loss: 0.6083 - val_accuracy: 0.6482\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5798 - accuracy: 0.7028 - val_loss: 0.6070 - val_accuracy: 0.6483\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5787 - accuracy: 0.7043 - val_loss: 0.6036 - val_accuracy: 0.6511\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5771 - accuracy: 0.7052 - val_loss: 0.6083 - val_accuracy: 0.6457\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5761 - accuracy: 0.7068 - val_loss: 0.6106 - val_accuracy: 0.6427\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5751 - accuracy: 0.7083 - val_loss: 0.6065 - val_accuracy: 0.6462\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5740 - accuracy: 0.7082 - val_loss: 0.6085 - val_accuracy: 0.6441\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5730 - accuracy: 0.7113 - val_loss: 0.5964 - val_accuracy: 0.6565\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.7393 - accuracy: 0.4523 - val_loss: 0.7250 - val_accuracy: 0.2956\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.7214 - accuracy: 0.4698 - val_loss: 0.7260 - val_accuracy: 0.2828\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.7085 - accuracy: 0.4982 - val_loss: 0.7164 - val_accuracy: 0.3778\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.7005 - accuracy: 0.5160 - val_loss: 0.7089 - val_accuracy: 0.4544\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6926 - accuracy: 0.5370 - val_loss: 0.6944 - val_accuracy: 0.5277\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6849 - accuracy: 0.5601 - val_loss: 0.6936 - val_accuracy: 0.5314\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6785 - accuracy: 0.5725 - val_loss: 0.6839 - val_accuracy: 0.5631\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6728 - accuracy: 0.5907 - val_loss: 0.6784 - val_accuracy: 0.5814\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.6676 - accuracy: 0.6022 - val_loss: 0.6791 - val_accuracy: 0.5853\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6633 - accuracy: 0.6112 - val_loss: 0.6723 - val_accuracy: 0.5976\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6596 - accuracy: 0.6213 - val_loss: 0.6693 - val_accuracy: 0.6012\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6553 - accuracy: 0.6274 - val_loss: 0.6688 - val_accuracy: 0.5998\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6524 - accuracy: 0.6349 - val_loss: 0.6676 - val_accuracy: 0.6011\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6491 - accuracy: 0.6402 - val_loss: 0.6577 - val_accuracy: 0.6144\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6459 - accuracy: 0.6437 - val_loss: 0.6558 - val_accuracy: 0.6133\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6426 - accuracy: 0.6493 - val_loss: 0.6512 - val_accuracy: 0.6201\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6402 - accuracy: 0.6505 - val_loss: 0.6492 - val_accuracy: 0.6216\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6372 - accuracy: 0.6548 - val_loss: 0.6471 - val_accuracy: 0.6236\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6337 - accuracy: 0.6593 - val_loss: 0.6475 - val_accuracy: 0.6214\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6327 - accuracy: 0.6583 - val_loss: 0.6444 - val_accuracy: 0.6220\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6297 - accuracy: 0.6628 - val_loss: 0.6406 - val_accuracy: 0.6257\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6274 - accuracy: 0.6666 - val_loss: 0.6385 - val_accuracy: 0.6269\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6249 - accuracy: 0.6676 - val_loss: 0.6388 - val_accuracy: 0.6263\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6228 - accuracy: 0.6688 - val_loss: 0.6364 - val_accuracy: 0.6278\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6200 - accuracy: 0.6718 - val_loss: 0.6354 - val_accuracy: 0.6278\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6180 - accuracy: 0.6737 - val_loss: 0.6314 - val_accuracy: 0.6301\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6171 - accuracy: 0.6738 - val_loss: 0.6339 - val_accuracy: 0.6273\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6160 - accuracy: 0.6744 - val_loss: 0.6309 - val_accuracy: 0.6303\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6131 - accuracy: 0.6766 - val_loss: 0.6301 - val_accuracy: 0.6315\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6113 - accuracy: 0.6803 - val_loss: 0.6274 - val_accuracy: 0.6333\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6106 - accuracy: 0.6774 - val_loss: 0.6285 - val_accuracy: 0.6322\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6082 - accuracy: 0.6822 - val_loss: 0.6266 - val_accuracy: 0.6329\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6067 - accuracy: 0.6819 - val_loss: 0.6233 - val_accuracy: 0.6352\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6056 - accuracy: 0.6842 - val_loss: 0.6263 - val_accuracy: 0.6307\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6033 - accuracy: 0.6879 - val_loss: 0.6189 - val_accuracy: 0.6399\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6017 - accuracy: 0.6863 - val_loss: 0.6218 - val_accuracy: 0.6350\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6006 - accuracy: 0.6871 - val_loss: 0.6194 - val_accuracy: 0.6408\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5993 - accuracy: 0.6884 - val_loss: 0.6203 - val_accuracy: 0.6397\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5967 - accuracy: 0.6942 - val_loss: 0.6141 - val_accuracy: 0.6501\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5952 - accuracy: 0.6928 - val_loss: 0.6194 - val_accuracy: 0.6431\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5944 - accuracy: 0.6916 - val_loss: 0.6131 - val_accuracy: 0.6485\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5933 - accuracy: 0.6938 - val_loss: 0.6184 - val_accuracy: 0.6433\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 832us/step - loss: 0.5921 - accuracy: 0.6945 - val_loss: 0.6138 - val_accuracy: 0.6464\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.5908 - accuracy: 0.6953 - val_loss: 0.6146 - val_accuracy: 0.6436\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 868us/step - loss: 0.5893 - accuracy: 0.6967 - val_loss: 0.6126 - val_accuracy: 0.6448\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 744us/step - loss: 0.5882 - accuracy: 0.6990 - val_loss: 0.6102 - val_accuracy: 0.6469\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 839us/step - loss: 0.5875 - accuracy: 0.6980 - val_loss: 0.6171 - val_accuracy: 0.6381\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.5857 - accuracy: 0.6998 - val_loss: 0.6113 - val_accuracy: 0.6446\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5852 - accuracy: 0.6994 - val_loss: 0.6159 - val_accuracy: 0.6385\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.5835 - accuracy: 0.7034 - val_loss: 0.6088 - val_accuracy: 0.6469\n",
      "\n",
      "Training model with noise_multiplier=1.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.5 iterated over 83600 steps satisfies differential privacy with eps = 0.643 and delta = 1e-05.\n",
      "The optimal RDP order is 32.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.7137 - accuracy: 0.4611 - val_loss: 0.7075 - val_accuracy: 0.4029\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.7046 - accuracy: 0.4837 - val_loss: 0.7202 - val_accuracy: 0.3162\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6999 - accuracy: 0.4974 - val_loss: 0.7203 - val_accuracy: 0.3211\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 795us/step - loss: 0.6966 - accuracy: 0.5104 - val_loss: 0.7202 - val_accuracy: 0.3325\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6936 - accuracy: 0.5187 - val_loss: 0.7159 - val_accuracy: 0.3846\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.6896 - accuracy: 0.5315 - val_loss: 0.7130 - val_accuracy: 0.4209\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6866 - accuracy: 0.5415 - val_loss: 0.7093 - val_accuracy: 0.4422\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.6835 - accuracy: 0.5550 - val_loss: 0.7039 - val_accuracy: 0.4706\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6813 - accuracy: 0.5619 - val_loss: 0.7013 - val_accuracy: 0.4877\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.6777 - accuracy: 0.5730 - val_loss: 0.6980 - val_accuracy: 0.5046\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6760 - accuracy: 0.5798 - val_loss: 0.6956 - val_accuracy: 0.5252\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.6725 - accuracy: 0.5901 - val_loss: 0.6932 - val_accuracy: 0.5446\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6701 - accuracy: 0.5974 - val_loss: 0.6909 - val_accuracy: 0.5594\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6675 - accuracy: 0.6040 - val_loss: 0.6895 - val_accuracy: 0.5674\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6647 - accuracy: 0.6107 - val_loss: 0.6873 - val_accuracy: 0.5769\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 819us/step - loss: 0.6626 - accuracy: 0.6152 - val_loss: 0.6864 - val_accuracy: 0.5828\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6601 - accuracy: 0.6243 - val_loss: 0.6838 - val_accuracy: 0.5908\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.6578 - accuracy: 0.6274 - val_loss: 0.6802 - val_accuracy: 0.6000\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6554 - accuracy: 0.6326 - val_loss: 0.6791 - val_accuracy: 0.6031\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.6530 - accuracy: 0.6345 - val_loss: 0.6757 - val_accuracy: 0.6078\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6516 - accuracy: 0.6367 - val_loss: 0.6735 - val_accuracy: 0.6096\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6485 - accuracy: 0.6445 - val_loss: 0.6701 - val_accuracy: 0.6158\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.6469 - accuracy: 0.6450 - val_loss: 0.6694 - val_accuracy: 0.6163\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6446 - accuracy: 0.6475 - val_loss: 0.6662 - val_accuracy: 0.6244\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 769us/step - loss: 0.6436 - accuracy: 0.6471 - val_loss: 0.6648 - val_accuracy: 0.6251\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6407 - accuracy: 0.6537 - val_loss: 0.6633 - val_accuracy: 0.6272\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 782us/step - loss: 0.6389 - accuracy: 0.6560 - val_loss: 0.6621 - val_accuracy: 0.6294\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6365 - accuracy: 0.6580 - val_loss: 0.6623 - val_accuracy: 0.6281\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6351 - accuracy: 0.6580 - val_loss: 0.6595 - val_accuracy: 0.6352\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6336 - accuracy: 0.6593 - val_loss: 0.6550 - val_accuracy: 0.6472\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6309 - accuracy: 0.6631 - val_loss: 0.6503 - val_accuracy: 0.6570\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6293 - accuracy: 0.6647 - val_loss: 0.6514 - val_accuracy: 0.6516\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6269 - accuracy: 0.6680 - val_loss: 0.6493 - val_accuracy: 0.6534\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 791us/step - loss: 0.6253 - accuracy: 0.6674 - val_loss: 0.6488 - val_accuracy: 0.6516\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6230 - accuracy: 0.6724 - val_loss: 0.6479 - val_accuracy: 0.6502\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.6210 - accuracy: 0.6730 - val_loss: 0.6417 - val_accuracy: 0.6591\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6192 - accuracy: 0.6739 - val_loss: 0.6388 - val_accuracy: 0.6607\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 787us/step - loss: 0.6170 - accuracy: 0.6763 - val_loss: 0.6365 - val_accuracy: 0.6623\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6152 - accuracy: 0.6772 - val_loss: 0.6361 - val_accuracy: 0.6600\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.6141 - accuracy: 0.6782 - val_loss: 0.6353 - val_accuracy: 0.6577\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6109 - accuracy: 0.6804 - val_loss: 0.6321 - val_accuracy: 0.6603\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6093 - accuracy: 0.6837 - val_loss: 0.6340 - val_accuracy: 0.6533\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6074 - accuracy: 0.6833 - val_loss: 0.6309 - val_accuracy: 0.6561\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6058 - accuracy: 0.6839 - val_loss: 0.6304 - val_accuracy: 0.6542\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6036 - accuracy: 0.6863 - val_loss: 0.6313 - val_accuracy: 0.6517\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6018 - accuracy: 0.6864 - val_loss: 0.6268 - val_accuracy: 0.6565\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5996 - accuracy: 0.6876 - val_loss: 0.6252 - val_accuracy: 0.6590\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5973 - accuracy: 0.6904 - val_loss: 0.6229 - val_accuracy: 0.6595\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5947 - accuracy: 0.6911 - val_loss: 0.6175 - val_accuracy: 0.6643\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.5917 - accuracy: 0.6953 - val_loss: 0.6200 - val_accuracy: 0.6601\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.7111 - accuracy: 0.5185 - val_loss: 0.7183 - val_accuracy: 0.4103\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6894 - accuracy: 0.5358 - val_loss: 0.6894 - val_accuracy: 0.5316\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6833 - accuracy: 0.5507 - val_loss: 0.6855 - val_accuracy: 0.5461\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6784 - accuracy: 0.5600 - val_loss: 0.6810 - val_accuracy: 0.5549\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6732 - accuracy: 0.5760 - val_loss: 0.6790 - val_accuracy: 0.5565\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6702 - accuracy: 0.5827 - val_loss: 0.6739 - val_accuracy: 0.5715\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6678 - accuracy: 0.5905 - val_loss: 0.6719 - val_accuracy: 0.5778\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6635 - accuracy: 0.5993 - val_loss: 0.6722 - val_accuracy: 0.5788\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6608 - accuracy: 0.6062 - val_loss: 0.6642 - val_accuracy: 0.5977\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6578 - accuracy: 0.6128 - val_loss: 0.6646 - val_accuracy: 0.5948\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6546 - accuracy: 0.6181 - val_loss: 0.6644 - val_accuracy: 0.5952\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6524 - accuracy: 0.6198 - val_loss: 0.6623 - val_accuracy: 0.6030\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6495 - accuracy: 0.6273 - val_loss: 0.6602 - val_accuracy: 0.6072\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6473 - accuracy: 0.6310 - val_loss: 0.6583 - val_accuracy: 0.6093\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6448 - accuracy: 0.6348 - val_loss: 0.6546 - val_accuracy: 0.6156\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6424 - accuracy: 0.6368 - val_loss: 0.6531 - val_accuracy: 0.6171\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6401 - accuracy: 0.6405 - val_loss: 0.6564 - val_accuracy: 0.6072\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6372 - accuracy: 0.6435 - val_loss: 0.6510 - val_accuracy: 0.6177\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6345 - accuracy: 0.6476 - val_loss: 0.6502 - val_accuracy: 0.6180\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6323 - accuracy: 0.6517 - val_loss: 0.6491 - val_accuracy: 0.6164\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6302 - accuracy: 0.6525 - val_loss: 0.6488 - val_accuracy: 0.6141\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6281 - accuracy: 0.6553 - val_loss: 0.6465 - val_accuracy: 0.6146\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6254 - accuracy: 0.6558 - val_loss: 0.6389 - val_accuracy: 0.6262\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6223 - accuracy: 0.6622 - val_loss: 0.6399 - val_accuracy: 0.6221\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6211 - accuracy: 0.6608 - val_loss: 0.6303 - val_accuracy: 0.6331\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6182 - accuracy: 0.6630 - val_loss: 0.6326 - val_accuracy: 0.6279\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6153 - accuracy: 0.6679 - val_loss: 0.6296 - val_accuracy: 0.6315\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6123 - accuracy: 0.6684 - val_loss: 0.6246 - val_accuracy: 0.6365\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6113 - accuracy: 0.6707 - val_loss: 0.6215 - val_accuracy: 0.6391\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6084 - accuracy: 0.6737 - val_loss: 0.6232 - val_accuracy: 0.6345\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6235 - val_accuracy: 0.6320\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6058 - accuracy: 0.6734 - val_loss: 0.6231 - val_accuracy: 0.6307\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6040 - accuracy: 0.6774 - val_loss: 0.6204 - val_accuracy: 0.6341\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6026 - accuracy: 0.6778 - val_loss: 0.6177 - val_accuracy: 0.6391\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6008 - accuracy: 0.6805 - val_loss: 0.6178 - val_accuracy: 0.6382\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5992 - accuracy: 0.6819 - val_loss: 0.6183 - val_accuracy: 0.6364\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5980 - accuracy: 0.6836 - val_loss: 0.6176 - val_accuracy: 0.6370\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5957 - accuracy: 0.6856 - val_loss: 0.6111 - val_accuracy: 0.6456\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5942 - accuracy: 0.6867 - val_loss: 0.6167 - val_accuracy: 0.6371\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5925 - accuracy: 0.6891 - val_loss: 0.6181 - val_accuracy: 0.6347\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5920 - accuracy: 0.6880 - val_loss: 0.6184 - val_accuracy: 0.6334\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.5892 - accuracy: 0.6921 - val_loss: 0.6134 - val_accuracy: 0.6373\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5885 - accuracy: 0.6924 - val_loss: 0.6161 - val_accuracy: 0.6347\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5869 - accuracy: 0.6930 - val_loss: 0.6156 - val_accuracy: 0.6343\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5862 - accuracy: 0.6925 - val_loss: 0.6062 - val_accuracy: 0.6428\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5841 - accuracy: 0.6954 - val_loss: 0.6128 - val_accuracy: 0.6354\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5829 - accuracy: 0.6980 - val_loss: 0.6125 - val_accuracy: 0.6350\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5810 - accuracy: 0.6981 - val_loss: 0.6060 - val_accuracy: 0.6417\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5800 - accuracy: 0.6993 - val_loss: 0.6104 - val_accuracy: 0.6362\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5781 - accuracy: 0.6990 - val_loss: 0.6094 - val_accuracy: 0.6372\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.7194 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.7203 - accuracy: 0.5141 - val_loss: 0.6953 - val_accuracy: 0.4881\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.7075 - accuracy: 0.5281 - val_loss: 0.7026 - val_accuracy: 0.4715\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6980 - accuracy: 0.5429 - val_loss: 0.6939 - val_accuracy: 0.5148\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6906 - accuracy: 0.5536 - val_loss: 0.6896 - val_accuracy: 0.5353\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6868 - accuracy: 0.5589 - val_loss: 0.6847 - val_accuracy: 0.5532\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6807 - accuracy: 0.5731 - val_loss: 0.6877 - val_accuracy: 0.5483\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6773 - accuracy: 0.5772 - val_loss: 0.6834 - val_accuracy: 0.5591\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6718 - accuracy: 0.5876 - val_loss: 0.6797 - val_accuracy: 0.5712\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6695 - accuracy: 0.5938 - val_loss: 0.6728 - val_accuracy: 0.5955\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6652 - accuracy: 0.5985 - val_loss: 0.6751 - val_accuracy: 0.5864\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6624 - accuracy: 0.6057 - val_loss: 0.6742 - val_accuracy: 0.5900\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6573 - accuracy: 0.6147 - val_loss: 0.6684 - val_accuracy: 0.6078\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6556 - accuracy: 0.6182 - val_loss: 0.6634 - val_accuracy: 0.6188\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6515 - accuracy: 0.6246 - val_loss: 0.6649 - val_accuracy: 0.6137\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6484 - accuracy: 0.6303 - val_loss: 0.6595 - val_accuracy: 0.6221\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6451 - accuracy: 0.6361 - val_loss: 0.6566 - val_accuracy: 0.6265\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6443 - accuracy: 0.6364 - val_loss: 0.6552 - val_accuracy: 0.6270\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6410 - accuracy: 0.6412 - val_loss: 0.6493 - val_accuracy: 0.6360\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6380 - accuracy: 0.6466 - val_loss: 0.6542 - val_accuracy: 0.6250\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6351 - accuracy: 0.6507 - val_loss: 0.6481 - val_accuracy: 0.6342\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6318 - accuracy: 0.6497 - val_loss: 0.6508 - val_accuracy: 0.6272\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6311 - accuracy: 0.6522 - val_loss: 0.6453 - val_accuracy: 0.6351\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6283 - accuracy: 0.6596 - val_loss: 0.6397 - val_accuracy: 0.6422\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6255 - accuracy: 0.6603 - val_loss: 0.6428 - val_accuracy: 0.6372\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6237 - accuracy: 0.6635 - val_loss: 0.6475 - val_accuracy: 0.6291\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6216 - accuracy: 0.6651 - val_loss: 0.6395 - val_accuracy: 0.6397\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6197 - accuracy: 0.6666 - val_loss: 0.6351 - val_accuracy: 0.6444\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6178 - accuracy: 0.6678 - val_loss: 0.6327 - val_accuracy: 0.6464\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6144 - accuracy: 0.6718 - val_loss: 0.6347 - val_accuracy: 0.6418\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6126 - accuracy: 0.6731 - val_loss: 0.6327 - val_accuracy: 0.6434\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6120 - accuracy: 0.6725 - val_loss: 0.6332 - val_accuracy: 0.6430\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.6099 - accuracy: 0.6750 - val_loss: 0.6303 - val_accuracy: 0.6445\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.6080 - accuracy: 0.6757 - val_loss: 0.6215 - val_accuracy: 0.6569\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 852us/step - loss: 0.6052 - accuracy: 0.6785 - val_loss: 0.6288 - val_accuracy: 0.6453\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 815us/step - loss: 0.6048 - accuracy: 0.6797 - val_loss: 0.6219 - val_accuracy: 0.6550\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.6021 - accuracy: 0.6840 - val_loss: 0.6167 - val_accuracy: 0.6603\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 850us/step - loss: 0.6010 - accuracy: 0.6842 - val_loss: 0.6282 - val_accuracy: 0.6462\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.5994 - accuracy: 0.6838 - val_loss: 0.6221 - val_accuracy: 0.6525\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 788us/step - loss: 0.5973 - accuracy: 0.6839 - val_loss: 0.6187 - val_accuracy: 0.6554\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5956 - accuracy: 0.6888 - val_loss: 0.6168 - val_accuracy: 0.6564\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.5933 - accuracy: 0.6888 - val_loss: 0.6166 - val_accuracy: 0.6553\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.5935 - accuracy: 0.6925 - val_loss: 0.6203 - val_accuracy: 0.6510\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 791us/step - loss: 0.5920 - accuracy: 0.6917 - val_loss: 0.6142 - val_accuracy: 0.6566\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5899 - accuracy: 0.6927 - val_loss: 0.6132 - val_accuracy: 0.6569\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 811us/step - loss: 0.5882 - accuracy: 0.6934 - val_loss: 0.6132 - val_accuracy: 0.6566\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5883 - accuracy: 0.6932 - val_loss: 0.6064 - val_accuracy: 0.6619\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.5862 - accuracy: 0.6971 - val_loss: 0.6159 - val_accuracy: 0.6501\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5845 - accuracy: 0.6984 - val_loss: 0.6110 - val_accuracy: 0.6527\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.5839 - accuracy: 0.6976 - val_loss: 0.6085 - val_accuracy: 0.6543\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5819 - accuracy: 0.7002 - val_loss: 0.6108 - val_accuracy: 0.6503\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 809us/step - loss: 0.6962 - accuracy: 0.5223 - val_loss: 0.6864 - val_accuracy: 0.5433\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.6826 - accuracy: 0.5595 - val_loss: 0.6945 - val_accuracy: 0.5248\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.6774 - accuracy: 0.5755 - val_loss: 0.6923 - val_accuracy: 0.5377\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 719us/step - loss: 0.6723 - accuracy: 0.5877 - val_loss: 0.6868 - val_accuracy: 0.5568\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.6680 - accuracy: 0.5984 - val_loss: 0.6835 - val_accuracy: 0.5684\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 929us/step - loss: 0.6635 - accuracy: 0.6090 - val_loss: 0.6799 - val_accuracy: 0.5807\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6588 - accuracy: 0.6165 - val_loss: 0.6729 - val_accuracy: 0.6056\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 969us/step - loss: 0.6551 - accuracy: 0.6216 - val_loss: 0.6701 - val_accuracy: 0.6110\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 856us/step - loss: 0.6510 - accuracy: 0.6314 - val_loss: 0.6660 - val_accuracy: 0.6183\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.6485 - accuracy: 0.6349 - val_loss: 0.6653 - val_accuracy: 0.6195\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.6452 - accuracy: 0.6382 - val_loss: 0.6599 - val_accuracy: 0.6278\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6422 - accuracy: 0.6425 - val_loss: 0.6613 - val_accuracy: 0.6239\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 854us/step - loss: 0.6394 - accuracy: 0.6482 - val_loss: 0.6530 - val_accuracy: 0.6339\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.6368 - accuracy: 0.6506 - val_loss: 0.6514 - val_accuracy: 0.6343\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 834us/step - loss: 0.6337 - accuracy: 0.6549 - val_loss: 0.6520 - val_accuracy: 0.6323\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6308 - accuracy: 0.6585 - val_loss: 0.6498 - val_accuracy: 0.6323\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 787us/step - loss: 0.6289 - accuracy: 0.6586 - val_loss: 0.6428 - val_accuracy: 0.6396\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6263 - accuracy: 0.6634 - val_loss: 0.6402 - val_accuracy: 0.6423\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.6243 - accuracy: 0.6663 - val_loss: 0.6465 - val_accuracy: 0.6313\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6220 - accuracy: 0.6674 - val_loss: 0.6347 - val_accuracy: 0.6467\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.6193 - accuracy: 0.6702 - val_loss: 0.6321 - val_accuracy: 0.6481\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6176 - accuracy: 0.6728 - val_loss: 0.6326 - val_accuracy: 0.6457\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 791us/step - loss: 0.6150 - accuracy: 0.6750 - val_loss: 0.6317 - val_accuracy: 0.6450\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6134 - accuracy: 0.6756 - val_loss: 0.6329 - val_accuracy: 0.6420\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.6124 - accuracy: 0.6792 - val_loss: 0.6326 - val_accuracy: 0.6398\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6097 - accuracy: 0.6787 - val_loss: 0.6253 - val_accuracy: 0.6471\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6078 - accuracy: 0.6819 - val_loss: 0.6217 - val_accuracy: 0.6506\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6058 - accuracy: 0.6844 - val_loss: 0.6277 - val_accuracy: 0.6402\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6046 - accuracy: 0.6842 - val_loss: 0.6155 - val_accuracy: 0.6560\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6023 - accuracy: 0.6885 - val_loss: 0.6209 - val_accuracy: 0.6475\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6008 - accuracy: 0.6883 - val_loss: 0.6240 - val_accuracy: 0.6422\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5987 - accuracy: 0.6921 - val_loss: 0.6243 - val_accuracy: 0.6416\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5973 - accuracy: 0.6914 - val_loss: 0.6152 - val_accuracy: 0.6520\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.5952 - accuracy: 0.6929 - val_loss: 0.6183 - val_accuracy: 0.6466\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5938 - accuracy: 0.6942 - val_loss: 0.6186 - val_accuracy: 0.6445\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5919 - accuracy: 0.6970 - val_loss: 0.6106 - val_accuracy: 0.6517\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5896 - accuracy: 0.6978 - val_loss: 0.6118 - val_accuracy: 0.6487\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5895 - accuracy: 0.6976 - val_loss: 0.6165 - val_accuracy: 0.6434\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5876 - accuracy: 0.7003 - val_loss: 0.6144 - val_accuracy: 0.6440\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.5854 - accuracy: 0.7035 - val_loss: 0.6098 - val_accuracy: 0.6469\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5850 - accuracy: 0.7025 - val_loss: 0.6120 - val_accuracy: 0.6441\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5830 - accuracy: 0.7033 - val_loss: 0.6121 - val_accuracy: 0.6436\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.5819 - accuracy: 0.7048 - val_loss: 0.6112 - val_accuracy: 0.6428\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5803 - accuracy: 0.7063 - val_loss: 0.6111 - val_accuracy: 0.6425\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5785 - accuracy: 0.7083 - val_loss: 0.6062 - val_accuracy: 0.6453\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.5788 - accuracy: 0.7090 - val_loss: 0.6097 - val_accuracy: 0.6424\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5769 - accuracy: 0.7090 - val_loss: 0.6104 - val_accuracy: 0.6408\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5753 - accuracy: 0.7116 - val_loss: 0.6136 - val_accuracy: 0.6376\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5739 - accuracy: 0.7122 - val_loss: 0.6131 - val_accuracy: 0.6374\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5732 - accuracy: 0.7112 - val_loss: 0.6114 - val_accuracy: 0.6385\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.7218 - accuracy: 0.5092 - val_loss: 0.7452 - val_accuracy: 0.1862\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.7122 - accuracy: 0.5099 - val_loss: 0.7288 - val_accuracy: 0.2824\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.7041 - accuracy: 0.5235 - val_loss: 0.7173 - val_accuracy: 0.3668\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6998 - accuracy: 0.5268 - val_loss: 0.7156 - val_accuracy: 0.3977\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6944 - accuracy: 0.5349 - val_loss: 0.7133 - val_accuracy: 0.4299\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6917 - accuracy: 0.5375 - val_loss: 0.7102 - val_accuracy: 0.4585\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6869 - accuracy: 0.5508 - val_loss: 0.7035 - val_accuracy: 0.4942\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6827 - accuracy: 0.5583 - val_loss: 0.6954 - val_accuracy: 0.5358\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6817 - accuracy: 0.5593 - val_loss: 0.6993 - val_accuracy: 0.5233\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6777 - accuracy: 0.5690 - val_loss: 0.6975 - val_accuracy: 0.5340\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6749 - accuracy: 0.5738 - val_loss: 0.6911 - val_accuracy: 0.5593\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6727 - accuracy: 0.5793 - val_loss: 0.6930 - val_accuracy: 0.5536\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6693 - accuracy: 0.5888 - val_loss: 0.6874 - val_accuracy: 0.5703\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6675 - accuracy: 0.5893 - val_loss: 0.6858 - val_accuracy: 0.5748\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6633 - accuracy: 0.5980 - val_loss: 0.6839 - val_accuracy: 0.5812\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6622 - accuracy: 0.6026 - val_loss: 0.6826 - val_accuracy: 0.5868\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6594 - accuracy: 0.6075 - val_loss: 0.6781 - val_accuracy: 0.5989\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6570 - accuracy: 0.6127 - val_loss: 0.6774 - val_accuracy: 0.5995\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6548 - accuracy: 0.6174 - val_loss: 0.6757 - val_accuracy: 0.6026\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6517 - accuracy: 0.6197 - val_loss: 0.6732 - val_accuracy: 0.6077\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6498 - accuracy: 0.6255 - val_loss: 0.6724 - val_accuracy: 0.6101\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6471 - accuracy: 0.6289 - val_loss: 0.6673 - val_accuracy: 0.6195\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6460 - accuracy: 0.6293 - val_loss: 0.6692 - val_accuracy: 0.6159\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6423 - accuracy: 0.6360 - val_loss: 0.6644 - val_accuracy: 0.6225\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6417 - accuracy: 0.6367 - val_loss: 0.6649 - val_accuracy: 0.6210\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6395 - accuracy: 0.6393 - val_loss: 0.6628 - val_accuracy: 0.6230\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6366 - accuracy: 0.6433 - val_loss: 0.6619 - val_accuracy: 0.6235\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6358 - accuracy: 0.6420 - val_loss: 0.6606 - val_accuracy: 0.6242\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6335 - accuracy: 0.6457 - val_loss: 0.6580 - val_accuracy: 0.6274\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6316 - accuracy: 0.6495 - val_loss: 0.6570 - val_accuracy: 0.6274\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6307 - accuracy: 0.6494 - val_loss: 0.6573 - val_accuracy: 0.6262\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6279 - accuracy: 0.6526 - val_loss: 0.6537 - val_accuracy: 0.6320\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6252 - accuracy: 0.6546 - val_loss: 0.6511 - val_accuracy: 0.6360\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6230 - accuracy: 0.6584 - val_loss: 0.6491 - val_accuracy: 0.6374\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6228 - accuracy: 0.6566 - val_loss: 0.6489 - val_accuracy: 0.6371\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6205 - accuracy: 0.6583 - val_loss: 0.6517 - val_accuracy: 0.6316\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6202 - accuracy: 0.6591 - val_loss: 0.6436 - val_accuracy: 0.6417\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6172 - accuracy: 0.6625 - val_loss: 0.6434 - val_accuracy: 0.6413\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6150 - accuracy: 0.6645 - val_loss: 0.6461 - val_accuracy: 0.6380\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6151 - accuracy: 0.6617 - val_loss: 0.6411 - val_accuracy: 0.6438\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6127 - accuracy: 0.6659 - val_loss: 0.6359 - val_accuracy: 0.6513\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6102 - accuracy: 0.6678 - val_loss: 0.6376 - val_accuracy: 0.6476\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6095 - accuracy: 0.6678 - val_loss: 0.6387 - val_accuracy: 0.6459\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6078 - accuracy: 0.6689 - val_loss: 0.6342 - val_accuracy: 0.6511\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6059 - accuracy: 0.6717 - val_loss: 0.6346 - val_accuracy: 0.6492\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6044 - accuracy: 0.6743 - val_loss: 0.6360 - val_accuracy: 0.6468\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6028 - accuracy: 0.6730 - val_loss: 0.6366 - val_accuracy: 0.6453\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6017 - accuracy: 0.6761 - val_loss: 0.6267 - val_accuracy: 0.6537\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6004 - accuracy: 0.6757 - val_loss: 0.6268 - val_accuracy: 0.6528\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5983 - accuracy: 0.6802 - val_loss: 0.6277 - val_accuracy: 0.6511\n",
      "\n",
      "Training model with noise_multiplier=2.0...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.0 iterated over 83600 steps satisfies differential privacy with eps = 0.449 and delta = 1e-05.\n",
      "The optimal RDP order is 53.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.7739 - accuracy: 0.4936 - val_loss: 0.7563 - val_accuracy: 0.1973\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.7225 - accuracy: 0.4813 - val_loss: 0.7196 - val_accuracy: 0.3244\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.7126 - accuracy: 0.4933 - val_loss: 0.7108 - val_accuracy: 0.4050\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.7062 - accuracy: 0.5032 - val_loss: 0.7056 - val_accuracy: 0.4538\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6974 - accuracy: 0.5224 - val_loss: 0.7007 - val_accuracy: 0.4947\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6926 - accuracy: 0.5292 - val_loss: 0.6956 - val_accuracy: 0.5202\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6855 - accuracy: 0.5462 - val_loss: 0.6859 - val_accuracy: 0.5531\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6810 - accuracy: 0.5575 - val_loss: 0.6797 - val_accuracy: 0.5699\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6755 - accuracy: 0.5702 - val_loss: 0.6775 - val_accuracy: 0.5719\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6704 - accuracy: 0.5815 - val_loss: 0.6704 - val_accuracy: 0.5873\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6658 - accuracy: 0.5885 - val_loss: 0.6675 - val_accuracy: 0.5881\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6604 - accuracy: 0.5983 - val_loss: 0.6643 - val_accuracy: 0.5944\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.6583 - accuracy: 0.6037 - val_loss: 0.6618 - val_accuracy: 0.5980\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6532 - accuracy: 0.6148 - val_loss: 0.6628 - val_accuracy: 0.5943\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6507 - accuracy: 0.6190 - val_loss: 0.6498 - val_accuracy: 0.6194\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6464 - accuracy: 0.6251 - val_loss: 0.6494 - val_accuracy: 0.6169\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6448 - accuracy: 0.6280 - val_loss: 0.6495 - val_accuracy: 0.6155\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6416 - accuracy: 0.6310 - val_loss: 0.6500 - val_accuracy: 0.6130\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6377 - accuracy: 0.6411 - val_loss: 0.6414 - val_accuracy: 0.6269\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6347 - accuracy: 0.6451 - val_loss: 0.6381 - val_accuracy: 0.6310\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6331 - accuracy: 0.6458 - val_loss: 0.6385 - val_accuracy: 0.6276\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6305 - accuracy: 0.6509 - val_loss: 0.6392 - val_accuracy: 0.6239\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6278 - accuracy: 0.6534 - val_loss: 0.6315 - val_accuracy: 0.6341\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6251 - accuracy: 0.6562 - val_loss: 0.6357 - val_accuracy: 0.6263\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.6224 - accuracy: 0.6597 - val_loss: 0.6261 - val_accuracy: 0.6395\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6189 - accuracy: 0.6625 - val_loss: 0.6269 - val_accuracy: 0.6372\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6172 - accuracy: 0.6653 - val_loss: 0.6252 - val_accuracy: 0.6383\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6160 - accuracy: 0.6652 - val_loss: 0.6217 - val_accuracy: 0.6412\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6127 - accuracy: 0.6679 - val_loss: 0.6228 - val_accuracy: 0.6387\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6117 - accuracy: 0.6695 - val_loss: 0.6228 - val_accuracy: 0.6366\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6089 - accuracy: 0.6732 - val_loss: 0.6158 - val_accuracy: 0.6446\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6064 - accuracy: 0.6753 - val_loss: 0.6195 - val_accuracy: 0.6385\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.6046 - accuracy: 0.6770 - val_loss: 0.6185 - val_accuracy: 0.6381\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6026 - accuracy: 0.6809 - val_loss: 0.6158 - val_accuracy: 0.6397\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6013 - accuracy: 0.6817 - val_loss: 0.6112 - val_accuracy: 0.6458\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5999 - accuracy: 0.6840 - val_loss: 0.6099 - val_accuracy: 0.6468\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5983 - accuracy: 0.6842 - val_loss: 0.6143 - val_accuracy: 0.6396\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5961 - accuracy: 0.6879 - val_loss: 0.6182 - val_accuracy: 0.6337\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5946 - accuracy: 0.6887 - val_loss: 0.6139 - val_accuracy: 0.6386\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5929 - accuracy: 0.6915 - val_loss: 0.6073 - val_accuracy: 0.6468\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.5913 - accuracy: 0.6940 - val_loss: 0.6087 - val_accuracy: 0.6438\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5891 - accuracy: 0.6953 - val_loss: 0.6041 - val_accuracy: 0.6489\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5887 - accuracy: 0.6949 - val_loss: 0.6049 - val_accuracy: 0.6469\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5867 - accuracy: 0.6963 - val_loss: 0.6071 - val_accuracy: 0.6429\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5845 - accuracy: 0.7005 - val_loss: 0.6077 - val_accuracy: 0.6406\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5834 - accuracy: 0.7011 - val_loss: 0.6124 - val_accuracy: 0.6342\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5817 - accuracy: 0.7033 - val_loss: 0.6031 - val_accuracy: 0.6440\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5801 - accuracy: 0.7044 - val_loss: 0.6060 - val_accuracy: 0.6389\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5801 - accuracy: 0.7039 - val_loss: 0.6113 - val_accuracy: 0.6326\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5778 - accuracy: 0.7070 - val_loss: 0.6014 - val_accuracy: 0.6466\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6996 - accuracy: 0.5110 - val_loss: 0.7395 - val_accuracy: 0.2813\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6910 - accuracy: 0.5266 - val_loss: 0.7174 - val_accuracy: 0.3961\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6836 - accuracy: 0.5430 - val_loss: 0.7111 - val_accuracy: 0.4304\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6769 - accuracy: 0.5660 - val_loss: 0.7043 - val_accuracy: 0.4753\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6709 - accuracy: 0.5808 - val_loss: 0.7004 - val_accuracy: 0.4975\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6665 - accuracy: 0.5934 - val_loss: 0.6898 - val_accuracy: 0.5568\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6615 - accuracy: 0.6106 - val_loss: 0.6861 - val_accuracy: 0.5707\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6569 - accuracy: 0.6191 - val_loss: 0.6839 - val_accuracy: 0.5787\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6532 - accuracy: 0.6261 - val_loss: 0.6810 - val_accuracy: 0.5877\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6484 - accuracy: 0.6350 - val_loss: 0.6763 - val_accuracy: 0.5989\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6444 - accuracy: 0.6438 - val_loss: 0.6732 - val_accuracy: 0.6068\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6408 - accuracy: 0.6479 - val_loss: 0.6713 - val_accuracy: 0.6110\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6370 - accuracy: 0.6555 - val_loss: 0.6652 - val_accuracy: 0.6239\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6339 - accuracy: 0.6588 - val_loss: 0.6615 - val_accuracy: 0.6280\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6297 - accuracy: 0.6641 - val_loss: 0.6573 - val_accuracy: 0.6344\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6277 - accuracy: 0.6654 - val_loss: 0.6580 - val_accuracy: 0.6278\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6241 - accuracy: 0.6696 - val_loss: 0.6545 - val_accuracy: 0.6323\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6212 - accuracy: 0.6733 - val_loss: 0.6505 - val_accuracy: 0.6374\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6186 - accuracy: 0.6777 - val_loss: 0.6451 - val_accuracy: 0.6423\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6155 - accuracy: 0.6769 - val_loss: 0.6428 - val_accuracy: 0.6435\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.6127 - accuracy: 0.6795 - val_loss: 0.6430 - val_accuracy: 0.6374\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6100 - accuracy: 0.6820 - val_loss: 0.6394 - val_accuracy: 0.6408\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6072 - accuracy: 0.6828 - val_loss: 0.6372 - val_accuracy: 0.6409\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6055 - accuracy: 0.6840 - val_loss: 0.6355 - val_accuracy: 0.6410\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6027 - accuracy: 0.6876 - val_loss: 0.6309 - val_accuracy: 0.6472\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6004 - accuracy: 0.6886 - val_loss: 0.6295 - val_accuracy: 0.6469\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5987 - accuracy: 0.6898 - val_loss: 0.6275 - val_accuracy: 0.6469\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.5961 - accuracy: 0.6893 - val_loss: 0.6329 - val_accuracy: 0.6352\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5936 - accuracy: 0.6934 - val_loss: 0.6258 - val_accuracy: 0.6440\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.5930 - accuracy: 0.6932 - val_loss: 0.6292 - val_accuracy: 0.6366\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5899 - accuracy: 0.6966 - val_loss: 0.6261 - val_accuracy: 0.6398\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.5877 - accuracy: 0.6969 - val_loss: 0.6192 - val_accuracy: 0.6491\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5863 - accuracy: 0.6984 - val_loss: 0.6194 - val_accuracy: 0.6477\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5837 - accuracy: 0.7001 - val_loss: 0.6195 - val_accuracy: 0.6479\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5828 - accuracy: 0.7010 - val_loss: 0.6177 - val_accuracy: 0.6489\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5805 - accuracy: 0.7021 - val_loss: 0.6148 - val_accuracy: 0.6516\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.5794 - accuracy: 0.7050 - val_loss: 0.6084 - val_accuracy: 0.6592\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5769 - accuracy: 0.7045 - val_loss: 0.6055 - val_accuracy: 0.6618\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5753 - accuracy: 0.7048 - val_loss: 0.6136 - val_accuracy: 0.6528\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5742 - accuracy: 0.7065 - val_loss: 0.6116 - val_accuracy: 0.6541\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.5720 - accuracy: 0.7108 - val_loss: 0.6170 - val_accuracy: 0.6491\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5716 - accuracy: 0.7079 - val_loss: 0.6063 - val_accuracy: 0.6583\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.5696 - accuracy: 0.7099 - val_loss: 0.6167 - val_accuracy: 0.6486\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.5680 - accuracy: 0.7121 - val_loss: 0.6030 - val_accuracy: 0.6608\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5675 - accuracy: 0.7106 - val_loss: 0.6123 - val_accuracy: 0.6522\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5652 - accuracy: 0.7132 - val_loss: 0.6087 - val_accuracy: 0.6549\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5650 - accuracy: 0.7111 - val_loss: 0.6112 - val_accuracy: 0.6524\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5627 - accuracy: 0.7146 - val_loss: 0.6069 - val_accuracy: 0.6545\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5607 - accuracy: 0.7165 - val_loss: 0.6069 - val_accuracy: 0.6542\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.5595 - accuracy: 0.7160 - val_loss: 0.6012 - val_accuracy: 0.6598\n",
      "Epoch 1/50\n",
      "1641/1672 [============================>.] - ETA: 0s - loss: 0.7109 - accuracy: 0.5225WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.7107 - accuracy: 0.5226 - val_loss: 0.7364 - val_accuracy: 0.3410\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6951 - accuracy: 0.5303 - val_loss: 0.7082 - val_accuracy: 0.4481\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6878 - accuracy: 0.5460 - val_loss: 0.7020 - val_accuracy: 0.4817\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.6819 - accuracy: 0.5579 - val_loss: 0.6959 - val_accuracy: 0.5078\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6751 - accuracy: 0.5749 - val_loss: 0.6846 - val_accuracy: 0.5544\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6679 - accuracy: 0.5943 - val_loss: 0.6810 - val_accuracy: 0.5612\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6627 - accuracy: 0.6020 - val_loss: 0.6739 - val_accuracy: 0.5809\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6574 - accuracy: 0.6126 - val_loss: 0.6699 - val_accuracy: 0.5915\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6529 - accuracy: 0.6224 - val_loss: 0.6622 - val_accuracy: 0.6064\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6489 - accuracy: 0.6310 - val_loss: 0.6640 - val_accuracy: 0.6021\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6460 - accuracy: 0.6324 - val_loss: 0.6597 - val_accuracy: 0.6102\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6429 - accuracy: 0.6385 - val_loss: 0.6563 - val_accuracy: 0.6130\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6399 - accuracy: 0.6447 - val_loss: 0.6545 - val_accuracy: 0.6120\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6378 - accuracy: 0.6449 - val_loss: 0.6520 - val_accuracy: 0.6158\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6337 - accuracy: 0.6541 - val_loss: 0.6487 - val_accuracy: 0.6193\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6309 - accuracy: 0.6574 - val_loss: 0.6497 - val_accuracy: 0.6144\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.6277 - accuracy: 0.6619 - val_loss: 0.6449 - val_accuracy: 0.6207\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6263 - accuracy: 0.6632 - val_loss: 0.6413 - val_accuracy: 0.6247\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6235 - accuracy: 0.6689 - val_loss: 0.6379 - val_accuracy: 0.6276\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6219 - accuracy: 0.6694 - val_loss: 0.6387 - val_accuracy: 0.6252\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6185 - accuracy: 0.6756 - val_loss: 0.6349 - val_accuracy: 0.6297\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6166 - accuracy: 0.6779 - val_loss: 0.6391 - val_accuracy: 0.6227\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6145 - accuracy: 0.6797 - val_loss: 0.6305 - val_accuracy: 0.6367\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6115 - accuracy: 0.6827 - val_loss: 0.6300 - val_accuracy: 0.6384\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6097 - accuracy: 0.6867 - val_loss: 0.6298 - val_accuracy: 0.6386\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6080 - accuracy: 0.6881 - val_loss: 0.6280 - val_accuracy: 0.6420\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6058 - accuracy: 0.6884 - val_loss: 0.6304 - val_accuracy: 0.6371\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6041 - accuracy: 0.6920 - val_loss: 0.6244 - val_accuracy: 0.6454\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6018 - accuracy: 0.6951 - val_loss: 0.6269 - val_accuracy: 0.6420\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5999 - accuracy: 0.6954 - val_loss: 0.6265 - val_accuracy: 0.6412\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5984 - accuracy: 0.6959 - val_loss: 0.6251 - val_accuracy: 0.6415\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5961 - accuracy: 0.6994 - val_loss: 0.6221 - val_accuracy: 0.6448\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5946 - accuracy: 0.7008 - val_loss: 0.6130 - val_accuracy: 0.6542\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5934 - accuracy: 0.7014 - val_loss: 0.6206 - val_accuracy: 0.6455\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.5903 - accuracy: 0.7040 - val_loss: 0.6193 - val_accuracy: 0.6451\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5901 - accuracy: 0.7027 - val_loss: 0.6161 - val_accuracy: 0.6476\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.5884 - accuracy: 0.7062 - val_loss: 0.6143 - val_accuracy: 0.6492\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5865 - accuracy: 0.7045 - val_loss: 0.6151 - val_accuracy: 0.6471\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.5853 - accuracy: 0.7066 - val_loss: 0.6113 - val_accuracy: 0.6508\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5833 - accuracy: 0.7090 - val_loss: 0.6053 - val_accuracy: 0.6571\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5821 - accuracy: 0.7090 - val_loss: 0.6142 - val_accuracy: 0.6479\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5812 - accuracy: 0.7082 - val_loss: 0.6133 - val_accuracy: 0.6500\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5790 - accuracy: 0.7114 - val_loss: 0.6092 - val_accuracy: 0.6541\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.5781 - accuracy: 0.7105 - val_loss: 0.6043 - val_accuracy: 0.6576\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5770 - accuracy: 0.7125 - val_loss: 0.6056 - val_accuracy: 0.6566\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.5751 - accuracy: 0.7133 - val_loss: 0.6066 - val_accuracy: 0.6558\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.5736 - accuracy: 0.7139 - val_loss: 0.6079 - val_accuracy: 0.6542\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5734 - accuracy: 0.7144 - val_loss: 0.6078 - val_accuracy: 0.6537\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.5715 - accuracy: 0.7157 - val_loss: 0.6075 - val_accuracy: 0.6535\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5703 - accuracy: 0.7165 - val_loss: 0.6047 - val_accuracy: 0.6545\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.7087 - accuracy: 0.5241 - val_loss: 0.7141 - val_accuracy: 0.3687\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6982 - accuracy: 0.5355 - val_loss: 0.7198 - val_accuracy: 0.3469\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6937 - accuracy: 0.5416 - val_loss: 0.7187 - val_accuracy: 0.3623\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6892 - accuracy: 0.5494 - val_loss: 0.7136 - val_accuracy: 0.3961\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6832 - accuracy: 0.5641 - val_loss: 0.7043 - val_accuracy: 0.4514\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6818 - accuracy: 0.5644 - val_loss: 0.7066 - val_accuracy: 0.4511\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6769 - accuracy: 0.5744 - val_loss: 0.7006 - val_accuracy: 0.4894\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6728 - accuracy: 0.5880 - val_loss: 0.6988 - val_accuracy: 0.5037\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6692 - accuracy: 0.5950 - val_loss: 0.6987 - val_accuracy: 0.5072\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6671 - accuracy: 0.5992 - val_loss: 0.7008 - val_accuracy: 0.5036\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6630 - accuracy: 0.6073 - val_loss: 0.6931 - val_accuracy: 0.5307\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6612 - accuracy: 0.6124 - val_loss: 0.6868 - val_accuracy: 0.5493\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6588 - accuracy: 0.6140 - val_loss: 0.6913 - val_accuracy: 0.5373\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6554 - accuracy: 0.6222 - val_loss: 0.6866 - val_accuracy: 0.5516\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6533 - accuracy: 0.6278 - val_loss: 0.6817 - val_accuracy: 0.5708\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6502 - accuracy: 0.6323 - val_loss: 0.6776 - val_accuracy: 0.5819\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6469 - accuracy: 0.6391 - val_loss: 0.6780 - val_accuracy: 0.5813\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6433 - accuracy: 0.6457 - val_loss: 0.6746 - val_accuracy: 0.5862\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6410 - accuracy: 0.6509 - val_loss: 0.6713 - val_accuracy: 0.5927\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6377 - accuracy: 0.6547 - val_loss: 0.6677 - val_accuracy: 0.5986\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6355 - accuracy: 0.6571 - val_loss: 0.6641 - val_accuracy: 0.6031\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6330 - accuracy: 0.6591 - val_loss: 0.6629 - val_accuracy: 0.6046\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6300 - accuracy: 0.6640 - val_loss: 0.6603 - val_accuracy: 0.6077\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6269 - accuracy: 0.6657 - val_loss: 0.6520 - val_accuracy: 0.6214\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6248 - accuracy: 0.6694 - val_loss: 0.6511 - val_accuracy: 0.6227\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6221 - accuracy: 0.6712 - val_loss: 0.6553 - val_accuracy: 0.6135\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6203 - accuracy: 0.6723 - val_loss: 0.6566 - val_accuracy: 0.6120\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6170 - accuracy: 0.6759 - val_loss: 0.6440 - val_accuracy: 0.6322\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6152 - accuracy: 0.6796 - val_loss: 0.6502 - val_accuracy: 0.6213\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6114 - accuracy: 0.6840 - val_loss: 0.6443 - val_accuracy: 0.6303\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6102 - accuracy: 0.6816 - val_loss: 0.6398 - val_accuracy: 0.6353\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6087 - accuracy: 0.6828 - val_loss: 0.6416 - val_accuracy: 0.6324\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6054 - accuracy: 0.6871 - val_loss: 0.6430 - val_accuracy: 0.6302\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.6039 - accuracy: 0.6882 - val_loss: 0.6367 - val_accuracy: 0.6373\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.6020 - accuracy: 0.6904 - val_loss: 0.6353 - val_accuracy: 0.6397\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 883us/step - loss: 0.6005 - accuracy: 0.6899 - val_loss: 0.6423 - val_accuracy: 0.6288\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 769us/step - loss: 0.5979 - accuracy: 0.6925 - val_loss: 0.6320 - val_accuracy: 0.6430\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.5955 - accuracy: 0.6966 - val_loss: 0.6367 - val_accuracy: 0.6355\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5932 - accuracy: 0.6979 - val_loss: 0.6266 - val_accuracy: 0.6470\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.5924 - accuracy: 0.6985 - val_loss: 0.6290 - val_accuracy: 0.6436\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5899 - accuracy: 0.7010 - val_loss: 0.6272 - val_accuracy: 0.6450\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.5878 - accuracy: 0.7019 - val_loss: 0.6200 - val_accuracy: 0.6525\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5862 - accuracy: 0.7026 - val_loss: 0.6236 - val_accuracy: 0.6468\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.5839 - accuracy: 0.7057 - val_loss: 0.6231 - val_accuracy: 0.6465\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5823 - accuracy: 0.7073 - val_loss: 0.6275 - val_accuracy: 0.6394\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.5804 - accuracy: 0.7070 - val_loss: 0.6184 - val_accuracy: 0.6516\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5802 - accuracy: 0.7048 - val_loss: 0.6110 - val_accuracy: 0.6637\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5781 - accuracy: 0.7082 - val_loss: 0.6216 - val_accuracy: 0.6448\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.5763 - accuracy: 0.7088 - val_loss: 0.6170 - val_accuracy: 0.6514\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5756 - accuracy: 0.7103 - val_loss: 0.6139 - val_accuracy: 0.6581\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.7044 - accuracy: 0.5211 - val_loss: 0.6817 - val_accuracy: 0.5584\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6904 - accuracy: 0.5452 - val_loss: 0.6909 - val_accuracy: 0.5185\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 841us/step - loss: 0.6854 - accuracy: 0.5565 - val_loss: 0.6869 - val_accuracy: 0.5478\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 826us/step - loss: 0.6809 - accuracy: 0.5646 - val_loss: 0.6792 - val_accuracy: 0.5808\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6764 - accuracy: 0.5719 - val_loss: 0.6734 - val_accuracy: 0.6027\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6695 - accuracy: 0.5882 - val_loss: 0.6701 - val_accuracy: 0.6102\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.6675 - accuracy: 0.5923 - val_loss: 0.6726 - val_accuracy: 0.6021\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.6629 - accuracy: 0.6016 - val_loss: 0.6677 - val_accuracy: 0.6123\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6586 - accuracy: 0.6140 - val_loss: 0.6639 - val_accuracy: 0.6172\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6560 - accuracy: 0.6179 - val_loss: 0.6610 - val_accuracy: 0.6214\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6531 - accuracy: 0.6224 - val_loss: 0.6577 - val_accuracy: 0.6261\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6484 - accuracy: 0.6319 - val_loss: 0.6530 - val_accuracy: 0.6328\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.6453 - accuracy: 0.6361 - val_loss: 0.6529 - val_accuracy: 0.6299\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6435 - accuracy: 0.6388 - val_loss: 0.6511 - val_accuracy: 0.6315\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 781us/step - loss: 0.6408 - accuracy: 0.6418 - val_loss: 0.6520 - val_accuracy: 0.6278\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6370 - accuracy: 0.6469 - val_loss: 0.6490 - val_accuracy: 0.6318\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.6349 - accuracy: 0.6502 - val_loss: 0.6435 - val_accuracy: 0.6403\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6323 - accuracy: 0.6529 - val_loss: 0.6432 - val_accuracy: 0.6398\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.6295 - accuracy: 0.6582 - val_loss: 0.6407 - val_accuracy: 0.6443\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.6271 - accuracy: 0.6589 - val_loss: 0.6377 - val_accuracy: 0.6495\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6240 - accuracy: 0.6638 - val_loss: 0.6354 - val_accuracy: 0.6539\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.6207 - accuracy: 0.6680 - val_loss: 0.6327 - val_accuracy: 0.6577\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6193 - accuracy: 0.6690 - val_loss: 0.6367 - val_accuracy: 0.6493\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.6166 - accuracy: 0.6705 - val_loss: 0.6278 - val_accuracy: 0.6643\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6152 - accuracy: 0.6728 - val_loss: 0.6336 - val_accuracy: 0.6542\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6132 - accuracy: 0.6748 - val_loss: 0.6242 - val_accuracy: 0.6700\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6099 - accuracy: 0.6780 - val_loss: 0.6305 - val_accuracy: 0.6596\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6079 - accuracy: 0.6811 - val_loss: 0.6250 - val_accuracy: 0.6680\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 778us/step - loss: 0.6045 - accuracy: 0.6848 - val_loss: 0.6181 - val_accuracy: 0.6738\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6024 - accuracy: 0.6860 - val_loss: 0.6188 - val_accuracy: 0.6720\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 799us/step - loss: 0.6018 - accuracy: 0.6863 - val_loss: 0.6206 - val_accuracy: 0.6695\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5994 - accuracy: 0.6904 - val_loss: 0.6207 - val_accuracy: 0.6686\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.5978 - accuracy: 0.6905 - val_loss: 0.6174 - val_accuracy: 0.6709\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5955 - accuracy: 0.6928 - val_loss: 0.6125 - val_accuracy: 0.6762\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.5935 - accuracy: 0.6939 - val_loss: 0.6144 - val_accuracy: 0.6730\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5918 - accuracy: 0.6975 - val_loss: 0.6166 - val_accuracy: 0.6690\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5907 - accuracy: 0.6962 - val_loss: 0.6071 - val_accuracy: 0.6780\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5888 - accuracy: 0.6990 - val_loss: 0.6124 - val_accuracy: 0.6710\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5863 - accuracy: 0.7007 - val_loss: 0.6163 - val_accuracy: 0.6638\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5848 - accuracy: 0.7021 - val_loss: 0.6080 - val_accuracy: 0.6725\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.5828 - accuracy: 0.7047 - val_loss: 0.6097 - val_accuracy: 0.6699\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5824 - accuracy: 0.7034 - val_loss: 0.6095 - val_accuracy: 0.6687\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5804 - accuracy: 0.7090 - val_loss: 0.6147 - val_accuracy: 0.6631\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5788 - accuracy: 0.7086 - val_loss: 0.6091 - val_accuracy: 0.6665\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.5778 - accuracy: 0.7080 - val_loss: 0.6016 - val_accuracy: 0.6721\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 813us/step - loss: 0.5759 - accuracy: 0.7095 - val_loss: 0.6051 - val_accuracy: 0.6679\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5750 - accuracy: 0.7122 - val_loss: 0.6022 - val_accuracy: 0.6691\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5732 - accuracy: 0.7137 - val_loss: 0.6063 - val_accuracy: 0.6658\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5720 - accuracy: 0.7135 - val_loss: 0.5987 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5702 - accuracy: 0.7155 - val_loss: 0.5974 - val_accuracy: 0.6690\n",
      "\n",
      "Training model with noise_multiplier=2.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.5 iterated over 83600 steps satisfies differential privacy with eps = 0.35 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6969 - accuracy: 0.5098 - val_loss: 0.7055 - val_accuracy: 0.4131\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 974us/step - loss: 0.6840 - accuracy: 0.5475 - val_loss: 0.6977 - val_accuracy: 0.4800\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 915us/step - loss: 0.6752 - accuracy: 0.5716 - val_loss: 0.6900 - val_accuracy: 0.5431\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 886us/step - loss: 0.6675 - accuracy: 0.5908 - val_loss: 0.6828 - val_accuracy: 0.5829\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 798us/step - loss: 0.6604 - accuracy: 0.6077 - val_loss: 0.6775 - val_accuracy: 0.6031\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 822us/step - loss: 0.6548 - accuracy: 0.6183 - val_loss: 0.6755 - val_accuracy: 0.6098\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 899us/step - loss: 0.6503 - accuracy: 0.6280 - val_loss: 0.6670 - val_accuracy: 0.6268\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 890us/step - loss: 0.6466 - accuracy: 0.6296 - val_loss: 0.6640 - val_accuracy: 0.6295\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 845us/step - loss: 0.6423 - accuracy: 0.6377 - val_loss: 0.6577 - val_accuracy: 0.6362\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 905us/step - loss: 0.6395 - accuracy: 0.6399 - val_loss: 0.6509 - val_accuracy: 0.6468\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 921us/step - loss: 0.6360 - accuracy: 0.6451 - val_loss: 0.6513 - val_accuracy: 0.6426\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 841us/step - loss: 0.6319 - accuracy: 0.6492 - val_loss: 0.6520 - val_accuracy: 0.6415\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 846us/step - loss: 0.6304 - accuracy: 0.6534 - val_loss: 0.6507 - val_accuracy: 0.6424\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 825us/step - loss: 0.6277 - accuracy: 0.6563 - val_loss: 0.6443 - val_accuracy: 0.6513\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 800us/step - loss: 0.6258 - accuracy: 0.6565 - val_loss: 0.6421 - val_accuracy: 0.6544\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 801us/step - loss: 0.6225 - accuracy: 0.6579 - val_loss: 0.6384 - val_accuracy: 0.6574\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 794us/step - loss: 0.6200 - accuracy: 0.6638 - val_loss: 0.6357 - val_accuracy: 0.6576\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 774us/step - loss: 0.6191 - accuracy: 0.6619 - val_loss: 0.6368 - val_accuracy: 0.6560\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 864us/step - loss: 0.6166 - accuracy: 0.6651 - val_loss: 0.6301 - val_accuracy: 0.6606\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 891us/step - loss: 0.6133 - accuracy: 0.6685 - val_loss: 0.6325 - val_accuracy: 0.6570\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6118 - accuracy: 0.6706 - val_loss: 0.6312 - val_accuracy: 0.6561\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 901us/step - loss: 0.6100 - accuracy: 0.6738 - val_loss: 0.6274 - val_accuracy: 0.6591\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 920us/step - loss: 0.6076 - accuracy: 0.6733 - val_loss: 0.6289 - val_accuracy: 0.6553\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.6058 - accuracy: 0.6757 - val_loss: 0.6265 - val_accuracy: 0.6564\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.6039 - accuracy: 0.6779 - val_loss: 0.6245 - val_accuracy: 0.6566\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6024 - accuracy: 0.6801 - val_loss: 0.6226 - val_accuracy: 0.6564\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6003 - accuracy: 0.6806 - val_loss: 0.6233 - val_accuracy: 0.6548\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5984 - accuracy: 0.6832 - val_loss: 0.6245 - val_accuracy: 0.6521\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5967 - accuracy: 0.6843 - val_loss: 0.6211 - val_accuracy: 0.6554\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5954 - accuracy: 0.6861 - val_loss: 0.6188 - val_accuracy: 0.6552\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5939 - accuracy: 0.6866 - val_loss: 0.6124 - val_accuracy: 0.6617\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5926 - accuracy: 0.6870 - val_loss: 0.6154 - val_accuracy: 0.6562\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5893 - accuracy: 0.6930 - val_loss: 0.6087 - val_accuracy: 0.6617\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5883 - accuracy: 0.6914 - val_loss: 0.6078 - val_accuracy: 0.6623\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5870 - accuracy: 0.6928 - val_loss: 0.6169 - val_accuracy: 0.6516\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 953us/step - loss: 0.5858 - accuracy: 0.6945 - val_loss: 0.6113 - val_accuracy: 0.6548\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 904us/step - loss: 0.5840 - accuracy: 0.6948 - val_loss: 0.6090 - val_accuracy: 0.6568\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 927us/step - loss: 0.5825 - accuracy: 0.6992 - val_loss: 0.6106 - val_accuracy: 0.6537\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 976us/step - loss: 0.5813 - accuracy: 0.6981 - val_loss: 0.6093 - val_accuracy: 0.6537\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5795 - accuracy: 0.7027 - val_loss: 0.6074 - val_accuracy: 0.6540\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5787 - accuracy: 0.7033 - val_loss: 0.6067 - val_accuracy: 0.6542\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 921us/step - loss: 0.5769 - accuracy: 0.7060 - val_loss: 0.6016 - val_accuracy: 0.6594\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5754 - accuracy: 0.7049 - val_loss: 0.6053 - val_accuracy: 0.6559\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5741 - accuracy: 0.7073 - val_loss: 0.6052 - val_accuracy: 0.6556\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 946us/step - loss: 0.5727 - accuracy: 0.7093 - val_loss: 0.6070 - val_accuracy: 0.6529\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5719 - accuracy: 0.7122 - val_loss: 0.6082 - val_accuracy: 0.6524\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 895us/step - loss: 0.5699 - accuracy: 0.7123 - val_loss: 0.6057 - val_accuracy: 0.6548\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 968us/step - loss: 0.5687 - accuracy: 0.7134 - val_loss: 0.6059 - val_accuracy: 0.6540\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 894us/step - loss: 0.5676 - accuracy: 0.7155 - val_loss: 0.6060 - val_accuracy: 0.6538\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 937us/step - loss: 0.5673 - accuracy: 0.7146 - val_loss: 0.6014 - val_accuracy: 0.6566\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6880 - accuracy: 0.5578 - val_loss: 0.6939 - val_accuracy: 0.5180\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 961us/step - loss: 0.6779 - accuracy: 0.5749 - val_loss: 0.6818 - val_accuracy: 0.5525\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 809us/step - loss: 0.6692 - accuracy: 0.5889 - val_loss: 0.6758 - val_accuracy: 0.5650\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 828us/step - loss: 0.6645 - accuracy: 0.5980 - val_loss: 0.6757 - val_accuracy: 0.5661\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 826us/step - loss: 0.6570 - accuracy: 0.6135 - val_loss: 0.6665 - val_accuracy: 0.5811\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 788us/step - loss: 0.6511 - accuracy: 0.6180 - val_loss: 0.6609 - val_accuracy: 0.5903\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.6474 - accuracy: 0.6252 - val_loss: 0.6497 - val_accuracy: 0.6043\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 896us/step - loss: 0.6424 - accuracy: 0.6329 - val_loss: 0.6541 - val_accuracy: 0.5985\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.6392 - accuracy: 0.6335 - val_loss: 0.6512 - val_accuracy: 0.6009\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.6346 - accuracy: 0.6398 - val_loss: 0.6500 - val_accuracy: 0.5991\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 814us/step - loss: 0.6335 - accuracy: 0.6427 - val_loss: 0.6375 - val_accuracy: 0.6161\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 881us/step - loss: 0.6307 - accuracy: 0.6456 - val_loss: 0.6417 - val_accuracy: 0.6039\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 820us/step - loss: 0.6283 - accuracy: 0.6469 - val_loss: 0.6434 - val_accuracy: 0.6001\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.6257 - accuracy: 0.6520 - val_loss: 0.6388 - val_accuracy: 0.6071\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 833us/step - loss: 0.6241 - accuracy: 0.6532 - val_loss: 0.6382 - val_accuracy: 0.6077\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 840us/step - loss: 0.6208 - accuracy: 0.6579 - val_loss: 0.6348 - val_accuracy: 0.6137\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 983us/step - loss: 0.6191 - accuracy: 0.6586 - val_loss: 0.6314 - val_accuracy: 0.6186\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 958us/step - loss: 0.6178 - accuracy: 0.6600 - val_loss: 0.6335 - val_accuracy: 0.6150\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6146 - accuracy: 0.6626 - val_loss: 0.6294 - val_accuracy: 0.6193\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.6135 - accuracy: 0.6623 - val_loss: 0.6306 - val_accuracy: 0.6177\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 864us/step - loss: 0.6114 - accuracy: 0.6651 - val_loss: 0.6312 - val_accuracy: 0.6167\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6100 - accuracy: 0.6682 - val_loss: 0.6266 - val_accuracy: 0.6218\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 978us/step - loss: 0.6090 - accuracy: 0.6675 - val_loss: 0.6304 - val_accuracy: 0.6188\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6064 - accuracy: 0.6725 - val_loss: 0.6249 - val_accuracy: 0.6228\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6053 - accuracy: 0.6719 - val_loss: 0.6225 - val_accuracy: 0.6245\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6048 - accuracy: 0.6744 - val_loss: 0.6254 - val_accuracy: 0.6221\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6029 - accuracy: 0.6771 - val_loss: 0.6262 - val_accuracy: 0.6219\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 876us/step - loss: 0.6018 - accuracy: 0.6753 - val_loss: 0.6234 - val_accuracy: 0.6226\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6002 - accuracy: 0.6771 - val_loss: 0.6196 - val_accuracy: 0.6231\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 978us/step - loss: 0.5985 - accuracy: 0.6808 - val_loss: 0.6167 - val_accuracy: 0.6239\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 808us/step - loss: 0.5976 - accuracy: 0.6807 - val_loss: 0.6226 - val_accuracy: 0.6216\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5962 - accuracy: 0.6833 - val_loss: 0.6195 - val_accuracy: 0.6211\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 933us/step - loss: 0.5952 - accuracy: 0.6831 - val_loss: 0.6247 - val_accuracy: 0.6178\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5935 - accuracy: 0.6845 - val_loss: 0.6160 - val_accuracy: 0.6239\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5929 - accuracy: 0.6862 - val_loss: 0.6231 - val_accuracy: 0.6185\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5918 - accuracy: 0.6861 - val_loss: 0.6162 - val_accuracy: 0.6257\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5893 - accuracy: 0.6891 - val_loss: 0.6178 - val_accuracy: 0.6241\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 806us/step - loss: 0.5892 - accuracy: 0.6892 - val_loss: 0.6146 - val_accuracy: 0.6334\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5879 - accuracy: 0.6902 - val_loss: 0.6123 - val_accuracy: 0.6362\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 865us/step - loss: 0.5864 - accuracy: 0.6916 - val_loss: 0.6125 - val_accuracy: 0.6356\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5855 - accuracy: 0.6940 - val_loss: 0.6231 - val_accuracy: 0.6195\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 915us/step - loss: 0.5845 - accuracy: 0.6948 - val_loss: 0.6127 - val_accuracy: 0.6334\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.5834 - accuracy: 0.6954 - val_loss: 0.6162 - val_accuracy: 0.6304\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5821 - accuracy: 0.6968 - val_loss: 0.6151 - val_accuracy: 0.6312\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 825us/step - loss: 0.5809 - accuracy: 0.6978 - val_loss: 0.6123 - val_accuracy: 0.6318\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5797 - accuracy: 0.6988 - val_loss: 0.6192 - val_accuracy: 0.6279\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 844us/step - loss: 0.5791 - accuracy: 0.6995 - val_loss: 0.6156 - val_accuracy: 0.6308\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 916us/step - loss: 0.5779 - accuracy: 0.7009 - val_loss: 0.6159 - val_accuracy: 0.6301\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 971us/step - loss: 0.5779 - accuracy: 0.7014 - val_loss: 0.6086 - val_accuracy: 0.6328\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 893us/step - loss: 0.5759 - accuracy: 0.7014 - val_loss: 0.6071 - val_accuracy: 0.6352\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7067 - accuracy: 0.5345 - val_loss: 0.7534 - val_accuracy: 0.3311\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 836us/step - loss: 0.6838 - accuracy: 0.5574 - val_loss: 0.7038 - val_accuracy: 0.5232\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 912us/step - loss: 0.6771 - accuracy: 0.5742 - val_loss: 0.6926 - val_accuracy: 0.5667\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6721 - accuracy: 0.5870 - val_loss: 0.6892 - val_accuracy: 0.5756\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6668 - accuracy: 0.6047 - val_loss: 0.6841 - val_accuracy: 0.5843\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 969us/step - loss: 0.6631 - accuracy: 0.6108 - val_loss: 0.6775 - val_accuracy: 0.5992\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 776us/step - loss: 0.6595 - accuracy: 0.6171 - val_loss: 0.6792 - val_accuracy: 0.5919\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 850us/step - loss: 0.6558 - accuracy: 0.6237 - val_loss: 0.6743 - val_accuracy: 0.6010\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 869us/step - loss: 0.6533 - accuracy: 0.6299 - val_loss: 0.6687 - val_accuracy: 0.6117\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6499 - accuracy: 0.6337 - val_loss: 0.6683 - val_accuracy: 0.6084\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6464 - accuracy: 0.6408 - val_loss: 0.6645 - val_accuracy: 0.6165\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6443 - accuracy: 0.6457 - val_loss: 0.6637 - val_accuracy: 0.6148\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 973us/step - loss: 0.6405 - accuracy: 0.6494 - val_loss: 0.6567 - val_accuracy: 0.6262\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 830us/step - loss: 0.6378 - accuracy: 0.6548 - val_loss: 0.6608 - val_accuracy: 0.6122\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 852us/step - loss: 0.6354 - accuracy: 0.6593 - val_loss: 0.6557 - val_accuracy: 0.6201\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 842us/step - loss: 0.6326 - accuracy: 0.6603 - val_loss: 0.6542 - val_accuracy: 0.6216\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 833us/step - loss: 0.6291 - accuracy: 0.6675 - val_loss: 0.6511 - val_accuracy: 0.6280\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 831us/step - loss: 0.6265 - accuracy: 0.6703 - val_loss: 0.6467 - val_accuracy: 0.6344\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 829us/step - loss: 0.6239 - accuracy: 0.6732 - val_loss: 0.6449 - val_accuracy: 0.6341\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 859us/step - loss: 0.6226 - accuracy: 0.6725 - val_loss: 0.6441 - val_accuracy: 0.6328\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 837us/step - loss: 0.6196 - accuracy: 0.6761 - val_loss: 0.6439 - val_accuracy: 0.6318\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 840us/step - loss: 0.6167 - accuracy: 0.6798 - val_loss: 0.6380 - val_accuracy: 0.6366\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 849us/step - loss: 0.6159 - accuracy: 0.6813 - val_loss: 0.6411 - val_accuracy: 0.6316\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 832us/step - loss: 0.6130 - accuracy: 0.6832 - val_loss: 0.6361 - val_accuracy: 0.6355\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 854us/step - loss: 0.6112 - accuracy: 0.6868 - val_loss: 0.6363 - val_accuracy: 0.6337\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 796us/step - loss: 0.6086 - accuracy: 0.6873 - val_loss: 0.6375 - val_accuracy: 0.6307\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 848us/step - loss: 0.6065 - accuracy: 0.6888 - val_loss: 0.6303 - val_accuracy: 0.6434\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 843us/step - loss: 0.6044 - accuracy: 0.6922 - val_loss: 0.6312 - val_accuracy: 0.6409\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 798us/step - loss: 0.6028 - accuracy: 0.6936 - val_loss: 0.6297 - val_accuracy: 0.6425\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 866us/step - loss: 0.6010 - accuracy: 0.6940 - val_loss: 0.6262 - val_accuracy: 0.6454\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 834us/step - loss: 0.5986 - accuracy: 0.6970 - val_loss: 0.6279 - val_accuracy: 0.6427\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 841us/step - loss: 0.5965 - accuracy: 0.6976 - val_loss: 0.6269 - val_accuracy: 0.6438\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 848us/step - loss: 0.5947 - accuracy: 0.7001 - val_loss: 0.6244 - val_accuracy: 0.6457\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 828us/step - loss: 0.5932 - accuracy: 0.7015 - val_loss: 0.6226 - val_accuracy: 0.6467\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 850us/step - loss: 0.5918 - accuracy: 0.7007 - val_loss: 0.6218 - val_accuracy: 0.6469\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 836us/step - loss: 0.5889 - accuracy: 0.7036 - val_loss: 0.6221 - val_accuracy: 0.6462\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 852us/step - loss: 0.5872 - accuracy: 0.7058 - val_loss: 0.6201 - val_accuracy: 0.6474\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 822us/step - loss: 0.5862 - accuracy: 0.7067 - val_loss: 0.6177 - val_accuracy: 0.6493\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 820us/step - loss: 0.5838 - accuracy: 0.7092 - val_loss: 0.6188 - val_accuracy: 0.6479\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 837us/step - loss: 0.5824 - accuracy: 0.7086 - val_loss: 0.6205 - val_accuracy: 0.6455\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 884us/step - loss: 0.5809 - accuracy: 0.7106 - val_loss: 0.6116 - val_accuracy: 0.6582\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5790 - accuracy: 0.7113 - val_loss: 0.6128 - val_accuracy: 0.6562\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 872us/step - loss: 0.5774 - accuracy: 0.7119 - val_loss: 0.6153 - val_accuracy: 0.6521\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 859us/step - loss: 0.5749 - accuracy: 0.7140 - val_loss: 0.6168 - val_accuracy: 0.6506\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 898us/step - loss: 0.5744 - accuracy: 0.7126 - val_loss: 0.6088 - val_accuracy: 0.6611\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 888us/step - loss: 0.5721 - accuracy: 0.7166 - val_loss: 0.6110 - val_accuracy: 0.6587\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 897us/step - loss: 0.5712 - accuracy: 0.7157 - val_loss: 0.6134 - val_accuracy: 0.6545\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 930us/step - loss: 0.5702 - accuracy: 0.7165 - val_loss: 0.6116 - val_accuracy: 0.6573\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5673 - accuracy: 0.7201 - val_loss: 0.6085 - val_accuracy: 0.6608\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 886us/step - loss: 0.5671 - accuracy: 0.7181 - val_loss: 0.5977 - val_accuracy: 0.6721\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.7052 - accuracy: 0.5029 - val_loss: 0.7317 - val_accuracy: 0.2573\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6998 - accuracy: 0.5129 - val_loss: 0.7287 - val_accuracy: 0.2676\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6935 - accuracy: 0.5329 - val_loss: 0.7263 - val_accuracy: 0.2748\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.7214 - val_accuracy: 0.3254\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6842 - accuracy: 0.5573 - val_loss: 0.7120 - val_accuracy: 0.4010\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6797 - accuracy: 0.5717 - val_loss: 0.7049 - val_accuracy: 0.4584\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6741 - accuracy: 0.5896 - val_loss: 0.7044 - val_accuracy: 0.4698\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6696 - accuracy: 0.6017 - val_loss: 0.7032 - val_accuracy: 0.4862\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6657 - accuracy: 0.6120 - val_loss: 0.6983 - val_accuracy: 0.5075\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6613 - accuracy: 0.6241 - val_loss: 0.6929 - val_accuracy: 0.5269\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6580 - accuracy: 0.6290 - val_loss: 0.6868 - val_accuracy: 0.5477\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6549 - accuracy: 0.6364 - val_loss: 0.6876 - val_accuracy: 0.5476\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 925us/step - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6844 - val_accuracy: 0.5565\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6461 - accuracy: 0.6544 - val_loss: 0.6797 - val_accuracy: 0.5709\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6420 - accuracy: 0.6604 - val_loss: 0.6819 - val_accuracy: 0.5646\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 931us/step - loss: 0.6394 - accuracy: 0.6626 - val_loss: 0.6728 - val_accuracy: 0.5842\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6368 - accuracy: 0.6668 - val_loss: 0.6735 - val_accuracy: 0.5829\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6336 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 0.5944\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6311 - accuracy: 0.6712 - val_loss: 0.6613 - val_accuracy: 0.6028\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6274 - accuracy: 0.6782 - val_loss: 0.6607 - val_accuracy: 0.6030\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 929us/step - loss: 0.6247 - accuracy: 0.6791 - val_loss: 0.6599 - val_accuracy: 0.6033\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6202 - accuracy: 0.6841 - val_loss: 0.6593 - val_accuracy: 0.6022\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 878us/step - loss: 0.6188 - accuracy: 0.6852 - val_loss: 0.6549 - val_accuracy: 0.6088\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 937us/step - loss: 0.6161 - accuracy: 0.6864 - val_loss: 0.6514 - val_accuracy: 0.6151\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 977us/step - loss: 0.6135 - accuracy: 0.6873 - val_loss: 0.6470 - val_accuracy: 0.6219\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.6112 - accuracy: 0.6909 - val_loss: 0.6446 - val_accuracy: 0.6262\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6077 - accuracy: 0.6941 - val_loss: 0.6423 - val_accuracy: 0.6298\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 951us/step - loss: 0.6052 - accuracy: 0.6962 - val_loss: 0.6424 - val_accuracy: 0.6286\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 920us/step - loss: 0.6032 - accuracy: 0.6946 - val_loss: 0.6349 - val_accuracy: 0.6429\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6012 - accuracy: 0.6963 - val_loss: 0.6349 - val_accuracy: 0.6398\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 822us/step - loss: 0.5984 - accuracy: 0.6982 - val_loss: 0.6357 - val_accuracy: 0.6366\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5981 - accuracy: 0.6979 - val_loss: 0.6323 - val_accuracy: 0.6410\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 831us/step - loss: 0.5945 - accuracy: 0.6996 - val_loss: 0.6324 - val_accuracy: 0.6395\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5929 - accuracy: 0.7017 - val_loss: 0.6294 - val_accuracy: 0.6420\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 872us/step - loss: 0.5915 - accuracy: 0.7024 - val_loss: 0.6245 - val_accuracy: 0.6489\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 997us/step - loss: 0.5890 - accuracy: 0.7032 - val_loss: 0.6266 - val_accuracy: 0.6444\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 977us/step - loss: 0.5860 - accuracy: 0.7056 - val_loss: 0.6272 - val_accuracy: 0.6418\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 918us/step - loss: 0.5845 - accuracy: 0.7050 - val_loss: 0.6223 - val_accuracy: 0.6490\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5825 - accuracy: 0.7076 - val_loss: 0.6269 - val_accuracy: 0.6404\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 824us/step - loss: 0.5811 - accuracy: 0.7087 - val_loss: 0.6161 - val_accuracy: 0.6551\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5795 - accuracy: 0.7076 - val_loss: 0.6181 - val_accuracy: 0.6510\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 816us/step - loss: 0.5774 - accuracy: 0.7106 - val_loss: 0.6156 - val_accuracy: 0.6531\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5756 - accuracy: 0.7133 - val_loss: 0.6148 - val_accuracy: 0.6532\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 927us/step - loss: 0.5744 - accuracy: 0.7122 - val_loss: 0.6127 - val_accuracy: 0.6545\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 892us/step - loss: 0.5730 - accuracy: 0.7135 - val_loss: 0.6094 - val_accuracy: 0.6574\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 826us/step - loss: 0.5719 - accuracy: 0.7125 - val_loss: 0.6084 - val_accuracy: 0.6581\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.5694 - accuracy: 0.7139 - val_loss: 0.6097 - val_accuracy: 0.6561\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.5676 - accuracy: 0.7170 - val_loss: 0.6055 - val_accuracy: 0.6593\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 742us/step - loss: 0.5660 - accuracy: 0.7154 - val_loss: 0.6125 - val_accuracy: 0.6518\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.5654 - accuracy: 0.7168 - val_loss: 0.6074 - val_accuracy: 0.6575\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.7210 - accuracy: 0.4845 - val_loss: 0.7277 - val_accuracy: 0.3241\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 719us/step - loss: 0.7067 - accuracy: 0.5067 - val_loss: 0.7105 - val_accuracy: 0.4495\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.6950 - accuracy: 0.5374 - val_loss: 0.6999 - val_accuracy: 0.4947\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.6837 - accuracy: 0.5628 - val_loss: 0.6947 - val_accuracy: 0.5270\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.6746 - accuracy: 0.5857 - val_loss: 0.6818 - val_accuracy: 0.5687\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6681 - accuracy: 0.5999 - val_loss: 0.6790 - val_accuracy: 0.5717\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.6643 - accuracy: 0.6065 - val_loss: 0.6760 - val_accuracy: 0.5769\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.6573 - accuracy: 0.6221 - val_loss: 0.6712 - val_accuracy: 0.5859\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.6540 - accuracy: 0.6285 - val_loss: 0.6670 - val_accuracy: 0.5976\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.6490 - accuracy: 0.6381 - val_loss: 0.6629 - val_accuracy: 0.6058\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.6451 - accuracy: 0.6454 - val_loss: 0.6617 - val_accuracy: 0.6077\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.6413 - accuracy: 0.6522 - val_loss: 0.6546 - val_accuracy: 0.6188\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.6375 - accuracy: 0.6569 - val_loss: 0.6565 - val_accuracy: 0.6144\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.6336 - accuracy: 0.6601 - val_loss: 0.6537 - val_accuracy: 0.6183\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6307 - accuracy: 0.6656 - val_loss: 0.6505 - val_accuracy: 0.6224\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.6263 - accuracy: 0.6703 - val_loss: 0.6494 - val_accuracy: 0.6228\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.6239 - accuracy: 0.6724 - val_loss: 0.6482 - val_accuracy: 0.6237\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6210 - accuracy: 0.6750 - val_loss: 0.6446 - val_accuracy: 0.6293\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.6177 - accuracy: 0.6808 - val_loss: 0.6402 - val_accuracy: 0.6322\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.6142 - accuracy: 0.6835 - val_loss: 0.6414 - val_accuracy: 0.6300\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6116 - accuracy: 0.6859 - val_loss: 0.6378 - val_accuracy: 0.6324\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.6089 - accuracy: 0.6874 - val_loss: 0.6406 - val_accuracy: 0.6278\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.6065 - accuracy: 0.6902 - val_loss: 0.6354 - val_accuracy: 0.6318\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.6042 - accuracy: 0.6909 - val_loss: 0.6322 - val_accuracy: 0.6331\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.6015 - accuracy: 0.6956 - val_loss: 0.6350 - val_accuracy: 0.6298\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.5988 - accuracy: 0.6958 - val_loss: 0.6253 - val_accuracy: 0.6391\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.5966 - accuracy: 0.6997 - val_loss: 0.6268 - val_accuracy: 0.6362\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 799us/step - loss: 0.5944 - accuracy: 0.7009 - val_loss: 0.6250 - val_accuracy: 0.6375\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.5923 - accuracy: 0.7018 - val_loss: 0.6249 - val_accuracy: 0.6378\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.5912 - accuracy: 0.7022 - val_loss: 0.6213 - val_accuracy: 0.6412\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.5883 - accuracy: 0.7073 - val_loss: 0.6243 - val_accuracy: 0.6362\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.5872 - accuracy: 0.7050 - val_loss: 0.6162 - val_accuracy: 0.6454\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.5846 - accuracy: 0.7076 - val_loss: 0.6196 - val_accuracy: 0.6402\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5826 - accuracy: 0.7076 - val_loss: 0.6185 - val_accuracy: 0.6406\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 988us/step - loss: 0.5806 - accuracy: 0.7099 - val_loss: 0.6184 - val_accuracy: 0.6393\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 865us/step - loss: 0.5787 - accuracy: 0.7119 - val_loss: 0.6149 - val_accuracy: 0.6429\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 847us/step - loss: 0.5773 - accuracy: 0.7137 - val_loss: 0.6160 - val_accuracy: 0.6409\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 851us/step - loss: 0.5760 - accuracy: 0.7137 - val_loss: 0.6075 - val_accuracy: 0.6495\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 848us/step - loss: 0.5735 - accuracy: 0.7177 - val_loss: 0.6139 - val_accuracy: 0.6434\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 827us/step - loss: 0.5727 - accuracy: 0.7162 - val_loss: 0.6078 - val_accuracy: 0.6481\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 848us/step - loss: 0.5717 - accuracy: 0.7160 - val_loss: 0.6140 - val_accuracy: 0.6430\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 862us/step - loss: 0.5688 - accuracy: 0.7202 - val_loss: 0.6028 - val_accuracy: 0.6531\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 856us/step - loss: 0.5672 - accuracy: 0.7210 - val_loss: 0.6004 - val_accuracy: 0.6550\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 850us/step - loss: 0.5661 - accuracy: 0.7210 - val_loss: 0.6064 - val_accuracy: 0.6500\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 834us/step - loss: 0.5651 - accuracy: 0.7230 - val_loss: 0.6047 - val_accuracy: 0.6508\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 863us/step - loss: 0.5638 - accuracy: 0.7230 - val_loss: 0.6058 - val_accuracy: 0.6500\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 859us/step - loss: 0.5614 - accuracy: 0.7226 - val_loss: 0.6041 - val_accuracy: 0.6514\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 866us/step - loss: 0.5606 - accuracy: 0.7258 - val_loss: 0.6051 - val_accuracy: 0.6500\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 844us/step - loss: 0.5590 - accuracy: 0.7232 - val_loss: 0.6019 - val_accuracy: 0.6535\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 959us/step - loss: 0.5585 - accuracy: 0.7269 - val_loss: 0.6060 - val_accuracy: 0.6485\n"
     ]
    }
   ],
   "source": [
    "# 3. Vary noise_multiplier\n",
    "results_noise_multiplier = {}\n",
    "eps_noise_multiplier = {}\n",
    "for noise in noise_multiplier_values:\n",
    "    print(f\"\\nTraining model with noise_multiplier={noise}...\")\n",
    "    n = len(X_train_filtered)\n",
    "    eps = compute_privacy_budget(n, default_batch_size, noise, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "        batch_size=default_batch_size, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=noise\n",
    "    )\n",
    "    results_noise_multiplier[noise] = compute_statistics(results)\n",
    "    eps_noise_multiplier[noise] = eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83a13266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to 'results/CDP_parameter_results.csv'\n",
      "\n",
      "Results (Averages):\n",
      "                No DP (mean)  batch_size=16 (=0.85) (mean)  \\\n",
      "ROC AUC              0.9015                         0.7549   \n",
      "Accuracy             0.8108                         0.5496   \n",
      "Precision            0.3676                         0.1817   \n",
      "Recall               0.8548                         0.8130   \n",
      "F1 Score             0.5140                         0.2970   \n",
      "Type I Error         0.1950                         0.4854   \n",
      "Type II Error        0.1452                         0.1870   \n",
      "\n",
      "               batch_size=32 (=1.06) (mean)  batch_size=64 (=1.42) (mean)  \\\n",
      "ROC AUC                               0.7301                         0.7045   \n",
      "Accuracy                              0.4770                         0.3699   \n",
      "Precision                             0.1647                         0.1469   \n",
      "Recall                                0.8495                         0.9110   \n",
      "F1 Score                              0.2757                         0.2530   \n",
      "Type I Error                          0.5723                         0.7018   \n",
      "Type II Error                         0.1505                         0.0890   \n",
      "\n",
      "               batch_size=128 (=2.01) (mean)  \\\n",
      "ROC AUC                                0.6926   \n",
      "Accuracy                               0.2742   \n",
      "Precision                              0.1347   \n",
      "Recall                                 0.9548   \n",
      "F1 Score                               0.2360   \n",
      "Type I Error                           0.8160   \n",
      "Type II Error                          0.0452   \n",
      "\n",
      "               sample_size_ratio=1 (=1.06) (mean)  \\\n",
      "ROC AUC                                     0.7389   \n",
      "Accuracy                                    0.4972   \n",
      "Precision                                   0.1688   \n",
      "Recall                                      0.8397   \n",
      "F1 Score                                    0.2811   \n",
      "Type I Error                                0.5481   \n",
      "Type II Error                               0.1603   \n",
      "\n",
      "               sample_size_ratio=0.5 (=1.42) (mean)  \\\n",
      "ROC AUC                                       0.7042   \n",
      "Accuracy                                      0.3269   \n",
      "Precision                                     0.1411   \n",
      "Recall                                        0.9217   \n",
      "F1 Score                                      0.2442   \n",
      "Type I Error                                  0.7519   \n",
      "Type II Error                                 0.0783   \n",
      "\n",
      "               sample_size_ratio=0.1 (=3.30) (mean)  \\\n",
      "ROC AUC                                       0.6348   \n",
      "Accuracy                                      0.1397   \n",
      "Precision                                     0.1194   \n",
      "Recall                                        0.9941   \n",
      "F1 Score                                      0.2131   \n",
      "Type I Error                                  0.9735   \n",
      "Type II Error                                 0.0059   \n",
      "\n",
      "               sample_size_ratio=0.05 (=4.84) (mean)  \\\n",
      "ROC AUC                                        0.6078   \n",
      "Accuracy                                       0.1380   \n",
      "Precision                                      0.1191   \n",
      "Recall                                         0.9934   \n",
      "F1 Score                                       0.2126   \n",
      "Type I Error                                   0.9753   \n",
      "Type II Error                                  0.0066   \n",
      "\n",
      "               noise_multiplier=1.1 (=1.06) (mean)  \\\n",
      "ROC AUC                                      0.7309   \n",
      "Accuracy                                     0.4990   \n",
      "Precision                                    0.1685   \n",
      "Recall                                       0.8336   \n",
      "F1 Score                                     0.2803   \n",
      "Type I Error                                 0.5454   \n",
      "Type II Error                                0.1664   \n",
      "\n",
      "               noise_multiplier=1.5 (=0.64) (mean)  \\\n",
      "ROC AUC                                      0.7245   \n",
      "Accuracy                                     0.4733   \n",
      "Precision                                    0.1638   \n",
      "Recall                                       0.8518   \n",
      "F1 Score                                     0.2747   \n",
      "Type I Error                                 0.5769   \n",
      "Type II Error                                0.1482   \n",
      "\n",
      "               noise_multiplier=2.0 (=0.45) (mean)  \\\n",
      "ROC AUC                                      0.7345   \n",
      "Accuracy                                     0.4946   \n",
      "Precision                                    0.1678   \n",
      "Recall                                       0.8374   \n",
      "F1 Score                                     0.2795   \n",
      "Type I Error                                 0.5508   \n",
      "Type II Error                                0.1626   \n",
      "\n",
      "               noise_multiplier=2.5 (=0.35) (mean)  \n",
      "ROC AUC                                      0.7369  \n",
      "Accuracy                                     0.5087  \n",
      "Precision                                    0.1712  \n",
      "Recall                                       0.8323  \n",
      "F1 Score                                     0.2839  \n",
      "Type I Error                                 0.5341  \n",
      "Type II Error                                0.1677  \n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "results_stats = {\n",
    "    'batch_size': results_batch_size,\n",
    "    'sample_size_ratio': results_sample_size,\n",
    "    'noise_multiplier': results_noise_multiplier\n",
    "}\n",
    "data = {}\n",
    "\n",
    "# Add results for non-DP model\n",
    "data['No DP (mean)'] = results_no_dp_stats['mean']\n",
    "data['No DP (min)'] = results_no_dp_stats['min']\n",
    "data['No DP (max)'] = results_no_dp_stats['max']\n",
    "\n",
    "# Add results for DP models\n",
    "for param, stats_dict in results_stats.items():\n",
    "    for value, stats in stats_dict.items():\n",
    "        # Get the corresponding epsilon value based on the parameter\n",
    "        if param == 'batch_size':\n",
    "            eps = eps_batch_size.get(value, float('inf'))\n",
    "        elif param == 'sample_size_ratio':\n",
    "            eps = eps_sample_size.get(value, float('inf'))\n",
    "        else:  # noise_multiplier\n",
    "            eps = eps_noise_multiplier.get(value, float('inf'))\n",
    "        \n",
    "        # Format the model name with epsilon (if finite)\n",
    "        model = f'{param}={value} (={eps:.2f})' if eps != float('inf') else f'{param}={value}'\n",
    "        data[f'{model} (mean)'] = stats['mean']\n",
    "        data[f'{model} (min)'] = stats['min']\n",
    "        data[f'{model} (max)'] = stats['max']\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(data).round(4)\n",
    "results_df.to_csv('results/CDP_parameter_results.csv')\n",
    "print(\"\\nResults saved to 'results/CDP_parameter_results.csv'\")\n",
    "print(\"\\nResults (Averages):\\n\", results_df[[col for col in results_df.columns if 'mean' in col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a322053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot results, including No DP model\n",
    "def plot_parameter_results(stats_dict, eps_dict, param_name, colors, no_dp_stats):\n",
    "    metrics = list(no_dp_stats['mean'].keys())\n",
    "    values = list(stats_dict.keys())\n",
    "    n_metrics = len(metrics)\n",
    "    n_values = len(values) + 1  # +1 for No DP\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x_positions = np.arange(n_metrics)\n",
    "    \n",
    "    # Plot No DP model\n",
    "    means = []\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    for metric in metrics:\n",
    "        means.append(no_dp_stats['mean'][metric])\n",
    "        mins.append(no_dp_stats['min'][metric])\n",
    "        maxs.append(no_dp_stats['max'][metric])\n",
    "    \n",
    "    plt.scatter(x_positions + (0 - (n_values-1)/2) * 0.15, means, \n",
    "                color=colors[0], label='No DP', s=100)\n",
    "    for metric_idx in range(n_metrics):\n",
    "        plt.vlines(x_positions[metric_idx] + (0 - (n_values-1)/2) * 0.15, \n",
    "                   mins[metric_idx], maxs[metric_idx], \n",
    "                   color=colors[0], linestyle='-', linewidth=1)\n",
    "    \n",
    "    # Plot results varying the parameter\n",
    "    for value_idx, value in enumerate(values, start=1):\n",
    "        means = []\n",
    "        mins = []\n",
    "        maxs = []\n",
    "        for metric in metrics:\n",
    "            means.append(stats_dict[value]['mean'][metric])\n",
    "            mins.append(stats_dict[value]['min'][metric])\n",
    "            maxs.append(stats_dict[value]['max'][metric])\n",
    "        \n",
    "        plt.scatter(x_positions + (value_idx - (n_values-1)/2) * 0.15, means, \n",
    "                    color=colors[value_idx], label=f'{param_name}={value} (={eps_dict[value]:.2f})', s=100)\n",
    "        for metric_idx in range(n_metrics):\n",
    "            plt.vlines(x_positions[metric_idx] + (value_idx - (n_values-1)/2) * 0.15, \n",
    "                       mins[metric_idx], maxs[metric_idx], \n",
    "                       color=colors[value_idx], linestyle='-', linewidth=1)\n",
    "    \n",
    "    plt.xticks(x_positions, metrics, rotation=45)\n",
    "    plt.title(f'Effect of Varying {param_name} on Model Performance')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(title=f'{param_name} Values', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/Effect_of_{param_name}_with_No_DP.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93697b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define colors\n",
    "colors = ['#0d4e9e', '#ffc520', '#7b9ca0', '#242624', '#cc7b4f']\n",
    "\n",
    "# Plot results\n",
    "plot_parameter_results(results_batch_size, eps_batch_size, 'batch_size', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_sample_size, eps_sample_size, 'sample_size_ratio', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_noise_multiplier, eps_noise_multiplier, 'noise_multiplier', colors, results_no_dp_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
