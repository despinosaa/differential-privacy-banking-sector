{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b36324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e24fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 33)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "data_path = 'C:/Users/danie/OneDrive/Documentos/1 UNIANDES/10 semestre/Tesis/differential-privacy-banking-sector/data/processed/bank-processed.csv'\n",
    "data = pd.read_csv(data_path, sep=',')\n",
    "print(data.shape)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y']\n",
    "\n",
    "# Define numeric columns\n",
    "numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Scale numeric columns\n",
    "scale = MinMaxScaler()\n",
    "X[numeric_cols] = scale.fit_transform(X[numeric_cols])\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752f6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply SMOTEENN for class balancing\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_resample, y_resample = smoteenn.fit_resample(X_train, y_train)\n",
    "X_resample = pd.DataFrame(X_resample, columns=X.columns)\n",
    "y_resample = pd.Series(y_resample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5300aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 26\n"
     ]
    }
   ],
   "source": [
    "# Feature selection with BorutaPy\n",
    "rf = xgb.XGBClassifier(eval_metric='logloss')\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
    "feat_selector.fit(X_resample.values, y_resample.values.ravel())\n",
    "X_filtered = X.columns[feat_selector.support_].tolist()\n",
    "print(f\"Selected features: {len(X_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacdacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data with selected features\n",
    "X_train_filtered = X_resample[X_filtered].values\n",
    "X_test_filtered = X_test[X_filtered].values\n",
    "y_train_filtered = y_resample.values\n",
    "y_test_filtered = y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e653b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neural network parameters\n",
    "input_size = len(X_filtered)\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n",
    "n_iterations = 10\n",
    "num_microbatches = 16\n",
    "l2_norm_clip = 1.0\n",
    "\n",
    "# Define parameter values to test\n",
    "batch_size_values = [16, 32, 64, 128]\n",
    "sample_size_ratio_values = [1, 0.5, 0.1, 0.05]\n",
    "noise_multiplier_values = [1.1, 1.5, 2.0, 2.5]\n",
    "\n",
    "# Fixed default values\n",
    "default_noise_multiplier = 1.1\n",
    "default_batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9916dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute privacy budget\n",
    "def compute_privacy_budget(n, batch_size, noise_multiplier, epochs, delta=1e-5):\n",
    "    try:\n",
    "        eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "            n=n, batch_size=batch_size, noise_multiplier=noise_multiplier,\n",
    "            epochs=epochs, delta=delta\n",
    "        )[0]\n",
    "        return eps\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing privacy budget: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Define neural network model\n",
    "def create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=False,\n",
    "                 num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                 noise_multiplier=1.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation='relu', input_shape=(input_size,)))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if use_dp:\n",
    "        optimizer = DPKerasSGDOptimizer(\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "            num_microbatches=num_microbatches,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to train model\n",
    "def train_model(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=False,\n",
    "                num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                noise_multiplier=1.1):\n",
    "    model = create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=use_dp,\n",
    "                         num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                         noise_multiplier=noise_multiplier)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    \n",
    "    y_pred_prob_test = model.predict(X_test, batch_size=batch_size).flatten()\n",
    "    y_pred_test = (y_pred_prob_test > 0.4).astype(int)\n",
    "    \n",
    "    return y_pred_prob_test, y_pred_test\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(y_true, y_pred, y_pred_prob):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    actual_negatives, actual_positives = conf_matrix[0].sum(), conf_matrix[1].sum()\n",
    "    false_positive_rate = conf_matrix[0][1] / actual_negatives if actual_negatives > 0 else 0\n",
    "    false_negative_rate = conf_matrix[1][0] / actual_positives if actual_positives > 0 else 0\n",
    "    return {\n",
    "        'ROC AUC': roc_auc_score(y_true, y_pred_prob),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Type I Error': false_positive_rate,\n",
    "        'Type II Error': false_negative_rate\n",
    "    }\n",
    "\n",
    "# Function to run multiple iterations\n",
    "def run_iterations(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp, n_iterations,\n",
    "                   num_microbatches, l2_norm_clip, noise_multiplier):\n",
    "    results = []\n",
    "    for _ in range(n_iterations):\n",
    "        y_pred_prob_test, y_pred_test = train_model(\n",
    "            X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=use_dp,\n",
    "            num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier\n",
    "        )\n",
    "        result = evaluate_model(y_test, y_pred_test, y_pred_prob_test)\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to compute statistics\n",
    "def compute_statistics(df):\n",
    "    stats = {\n",
    "        'mean': df.mean(),\n",
    "        'min': df.min(),\n",
    "        'max': df.max()\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "# Function to subsample training data\n",
    "def subsample_data(X, y, sample_size_ratio, random_state=42):\n",
    "    if sample_size_ratio >= 1.0:\n",
    "        return X, y\n",
    "    n_samples = int(len(X) * sample_size_ratio)\n",
    "    idx = np.random.choice(len(X), n_samples, replace=False)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1690fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model without DP...\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.5894 - accuracy: 0.6771 - val_loss: 0.5792 - val_accuracy: 0.6811\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.5435 - val_accuracy: 0.7193\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.3905 - accuracy: 0.8292 - val_loss: 0.4816 - val_accuracy: 0.7948\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.3282 - accuracy: 0.8710 - val_loss: 0.5284 - val_accuracy: 0.7833\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.2934 - accuracy: 0.8882 - val_loss: 0.4697 - val_accuracy: 0.8220\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2777 - accuracy: 0.8954 - val_loss: 0.5072 - val_accuracy: 0.8071\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.2677 - accuracy: 0.8989 - val_loss: 0.4677 - val_accuracy: 0.8251\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.2617 - accuracy: 0.9014 - val_loss: 0.4954 - val_accuracy: 0.8119\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.2576 - accuracy: 0.9027 - val_loss: 0.4750 - val_accuracy: 0.8175\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.2532 - accuracy: 0.9043 - val_loss: 0.4496 - val_accuracy: 0.8270\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.2501 - accuracy: 0.9055 - val_loss: 0.4485 - val_accuracy: 0.8276\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.2476 - accuracy: 0.9071 - val_loss: 0.4761 - val_accuracy: 0.8172\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.2452 - accuracy: 0.9076 - val_loss: 0.4756 - val_accuracy: 0.8142\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.2423 - accuracy: 0.9084 - val_loss: 0.4607 - val_accuracy: 0.8243\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.2402 - accuracy: 0.9089 - val_loss: 0.5197 - val_accuracy: 0.7995\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.2385 - accuracy: 0.9095 - val_loss: 0.4739 - val_accuracy: 0.8152\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.2370 - accuracy: 0.9096 - val_loss: 0.4216 - val_accuracy: 0.8318\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.2346 - accuracy: 0.9108 - val_loss: 0.4683 - val_accuracy: 0.8127\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.2329 - accuracy: 0.9114 - val_loss: 0.4613 - val_accuracy: 0.8155\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.2304 - accuracy: 0.9123 - val_loss: 0.4790 - val_accuracy: 0.8138\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.2293 - accuracy: 0.9131 - val_loss: 0.4461 - val_accuracy: 0.8245\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.2282 - accuracy: 0.9134 - val_loss: 0.4544 - val_accuracy: 0.8175\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2259 - accuracy: 0.9138 - val_loss: 0.5034 - val_accuracy: 0.8027\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.2246 - accuracy: 0.9147 - val_loss: 0.4311 - val_accuracy: 0.8309\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.2228 - accuracy: 0.9147 - val_loss: 0.4289 - val_accuracy: 0.8334\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2223 - accuracy: 0.9155 - val_loss: 0.4381 - val_accuracy: 0.8301\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.2204 - accuracy: 0.9160 - val_loss: 0.4309 - val_accuracy: 0.8325\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.2191 - accuracy: 0.9161 - val_loss: 0.4332 - val_accuracy: 0.8343\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.2181 - accuracy: 0.9164 - val_loss: 0.4447 - val_accuracy: 0.8253\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.2167 - accuracy: 0.9177 - val_loss: 0.4998 - val_accuracy: 0.8043\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.2156 - accuracy: 0.9183 - val_loss: 0.4855 - val_accuracy: 0.8081\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.2149 - accuracy: 0.9178 - val_loss: 0.4503 - val_accuracy: 0.8249\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.2131 - accuracy: 0.9188 - val_loss: 0.4985 - val_accuracy: 0.8076\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.2123 - accuracy: 0.9181 - val_loss: 0.4562 - val_accuracy: 0.8243\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.2114 - accuracy: 0.9197 - val_loss: 0.4608 - val_accuracy: 0.8213\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.2103 - accuracy: 0.9186 - val_loss: 0.4626 - val_accuracy: 0.8246\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.2089 - accuracy: 0.9201 - val_loss: 0.4512 - val_accuracy: 0.8244\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.2085 - accuracy: 0.9202 - val_loss: 0.4191 - val_accuracy: 0.8360\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.2079 - accuracy: 0.9202 - val_loss: 0.4336 - val_accuracy: 0.8327\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.2075 - accuracy: 0.9206 - val_loss: 0.4175 - val_accuracy: 0.8374\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.2059 - accuracy: 0.9209 - val_loss: 0.4629 - val_accuracy: 0.8192\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2048 - accuracy: 0.9220 - val_loss: 0.4346 - val_accuracy: 0.8319\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.2043 - accuracy: 0.9222 - val_loss: 0.5058 - val_accuracy: 0.8068\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.2034 - accuracy: 0.9222 - val_loss: 0.4853 - val_accuracy: 0.8147\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.2024 - accuracy: 0.9221 - val_loss: 0.4811 - val_accuracy: 0.8142\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.2023 - accuracy: 0.9230 - val_loss: 0.4501 - val_accuracy: 0.8223\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 803us/step - loss: 0.2015 - accuracy: 0.9237 - val_loss: 0.4557 - val_accuracy: 0.8276\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.2012 - accuracy: 0.9234 - val_loss: 0.4406 - val_accuracy: 0.8317\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.1993 - accuracy: 0.9242 - val_loss: 0.4962 - val_accuracy: 0.8098\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.1996 - accuracy: 0.9235 - val_loss: 0.4486 - val_accuracy: 0.8269\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.5888 - accuracy: 0.6818 - val_loss: 0.6001 - val_accuracy: 0.6596\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.4739 - accuracy: 0.7704 - val_loss: 0.5486 - val_accuracy: 0.7231\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.3967 - accuracy: 0.8250 - val_loss: 0.5044 - val_accuracy: 0.7845\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.3323 - accuracy: 0.8667 - val_loss: 0.4694 - val_accuracy: 0.8235\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.2987 - accuracy: 0.8858 - val_loss: 0.4637 - val_accuracy: 0.8299\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.2819 - accuracy: 0.8933 - val_loss: 0.5005 - val_accuracy: 0.8152\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.2736 - accuracy: 0.8973 - val_loss: 0.4890 - val_accuracy: 0.8215\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.2671 - accuracy: 0.9007 - val_loss: 0.4919 - val_accuracy: 0.8211\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.2619 - accuracy: 0.9023 - val_loss: 0.4820 - val_accuracy: 0.8251\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.2580 - accuracy: 0.9040 - val_loss: 0.5112 - val_accuracy: 0.8152\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.2543 - accuracy: 0.9053 - val_loss: 0.5108 - val_accuracy: 0.8128\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.2520 - accuracy: 0.9065 - val_loss: 0.4700 - val_accuracy: 0.8278\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.2495 - accuracy: 0.9065 - val_loss: 0.5073 - val_accuracy: 0.8136\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.2460 - accuracy: 0.9080 - val_loss: 0.4521 - val_accuracy: 0.8324\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.2436 - accuracy: 0.9093 - val_loss: 0.5089 - val_accuracy: 0.8122\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.2408 - accuracy: 0.9105 - val_loss: 0.4610 - val_accuracy: 0.8298\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.2379 - accuracy: 0.9104 - val_loss: 0.4716 - val_accuracy: 0.8244\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.2353 - accuracy: 0.9115 - val_loss: 0.4387 - val_accuracy: 0.8337\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.2336 - accuracy: 0.9121 - val_loss: 0.4562 - val_accuracy: 0.8305\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.2315 - accuracy: 0.9135 - val_loss: 0.5042 - val_accuracy: 0.8118\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2290 - accuracy: 0.9134 - val_loss: 0.4506 - val_accuracy: 0.8336\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.2275 - accuracy: 0.9139 - val_loss: 0.4756 - val_accuracy: 0.8206\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.2257 - accuracy: 0.9156 - val_loss: 0.4710 - val_accuracy: 0.8258\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.2240 - accuracy: 0.9157 - val_loss: 0.4696 - val_accuracy: 0.8227\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.2228 - accuracy: 0.9156 - val_loss: 0.4989 - val_accuracy: 0.8110\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.2207 - accuracy: 0.9167 - val_loss: 0.4378 - val_accuracy: 0.8331\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2190 - accuracy: 0.9170 - val_loss: 0.4519 - val_accuracy: 0.8318\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.2173 - accuracy: 0.9180 - val_loss: 0.4760 - val_accuracy: 0.8202\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.2166 - accuracy: 0.9176 - val_loss: 0.4878 - val_accuracy: 0.8169\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.2143 - accuracy: 0.9189 - val_loss: 0.4394 - val_accuracy: 0.8335\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.2137 - accuracy: 0.9185 - val_loss: 0.4520 - val_accuracy: 0.8343\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.2134 - accuracy: 0.9201 - val_loss: 0.5050 - val_accuracy: 0.8120\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.2117 - accuracy: 0.9195 - val_loss: 0.4672 - val_accuracy: 0.8235\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.2105 - accuracy: 0.9199 - val_loss: 0.4512 - val_accuracy: 0.8275\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2090 - accuracy: 0.9212 - val_loss: 0.4876 - val_accuracy: 0.8151\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2083 - accuracy: 0.9206 - val_loss: 0.4323 - val_accuracy: 0.8367\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2073 - accuracy: 0.9203 - val_loss: 0.4918 - val_accuracy: 0.8133\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.2067 - accuracy: 0.9217 - val_loss: 0.4595 - val_accuracy: 0.8252\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.2057 - accuracy: 0.9226 - val_loss: 0.4662 - val_accuracy: 0.8248\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.2051 - accuracy: 0.9217 - val_loss: 0.4616 - val_accuracy: 0.8277\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.2034 - accuracy: 0.9228 - val_loss: 0.4790 - val_accuracy: 0.8207\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.2024 - accuracy: 0.9229 - val_loss: 0.4792 - val_accuracy: 0.8204\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.2028 - accuracy: 0.9232 - val_loss: 0.4472 - val_accuracy: 0.8320\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2015 - accuracy: 0.9238 - val_loss: 0.4731 - val_accuracy: 0.8204\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.2011 - accuracy: 0.9233 - val_loss: 0.4627 - val_accuracy: 0.8266\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.2003 - accuracy: 0.9233 - val_loss: 0.5077 - val_accuracy: 0.8176\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.1994 - accuracy: 0.9245 - val_loss: 0.5031 - val_accuracy: 0.8140\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.1982 - accuracy: 0.9245 - val_loss: 0.4444 - val_accuracy: 0.8331\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.1985 - accuracy: 0.9250 - val_loss: 0.4694 - val_accuracy: 0.8233\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.1981 - accuracy: 0.9243 - val_loss: 0.4536 - val_accuracy: 0.8327\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5815 - accuracy: 0.6990 - val_loss: 0.5410 - val_accuracy: 0.7049\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.4526 - accuracy: 0.7901 - val_loss: 0.5032 - val_accuracy: 0.7558\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.3661 - accuracy: 0.8475 - val_loss: 0.4958 - val_accuracy: 0.7908\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.3094 - accuracy: 0.8787 - val_loss: 0.4806 - val_accuracy: 0.8102\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.2815 - accuracy: 0.8920 - val_loss: 0.4656 - val_accuracy: 0.8201\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.2700 - accuracy: 0.8963 - val_loss: 0.4365 - val_accuracy: 0.8328\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.2627 - accuracy: 0.8995 - val_loss: 0.4717 - val_accuracy: 0.8169\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.2581 - accuracy: 0.9016 - val_loss: 0.4829 - val_accuracy: 0.8104\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.2548 - accuracy: 0.9023 - val_loss: 0.5601 - val_accuracy: 0.7812\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.2518 - accuracy: 0.9033 - val_loss: 0.4433 - val_accuracy: 0.8268\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.2489 - accuracy: 0.9051 - val_loss: 0.4703 - val_accuracy: 0.8138\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.2464 - accuracy: 0.9048 - val_loss: 0.4655 - val_accuracy: 0.8127\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.2442 - accuracy: 0.9061 - val_loss: 0.4806 - val_accuracy: 0.8065\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.2416 - accuracy: 0.9082 - val_loss: 0.4413 - val_accuracy: 0.8261\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2404 - accuracy: 0.9083 - val_loss: 0.4677 - val_accuracy: 0.8134\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.2376 - accuracy: 0.9095 - val_loss: 0.5052 - val_accuracy: 0.7986\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.2351 - accuracy: 0.9105 - val_loss: 0.4608 - val_accuracy: 0.8164\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.2344 - accuracy: 0.9106 - val_loss: 0.4469 - val_accuracy: 0.8207\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.2329 - accuracy: 0.9101 - val_loss: 0.4679 - val_accuracy: 0.8126\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2310 - accuracy: 0.9122 - val_loss: 0.4479 - val_accuracy: 0.8185\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.2294 - accuracy: 0.9129 - val_loss: 0.4732 - val_accuracy: 0.8123\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.2276 - accuracy: 0.9130 - val_loss: 0.4613 - val_accuracy: 0.8152\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.2259 - accuracy: 0.9143 - val_loss: 0.4490 - val_accuracy: 0.8227\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.2244 - accuracy: 0.9149 - val_loss: 0.4716 - val_accuracy: 0.8119\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.2236 - accuracy: 0.9144 - val_loss: 0.4781 - val_accuracy: 0.8099\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.2224 - accuracy: 0.9152 - val_loss: 0.5029 - val_accuracy: 0.8031\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.2204 - accuracy: 0.9161 - val_loss: 0.4075 - val_accuracy: 0.8394\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.2201 - accuracy: 0.9166 - val_loss: 0.4444 - val_accuracy: 0.8253\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.2179 - accuracy: 0.9174 - val_loss: 0.4511 - val_accuracy: 0.8243\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.2165 - accuracy: 0.9176 - val_loss: 0.4487 - val_accuracy: 0.8244\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.2155 - accuracy: 0.9177 - val_loss: 0.4658 - val_accuracy: 0.8131\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.2148 - accuracy: 0.9180 - val_loss: 0.4411 - val_accuracy: 0.8275\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2135 - accuracy: 0.9188 - val_loss: 0.4708 - val_accuracy: 0.8150\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.2125 - accuracy: 0.9187 - val_loss: 0.4682 - val_accuracy: 0.8182\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2117 - accuracy: 0.9191 - val_loss: 0.4591 - val_accuracy: 0.8193\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.2100 - accuracy: 0.9200 - val_loss: 0.4490 - val_accuracy: 0.8272\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.2082 - accuracy: 0.9206 - val_loss: 0.4720 - val_accuracy: 0.8157\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.2080 - accuracy: 0.9204 - val_loss: 0.4618 - val_accuracy: 0.8233\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.2074 - accuracy: 0.9205 - val_loss: 0.4659 - val_accuracy: 0.8188\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.2064 - accuracy: 0.9217 - val_loss: 0.4720 - val_accuracy: 0.8141\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2051 - accuracy: 0.9218 - val_loss: 0.4679 - val_accuracy: 0.8190\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.2046 - accuracy: 0.9219 - val_loss: 0.4398 - val_accuracy: 0.8310\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.2037 - accuracy: 0.9224 - val_loss: 0.5091 - val_accuracy: 0.7994\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.2028 - accuracy: 0.9231 - val_loss: 0.4671 - val_accuracy: 0.8206\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.2015 - accuracy: 0.9237 - val_loss: 0.4832 - val_accuracy: 0.8158\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2012 - accuracy: 0.9237 - val_loss: 0.4682 - val_accuracy: 0.8176\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.2004 - accuracy: 0.9246 - val_loss: 0.4688 - val_accuracy: 0.8233\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.2003 - accuracy: 0.9240 - val_loss: 0.4941 - val_accuracy: 0.8115\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.1992 - accuracy: 0.9239 - val_loss: 0.4536 - val_accuracy: 0.8254\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.1987 - accuracy: 0.9248 - val_loss: 0.4615 - val_accuracy: 0.8277\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.5659 - accuracy: 0.7082 - val_loss: 0.5283 - val_accuracy: 0.7204\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.4405 - accuracy: 0.7966 - val_loss: 0.5100 - val_accuracy: 0.7598\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.3611 - accuracy: 0.8506 - val_loss: 0.5008 - val_accuracy: 0.7948\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.3088 - accuracy: 0.8817 - val_loss: 0.5155 - val_accuracy: 0.8031\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.2840 - accuracy: 0.8929 - val_loss: 0.4669 - val_accuracy: 0.8293\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2719 - accuracy: 0.8979 - val_loss: 0.4826 - val_accuracy: 0.8231\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2641 - accuracy: 0.8997 - val_loss: 0.4980 - val_accuracy: 0.8143\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.2592 - accuracy: 0.9021 - val_loss: 0.5140 - val_accuracy: 0.8108\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2560 - accuracy: 0.9033 - val_loss: 0.4699 - val_accuracy: 0.8245\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.2523 - accuracy: 0.9055 - val_loss: 0.4920 - val_accuracy: 0.8168\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.2493 - accuracy: 0.9065 - val_loss: 0.4825 - val_accuracy: 0.8173\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.2469 - accuracy: 0.9071 - val_loss: 0.4416 - val_accuracy: 0.8325\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.2449 - accuracy: 0.9076 - val_loss: 0.5169 - val_accuracy: 0.8076\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.2432 - accuracy: 0.9085 - val_loss: 0.4657 - val_accuracy: 0.8254\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.2412 - accuracy: 0.9093 - val_loss: 0.4811 - val_accuracy: 0.8201\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.2386 - accuracy: 0.9111 - val_loss: 0.4879 - val_accuracy: 0.8161\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.2369 - accuracy: 0.9109 - val_loss: 0.4870 - val_accuracy: 0.8154\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2358 - accuracy: 0.9109 - val_loss: 0.4390 - val_accuracy: 0.8336\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2338 - accuracy: 0.9128 - val_loss: 0.4647 - val_accuracy: 0.8251\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.2325 - accuracy: 0.9130 - val_loss: 0.4481 - val_accuracy: 0.8295\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2315 - accuracy: 0.9129 - val_loss: 0.4460 - val_accuracy: 0.8316\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.2290 - accuracy: 0.9136 - val_loss: 0.5186 - val_accuracy: 0.8031\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2279 - accuracy: 0.9145 - val_loss: 0.5368 - val_accuracy: 0.7998\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.2268 - accuracy: 0.9150 - val_loss: 0.4958 - val_accuracy: 0.8110\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.2246 - accuracy: 0.9154 - val_loss: 0.4612 - val_accuracy: 0.8254\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.2239 - accuracy: 0.9162 - val_loss: 0.4410 - val_accuracy: 0.8334\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.2231 - accuracy: 0.9153 - val_loss: 0.4736 - val_accuracy: 0.8180\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.2215 - accuracy: 0.9164 - val_loss: 0.4731 - val_accuracy: 0.8252\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.2205 - accuracy: 0.9169 - val_loss: 0.4624 - val_accuracy: 0.8247\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.2193 - accuracy: 0.9173 - val_loss: 0.4510 - val_accuracy: 0.8286\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.2188 - accuracy: 0.9177 - val_loss: 0.5126 - val_accuracy: 0.8035\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.2173 - accuracy: 0.9183 - val_loss: 0.4780 - val_accuracy: 0.8205\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2167 - accuracy: 0.9186 - val_loss: 0.4280 - val_accuracy: 0.8409\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.2159 - accuracy: 0.9186 - val_loss: 0.4444 - val_accuracy: 0.8309\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.2145 - accuracy: 0.9191 - val_loss: 0.4827 - val_accuracy: 0.8188\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.2135 - accuracy: 0.9192 - val_loss: 0.4875 - val_accuracy: 0.8165\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.2127 - accuracy: 0.9188 - val_loss: 0.4771 - val_accuracy: 0.8198\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.2123 - accuracy: 0.9195 - val_loss: 0.4350 - val_accuracy: 0.8372\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.2108 - accuracy: 0.9199 - val_loss: 0.4618 - val_accuracy: 0.8290\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.2108 - accuracy: 0.9198 - val_loss: 0.4495 - val_accuracy: 0.8253\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.2102 - accuracy: 0.9199 - val_loss: 0.5229 - val_accuracy: 0.8003\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2090 - accuracy: 0.9206 - val_loss: 0.4480 - val_accuracy: 0.8334\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.2092 - accuracy: 0.9202 - val_loss: 0.4468 - val_accuracy: 0.8294\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.2075 - accuracy: 0.9213 - val_loss: 0.4915 - val_accuracy: 0.8196\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.2066 - accuracy: 0.9216 - val_loss: 0.4041 - val_accuracy: 0.8471\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.2061 - accuracy: 0.9219 - val_loss: 0.4564 - val_accuracy: 0.8241\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.2063 - accuracy: 0.9218 - val_loss: 0.4549 - val_accuracy: 0.8291\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.2049 - accuracy: 0.9222 - val_loss: 0.4607 - val_accuracy: 0.8294\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.2043 - accuracy: 0.9229 - val_loss: 0.4627 - val_accuracy: 0.8256\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.2036 - accuracy: 0.9225 - val_loss: 0.4372 - val_accuracy: 0.8363\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5582 - accuracy: 0.7148 - val_loss: 0.5372 - val_accuracy: 0.7109\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.4368 - accuracy: 0.8021 - val_loss: 0.5498 - val_accuracy: 0.7294\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.3525 - accuracy: 0.8563 - val_loss: 0.4763 - val_accuracy: 0.8110\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.2992 - accuracy: 0.8856 - val_loss: 0.4865 - val_accuracy: 0.8155\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.2760 - accuracy: 0.8945 - val_loss: 0.4992 - val_accuracy: 0.8133\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.2659 - accuracy: 0.8995 - val_loss: 0.4586 - val_accuracy: 0.8298\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.2588 - accuracy: 0.9016 - val_loss: 0.4784 - val_accuracy: 0.8201\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.2549 - accuracy: 0.9025 - val_loss: 0.4727 - val_accuracy: 0.8222\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.2509 - accuracy: 0.9046 - val_loss: 0.4941 - val_accuracy: 0.8151\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.2468 - accuracy: 0.9065 - val_loss: 0.5661 - val_accuracy: 0.7844\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.2438 - accuracy: 0.9068 - val_loss: 0.4605 - val_accuracy: 0.8224\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.2421 - accuracy: 0.9081 - val_loss: 0.4716 - val_accuracy: 0.8217\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.2396 - accuracy: 0.9078 - val_loss: 0.4575 - val_accuracy: 0.8237\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.2372 - accuracy: 0.9091 - val_loss: 0.4566 - val_accuracy: 0.8257\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.2346 - accuracy: 0.9102 - val_loss: 0.4674 - val_accuracy: 0.8189\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.2330 - accuracy: 0.9106 - val_loss: 0.4375 - val_accuracy: 0.8295\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.2303 - accuracy: 0.9120 - val_loss: 0.4501 - val_accuracy: 0.8242\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.2294 - accuracy: 0.9124 - val_loss: 0.4688 - val_accuracy: 0.8190\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.2276 - accuracy: 0.9122 - val_loss: 0.4168 - val_accuracy: 0.8392\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.2254 - accuracy: 0.9133 - val_loss: 0.4740 - val_accuracy: 0.8168\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.2237 - accuracy: 0.9140 - val_loss: 0.4945 - val_accuracy: 0.8109\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.2224 - accuracy: 0.9144 - val_loss: 0.5029 - val_accuracy: 0.8081\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.2214 - accuracy: 0.9149 - val_loss: 0.4652 - val_accuracy: 0.8182\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.2193 - accuracy: 0.9158 - val_loss: 0.4334 - val_accuracy: 0.8306\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.2187 - accuracy: 0.9159 - val_loss: 0.4413 - val_accuracy: 0.8294\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.2169 - accuracy: 0.9168 - val_loss: 0.4489 - val_accuracy: 0.8264\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.2166 - accuracy: 0.9175 - val_loss: 0.4019 - val_accuracy: 0.8447\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.2152 - accuracy: 0.9175 - val_loss: 0.4530 - val_accuracy: 0.8255\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.2134 - accuracy: 0.9185 - val_loss: 0.4877 - val_accuracy: 0.8173\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.2121 - accuracy: 0.9182 - val_loss: 0.4597 - val_accuracy: 0.8222\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.2123 - accuracy: 0.9182 - val_loss: 0.4247 - val_accuracy: 0.8373\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.2105 - accuracy: 0.9188 - val_loss: 0.4359 - val_accuracy: 0.8322\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.2097 - accuracy: 0.9198 - val_loss: 0.4501 - val_accuracy: 0.8289\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.2081 - accuracy: 0.9200 - val_loss: 0.4783 - val_accuracy: 0.8198\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.2084 - accuracy: 0.9203 - val_loss: 0.4731 - val_accuracy: 0.8220\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.2073 - accuracy: 0.9205 - val_loss: 0.4748 - val_accuracy: 0.8216\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.2064 - accuracy: 0.9212 - val_loss: 0.4237 - val_accuracy: 0.8378\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.2050 - accuracy: 0.9214 - val_loss: 0.4530 - val_accuracy: 0.8303\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.2046 - accuracy: 0.9208 - val_loss: 0.4554 - val_accuracy: 0.8255\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.2038 - accuracy: 0.9222 - val_loss: 0.4962 - val_accuracy: 0.8148\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.2028 - accuracy: 0.9220 - val_loss: 0.4871 - val_accuracy: 0.8118\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.2023 - accuracy: 0.9225 - val_loss: 0.4589 - val_accuracy: 0.8288\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.2010 - accuracy: 0.9238 - val_loss: 0.4735 - val_accuracy: 0.8176\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.2014 - accuracy: 0.9229 - val_loss: 0.5056 - val_accuracy: 0.8113\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.2003 - accuracy: 0.9232 - val_loss: 0.4763 - val_accuracy: 0.8210\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.1996 - accuracy: 0.9237 - val_loss: 0.4418 - val_accuracy: 0.8339\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.1989 - accuracy: 0.9242 - val_loss: 0.4867 - val_accuracy: 0.8170\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.1984 - accuracy: 0.9243 - val_loss: 0.4591 - val_accuracy: 0.8266\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.1969 - accuracy: 0.9256 - val_loss: 0.4623 - val_accuracy: 0.8241\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.1974 - accuracy: 0.9254 - val_loss: 0.4804 - val_accuracy: 0.8195\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.5789 - accuracy: 0.6977 - val_loss: 0.6070 - val_accuracy: 0.6498\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.4683 - accuracy: 0.7747 - val_loss: 0.5235 - val_accuracy: 0.7323\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.3959 - accuracy: 0.8240 - val_loss: 0.5628 - val_accuracy: 0.7261\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.3335 - accuracy: 0.8671 - val_loss: 0.4834 - val_accuracy: 0.8057\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.2978 - accuracy: 0.8849 - val_loss: 0.4750 - val_accuracy: 0.8173\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.2803 - accuracy: 0.8917 - val_loss: 0.4376 - val_accuracy: 0.8346\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.2704 - accuracy: 0.8959 - val_loss: 0.4692 - val_accuracy: 0.8230\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.2654 - accuracy: 0.8990 - val_loss: 0.4495 - val_accuracy: 0.8293\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.2609 - accuracy: 0.9000 - val_loss: 0.4918 - val_accuracy: 0.8102\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.2569 - accuracy: 0.9017 - val_loss: 0.4827 - val_accuracy: 0.8131\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.2537 - accuracy: 0.9031 - val_loss: 0.4742 - val_accuracy: 0.8172\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.2501 - accuracy: 0.9044 - val_loss: 0.4563 - val_accuracy: 0.8241\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.2480 - accuracy: 0.9051 - val_loss: 0.4607 - val_accuracy: 0.8230\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.2447 - accuracy: 0.9069 - val_loss: 0.4834 - val_accuracy: 0.8152\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.2431 - accuracy: 0.9078 - val_loss: 0.4366 - val_accuracy: 0.8318\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.2410 - accuracy: 0.9073 - val_loss: 0.4955 - val_accuracy: 0.8094\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.2392 - accuracy: 0.9090 - val_loss: 0.4729 - val_accuracy: 0.8188\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.2365 - accuracy: 0.9093 - val_loss: 0.5206 - val_accuracy: 0.8011\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.2358 - accuracy: 0.9097 - val_loss: 0.4323 - val_accuracy: 0.8317\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2321 - accuracy: 0.9109 - val_loss: 0.4872 - val_accuracy: 0.8144\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.2327 - accuracy: 0.9104 - val_loss: 0.4474 - val_accuracy: 0.8256\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.2297 - accuracy: 0.9122 - val_loss: 0.4579 - val_accuracy: 0.8216\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.2287 - accuracy: 0.9124 - val_loss: 0.4804 - val_accuracy: 0.8168\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.2267 - accuracy: 0.9131 - val_loss: 0.4824 - val_accuracy: 0.8137\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.2248 - accuracy: 0.9138 - val_loss: 0.4597 - val_accuracy: 0.8221\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2235 - accuracy: 0.9142 - val_loss: 0.4564 - val_accuracy: 0.8233\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.2222 - accuracy: 0.9146 - val_loss: 0.4400 - val_accuracy: 0.8307\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.2198 - accuracy: 0.9162 - val_loss: 0.4766 - val_accuracy: 0.8198\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.2204 - accuracy: 0.9162 - val_loss: 0.4712 - val_accuracy: 0.8193\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.2179 - accuracy: 0.9169 - val_loss: 0.4459 - val_accuracy: 0.8279\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.2172 - accuracy: 0.9171 - val_loss: 0.4525 - val_accuracy: 0.8257\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.2158 - accuracy: 0.9175 - val_loss: 0.4368 - val_accuracy: 0.8328\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.2149 - accuracy: 0.9175 - val_loss: 0.4451 - val_accuracy: 0.8316\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.2133 - accuracy: 0.9178 - val_loss: 0.4376 - val_accuracy: 0.8316\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.2119 - accuracy: 0.9191 - val_loss: 0.4494 - val_accuracy: 0.8272\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.2120 - accuracy: 0.9182 - val_loss: 0.4501 - val_accuracy: 0.8300\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.2107 - accuracy: 0.9181 - val_loss: 0.4566 - val_accuracy: 0.8254\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.2096 - accuracy: 0.9200 - val_loss: 0.4802 - val_accuracy: 0.8176\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.2084 - accuracy: 0.9191 - val_loss: 0.4718 - val_accuracy: 0.8232\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.2077 - accuracy: 0.9208 - val_loss: 0.4567 - val_accuracy: 0.8262\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.2065 - accuracy: 0.9209 - val_loss: 0.4492 - val_accuracy: 0.8305\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.2050 - accuracy: 0.9211 - val_loss: 0.5085 - val_accuracy: 0.8075\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2042 - accuracy: 0.9219 - val_loss: 0.4483 - val_accuracy: 0.8345\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.2038 - accuracy: 0.9216 - val_loss: 0.4222 - val_accuracy: 0.8410\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.2021 - accuracy: 0.9221 - val_loss: 0.4819 - val_accuracy: 0.8144\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.2018 - accuracy: 0.9225 - val_loss: 0.4452 - val_accuracy: 0.8343\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.2013 - accuracy: 0.9223 - val_loss: 0.4837 - val_accuracy: 0.8200\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.2009 - accuracy: 0.9223 - val_loss: 0.5325 - val_accuracy: 0.7998\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.1995 - accuracy: 0.9234 - val_loss: 0.4668 - val_accuracy: 0.8298\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.1985 - accuracy: 0.9237 - val_loss: 0.4699 - val_accuracy: 0.8243\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5846 - accuracy: 0.6932 - val_loss: 0.5716 - val_accuracy: 0.6729\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.4762 - accuracy: 0.7694 - val_loss: 0.5750 - val_accuracy: 0.6979\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.3924 - accuracy: 0.8286 - val_loss: 0.5057 - val_accuracy: 0.7824\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.3313 - accuracy: 0.8674 - val_loss: 0.4794 - val_accuracy: 0.8148\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.2953 - accuracy: 0.8873 - val_loss: 0.5082 - val_accuracy: 0.8056\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.2773 - accuracy: 0.8939 - val_loss: 0.4814 - val_accuracy: 0.8192\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2668 - accuracy: 0.8976 - val_loss: 0.4764 - val_accuracy: 0.8203\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.2610 - accuracy: 0.8998 - val_loss: 0.4634 - val_accuracy: 0.8240\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.2569 - accuracy: 0.9020 - val_loss: 0.4488 - val_accuracy: 0.8273\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.2524 - accuracy: 0.9028 - val_loss: 0.4825 - val_accuracy: 0.8154\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.2490 - accuracy: 0.9043 - val_loss: 0.4864 - val_accuracy: 0.8126\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.2462 - accuracy: 0.9053 - val_loss: 0.5174 - val_accuracy: 0.8029\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.2444 - accuracy: 0.9060 - val_loss: 0.4553 - val_accuracy: 0.8233\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.2423 - accuracy: 0.9075 - val_loss: 0.4727 - val_accuracy: 0.8160\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.2396 - accuracy: 0.9078 - val_loss: 0.4575 - val_accuracy: 0.8223\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.2375 - accuracy: 0.9090 - val_loss: 0.4870 - val_accuracy: 0.8121\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2350 - accuracy: 0.9096 - val_loss: 0.4706 - val_accuracy: 0.8169\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2336 - accuracy: 0.9103 - val_loss: 0.4574 - val_accuracy: 0.8215\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.2321 - accuracy: 0.9112 - val_loss: 0.4509 - val_accuracy: 0.8238\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2300 - accuracy: 0.9122 - val_loss: 0.4453 - val_accuracy: 0.8262\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2282 - accuracy: 0.9122 - val_loss: 0.4962 - val_accuracy: 0.8040\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.2269 - accuracy: 0.9130 - val_loss: 0.4684 - val_accuracy: 0.8138\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.2265 - accuracy: 0.9125 - val_loss: 0.4681 - val_accuracy: 0.8170\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.2238 - accuracy: 0.9141 - val_loss: 0.4596 - val_accuracy: 0.8223\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.2232 - accuracy: 0.9145 - val_loss: 0.4717 - val_accuracy: 0.8180\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.2209 - accuracy: 0.9155 - val_loss: 0.5262 - val_accuracy: 0.7937\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.2205 - accuracy: 0.9154 - val_loss: 0.4257 - val_accuracy: 0.8329\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.2188 - accuracy: 0.9153 - val_loss: 0.4189 - val_accuracy: 0.8357\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.2184 - accuracy: 0.9162 - val_loss: 0.4918 - val_accuracy: 0.8105\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.2166 - accuracy: 0.9160 - val_loss: 0.4683 - val_accuracy: 0.8134\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.2161 - accuracy: 0.9174 - val_loss: 0.4493 - val_accuracy: 0.8278\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.2153 - accuracy: 0.9180 - val_loss: 0.4664 - val_accuracy: 0.8174\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2136 - accuracy: 0.9188 - val_loss: 0.5058 - val_accuracy: 0.8035\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2132 - accuracy: 0.9191 - val_loss: 0.4392 - val_accuracy: 0.8295\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.2119 - accuracy: 0.9190 - val_loss: 0.4022 - val_accuracy: 0.8434\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2104 - accuracy: 0.9192 - val_loss: 0.5023 - val_accuracy: 0.8038\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2108 - accuracy: 0.9187 - val_loss: 0.4591 - val_accuracy: 0.8227\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.2094 - accuracy: 0.9195 - val_loss: 0.4706 - val_accuracy: 0.8209\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.2080 - accuracy: 0.9194 - val_loss: 0.4208 - val_accuracy: 0.8367\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.2071 - accuracy: 0.9208 - val_loss: 0.4758 - val_accuracy: 0.8180\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.2065 - accuracy: 0.9208 - val_loss: 0.4401 - val_accuracy: 0.8325\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.2054 - accuracy: 0.9216 - val_loss: 0.4106 - val_accuracy: 0.8407\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.2061 - accuracy: 0.9209 - val_loss: 0.4654 - val_accuracy: 0.8211\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.2045 - accuracy: 0.9218 - val_loss: 0.4385 - val_accuracy: 0.8315\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.2036 - accuracy: 0.9226 - val_loss: 0.4659 - val_accuracy: 0.8193\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.2035 - accuracy: 0.9220 - val_loss: 0.4736 - val_accuracy: 0.8182\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.2036 - accuracy: 0.9224 - val_loss: 0.4659 - val_accuracy: 0.8244\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.2009 - accuracy: 0.9233 - val_loss: 0.4728 - val_accuracy: 0.8211\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.2013 - accuracy: 0.9227 - val_loss: 0.4875 - val_accuracy: 0.8123\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.2000 - accuracy: 0.9239 - val_loss: 0.4652 - val_accuracy: 0.8241\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5911 - accuracy: 0.6776 - val_loss: 0.5831 - val_accuracy: 0.6698\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.4600 - accuracy: 0.7832 - val_loss: 0.5414 - val_accuracy: 0.7152\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.3782 - accuracy: 0.8378 - val_loss: 0.5053 - val_accuracy: 0.7778\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.3214 - accuracy: 0.8731 - val_loss: 0.4516 - val_accuracy: 0.8249\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.2919 - accuracy: 0.8875 - val_loss: 0.5045 - val_accuracy: 0.8038\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.2763 - accuracy: 0.8943 - val_loss: 0.4620 - val_accuracy: 0.8231\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.2676 - accuracy: 0.8965 - val_loss: 0.4413 - val_accuracy: 0.8275\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.2619 - accuracy: 0.8991 - val_loss: 0.4624 - val_accuracy: 0.8203\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.2573 - accuracy: 0.9017 - val_loss: 0.4740 - val_accuracy: 0.8141\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.2542 - accuracy: 0.9031 - val_loss: 0.4696 - val_accuracy: 0.8139\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.2504 - accuracy: 0.9044 - val_loss: 0.4615 - val_accuracy: 0.8174\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.2479 - accuracy: 0.9051 - val_loss: 0.4368 - val_accuracy: 0.8267\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.2459 - accuracy: 0.9066 - val_loss: 0.4809 - val_accuracy: 0.8131\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.2430 - accuracy: 0.9078 - val_loss: 0.4383 - val_accuracy: 0.8258\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.2412 - accuracy: 0.9085 - val_loss: 0.5336 - val_accuracy: 0.7908\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.2382 - accuracy: 0.9097 - val_loss: 0.4484 - val_accuracy: 0.8230\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.2360 - accuracy: 0.9100 - val_loss: 0.4889 - val_accuracy: 0.8105\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.2337 - accuracy: 0.9109 - val_loss: 0.4281 - val_accuracy: 0.8320\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.2324 - accuracy: 0.9114 - val_loss: 0.4687 - val_accuracy: 0.8161\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.2298 - accuracy: 0.9120 - val_loss: 0.4744 - val_accuracy: 0.8183\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.2285 - accuracy: 0.9128 - val_loss: 0.4248 - val_accuracy: 0.8338\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2265 - accuracy: 0.9145 - val_loss: 0.4674 - val_accuracy: 0.8178\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.2260 - accuracy: 0.9138 - val_loss: 0.4681 - val_accuracy: 0.8160\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.2241 - accuracy: 0.9143 - val_loss: 0.4512 - val_accuracy: 0.8254\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.2224 - accuracy: 0.9152 - val_loss: 0.5015 - val_accuracy: 0.8074\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.2210 - accuracy: 0.9158 - val_loss: 0.4638 - val_accuracy: 0.8200\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.2199 - accuracy: 0.9157 - val_loss: 0.4592 - val_accuracy: 0.8209\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.2181 - accuracy: 0.9165 - val_loss: 0.4516 - val_accuracy: 0.8226\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2172 - accuracy: 0.9169 - val_loss: 0.4484 - val_accuracy: 0.8245\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.2152 - accuracy: 0.9178 - val_loss: 0.4668 - val_accuracy: 0.8241\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.2140 - accuracy: 0.9180 - val_loss: 0.4506 - val_accuracy: 0.8273\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.2135 - accuracy: 0.9184 - val_loss: 0.4772 - val_accuracy: 0.8165\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.2127 - accuracy: 0.9188 - val_loss: 0.4556 - val_accuracy: 0.8233\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.2108 - accuracy: 0.9189 - val_loss: 0.4782 - val_accuracy: 0.8179\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.2099 - accuracy: 0.9205 - val_loss: 0.4570 - val_accuracy: 0.8235\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.2097 - accuracy: 0.9196 - val_loss: 0.4801 - val_accuracy: 0.8158\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.2082 - accuracy: 0.9207 - val_loss: 0.4657 - val_accuracy: 0.8232\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.2076 - accuracy: 0.9210 - val_loss: 0.5188 - val_accuracy: 0.8002\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.2071 - accuracy: 0.9206 - val_loss: 0.4332 - val_accuracy: 0.8356\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2056 - accuracy: 0.9214 - val_loss: 0.5015 - val_accuracy: 0.8112\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.2049 - accuracy: 0.9221 - val_loss: 0.4517 - val_accuracy: 0.8261\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.2046 - accuracy: 0.9211 - val_loss: 0.4454 - val_accuracy: 0.8308\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.2029 - accuracy: 0.9227 - val_loss: 0.4696 - val_accuracy: 0.8207\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.2023 - accuracy: 0.9222 - val_loss: 0.4485 - val_accuracy: 0.8296\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2022 - accuracy: 0.9227 - val_loss: 0.4720 - val_accuracy: 0.8223\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.2012 - accuracy: 0.9227 - val_loss: 0.4584 - val_accuracy: 0.8251\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2006 - accuracy: 0.9231 - val_loss: 0.4400 - val_accuracy: 0.8299\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.2010 - accuracy: 0.9229 - val_loss: 0.4861 - val_accuracy: 0.8206\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.1995 - accuracy: 0.9239 - val_loss: 0.4662 - val_accuracy: 0.8251\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.1988 - accuracy: 0.9241 - val_loss: 0.4784 - val_accuracy: 0.8193\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5737 - accuracy: 0.6958 - val_loss: 0.5312 - val_accuracy: 0.7281\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.4559 - accuracy: 0.7855 - val_loss: 0.5527 - val_accuracy: 0.7263\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.3780 - accuracy: 0.8386 - val_loss: 0.4817 - val_accuracy: 0.8092\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.3230 - accuracy: 0.8731 - val_loss: 0.5001 - val_accuracy: 0.8123\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2928 - accuracy: 0.8877 - val_loss: 0.4716 - val_accuracy: 0.8259\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.2791 - accuracy: 0.8935 - val_loss: 0.4620 - val_accuracy: 0.8306\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.2710 - accuracy: 0.8968 - val_loss: 0.4909 - val_accuracy: 0.8201\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.2655 - accuracy: 0.9000 - val_loss: 0.4617 - val_accuracy: 0.8306\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.2605 - accuracy: 0.9020 - val_loss: 0.5144 - val_accuracy: 0.8095\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.2568 - accuracy: 0.9031 - val_loss: 0.4718 - val_accuracy: 0.8241\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.2534 - accuracy: 0.9048 - val_loss: 0.4670 - val_accuracy: 0.8273\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.2507 - accuracy: 0.9061 - val_loss: 0.4574 - val_accuracy: 0.8259\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.2477 - accuracy: 0.9060 - val_loss: 0.4889 - val_accuracy: 0.8170\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.2449 - accuracy: 0.9076 - val_loss: 0.4907 - val_accuracy: 0.8172\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.2423 - accuracy: 0.9083 - val_loss: 0.4303 - val_accuracy: 0.8346\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.2397 - accuracy: 0.9093 - val_loss: 0.4496 - val_accuracy: 0.8310\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.2373 - accuracy: 0.9100 - val_loss: 0.4695 - val_accuracy: 0.8211\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.2350 - accuracy: 0.9114 - val_loss: 0.4795 - val_accuracy: 0.8180\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.2327 - accuracy: 0.9113 - val_loss: 0.4630 - val_accuracy: 0.8228\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.2302 - accuracy: 0.9124 - val_loss: 0.4832 - val_accuracy: 0.8155\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.2285 - accuracy: 0.9132 - val_loss: 0.4791 - val_accuracy: 0.8128\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.2271 - accuracy: 0.9134 - val_loss: 0.4697 - val_accuracy: 0.8167\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.2252 - accuracy: 0.9145 - val_loss: 0.4685 - val_accuracy: 0.8224\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.2227 - accuracy: 0.9152 - val_loss: 0.4784 - val_accuracy: 0.8149\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.2205 - accuracy: 0.9164 - val_loss: 0.4471 - val_accuracy: 0.8247\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.2190 - accuracy: 0.9165 - val_loss: 0.4887 - val_accuracy: 0.8176\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.2177 - accuracy: 0.9180 - val_loss: 0.4931 - val_accuracy: 0.8131\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.2163 - accuracy: 0.9180 - val_loss: 0.4364 - val_accuracy: 0.8338\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.2146 - accuracy: 0.9183 - val_loss: 0.4564 - val_accuracy: 0.8243\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.2136 - accuracy: 0.9200 - val_loss: 0.4563 - val_accuracy: 0.8268\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.2123 - accuracy: 0.9190 - val_loss: 0.4363 - val_accuracy: 0.8337\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.2109 - accuracy: 0.9194 - val_loss: 0.4396 - val_accuracy: 0.8320\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.2093 - accuracy: 0.9195 - val_loss: 0.4475 - val_accuracy: 0.8268\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.2085 - accuracy: 0.9208 - val_loss: 0.4414 - val_accuracy: 0.8301\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.2069 - accuracy: 0.9219 - val_loss: 0.4398 - val_accuracy: 0.8322\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.2057 - accuracy: 0.9217 - val_loss: 0.4638 - val_accuracy: 0.8226\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.2053 - accuracy: 0.9222 - val_loss: 0.4491 - val_accuracy: 0.8311\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.2035 - accuracy: 0.9236 - val_loss: 0.4394 - val_accuracy: 0.8373\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.2030 - accuracy: 0.9231 - val_loss: 0.4663 - val_accuracy: 0.8266\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.2022 - accuracy: 0.9238 - val_loss: 0.4724 - val_accuracy: 0.8236\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.2021 - accuracy: 0.9234 - val_loss: 0.4361 - val_accuracy: 0.8368\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.2003 - accuracy: 0.9242 - val_loss: 0.4864 - val_accuracy: 0.8170\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.1995 - accuracy: 0.9242 - val_loss: 0.4637 - val_accuracy: 0.8254\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.1991 - accuracy: 0.9248 - val_loss: 0.4420 - val_accuracy: 0.8316\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.1994 - accuracy: 0.9255 - val_loss: 0.4567 - val_accuracy: 0.8313\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.1981 - accuracy: 0.9259 - val_loss: 0.5008 - val_accuracy: 0.8116\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.1976 - accuracy: 0.9247 - val_loss: 0.4528 - val_accuracy: 0.8293\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.1965 - accuracy: 0.9253 - val_loss: 0.4792 - val_accuracy: 0.8203\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.1951 - accuracy: 0.9261 - val_loss: 0.4544 - val_accuracy: 0.8253\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.1949 - accuracy: 0.9263 - val_loss: 0.4359 - val_accuracy: 0.8351\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.5895 - accuracy: 0.6884 - val_loss: 0.5865 - val_accuracy: 0.6708\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.4660 - accuracy: 0.7825 - val_loss: 0.5282 - val_accuracy: 0.7394\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.3843 - accuracy: 0.8337 - val_loss: 0.5401 - val_accuracy: 0.7600\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.3236 - accuracy: 0.8731 - val_loss: 0.4992 - val_accuracy: 0.8067\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.2914 - accuracy: 0.8895 - val_loss: 0.4987 - val_accuracy: 0.8087\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.2758 - accuracy: 0.8948 - val_loss: 0.4679 - val_accuracy: 0.8222\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2677 - accuracy: 0.8980 - val_loss: 0.5161 - val_accuracy: 0.8028\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.2625 - accuracy: 0.9003 - val_loss: 0.5071 - val_accuracy: 0.8064\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.2584 - accuracy: 0.9009 - val_loss: 0.4961 - val_accuracy: 0.8098\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.2544 - accuracy: 0.9031 - val_loss: 0.5280 - val_accuracy: 0.7948\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.2514 - accuracy: 0.9043 - val_loss: 0.5142 - val_accuracy: 0.8016\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.2486 - accuracy: 0.9051 - val_loss: 0.4953 - val_accuracy: 0.8065\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.2470 - accuracy: 0.9055 - val_loss: 0.4290 - val_accuracy: 0.8319\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.2446 - accuracy: 0.9071 - val_loss: 0.4673 - val_accuracy: 0.8185\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.2420 - accuracy: 0.9071 - val_loss: 0.4499 - val_accuracy: 0.8251\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.2398 - accuracy: 0.9085 - val_loss: 0.4805 - val_accuracy: 0.8099\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.2383 - accuracy: 0.9085 - val_loss: 0.4756 - val_accuracy: 0.8167\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.2370 - accuracy: 0.9097 - val_loss: 0.4997 - val_accuracy: 0.8065\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.2344 - accuracy: 0.9107 - val_loss: 0.4893 - val_accuracy: 0.8097\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.2323 - accuracy: 0.9112 - val_loss: 0.4433 - val_accuracy: 0.8279\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.2311 - accuracy: 0.9120 - val_loss: 0.4533 - val_accuracy: 0.8247\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.2286 - accuracy: 0.9131 - val_loss: 0.4811 - val_accuracy: 0.8185\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.2278 - accuracy: 0.9126 - val_loss: 0.5032 - val_accuracy: 0.8032\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.2267 - accuracy: 0.9136 - val_loss: 0.4488 - val_accuracy: 0.8269\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.2251 - accuracy: 0.9141 - val_loss: 0.4907 - val_accuracy: 0.8141\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.2239 - accuracy: 0.9147 - val_loss: 0.4808 - val_accuracy: 0.8148\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.2223 - accuracy: 0.9161 - val_loss: 0.4760 - val_accuracy: 0.8196\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.2210 - accuracy: 0.9151 - val_loss: 0.4526 - val_accuracy: 0.8263\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.2196 - accuracy: 0.9164 - val_loss: 0.4809 - val_accuracy: 0.8170\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.2185 - accuracy: 0.9168 - val_loss: 0.4461 - val_accuracy: 0.8265\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.2179 - accuracy: 0.9164 - val_loss: 0.4477 - val_accuracy: 0.8276\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.2162 - accuracy: 0.9169 - val_loss: 0.4880 - val_accuracy: 0.8143\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.2158 - accuracy: 0.9175 - val_loss: 0.4894 - val_accuracy: 0.8168\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.2142 - accuracy: 0.9183 - val_loss: 0.4749 - val_accuracy: 0.8190\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.2136 - accuracy: 0.9190 - val_loss: 0.4641 - val_accuracy: 0.8240\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.2127 - accuracy: 0.9191 - val_loss: 0.4562 - val_accuracy: 0.8262\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.2112 - accuracy: 0.9193 - val_loss: 0.4915 - val_accuracy: 0.8140\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2116 - accuracy: 0.9190 - val_loss: 0.4597 - val_accuracy: 0.8288\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.2094 - accuracy: 0.9194 - val_loss: 0.4792 - val_accuracy: 0.8204\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.2088 - accuracy: 0.9198 - val_loss: 0.4215 - val_accuracy: 0.8402\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.2081 - accuracy: 0.9203 - val_loss: 0.4736 - val_accuracy: 0.8189\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.2075 - accuracy: 0.9206 - val_loss: 0.4446 - val_accuracy: 0.8343\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.2069 - accuracy: 0.9206 - val_loss: 0.4966 - val_accuracy: 0.8165\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.2061 - accuracy: 0.9211 - val_loss: 0.4650 - val_accuracy: 0.8288\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.2049 - accuracy: 0.9219 - val_loss: 0.4915 - val_accuracy: 0.8179\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.2045 - accuracy: 0.9211 - val_loss: 0.4524 - val_accuracy: 0.8305\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.2038 - accuracy: 0.9225 - val_loss: 0.4654 - val_accuracy: 0.8258\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.2031 - accuracy: 0.9219 - val_loss: 0.4663 - val_accuracy: 0.8252\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.2023 - accuracy: 0.9233 - val_loss: 0.4645 - val_accuracy: 0.8284\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.2019 - accuracy: 0.9237 - val_loss: 0.4619 - val_accuracy: 0.8303\n"
     ]
    }
   ],
   "source": [
    "# Train model without DP\n",
    "print(\"Training model without DP...\")\n",
    "results_no_dp = run_iterations(\n",
    "    X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "    batch_size=default_batch_size, epochs=epochs, use_dp=False, n_iterations=n_iterations,\n",
    "    num_microbatches=None, l2_norm_clip=None, noise_multiplier=None\n",
    ")\n",
    "results_no_dp_stats = compute_statistics(results_no_dp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec3c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with batch_size=16...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.1 iterated over 167200 steps satisfies differential privacy with eps = 0.849 and delta = 1e-05.\n",
      "The optimal RDP order is 19.0.\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.7064 - accuracy: 0.5015 - val_loss: 0.6933 - val_accuracy: 0.4939\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 407us/step - loss: 0.6841 - accuracy: 0.5496 - val_loss: 0.6955 - val_accuracy: 0.5208\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 407us/step - loss: 0.6745 - accuracy: 0.5763 - val_loss: 0.6865 - val_accuracy: 0.5643\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.6661 - accuracy: 0.6014 - val_loss: 0.6826 - val_accuracy: 0.5808\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.6599 - accuracy: 0.6149 - val_loss: 0.6675 - val_accuracy: 0.6182\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 411us/step - loss: 0.6503 - accuracy: 0.6360 - val_loss: 0.6626 - val_accuracy: 0.6291\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.6437 - accuracy: 0.6454 - val_loss: 0.6522 - val_accuracy: 0.6475\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.6377 - accuracy: 0.6522 - val_loss: 0.6532 - val_accuracy: 0.6410\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 396us/step - loss: 0.6327 - accuracy: 0.6614 - val_loss: 0.6500 - val_accuracy: 0.6433\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 401us/step - loss: 0.6277 - accuracy: 0.6678 - val_loss: 0.6438 - val_accuracy: 0.6487\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.6229 - accuracy: 0.6704 - val_loss: 0.6434 - val_accuracy: 0.6467\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 397us/step - loss: 0.6182 - accuracy: 0.6762 - val_loss: 0.6393 - val_accuracy: 0.6481\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 400us/step - loss: 0.6141 - accuracy: 0.6814 - val_loss: 0.6349 - val_accuracy: 0.6507\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.6093 - accuracy: 0.6838 - val_loss: 0.6315 - val_accuracy: 0.6535\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 439us/step - loss: 0.6050 - accuracy: 0.6872 - val_loss: 0.6194 - val_accuracy: 0.6674\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 405us/step - loss: 0.5997 - accuracy: 0.6904 - val_loss: 0.6160 - val_accuracy: 0.6680\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 398us/step - loss: 0.5973 - accuracy: 0.6921 - val_loss: 0.6198 - val_accuracy: 0.6593\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 395us/step - loss: 0.5925 - accuracy: 0.6987 - val_loss: 0.6167 - val_accuracy: 0.6607\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 384us/step - loss: 0.5901 - accuracy: 0.6994 - val_loss: 0.6130 - val_accuracy: 0.6655\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 385us/step - loss: 0.5867 - accuracy: 0.7024 - val_loss: 0.6151 - val_accuracy: 0.6606\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.5838 - accuracy: 0.7067 - val_loss: 0.6163 - val_accuracy: 0.6564\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 4s 1ms/step - loss: 0.5785 - accuracy: 0.7104 - val_loss: 0.6053 - val_accuracy: 0.6670\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.5767 - accuracy: 0.7128 - val_loss: 0.6154 - val_accuracy: 0.6582\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.5752 - accuracy: 0.7130 - val_loss: 0.6022 - val_accuracy: 0.6674\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5713 - accuracy: 0.7174 - val_loss: 0.6051 - val_accuracy: 0.6652\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.5681 - accuracy: 0.7199 - val_loss: 0.6070 - val_accuracy: 0.6631\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.5662 - accuracy: 0.7205 - val_loss: 0.6065 - val_accuracy: 0.6636\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.5630 - accuracy: 0.7222 - val_loss: 0.6003 - val_accuracy: 0.6692\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.5615 - accuracy: 0.7246 - val_loss: 0.6070 - val_accuracy: 0.6607\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.5593 - accuracy: 0.7242 - val_loss: 0.5883 - val_accuracy: 0.6775\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5572 - accuracy: 0.7278 - val_loss: 0.5874 - val_accuracy: 0.6772\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.5540 - accuracy: 0.7293 - val_loss: 0.6003 - val_accuracy: 0.6671\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.5529 - accuracy: 0.7284 - val_loss: 0.5898 - val_accuracy: 0.6741\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.5501 - accuracy: 0.7304 - val_loss: 0.5901 - val_accuracy: 0.6729\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.5474 - accuracy: 0.7314 - val_loss: 0.6042 - val_accuracy: 0.6610\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.5462 - accuracy: 0.7332 - val_loss: 0.5929 - val_accuracy: 0.6690\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.5435 - accuracy: 0.7344 - val_loss: 0.5857 - val_accuracy: 0.6752\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.5416 - accuracy: 0.7348 - val_loss: 0.5939 - val_accuracy: 0.6660\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.5400 - accuracy: 0.7358 - val_loss: 0.5872 - val_accuracy: 0.6715\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5387 - accuracy: 0.7364 - val_loss: 0.5924 - val_accuracy: 0.6668\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.5377 - accuracy: 0.7366 - val_loss: 0.5856 - val_accuracy: 0.6734\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.5348 - accuracy: 0.7388 - val_loss: 0.5927 - val_accuracy: 0.6660\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5330 - accuracy: 0.7394 - val_loss: 0.5803 - val_accuracy: 0.6774\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.5330 - accuracy: 0.7381 - val_loss: 0.5920 - val_accuracy: 0.6658\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.5302 - accuracy: 0.7397 - val_loss: 0.5961 - val_accuracy: 0.6619\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5288 - accuracy: 0.7397 - val_loss: 0.6013 - val_accuracy: 0.6552\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5289 - accuracy: 0.7396 - val_loss: 0.5894 - val_accuracy: 0.6673\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.5260 - accuracy: 0.7410 - val_loss: 0.5938 - val_accuracy: 0.6615\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5251 - accuracy: 0.7422 - val_loss: 0.5991 - val_accuracy: 0.6568\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.5236 - accuracy: 0.7426 - val_loss: 0.5939 - val_accuracy: 0.6605\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.6763 - accuracy: 0.5774 - val_loss: 0.7035 - val_accuracy: 0.4946\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.6622 - accuracy: 0.6127 - val_loss: 0.6879 - val_accuracy: 0.5587\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.6497 - accuracy: 0.6407 - val_loss: 0.6750 - val_accuracy: 0.5957\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.6368 - accuracy: 0.6590 - val_loss: 0.6590 - val_accuracy: 0.6239\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.6294 - accuracy: 0.6655 - val_loss: 0.6624 - val_accuracy: 0.6096\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.6206 - accuracy: 0.6738 - val_loss: 0.6576 - val_accuracy: 0.6140\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.6162 - accuracy: 0.6776 - val_loss: 0.6496 - val_accuracy: 0.6245\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.6104 - accuracy: 0.6822 - val_loss: 0.6376 - val_accuracy: 0.6422\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.6053 - accuracy: 0.6865 - val_loss: 0.6318 - val_accuracy: 0.6458\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.6022 - accuracy: 0.6855 - val_loss: 0.6348 - val_accuracy: 0.6402\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.5973 - accuracy: 0.6909 - val_loss: 0.6209 - val_accuracy: 0.6530\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5931 - accuracy: 0.6929 - val_loss: 0.6227 - val_accuracy: 0.6472\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5896 - accuracy: 0.6976 - val_loss: 0.6157 - val_accuracy: 0.6544\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.5855 - accuracy: 0.6990 - val_loss: 0.6240 - val_accuracy: 0.6413\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.5838 - accuracy: 0.7011 - val_loss: 0.6221 - val_accuracy: 0.6419\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5807 - accuracy: 0.7026 - val_loss: 0.6036 - val_accuracy: 0.6633\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.5762 - accuracy: 0.7077 - val_loss: 0.6151 - val_accuracy: 0.6496\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.5741 - accuracy: 0.7092 - val_loss: 0.6040 - val_accuracy: 0.6607\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5706 - accuracy: 0.7106 - val_loss: 0.6132 - val_accuracy: 0.6481\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.5677 - accuracy: 0.7139 - val_loss: 0.5982 - val_accuracy: 0.6643\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.5658 - accuracy: 0.7135 - val_loss: 0.6040 - val_accuracy: 0.6577\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.5627 - accuracy: 0.7148 - val_loss: 0.6048 - val_accuracy: 0.6549\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5596 - accuracy: 0.7193 - val_loss: 0.6014 - val_accuracy: 0.6564\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.5574 - accuracy: 0.7197 - val_loss: 0.5939 - val_accuracy: 0.6633\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.5538 - accuracy: 0.7234 - val_loss: 0.6015 - val_accuracy: 0.6558\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.5525 - accuracy: 0.7237 - val_loss: 0.6059 - val_accuracy: 0.6511\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.5504 - accuracy: 0.7249 - val_loss: 0.6132 - val_accuracy: 0.6433\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.5481 - accuracy: 0.7273 - val_loss: 0.6036 - val_accuracy: 0.6503\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5452 - accuracy: 0.7283 - val_loss: 0.5920 - val_accuracy: 0.6621\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.5441 - accuracy: 0.7281 - val_loss: 0.6112 - val_accuracy: 0.6430\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.5413 - accuracy: 0.7301 - val_loss: 0.5949 - val_accuracy: 0.6594\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.5394 - accuracy: 0.7313 - val_loss: 0.5947 - val_accuracy: 0.6580\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5375 - accuracy: 0.7339 - val_loss: 0.5926 - val_accuracy: 0.6615\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.5352 - accuracy: 0.7330 - val_loss: 0.6014 - val_accuracy: 0.6512\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.5337 - accuracy: 0.7335 - val_loss: 0.5957 - val_accuracy: 0.6564\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 407us/step - loss: 0.5324 - accuracy: 0.7361 - val_loss: 0.6051 - val_accuracy: 0.6487\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.5313 - accuracy: 0.7345 - val_loss: 0.5956 - val_accuracy: 0.6569\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 407us/step - loss: 0.5280 - accuracy: 0.7378 - val_loss: 0.5973 - val_accuracy: 0.6553\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 405us/step - loss: 0.5270 - accuracy: 0.7392 - val_loss: 0.6126 - val_accuracy: 0.6436\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 405us/step - loss: 0.5252 - accuracy: 0.7393 - val_loss: 0.5874 - val_accuracy: 0.6642\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.5236 - accuracy: 0.7403 - val_loss: 0.6016 - val_accuracy: 0.6524\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.5218 - accuracy: 0.7415 - val_loss: 0.6025 - val_accuracy: 0.6523\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.5201 - accuracy: 0.7408 - val_loss: 0.6042 - val_accuracy: 0.6508\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.5191 - accuracy: 0.7437 - val_loss: 0.5949 - val_accuracy: 0.6575\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 403us/step - loss: 0.5174 - accuracy: 0.7453 - val_loss: 0.5897 - val_accuracy: 0.6628\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.5152 - accuracy: 0.7452 - val_loss: 0.5968 - val_accuracy: 0.6572\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.5159 - accuracy: 0.7432 - val_loss: 0.5938 - val_accuracy: 0.6593\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.5126 - accuracy: 0.7451 - val_loss: 0.5956 - val_accuracy: 0.6577\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.5126 - accuracy: 0.7447 - val_loss: 0.5901 - val_accuracy: 0.6627\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 407us/step - loss: 0.5098 - accuracy: 0.7491 - val_loss: 0.5959 - val_accuracy: 0.6566\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.7165 - accuracy: 0.5374 - val_loss: 0.7154 - val_accuracy: 0.4737\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.6877 - accuracy: 0.5657 - val_loss: 0.6862 - val_accuracy: 0.5756\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.6700 - accuracy: 0.5861 - val_loss: 0.6860 - val_accuracy: 0.5820\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 417us/step - loss: 0.6588 - accuracy: 0.6059 - val_loss: 0.6748 - val_accuracy: 0.5967\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.6513 - accuracy: 0.6197 - val_loss: 0.6643 - val_accuracy: 0.6172\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.6421 - accuracy: 0.6305 - val_loss: 0.6551 - val_accuracy: 0.6372\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 408us/step - loss: 0.6344 - accuracy: 0.6404 - val_loss: 0.6508 - val_accuracy: 0.6389\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.6281 - accuracy: 0.6474 - val_loss: 0.6418 - val_accuracy: 0.6509\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.6238 - accuracy: 0.6541 - val_loss: 0.6397 - val_accuracy: 0.6495\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.6196 - accuracy: 0.6600 - val_loss: 0.6310 - val_accuracy: 0.6603\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 411us/step - loss: 0.6155 - accuracy: 0.6634 - val_loss: 0.6361 - val_accuracy: 0.6527\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 411us/step - loss: 0.6111 - accuracy: 0.6662 - val_loss: 0.6297 - val_accuracy: 0.6576\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.6082 - accuracy: 0.6708 - val_loss: 0.6254 - val_accuracy: 0.6592\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.6042 - accuracy: 0.6747 - val_loss: 0.6276 - val_accuracy: 0.6523\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 416us/step - loss: 0.6004 - accuracy: 0.6783 - val_loss: 0.6258 - val_accuracy: 0.6512\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.5968 - accuracy: 0.6833 - val_loss: 0.6321 - val_accuracy: 0.6414\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5935 - accuracy: 0.6859 - val_loss: 0.6236 - val_accuracy: 0.6486\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.5908 - accuracy: 0.6885 - val_loss: 0.6165 - val_accuracy: 0.6544\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.5880 - accuracy: 0.6908 - val_loss: 0.6175 - val_accuracy: 0.6532\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 411us/step - loss: 0.5838 - accuracy: 0.6941 - val_loss: 0.6147 - val_accuracy: 0.6535\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.5815 - accuracy: 0.6970 - val_loss: 0.6249 - val_accuracy: 0.6418\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.5782 - accuracy: 0.7000 - val_loss: 0.6245 - val_accuracy: 0.6388\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.5761 - accuracy: 0.7016 - val_loss: 0.6241 - val_accuracy: 0.6396\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.5735 - accuracy: 0.7052 - val_loss: 0.6180 - val_accuracy: 0.6446\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.5704 - accuracy: 0.7065 - val_loss: 0.6129 - val_accuracy: 0.6479\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 413us/step - loss: 0.5684 - accuracy: 0.7088 - val_loss: 0.6151 - val_accuracy: 0.6455\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 413us/step - loss: 0.5667 - accuracy: 0.7113 - val_loss: 0.6043 - val_accuracy: 0.6572\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 411us/step - loss: 0.5639 - accuracy: 0.7127 - val_loss: 0.6040 - val_accuracy: 0.6575\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.5608 - accuracy: 0.7142 - val_loss: 0.6122 - val_accuracy: 0.6509\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.5589 - accuracy: 0.7163 - val_loss: 0.6160 - val_accuracy: 0.6471\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.5564 - accuracy: 0.7172 - val_loss: 0.6171 - val_accuracy: 0.6459\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.5547 - accuracy: 0.7209 - val_loss: 0.6143 - val_accuracy: 0.6483\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5519 - accuracy: 0.7215 - val_loss: 0.5984 - val_accuracy: 0.6622\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5500 - accuracy: 0.7237 - val_loss: 0.6059 - val_accuracy: 0.6560\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 415us/step - loss: 0.5489 - accuracy: 0.7235 - val_loss: 0.6015 - val_accuracy: 0.6605\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.5470 - accuracy: 0.7268 - val_loss: 0.6058 - val_accuracy: 0.6569\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 415us/step - loss: 0.5442 - accuracy: 0.7269 - val_loss: 0.6147 - val_accuracy: 0.6479\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.5433 - accuracy: 0.7279 - val_loss: 0.5932 - val_accuracy: 0.6666\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.5400 - accuracy: 0.7299 - val_loss: 0.6033 - val_accuracy: 0.6587\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5388 - accuracy: 0.7308 - val_loss: 0.5951 - val_accuracy: 0.6656\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.5370 - accuracy: 0.7307 - val_loss: 0.6121 - val_accuracy: 0.6522\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5363 - accuracy: 0.7316 - val_loss: 0.5949 - val_accuracy: 0.6667\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.5338 - accuracy: 0.7340 - val_loss: 0.6075 - val_accuracy: 0.6566\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.5328 - accuracy: 0.7357 - val_loss: 0.6075 - val_accuracy: 0.6572\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.5303 - accuracy: 0.7365 - val_loss: 0.5999 - val_accuracy: 0.6637\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5281 - accuracy: 0.7370 - val_loss: 0.6040 - val_accuracy: 0.6604\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.5277 - accuracy: 0.7376 - val_loss: 0.5964 - val_accuracy: 0.6671\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.5255 - accuracy: 0.7390 - val_loss: 0.6008 - val_accuracy: 0.6637\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 444us/step - loss: 0.5244 - accuracy: 0.7400 - val_loss: 0.5973 - val_accuracy: 0.6657\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 440us/step - loss: 0.5236 - accuracy: 0.7403 - val_loss: 0.6006 - val_accuracy: 0.6629\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 416us/step - loss: 0.7012 - accuracy: 0.5176 - val_loss: 0.7318 - val_accuracy: 0.2877\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 392us/step - loss: 0.6866 - accuracy: 0.5442 - val_loss: 0.7148 - val_accuracy: 0.4324\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.6783 - accuracy: 0.5749 - val_loss: 0.7067 - val_accuracy: 0.4931\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.6724 - accuracy: 0.5902 - val_loss: 0.7053 - val_accuracy: 0.5079\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.6672 - accuracy: 0.6032 - val_loss: 0.7029 - val_accuracy: 0.5177\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.6632 - accuracy: 0.6132 - val_loss: 0.6939 - val_accuracy: 0.5423\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.6591 - accuracy: 0.6197 - val_loss: 0.6934 - val_accuracy: 0.5488\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.6561 - accuracy: 0.6262 - val_loss: 0.6887 - val_accuracy: 0.5615\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.6526 - accuracy: 0.6308 - val_loss: 0.6820 - val_accuracy: 0.5782\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.6490 - accuracy: 0.6380 - val_loss: 0.6808 - val_accuracy: 0.5791\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.6456 - accuracy: 0.6434 - val_loss: 0.6793 - val_accuracy: 0.5818\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.6427 - accuracy: 0.6457 - val_loss: 0.6707 - val_accuracy: 0.6023\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.6392 - accuracy: 0.6500 - val_loss: 0.6731 - val_accuracy: 0.5945\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.6363 - accuracy: 0.6537 - val_loss: 0.6623 - val_accuracy: 0.6189\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.6325 - accuracy: 0.6584 - val_loss: 0.6663 - val_accuracy: 0.6095\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.6298 - accuracy: 0.6604 - val_loss: 0.6635 - val_accuracy: 0.6142\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.6267 - accuracy: 0.6635 - val_loss: 0.6564 - val_accuracy: 0.6267\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.6241 - accuracy: 0.6662 - val_loss: 0.6547 - val_accuracy: 0.6263\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.6213 - accuracy: 0.6685 - val_loss: 0.6534 - val_accuracy: 0.6253\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.6183 - accuracy: 0.6713 - val_loss: 0.6523 - val_accuracy: 0.6269\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.6154 - accuracy: 0.6740 - val_loss: 0.6504 - val_accuracy: 0.6287\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.6116 - accuracy: 0.6776 - val_loss: 0.6449 - val_accuracy: 0.6344\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.6102 - accuracy: 0.6764 - val_loss: 0.6435 - val_accuracy: 0.6345\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.6065 - accuracy: 0.6820 - val_loss: 0.6395 - val_accuracy: 0.6380\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.6038 - accuracy: 0.6819 - val_loss: 0.6417 - val_accuracy: 0.6334\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.6017 - accuracy: 0.6834 - val_loss: 0.6425 - val_accuracy: 0.6310\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.5992 - accuracy: 0.6862 - val_loss: 0.6281 - val_accuracy: 0.6460\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5959 - accuracy: 0.6892 - val_loss: 0.6390 - val_accuracy: 0.6334\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.5936 - accuracy: 0.6916 - val_loss: 0.6282 - val_accuracy: 0.6444\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.5902 - accuracy: 0.6931 - val_loss: 0.6314 - val_accuracy: 0.6398\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.5886 - accuracy: 0.6943 - val_loss: 0.6332 - val_accuracy: 0.6376\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.5864 - accuracy: 0.6978 - val_loss: 0.6252 - val_accuracy: 0.6430\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.5840 - accuracy: 0.6970 - val_loss: 0.6285 - val_accuracy: 0.6383\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.5822 - accuracy: 0.7021 - val_loss: 0.6243 - val_accuracy: 0.6412\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.5797 - accuracy: 0.7019 - val_loss: 0.6310 - val_accuracy: 0.6312\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.5778 - accuracy: 0.7044 - val_loss: 0.6263 - val_accuracy: 0.6375\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.5756 - accuracy: 0.7065 - val_loss: 0.6248 - val_accuracy: 0.6398\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.5734 - accuracy: 0.7089 - val_loss: 0.6235 - val_accuracy: 0.6415\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5713 - accuracy: 0.7094 - val_loss: 0.6240 - val_accuracy: 0.6408\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.5686 - accuracy: 0.7109 - val_loss: 0.6232 - val_accuracy: 0.6422\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.5664 - accuracy: 0.7125 - val_loss: 0.6200 - val_accuracy: 0.6448\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.5658 - accuracy: 0.7162 - val_loss: 0.6112 - val_accuracy: 0.6554\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.5628 - accuracy: 0.7139 - val_loss: 0.6173 - val_accuracy: 0.6488\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5615 - accuracy: 0.7171 - val_loss: 0.6109 - val_accuracy: 0.6563\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.5600 - accuracy: 0.7175 - val_loss: 0.6185 - val_accuracy: 0.6483\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.5584 - accuracy: 0.7188 - val_loss: 0.6120 - val_accuracy: 0.6558\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.5562 - accuracy: 0.7192 - val_loss: 0.6154 - val_accuracy: 0.6512\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.5545 - accuracy: 0.7194 - val_loss: 0.6040 - val_accuracy: 0.6619\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.5524 - accuracy: 0.7240 - val_loss: 0.6031 - val_accuracy: 0.6631\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.5507 - accuracy: 0.7237 - val_loss: 0.6105 - val_accuracy: 0.6555\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.6981 - accuracy: 0.5523 - val_loss: 0.6893 - val_accuracy: 0.5176\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.6802 - accuracy: 0.5753 - val_loss: 0.6833 - val_accuracy: 0.5431\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 434us/step - loss: 0.6682 - accuracy: 0.5968 - val_loss: 0.6795 - val_accuracy: 0.5638\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.6572 - accuracy: 0.6130 - val_loss: 0.6707 - val_accuracy: 0.5883\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 405us/step - loss: 0.6472 - accuracy: 0.6344 - val_loss: 0.6649 - val_accuracy: 0.5978\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.6413 - accuracy: 0.6398 - val_loss: 0.6569 - val_accuracy: 0.6093\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 401us/step - loss: 0.6336 - accuracy: 0.6502 - val_loss: 0.6522 - val_accuracy: 0.6127\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.6266 - accuracy: 0.6593 - val_loss: 0.6532 - val_accuracy: 0.6070\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 403us/step - loss: 0.6214 - accuracy: 0.6681 - val_loss: 0.6488 - val_accuracy: 0.6117\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.6166 - accuracy: 0.6706 - val_loss: 0.6344 - val_accuracy: 0.6297\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.6120 - accuracy: 0.6756 - val_loss: 0.6352 - val_accuracy: 0.6262\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.6076 - accuracy: 0.6778 - val_loss: 0.6329 - val_accuracy: 0.6291\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 403us/step - loss: 0.6022 - accuracy: 0.6820 - val_loss: 0.6212 - val_accuracy: 0.6405\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.5991 - accuracy: 0.6845 - val_loss: 0.6375 - val_accuracy: 0.6214\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.5963 - accuracy: 0.6871 - val_loss: 0.6297 - val_accuracy: 0.6299\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 405us/step - loss: 0.5919 - accuracy: 0.6901 - val_loss: 0.6256 - val_accuracy: 0.6324\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.5866 - accuracy: 0.6953 - val_loss: 0.6218 - val_accuracy: 0.6388\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.5837 - accuracy: 0.6974 - val_loss: 0.6171 - val_accuracy: 0.6450\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 398us/step - loss: 0.5803 - accuracy: 0.6994 - val_loss: 0.6095 - val_accuracy: 0.6544\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5769 - accuracy: 0.7029 - val_loss: 0.6064 - val_accuracy: 0.6580\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 400us/step - loss: 0.5744 - accuracy: 0.7045 - val_loss: 0.6166 - val_accuracy: 0.6450\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.5726 - accuracy: 0.7069 - val_loss: 0.6214 - val_accuracy: 0.6394\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.5695 - accuracy: 0.7063 - val_loss: 0.6161 - val_accuracy: 0.6451\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.5668 - accuracy: 0.7106 - val_loss: 0.6101 - val_accuracy: 0.6507\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.5662 - accuracy: 0.7099 - val_loss: 0.6150 - val_accuracy: 0.6454\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.5635 - accuracy: 0.7122 - val_loss: 0.6140 - val_accuracy: 0.6462\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.5623 - accuracy: 0.7135 - val_loss: 0.6051 - val_accuracy: 0.6534\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.5588 - accuracy: 0.7146 - val_loss: 0.5984 - val_accuracy: 0.6593\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.5583 - accuracy: 0.7152 - val_loss: 0.5960 - val_accuracy: 0.6600\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5559 - accuracy: 0.7176 - val_loss: 0.6099 - val_accuracy: 0.6457\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.5535 - accuracy: 0.7207 - val_loss: 0.6009 - val_accuracy: 0.6545\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 408us/step - loss: 0.5518 - accuracy: 0.7195 - val_loss: 0.5932 - val_accuracy: 0.6603\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.5506 - accuracy: 0.7210 - val_loss: 0.6129 - val_accuracy: 0.6423\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.5491 - accuracy: 0.7216 - val_loss: 0.6159 - val_accuracy: 0.6394\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 407us/step - loss: 0.5477 - accuracy: 0.7205 - val_loss: 0.5843 - val_accuracy: 0.6638\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.5459 - accuracy: 0.7243 - val_loss: 0.5953 - val_accuracy: 0.6556\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.5436 - accuracy: 0.7253 - val_loss: 0.6040 - val_accuracy: 0.6497\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.5417 - accuracy: 0.7258 - val_loss: 0.6104 - val_accuracy: 0.6439\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.5395 - accuracy: 0.7276 - val_loss: 0.6031 - val_accuracy: 0.6506\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.5399 - accuracy: 0.7257 - val_loss: 0.6044 - val_accuracy: 0.6498\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.5379 - accuracy: 0.7266 - val_loss: 0.6032 - val_accuracy: 0.6503\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 403us/step - loss: 0.5359 - accuracy: 0.7290 - val_loss: 0.6054 - val_accuracy: 0.6483\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 400us/step - loss: 0.5350 - accuracy: 0.7294 - val_loss: 0.6097 - val_accuracy: 0.6450\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.5322 - accuracy: 0.7298 - val_loss: 0.6077 - val_accuracy: 0.6462\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 403us/step - loss: 0.5314 - accuracy: 0.7305 - val_loss: 0.6098 - val_accuracy: 0.6446\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.5311 - accuracy: 0.7306 - val_loss: 0.5950 - val_accuracy: 0.6555\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.5286 - accuracy: 0.7327 - val_loss: 0.6007 - val_accuracy: 0.6503\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.5267 - accuracy: 0.7344 - val_loss: 0.6055 - val_accuracy: 0.6468\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.5257 - accuracy: 0.7363 - val_loss: 0.6023 - val_accuracy: 0.6490\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.5243 - accuracy: 0.7361 - val_loss: 0.5962 - val_accuracy: 0.6537\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 438us/step - loss: 0.7036 - accuracy: 0.5158 - val_loss: 0.7240 - val_accuracy: 0.3169\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.6875 - accuracy: 0.5435 - val_loss: 0.7184 - val_accuracy: 0.3279\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.6775 - accuracy: 0.5649 - val_loss: 0.7161 - val_accuracy: 0.3691\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 403us/step - loss: 0.6673 - accuracy: 0.5891 - val_loss: 0.6981 - val_accuracy: 0.4903\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.6573 - accuracy: 0.6139 - val_loss: 0.6836 - val_accuracy: 0.5727\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.6483 - accuracy: 0.6331 - val_loss: 0.6829 - val_accuracy: 0.5816\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.6405 - accuracy: 0.6488 - val_loss: 0.6727 - val_accuracy: 0.6067\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.6336 - accuracy: 0.6584 - val_loss: 0.6729 - val_accuracy: 0.6000\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 401us/step - loss: 0.6264 - accuracy: 0.6687 - val_loss: 0.6669 - val_accuracy: 0.6113\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.6210 - accuracy: 0.6735 - val_loss: 0.6614 - val_accuracy: 0.6178\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.6170 - accuracy: 0.6764 - val_loss: 0.6543 - val_accuracy: 0.6295\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.6104 - accuracy: 0.6829 - val_loss: 0.6467 - val_accuracy: 0.6439\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.6075 - accuracy: 0.6845 - val_loss: 0.6360 - val_accuracy: 0.6569\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 413us/step - loss: 0.6023 - accuracy: 0.6898 - val_loss: 0.6394 - val_accuracy: 0.6502\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.5990 - accuracy: 0.6891 - val_loss: 0.6322 - val_accuracy: 0.6561\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.5951 - accuracy: 0.6923 - val_loss: 0.6345 - val_accuracy: 0.6500\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.5911 - accuracy: 0.6971 - val_loss: 0.6303 - val_accuracy: 0.6524\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.5866 - accuracy: 0.7011 - val_loss: 0.6360 - val_accuracy: 0.6447\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.5836 - accuracy: 0.7011 - val_loss: 0.6260 - val_accuracy: 0.6521\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 401us/step - loss: 0.5799 - accuracy: 0.7043 - val_loss: 0.6282 - val_accuracy: 0.6485\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.5774 - accuracy: 0.7056 - val_loss: 0.6139 - val_accuracy: 0.6650\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.5740 - accuracy: 0.7088 - val_loss: 0.6215 - val_accuracy: 0.6534\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.5705 - accuracy: 0.7115 - val_loss: 0.6158 - val_accuracy: 0.6605\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.5680 - accuracy: 0.7127 - val_loss: 0.6130 - val_accuracy: 0.6617\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.5648 - accuracy: 0.7158 - val_loss: 0.6139 - val_accuracy: 0.6580\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.5628 - accuracy: 0.7157 - val_loss: 0.6043 - val_accuracy: 0.6668\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.5600 - accuracy: 0.7177 - val_loss: 0.6083 - val_accuracy: 0.6618\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.5569 - accuracy: 0.7205 - val_loss: 0.6225 - val_accuracy: 0.6468\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.5555 - accuracy: 0.7189 - val_loss: 0.6095 - val_accuracy: 0.6586\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.5535 - accuracy: 0.7214 - val_loss: 0.6058 - val_accuracy: 0.6607\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5501 - accuracy: 0.7249 - val_loss: 0.6094 - val_accuracy: 0.6570\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.5481 - accuracy: 0.7253 - val_loss: 0.6052 - val_accuracy: 0.6581\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5470 - accuracy: 0.7275 - val_loss: 0.6132 - val_accuracy: 0.6525\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.5431 - accuracy: 0.7303 - val_loss: 0.6205 - val_accuracy: 0.6464\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.5418 - accuracy: 0.7299 - val_loss: 0.6080 - val_accuracy: 0.6565\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.5402 - accuracy: 0.7299 - val_loss: 0.6064 - val_accuracy: 0.6579\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.5383 - accuracy: 0.7313 - val_loss: 0.6034 - val_accuracy: 0.6601\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.5367 - accuracy: 0.7343 - val_loss: 0.6042 - val_accuracy: 0.6600\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.5342 - accuracy: 0.7344 - val_loss: 0.5857 - val_accuracy: 0.6758\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 464us/step - loss: 0.5334 - accuracy: 0.7333 - val_loss: 0.5959 - val_accuracy: 0.6660\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.5311 - accuracy: 0.7353 - val_loss: 0.6167 - val_accuracy: 0.6474\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.5291 - accuracy: 0.7357 - val_loss: 0.5917 - val_accuracy: 0.6687\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.5285 - accuracy: 0.7363 - val_loss: 0.5953 - val_accuracy: 0.6663\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.5264 - accuracy: 0.7361 - val_loss: 0.5883 - val_accuracy: 0.6717\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5255 - accuracy: 0.7386 - val_loss: 0.5890 - val_accuracy: 0.6712\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.5237 - accuracy: 0.7400 - val_loss: 0.5894 - val_accuracy: 0.6708\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 463us/step - loss: 0.5227 - accuracy: 0.7383 - val_loss: 0.6112 - val_accuracy: 0.6532\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.5207 - accuracy: 0.7409 - val_loss: 0.5997 - val_accuracy: 0.6637\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.5190 - accuracy: 0.7433 - val_loss: 0.6061 - val_accuracy: 0.6586\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.5180 - accuracy: 0.7435 - val_loss: 0.6073 - val_accuracy: 0.6586\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.6885 - accuracy: 0.5453 - val_loss: 0.7191 - val_accuracy: 0.3442\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 466us/step - loss: 0.6770 - accuracy: 0.5680 - val_loss: 0.7019 - val_accuracy: 0.4466\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.6686 - accuracy: 0.5877 - val_loss: 0.6941 - val_accuracy: 0.4913\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.6600 - accuracy: 0.6049 - val_loss: 0.6780 - val_accuracy: 0.5560\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.6528 - accuracy: 0.6200 - val_loss: 0.6740 - val_accuracy: 0.5740\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.6468 - accuracy: 0.6316 - val_loss: 0.6736 - val_accuracy: 0.5741\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.6417 - accuracy: 0.6391 - val_loss: 0.6715 - val_accuracy: 0.5776\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.6376 - accuracy: 0.6441 - val_loss: 0.6587 - val_accuracy: 0.6110\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.6325 - accuracy: 0.6513 - val_loss: 0.6640 - val_accuracy: 0.5952\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.6270 - accuracy: 0.6604 - val_loss: 0.6554 - val_accuracy: 0.6120\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.6224 - accuracy: 0.6648 - val_loss: 0.6559 - val_accuracy: 0.6099\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.6175 - accuracy: 0.6724 - val_loss: 0.6417 - val_accuracy: 0.6366\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.6139 - accuracy: 0.6726 - val_loss: 0.6450 - val_accuracy: 0.6281\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.6096 - accuracy: 0.6774 - val_loss: 0.6509 - val_accuracy: 0.6183\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.6059 - accuracy: 0.6773 - val_loss: 0.6463 - val_accuracy: 0.6270\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.6021 - accuracy: 0.6809 - val_loss: 0.6357 - val_accuracy: 0.6407\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.5979 - accuracy: 0.6871 - val_loss: 0.6316 - val_accuracy: 0.6455\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5936 - accuracy: 0.6896 - val_loss: 0.6326 - val_accuracy: 0.6428\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.5921 - accuracy: 0.6885 - val_loss: 0.6231 - val_accuracy: 0.6564\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.5876 - accuracy: 0.6936 - val_loss: 0.6208 - val_accuracy: 0.6574\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.5833 - accuracy: 0.6962 - val_loss: 0.6114 - val_accuracy: 0.6684\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 476us/step - loss: 0.5814 - accuracy: 0.6980 - val_loss: 0.6171 - val_accuracy: 0.6606\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.5789 - accuracy: 0.6992 - val_loss: 0.6261 - val_accuracy: 0.6504\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.5760 - accuracy: 0.7016 - val_loss: 0.6160 - val_accuracy: 0.6606\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 457us/step - loss: 0.5727 - accuracy: 0.7036 - val_loss: 0.6169 - val_accuracy: 0.6598\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.5704 - accuracy: 0.7059 - val_loss: 0.6168 - val_accuracy: 0.6602\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5671 - accuracy: 0.7087 - val_loss: 0.6253 - val_accuracy: 0.6495\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5656 - accuracy: 0.7097 - val_loss: 0.6019 - val_accuracy: 0.6742\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5631 - accuracy: 0.7111 - val_loss: 0.6250 - val_accuracy: 0.6490\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 428us/step - loss: 0.5604 - accuracy: 0.7153 - val_loss: 0.6065 - val_accuracy: 0.6689\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 411us/step - loss: 0.5585 - accuracy: 0.7145 - val_loss: 0.6070 - val_accuracy: 0.6679\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.5568 - accuracy: 0.7164 - val_loss: 0.6146 - val_accuracy: 0.6610\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.5544 - accuracy: 0.7181 - val_loss: 0.6153 - val_accuracy: 0.6606\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5527 - accuracy: 0.7202 - val_loss: 0.6117 - val_accuracy: 0.6637\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.5513 - accuracy: 0.7206 - val_loss: 0.6044 - val_accuracy: 0.6708\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.5492 - accuracy: 0.7225 - val_loss: 0.6118 - val_accuracy: 0.6635\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.5468 - accuracy: 0.7230 - val_loss: 0.6068 - val_accuracy: 0.6676\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 441us/step - loss: 0.5460 - accuracy: 0.7236 - val_loss: 0.6194 - val_accuracy: 0.6575\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.5444 - accuracy: 0.7240 - val_loss: 0.6146 - val_accuracy: 0.6624\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 447us/step - loss: 0.5427 - accuracy: 0.7254 - val_loss: 0.6005 - val_accuracy: 0.6725\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 408us/step - loss: 0.5417 - accuracy: 0.7270 - val_loss: 0.6039 - val_accuracy: 0.6709\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.5400 - accuracy: 0.7283 - val_loss: 0.6250 - val_accuracy: 0.6554\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.5389 - accuracy: 0.7285 - val_loss: 0.6096 - val_accuracy: 0.6665\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 408us/step - loss: 0.5373 - accuracy: 0.7295 - val_loss: 0.6051 - val_accuracy: 0.6709\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.5356 - accuracy: 0.7300 - val_loss: 0.6042 - val_accuracy: 0.6712\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5349 - accuracy: 0.7290 - val_loss: 0.6113 - val_accuracy: 0.6665\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.5333 - accuracy: 0.7306 - val_loss: 0.6085 - val_accuracy: 0.6678\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5323 - accuracy: 0.7322 - val_loss: 0.6099 - val_accuracy: 0.6664\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 401us/step - loss: 0.5307 - accuracy: 0.7341 - val_loss: 0.6105 - val_accuracy: 0.6652\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.5306 - accuracy: 0.7331 - val_loss: 0.6064 - val_accuracy: 0.6689\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.7264 - accuracy: 0.4984 - val_loss: 0.7436 - val_accuracy: 0.2395\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 416us/step - loss: 0.7044 - accuracy: 0.5132 - val_loss: 0.7314 - val_accuracy: 0.3360\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 393us/step - loss: 0.6954 - accuracy: 0.5307 - val_loss: 0.7299 - val_accuracy: 0.3649\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.6866 - accuracy: 0.5526 - val_loss: 0.7184 - val_accuracy: 0.4183\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 397us/step - loss: 0.6784 - accuracy: 0.5714 - val_loss: 0.7040 - val_accuracy: 0.4768\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.6716 - accuracy: 0.5914 - val_loss: 0.7024 - val_accuracy: 0.4987\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.6647 - accuracy: 0.6062 - val_loss: 0.6975 - val_accuracy: 0.5159\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 404us/step - loss: 0.6586 - accuracy: 0.6188 - val_loss: 0.6932 - val_accuracy: 0.5254\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 414us/step - loss: 0.6527 - accuracy: 0.6307 - val_loss: 0.6754 - val_accuracy: 0.5827\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.6470 - accuracy: 0.6397 - val_loss: 0.6831 - val_accuracy: 0.5584\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.6412 - accuracy: 0.6492 - val_loss: 0.6755 - val_accuracy: 0.5826\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.6364 - accuracy: 0.6538 - val_loss: 0.6639 - val_accuracy: 0.6101\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 403us/step - loss: 0.6315 - accuracy: 0.6594 - val_loss: 0.6709 - val_accuracy: 0.5971\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.6274 - accuracy: 0.6638 - val_loss: 0.6539 - val_accuracy: 0.6273\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.6233 - accuracy: 0.6668 - val_loss: 0.6684 - val_accuracy: 0.6033\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.6198 - accuracy: 0.6690 - val_loss: 0.6551 - val_accuracy: 0.6234\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 391us/step - loss: 0.6149 - accuracy: 0.6746 - val_loss: 0.6520 - val_accuracy: 0.6267\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 415us/step - loss: 0.6121 - accuracy: 0.6764 - val_loss: 0.6434 - val_accuracy: 0.6365\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 402us/step - loss: 0.6099 - accuracy: 0.6772 - val_loss: 0.6401 - val_accuracy: 0.6396\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.6054 - accuracy: 0.6827 - val_loss: 0.6410 - val_accuracy: 0.6366\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.6024 - accuracy: 0.6844 - val_loss: 0.6320 - val_accuracy: 0.6444\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.5999 - accuracy: 0.6851 - val_loss: 0.6416 - val_accuracy: 0.6320\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 431us/step - loss: 0.5964 - accuracy: 0.6896 - val_loss: 0.6361 - val_accuracy: 0.6337\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 408us/step - loss: 0.5939 - accuracy: 0.6911 - val_loss: 0.6287 - val_accuracy: 0.6405\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 432us/step - loss: 0.5909 - accuracy: 0.6952 - val_loss: 0.6336 - val_accuracy: 0.6351\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.5892 - accuracy: 0.6939 - val_loss: 0.6313 - val_accuracy: 0.6378\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.5854 - accuracy: 0.6982 - val_loss: 0.6229 - val_accuracy: 0.6449\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.5835 - accuracy: 0.7006 - val_loss: 0.6368 - val_accuracy: 0.6325\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.5808 - accuracy: 0.7035 - val_loss: 0.6162 - val_accuracy: 0.6483\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 413us/step - loss: 0.5786 - accuracy: 0.7027 - val_loss: 0.6318 - val_accuracy: 0.6377\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.5762 - accuracy: 0.7086 - val_loss: 0.6357 - val_accuracy: 0.6355\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 397us/step - loss: 0.5746 - accuracy: 0.7065 - val_loss: 0.6199 - val_accuracy: 0.6469\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.5715 - accuracy: 0.7114 - val_loss: 0.6281 - val_accuracy: 0.6403\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 407us/step - loss: 0.5702 - accuracy: 0.7089 - val_loss: 0.6197 - val_accuracy: 0.6466\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 416us/step - loss: 0.5682 - accuracy: 0.7125 - val_loss: 0.6198 - val_accuracy: 0.6474\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.5657 - accuracy: 0.7142 - val_loss: 0.6237 - val_accuracy: 0.6449\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.5643 - accuracy: 0.7141 - val_loss: 0.6259 - val_accuracy: 0.6440\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 397us/step - loss: 0.5630 - accuracy: 0.7142 - val_loss: 0.6215 - val_accuracy: 0.6481\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.5605 - accuracy: 0.7171 - val_loss: 0.6122 - val_accuracy: 0.6549\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 411us/step - loss: 0.5595 - accuracy: 0.7162 - val_loss: 0.6131 - val_accuracy: 0.6545\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.5579 - accuracy: 0.7172 - val_loss: 0.6253 - val_accuracy: 0.6470\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 405us/step - loss: 0.5561 - accuracy: 0.7181 - val_loss: 0.6158 - val_accuracy: 0.6524\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.5543 - accuracy: 0.7183 - val_loss: 0.6124 - val_accuracy: 0.6552\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 408us/step - loss: 0.5526 - accuracy: 0.7195 - val_loss: 0.6087 - val_accuracy: 0.6573\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 422us/step - loss: 0.5513 - accuracy: 0.7206 - val_loss: 0.6120 - val_accuracy: 0.6569\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.5494 - accuracy: 0.7207 - val_loss: 0.6218 - val_accuracy: 0.6498\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.5483 - accuracy: 0.7202 - val_loss: 0.6021 - val_accuracy: 0.6632\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 408us/step - loss: 0.5461 - accuracy: 0.7227 - val_loss: 0.6133 - val_accuracy: 0.6558\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 620us/step - loss: 0.5456 - accuracy: 0.7213 - val_loss: 0.6111 - val_accuracy: 0.6562\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.5441 - accuracy: 0.7215 - val_loss: 0.6127 - val_accuracy: 0.6550\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.7220 - accuracy: 0.4903 - val_loss: 0.7129 - val_accuracy: 0.5243\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.6928 - accuracy: 0.5460 - val_loss: 0.7013 - val_accuracy: 0.5383\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.6782 - accuracy: 0.5766 - val_loss: 0.6838 - val_accuracy: 0.5663\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.6684 - accuracy: 0.5946 - val_loss: 0.6777 - val_accuracy: 0.5691\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.6609 - accuracy: 0.6066 - val_loss: 0.6762 - val_accuracy: 0.5733\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.6551 - accuracy: 0.6199 - val_loss: 0.6746 - val_accuracy: 0.5779\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.6505 - accuracy: 0.6276 - val_loss: 0.6627 - val_accuracy: 0.5999\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.6463 - accuracy: 0.6345 - val_loss: 0.6625 - val_accuracy: 0.6035\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.6419 - accuracy: 0.6407 - val_loss: 0.6514 - val_accuracy: 0.6211\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.6374 - accuracy: 0.6477 - val_loss: 0.6553 - val_accuracy: 0.6197\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.6327 - accuracy: 0.6547 - val_loss: 0.6463 - val_accuracy: 0.6311\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.6296 - accuracy: 0.6571 - val_loss: 0.6433 - val_accuracy: 0.6333\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.6265 - accuracy: 0.6610 - val_loss: 0.6445 - val_accuracy: 0.6304\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.6228 - accuracy: 0.6653 - val_loss: 0.6397 - val_accuracy: 0.6345\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.6187 - accuracy: 0.6702 - val_loss: 0.6341 - val_accuracy: 0.6414\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.6159 - accuracy: 0.6735 - val_loss: 0.6309 - val_accuracy: 0.6446\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.6120 - accuracy: 0.6771 - val_loss: 0.6313 - val_accuracy: 0.6438\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.6092 - accuracy: 0.6794 - val_loss: 0.6317 - val_accuracy: 0.6443\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.6058 - accuracy: 0.6835 - val_loss: 0.6377 - val_accuracy: 0.6383\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.6026 - accuracy: 0.6856 - val_loss: 0.6334 - val_accuracy: 0.6418\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.5997 - accuracy: 0.6894 - val_loss: 0.6270 - val_accuracy: 0.6472\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5969 - accuracy: 0.6904 - val_loss: 0.6175 - val_accuracy: 0.6566\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.5930 - accuracy: 0.6955 - val_loss: 0.6197 - val_accuracy: 0.6542\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.5915 - accuracy: 0.6961 - val_loss: 0.6242 - val_accuracy: 0.6489\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.5880 - accuracy: 0.6994 - val_loss: 0.6144 - val_accuracy: 0.6592\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.5853 - accuracy: 0.7020 - val_loss: 0.6164 - val_accuracy: 0.6545\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.5833 - accuracy: 0.7031 - val_loss: 0.6145 - val_accuracy: 0.6555\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5798 - accuracy: 0.7068 - val_loss: 0.6116 - val_accuracy: 0.6576\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.5782 - accuracy: 0.7093 - val_loss: 0.6165 - val_accuracy: 0.6520\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.5751 - accuracy: 0.7093 - val_loss: 0.6126 - val_accuracy: 0.6550\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.5718 - accuracy: 0.7128 - val_loss: 0.6075 - val_accuracy: 0.6573\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.5710 - accuracy: 0.7129 - val_loss: 0.6139 - val_accuracy: 0.6507\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5686 - accuracy: 0.7135 - val_loss: 0.6128 - val_accuracy: 0.6520\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5657 - accuracy: 0.7151 - val_loss: 0.6081 - val_accuracy: 0.6562\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5637 - accuracy: 0.7172 - val_loss: 0.6153 - val_accuracy: 0.6509\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.5617 - accuracy: 0.7183 - val_loss: 0.6005 - val_accuracy: 0.6623\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5599 - accuracy: 0.7211 - val_loss: 0.6141 - val_accuracy: 0.6497\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.5583 - accuracy: 0.7207 - val_loss: 0.5962 - val_accuracy: 0.6662\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.5557 - accuracy: 0.7227 - val_loss: 0.6037 - val_accuracy: 0.6587\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.5539 - accuracy: 0.7232 - val_loss: 0.6007 - val_accuracy: 0.6621\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.5512 - accuracy: 0.7238 - val_loss: 0.5971 - val_accuracy: 0.6640\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.5501 - accuracy: 0.7243 - val_loss: 0.6059 - val_accuracy: 0.6569\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5491 - accuracy: 0.7242 - val_loss: 0.6226 - val_accuracy: 0.6415\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 467us/step - loss: 0.5467 - accuracy: 0.7263 - val_loss: 0.6003 - val_accuracy: 0.6617\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5456 - accuracy: 0.7262 - val_loss: 0.5921 - val_accuracy: 0.6676\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.5429 - accuracy: 0.7298 - val_loss: 0.5989 - val_accuracy: 0.6616\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5422 - accuracy: 0.7293 - val_loss: 0.6087 - val_accuracy: 0.6549\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5414 - accuracy: 0.7276 - val_loss: 0.6005 - val_accuracy: 0.6610\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.5391 - accuracy: 0.7321 - val_loss: 0.6026 - val_accuracy: 0.6591\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 473us/step - loss: 0.5381 - accuracy: 0.7291 - val_loss: 0.6012 - val_accuracy: 0.6601\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.7147 - accuracy: 0.5233 - val_loss: 0.7011 - val_accuracy: 0.4903\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.6872 - accuracy: 0.5559 - val_loss: 0.6877 - val_accuracy: 0.5518\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.6717 - accuracy: 0.5857 - val_loss: 0.6764 - val_accuracy: 0.5753\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 1s 410us/step - loss: 0.6595 - accuracy: 0.6065 - val_loss: 0.6699 - val_accuracy: 0.5860\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.6498 - accuracy: 0.6168 - val_loss: 0.6581 - val_accuracy: 0.6081\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 1s 409us/step - loss: 0.6417 - accuracy: 0.6299 - val_loss: 0.6501 - val_accuracy: 0.6172\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 1s 429us/step - loss: 0.6348 - accuracy: 0.6381 - val_loss: 0.6543 - val_accuracy: 0.6030\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 1s 437us/step - loss: 0.6291 - accuracy: 0.6429 - val_loss: 0.6372 - val_accuracy: 0.6310\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 1s 436us/step - loss: 0.6250 - accuracy: 0.6488 - val_loss: 0.6458 - val_accuracy: 0.6123\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 1s 408us/step - loss: 0.6191 - accuracy: 0.6537 - val_loss: 0.6309 - val_accuracy: 0.6343\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 1s 425us/step - loss: 0.6142 - accuracy: 0.6570 - val_loss: 0.6232 - val_accuracy: 0.6439\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 1s 405us/step - loss: 0.6088 - accuracy: 0.6634 - val_loss: 0.6131 - val_accuracy: 0.6544\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.6051 - accuracy: 0.6663 - val_loss: 0.6154 - val_accuracy: 0.6450\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 1s 424us/step - loss: 0.6017 - accuracy: 0.6699 - val_loss: 0.6194 - val_accuracy: 0.6382\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 1s 405us/step - loss: 0.5982 - accuracy: 0.6727 - val_loss: 0.6118 - val_accuracy: 0.6439\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 1s 430us/step - loss: 0.5943 - accuracy: 0.6779 - val_loss: 0.6072 - val_accuracy: 0.6504\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 1s 393us/step - loss: 0.5909 - accuracy: 0.6817 - val_loss: 0.6109 - val_accuracy: 0.6437\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.5870 - accuracy: 0.6872 - val_loss: 0.6046 - val_accuracy: 0.6468\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 1s 416us/step - loss: 0.5830 - accuracy: 0.6894 - val_loss: 0.6031 - val_accuracy: 0.6470\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 1s 396us/step - loss: 0.5814 - accuracy: 0.6915 - val_loss: 0.6092 - val_accuracy: 0.6383\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 1s 413us/step - loss: 0.5782 - accuracy: 0.6933 - val_loss: 0.5987 - val_accuracy: 0.6469\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 1s 398us/step - loss: 0.5753 - accuracy: 0.6968 - val_loss: 0.6080 - val_accuracy: 0.6336\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.5723 - accuracy: 0.7003 - val_loss: 0.6051 - val_accuracy: 0.6340\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 1s 415us/step - loss: 0.5691 - accuracy: 0.7026 - val_loss: 0.5969 - val_accuracy: 0.6449\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.5672 - accuracy: 0.7048 - val_loss: 0.6104 - val_accuracy: 0.6295\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 1s 413us/step - loss: 0.5646 - accuracy: 0.7068 - val_loss: 0.5869 - val_accuracy: 0.6553\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 1s 397us/step - loss: 0.5619 - accuracy: 0.7093 - val_loss: 0.6036 - val_accuracy: 0.6387\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 1s 418us/step - loss: 0.5595 - accuracy: 0.7117 - val_loss: 0.5995 - val_accuracy: 0.6438\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 1s 393us/step - loss: 0.5570 - accuracy: 0.7141 - val_loss: 0.6002 - val_accuracy: 0.6428\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 1s 414us/step - loss: 0.5545 - accuracy: 0.7166 - val_loss: 0.6010 - val_accuracy: 0.6403\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 1s 398us/step - loss: 0.5537 - accuracy: 0.7170 - val_loss: 0.6080 - val_accuracy: 0.6359\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 1s 415us/step - loss: 0.5504 - accuracy: 0.7190 - val_loss: 0.5841 - val_accuracy: 0.6605\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 1s 416us/step - loss: 0.5493 - accuracy: 0.7186 - val_loss: 0.5914 - val_accuracy: 0.6510\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 398us/step - loss: 0.5464 - accuracy: 0.7215 - val_loss: 0.5942 - val_accuracy: 0.6481\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.5445 - accuracy: 0.7241 - val_loss: 0.5983 - val_accuracy: 0.6429\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 399us/step - loss: 0.5426 - accuracy: 0.7268 - val_loss: 0.5975 - val_accuracy: 0.6429\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 1s 419us/step - loss: 0.5414 - accuracy: 0.7257 - val_loss: 0.6113 - val_accuracy: 0.6307\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 1s 412us/step - loss: 0.5401 - accuracy: 0.7286 - val_loss: 0.5993 - val_accuracy: 0.6406\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.5374 - accuracy: 0.7288 - val_loss: 0.6020 - val_accuracy: 0.6392\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 1s 406us/step - loss: 0.5366 - accuracy: 0.7291 - val_loss: 0.5926 - val_accuracy: 0.6461\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.5341 - accuracy: 0.7315 - val_loss: 0.5921 - val_accuracy: 0.6470\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 1s 420us/step - loss: 0.5332 - accuracy: 0.7308 - val_loss: 0.5904 - val_accuracy: 0.6493\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 1s 401us/step - loss: 0.5318 - accuracy: 0.7327 - val_loss: 0.6025 - val_accuracy: 0.6394\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 1s 423us/step - loss: 0.5303 - accuracy: 0.7346 - val_loss: 0.5941 - val_accuracy: 0.6475\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 1s 435us/step - loss: 0.5298 - accuracy: 0.7319 - val_loss: 0.5942 - val_accuracy: 0.6475\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 1s 427us/step - loss: 0.5279 - accuracy: 0.7344 - val_loss: 0.5929 - val_accuracy: 0.6481\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 1s 401us/step - loss: 0.5257 - accuracy: 0.7363 - val_loss: 0.5912 - val_accuracy: 0.6502\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 1s 426us/step - loss: 0.5234 - accuracy: 0.7379 - val_loss: 0.5839 - val_accuracy: 0.6570\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 1s 401us/step - loss: 0.5231 - accuracy: 0.7392 - val_loss: 0.5900 - val_accuracy: 0.6511\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 1s 421us/step - loss: 0.5225 - accuracy: 0.7400 - val_loss: 0.5893 - val_accuracy: 0.6528\n",
      "\n",
      "Training model with batch_size=32...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6979 - accuracy: 0.5345 - val_loss: 0.7243 - val_accuracy: 0.3543\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6897 - accuracy: 0.5531 - val_loss: 0.7195 - val_accuracy: 0.4034\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6848 - accuracy: 0.5619 - val_loss: 0.7164 - val_accuracy: 0.4393\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6801 - accuracy: 0.5746 - val_loss: 0.7100 - val_accuracy: 0.4803\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6738 - accuracy: 0.5910 - val_loss: 0.7066 - val_accuracy: 0.5050\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6703 - accuracy: 0.5974 - val_loss: 0.6985 - val_accuracy: 0.5364\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6668 - accuracy: 0.6041 - val_loss: 0.6928 - val_accuracy: 0.5525\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6623 - accuracy: 0.6130 - val_loss: 0.6910 - val_accuracy: 0.5588\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6588 - accuracy: 0.6200 - val_loss: 0.6888 - val_accuracy: 0.5651\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.6559 - accuracy: 0.6269 - val_loss: 0.6845 - val_accuracy: 0.5744\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6520 - accuracy: 0.6333 - val_loss: 0.6846 - val_accuracy: 0.5747\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6492 - accuracy: 0.6395 - val_loss: 0.6781 - val_accuracy: 0.5881\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6453 - accuracy: 0.6468 - val_loss: 0.6769 - val_accuracy: 0.5921\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6424 - accuracy: 0.6465 - val_loss: 0.6759 - val_accuracy: 0.5942\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6398 - accuracy: 0.6536 - val_loss: 0.6661 - val_accuracy: 0.6098\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6378 - accuracy: 0.6561 - val_loss: 0.6724 - val_accuracy: 0.5997\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6348 - accuracy: 0.6593 - val_loss: 0.6737 - val_accuracy: 0.5969\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6335 - accuracy: 0.6613 - val_loss: 0.6690 - val_accuracy: 0.6052\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6310 - accuracy: 0.6646 - val_loss: 0.6640 - val_accuracy: 0.6134\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6291 - accuracy: 0.6682 - val_loss: 0.6639 - val_accuracy: 0.6126\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6257 - accuracy: 0.6707 - val_loss: 0.6566 - val_accuracy: 0.6247\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6236 - accuracy: 0.6731 - val_loss: 0.6536 - val_accuracy: 0.6274\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6222 - accuracy: 0.6721 - val_loss: 0.6560 - val_accuracy: 0.6242\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6194 - accuracy: 0.6782 - val_loss: 0.6549 - val_accuracy: 0.6240\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6169 - accuracy: 0.6805 - val_loss: 0.6500 - val_accuracy: 0.6302\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6148 - accuracy: 0.6814 - val_loss: 0.6467 - val_accuracy: 0.6315\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6132 - accuracy: 0.6848 - val_loss: 0.6420 - val_accuracy: 0.6334\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6107 - accuracy: 0.6861 - val_loss: 0.6435 - val_accuracy: 0.6308\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6090 - accuracy: 0.6865 - val_loss: 0.6409 - val_accuracy: 0.6321\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6064 - accuracy: 0.6905 - val_loss: 0.6444 - val_accuracy: 0.6262\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6054 - accuracy: 0.6879 - val_loss: 0.6436 - val_accuracy: 0.6253\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6036 - accuracy: 0.6914 - val_loss: 0.6381 - val_accuracy: 0.6318\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6017 - accuracy: 0.6929 - val_loss: 0.6353 - val_accuracy: 0.6331\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5990 - accuracy: 0.6933 - val_loss: 0.6360 - val_accuracy: 0.6318\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5979 - accuracy: 0.6942 - val_loss: 0.6375 - val_accuracy: 0.6294\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5959 - accuracy: 0.6954 - val_loss: 0.6368 - val_accuracy: 0.6295\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.5942 - accuracy: 0.6983 - val_loss: 0.6385 - val_accuracy: 0.6277\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5919 - accuracy: 0.7002 - val_loss: 0.6329 - val_accuracy: 0.6311\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5912 - accuracy: 0.6999 - val_loss: 0.6338 - val_accuracy: 0.6291\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5904 - accuracy: 0.6985 - val_loss: 0.6224 - val_accuracy: 0.6366\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5876 - accuracy: 0.7011 - val_loss: 0.6286 - val_accuracy: 0.6311\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5869 - accuracy: 0.7027 - val_loss: 0.6295 - val_accuracy: 0.6300\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5855 - accuracy: 0.7052 - val_loss: 0.6288 - val_accuracy: 0.6309\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5835 - accuracy: 0.7042 - val_loss: 0.6229 - val_accuracy: 0.6333\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5822 - accuracy: 0.7041 - val_loss: 0.6308 - val_accuracy: 0.6278\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5801 - accuracy: 0.7060 - val_loss: 0.6205 - val_accuracy: 0.6350\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.5788 - accuracy: 0.7073 - val_loss: 0.6246 - val_accuracy: 0.6300\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5776 - accuracy: 0.7081 - val_loss: 0.6210 - val_accuracy: 0.6336\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5754 - accuracy: 0.7092 - val_loss: 0.6224 - val_accuracy: 0.6323\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5742 - accuracy: 0.7116 - val_loss: 0.6181 - val_accuracy: 0.6381\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.7219 - accuracy: 0.5218 - val_loss: 0.7237 - val_accuracy: 0.4325\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6856 - accuracy: 0.5434 - val_loss: 0.6992 - val_accuracy: 0.5268\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6800 - accuracy: 0.5534 - val_loss: 0.6926 - val_accuracy: 0.5602\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6747 - accuracy: 0.5633 - val_loss: 0.6954 - val_accuracy: 0.5485\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6693 - accuracy: 0.5721 - val_loss: 0.6859 - val_accuracy: 0.5822\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6669 - accuracy: 0.5766 - val_loss: 0.6788 - val_accuracy: 0.5995\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6617 - accuracy: 0.5864 - val_loss: 0.6766 - val_accuracy: 0.5994\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6571 - accuracy: 0.5941 - val_loss: 0.6749 - val_accuracy: 0.6010\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6529 - accuracy: 0.6014 - val_loss: 0.6707 - val_accuracy: 0.6052\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6483 - accuracy: 0.6123 - val_loss: 0.6709 - val_accuracy: 0.5997\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6449 - accuracy: 0.6157 - val_loss: 0.6658 - val_accuracy: 0.6085\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6418 - accuracy: 0.6203 - val_loss: 0.6643 - val_accuracy: 0.6059\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6401 - accuracy: 0.6193 - val_loss: 0.6577 - val_accuracy: 0.6192\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6371 - accuracy: 0.6260 - val_loss: 0.6543 - val_accuracy: 0.6225\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6343 - accuracy: 0.6304 - val_loss: 0.6528 - val_accuracy: 0.6231\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6313 - accuracy: 0.6321 - val_loss: 0.6542 - val_accuracy: 0.6153\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6293 - accuracy: 0.6350 - val_loss: 0.6495 - val_accuracy: 0.6227\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6272 - accuracy: 0.6376 - val_loss: 0.6535 - val_accuracy: 0.6104\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6233 - accuracy: 0.6420 - val_loss: 0.6498 - val_accuracy: 0.6153\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6212 - accuracy: 0.6432 - val_loss: 0.6382 - val_accuracy: 0.6370\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6194 - accuracy: 0.6470 - val_loss: 0.6380 - val_accuracy: 0.6347\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6162 - accuracy: 0.6505 - val_loss: 0.6372 - val_accuracy: 0.6342\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6148 - accuracy: 0.6537 - val_loss: 0.6358 - val_accuracy: 0.6343\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6121 - accuracy: 0.6556 - val_loss: 0.6390 - val_accuracy: 0.6269\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6111 - accuracy: 0.6594 - val_loss: 0.6318 - val_accuracy: 0.6377\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6093 - accuracy: 0.6600 - val_loss: 0.6316 - val_accuracy: 0.6375\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6065 - accuracy: 0.6620 - val_loss: 0.6354 - val_accuracy: 0.6299\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6060 - accuracy: 0.6654 - val_loss: 0.6281 - val_accuracy: 0.6402\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6032 - accuracy: 0.6656 - val_loss: 0.6282 - val_accuracy: 0.6393\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6021 - accuracy: 0.6665 - val_loss: 0.6257 - val_accuracy: 0.6407\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.5992 - accuracy: 0.6713 - val_loss: 0.6251 - val_accuracy: 0.6397\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5987 - accuracy: 0.6728 - val_loss: 0.6261 - val_accuracy: 0.6375\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5961 - accuracy: 0.6757 - val_loss: 0.6201 - val_accuracy: 0.6434\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5946 - accuracy: 0.6774 - val_loss: 0.6189 - val_accuracy: 0.6426\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5923 - accuracy: 0.6821 - val_loss: 0.6198 - val_accuracy: 0.6413\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5906 - accuracy: 0.6824 - val_loss: 0.6217 - val_accuracy: 0.6383\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5893 - accuracy: 0.6840 - val_loss: 0.6240 - val_accuracy: 0.6351\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5890 - accuracy: 0.6844 - val_loss: 0.6202 - val_accuracy: 0.6393\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5871 - accuracy: 0.6868 - val_loss: 0.6173 - val_accuracy: 0.6422\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5849 - accuracy: 0.6904 - val_loss: 0.6149 - val_accuracy: 0.6444\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5834 - accuracy: 0.6913 - val_loss: 0.6155 - val_accuracy: 0.6417\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5821 - accuracy: 0.6927 - val_loss: 0.6154 - val_accuracy: 0.6415\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5807 - accuracy: 0.6951 - val_loss: 0.6147 - val_accuracy: 0.6412\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5794 - accuracy: 0.6956 - val_loss: 0.6098 - val_accuracy: 0.6451\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5788 - accuracy: 0.6972 - val_loss: 0.6141 - val_accuracy: 0.6401\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5764 - accuracy: 0.7004 - val_loss: 0.6138 - val_accuracy: 0.6405\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5758 - accuracy: 0.6991 - val_loss: 0.6140 - val_accuracy: 0.6397\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5739 - accuracy: 0.7040 - val_loss: 0.6142 - val_accuracy: 0.6392\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5718 - accuracy: 0.7052 - val_loss: 0.6221 - val_accuracy: 0.6320\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5718 - accuracy: 0.7058 - val_loss: 0.6099 - val_accuracy: 0.6414\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.7015 - accuracy: 0.5325 - val_loss: 0.7609 - val_accuracy: 0.2303\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6872 - accuracy: 0.5481 - val_loss: 0.7163 - val_accuracy: 0.4015\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6823 - accuracy: 0.5639 - val_loss: 0.7034 - val_accuracy: 0.4711\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6790 - accuracy: 0.5745 - val_loss: 0.6997 - val_accuracy: 0.4882\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6756 - accuracy: 0.5852 - val_loss: 0.6988 - val_accuracy: 0.4926\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6738 - accuracy: 0.5886 - val_loss: 0.6980 - val_accuracy: 0.4953\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6701 - accuracy: 0.5997 - val_loss: 0.6970 - val_accuracy: 0.4971\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6682 - accuracy: 0.6070 - val_loss: 0.6937 - val_accuracy: 0.5054\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6655 - accuracy: 0.6112 - val_loss: 0.6914 - val_accuracy: 0.5095\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6628 - accuracy: 0.6227 - val_loss: 0.6888 - val_accuracy: 0.5132\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6609 - accuracy: 0.6238 - val_loss: 0.6905 - val_accuracy: 0.5088\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6590 - accuracy: 0.6274 - val_loss: 0.6871 - val_accuracy: 0.5174\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6560 - accuracy: 0.6339 - val_loss: 0.6854 - val_accuracy: 0.5247\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6548 - accuracy: 0.6342 - val_loss: 0.6847 - val_accuracy: 0.5277\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6509 - accuracy: 0.6419 - val_loss: 0.6823 - val_accuracy: 0.5350\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6505 - accuracy: 0.6425 - val_loss: 0.6798 - val_accuracy: 0.5399\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6475 - accuracy: 0.6465 - val_loss: 0.6788 - val_accuracy: 0.5415\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6456 - accuracy: 0.6477 - val_loss: 0.6750 - val_accuracy: 0.5530\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6432 - accuracy: 0.6525 - val_loss: 0.6746 - val_accuracy: 0.5534\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6405 - accuracy: 0.6555 - val_loss: 0.6721 - val_accuracy: 0.5586\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6390 - accuracy: 0.6553 - val_loss: 0.6693 - val_accuracy: 0.5651\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6372 - accuracy: 0.6568 - val_loss: 0.6680 - val_accuracy: 0.5675\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6344 - accuracy: 0.6602 - val_loss: 0.6669 - val_accuracy: 0.5692\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6325 - accuracy: 0.6640 - val_loss: 0.6653 - val_accuracy: 0.5727\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6304 - accuracy: 0.6629 - val_loss: 0.6609 - val_accuracy: 0.5797\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6278 - accuracy: 0.6654 - val_loss: 0.6585 - val_accuracy: 0.5849\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6260 - accuracy: 0.6660 - val_loss: 0.6576 - val_accuracy: 0.5860\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6236 - accuracy: 0.6694 - val_loss: 0.6533 - val_accuracy: 0.5937\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6219 - accuracy: 0.6712 - val_loss: 0.6538 - val_accuracy: 0.5911\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6192 - accuracy: 0.6723 - val_loss: 0.6493 - val_accuracy: 0.5992\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6172 - accuracy: 0.6739 - val_loss: 0.6490 - val_accuracy: 0.5981\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6149 - accuracy: 0.6756 - val_loss: 0.6464 - val_accuracy: 0.6018\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6125 - accuracy: 0.6777 - val_loss: 0.6440 - val_accuracy: 0.6031\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6111 - accuracy: 0.6756 - val_loss: 0.6454 - val_accuracy: 0.6005\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6088 - accuracy: 0.6790 - val_loss: 0.6450 - val_accuracy: 0.6006\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6073 - accuracy: 0.6780 - val_loss: 0.6418 - val_accuracy: 0.6052\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6054 - accuracy: 0.6817 - val_loss: 0.6373 - val_accuracy: 0.6096\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6027 - accuracy: 0.6843 - val_loss: 0.6364 - val_accuracy: 0.6106\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6012 - accuracy: 0.6850 - val_loss: 0.6343 - val_accuracy: 0.6124\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6000 - accuracy: 0.6852 - val_loss: 0.6330 - val_accuracy: 0.6141\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.5973 - accuracy: 0.6870 - val_loss: 0.6319 - val_accuracy: 0.6152\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5955 - accuracy: 0.6897 - val_loss: 0.6334 - val_accuracy: 0.6133\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.5936 - accuracy: 0.6890 - val_loss: 0.6266 - val_accuracy: 0.6246\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5923 - accuracy: 0.6900 - val_loss: 0.6264 - val_accuracy: 0.6235\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5901 - accuracy: 0.6942 - val_loss: 0.6279 - val_accuracy: 0.6207\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5888 - accuracy: 0.6930 - val_loss: 0.6219 - val_accuracy: 0.6290\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.5866 - accuracy: 0.6931 - val_loss: 0.6212 - val_accuracy: 0.6289\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5857 - accuracy: 0.6939 - val_loss: 0.6281 - val_accuracy: 0.6201\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.5837 - accuracy: 0.6967 - val_loss: 0.6172 - val_accuracy: 0.6326\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5819 - accuracy: 0.6995 - val_loss: 0.6200 - val_accuracy: 0.6277\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.7280 - accuracy: 0.4932 - val_loss: 0.7253 - val_accuracy: 0.3682\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.7106 - accuracy: 0.5105 - val_loss: 0.7038 - val_accuracy: 0.4759\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6982 - accuracy: 0.5279 - val_loss: 0.6975 - val_accuracy: 0.4720\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6875 - accuracy: 0.5468 - val_loss: 0.6854 - val_accuracy: 0.5662\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6786 - accuracy: 0.5668 - val_loss: 0.6804 - val_accuracy: 0.5758\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6717 - accuracy: 0.5823 - val_loss: 0.6727 - val_accuracy: 0.5984\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6652 - accuracy: 0.5977 - val_loss: 0.6700 - val_accuracy: 0.6013\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6596 - accuracy: 0.6068 - val_loss: 0.6616 - val_accuracy: 0.6219\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6549 - accuracy: 0.6124 - val_loss: 0.6623 - val_accuracy: 0.6102\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6495 - accuracy: 0.6256 - val_loss: 0.6579 - val_accuracy: 0.6165\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6445 - accuracy: 0.6337 - val_loss: 0.6523 - val_accuracy: 0.6260\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6398 - accuracy: 0.6436 - val_loss: 0.6481 - val_accuracy: 0.6311\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6352 - accuracy: 0.6462 - val_loss: 0.6432 - val_accuracy: 0.6389\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6316 - accuracy: 0.6534 - val_loss: 0.6437 - val_accuracy: 0.6326\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6277 - accuracy: 0.6591 - val_loss: 0.6414 - val_accuracy: 0.6347\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6250 - accuracy: 0.6604 - val_loss: 0.6361 - val_accuracy: 0.6418\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6211 - accuracy: 0.6659 - val_loss: 0.6332 - val_accuracy: 0.6437\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6174 - accuracy: 0.6684 - val_loss: 0.6302 - val_accuracy: 0.6460\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6149 - accuracy: 0.6737 - val_loss: 0.6303 - val_accuracy: 0.6430\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6123 - accuracy: 0.6725 - val_loss: 0.6233 - val_accuracy: 0.6509\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6094 - accuracy: 0.6763 - val_loss: 0.6233 - val_accuracy: 0.6487\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6074 - accuracy: 0.6790 - val_loss: 0.6161 - val_accuracy: 0.6549\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6049 - accuracy: 0.6811 - val_loss: 0.6196 - val_accuracy: 0.6483\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6032 - accuracy: 0.6812 - val_loss: 0.6169 - val_accuracy: 0.6495\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6003 - accuracy: 0.6856 - val_loss: 0.6188 - val_accuracy: 0.6457\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5990 - accuracy: 0.6861 - val_loss: 0.6157 - val_accuracy: 0.6472\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5969 - accuracy: 0.6876 - val_loss: 0.6131 - val_accuracy: 0.6482\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5940 - accuracy: 0.6914 - val_loss: 0.6129 - val_accuracy: 0.6480\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5931 - accuracy: 0.6926 - val_loss: 0.6118 - val_accuracy: 0.6480\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5915 - accuracy: 0.6933 - val_loss: 0.6116 - val_accuracy: 0.6471\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5903 - accuracy: 0.6932 - val_loss: 0.6157 - val_accuracy: 0.6414\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5888 - accuracy: 0.6976 - val_loss: 0.6103 - val_accuracy: 0.6477\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5855 - accuracy: 0.6991 - val_loss: 0.6113 - val_accuracy: 0.6455\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5850 - accuracy: 0.7011 - val_loss: 0.6083 - val_accuracy: 0.6488\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5830 - accuracy: 0.7038 - val_loss: 0.6004 - val_accuracy: 0.6560\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.5822 - accuracy: 0.7029 - val_loss: 0.6128 - val_accuracy: 0.6437\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5799 - accuracy: 0.7042 - val_loss: 0.6029 - val_accuracy: 0.6537\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5790 - accuracy: 0.7065 - val_loss: 0.6094 - val_accuracy: 0.6464\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5771 - accuracy: 0.7076 - val_loss: 0.6012 - val_accuracy: 0.6551\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5761 - accuracy: 0.7091 - val_loss: 0.6102 - val_accuracy: 0.6461\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5735 - accuracy: 0.7096 - val_loss: 0.5956 - val_accuracy: 0.6603\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5729 - accuracy: 0.7099 - val_loss: 0.6022 - val_accuracy: 0.6535\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5720 - accuracy: 0.7125 - val_loss: 0.6000 - val_accuracy: 0.6554\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.5691 - accuracy: 0.7130 - val_loss: 0.6005 - val_accuracy: 0.6547\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5687 - accuracy: 0.7155 - val_loss: 0.5956 - val_accuracy: 0.6597\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5673 - accuracy: 0.7151 - val_loss: 0.6061 - val_accuracy: 0.6487\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5669 - accuracy: 0.7137 - val_loss: 0.5978 - val_accuracy: 0.6580\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5652 - accuracy: 0.7155 - val_loss: 0.5974 - val_accuracy: 0.6581\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.5633 - accuracy: 0.7171 - val_loss: 0.5981 - val_accuracy: 0.6590\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.5627 - accuracy: 0.7171 - val_loss: 0.6005 - val_accuracy: 0.6579\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.7256 - accuracy: 0.4793 - val_loss: 0.6935 - val_accuracy: 0.5030\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.7049 - accuracy: 0.5072 - val_loss: 0.7214 - val_accuracy: 0.3603\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 420us/step - loss: 0.6969 - accuracy: 0.5296 - val_loss: 0.7210 - val_accuracy: 0.3726\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6906 - accuracy: 0.5497 - val_loss: 0.7157 - val_accuracy: 0.4061\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6871 - accuracy: 0.5595 - val_loss: 0.7091 - val_accuracy: 0.4594\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6837 - accuracy: 0.5701 - val_loss: 0.7048 - val_accuracy: 0.4893\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6812 - accuracy: 0.5783 - val_loss: 0.7022 - val_accuracy: 0.5049\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6781 - accuracy: 0.5886 - val_loss: 0.7004 - val_accuracy: 0.5130\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6766 - accuracy: 0.5932 - val_loss: 0.6985 - val_accuracy: 0.5202\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 414us/step - loss: 0.6738 - accuracy: 0.6020 - val_loss: 0.6980 - val_accuracy: 0.5204\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6714 - accuracy: 0.6106 - val_loss: 0.6942 - val_accuracy: 0.5299\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6692 - accuracy: 0.6152 - val_loss: 0.6905 - val_accuracy: 0.5394\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.6672 - accuracy: 0.6214 - val_loss: 0.6907 - val_accuracy: 0.5375\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6647 - accuracy: 0.6268 - val_loss: 0.6868 - val_accuracy: 0.5484\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6627 - accuracy: 0.6323 - val_loss: 0.6855 - val_accuracy: 0.5511\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6599 - accuracy: 0.6400 - val_loss: 0.6825 - val_accuracy: 0.5624\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.6575 - accuracy: 0.6449 - val_loss: 0.6801 - val_accuracy: 0.5704\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6550 - accuracy: 0.6478 - val_loss: 0.6785 - val_accuracy: 0.5741\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6529 - accuracy: 0.6502 - val_loss: 0.6762 - val_accuracy: 0.5810\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 420us/step - loss: 0.6520 - accuracy: 0.6535 - val_loss: 0.6737 - val_accuracy: 0.5880\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6486 - accuracy: 0.6587 - val_loss: 0.6730 - val_accuracy: 0.5892\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6473 - accuracy: 0.6610 - val_loss: 0.6710 - val_accuracy: 0.5941\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.6448 - accuracy: 0.6650 - val_loss: 0.6675 - val_accuracy: 0.6030\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.6425 - accuracy: 0.6682 - val_loss: 0.6627 - val_accuracy: 0.6137\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6400 - accuracy: 0.6723 - val_loss: 0.6617 - val_accuracy: 0.6136\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6378 - accuracy: 0.6737 - val_loss: 0.6624 - val_accuracy: 0.6113\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6362 - accuracy: 0.6732 - val_loss: 0.6600 - val_accuracy: 0.6136\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6342 - accuracy: 0.6780 - val_loss: 0.6557 - val_accuracy: 0.6197\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6314 - accuracy: 0.6790 - val_loss: 0.6531 - val_accuracy: 0.6215\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6294 - accuracy: 0.6824 - val_loss: 0.6505 - val_accuracy: 0.6235\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.6274 - accuracy: 0.6837 - val_loss: 0.6519 - val_accuracy: 0.6207\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6253 - accuracy: 0.6856 - val_loss: 0.6484 - val_accuracy: 0.6245\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 421us/step - loss: 0.6237 - accuracy: 0.6860 - val_loss: 0.6474 - val_accuracy: 0.6257\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6212 - accuracy: 0.6870 - val_loss: 0.6424 - val_accuracy: 0.6305\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6194 - accuracy: 0.6900 - val_loss: 0.6431 - val_accuracy: 0.6287\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6171 - accuracy: 0.6918 - val_loss: 0.6399 - val_accuracy: 0.6324\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6163 - accuracy: 0.6916 - val_loss: 0.6365 - val_accuracy: 0.6375\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6136 - accuracy: 0.6941 - val_loss: 0.6346 - val_accuracy: 0.6393\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6114 - accuracy: 0.6939 - val_loss: 0.6357 - val_accuracy: 0.6363\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6098 - accuracy: 0.6976 - val_loss: 0.6319 - val_accuracy: 0.6424\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6084 - accuracy: 0.6969 - val_loss: 0.6346 - val_accuracy: 0.6373\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6076 - accuracy: 0.6979 - val_loss: 0.6334 - val_accuracy: 0.6378\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6047 - accuracy: 0.6988 - val_loss: 0.6279 - val_accuracy: 0.6436\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6032 - accuracy: 0.7014 - val_loss: 0.6315 - val_accuracy: 0.6393\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6029 - accuracy: 0.6999 - val_loss: 0.6270 - val_accuracy: 0.6422\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.6011 - accuracy: 0.7016 - val_loss: 0.6282 - val_accuracy: 0.6405\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5985 - accuracy: 0.7015 - val_loss: 0.6291 - val_accuracy: 0.6395\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5980 - accuracy: 0.7019 - val_loss: 0.6305 - val_accuracy: 0.6377\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.5963 - accuracy: 0.7043 - val_loss: 0.6236 - val_accuracy: 0.6431\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.5950 - accuracy: 0.7047 - val_loss: 0.6211 - val_accuracy: 0.6465\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.7428 - accuracy: 0.5153 - val_loss: 0.7846 - val_accuracy: 0.1916\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6999 - accuracy: 0.5200 - val_loss: 0.7316 - val_accuracy: 0.3417\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6923 - accuracy: 0.5342 - val_loss: 0.7178 - val_accuracy: 0.4319\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6860 - accuracy: 0.5503 - val_loss: 0.7071 - val_accuracy: 0.4915\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6783 - accuracy: 0.5689 - val_loss: 0.7027 - val_accuracy: 0.5201\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6734 - accuracy: 0.5823 - val_loss: 0.6908 - val_accuracy: 0.5718\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6673 - accuracy: 0.5981 - val_loss: 0.6862 - val_accuracy: 0.5853\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6643 - accuracy: 0.6042 - val_loss: 0.6837 - val_accuracy: 0.5916\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.6605 - accuracy: 0.6114 - val_loss: 0.6822 - val_accuracy: 0.5952\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6577 - accuracy: 0.6154 - val_loss: 0.6790 - val_accuracy: 0.6008\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6545 - accuracy: 0.6231 - val_loss: 0.6747 - val_accuracy: 0.6095\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6513 - accuracy: 0.6290 - val_loss: 0.6724 - val_accuracy: 0.6142\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6487 - accuracy: 0.6317 - val_loss: 0.6713 - val_accuracy: 0.6168\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6459 - accuracy: 0.6361 - val_loss: 0.6679 - val_accuracy: 0.6230\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6436 - accuracy: 0.6400 - val_loss: 0.6641 - val_accuracy: 0.6283\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6407 - accuracy: 0.6454 - val_loss: 0.6662 - val_accuracy: 0.6237\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6392 - accuracy: 0.6474 - val_loss: 0.6632 - val_accuracy: 0.6273\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6357 - accuracy: 0.6497 - val_loss: 0.6534 - val_accuracy: 0.6416\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6341 - accuracy: 0.6514 - val_loss: 0.6579 - val_accuracy: 0.6332\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6318 - accuracy: 0.6550 - val_loss: 0.6531 - val_accuracy: 0.6375\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6305 - accuracy: 0.6563 - val_loss: 0.6546 - val_accuracy: 0.6355\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6287 - accuracy: 0.6571 - val_loss: 0.6527 - val_accuracy: 0.6366\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6255 - accuracy: 0.6601 - val_loss: 0.6478 - val_accuracy: 0.6416\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6231 - accuracy: 0.6620 - val_loss: 0.6467 - val_accuracy: 0.6419\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6214 - accuracy: 0.6648 - val_loss: 0.6447 - val_accuracy: 0.6435\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6209 - accuracy: 0.6647 - val_loss: 0.6502 - val_accuracy: 0.6342\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6193 - accuracy: 0.6661 - val_loss: 0.6400 - val_accuracy: 0.6458\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6167 - accuracy: 0.6688 - val_loss: 0.6414 - val_accuracy: 0.6434\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6147 - accuracy: 0.6697 - val_loss: 0.6454 - val_accuracy: 0.6387\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6129 - accuracy: 0.6715 - val_loss: 0.6392 - val_accuracy: 0.6433\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6116 - accuracy: 0.6713 - val_loss: 0.6352 - val_accuracy: 0.6471\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6106 - accuracy: 0.6727 - val_loss: 0.6367 - val_accuracy: 0.6436\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6080 - accuracy: 0.6738 - val_loss: 0.6335 - val_accuracy: 0.6469\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6055 - accuracy: 0.6788 - val_loss: 0.6352 - val_accuracy: 0.6434\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6057 - accuracy: 0.6782 - val_loss: 0.6343 - val_accuracy: 0.6448\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6041 - accuracy: 0.6785 - val_loss: 0.6317 - val_accuracy: 0.6467\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6021 - accuracy: 0.6808 - val_loss: 0.6306 - val_accuracy: 0.6482\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6004 - accuracy: 0.6810 - val_loss: 0.6319 - val_accuracy: 0.6474\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5991 - accuracy: 0.6817 - val_loss: 0.6303 - val_accuracy: 0.6476\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5981 - accuracy: 0.6832 - val_loss: 0.6257 - val_accuracy: 0.6507\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5971 - accuracy: 0.6830 - val_loss: 0.6257 - val_accuracy: 0.6500\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.5944 - accuracy: 0.6857 - val_loss: 0.6295 - val_accuracy: 0.6462\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5940 - accuracy: 0.6877 - val_loss: 0.6231 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5912 - accuracy: 0.6898 - val_loss: 0.6258 - val_accuracy: 0.6487\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5920 - accuracy: 0.6878 - val_loss: 0.6231 - val_accuracy: 0.6501\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5901 - accuracy: 0.6883 - val_loss: 0.6268 - val_accuracy: 0.6476\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.5889 - accuracy: 0.6914 - val_loss: 0.6239 - val_accuracy: 0.6495\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5876 - accuracy: 0.6923 - val_loss: 0.6225 - val_accuracy: 0.6518\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5865 - accuracy: 0.6929 - val_loss: 0.6200 - val_accuracy: 0.6517\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5845 - accuracy: 0.6955 - val_loss: 0.6194 - val_accuracy: 0.6519\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.7147 - accuracy: 0.5015 - val_loss: 0.6905 - val_accuracy: 0.5466\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.7048 - accuracy: 0.5186 - val_loss: 0.6930 - val_accuracy: 0.5446\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6959 - accuracy: 0.5361 - val_loss: 0.6895 - val_accuracy: 0.5672\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6928 - accuracy: 0.5383 - val_loss: 0.6849 - val_accuracy: 0.5906\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6879 - accuracy: 0.5495 - val_loss: 0.6841 - val_accuracy: 0.5918\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6830 - accuracy: 0.5588 - val_loss: 0.6786 - val_accuracy: 0.6089\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6787 - accuracy: 0.5691 - val_loss: 0.6726 - val_accuracy: 0.6237\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6740 - accuracy: 0.5790 - val_loss: 0.6721 - val_accuracy: 0.6169\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6695 - accuracy: 0.5863 - val_loss: 0.6689 - val_accuracy: 0.6209\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6657 - accuracy: 0.5970 - val_loss: 0.6664 - val_accuracy: 0.6211\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6642 - accuracy: 0.5998 - val_loss: 0.6613 - val_accuracy: 0.6312\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6580 - accuracy: 0.6135 - val_loss: 0.6638 - val_accuracy: 0.6172\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6571 - accuracy: 0.6141 - val_loss: 0.6555 - val_accuracy: 0.6359\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6519 - accuracy: 0.6231 - val_loss: 0.6547 - val_accuracy: 0.6314\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6489 - accuracy: 0.6288 - val_loss: 0.6548 - val_accuracy: 0.6272\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6471 - accuracy: 0.6303 - val_loss: 0.6484 - val_accuracy: 0.6376\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6438 - accuracy: 0.6349 - val_loss: 0.6470 - val_accuracy: 0.6367\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6411 - accuracy: 0.6417 - val_loss: 0.6432 - val_accuracy: 0.6420\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6366 - accuracy: 0.6481 - val_loss: 0.6395 - val_accuracy: 0.6460\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6350 - accuracy: 0.6484 - val_loss: 0.6412 - val_accuracy: 0.6372\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6326 - accuracy: 0.6508 - val_loss: 0.6378 - val_accuracy: 0.6396\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6292 - accuracy: 0.6562 - val_loss: 0.6367 - val_accuracy: 0.6373\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6258 - accuracy: 0.6602 - val_loss: 0.6344 - val_accuracy: 0.6381\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6241 - accuracy: 0.6615 - val_loss: 0.6349 - val_accuracy: 0.6352\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6214 - accuracy: 0.6641 - val_loss: 0.6294 - val_accuracy: 0.6430\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6184 - accuracy: 0.6694 - val_loss: 0.6305 - val_accuracy: 0.6391\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6167 - accuracy: 0.6689 - val_loss: 0.6260 - val_accuracy: 0.6453\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6131 - accuracy: 0.6725 - val_loss: 0.6214 - val_accuracy: 0.6528\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6118 - accuracy: 0.6730 - val_loss: 0.6194 - val_accuracy: 0.6544\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6091 - accuracy: 0.6768 - val_loss: 0.6190 - val_accuracy: 0.6539\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6063 - accuracy: 0.6778 - val_loss: 0.6170 - val_accuracy: 0.6540\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6050 - accuracy: 0.6790 - val_loss: 0.6141 - val_accuracy: 0.6564\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6019 - accuracy: 0.6844 - val_loss: 0.6147 - val_accuracy: 0.6531\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6005 - accuracy: 0.6845 - val_loss: 0.6193 - val_accuracy: 0.6436\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5986 - accuracy: 0.6853 - val_loss: 0.6150 - val_accuracy: 0.6498\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.5972 - accuracy: 0.6875 - val_loss: 0.6145 - val_accuracy: 0.6489\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5956 - accuracy: 0.6883 - val_loss: 0.6061 - val_accuracy: 0.6563\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5945 - accuracy: 0.6904 - val_loss: 0.6127 - val_accuracy: 0.6469\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5924 - accuracy: 0.6908 - val_loss: 0.6090 - val_accuracy: 0.6489\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5905 - accuracy: 0.6938 - val_loss: 0.6056 - val_accuracy: 0.6525\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5895 - accuracy: 0.6932 - val_loss: 0.6134 - val_accuracy: 0.6406\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5884 - accuracy: 0.6971 - val_loss: 0.6080 - val_accuracy: 0.6443\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5861 - accuracy: 0.6979 - val_loss: 0.6089 - val_accuracy: 0.6426\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5837 - accuracy: 0.7019 - val_loss: 0.6118 - val_accuracy: 0.6394\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5835 - accuracy: 0.7005 - val_loss: 0.6118 - val_accuracy: 0.6387\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5822 - accuracy: 0.7005 - val_loss: 0.6037 - val_accuracy: 0.6509\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5809 - accuracy: 0.7049 - val_loss: 0.6044 - val_accuracy: 0.6495\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5798 - accuracy: 0.7032 - val_loss: 0.6020 - val_accuracy: 0.6537\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.5766 - accuracy: 0.7074 - val_loss: 0.6012 - val_accuracy: 0.6542\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.5752 - accuracy: 0.7079 - val_loss: 0.6081 - val_accuracy: 0.6453\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.7219 - accuracy: 0.4826 - val_loss: 0.7247 - val_accuracy: 0.3522\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.7109 - accuracy: 0.5047 - val_loss: 0.7180 - val_accuracy: 0.3968\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.7016 - accuracy: 0.5219 - val_loss: 0.7070 - val_accuracy: 0.4554\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6954 - accuracy: 0.5347 - val_loss: 0.7050 - val_accuracy: 0.4806\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6895 - accuracy: 0.5489 - val_loss: 0.6943 - val_accuracy: 0.5247\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6841 - accuracy: 0.5621 - val_loss: 0.6918 - val_accuracy: 0.5389\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6793 - accuracy: 0.5728 - val_loss: 0.6893 - val_accuracy: 0.5511\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6739 - accuracy: 0.5863 - val_loss: 0.6841 - val_accuracy: 0.5661\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6707 - accuracy: 0.5936 - val_loss: 0.6808 - val_accuracy: 0.5728\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6679 - accuracy: 0.6025 - val_loss: 0.6781 - val_accuracy: 0.5771\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6651 - accuracy: 0.6097 - val_loss: 0.6761 - val_accuracy: 0.5812\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6611 - accuracy: 0.6178 - val_loss: 0.6733 - val_accuracy: 0.5863\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6576 - accuracy: 0.6254 - val_loss: 0.6655 - val_accuracy: 0.6056\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6554 - accuracy: 0.6290 - val_loss: 0.6681 - val_accuracy: 0.5967\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6525 - accuracy: 0.6343 - val_loss: 0.6645 - val_accuracy: 0.6054\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6499 - accuracy: 0.6397 - val_loss: 0.6601 - val_accuracy: 0.6107\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6466 - accuracy: 0.6435 - val_loss: 0.6549 - val_accuracy: 0.6153\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6442 - accuracy: 0.6484 - val_loss: 0.6523 - val_accuracy: 0.6174\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6416 - accuracy: 0.6518 - val_loss: 0.6537 - val_accuracy: 0.6153\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6381 - accuracy: 0.6557 - val_loss: 0.6466 - val_accuracy: 0.6250\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6369 - accuracy: 0.6586 - val_loss: 0.6470 - val_accuracy: 0.6244\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6344 - accuracy: 0.6605 - val_loss: 0.6425 - val_accuracy: 0.6282\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6318 - accuracy: 0.6644 - val_loss: 0.6430 - val_accuracy: 0.6276\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6301 - accuracy: 0.6652 - val_loss: 0.6430 - val_accuracy: 0.6273\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6269 - accuracy: 0.6702 - val_loss: 0.6415 - val_accuracy: 0.6282\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6249 - accuracy: 0.6719 - val_loss: 0.6338 - val_accuracy: 0.6383\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6232 - accuracy: 0.6750 - val_loss: 0.6379 - val_accuracy: 0.6290\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6208 - accuracy: 0.6768 - val_loss: 0.6351 - val_accuracy: 0.6313\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6185 - accuracy: 0.6801 - val_loss: 0.6354 - val_accuracy: 0.6282\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6166 - accuracy: 0.6806 - val_loss: 0.6309 - val_accuracy: 0.6340\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6154 - accuracy: 0.6819 - val_loss: 0.6275 - val_accuracy: 0.6371\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.6131 - accuracy: 0.6849 - val_loss: 0.6263 - val_accuracy: 0.6355\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6108 - accuracy: 0.6862 - val_loss: 0.6256 - val_accuracy: 0.6323\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6091 - accuracy: 0.6898 - val_loss: 0.6305 - val_accuracy: 0.6246\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6075 - accuracy: 0.6883 - val_loss: 0.6271 - val_accuracy: 0.6260\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6051 - accuracy: 0.6938 - val_loss: 0.6227 - val_accuracy: 0.6291\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6038 - accuracy: 0.6919 - val_loss: 0.6221 - val_accuracy: 0.6294\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6029 - accuracy: 0.6928 - val_loss: 0.6242 - val_accuracy: 0.6279\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6001 - accuracy: 0.6958 - val_loss: 0.6213 - val_accuracy: 0.6304\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5983 - accuracy: 0.6959 - val_loss: 0.6169 - val_accuracy: 0.6333\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5970 - accuracy: 0.6988 - val_loss: 0.6140 - val_accuracy: 0.6374\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.5954 - accuracy: 0.7001 - val_loss: 0.6187 - val_accuracy: 0.6304\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5934 - accuracy: 0.6992 - val_loss: 0.6166 - val_accuracy: 0.6329\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.5920 - accuracy: 0.7023 - val_loss: 0.6089 - val_accuracy: 0.6399\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5905 - accuracy: 0.7031 - val_loss: 0.6173 - val_accuracy: 0.6305\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5894 - accuracy: 0.7045 - val_loss: 0.6156 - val_accuracy: 0.6324\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5889 - accuracy: 0.7040 - val_loss: 0.6133 - val_accuracy: 0.6342\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5867 - accuracy: 0.7048 - val_loss: 0.6166 - val_accuracy: 0.6304\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5854 - accuracy: 0.7073 - val_loss: 0.6158 - val_accuracy: 0.6309\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.5835 - accuracy: 0.7074 - val_loss: 0.6070 - val_accuracy: 0.6391\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.7053 - accuracy: 0.5041 - val_loss: 0.7106 - val_accuracy: 0.4571\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6967 - accuracy: 0.5253 - val_loss: 0.7015 - val_accuracy: 0.4988\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6873 - accuracy: 0.5456 - val_loss: 0.6907 - val_accuracy: 0.5422\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6813 - accuracy: 0.5641 - val_loss: 0.6905 - val_accuracy: 0.5414\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6754 - accuracy: 0.5757 - val_loss: 0.6897 - val_accuracy: 0.5456\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6714 - accuracy: 0.5862 - val_loss: 0.6815 - val_accuracy: 0.5702\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6656 - accuracy: 0.6024 - val_loss: 0.6789 - val_accuracy: 0.5739\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6628 - accuracy: 0.6081 - val_loss: 0.6727 - val_accuracy: 0.5894\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6588 - accuracy: 0.6161 - val_loss: 0.6686 - val_accuracy: 0.5957\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6561 - accuracy: 0.6184 - val_loss: 0.6763 - val_accuracy: 0.5782\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6529 - accuracy: 0.6261 - val_loss: 0.6714 - val_accuracy: 0.5853\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6495 - accuracy: 0.6333 - val_loss: 0.6632 - val_accuracy: 0.6084\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6472 - accuracy: 0.6363 - val_loss: 0.6593 - val_accuracy: 0.6128\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6439 - accuracy: 0.6428 - val_loss: 0.6572 - val_accuracy: 0.6144\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6420 - accuracy: 0.6444 - val_loss: 0.6532 - val_accuracy: 0.6207\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6390 - accuracy: 0.6489 - val_loss: 0.6545 - val_accuracy: 0.6165\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6369 - accuracy: 0.6525 - val_loss: 0.6568 - val_accuracy: 0.6089\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6343 - accuracy: 0.6565 - val_loss: 0.6490 - val_accuracy: 0.6259\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6317 - accuracy: 0.6579 - val_loss: 0.6488 - val_accuracy: 0.6236\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.6296 - accuracy: 0.6584 - val_loss: 0.6442 - val_accuracy: 0.6311\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6275 - accuracy: 0.6617 - val_loss: 0.6422 - val_accuracy: 0.6335\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6259 - accuracy: 0.6630 - val_loss: 0.6375 - val_accuracy: 0.6422\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6226 - accuracy: 0.6674 - val_loss: 0.6402 - val_accuracy: 0.6378\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6205 - accuracy: 0.6700 - val_loss: 0.6368 - val_accuracy: 0.6418\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6188 - accuracy: 0.6687 - val_loss: 0.6380 - val_accuracy: 0.6371\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6160 - accuracy: 0.6724 - val_loss: 0.6306 - val_accuracy: 0.6457\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6146 - accuracy: 0.6746 - val_loss: 0.6313 - val_accuracy: 0.6433\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6121 - accuracy: 0.6768 - val_loss: 0.6341 - val_accuracy: 0.6387\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6111 - accuracy: 0.6775 - val_loss: 0.6294 - val_accuracy: 0.6431\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6083 - accuracy: 0.6820 - val_loss: 0.6272 - val_accuracy: 0.6444\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6068 - accuracy: 0.6805 - val_loss: 0.6253 - val_accuracy: 0.6460\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6050 - accuracy: 0.6830 - val_loss: 0.6250 - val_accuracy: 0.6433\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6028 - accuracy: 0.6852 - val_loss: 0.6176 - val_accuracy: 0.6501\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6008 - accuracy: 0.6857 - val_loss: 0.6225 - val_accuracy: 0.6419\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5997 - accuracy: 0.6873 - val_loss: 0.6135 - val_accuracy: 0.6503\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5971 - accuracy: 0.6891 - val_loss: 0.6185 - val_accuracy: 0.6431\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5960 - accuracy: 0.6897 - val_loss: 0.6183 - val_accuracy: 0.6406\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.5943 - accuracy: 0.6913 - val_loss: 0.6126 - val_accuracy: 0.6462\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.5934 - accuracy: 0.6928 - val_loss: 0.6149 - val_accuracy: 0.6426\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5916 - accuracy: 0.6938 - val_loss: 0.6154 - val_accuracy: 0.6414\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5893 - accuracy: 0.6967 - val_loss: 0.6067 - val_accuracy: 0.6510\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5876 - accuracy: 0.6979 - val_loss: 0.6099 - val_accuracy: 0.6449\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.5869 - accuracy: 0.6978 - val_loss: 0.6093 - val_accuracy: 0.6455\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5853 - accuracy: 0.6973 - val_loss: 0.6084 - val_accuracy: 0.6457\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5829 - accuracy: 0.7016 - val_loss: 0.6027 - val_accuracy: 0.6534\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5818 - accuracy: 0.7023 - val_loss: 0.6102 - val_accuracy: 0.6409\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5803 - accuracy: 0.7033 - val_loss: 0.6063 - val_accuracy: 0.6466\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5797 - accuracy: 0.7059 - val_loss: 0.6168 - val_accuracy: 0.6308\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5777 - accuracy: 0.7053 - val_loss: 0.6092 - val_accuracy: 0.6412\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5763 - accuracy: 0.7060 - val_loss: 0.6133 - val_accuracy: 0.6339\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.7251 - accuracy: 0.5144 - val_loss: 0.6838 - val_accuracy: 0.5628\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6907 - accuracy: 0.5406 - val_loss: 0.7062 - val_accuracy: 0.4675\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6839 - accuracy: 0.5547 - val_loss: 0.6986 - val_accuracy: 0.5131\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.6771 - accuracy: 0.5697 - val_loss: 0.6992 - val_accuracy: 0.5206\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6718 - accuracy: 0.5810 - val_loss: 0.6938 - val_accuracy: 0.5423\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6674 - accuracy: 0.5886 - val_loss: 0.6861 - val_accuracy: 0.5638\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6629 - accuracy: 0.5984 - val_loss: 0.6843 - val_accuracy: 0.5681\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6585 - accuracy: 0.6063 - val_loss: 0.6766 - val_accuracy: 0.5856\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6553 - accuracy: 0.6131 - val_loss: 0.6769 - val_accuracy: 0.5845\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6520 - accuracy: 0.6169 - val_loss: 0.6742 - val_accuracy: 0.5917\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6497 - accuracy: 0.6226 - val_loss: 0.6710 - val_accuracy: 0.5989\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6459 - accuracy: 0.6298 - val_loss: 0.6682 - val_accuracy: 0.6039\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6429 - accuracy: 0.6340 - val_loss: 0.6675 - val_accuracy: 0.6035\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6397 - accuracy: 0.6385 - val_loss: 0.6627 - val_accuracy: 0.6121\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6375 - accuracy: 0.6395 - val_loss: 0.6593 - val_accuracy: 0.6168\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6358 - accuracy: 0.6417 - val_loss: 0.6559 - val_accuracy: 0.6238\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6325 - accuracy: 0.6461 - val_loss: 0.6574 - val_accuracy: 0.6183\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6297 - accuracy: 0.6484 - val_loss: 0.6594 - val_accuracy: 0.6131\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6283 - accuracy: 0.6526 - val_loss: 0.6519 - val_accuracy: 0.6246\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6254 - accuracy: 0.6556 - val_loss: 0.6532 - val_accuracy: 0.6219\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6236 - accuracy: 0.6562 - val_loss: 0.6469 - val_accuracy: 0.6305\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6208 - accuracy: 0.6600 - val_loss: 0.6508 - val_accuracy: 0.6230\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6189 - accuracy: 0.6607 - val_loss: 0.6465 - val_accuracy: 0.6290\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6166 - accuracy: 0.6659 - val_loss: 0.6457 - val_accuracy: 0.6298\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.6154 - accuracy: 0.6635 - val_loss: 0.6445 - val_accuracy: 0.6315\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6133 - accuracy: 0.6658 - val_loss: 0.6462 - val_accuracy: 0.6277\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6105 - accuracy: 0.6660 - val_loss: 0.6429 - val_accuracy: 0.6332\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6093 - accuracy: 0.6710 - val_loss: 0.6379 - val_accuracy: 0.6403\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6073 - accuracy: 0.6718 - val_loss: 0.6378 - val_accuracy: 0.6389\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6057 - accuracy: 0.6750 - val_loss: 0.6394 - val_accuracy: 0.6352\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6043 - accuracy: 0.6748 - val_loss: 0.6349 - val_accuracy: 0.6415\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6032 - accuracy: 0.6774 - val_loss: 0.6320 - val_accuracy: 0.6453\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5996 - accuracy: 0.6808 - val_loss: 0.6355 - val_accuracy: 0.6380\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5993 - accuracy: 0.6804 - val_loss: 0.6308 - val_accuracy: 0.6444\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5988 - accuracy: 0.6804 - val_loss: 0.6347 - val_accuracy: 0.6377\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5959 - accuracy: 0.6835 - val_loss: 0.6314 - val_accuracy: 0.6412\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5940 - accuracy: 0.6839 - val_loss: 0.6285 - val_accuracy: 0.6441\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5918 - accuracy: 0.6884 - val_loss: 0.6246 - val_accuracy: 0.6501\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5899 - accuracy: 0.6897 - val_loss: 0.6282 - val_accuracy: 0.6440\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5886 - accuracy: 0.6912 - val_loss: 0.6259 - val_accuracy: 0.6474\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.5873 - accuracy: 0.6903 - val_loss: 0.6244 - val_accuracy: 0.6483\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 810us/step - loss: 0.5853 - accuracy: 0.6940 - val_loss: 0.6187 - val_accuracy: 0.6569\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5837 - accuracy: 0.6936 - val_loss: 0.6257 - val_accuracy: 0.6456\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.5830 - accuracy: 0.6949 - val_loss: 0.6215 - val_accuracy: 0.6517\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5814 - accuracy: 0.6952 - val_loss: 0.6234 - val_accuracy: 0.6482\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5802 - accuracy: 0.6963 - val_loss: 0.6158 - val_accuracy: 0.6595\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5779 - accuracy: 0.6992 - val_loss: 0.6181 - val_accuracy: 0.6558\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5763 - accuracy: 0.6990 - val_loss: 0.6140 - val_accuracy: 0.6605\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5754 - accuracy: 0.7025 - val_loss: 0.6180 - val_accuracy: 0.6547\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5742 - accuracy: 0.7024 - val_loss: 0.6193 - val_accuracy: 0.6534\n",
      "\n",
      "Training model with batch_size=64...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.1 iterated over 41800 steps satisfies differential privacy with eps = 1.42 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.7161 - accuracy: 0.4732 - val_loss: 0.7114 - val_accuracy: 0.4079\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.7082 - accuracy: 0.4925 - val_loss: 0.7275 - val_accuracy: 0.3241\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.7027 - accuracy: 0.5039 - val_loss: 0.7268 - val_accuracy: 0.3396\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 595us/step - loss: 0.7000 - accuracy: 0.5083 - val_loss: 0.7259 - val_accuracy: 0.3587\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6943 - accuracy: 0.5220 - val_loss: 0.7228 - val_accuracy: 0.3795\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 581us/step - loss: 0.6906 - accuracy: 0.5321 - val_loss: 0.7195 - val_accuracy: 0.4087\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6884 - accuracy: 0.5373 - val_loss: 0.7154 - val_accuracy: 0.4341\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6846 - accuracy: 0.5479 - val_loss: 0.7141 - val_accuracy: 0.4440\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 613us/step - loss: 0.6821 - accuracy: 0.5532 - val_loss: 0.7104 - val_accuracy: 0.4627\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 594us/step - loss: 0.6794 - accuracy: 0.5601 - val_loss: 0.7079 - val_accuracy: 0.4779\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.6757 - accuracy: 0.5680 - val_loss: 0.7042 - val_accuracy: 0.5033\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 593us/step - loss: 0.6740 - accuracy: 0.5719 - val_loss: 0.7008 - val_accuracy: 0.5170\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.6714 - accuracy: 0.5797 - val_loss: 0.6994 - val_accuracy: 0.5218\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 602us/step - loss: 0.6691 - accuracy: 0.5860 - val_loss: 0.6967 - val_accuracy: 0.5342\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6678 - accuracy: 0.5884 - val_loss: 0.6976 - val_accuracy: 0.5305\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6663 - accuracy: 0.5904 - val_loss: 0.6926 - val_accuracy: 0.5507\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6642 - accuracy: 0.5944 - val_loss: 0.6893 - val_accuracy: 0.5675\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6616 - accuracy: 0.6004 - val_loss: 0.6905 - val_accuracy: 0.5638\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6606 - accuracy: 0.6044 - val_loss: 0.6900 - val_accuracy: 0.5638\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6579 - accuracy: 0.6109 - val_loss: 0.6861 - val_accuracy: 0.5739\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6574 - accuracy: 0.6102 - val_loss: 0.6847 - val_accuracy: 0.5764\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6550 - accuracy: 0.6125 - val_loss: 0.6820 - val_accuracy: 0.5829\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6538 - accuracy: 0.6151 - val_loss: 0.6819 - val_accuracy: 0.5822\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6530 - accuracy: 0.6166 - val_loss: 0.6794 - val_accuracy: 0.5907\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6512 - accuracy: 0.6223 - val_loss: 0.6782 - val_accuracy: 0.5960\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.6496 - accuracy: 0.6245 - val_loss: 0.6772 - val_accuracy: 0.5975\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 606us/step - loss: 0.6488 - accuracy: 0.6223 - val_loss: 0.6759 - val_accuracy: 0.5994\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 673us/step - loss: 0.6482 - accuracy: 0.6253 - val_loss: 0.6738 - val_accuracy: 0.6032\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6457 - accuracy: 0.6279 - val_loss: 0.6735 - val_accuracy: 0.6022\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6444 - accuracy: 0.6304 - val_loss: 0.6714 - val_accuracy: 0.6060\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 578us/step - loss: 0.6431 - accuracy: 0.6311 - val_loss: 0.6710 - val_accuracy: 0.6061\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6427 - accuracy: 0.6345 - val_loss: 0.6709 - val_accuracy: 0.6043\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6410 - accuracy: 0.6358 - val_loss: 0.6698 - val_accuracy: 0.6057\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6382 - accuracy: 0.6408 - val_loss: 0.6716 - val_accuracy: 0.5994\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.6380 - accuracy: 0.6376 - val_loss: 0.6701 - val_accuracy: 0.6017\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6357 - accuracy: 0.6401 - val_loss: 0.6682 - val_accuracy: 0.6053\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6356 - accuracy: 0.6411 - val_loss: 0.6661 - val_accuracy: 0.6075\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6347 - accuracy: 0.6435 - val_loss: 0.6661 - val_accuracy: 0.6061\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 570us/step - loss: 0.6332 - accuracy: 0.6451 - val_loss: 0.6641 - val_accuracy: 0.6104\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.6317 - accuracy: 0.6483 - val_loss: 0.6605 - val_accuracy: 0.6171\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 578us/step - loss: 0.6310 - accuracy: 0.6460 - val_loss: 0.6609 - val_accuracy: 0.6138\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 647us/step - loss: 0.6298 - accuracy: 0.6497 - val_loss: 0.6626 - val_accuracy: 0.6088\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.6289 - accuracy: 0.6491 - val_loss: 0.6600 - val_accuracy: 0.6128\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6272 - accuracy: 0.6525 - val_loss: 0.6583 - val_accuracy: 0.6151\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 578us/step - loss: 0.6272 - accuracy: 0.6491 - val_loss: 0.6551 - val_accuracy: 0.6204\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6264 - accuracy: 0.6524 - val_loss: 0.6577 - val_accuracy: 0.6145\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6250 - accuracy: 0.6548 - val_loss: 0.6572 - val_accuracy: 0.6140\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6241 - accuracy: 0.6567 - val_loss: 0.6542 - val_accuracy: 0.6176\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6228 - accuracy: 0.6555 - val_loss: 0.6553 - val_accuracy: 0.6144\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.6219 - accuracy: 0.6560 - val_loss: 0.6512 - val_accuracy: 0.6222\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.7187 - accuracy: 0.5087 - val_loss: 0.8252 - val_accuracy: 0.1214\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 675us/step - loss: 0.7054 - accuracy: 0.5048 - val_loss: 0.7762 - val_accuracy: 0.1318\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6982 - accuracy: 0.5104 - val_loss: 0.7496 - val_accuracy: 0.1723\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 685us/step - loss: 0.6940 - accuracy: 0.5173 - val_loss: 0.7342 - val_accuracy: 0.2364\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6908 - accuracy: 0.5244 - val_loss: 0.7249 - val_accuracy: 0.2862\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6891 - accuracy: 0.5324 - val_loss: 0.7188 - val_accuracy: 0.3287\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6863 - accuracy: 0.5408 - val_loss: 0.7144 - val_accuracy: 0.3660\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 614us/step - loss: 0.6828 - accuracy: 0.5515 - val_loss: 0.7117 - val_accuracy: 0.3996\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 670us/step - loss: 0.6817 - accuracy: 0.5568 - val_loss: 0.7101 - val_accuracy: 0.4247\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 608us/step - loss: 0.6796 - accuracy: 0.5617 - val_loss: 0.7079 - val_accuracy: 0.4405\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6777 - accuracy: 0.5719 - val_loss: 0.7070 - val_accuracy: 0.4411\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 600us/step - loss: 0.6754 - accuracy: 0.5748 - val_loss: 0.7051 - val_accuracy: 0.4535\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 676us/step - loss: 0.6738 - accuracy: 0.5838 - val_loss: 0.7036 - val_accuracy: 0.4695\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 594us/step - loss: 0.6718 - accuracy: 0.5870 - val_loss: 0.7024 - val_accuracy: 0.4823\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 675us/step - loss: 0.6710 - accuracy: 0.5912 - val_loss: 0.7011 - val_accuracy: 0.4954\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 614us/step - loss: 0.6680 - accuracy: 0.5990 - val_loss: 0.6995 - val_accuracy: 0.5098\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 674us/step - loss: 0.6676 - accuracy: 0.5988 - val_loss: 0.6982 - val_accuracy: 0.5221\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6661 - accuracy: 0.6028 - val_loss: 0.6969 - val_accuracy: 0.5280\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6649 - accuracy: 0.6067 - val_loss: 0.6960 - val_accuracy: 0.5285\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 671us/step - loss: 0.6638 - accuracy: 0.6068 - val_loss: 0.6948 - val_accuracy: 0.5314\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 612us/step - loss: 0.6618 - accuracy: 0.6130 - val_loss: 0.6940 - val_accuracy: 0.5329\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 664us/step - loss: 0.6599 - accuracy: 0.6190 - val_loss: 0.6920 - val_accuracy: 0.5382\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.6592 - accuracy: 0.6205 - val_loss: 0.6909 - val_accuracy: 0.5416\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 679us/step - loss: 0.6586 - accuracy: 0.6197 - val_loss: 0.6890 - val_accuracy: 0.5467\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 603us/step - loss: 0.6571 - accuracy: 0.6226 - val_loss: 0.6877 - val_accuracy: 0.5503\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 670us/step - loss: 0.6556 - accuracy: 0.6265 - val_loss: 0.6861 - val_accuracy: 0.5532\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 606us/step - loss: 0.6542 - accuracy: 0.6291 - val_loss: 0.6839 - val_accuracy: 0.5591\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6535 - accuracy: 0.6300 - val_loss: 0.6829 - val_accuracy: 0.5623\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.6516 - accuracy: 0.6338 - val_loss: 0.6821 - val_accuracy: 0.5632\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 668us/step - loss: 0.6515 - accuracy: 0.6312 - val_loss: 0.6807 - val_accuracy: 0.5645\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 600us/step - loss: 0.6496 - accuracy: 0.6361 - val_loss: 0.6793 - val_accuracy: 0.5665\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 679us/step - loss: 0.6485 - accuracy: 0.6372 - val_loss: 0.6776 - val_accuracy: 0.5683\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6466 - accuracy: 0.6417 - val_loss: 0.6768 - val_accuracy: 0.5675\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.6458 - accuracy: 0.6415 - val_loss: 0.6754 - val_accuracy: 0.5701\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 606us/step - loss: 0.6453 - accuracy: 0.6406 - val_loss: 0.6735 - val_accuracy: 0.5755\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6434 - accuracy: 0.6432 - val_loss: 0.6727 - val_accuracy: 0.5775\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6428 - accuracy: 0.6443 - val_loss: 0.6728 - val_accuracy: 0.5768\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 664us/step - loss: 0.6419 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.5823\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6408 - accuracy: 0.6449 - val_loss: 0.6699 - val_accuracy: 0.5850\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6393 - accuracy: 0.6474 - val_loss: 0.6677 - val_accuracy: 0.5906\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.6381 - accuracy: 0.6518 - val_loss: 0.6666 - val_accuracy: 0.5922\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6371 - accuracy: 0.6487 - val_loss: 0.6656 - val_accuracy: 0.5936\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6361 - accuracy: 0.6522 - val_loss: 0.6657 - val_accuracy: 0.5915\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 602us/step - loss: 0.6348 - accuracy: 0.6526 - val_loss: 0.6652 - val_accuracy: 0.5919\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6340 - accuracy: 0.6530 - val_loss: 0.6637 - val_accuracy: 0.5938\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 595us/step - loss: 0.6326 - accuracy: 0.6554 - val_loss: 0.6625 - val_accuracy: 0.5954\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6311 - accuracy: 0.6565 - val_loss: 0.6612 - val_accuracy: 0.5965\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 593us/step - loss: 0.6306 - accuracy: 0.6570 - val_loss: 0.6597 - val_accuracy: 0.5985\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6297 - accuracy: 0.6575 - val_loss: 0.6588 - val_accuracy: 0.5988\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 685us/step - loss: 0.6287 - accuracy: 0.6561 - val_loss: 0.6569 - val_accuracy: 0.6025\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.7415 - accuracy: 0.5076 - val_loss: 0.8429 - val_accuracy: 0.1392\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.7088 - accuracy: 0.4939 - val_loss: 0.7675 - val_accuracy: 0.2305\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 610us/step - loss: 0.7010 - accuracy: 0.4966 - val_loss: 0.7406 - val_accuracy: 0.3027\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 619us/step - loss: 0.6972 - accuracy: 0.5025 - val_loss: 0.7311 - val_accuracy: 0.3236\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6927 - accuracy: 0.5111 - val_loss: 0.7237 - val_accuracy: 0.3512\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 582us/step - loss: 0.6892 - accuracy: 0.5230 - val_loss: 0.7207 - val_accuracy: 0.3701\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 595us/step - loss: 0.6861 - accuracy: 0.5302 - val_loss: 0.7188 - val_accuracy: 0.3785\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 549us/step - loss: 0.6834 - accuracy: 0.5402 - val_loss: 0.7143 - val_accuracy: 0.4211\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 598us/step - loss: 0.6801 - accuracy: 0.5476 - val_loss: 0.7094 - val_accuracy: 0.4764\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 527us/step - loss: 0.6770 - accuracy: 0.5584 - val_loss: 0.7062 - val_accuracy: 0.5055\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6755 - accuracy: 0.5644 - val_loss: 0.7036 - val_accuracy: 0.5222\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 553us/step - loss: 0.6721 - accuracy: 0.5775 - val_loss: 0.7008 - val_accuracy: 0.5363\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 589us/step - loss: 0.6700 - accuracy: 0.5811 - val_loss: 0.6988 - val_accuracy: 0.5415\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 527us/step - loss: 0.6688 - accuracy: 0.5845 - val_loss: 0.6960 - val_accuracy: 0.5489\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6658 - accuracy: 0.5933 - val_loss: 0.6956 - val_accuracy: 0.5477\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 526us/step - loss: 0.6647 - accuracy: 0.5956 - val_loss: 0.6926 - val_accuracy: 0.5545\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.6631 - accuracy: 0.6005 - val_loss: 0.6908 - val_accuracy: 0.5618\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 524us/step - loss: 0.6609 - accuracy: 0.6059 - val_loss: 0.6883 - val_accuracy: 0.5678\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 603us/step - loss: 0.6606 - accuracy: 0.6027 - val_loss: 0.6862 - val_accuracy: 0.5733\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6576 - accuracy: 0.6106 - val_loss: 0.6845 - val_accuracy: 0.5778\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 541us/step - loss: 0.6559 - accuracy: 0.6134 - val_loss: 0.6823 - val_accuracy: 0.5823\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.6548 - accuracy: 0.6188 - val_loss: 0.6821 - val_accuracy: 0.5819\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 537us/step - loss: 0.6538 - accuracy: 0.6184 - val_loss: 0.6797 - val_accuracy: 0.5871\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 594us/step - loss: 0.6526 - accuracy: 0.6203 - val_loss: 0.6781 - val_accuracy: 0.5901\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 536us/step - loss: 0.6508 - accuracy: 0.6221 - val_loss: 0.6779 - val_accuracy: 0.5893\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6495 - accuracy: 0.6231 - val_loss: 0.6753 - val_accuracy: 0.5917\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 539us/step - loss: 0.6473 - accuracy: 0.6321 - val_loss: 0.6724 - val_accuracy: 0.5965\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6461 - accuracy: 0.6313 - val_loss: 0.6728 - val_accuracy: 0.5942\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.6463 - accuracy: 0.6303 - val_loss: 0.6722 - val_accuracy: 0.5945\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.6453 - accuracy: 0.6306 - val_loss: 0.6708 - val_accuracy: 0.5974\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.6429 - accuracy: 0.6334 - val_loss: 0.6694 - val_accuracy: 0.5988\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 610us/step - loss: 0.6414 - accuracy: 0.6389 - val_loss: 0.6675 - val_accuracy: 0.6023\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 527us/step - loss: 0.6400 - accuracy: 0.6401 - val_loss: 0.6671 - val_accuracy: 0.6029\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 616us/step - loss: 0.6387 - accuracy: 0.6401 - val_loss: 0.6661 - val_accuracy: 0.6057\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6378 - accuracy: 0.6412 - val_loss: 0.6648 - val_accuracy: 0.6054\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 550us/step - loss: 0.6365 - accuracy: 0.6444 - val_loss: 0.6648 - val_accuracy: 0.6056\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 598us/step - loss: 0.6342 - accuracy: 0.6478 - val_loss: 0.6596 - val_accuracy: 0.6137\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 531us/step - loss: 0.6338 - accuracy: 0.6471 - val_loss: 0.6576 - val_accuracy: 0.6175\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6318 - accuracy: 0.6488 - val_loss: 0.6595 - val_accuracy: 0.6124\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6306 - accuracy: 0.6520 - val_loss: 0.6565 - val_accuracy: 0.6171\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 598us/step - loss: 0.6297 - accuracy: 0.6543 - val_loss: 0.6545 - val_accuracy: 0.6196\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 536us/step - loss: 0.6285 - accuracy: 0.6507 - val_loss: 0.6537 - val_accuracy: 0.6201\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 607us/step - loss: 0.6261 - accuracy: 0.6560 - val_loss: 0.6539 - val_accuracy: 0.6197\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 528us/step - loss: 0.6246 - accuracy: 0.6592 - val_loss: 0.6530 - val_accuracy: 0.6195\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 598us/step - loss: 0.6241 - accuracy: 0.6561 - val_loss: 0.6495 - val_accuracy: 0.6231\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 527us/step - loss: 0.6231 - accuracy: 0.6596 - val_loss: 0.6484 - val_accuracy: 0.6241\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 612us/step - loss: 0.6214 - accuracy: 0.6606 - val_loss: 0.6464 - val_accuracy: 0.6263\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6197 - accuracy: 0.6636 - val_loss: 0.6459 - val_accuracy: 0.6263\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 545us/step - loss: 0.6195 - accuracy: 0.6624 - val_loss: 0.6456 - val_accuracy: 0.6263\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 603us/step - loss: 0.6183 - accuracy: 0.6624 - val_loss: 0.6443 - val_accuracy: 0.6287\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 560us/step - loss: 0.7172 - accuracy: 0.5265 - val_loss: 0.7641 - val_accuracy: 0.2693\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 589us/step - loss: 0.7023 - accuracy: 0.5350 - val_loss: 0.7297 - val_accuracy: 0.3735\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 527us/step - loss: 0.6968 - accuracy: 0.5395 - val_loss: 0.7177 - val_accuracy: 0.4215\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 601us/step - loss: 0.6904 - accuracy: 0.5532 - val_loss: 0.7087 - val_accuracy: 0.4754\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 521us/step - loss: 0.6844 - accuracy: 0.5618 - val_loss: 0.7038 - val_accuracy: 0.5014\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 598us/step - loss: 0.6787 - accuracy: 0.5720 - val_loss: 0.6998 - val_accuracy: 0.5161\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 520us/step - loss: 0.6742 - accuracy: 0.5843 - val_loss: 0.6936 - val_accuracy: 0.5382\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6712 - accuracy: 0.5888 - val_loss: 0.6890 - val_accuracy: 0.5513\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.6646 - accuracy: 0.5989 - val_loss: 0.6832 - val_accuracy: 0.5715\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 551us/step - loss: 0.6618 - accuracy: 0.6043 - val_loss: 0.6812 - val_accuracy: 0.5853\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 520us/step - loss: 0.6576 - accuracy: 0.6138 - val_loss: 0.6786 - val_accuracy: 0.5953\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 591us/step - loss: 0.6563 - accuracy: 0.6137 - val_loss: 0.6770 - val_accuracy: 0.6002\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 516us/step - loss: 0.6545 - accuracy: 0.6194 - val_loss: 0.6759 - val_accuracy: 0.6022\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 582us/step - loss: 0.6496 - accuracy: 0.6265 - val_loss: 0.6722 - val_accuracy: 0.6093\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 520us/step - loss: 0.6482 - accuracy: 0.6291 - val_loss: 0.6700 - val_accuracy: 0.6122\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 588us/step - loss: 0.6458 - accuracy: 0.6337 - val_loss: 0.6660 - val_accuracy: 0.6183\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 519us/step - loss: 0.6440 - accuracy: 0.6344 - val_loss: 0.6635 - val_accuracy: 0.6218\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 603us/step - loss: 0.6420 - accuracy: 0.6415 - val_loss: 0.6623 - val_accuracy: 0.6216\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 526us/step - loss: 0.6403 - accuracy: 0.6410 - val_loss: 0.6595 - val_accuracy: 0.6244\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 594us/step - loss: 0.6383 - accuracy: 0.6422 - val_loss: 0.6585 - val_accuracy: 0.6256\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 523us/step - loss: 0.6355 - accuracy: 0.6459 - val_loss: 0.6579 - val_accuracy: 0.6251\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6356 - accuracy: 0.6475 - val_loss: 0.6553 - val_accuracy: 0.6289\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 563us/step - loss: 0.6322 - accuracy: 0.6506 - val_loss: 0.6546 - val_accuracy: 0.6282\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 548us/step - loss: 0.6309 - accuracy: 0.6525 - val_loss: 0.6510 - val_accuracy: 0.6324\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 508us/step - loss: 0.6310 - accuracy: 0.6539 - val_loss: 0.6508 - val_accuracy: 0.6316\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 598us/step - loss: 0.6281 - accuracy: 0.6565 - val_loss: 0.6477 - val_accuracy: 0.6352\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6273 - accuracy: 0.6560 - val_loss: 0.6502 - val_accuracy: 0.6307\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 539us/step - loss: 0.6258 - accuracy: 0.6600 - val_loss: 0.6493 - val_accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 519us/step - loss: 0.6245 - accuracy: 0.6606 - val_loss: 0.6439 - val_accuracy: 0.6393\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 601us/step - loss: 0.6229 - accuracy: 0.6632 - val_loss: 0.6432 - val_accuracy: 0.6387\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 511us/step - loss: 0.6212 - accuracy: 0.6645 - val_loss: 0.6412 - val_accuracy: 0.6402\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 593us/step - loss: 0.6210 - accuracy: 0.6657 - val_loss: 0.6430 - val_accuracy: 0.6373\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 525us/step - loss: 0.6190 - accuracy: 0.6665 - val_loss: 0.6413 - val_accuracy: 0.6388\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 592us/step - loss: 0.6187 - accuracy: 0.6680 - val_loss: 0.6424 - val_accuracy: 0.6353\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 513us/step - loss: 0.6160 - accuracy: 0.6689 - val_loss: 0.6389 - val_accuracy: 0.6398\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.6163 - accuracy: 0.6699 - val_loss: 0.6375 - val_accuracy: 0.6412\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 522us/step - loss: 0.6145 - accuracy: 0.6716 - val_loss: 0.6374 - val_accuracy: 0.6407\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 600us/step - loss: 0.6136 - accuracy: 0.6724 - val_loss: 0.6347 - val_accuracy: 0.6444\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 525us/step - loss: 0.6122 - accuracy: 0.6726 - val_loss: 0.6335 - val_accuracy: 0.6450\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 602us/step - loss: 0.6116 - accuracy: 0.6747 - val_loss: 0.6342 - val_accuracy: 0.6443\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 521us/step - loss: 0.6104 - accuracy: 0.6751 - val_loss: 0.6332 - val_accuracy: 0.6451\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6091 - accuracy: 0.6778 - val_loss: 0.6323 - val_accuracy: 0.6458\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 612us/step - loss: 0.6089 - accuracy: 0.6773 - val_loss: 0.6319 - val_accuracy: 0.6458\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 528us/step - loss: 0.6073 - accuracy: 0.6787 - val_loss: 0.6317 - val_accuracy: 0.6457\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6059 - accuracy: 0.6788 - val_loss: 0.6303 - val_accuracy: 0.6471\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6053 - accuracy: 0.6809 - val_loss: 0.6284 - val_accuracy: 0.6491\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 541us/step - loss: 0.6040 - accuracy: 0.6812 - val_loss: 0.6280 - val_accuracy: 0.6488\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 593us/step - loss: 0.6023 - accuracy: 0.6848 - val_loss: 0.6240 - val_accuracy: 0.6538\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 519us/step - loss: 0.6022 - accuracy: 0.6813 - val_loss: 0.6256 - val_accuracy: 0.6509\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 594us/step - loss: 0.6014 - accuracy: 0.6823 - val_loss: 0.6255 - val_accuracy: 0.6501\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.7374 - accuracy: 0.4991 - val_loss: 0.6740 - val_accuracy: 0.6177\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.7115 - accuracy: 0.5179 - val_loss: 0.7094 - val_accuracy: 0.4644\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 574us/step - loss: 0.7049 - accuracy: 0.5258 - val_loss: 0.7124 - val_accuracy: 0.4658\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 525us/step - loss: 0.7034 - accuracy: 0.5297 - val_loss: 0.7068 - val_accuracy: 0.4935\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 534us/step - loss: 0.6958 - accuracy: 0.5426 - val_loss: 0.7062 - val_accuracy: 0.5022\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 593us/step - loss: 0.6908 - accuracy: 0.5517 - val_loss: 0.7022 - val_accuracy: 0.5170\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 522us/step - loss: 0.6888 - accuracy: 0.5550 - val_loss: 0.6984 - val_accuracy: 0.5297\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 593us/step - loss: 0.6843 - accuracy: 0.5639 - val_loss: 0.6958 - val_accuracy: 0.5379\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6813 - accuracy: 0.5694 - val_loss: 0.6921 - val_accuracy: 0.5506\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 535us/step - loss: 0.6775 - accuracy: 0.5747 - val_loss: 0.6893 - val_accuracy: 0.5581\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6751 - accuracy: 0.5829 - val_loss: 0.6872 - val_accuracy: 0.5651\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 523us/step - loss: 0.6711 - accuracy: 0.5897 - val_loss: 0.6843 - val_accuracy: 0.5695\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6670 - accuracy: 0.5958 - val_loss: 0.6838 - val_accuracy: 0.5705\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 523us/step - loss: 0.6669 - accuracy: 0.5965 - val_loss: 0.6804 - val_accuracy: 0.5790\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 595us/step - loss: 0.6651 - accuracy: 0.6012 - val_loss: 0.6753 - val_accuracy: 0.5918\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6621 - accuracy: 0.6067 - val_loss: 0.6746 - val_accuracy: 0.5942\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 542us/step - loss: 0.6578 - accuracy: 0.6143 - val_loss: 0.6734 - val_accuracy: 0.5959\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 516us/step - loss: 0.6564 - accuracy: 0.6176 - val_loss: 0.6707 - val_accuracy: 0.6001\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 595us/step - loss: 0.6546 - accuracy: 0.6194 - val_loss: 0.6681 - val_accuracy: 0.6050\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 522us/step - loss: 0.6525 - accuracy: 0.6219 - val_loss: 0.6701 - val_accuracy: 0.6020\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 591us/step - loss: 0.6499 - accuracy: 0.6272 - val_loss: 0.6676 - val_accuracy: 0.6058\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6489 - accuracy: 0.6300 - val_loss: 0.6666 - val_accuracy: 0.6070\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 529us/step - loss: 0.6464 - accuracy: 0.6324 - val_loss: 0.6644 - val_accuracy: 0.6090\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 600us/step - loss: 0.6455 - accuracy: 0.6346 - val_loss: 0.6636 - val_accuracy: 0.6086\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 512us/step - loss: 0.6431 - accuracy: 0.6387 - val_loss: 0.6598 - val_accuracy: 0.6146\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 589us/step - loss: 0.6411 - accuracy: 0.6427 - val_loss: 0.6592 - val_accuracy: 0.6141\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6392 - accuracy: 0.6455 - val_loss: 0.6590 - val_accuracy: 0.6148\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6387 - accuracy: 0.6472 - val_loss: 0.6565 - val_accuracy: 0.6183\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 601us/step - loss: 0.6369 - accuracy: 0.6489 - val_loss: 0.6543 - val_accuracy: 0.6205\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 528us/step - loss: 0.6360 - accuracy: 0.6514 - val_loss: 0.6523 - val_accuracy: 0.6237\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 588us/step - loss: 0.6336 - accuracy: 0.6532 - val_loss: 0.6511 - val_accuracy: 0.6245\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 537us/step - loss: 0.6330 - accuracy: 0.6541 - val_loss: 0.6513 - val_accuracy: 0.6248\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6314 - accuracy: 0.6593 - val_loss: 0.6503 - val_accuracy: 0.6260\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 538us/step - loss: 0.6296 - accuracy: 0.6609 - val_loss: 0.6491 - val_accuracy: 0.6263\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 587us/step - loss: 0.6280 - accuracy: 0.6607 - val_loss: 0.6481 - val_accuracy: 0.6273\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 582us/step - loss: 0.6265 - accuracy: 0.6642 - val_loss: 0.6489 - val_accuracy: 0.6257\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 533us/step - loss: 0.6274 - accuracy: 0.6648 - val_loss: 0.6465 - val_accuracy: 0.6286\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6242 - accuracy: 0.6658 - val_loss: 0.6461 - val_accuracy: 0.6288\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 523us/step - loss: 0.6243 - accuracy: 0.6653 - val_loss: 0.6459 - val_accuracy: 0.6289\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 589us/step - loss: 0.6221 - accuracy: 0.6702 - val_loss: 0.6428 - val_accuracy: 0.6324\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 528us/step - loss: 0.6213 - accuracy: 0.6702 - val_loss: 0.6422 - val_accuracy: 0.6322\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 595us/step - loss: 0.6205 - accuracy: 0.6714 - val_loss: 0.6427 - val_accuracy: 0.6322\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6195 - accuracy: 0.6728 - val_loss: 0.6407 - val_accuracy: 0.6351\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 529us/step - loss: 0.6178 - accuracy: 0.6741 - val_loss: 0.6399 - val_accuracy: 0.6356\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 591us/step - loss: 0.6168 - accuracy: 0.6746 - val_loss: 0.6423 - val_accuracy: 0.6325\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 534us/step - loss: 0.6163 - accuracy: 0.6754 - val_loss: 0.6390 - val_accuracy: 0.6361\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 594us/step - loss: 0.6140 - accuracy: 0.6789 - val_loss: 0.6372 - val_accuracy: 0.6383\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 550us/step - loss: 0.6144 - accuracy: 0.6783 - val_loss: 0.6389 - val_accuracy: 0.6366\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 601us/step - loss: 0.6134 - accuracy: 0.6781 - val_loss: 0.6375 - val_accuracy: 0.6383\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6118 - accuracy: 0.6798 - val_loss: 0.6374 - val_accuracy: 0.6382\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.7137 - accuracy: 0.5095 - val_loss: 0.7739 - val_accuracy: 0.1462\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 587us/step - loss: 0.7029 - accuracy: 0.5129 - val_loss: 0.7356 - val_accuracy: 0.2631\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 530us/step - loss: 0.6981 - accuracy: 0.5174 - val_loss: 0.7239 - val_accuracy: 0.3321\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6942 - accuracy: 0.5255 - val_loss: 0.7200 - val_accuracy: 0.3630\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 554us/step - loss: 0.6912 - accuracy: 0.5368 - val_loss: 0.7156 - val_accuracy: 0.3982\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 617us/step - loss: 0.6881 - accuracy: 0.5430 - val_loss: 0.7126 - val_accuracy: 0.4261\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 527us/step - loss: 0.6854 - accuracy: 0.5490 - val_loss: 0.7086 - val_accuracy: 0.4533\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 601us/step - loss: 0.6813 - accuracy: 0.5629 - val_loss: 0.7062 - val_accuracy: 0.4708\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.6784 - accuracy: 0.5703 - val_loss: 0.7061 - val_accuracy: 0.4757\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 533us/step - loss: 0.6766 - accuracy: 0.5746 - val_loss: 0.7054 - val_accuracy: 0.4809\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 602us/step - loss: 0.6736 - accuracy: 0.5817 - val_loss: 0.7019 - val_accuracy: 0.5002\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 533us/step - loss: 0.6717 - accuracy: 0.5862 - val_loss: 0.7009 - val_accuracy: 0.5077\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 600us/step - loss: 0.6708 - accuracy: 0.5887 - val_loss: 0.6994 - val_accuracy: 0.5183\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 526us/step - loss: 0.6674 - accuracy: 0.5964 - val_loss: 0.6990 - val_accuracy: 0.5205\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.6668 - accuracy: 0.5977 - val_loss: 0.6971 - val_accuracy: 0.5271\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6644 - accuracy: 0.6056 - val_loss: 0.6940 - val_accuracy: 0.5360\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 550us/step - loss: 0.6633 - accuracy: 0.6091 - val_loss: 0.6942 - val_accuracy: 0.5365\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 591us/step - loss: 0.6604 - accuracy: 0.6116 - val_loss: 0.6923 - val_accuracy: 0.5426\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 529us/step - loss: 0.6608 - accuracy: 0.6132 - val_loss: 0.6902 - val_accuracy: 0.5500\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 599us/step - loss: 0.6584 - accuracy: 0.6189 - val_loss: 0.6884 - val_accuracy: 0.5559\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 591us/step - loss: 0.6573 - accuracy: 0.6201 - val_loss: 0.6862 - val_accuracy: 0.5625\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 534us/step - loss: 0.6556 - accuracy: 0.6234 - val_loss: 0.6861 - val_accuracy: 0.5640\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.6542 - accuracy: 0.6254 - val_loss: 0.6857 - val_accuracy: 0.5662\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 582us/step - loss: 0.6524 - accuracy: 0.6322 - val_loss: 0.6835 - val_accuracy: 0.5713\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 513us/step - loss: 0.6510 - accuracy: 0.6314 - val_loss: 0.6821 - val_accuracy: 0.5758\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 574us/step - loss: 0.6497 - accuracy: 0.6331 - val_loss: 0.6792 - val_accuracy: 0.5831\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 508us/step - loss: 0.6490 - accuracy: 0.6343 - val_loss: 0.6799 - val_accuracy: 0.5808\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.6460 - accuracy: 0.6401 - val_loss: 0.6772 - val_accuracy: 0.5879\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6457 - accuracy: 0.6404 - val_loss: 0.6765 - val_accuracy: 0.5902\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 523us/step - loss: 0.6442 - accuracy: 0.6433 - val_loss: 0.6732 - val_accuracy: 0.5959\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6424 - accuracy: 0.6453 - val_loss: 0.6733 - val_accuracy: 0.5956\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 512us/step - loss: 0.6414 - accuracy: 0.6455 - val_loss: 0.6729 - val_accuracy: 0.5962\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6403 - accuracy: 0.6475 - val_loss: 0.6712 - val_accuracy: 0.5996\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 563us/step - loss: 0.6387 - accuracy: 0.6519 - val_loss: 0.6713 - val_accuracy: 0.5981\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 521us/step - loss: 0.6380 - accuracy: 0.6514 - val_loss: 0.6698 - val_accuracy: 0.5997\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6370 - accuracy: 0.6516 - val_loss: 0.6676 - val_accuracy: 0.6042\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 536us/step - loss: 0.6354 - accuracy: 0.6565 - val_loss: 0.6671 - val_accuracy: 0.6043\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6334 - accuracy: 0.6571 - val_loss: 0.6678 - val_accuracy: 0.6036\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 519us/step - loss: 0.6322 - accuracy: 0.6580 - val_loss: 0.6643 - val_accuracy: 0.6089\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6322 - accuracy: 0.6584 - val_loss: 0.6594 - val_accuracy: 0.6185\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 580us/step - loss: 0.6303 - accuracy: 0.6618 - val_loss: 0.6607 - val_accuracy: 0.6161\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 513us/step - loss: 0.6288 - accuracy: 0.6617 - val_loss: 0.6608 - val_accuracy: 0.6147\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6273 - accuracy: 0.6631 - val_loss: 0.6587 - val_accuracy: 0.6163\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 513us/step - loss: 0.6260 - accuracy: 0.6669 - val_loss: 0.6578 - val_accuracy: 0.6174\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 721us/step - loss: 0.6256 - accuracy: 0.6639 - val_loss: 0.6575 - val_accuracy: 0.6172\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6245 - accuracy: 0.6670 - val_loss: 0.6566 - val_accuracy: 0.6182\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 548us/step - loss: 0.6235 - accuracy: 0.6682 - val_loss: 0.6564 - val_accuracy: 0.6183\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6227 - accuracy: 0.6681 - val_loss: 0.6540 - val_accuracy: 0.6237\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 521us/step - loss: 0.6214 - accuracy: 0.6705 - val_loss: 0.6529 - val_accuracy: 0.6255\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6203 - accuracy: 0.6719 - val_loss: 0.6529 - val_accuracy: 0.6246\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.7415 - accuracy: 0.4993 - val_loss: 0.6121 - val_accuracy: 0.8641\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 578us/step - loss: 0.6878 - accuracy: 0.5537 - val_loss: 0.6778 - val_accuracy: 0.5789\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 506us/step - loss: 0.6809 - accuracy: 0.5740 - val_loss: 0.6930 - val_accuracy: 0.5234\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6774 - accuracy: 0.5793 - val_loss: 0.6924 - val_accuracy: 0.5244\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 548us/step - loss: 0.6755 - accuracy: 0.5885 - val_loss: 0.6926 - val_accuracy: 0.5245\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 526us/step - loss: 0.6731 - accuracy: 0.5919 - val_loss: 0.6912 - val_accuracy: 0.5297\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 578us/step - loss: 0.6704 - accuracy: 0.6025 - val_loss: 0.6897 - val_accuracy: 0.5351\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 507us/step - loss: 0.6674 - accuracy: 0.6112 - val_loss: 0.6866 - val_accuracy: 0.5446\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6657 - accuracy: 0.6099 - val_loss: 0.6854 - val_accuracy: 0.5503\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 516us/step - loss: 0.6643 - accuracy: 0.6164 - val_loss: 0.6841 - val_accuracy: 0.5528\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6617 - accuracy: 0.6257 - val_loss: 0.6820 - val_accuracy: 0.5593\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 617us/step - loss: 0.6593 - accuracy: 0.6242 - val_loss: 0.6826 - val_accuracy: 0.5542\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 680us/step - loss: 0.6572 - accuracy: 0.6310 - val_loss: 0.6814 - val_accuracy: 0.5572\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.6555 - accuracy: 0.6347 - val_loss: 0.6811 - val_accuracy: 0.5571\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6529 - accuracy: 0.6395 - val_loss: 0.6772 - val_accuracy: 0.5666\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6503 - accuracy: 0.6468 - val_loss: 0.6768 - val_accuracy: 0.5671\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6491 - accuracy: 0.6481 - val_loss: 0.6749 - val_accuracy: 0.5723\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 664us/step - loss: 0.6476 - accuracy: 0.6485 - val_loss: 0.6730 - val_accuracy: 0.5765\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.6454 - accuracy: 0.6528 - val_loss: 0.6712 - val_accuracy: 0.5789\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6440 - accuracy: 0.6546 - val_loss: 0.6700 - val_accuracy: 0.5806\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6410 - accuracy: 0.6585 - val_loss: 0.6666 - val_accuracy: 0.5883\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6404 - accuracy: 0.6605 - val_loss: 0.6653 - val_accuracy: 0.5895\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 616us/step - loss: 0.6376 - accuracy: 0.6632 - val_loss: 0.6632 - val_accuracy: 0.5962\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6356 - accuracy: 0.6648 - val_loss: 0.6622 - val_accuracy: 0.5979\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6334 - accuracy: 0.6685 - val_loss: 0.6618 - val_accuracy: 0.5987\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.6317 - accuracy: 0.6712 - val_loss: 0.6595 - val_accuracy: 0.6029\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6299 - accuracy: 0.6704 - val_loss: 0.6581 - val_accuracy: 0.6047\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6291 - accuracy: 0.6739 - val_loss: 0.6555 - val_accuracy: 0.6091\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6273 - accuracy: 0.6766 - val_loss: 0.6540 - val_accuracy: 0.6107\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6251 - accuracy: 0.6771 - val_loss: 0.6520 - val_accuracy: 0.6137\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6237 - accuracy: 0.6766 - val_loss: 0.6509 - val_accuracy: 0.6150\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6230 - accuracy: 0.6764 - val_loss: 0.6481 - val_accuracy: 0.6175\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6218 - accuracy: 0.6803 - val_loss: 0.6469 - val_accuracy: 0.6190\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 586us/step - loss: 0.6208 - accuracy: 0.6801 - val_loss: 0.6432 - val_accuracy: 0.6235\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6182 - accuracy: 0.6835 - val_loss: 0.6437 - val_accuracy: 0.6215\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6170 - accuracy: 0.6842 - val_loss: 0.6416 - val_accuracy: 0.6234\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6169 - accuracy: 0.6816 - val_loss: 0.6402 - val_accuracy: 0.6244\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6146 - accuracy: 0.6842 - val_loss: 0.6380 - val_accuracy: 0.6259\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6132 - accuracy: 0.6862 - val_loss: 0.6371 - val_accuracy: 0.6255\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.6125 - accuracy: 0.6869 - val_loss: 0.6360 - val_accuracy: 0.6262\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 663us/step - loss: 0.6109 - accuracy: 0.6884 - val_loss: 0.6386 - val_accuracy: 0.6228\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6097 - accuracy: 0.6878 - val_loss: 0.6348 - val_accuracy: 0.6256\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 592us/step - loss: 0.6079 - accuracy: 0.6925 - val_loss: 0.6343 - val_accuracy: 0.6255\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6073 - accuracy: 0.6895 - val_loss: 0.6343 - val_accuracy: 0.6248\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6053 - accuracy: 0.6926 - val_loss: 0.6306 - val_accuracy: 0.6287\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 611us/step - loss: 0.6045 - accuracy: 0.6921 - val_loss: 0.6357 - val_accuracy: 0.6230\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6036 - accuracy: 0.6931 - val_loss: 0.6302 - val_accuracy: 0.6274\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.6024 - accuracy: 0.6941 - val_loss: 0.6291 - val_accuracy: 0.6280\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.6005 - accuracy: 0.6949 - val_loss: 0.6300 - val_accuracy: 0.6277\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.5997 - accuracy: 0.6962 - val_loss: 0.6259 - val_accuracy: 0.6307\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.8329 - accuracy: 0.4796 - val_loss: 0.5880 - val_accuracy: 0.8766\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.7134 - accuracy: 0.4943 - val_loss: 0.6819 - val_accuracy: 0.5681\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.7072 - accuracy: 0.4979 - val_loss: 0.7000 - val_accuracy: 0.4443\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 680us/step - loss: 0.7024 - accuracy: 0.5073 - val_loss: 0.6999 - val_accuracy: 0.4512\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6991 - accuracy: 0.5125 - val_loss: 0.6983 - val_accuracy: 0.4637\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6952 - accuracy: 0.5192 - val_loss: 0.6941 - val_accuracy: 0.4889\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6927 - accuracy: 0.5241 - val_loss: 0.6899 - val_accuracy: 0.5103\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.6876 - accuracy: 0.5366 - val_loss: 0.6878 - val_accuracy: 0.5237\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6858 - accuracy: 0.5408 - val_loss: 0.6850 - val_accuracy: 0.5433\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6817 - accuracy: 0.5540 - val_loss: 0.6827 - val_accuracy: 0.5571\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.6808 - accuracy: 0.5512 - val_loss: 0.6806 - val_accuracy: 0.5727\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.6764 - accuracy: 0.5620 - val_loss: 0.6763 - val_accuracy: 0.5890\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.6737 - accuracy: 0.5679 - val_loss: 0.6719 - val_accuracy: 0.6035\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6700 - accuracy: 0.5775 - val_loss: 0.6695 - val_accuracy: 0.6099\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6666 - accuracy: 0.5832 - val_loss: 0.6659 - val_accuracy: 0.6206\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 669us/step - loss: 0.6645 - accuracy: 0.5864 - val_loss: 0.6666 - val_accuracy: 0.6196\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.6624 - accuracy: 0.5944 - val_loss: 0.6623 - val_accuracy: 0.6279\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6582 - accuracy: 0.6005 - val_loss: 0.6611 - val_accuracy: 0.6305\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.6566 - accuracy: 0.6072 - val_loss: 0.6627 - val_accuracy: 0.6265\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 602us/step - loss: 0.6561 - accuracy: 0.6057 - val_loss: 0.6612 - val_accuracy: 0.6294\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.6540 - accuracy: 0.6107 - val_loss: 0.6573 - val_accuracy: 0.6352\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6511 - accuracy: 0.6146 - val_loss: 0.6558 - val_accuracy: 0.6367\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6484 - accuracy: 0.6197 - val_loss: 0.6552 - val_accuracy: 0.6362\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6471 - accuracy: 0.6245 - val_loss: 0.6534 - val_accuracy: 0.6362\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6450 - accuracy: 0.6265 - val_loss: 0.6518 - val_accuracy: 0.6381\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6440 - accuracy: 0.6303 - val_loss: 0.6532 - val_accuracy: 0.6346\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6418 - accuracy: 0.6328 - val_loss: 0.6504 - val_accuracy: 0.6375\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 593us/step - loss: 0.6388 - accuracy: 0.6388 - val_loss: 0.6467 - val_accuracy: 0.6419\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6375 - accuracy: 0.6361 - val_loss: 0.6482 - val_accuracy: 0.6366\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6356 - accuracy: 0.6419 - val_loss: 0.6459 - val_accuracy: 0.6398\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6356 - accuracy: 0.6409 - val_loss: 0.6448 - val_accuracy: 0.6410\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6330 - accuracy: 0.6451 - val_loss: 0.6432 - val_accuracy: 0.6417\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6312 - accuracy: 0.6516 - val_loss: 0.6429 - val_accuracy: 0.6407\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.6299 - accuracy: 0.6503 - val_loss: 0.6437 - val_accuracy: 0.6368\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6273 - accuracy: 0.6547 - val_loss: 0.6391 - val_accuracy: 0.6428\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6261 - accuracy: 0.6597 - val_loss: 0.6420 - val_accuracy: 0.6373\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6248 - accuracy: 0.6579 - val_loss: 0.6393 - val_accuracy: 0.6403\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6229 - accuracy: 0.6611 - val_loss: 0.6384 - val_accuracy: 0.6403\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 610us/step - loss: 0.6217 - accuracy: 0.6625 - val_loss: 0.6363 - val_accuracy: 0.6420\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 682us/step - loss: 0.6204 - accuracy: 0.6640 - val_loss: 0.6356 - val_accuracy: 0.6423\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 682us/step - loss: 0.6187 - accuracy: 0.6677 - val_loss: 0.6325 - val_accuracy: 0.6456\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6182 - accuracy: 0.6671 - val_loss: 0.6316 - val_accuracy: 0.6454\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.6165 - accuracy: 0.6709 - val_loss: 0.6307 - val_accuracy: 0.6457\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6144 - accuracy: 0.6739 - val_loss: 0.6314 - val_accuracy: 0.6425\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 598us/step - loss: 0.6126 - accuracy: 0.6751 - val_loss: 0.6269 - val_accuracy: 0.6498\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.6131 - accuracy: 0.6751 - val_loss: 0.6275 - val_accuracy: 0.6477\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.6110 - accuracy: 0.6765 - val_loss: 0.6278 - val_accuracy: 0.6454\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.6094 - accuracy: 0.6799 - val_loss: 0.6257 - val_accuracy: 0.6488\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 664us/step - loss: 0.6082 - accuracy: 0.6798 - val_loss: 0.6289 - val_accuracy: 0.6399\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6062 - accuracy: 0.6837 - val_loss: 0.6266 - val_accuracy: 0.6445\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.7054 - accuracy: 0.5302 - val_loss: 0.7301 - val_accuracy: 0.3382\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.7005 - accuracy: 0.5360 - val_loss: 0.7187 - val_accuracy: 0.3880\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6984 - accuracy: 0.5363 - val_loss: 0.7123 - val_accuracy: 0.4097\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6913 - accuracy: 0.5492 - val_loss: 0.7090 - val_accuracy: 0.4229\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 668us/step - loss: 0.6880 - accuracy: 0.5596 - val_loss: 0.7054 - val_accuracy: 0.4419\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6858 - accuracy: 0.5621 - val_loss: 0.7060 - val_accuracy: 0.4456\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 587us/step - loss: 0.6821 - accuracy: 0.5721 - val_loss: 0.7033 - val_accuracy: 0.4610\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 668us/step - loss: 0.6797 - accuracy: 0.5762 - val_loss: 0.6976 - val_accuracy: 0.4796\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6778 - accuracy: 0.5802 - val_loss: 0.6963 - val_accuracy: 0.4836\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 595us/step - loss: 0.6753 - accuracy: 0.5878 - val_loss: 0.6935 - val_accuracy: 0.4921\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6730 - accuracy: 0.5899 - val_loss: 0.6937 - val_accuracy: 0.4930\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 581us/step - loss: 0.6709 - accuracy: 0.5928 - val_loss: 0.6914 - val_accuracy: 0.4998\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 663us/step - loss: 0.6680 - accuracy: 0.6022 - val_loss: 0.6899 - val_accuracy: 0.5075\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 663us/step - loss: 0.6670 - accuracy: 0.6036 - val_loss: 0.6886 - val_accuracy: 0.5114\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6650 - accuracy: 0.6097 - val_loss: 0.6853 - val_accuracy: 0.5212\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.6632 - accuracy: 0.6113 - val_loss: 0.6858 - val_accuracy: 0.5216\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6613 - accuracy: 0.6141 - val_loss: 0.6837 - val_accuracy: 0.5283\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 658us/step - loss: 0.6601 - accuracy: 0.6178 - val_loss: 0.6815 - val_accuracy: 0.5361\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 582us/step - loss: 0.6582 - accuracy: 0.6229 - val_loss: 0.6813 - val_accuracy: 0.5371\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 663us/step - loss: 0.6572 - accuracy: 0.6241 - val_loss: 0.6814 - val_accuracy: 0.5389\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6556 - accuracy: 0.6273 - val_loss: 0.6789 - val_accuracy: 0.5448\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 588us/step - loss: 0.6537 - accuracy: 0.6295 - val_loss: 0.6799 - val_accuracy: 0.5427\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.6522 - accuracy: 0.6307 - val_loss: 0.6767 - val_accuracy: 0.5484\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6515 - accuracy: 0.6327 - val_loss: 0.6781 - val_accuracy: 0.5474\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6493 - accuracy: 0.6352 - val_loss: 0.6734 - val_accuracy: 0.5561\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 676us/step - loss: 0.6486 - accuracy: 0.6383 - val_loss: 0.6732 - val_accuracy: 0.5571\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 680us/step - loss: 0.6455 - accuracy: 0.6404 - val_loss: 0.6715 - val_accuracy: 0.5618\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 581us/step - loss: 0.6458 - accuracy: 0.6406 - val_loss: 0.6719 - val_accuracy: 0.5604\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 663us/step - loss: 0.6445 - accuracy: 0.6442 - val_loss: 0.6709 - val_accuracy: 0.5640\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 663us/step - loss: 0.6422 - accuracy: 0.6459 - val_loss: 0.6696 - val_accuracy: 0.5664\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 586us/step - loss: 0.6421 - accuracy: 0.6469 - val_loss: 0.6692 - val_accuracy: 0.5675\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6395 - accuracy: 0.6475 - val_loss: 0.6657 - val_accuracy: 0.5744\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 671us/step - loss: 0.6391 - accuracy: 0.6503 - val_loss: 0.6664 - val_accuracy: 0.5730\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 594us/step - loss: 0.6380 - accuracy: 0.6505 - val_loss: 0.6636 - val_accuracy: 0.5788\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 678us/step - loss: 0.6372 - accuracy: 0.6544 - val_loss: 0.6650 - val_accuracy: 0.5759\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6354 - accuracy: 0.6565 - val_loss: 0.6621 - val_accuracy: 0.5830\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 586us/step - loss: 0.6340 - accuracy: 0.6568 - val_loss: 0.6605 - val_accuracy: 0.5866\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 670us/step - loss: 0.6338 - accuracy: 0.6558 - val_loss: 0.6607 - val_accuracy: 0.5864\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 680us/step - loss: 0.6309 - accuracy: 0.6587 - val_loss: 0.6597 - val_accuracy: 0.5883\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 580us/step - loss: 0.6307 - accuracy: 0.6611 - val_loss: 0.6587 - val_accuracy: 0.5916\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 665us/step - loss: 0.6300 - accuracy: 0.6619 - val_loss: 0.6570 - val_accuracy: 0.5944\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6293 - accuracy: 0.6615 - val_loss: 0.6555 - val_accuracy: 0.5983\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 682us/step - loss: 0.6283 - accuracy: 0.6634 - val_loss: 0.6554 - val_accuracy: 0.5987\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 602us/step - loss: 0.6261 - accuracy: 0.6668 - val_loss: 0.6542 - val_accuracy: 0.6001\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 669us/step - loss: 0.6253 - accuracy: 0.6662 - val_loss: 0.6528 - val_accuracy: 0.6016\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.6245 - accuracy: 0.6665 - val_loss: 0.6543 - val_accuracy: 0.5981\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 625us/step - loss: 0.6237 - accuracy: 0.6653 - val_loss: 0.6510 - val_accuracy: 0.6038\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6225 - accuracy: 0.6688 - val_loss: 0.6495 - val_accuracy: 0.6052\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6220 - accuracy: 0.6676 - val_loss: 0.6500 - val_accuracy: 0.6046\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6212 - accuracy: 0.6708 - val_loss: 0.6497 - val_accuracy: 0.6053\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 662us/step - loss: 0.7362 - accuracy: 0.4624 - val_loss: 0.6598 - val_accuracy: 0.6649\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.7224 - accuracy: 0.4586 - val_loss: 0.6932 - val_accuracy: 0.4954\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.7133 - accuracy: 0.4791 - val_loss: 0.7082 - val_accuracy: 0.3823\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 647us/step - loss: 0.7078 - accuracy: 0.4921 - val_loss: 0.7154 - val_accuracy: 0.3122\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.7037 - accuracy: 0.4967 - val_loss: 0.7175 - val_accuracy: 0.2990\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.7022 - accuracy: 0.5001 - val_loss: 0.7184 - val_accuracy: 0.2979\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6996 - accuracy: 0.5094 - val_loss: 0.7174 - val_accuracy: 0.3022\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6970 - accuracy: 0.5152 - val_loss: 0.7156 - val_accuracy: 0.3197\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6948 - accuracy: 0.5200 - val_loss: 0.7153 - val_accuracy: 0.3375\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6931 - accuracy: 0.5270 - val_loss: 0.7132 - val_accuracy: 0.3714\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6905 - accuracy: 0.5327 - val_loss: 0.7122 - val_accuracy: 0.3968\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 588us/step - loss: 0.6892 - accuracy: 0.5374 - val_loss: 0.7107 - val_accuracy: 0.4163\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6876 - accuracy: 0.5426 - val_loss: 0.7089 - val_accuracy: 0.4326\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6860 - accuracy: 0.5481 - val_loss: 0.7073 - val_accuracy: 0.4491\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 526us/step - loss: 0.6836 - accuracy: 0.5552 - val_loss: 0.7059 - val_accuracy: 0.4618\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6825 - accuracy: 0.5596 - val_loss: 0.7041 - val_accuracy: 0.4737\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6814 - accuracy: 0.5624 - val_loss: 0.7025 - val_accuracy: 0.4842\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 607us/step - loss: 0.6796 - accuracy: 0.5700 - val_loss: 0.7023 - val_accuracy: 0.4893\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 506us/step - loss: 0.6786 - accuracy: 0.5708 - val_loss: 0.7010 - val_accuracy: 0.4963\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 588us/step - loss: 0.6770 - accuracy: 0.5762 - val_loss: 0.6996 - val_accuracy: 0.5036\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 553us/step - loss: 0.6762 - accuracy: 0.5809 - val_loss: 0.6978 - val_accuracy: 0.5117\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 528us/step - loss: 0.6750 - accuracy: 0.5832 - val_loss: 0.6962 - val_accuracy: 0.5176\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 588us/step - loss: 0.6736 - accuracy: 0.5854 - val_loss: 0.6955 - val_accuracy: 0.5212\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 501us/step - loss: 0.6722 - accuracy: 0.5909 - val_loss: 0.6943 - val_accuracy: 0.5247\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 605us/step - loss: 0.6722 - accuracy: 0.5915 - val_loss: 0.6923 - val_accuracy: 0.5299\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 566us/step - loss: 0.6707 - accuracy: 0.5960 - val_loss: 0.6918 - val_accuracy: 0.5318\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 510us/step - loss: 0.6686 - accuracy: 0.6025 - val_loss: 0.6908 - val_accuracy: 0.5360\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6679 - accuracy: 0.6024 - val_loss: 0.6906 - val_accuracy: 0.5373\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 554us/step - loss: 0.6668 - accuracy: 0.6078 - val_loss: 0.6896 - val_accuracy: 0.5406\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 524us/step - loss: 0.6657 - accuracy: 0.6063 - val_loss: 0.6886 - val_accuracy: 0.5435\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6646 - accuracy: 0.6089 - val_loss: 0.6878 - val_accuracy: 0.5459\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 515us/step - loss: 0.6638 - accuracy: 0.6100 - val_loss: 0.6863 - val_accuracy: 0.5504\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6622 - accuracy: 0.6167 - val_loss: 0.6857 - val_accuracy: 0.5524\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 515us/step - loss: 0.6612 - accuracy: 0.6193 - val_loss: 0.6847 - val_accuracy: 0.5568\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 587us/step - loss: 0.6606 - accuracy: 0.6184 - val_loss: 0.6839 - val_accuracy: 0.5588\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 574us/step - loss: 0.6589 - accuracy: 0.6221 - val_loss: 0.6826 - val_accuracy: 0.5628\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 513us/step - loss: 0.6582 - accuracy: 0.6231 - val_loss: 0.6822 - val_accuracy: 0.5640\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6580 - accuracy: 0.6244 - val_loss: 0.6809 - val_accuracy: 0.5676\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.6570 - accuracy: 0.6246 - val_loss: 0.6796 - val_accuracy: 0.5701\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 517us/step - loss: 0.6562 - accuracy: 0.6277 - val_loss: 0.6787 - val_accuracy: 0.5715\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 608us/step - loss: 0.6547 - accuracy: 0.6305 - val_loss: 0.6776 - val_accuracy: 0.5733\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 581us/step - loss: 0.6530 - accuracy: 0.6316 - val_loss: 0.6765 - val_accuracy: 0.5754\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 566us/step - loss: 0.6530 - accuracy: 0.6301 - val_loss: 0.6769 - val_accuracy: 0.5745\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 523us/step - loss: 0.6513 - accuracy: 0.6340 - val_loss: 0.6755 - val_accuracy: 0.5779\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6503 - accuracy: 0.6353 - val_loss: 0.6736 - val_accuracy: 0.5823\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 512us/step - loss: 0.6502 - accuracy: 0.6355 - val_loss: 0.6727 - val_accuracy: 0.5847\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 591us/step - loss: 0.6496 - accuracy: 0.6375 - val_loss: 0.6728 - val_accuracy: 0.5851\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 591us/step - loss: 0.6483 - accuracy: 0.6363 - val_loss: 0.6714 - val_accuracy: 0.5875\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 519us/step - loss: 0.6478 - accuracy: 0.6399 - val_loss: 0.6709 - val_accuracy: 0.5884\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6462 - accuracy: 0.6413 - val_loss: 0.6702 - val_accuracy: 0.5897\n",
      "\n",
      "Training model with batch_size=128...\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.1 iterated over 20900 steps satisfies differential privacy with eps = 2.01 and delta = 1e-05.\n",
      "The optimal RDP order is 12.0.\n",
      "Epoch 1/50\n",
      "365/418 [=========================>....] - ETA: 0s - loss: 0.8204 - accuracy: 0.5223WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "418/418 [==============================] - 0s 915us/step - loss: 0.8149 - accuracy: 0.5215 - val_loss: 1.0494 - val_accuracy: 0.1175\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 665us/step - loss: 0.7523 - accuracy: 0.5123 - val_loss: 0.9044 - val_accuracy: 0.1182\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 656us/step - loss: 0.7296 - accuracy: 0.4994 - val_loss: 0.8300 - val_accuracy: 0.1225\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 794us/step - loss: 0.7205 - accuracy: 0.4908 - val_loss: 0.7897 - val_accuracy: 0.1378\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 667us/step - loss: 0.7174 - accuracy: 0.4862 - val_loss: 0.7675 - val_accuracy: 0.1558\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 792us/step - loss: 0.7133 - accuracy: 0.4900 - val_loss: 0.7551 - val_accuracy: 0.1702\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 681us/step - loss: 0.7111 - accuracy: 0.4881 - val_loss: 0.7475 - val_accuracy: 0.1821\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 772us/step - loss: 0.7084 - accuracy: 0.4953 - val_loss: 0.7415 - val_accuracy: 0.1944\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 726us/step - loss: 0.7076 - accuracy: 0.4929 - val_loss: 0.7376 - val_accuracy: 0.2063\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 795us/step - loss: 0.7056 - accuracy: 0.4976 - val_loss: 0.7346 - val_accuracy: 0.2185\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 680us/step - loss: 0.7030 - accuracy: 0.5039 - val_loss: 0.7320 - val_accuracy: 0.2326\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 786us/step - loss: 0.7009 - accuracy: 0.5113 - val_loss: 0.7296 - val_accuracy: 0.2495\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 721us/step - loss: 0.6998 - accuracy: 0.5116 - val_loss: 0.7279 - val_accuracy: 0.2620\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 654us/step - loss: 0.6989 - accuracy: 0.5150 - val_loss: 0.7254 - val_accuracy: 0.2845\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 824us/step - loss: 0.6964 - accuracy: 0.5173 - val_loss: 0.7234 - val_accuracy: 0.3006\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 672us/step - loss: 0.6954 - accuracy: 0.5200 - val_loss: 0.7216 - val_accuracy: 0.3156\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 807us/step - loss: 0.6949 - accuracy: 0.5264 - val_loss: 0.7199 - val_accuracy: 0.3315\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 673us/step - loss: 0.6919 - accuracy: 0.5315 - val_loss: 0.7182 - val_accuracy: 0.3508\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 788us/step - loss: 0.6907 - accuracy: 0.5329 - val_loss: 0.7168 - val_accuracy: 0.3714\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 668us/step - loss: 0.6886 - accuracy: 0.5390 - val_loss: 0.7155 - val_accuracy: 0.3888\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 763us/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.7139 - val_accuracy: 0.4044\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 677us/step - loss: 0.6870 - accuracy: 0.5464 - val_loss: 0.7125 - val_accuracy: 0.4193\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 661us/step - loss: 0.6856 - accuracy: 0.5477 - val_loss: 0.7105 - val_accuracy: 0.4345\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 783us/step - loss: 0.6845 - accuracy: 0.5510 - val_loss: 0.7082 - val_accuracy: 0.4503\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 667us/step - loss: 0.6833 - accuracy: 0.5562 - val_loss: 0.7069 - val_accuracy: 0.4614\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 787us/step - loss: 0.6817 - accuracy: 0.5594 - val_loss: 0.7055 - val_accuracy: 0.4752\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 694us/step - loss: 0.6805 - accuracy: 0.5621 - val_loss: 0.7043 - val_accuracy: 0.4876\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 665us/step - loss: 0.6786 - accuracy: 0.5686 - val_loss: 0.7027 - val_accuracy: 0.5008\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 900us/step - loss: 0.6775 - accuracy: 0.5695 - val_loss: 0.7019 - val_accuracy: 0.5074\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 876us/step - loss: 0.6763 - accuracy: 0.5741 - val_loss: 0.7006 - val_accuracy: 0.5163\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 804us/step - loss: 0.6762 - accuracy: 0.5752 - val_loss: 0.6990 - val_accuracy: 0.5256\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 675us/step - loss: 0.6738 - accuracy: 0.5807 - val_loss: 0.6974 - val_accuracy: 0.5336\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 781us/step - loss: 0.6728 - accuracy: 0.5855 - val_loss: 0.6959 - val_accuracy: 0.5365\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 702us/step - loss: 0.6714 - accuracy: 0.5899 - val_loss: 0.6949 - val_accuracy: 0.5402\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 658us/step - loss: 0.6715 - accuracy: 0.5890 - val_loss: 0.6935 - val_accuracy: 0.5443\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 795us/step - loss: 0.6689 - accuracy: 0.5937 - val_loss: 0.6926 - val_accuracy: 0.5467\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 667us/step - loss: 0.6686 - accuracy: 0.5964 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 782us/step - loss: 0.6680 - accuracy: 0.5958 - val_loss: 0.6907 - val_accuracy: 0.5526\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 676us/step - loss: 0.6678 - accuracy: 0.5977 - val_loss: 0.6896 - val_accuracy: 0.5559\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6659 - accuracy: 0.6021 - val_loss: 0.6886 - val_accuracy: 0.5569\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 700us/step - loss: 0.6649 - accuracy: 0.6044 - val_loss: 0.6872 - val_accuracy: 0.5601\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 814us/step - loss: 0.6630 - accuracy: 0.6083 - val_loss: 0.6859 - val_accuracy: 0.5621\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 667us/step - loss: 0.6636 - accuracy: 0.6072 - val_loss: 0.6856 - val_accuracy: 0.5630\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 791us/step - loss: 0.6615 - accuracy: 0.6128 - val_loss: 0.6846 - val_accuracy: 0.5650\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 667us/step - loss: 0.6620 - accuracy: 0.6126 - val_loss: 0.6837 - val_accuracy: 0.5667\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.6610 - accuracy: 0.6137 - val_loss: 0.6831 - val_accuracy: 0.5683\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 692us/step - loss: 0.6598 - accuracy: 0.6158 - val_loss: 0.6819 - val_accuracy: 0.5707\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 789us/step - loss: 0.6588 - accuracy: 0.6169 - val_loss: 0.6811 - val_accuracy: 0.5715\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 678us/step - loss: 0.6597 - accuracy: 0.6143 - val_loss: 0.6797 - val_accuracy: 0.5734\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 790us/step - loss: 0.6573 - accuracy: 0.6209 - val_loss: 0.6790 - val_accuracy: 0.5738\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 794us/step - loss: 0.7180 - accuracy: 0.5058 - val_loss: 0.7034 - val_accuracy: 0.4430\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 806us/step - loss: 0.7144 - accuracy: 0.5128 - val_loss: 0.7086 - val_accuracy: 0.4202\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 742us/step - loss: 0.7132 - accuracy: 0.5138 - val_loss: 0.7096 - val_accuracy: 0.4155\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 807us/step - loss: 0.7107 - accuracy: 0.5187 - val_loss: 0.7092 - val_accuracy: 0.4172\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 741us/step - loss: 0.7083 - accuracy: 0.5238 - val_loss: 0.7078 - val_accuracy: 0.4274\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 701us/step - loss: 0.7048 - accuracy: 0.5268 - val_loss: 0.7090 - val_accuracy: 0.4283\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.7016 - accuracy: 0.5331 - val_loss: 0.7043 - val_accuracy: 0.4554\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 710us/step - loss: 0.6993 - accuracy: 0.5379 - val_loss: 0.7041 - val_accuracy: 0.4630\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6983 - accuracy: 0.5433 - val_loss: 0.7032 - val_accuracy: 0.4674\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 774us/step - loss: 0.6959 - accuracy: 0.5452 - val_loss: 0.7029 - val_accuracy: 0.4723\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6927 - accuracy: 0.5516 - val_loss: 0.7022 - val_accuracy: 0.4768\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 810us/step - loss: 0.6918 - accuracy: 0.5540 - val_loss: 0.7012 - val_accuracy: 0.4859\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 741us/step - loss: 0.6901 - accuracy: 0.5561 - val_loss: 0.6989 - val_accuracy: 0.5009\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 798us/step - loss: 0.6877 - accuracy: 0.5651 - val_loss: 0.6979 - val_accuracy: 0.5070\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 747us/step - loss: 0.6845 - accuracy: 0.5671 - val_loss: 0.6955 - val_accuracy: 0.5183\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 768us/step - loss: 0.6852 - accuracy: 0.5669 - val_loss: 0.6946 - val_accuracy: 0.5238\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 781us/step - loss: 0.6829 - accuracy: 0.5734 - val_loss: 0.6928 - val_accuracy: 0.5299\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 706us/step - loss: 0.6811 - accuracy: 0.5770 - val_loss: 0.6914 - val_accuracy: 0.5349\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6789 - accuracy: 0.5791 - val_loss: 0.6905 - val_accuracy: 0.5371\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 718us/step - loss: 0.6774 - accuracy: 0.5838 - val_loss: 0.6901 - val_accuracy: 0.5380\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6749 - accuracy: 0.5895 - val_loss: 0.6885 - val_accuracy: 0.5430\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 712us/step - loss: 0.6739 - accuracy: 0.5877 - val_loss: 0.6882 - val_accuracy: 0.5458\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 885us/step - loss: 0.6738 - accuracy: 0.5929 - val_loss: 0.6860 - val_accuracy: 0.5542\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 713us/step - loss: 0.6693 - accuracy: 0.6003 - val_loss: 0.6854 - val_accuracy: 0.5573\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 865us/step - loss: 0.6693 - accuracy: 0.5995 - val_loss: 0.6842 - val_accuracy: 0.5621\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 729us/step - loss: 0.6693 - accuracy: 0.6010 - val_loss: 0.6835 - val_accuracy: 0.5660\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 897us/step - loss: 0.6660 - accuracy: 0.6092 - val_loss: 0.6828 - val_accuracy: 0.5705\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 734us/step - loss: 0.6669 - accuracy: 0.6055 - val_loss: 0.6804 - val_accuracy: 0.5785\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6637 - accuracy: 0.6130 - val_loss: 0.6803 - val_accuracy: 0.5796\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 706us/step - loss: 0.6617 - accuracy: 0.6141 - val_loss: 0.6782 - val_accuracy: 0.5871\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6626 - accuracy: 0.6165 - val_loss: 0.6784 - val_accuracy: 0.5868\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 724us/step - loss: 0.6603 - accuracy: 0.6183 - val_loss: 0.6771 - val_accuracy: 0.5904\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 889us/step - loss: 0.6592 - accuracy: 0.6208 - val_loss: 0.6769 - val_accuracy: 0.5923\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 718us/step - loss: 0.6566 - accuracy: 0.6257 - val_loss: 0.6756 - val_accuracy: 0.5956\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6561 - accuracy: 0.6271 - val_loss: 0.6746 - val_accuracy: 0.5970\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 718us/step - loss: 0.6564 - accuracy: 0.6265 - val_loss: 0.6742 - val_accuracy: 0.5986\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 699us/step - loss: 0.6547 - accuracy: 0.6323 - val_loss: 0.6731 - val_accuracy: 0.6001\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.6524 - accuracy: 0.6362 - val_loss: 0.6724 - val_accuracy: 0.6012\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.6522 - accuracy: 0.6337 - val_loss: 0.6706 - val_accuracy: 0.6051\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 731us/step - loss: 0.6505 - accuracy: 0.6370 - val_loss: 0.6687 - val_accuracy: 0.6084\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.6492 - accuracy: 0.6365 - val_loss: 0.6700 - val_accuracy: 0.6051\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 726us/step - loss: 0.6497 - accuracy: 0.6391 - val_loss: 0.6688 - val_accuracy: 0.6064\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 831us/step - loss: 0.6470 - accuracy: 0.6413 - val_loss: 0.6676 - val_accuracy: 0.6080\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 717us/step - loss: 0.6459 - accuracy: 0.6430 - val_loss: 0.6674 - val_accuracy: 0.6070\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6445 - accuracy: 0.6447 - val_loss: 0.6669 - val_accuracy: 0.6077\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 703us/step - loss: 0.6450 - accuracy: 0.6471 - val_loss: 0.6665 - val_accuracy: 0.6069\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.6427 - accuracy: 0.6511 - val_loss: 0.6653 - val_accuracy: 0.6078\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 704us/step - loss: 0.6415 - accuracy: 0.6525 - val_loss: 0.6639 - val_accuracy: 0.6086\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 888us/step - loss: 0.6405 - accuracy: 0.6539 - val_loss: 0.6625 - val_accuracy: 0.6104\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6403 - accuracy: 0.6531 - val_loss: 0.6618 - val_accuracy: 0.6109\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 786us/step - loss: 0.7665 - accuracy: 0.4967 - val_loss: 0.5314 - val_accuracy: 0.8837\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 789us/step - loss: 0.7068 - accuracy: 0.5232 - val_loss: 0.5982 - val_accuracy: 0.8676\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 765us/step - loss: 0.6875 - accuracy: 0.5487 - val_loss: 0.6422 - val_accuracy: 0.7209\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 753us/step - loss: 0.6810 - accuracy: 0.5649 - val_loss: 0.6672 - val_accuracy: 0.6219\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 772us/step - loss: 0.6772 - accuracy: 0.5762 - val_loss: 0.6815 - val_accuracy: 0.5719\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 709us/step - loss: 0.6749 - accuracy: 0.5797 - val_loss: 0.6886 - val_accuracy: 0.5484\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 823us/step - loss: 0.6735 - accuracy: 0.5838 - val_loss: 0.6917 - val_accuracy: 0.5441\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 702us/step - loss: 0.6705 - accuracy: 0.5911 - val_loss: 0.6922 - val_accuracy: 0.5444\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6676 - accuracy: 0.5963 - val_loss: 0.6920 - val_accuracy: 0.5455\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 787us/step - loss: 0.6687 - accuracy: 0.5951 - val_loss: 0.6907 - val_accuracy: 0.5515\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 747us/step - loss: 0.6651 - accuracy: 0.5973 - val_loss: 0.6899 - val_accuracy: 0.5566\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 696us/step - loss: 0.6645 - accuracy: 0.6026 - val_loss: 0.6883 - val_accuracy: 0.5620\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6628 - accuracy: 0.6045 - val_loss: 0.6870 - val_accuracy: 0.5654\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 808us/step - loss: 0.6607 - accuracy: 0.6064 - val_loss: 0.6859 - val_accuracy: 0.5682\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 744us/step - loss: 0.6616 - accuracy: 0.6084 - val_loss: 0.6845 - val_accuracy: 0.5713\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 821us/step - loss: 0.6611 - accuracy: 0.6098 - val_loss: 0.6836 - val_accuracy: 0.5740\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 795us/step - loss: 0.6582 - accuracy: 0.6134 - val_loss: 0.6823 - val_accuracy: 0.5785\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6561 - accuracy: 0.6135 - val_loss: 0.6818 - val_accuracy: 0.5796\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 713us/step - loss: 0.6566 - accuracy: 0.6137 - val_loss: 0.6802 - val_accuracy: 0.5830\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.6550 - accuracy: 0.6190 - val_loss: 0.6790 - val_accuracy: 0.5864\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 706us/step - loss: 0.6534 - accuracy: 0.6214 - val_loss: 0.6773 - val_accuracy: 0.5908\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 831us/step - loss: 0.6534 - accuracy: 0.6216 - val_loss: 0.6762 - val_accuracy: 0.5941\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 900us/step - loss: 0.6524 - accuracy: 0.6211 - val_loss: 0.6748 - val_accuracy: 0.5964\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 726us/step - loss: 0.6504 - accuracy: 0.6252 - val_loss: 0.6737 - val_accuracy: 0.5979\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 795us/step - loss: 0.6501 - accuracy: 0.6271 - val_loss: 0.6729 - val_accuracy: 0.5987\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 738us/step - loss: 0.6483 - accuracy: 0.6289 - val_loss: 0.6718 - val_accuracy: 0.6009\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.6482 - accuracy: 0.6294 - val_loss: 0.6710 - val_accuracy: 0.6023\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 718us/step - loss: 0.6471 - accuracy: 0.6299 - val_loss: 0.6700 - val_accuracy: 0.6039\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 880us/step - loss: 0.6456 - accuracy: 0.6323 - val_loss: 0.6692 - val_accuracy: 0.6060\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 686us/step - loss: 0.6446 - accuracy: 0.6340 - val_loss: 0.6675 - val_accuracy: 0.6099\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 868us/step - loss: 0.6438 - accuracy: 0.6355 - val_loss: 0.6661 - val_accuracy: 0.6126\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 692us/step - loss: 0.6429 - accuracy: 0.6358 - val_loss: 0.6660 - val_accuracy: 0.6128\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 803us/step - loss: 0.6427 - accuracy: 0.6369 - val_loss: 0.6652 - val_accuracy: 0.6146\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 711us/step - loss: 0.6408 - accuracy: 0.6409 - val_loss: 0.6647 - val_accuracy: 0.6159\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 841us/step - loss: 0.6414 - accuracy: 0.6396 - val_loss: 0.6630 - val_accuracy: 0.6193\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 696us/step - loss: 0.6390 - accuracy: 0.6419 - val_loss: 0.6620 - val_accuracy: 0.6210\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6394 - accuracy: 0.6408 - val_loss: 0.6610 - val_accuracy: 0.6230\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 780us/step - loss: 0.6378 - accuracy: 0.6451 - val_loss: 0.6600 - val_accuracy: 0.6258\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 754us/step - loss: 0.6377 - accuracy: 0.6429 - val_loss: 0.6591 - val_accuracy: 0.6267\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 695us/step - loss: 0.6359 - accuracy: 0.6452 - val_loss: 0.6584 - val_accuracy: 0.6278\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6363 - accuracy: 0.6451 - val_loss: 0.6589 - val_accuracy: 0.6271\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 692us/step - loss: 0.6347 - accuracy: 0.6469 - val_loss: 0.6578 - val_accuracy: 0.6289\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 874us/step - loss: 0.6342 - accuracy: 0.6484 - val_loss: 0.6570 - val_accuracy: 0.6302\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6330 - accuracy: 0.6504 - val_loss: 0.6555 - val_accuracy: 0.6319\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 713us/step - loss: 0.6325 - accuracy: 0.6500 - val_loss: 0.6546 - val_accuracy: 0.6335\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.6307 - accuracy: 0.6502 - val_loss: 0.6541 - val_accuracy: 0.6347\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 713us/step - loss: 0.6309 - accuracy: 0.6535 - val_loss: 0.6527 - val_accuracy: 0.6370\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6302 - accuracy: 0.6530 - val_loss: 0.6517 - val_accuracy: 0.6384\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.6286 - accuracy: 0.6550 - val_loss: 0.6509 - val_accuracy: 0.6393\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 747us/step - loss: 0.6283 - accuracy: 0.6546 - val_loss: 0.6496 - val_accuracy: 0.6423\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 891us/step - loss: 0.6876 - accuracy: 0.5526 - val_loss: 0.7397 - val_accuracy: 0.2632\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 711us/step - loss: 0.6839 - accuracy: 0.5623 - val_loss: 0.7247 - val_accuracy: 0.3364\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 805us/step - loss: 0.6821 - accuracy: 0.5656 - val_loss: 0.7144 - val_accuracy: 0.3968\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 719us/step - loss: 0.6800 - accuracy: 0.5726 - val_loss: 0.7067 - val_accuracy: 0.4605\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 829us/step - loss: 0.6789 - accuracy: 0.5738 - val_loss: 0.7016 - val_accuracy: 0.4889\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 717us/step - loss: 0.6780 - accuracy: 0.5772 - val_loss: 0.6973 - val_accuracy: 0.5068\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6753 - accuracy: 0.5820 - val_loss: 0.6945 - val_accuracy: 0.5175\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.6755 - accuracy: 0.5827 - val_loss: 0.6919 - val_accuracy: 0.5274\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 722us/step - loss: 0.6736 - accuracy: 0.5870 - val_loss: 0.6893 - val_accuracy: 0.5365\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 829us/step - loss: 0.6727 - accuracy: 0.5878 - val_loss: 0.6877 - val_accuracy: 0.5422\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 708us/step - loss: 0.6715 - accuracy: 0.5938 - val_loss: 0.6858 - val_accuracy: 0.5485\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 880us/step - loss: 0.6691 - accuracy: 0.5993 - val_loss: 0.6842 - val_accuracy: 0.5519\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 713us/step - loss: 0.6683 - accuracy: 0.5990 - val_loss: 0.6823 - val_accuracy: 0.5574\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.6014 - val_loss: 0.6812 - val_accuracy: 0.5602\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 719us/step - loss: 0.6669 - accuracy: 0.6041 - val_loss: 0.6797 - val_accuracy: 0.5645\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6651 - accuracy: 0.6092 - val_loss: 0.6784 - val_accuracy: 0.5676\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 801us/step - loss: 0.6633 - accuracy: 0.6118 - val_loss: 0.6773 - val_accuracy: 0.5703\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 715us/step - loss: 0.6630 - accuracy: 0.6112 - val_loss: 0.6755 - val_accuracy: 0.5754\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 803us/step - loss: 0.6624 - accuracy: 0.6144 - val_loss: 0.6744 - val_accuracy: 0.5792\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 710us/step - loss: 0.6609 - accuracy: 0.6158 - val_loss: 0.6731 - val_accuracy: 0.5832\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 837us/step - loss: 0.6597 - accuracy: 0.6195 - val_loss: 0.6719 - val_accuracy: 0.5849\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6581 - accuracy: 0.6247 - val_loss: 0.6711 - val_accuracy: 0.5862\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 727us/step - loss: 0.6575 - accuracy: 0.6226 - val_loss: 0.6698 - val_accuracy: 0.5906\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.6558 - accuracy: 0.6247 - val_loss: 0.6683 - val_accuracy: 0.5963\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 769us/step - loss: 0.6552 - accuracy: 0.6295 - val_loss: 0.6678 - val_accuracy: 0.5980\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 746us/step - loss: 0.6557 - accuracy: 0.6261 - val_loss: 0.6672 - val_accuracy: 0.6002\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 675us/step - loss: 0.6538 - accuracy: 0.6314 - val_loss: 0.6659 - val_accuracy: 0.6030\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.6531 - accuracy: 0.6313 - val_loss: 0.6647 - val_accuracy: 0.6059\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 774us/step - loss: 0.6519 - accuracy: 0.6332 - val_loss: 0.6636 - val_accuracy: 0.6072\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6353 - val_loss: 0.6632 - val_accuracy: 0.6077\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 915us/step - loss: 0.6499 - accuracy: 0.6384 - val_loss: 0.6620 - val_accuracy: 0.6089\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 711us/step - loss: 0.6489 - accuracy: 0.6398 - val_loss: 0.6609 - val_accuracy: 0.6110\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 800us/step - loss: 0.6494 - accuracy: 0.6372 - val_loss: 0.6605 - val_accuracy: 0.6110\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.6475 - accuracy: 0.6400 - val_loss: 0.6600 - val_accuracy: 0.6112\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6460 - accuracy: 0.6431 - val_loss: 0.6595 - val_accuracy: 0.6119\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 753us/step - loss: 0.6460 - accuracy: 0.6429 - val_loss: 0.6592 - val_accuracy: 0.6112\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 770us/step - loss: 0.6458 - accuracy: 0.6445 - val_loss: 0.6589 - val_accuracy: 0.6113\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 678us/step - loss: 0.6444 - accuracy: 0.6471 - val_loss: 0.6582 - val_accuracy: 0.6119\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.6442 - accuracy: 0.6465 - val_loss: 0.6576 - val_accuracy: 0.6120\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6442 - accuracy: 0.6462 - val_loss: 0.6577 - val_accuracy: 0.6103\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 702us/step - loss: 0.6424 - accuracy: 0.6509 - val_loss: 0.6570 - val_accuracy: 0.6111\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 817us/step - loss: 0.6428 - accuracy: 0.6480 - val_loss: 0.6564 - val_accuracy: 0.6119\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 711us/step - loss: 0.6408 - accuracy: 0.6519 - val_loss: 0.6562 - val_accuracy: 0.6112\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 815us/step - loss: 0.6401 - accuracy: 0.6511 - val_loss: 0.6553 - val_accuracy: 0.6121\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 702us/step - loss: 0.6404 - accuracy: 0.6511 - val_loss: 0.6546 - val_accuracy: 0.6121\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6387 - accuracy: 0.6533 - val_loss: 0.6546 - val_accuracy: 0.6115\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 794us/step - loss: 0.6384 - accuracy: 0.6528 - val_loss: 0.6539 - val_accuracy: 0.6128\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 724us/step - loss: 0.6381 - accuracy: 0.6548 - val_loss: 0.6531 - val_accuracy: 0.6145\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6373 - accuracy: 0.6559 - val_loss: 0.6528 - val_accuracy: 0.6141\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 712us/step - loss: 0.6373 - accuracy: 0.6543 - val_loss: 0.6528 - val_accuracy: 0.6135\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.7178 - accuracy: 0.4913 - val_loss: 0.6695 - val_accuracy: 0.6094\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 686us/step - loss: 0.7121 - accuracy: 0.4951 - val_loss: 0.6914 - val_accuracy: 0.5008\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.7067 - accuracy: 0.5054 - val_loss: 0.7020 - val_accuracy: 0.4630\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 729us/step - loss: 0.7039 - accuracy: 0.5117 - val_loss: 0.7065 - val_accuracy: 0.4499\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.7008 - accuracy: 0.5164 - val_loss: 0.7080 - val_accuracy: 0.4570\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 697us/step - loss: 0.6977 - accuracy: 0.5235 - val_loss: 0.7076 - val_accuracy: 0.4761\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6964 - accuracy: 0.5234 - val_loss: 0.7061 - val_accuracy: 0.4899\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 706us/step - loss: 0.6936 - accuracy: 0.5310 - val_loss: 0.7055 - val_accuracy: 0.4894\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 831us/step - loss: 0.6925 - accuracy: 0.5336 - val_loss: 0.7033 - val_accuracy: 0.4931\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 768us/step - loss: 0.6903 - accuracy: 0.5372 - val_loss: 0.7025 - val_accuracy: 0.4911\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 753us/step - loss: 0.6877 - accuracy: 0.5451 - val_loss: 0.7004 - val_accuracy: 0.4953\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 695us/step - loss: 0.6876 - accuracy: 0.5415 - val_loss: 0.7002 - val_accuracy: 0.4953\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.6850 - accuracy: 0.5521 - val_loss: 0.6980 - val_accuracy: 0.4971\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 701us/step - loss: 0.6831 - accuracy: 0.5528 - val_loss: 0.6963 - val_accuracy: 0.5008\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 827us/step - loss: 0.6825 - accuracy: 0.5545 - val_loss: 0.6952 - val_accuracy: 0.4992\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 789us/step - loss: 0.6800 - accuracy: 0.5610 - val_loss: 0.6938 - val_accuracy: 0.4993\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 723us/step - loss: 0.6797 - accuracy: 0.5621 - val_loss: 0.6923 - val_accuracy: 0.5003\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.6773 - accuracy: 0.5655 - val_loss: 0.6917 - val_accuracy: 0.4996\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 721us/step - loss: 0.6775 - accuracy: 0.5667 - val_loss: 0.6904 - val_accuracy: 0.5007\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.6749 - accuracy: 0.5696 - val_loss: 0.6899 - val_accuracy: 0.5002\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6722 - accuracy: 0.5768 - val_loss: 0.6887 - val_accuracy: 0.5027\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 710us/step - loss: 0.6731 - accuracy: 0.5748 - val_loss: 0.6876 - val_accuracy: 0.5064\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6709 - accuracy: 0.5798 - val_loss: 0.6868 - val_accuracy: 0.5080\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 782us/step - loss: 0.6699 - accuracy: 0.5818 - val_loss: 0.6865 - val_accuracy: 0.5075\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 747us/step - loss: 0.6698 - accuracy: 0.5815 - val_loss: 0.6859 - val_accuracy: 0.5095\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 672us/step - loss: 0.6686 - accuracy: 0.5857 - val_loss: 0.6849 - val_accuracy: 0.5123\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.6682 - accuracy: 0.5844 - val_loss: 0.6835 - val_accuracy: 0.5175\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.6663 - accuracy: 0.5898 - val_loss: 0.6819 - val_accuracy: 0.5245\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 728us/step - loss: 0.6641 - accuracy: 0.5946 - val_loss: 0.6812 - val_accuracy: 0.5279\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 807us/step - loss: 0.6642 - accuracy: 0.5926 - val_loss: 0.6798 - val_accuracy: 0.5330\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 707us/step - loss: 0.6624 - accuracy: 0.5969 - val_loss: 0.6794 - val_accuracy: 0.5353\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6606 - accuracy: 0.5989 - val_loss: 0.6788 - val_accuracy: 0.5373\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 806us/step - loss: 0.6614 - accuracy: 0.5983 - val_loss: 0.6789 - val_accuracy: 0.5364\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 724us/step - loss: 0.6608 - accuracy: 0.6022 - val_loss: 0.6772 - val_accuracy: 0.5393\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6600 - accuracy: 0.5998 - val_loss: 0.6769 - val_accuracy: 0.5399\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 708us/step - loss: 0.6584 - accuracy: 0.6053 - val_loss: 0.6760 - val_accuracy: 0.5425\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 829us/step - loss: 0.6580 - accuracy: 0.6048 - val_loss: 0.6754 - val_accuracy: 0.5438\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 796us/step - loss: 0.6563 - accuracy: 0.6075 - val_loss: 0.6750 - val_accuracy: 0.5452\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 735us/step - loss: 0.6553 - accuracy: 0.6093 - val_loss: 0.6744 - val_accuracy: 0.5480\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 822us/step - loss: 0.6550 - accuracy: 0.6112 - val_loss: 0.6729 - val_accuracy: 0.5513\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 713us/step - loss: 0.6539 - accuracy: 0.6118 - val_loss: 0.6724 - val_accuracy: 0.5505\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6546 - accuracy: 0.6101 - val_loss: 0.6719 - val_accuracy: 0.5501\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6524 - accuracy: 0.6162 - val_loss: 0.6709 - val_accuracy: 0.5511\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 712us/step - loss: 0.6515 - accuracy: 0.6178 - val_loss: 0.6706 - val_accuracy: 0.5511\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6511 - accuracy: 0.6191 - val_loss: 0.6697 - val_accuracy: 0.5530\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6504 - accuracy: 0.6182 - val_loss: 0.6694 - val_accuracy: 0.5534\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 708us/step - loss: 0.6488 - accuracy: 0.6211 - val_loss: 0.6686 - val_accuracy: 0.5548\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 831us/step - loss: 0.6480 - accuracy: 0.6215 - val_loss: 0.6688 - val_accuracy: 0.5538\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 923us/step - loss: 0.6483 - accuracy: 0.6231 - val_loss: 0.6683 - val_accuracy: 0.5534\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 871us/step - loss: 0.6481 - accuracy: 0.6229 - val_loss: 0.6673 - val_accuracy: 0.5552\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6947 - accuracy: 0.5512 - val_loss: 0.6309 - val_accuracy: 0.7684\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5683 - val_loss: 0.6644 - val_accuracy: 0.6178\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6766 - accuracy: 0.5828 - val_loss: 0.6769 - val_accuracy: 0.5732\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.6744 - accuracy: 0.5879 - val_loss: 0.6809 - val_accuracy: 0.5624\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 816us/step - loss: 0.6700 - accuracy: 0.5937 - val_loss: 0.6788 - val_accuracy: 0.5656\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 915us/step - loss: 0.6654 - accuracy: 0.5990 - val_loss: 0.6771 - val_accuracy: 0.5739\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 897us/step - loss: 0.6633 - accuracy: 0.6025 - val_loss: 0.6744 - val_accuracy: 0.5816\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 892us/step - loss: 0.6609 - accuracy: 0.6071 - val_loss: 0.6708 - val_accuracy: 0.5913\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 774us/step - loss: 0.6599 - accuracy: 0.6066 - val_loss: 0.6695 - val_accuracy: 0.5935\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 942us/step - loss: 0.6549 - accuracy: 0.6144 - val_loss: 0.6672 - val_accuracy: 0.5986\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.6526 - accuracy: 0.6187 - val_loss: 0.6649 - val_accuracy: 0.6027\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.6534 - accuracy: 0.6176 - val_loss: 0.6642 - val_accuracy: 0.6023\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 863us/step - loss: 0.6515 - accuracy: 0.6217 - val_loss: 0.6634 - val_accuracy: 0.6033\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 857us/step - loss: 0.6478 - accuracy: 0.6247 - val_loss: 0.6615 - val_accuracy: 0.6061\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 904us/step - loss: 0.6474 - accuracy: 0.6260 - val_loss: 0.6594 - val_accuracy: 0.6104\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 782us/step - loss: 0.6435 - accuracy: 0.6318 - val_loss: 0.6592 - val_accuracy: 0.6099\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 897us/step - loss: 0.6443 - accuracy: 0.6313 - val_loss: 0.6579 - val_accuracy: 0.6115\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 779us/step - loss: 0.6426 - accuracy: 0.6334 - val_loss: 0.6579 - val_accuracy: 0.6112\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6418 - accuracy: 0.6338 - val_loss: 0.6568 - val_accuracy: 0.6136\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 774us/step - loss: 0.6393 - accuracy: 0.6411 - val_loss: 0.6561 - val_accuracy: 0.6156\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 898us/step - loss: 0.6383 - accuracy: 0.6407 - val_loss: 0.6543 - val_accuracy: 0.6192\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6407 - val_loss: 0.6538 - val_accuracy: 0.6205\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 979us/step - loss: 0.6345 - accuracy: 0.6479 - val_loss: 0.6535 - val_accuracy: 0.6200\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 893us/step - loss: 0.6358 - accuracy: 0.6446 - val_loss: 0.6523 - val_accuracy: 0.6219\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 763us/step - loss: 0.6322 - accuracy: 0.6487 - val_loss: 0.6509 - val_accuracy: 0.6232\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 883us/step - loss: 0.6331 - accuracy: 0.6463 - val_loss: 0.6490 - val_accuracy: 0.6273\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 775us/step - loss: 0.6324 - accuracy: 0.6480 - val_loss: 0.6491 - val_accuracy: 0.6263\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 885us/step - loss: 0.6306 - accuracy: 0.6503 - val_loss: 0.6474 - val_accuracy: 0.6294\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 752us/step - loss: 0.6315 - accuracy: 0.6494 - val_loss: 0.6469 - val_accuracy: 0.6289\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 876us/step - loss: 0.6291 - accuracy: 0.6527 - val_loss: 0.6471 - val_accuracy: 0.6282\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 761us/step - loss: 0.6297 - accuracy: 0.6524 - val_loss: 0.6464 - val_accuracy: 0.6282\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.6269 - accuracy: 0.6528 - val_loss: 0.6441 - val_accuracy: 0.6311\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 755us/step - loss: 0.6261 - accuracy: 0.6539 - val_loss: 0.6443 - val_accuracy: 0.6305\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.6253 - accuracy: 0.6574 - val_loss: 0.6442 - val_accuracy: 0.6297\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6238 - accuracy: 0.6576 - val_loss: 0.6437 - val_accuracy: 0.6305\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 780us/step - loss: 0.6227 - accuracy: 0.6595 - val_loss: 0.6434 - val_accuracy: 0.6305\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.6233 - accuracy: 0.6596 - val_loss: 0.6416 - val_accuracy: 0.6322\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 766us/step - loss: 0.6229 - accuracy: 0.6588 - val_loss: 0.6409 - val_accuracy: 0.6324\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 902us/step - loss: 0.6211 - accuracy: 0.6589 - val_loss: 0.6405 - val_accuracy: 0.6330\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 770us/step - loss: 0.6199 - accuracy: 0.6619 - val_loss: 0.6397 - val_accuracy: 0.6334\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.6203 - accuracy: 0.6620 - val_loss: 0.6396 - val_accuracy: 0.6335\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 791us/step - loss: 0.6190 - accuracy: 0.6641 - val_loss: 0.6388 - val_accuracy: 0.6352\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 913us/step - loss: 0.6180 - accuracy: 0.6636 - val_loss: 0.6378 - val_accuracy: 0.6367\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 767us/step - loss: 0.6178 - accuracy: 0.6654 - val_loss: 0.6368 - val_accuracy: 0.6385\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 891us/step - loss: 0.6161 - accuracy: 0.6668 - val_loss: 0.6366 - val_accuracy: 0.6385\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 794us/step - loss: 0.6167 - accuracy: 0.6650 - val_loss: 0.6364 - val_accuracy: 0.6386\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6155 - accuracy: 0.6671 - val_loss: 0.6358 - val_accuracy: 0.6403\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 761us/step - loss: 0.6148 - accuracy: 0.6672 - val_loss: 0.6343 - val_accuracy: 0.6440\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 875us/step - loss: 0.6153 - accuracy: 0.6652 - val_loss: 0.6347 - val_accuracy: 0.6423\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 739us/step - loss: 0.6128 - accuracy: 0.6708 - val_loss: 0.6349 - val_accuracy: 0.6412\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 868us/step - loss: 0.7124 - accuracy: 0.5062 - val_loss: 0.6279 - val_accuracy: 0.8441\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.7039 - accuracy: 0.5162 - val_loss: 0.6564 - val_accuracy: 0.7506\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 780us/step - loss: 0.7002 - accuracy: 0.5173 - val_loss: 0.6727 - val_accuracy: 0.6594\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 893us/step - loss: 0.6963 - accuracy: 0.5239 - val_loss: 0.6825 - val_accuracy: 0.5925\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 729us/step - loss: 0.6954 - accuracy: 0.5233 - val_loss: 0.6879 - val_accuracy: 0.5676\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 863us/step - loss: 0.6933 - accuracy: 0.5302 - val_loss: 0.6904 - val_accuracy: 0.5573\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 799us/step - loss: 0.6904 - accuracy: 0.5355 - val_loss: 0.6919 - val_accuracy: 0.5503\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 876us/step - loss: 0.6895 - accuracy: 0.5388 - val_loss: 0.6926 - val_accuracy: 0.5474\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 733us/step - loss: 0.6888 - accuracy: 0.5404 - val_loss: 0.6925 - val_accuracy: 0.5488\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 898us/step - loss: 0.6882 - accuracy: 0.5413 - val_loss: 0.6920 - val_accuracy: 0.5511\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 742us/step - loss: 0.6850 - accuracy: 0.5463 - val_loss: 0.6909 - val_accuracy: 0.5568\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 890us/step - loss: 0.6837 - accuracy: 0.5494 - val_loss: 0.6906 - val_accuracy: 0.5578\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 744us/step - loss: 0.6846 - accuracy: 0.5480 - val_loss: 0.6902 - val_accuracy: 0.5587\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 880us/step - loss: 0.6830 - accuracy: 0.5544 - val_loss: 0.6897 - val_accuracy: 0.5598\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 885us/step - loss: 0.6815 - accuracy: 0.5555 - val_loss: 0.6890 - val_accuracy: 0.5624\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 756us/step - loss: 0.6805 - accuracy: 0.5576 - val_loss: 0.6889 - val_accuracy: 0.5607\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 892us/step - loss: 0.6793 - accuracy: 0.5603 - val_loss: 0.6876 - val_accuracy: 0.5642\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 874us/step - loss: 0.6792 - accuracy: 0.5607 - val_loss: 0.6867 - val_accuracy: 0.5683\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 744us/step - loss: 0.6778 - accuracy: 0.5641 - val_loss: 0.6860 - val_accuracy: 0.5687\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 733us/step - loss: 0.6779 - accuracy: 0.5632 - val_loss: 0.6861 - val_accuracy: 0.5686\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 907us/step - loss: 0.6762 - accuracy: 0.5676 - val_loss: 0.6855 - val_accuracy: 0.5693\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.6758 - accuracy: 0.5680 - val_loss: 0.6847 - val_accuracy: 0.5717\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 779us/step - loss: 0.6750 - accuracy: 0.5738 - val_loss: 0.6843 - val_accuracy: 0.5723\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 868us/step - loss: 0.6738 - accuracy: 0.5761 - val_loss: 0.6838 - val_accuracy: 0.5730\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 743us/step - loss: 0.6733 - accuracy: 0.5749 - val_loss: 0.6838 - val_accuracy: 0.5727\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6727 - accuracy: 0.5778 - val_loss: 0.6827 - val_accuracy: 0.5761\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 791us/step - loss: 0.6713 - accuracy: 0.5792 - val_loss: 0.6824 - val_accuracy: 0.5762\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6707 - accuracy: 0.5807 - val_loss: 0.6816 - val_accuracy: 0.5779\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 774us/step - loss: 0.6700 - accuracy: 0.5825 - val_loss: 0.6818 - val_accuracy: 0.5764\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 870us/step - loss: 0.6692 - accuracy: 0.5834 - val_loss: 0.6813 - val_accuracy: 0.5774\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 756us/step - loss: 0.6697 - accuracy: 0.5844 - val_loss: 0.6806 - val_accuracy: 0.5799\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 912us/step - loss: 0.6675 - accuracy: 0.5882 - val_loss: 0.6798 - val_accuracy: 0.5824\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 747us/step - loss: 0.6669 - accuracy: 0.5899 - val_loss: 0.6789 - val_accuracy: 0.5849\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.6667 - accuracy: 0.5885 - val_loss: 0.6787 - val_accuracy: 0.5842\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 750us/step - loss: 0.6661 - accuracy: 0.5891 - val_loss: 0.6777 - val_accuracy: 0.5870\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 883us/step - loss: 0.6655 - accuracy: 0.5919 - val_loss: 0.6775 - val_accuracy: 0.5866\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 739us/step - loss: 0.6647 - accuracy: 0.5927 - val_loss: 0.6771 - val_accuracy: 0.5881\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.6650 - accuracy: 0.5949 - val_loss: 0.6765 - val_accuracy: 0.5901\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 759us/step - loss: 0.6629 - accuracy: 0.5991 - val_loss: 0.6757 - val_accuracy: 0.5929\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.6620 - accuracy: 0.5997 - val_loss: 0.6750 - val_accuracy: 0.5942\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 875us/step - loss: 0.6617 - accuracy: 0.6020 - val_loss: 0.6745 - val_accuracy: 0.5954\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 794us/step - loss: 0.6623 - accuracy: 0.6008 - val_loss: 0.6736 - val_accuracy: 0.5978\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 888us/step - loss: 0.6599 - accuracy: 0.6049 - val_loss: 0.6734 - val_accuracy: 0.5973\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 736us/step - loss: 0.6596 - accuracy: 0.6032 - val_loss: 0.6728 - val_accuracy: 0.5990\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 882us/step - loss: 0.6597 - accuracy: 0.6039 - val_loss: 0.6719 - val_accuracy: 0.5999\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 742us/step - loss: 0.6580 - accuracy: 0.6097 - val_loss: 0.6723 - val_accuracy: 0.5975\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.6581 - accuracy: 0.6096 - val_loss: 0.6709 - val_accuracy: 0.6018\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 735us/step - loss: 0.6574 - accuracy: 0.6082 - val_loss: 0.6712 - val_accuracy: 0.5996\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 867us/step - loss: 0.6572 - accuracy: 0.6091 - val_loss: 0.6700 - val_accuracy: 0.6026\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6097 - val_loss: 0.6692 - val_accuracy: 0.6040\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 880us/step - loss: 0.7786 - accuracy: 0.5213 - val_loss: 1.0063 - val_accuracy: 0.1195\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 873us/step - loss: 0.7371 - accuracy: 0.5177 - val_loss: 0.8958 - val_accuracy: 0.1221\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 747us/step - loss: 0.7191 - accuracy: 0.5145 - val_loss: 0.8332 - val_accuracy: 0.1266\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 875us/step - loss: 0.7108 - accuracy: 0.5104 - val_loss: 0.7969 - val_accuracy: 0.1425\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 755us/step - loss: 0.7067 - accuracy: 0.5088 - val_loss: 0.7735 - val_accuracy: 0.1676\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 901us/step - loss: 0.7034 - accuracy: 0.5115 - val_loss: 0.7588 - val_accuracy: 0.2055\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 761us/step - loss: 0.7017 - accuracy: 0.5098 - val_loss: 0.7497 - val_accuracy: 0.2331\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 886us/step - loss: 0.7002 - accuracy: 0.5135 - val_loss: 0.7424 - val_accuracy: 0.2624\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 877us/step - loss: 0.6978 - accuracy: 0.5169 - val_loss: 0.7376 - val_accuracy: 0.2824\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 806us/step - loss: 0.6961 - accuracy: 0.5193 - val_loss: 0.7338 - val_accuracy: 0.2992\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 901us/step - loss: 0.6948 - accuracy: 0.5256 - val_loss: 0.7309 - val_accuracy: 0.3136\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 771us/step - loss: 0.6931 - accuracy: 0.5300 - val_loss: 0.7285 - val_accuracy: 0.3277\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 871us/step - loss: 0.6912 - accuracy: 0.5345 - val_loss: 0.7261 - val_accuracy: 0.3451\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 886us/step - loss: 0.6905 - accuracy: 0.5364 - val_loss: 0.7243 - val_accuracy: 0.3598\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 790us/step - loss: 0.6884 - accuracy: 0.5404 - val_loss: 0.7229 - val_accuracy: 0.3768\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 867us/step - loss: 0.6883 - accuracy: 0.5408 - val_loss: 0.7215 - val_accuracy: 0.3931\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 775us/step - loss: 0.6859 - accuracy: 0.5479 - val_loss: 0.7197 - val_accuracy: 0.4042\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6870 - accuracy: 0.5441 - val_loss: 0.7189 - val_accuracy: 0.4140\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 805us/step - loss: 0.6848 - accuracy: 0.5508 - val_loss: 0.7181 - val_accuracy: 0.4209\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 872us/step - loss: 0.6837 - accuracy: 0.5572 - val_loss: 0.7172 - val_accuracy: 0.4327\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 763us/step - loss: 0.6824 - accuracy: 0.5591 - val_loss: 0.7161 - val_accuracy: 0.4424\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.6802 - accuracy: 0.5615 - val_loss: 0.7154 - val_accuracy: 0.4496\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 781us/step - loss: 0.6796 - accuracy: 0.5640 - val_loss: 0.7140 - val_accuracy: 0.4614\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 883us/step - loss: 0.6792 - accuracy: 0.5661 - val_loss: 0.7128 - val_accuracy: 0.4685\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 779us/step - loss: 0.6794 - accuracy: 0.5672 - val_loss: 0.7118 - val_accuracy: 0.4767\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 901us/step - loss: 0.6773 - accuracy: 0.5717 - val_loss: 0.7112 - val_accuracy: 0.4797\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.6761 - accuracy: 0.5738 - val_loss: 0.7102 - val_accuracy: 0.4857\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.6757 - accuracy: 0.5772 - val_loss: 0.7095 - val_accuracy: 0.4884\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 906us/step - loss: 0.6748 - accuracy: 0.5790 - val_loss: 0.7088 - val_accuracy: 0.4903\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 789us/step - loss: 0.6743 - accuracy: 0.5795 - val_loss: 0.7079 - val_accuracy: 0.4959\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 889us/step - loss: 0.6733 - accuracy: 0.5850 - val_loss: 0.7067 - val_accuracy: 0.5005\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 766us/step - loss: 0.6727 - accuracy: 0.5869 - val_loss: 0.7058 - val_accuracy: 0.5050\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.6713 - accuracy: 0.5876 - val_loss: 0.7055 - val_accuracy: 0.5077\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 892us/step - loss: 0.6704 - accuracy: 0.5921 - val_loss: 0.7043 - val_accuracy: 0.5133\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 766us/step - loss: 0.6700 - accuracy: 0.5928 - val_loss: 0.7032 - val_accuracy: 0.5186\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 897us/step - loss: 0.6698 - accuracy: 0.5941 - val_loss: 0.7026 - val_accuracy: 0.5215\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 775us/step - loss: 0.6689 - accuracy: 0.5943 - val_loss: 0.7021 - val_accuracy: 0.5224\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 914us/step - loss: 0.6682 - accuracy: 0.5971 - val_loss: 0.7010 - val_accuracy: 0.5259\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 857us/step - loss: 0.6674 - accuracy: 0.6005 - val_loss: 0.7003 - val_accuracy: 0.5297\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 783us/step - loss: 0.6672 - accuracy: 0.5994 - val_loss: 0.6995 - val_accuracy: 0.5336\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 904us/step - loss: 0.6660 - accuracy: 0.6027 - val_loss: 0.6984 - val_accuracy: 0.5383\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 765us/step - loss: 0.6647 - accuracy: 0.6049 - val_loss: 0.6978 - val_accuracy: 0.5406\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 868us/step - loss: 0.6642 - accuracy: 0.6048 - val_loss: 0.6970 - val_accuracy: 0.5445\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 762us/step - loss: 0.6633 - accuracy: 0.6077 - val_loss: 0.6963 - val_accuracy: 0.5472\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 894us/step - loss: 0.6631 - accuracy: 0.6099 - val_loss: 0.6956 - val_accuracy: 0.5488\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 778us/step - loss: 0.6619 - accuracy: 0.6114 - val_loss: 0.6950 - val_accuracy: 0.5505\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 913us/step - loss: 0.6616 - accuracy: 0.6120 - val_loss: 0.6942 - val_accuracy: 0.5525\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.6610 - accuracy: 0.6144 - val_loss: 0.6934 - val_accuracy: 0.5541\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 803us/step - loss: 0.6611 - accuracy: 0.6124 - val_loss: 0.6926 - val_accuracy: 0.5563\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 928us/step - loss: 0.6601 - accuracy: 0.6150 - val_loss: 0.6923 - val_accuracy: 0.5582\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 991us/step - loss: 0.7517 - accuracy: 0.4777 - val_loss: 0.6330 - val_accuracy: 0.7402\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 755us/step - loss: 0.7304 - accuracy: 0.4806 - val_loss: 0.6828 - val_accuracy: 0.5635\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 878us/step - loss: 0.7225 - accuracy: 0.4840 - val_loss: 0.7096 - val_accuracy: 0.4395\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 779us/step - loss: 0.7174 - accuracy: 0.4940 - val_loss: 0.7225 - val_accuracy: 0.3745\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.7163 - accuracy: 0.4938 - val_loss: 0.7279 - val_accuracy: 0.3471\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 787us/step - loss: 0.7125 - accuracy: 0.5004 - val_loss: 0.7298 - val_accuracy: 0.3374\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 887us/step - loss: 0.7114 - accuracy: 0.5027 - val_loss: 0.7307 - val_accuracy: 0.3362\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 763us/step - loss: 0.7090 - accuracy: 0.5059 - val_loss: 0.7305 - val_accuracy: 0.3390\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 882us/step - loss: 0.7080 - accuracy: 0.5051 - val_loss: 0.7287 - val_accuracy: 0.3491\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.7042 - accuracy: 0.5102 - val_loss: 0.7264 - val_accuracy: 0.3598\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 811us/step - loss: 0.7038 - accuracy: 0.5130 - val_loss: 0.7257 - val_accuracy: 0.3613\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.7029 - accuracy: 0.5156 - val_loss: 0.7248 - val_accuracy: 0.3678\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 771us/step - loss: 0.7004 - accuracy: 0.5219 - val_loss: 0.7236 - val_accuracy: 0.3751\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.6996 - accuracy: 0.5212 - val_loss: 0.7218 - val_accuracy: 0.3841\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 769us/step - loss: 0.6977 - accuracy: 0.5235 - val_loss: 0.7212 - val_accuracy: 0.3873\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 923us/step - loss: 0.6965 - accuracy: 0.5277 - val_loss: 0.7199 - val_accuracy: 0.3918\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 883us/step - loss: 0.6937 - accuracy: 0.5337 - val_loss: 0.7187 - val_accuracy: 0.3993\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 779us/step - loss: 0.6939 - accuracy: 0.5335 - val_loss: 0.7175 - val_accuracy: 0.4083\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6934 - accuracy: 0.5366 - val_loss: 0.7164 - val_accuracy: 0.4149\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 925us/step - loss: 0.6912 - accuracy: 0.5382 - val_loss: 0.7142 - val_accuracy: 0.4259\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 802us/step - loss: 0.6899 - accuracy: 0.5397 - val_loss: 0.7142 - val_accuracy: 0.4312\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5407 - val_loss: 0.7125 - val_accuracy: 0.4426\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 979us/step - loss: 0.6876 - accuracy: 0.5430 - val_loss: 0.7113 - val_accuracy: 0.4502\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 912us/step - loss: 0.6867 - accuracy: 0.5469 - val_loss: 0.7100 - val_accuracy: 0.4579\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 791us/step - loss: 0.6855 - accuracy: 0.5509 - val_loss: 0.7095 - val_accuracy: 0.4589\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 872us/step - loss: 0.6845 - accuracy: 0.5542 - val_loss: 0.7079 - val_accuracy: 0.4688\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 789us/step - loss: 0.6832 - accuracy: 0.5581 - val_loss: 0.7069 - val_accuracy: 0.4730\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 900us/step - loss: 0.6831 - accuracy: 0.5575 - val_loss: 0.7064 - val_accuracy: 0.4745\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 767us/step - loss: 0.6811 - accuracy: 0.5629 - val_loss: 0.7050 - val_accuracy: 0.4815\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 901us/step - loss: 0.6809 - accuracy: 0.5622 - val_loss: 0.7035 - val_accuracy: 0.4881\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 769us/step - loss: 0.6803 - accuracy: 0.5633 - val_loss: 0.7031 - val_accuracy: 0.4893\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 915us/step - loss: 0.6782 - accuracy: 0.5675 - val_loss: 0.7026 - val_accuracy: 0.4930\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 904us/step - loss: 0.6776 - accuracy: 0.5701 - val_loss: 0.7009 - val_accuracy: 0.5022\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 779us/step - loss: 0.6770 - accuracy: 0.5700 - val_loss: 0.7006 - val_accuracy: 0.5034\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6761 - accuracy: 0.5726 - val_loss: 0.6992 - val_accuracy: 0.5082\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 810us/step - loss: 0.6755 - accuracy: 0.5739 - val_loss: 0.6987 - val_accuracy: 0.5095\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6743 - accuracy: 0.5758 - val_loss: 0.6978 - val_accuracy: 0.5119\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 794us/step - loss: 0.6710 - accuracy: 0.5862 - val_loss: 0.6973 - val_accuracy: 0.5131\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6719 - accuracy: 0.5849 - val_loss: 0.6967 - val_accuracy: 0.5158\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 901us/step - loss: 0.6702 - accuracy: 0.5866 - val_loss: 0.6952 - val_accuracy: 0.5200\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.6712 - accuracy: 0.5850 - val_loss: 0.6947 - val_accuracy: 0.5208\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 918us/step - loss: 0.6702 - accuracy: 0.5880 - val_loss: 0.6948 - val_accuracy: 0.5210\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6689 - accuracy: 0.5900 - val_loss: 0.6934 - val_accuracy: 0.5249\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 962us/step - loss: 0.6690 - accuracy: 0.5903 - val_loss: 0.6914 - val_accuracy: 0.5320\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 777us/step - loss: 0.6670 - accuracy: 0.5969 - val_loss: 0.6913 - val_accuracy: 0.5329\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 878us/step - loss: 0.6663 - accuracy: 0.5976 - val_loss: 0.6904 - val_accuracy: 0.5370\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6644 - accuracy: 0.6028 - val_loss: 0.6898 - val_accuracy: 0.5399\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 761us/step - loss: 0.6649 - accuracy: 0.5975 - val_loss: 0.6890 - val_accuracy: 0.5434\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 911us/step - loss: 0.6637 - accuracy: 0.6023 - val_loss: 0.6881 - val_accuracy: 0.5461\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6635 - accuracy: 0.6015 - val_loss: 0.6871 - val_accuracy: 0.5487\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.7020 - accuracy: 0.5415 - val_loss: 0.8161 - val_accuracy: 0.2263\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 865us/step - loss: 0.6900 - accuracy: 0.5523 - val_loss: 0.7673 - val_accuracy: 0.3259\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 780us/step - loss: 0.6843 - accuracy: 0.5589 - val_loss: 0.7392 - val_accuracy: 0.4020\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 909us/step - loss: 0.6824 - accuracy: 0.5632 - val_loss: 0.7222 - val_accuracy: 0.4419\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 898us/step - loss: 0.6804 - accuracy: 0.5686 - val_loss: 0.7124 - val_accuracy: 0.4762\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 784us/step - loss: 0.6791 - accuracy: 0.5710 - val_loss: 0.7056 - val_accuracy: 0.4967\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 906us/step - loss: 0.6792 - accuracy: 0.5733 - val_loss: 0.7018 - val_accuracy: 0.5081\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 762us/step - loss: 0.6778 - accuracy: 0.5758 - val_loss: 0.6992 - val_accuracy: 0.5179\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 870us/step - loss: 0.6767 - accuracy: 0.5826 - val_loss: 0.6976 - val_accuracy: 0.5255\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 778us/step - loss: 0.6765 - accuracy: 0.5790 - val_loss: 0.6966 - val_accuracy: 0.5299\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 912us/step - loss: 0.6739 - accuracy: 0.5852 - val_loss: 0.6959 - val_accuracy: 0.5335\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 798us/step - loss: 0.6745 - accuracy: 0.5835 - val_loss: 0.6945 - val_accuracy: 0.5394\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 958us/step - loss: 0.6730 - accuracy: 0.5872 - val_loss: 0.6940 - val_accuracy: 0.5411\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6712 - accuracy: 0.5910 - val_loss: 0.6936 - val_accuracy: 0.5417\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 827us/step - loss: 0.6714 - accuracy: 0.5907 - val_loss: 0.6932 - val_accuracy: 0.5429\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 875us/step - loss: 0.6706 - accuracy: 0.5915 - val_loss: 0.6925 - val_accuracy: 0.5469\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 788us/step - loss: 0.6706 - accuracy: 0.5949 - val_loss: 0.6913 - val_accuracy: 0.5524\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 952us/step - loss: 0.6697 - accuracy: 0.5955 - val_loss: 0.6909 - val_accuracy: 0.5524\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 775us/step - loss: 0.6693 - accuracy: 0.5990 - val_loss: 0.6903 - val_accuracy: 0.5535\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.6687 - accuracy: 0.5964 - val_loss: 0.6895 - val_accuracy: 0.5565\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6668 - accuracy: 0.5996 - val_loss: 0.6891 - val_accuracy: 0.5573\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6038 - val_loss: 0.6884 - val_accuracy: 0.5597\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 843us/step - loss: 0.6663 - accuracy: 0.6049 - val_loss: 0.6879 - val_accuracy: 0.5607\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.6659 - accuracy: 0.6031 - val_loss: 0.6876 - val_accuracy: 0.5612\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 682us/step - loss: 0.6640 - accuracy: 0.6126 - val_loss: 0.6868 - val_accuracy: 0.5636\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6639 - accuracy: 0.6085 - val_loss: 0.6859 - val_accuracy: 0.5653\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 764us/step - loss: 0.6630 - accuracy: 0.6126 - val_loss: 0.6855 - val_accuracy: 0.5653\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 758us/step - loss: 0.6619 - accuracy: 0.6124 - val_loss: 0.6849 - val_accuracy: 0.5664\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.6611 - accuracy: 0.6154 - val_loss: 0.6845 - val_accuracy: 0.5664\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 690us/step - loss: 0.6612 - accuracy: 0.6155 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.6591 - accuracy: 0.6207 - val_loss: 0.6832 - val_accuracy: 0.5685\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 804us/step - loss: 0.6589 - accuracy: 0.6228 - val_loss: 0.6826 - val_accuracy: 0.5696\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 706us/step - loss: 0.6590 - accuracy: 0.6189 - val_loss: 0.6823 - val_accuracy: 0.5706\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 719us/step - loss: 0.6584 - accuracy: 0.6214 - val_loss: 0.6809 - val_accuracy: 0.5747\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 800us/step - loss: 0.6578 - accuracy: 0.6241 - val_loss: 0.6810 - val_accuracy: 0.5738\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6569 - accuracy: 0.6255 - val_loss: 0.6806 - val_accuracy: 0.5748\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6567 - accuracy: 0.6266 - val_loss: 0.6803 - val_accuracy: 0.5751\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.6556 - accuracy: 0.6282 - val_loss: 0.6800 - val_accuracy: 0.5762\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 736us/step - loss: 0.6537 - accuracy: 0.6300 - val_loss: 0.6791 - val_accuracy: 0.5776\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 841us/step - loss: 0.6533 - accuracy: 0.6339 - val_loss: 0.6786 - val_accuracy: 0.5790\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 812us/step - loss: 0.6540 - accuracy: 0.6309 - val_loss: 0.6784 - val_accuracy: 0.5791\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 715us/step - loss: 0.6532 - accuracy: 0.6326 - val_loss: 0.6772 - val_accuracy: 0.5810\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.6522 - accuracy: 0.6343 - val_loss: 0.6767 - val_accuracy: 0.5818\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6514 - accuracy: 0.6357 - val_loss: 0.6762 - val_accuracy: 0.5822\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 804us/step - loss: 0.6511 - accuracy: 0.6369 - val_loss: 0.6760 - val_accuracy: 0.5820\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 750us/step - loss: 0.6498 - accuracy: 0.6403 - val_loss: 0.6758 - val_accuracy: 0.5817\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 804us/step - loss: 0.6506 - accuracy: 0.6382 - val_loss: 0.6749 - val_accuracy: 0.5828\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 802us/step - loss: 0.6493 - accuracy: 0.6401 - val_loss: 0.6741 - val_accuracy: 0.5837\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 744us/step - loss: 0.6471 - accuracy: 0.6443 - val_loss: 0.6735 - val_accuracy: 0.5852\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6417 - val_loss: 0.6727 - val_accuracy: 0.5859\n"
     ]
    }
   ],
   "source": [
    "# Run experiments varying parameters\n",
    "delta = 1e-5\n",
    "\n",
    "# 1. Vary batch_size\n",
    "results_batch_size = {}\n",
    "eps_batch_size = {}\n",
    "for bs in batch_size_values:\n",
    "    print(f\"\\nTraining model with batch_size={bs}...\")\n",
    "    n = len(X_train_filtered)\n",
    "    eps = compute_privacy_budget(n, bs, default_noise_multiplier, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "        batch_size=bs, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_batch_size[bs] = compute_statistics(results)\n",
    "    eps_batch_size[bs] = eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4efc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with sample_size_ratio=1...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.7118 - accuracy: 0.5099 - val_loss: 0.7417 - val_accuracy: 0.2258\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6983 - accuracy: 0.5202 - val_loss: 0.7142 - val_accuracy: 0.3298\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6917 - accuracy: 0.5344 - val_loss: 0.7104 - val_accuracy: 0.3550\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6871 - accuracy: 0.5467 - val_loss: 0.7082 - val_accuracy: 0.3727\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6835 - accuracy: 0.5575 - val_loss: 0.7029 - val_accuracy: 0.4202\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6798 - accuracy: 0.5679 - val_loss: 0.7030 - val_accuracy: 0.4315\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6769 - accuracy: 0.5747 - val_loss: 0.6984 - val_accuracy: 0.4518\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6737 - accuracy: 0.5877 - val_loss: 0.6935 - val_accuracy: 0.4762\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6714 - accuracy: 0.5943 - val_loss: 0.6919 - val_accuracy: 0.4878\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6673 - accuracy: 0.6042 - val_loss: 0.6884 - val_accuracy: 0.5124\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6644 - accuracy: 0.6081 - val_loss: 0.6850 - val_accuracy: 0.5353\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6617 - accuracy: 0.6156 - val_loss: 0.6846 - val_accuracy: 0.5426\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6589 - accuracy: 0.6209 - val_loss: 0.6805 - val_accuracy: 0.5589\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6565 - accuracy: 0.6257 - val_loss: 0.6764 - val_accuracy: 0.5762\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6544 - accuracy: 0.6291 - val_loss: 0.6775 - val_accuracy: 0.5734\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6520 - accuracy: 0.6355 - val_loss: 0.6765 - val_accuracy: 0.5782\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6489 - accuracy: 0.6414 - val_loss: 0.6718 - val_accuracy: 0.5885\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6468 - accuracy: 0.6430 - val_loss: 0.6722 - val_accuracy: 0.5882\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6444 - accuracy: 0.6477 - val_loss: 0.6680 - val_accuracy: 0.5950\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6420 - accuracy: 0.6514 - val_loss: 0.6681 - val_accuracy: 0.5946\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6398 - accuracy: 0.6530 - val_loss: 0.6657 - val_accuracy: 0.5989\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6370 - accuracy: 0.6551 - val_loss: 0.6589 - val_accuracy: 0.6145\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6357 - accuracy: 0.6593 - val_loss: 0.6645 - val_accuracy: 0.6010\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6341 - accuracy: 0.6565 - val_loss: 0.6593 - val_accuracy: 0.6106\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 421us/step - loss: 0.6302 - accuracy: 0.6641 - val_loss: 0.6577 - val_accuracy: 0.6123\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6290 - accuracy: 0.6627 - val_loss: 0.6570 - val_accuracy: 0.6124\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6264 - accuracy: 0.6680 - val_loss: 0.6513 - val_accuracy: 0.6188\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6251 - accuracy: 0.6667 - val_loss: 0.6487 - val_accuracy: 0.6222\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6226 - accuracy: 0.6721 - val_loss: 0.6485 - val_accuracy: 0.6200\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6205 - accuracy: 0.6702 - val_loss: 0.6483 - val_accuracy: 0.6176\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6180 - accuracy: 0.6731 - val_loss: 0.6442 - val_accuracy: 0.6248\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6161 - accuracy: 0.6739 - val_loss: 0.6456 - val_accuracy: 0.6175\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6143 - accuracy: 0.6765 - val_loss: 0.6417 - val_accuracy: 0.6258\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6123 - accuracy: 0.6786 - val_loss: 0.6340 - val_accuracy: 0.6363\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6108 - accuracy: 0.6810 - val_loss: 0.6392 - val_accuracy: 0.6271\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6081 - accuracy: 0.6821 - val_loss: 0.6362 - val_accuracy: 0.6304\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6065 - accuracy: 0.6834 - val_loss: 0.6330 - val_accuracy: 0.6329\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6040 - accuracy: 0.6853 - val_loss: 0.6336 - val_accuracy: 0.6304\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 421us/step - loss: 0.6012 - accuracy: 0.6891 - val_loss: 0.6293 - val_accuracy: 0.6360\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5991 - accuracy: 0.6897 - val_loss: 0.6293 - val_accuracy: 0.6359\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5967 - accuracy: 0.6910 - val_loss: 0.6261 - val_accuracy: 0.6396\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5958 - accuracy: 0.6922 - val_loss: 0.6297 - val_accuracy: 0.6343\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.5942 - accuracy: 0.6939 - val_loss: 0.6241 - val_accuracy: 0.6406\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.5921 - accuracy: 0.6965 - val_loss: 0.6226 - val_accuracy: 0.6415\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5895 - accuracy: 0.6967 - val_loss: 0.6267 - val_accuracy: 0.6360\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5885 - accuracy: 0.6964 - val_loss: 0.6216 - val_accuracy: 0.6419\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5864 - accuracy: 0.6988 - val_loss: 0.6173 - val_accuracy: 0.6458\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5847 - accuracy: 0.7008 - val_loss: 0.6169 - val_accuracy: 0.6461\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5829 - accuracy: 0.7051 - val_loss: 0.6156 - val_accuracy: 0.6457\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5814 - accuracy: 0.7029 - val_loss: 0.6190 - val_accuracy: 0.6435\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.7097 - accuracy: 0.5189 - val_loss: 0.7201 - val_accuracy: 0.4169\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6989 - accuracy: 0.5345 - val_loss: 0.7103 - val_accuracy: 0.4858\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6910 - accuracy: 0.5474 - val_loss: 0.7047 - val_accuracy: 0.5226\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6812 - accuracy: 0.5649 - val_loss: 0.6959 - val_accuracy: 0.5560\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6788 - accuracy: 0.5739 - val_loss: 0.6925 - val_accuracy: 0.5672\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6738 - accuracy: 0.5807 - val_loss: 0.6856 - val_accuracy: 0.5819\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6690 - accuracy: 0.5896 - val_loss: 0.6845 - val_accuracy: 0.5799\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6654 - accuracy: 0.5971 - val_loss: 0.6846 - val_accuracy: 0.5766\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6624 - accuracy: 0.6033 - val_loss: 0.6816 - val_accuracy: 0.5809\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6593 - accuracy: 0.6119 - val_loss: 0.6769 - val_accuracy: 0.5907\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6578 - accuracy: 0.6164 - val_loss: 0.6752 - val_accuracy: 0.5928\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6547 - accuracy: 0.6234 - val_loss: 0.6763 - val_accuracy: 0.5887\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6526 - accuracy: 0.6254 - val_loss: 0.6766 - val_accuracy: 0.5854\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6496 - accuracy: 0.6315 - val_loss: 0.6728 - val_accuracy: 0.5911\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6483 - accuracy: 0.6353 - val_loss: 0.6729 - val_accuracy: 0.5902\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6455 - accuracy: 0.6392 - val_loss: 0.6652 - val_accuracy: 0.6032\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6433 - accuracy: 0.6415 - val_loss: 0.6686 - val_accuracy: 0.5966\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6416 - accuracy: 0.6479 - val_loss: 0.6629 - val_accuracy: 0.6062\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6401 - accuracy: 0.6491 - val_loss: 0.6666 - val_accuracy: 0.5988\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6378 - accuracy: 0.6513 - val_loss: 0.6643 - val_accuracy: 0.6021\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6353 - accuracy: 0.6563 - val_loss: 0.6569 - val_accuracy: 0.6144\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6333 - accuracy: 0.6594 - val_loss: 0.6591 - val_accuracy: 0.6077\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6310 - accuracy: 0.6606 - val_loss: 0.6564 - val_accuracy: 0.6125\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6298 - accuracy: 0.6636 - val_loss: 0.6604 - val_accuracy: 0.6041\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6278 - accuracy: 0.6649 - val_loss: 0.6545 - val_accuracy: 0.6127\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6259 - accuracy: 0.6671 - val_loss: 0.6500 - val_accuracy: 0.6204\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6245 - accuracy: 0.6695 - val_loss: 0.6542 - val_accuracy: 0.6121\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6228 - accuracy: 0.6719 - val_loss: 0.6521 - val_accuracy: 0.6140\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6202 - accuracy: 0.6734 - val_loss: 0.6511 - val_accuracy: 0.6137\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6184 - accuracy: 0.6744 - val_loss: 0.6487 - val_accuracy: 0.6156\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6165 - accuracy: 0.6776 - val_loss: 0.6444 - val_accuracy: 0.6215\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6144 - accuracy: 0.6806 - val_loss: 0.6445 - val_accuracy: 0.6214\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6125 - accuracy: 0.6798 - val_loss: 0.6496 - val_accuracy: 0.6114\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6106 - accuracy: 0.6842 - val_loss: 0.6404 - val_accuracy: 0.6268\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6089 - accuracy: 0.6857 - val_loss: 0.6383 - val_accuracy: 0.6289\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6078 - accuracy: 0.6849 - val_loss: 0.6347 - val_accuracy: 0.6344\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6052 - accuracy: 0.6880 - val_loss: 0.6346 - val_accuracy: 0.6314\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6028 - accuracy: 0.6907 - val_loss: 0.6432 - val_accuracy: 0.6195\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6004 - accuracy: 0.6934 - val_loss: 0.6318 - val_accuracy: 0.6336\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5992 - accuracy: 0.6921 - val_loss: 0.6361 - val_accuracy: 0.6268\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5974 - accuracy: 0.6946 - val_loss: 0.6336 - val_accuracy: 0.6290\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5961 - accuracy: 0.6956 - val_loss: 0.6348 - val_accuracy: 0.6261\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5938 - accuracy: 0.6988 - val_loss: 0.6279 - val_accuracy: 0.6334\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5923 - accuracy: 0.7000 - val_loss: 0.6279 - val_accuracy: 0.6325\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5898 - accuracy: 0.7030 - val_loss: 0.6279 - val_accuracy: 0.6312\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5888 - accuracy: 0.7037 - val_loss: 0.6300 - val_accuracy: 0.6282\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5870 - accuracy: 0.7046 - val_loss: 0.6273 - val_accuracy: 0.6303\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.5859 - accuracy: 0.7036 - val_loss: 0.6311 - val_accuracy: 0.6251\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5842 - accuracy: 0.7061 - val_loss: 0.6228 - val_accuracy: 0.6329\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.5818 - accuracy: 0.7084 - val_loss: 0.6210 - val_accuracy: 0.6332\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.7320 - accuracy: 0.4807 - val_loss: 0.7368 - val_accuracy: 0.3731\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.7165 - accuracy: 0.4897 - val_loss: 0.7170 - val_accuracy: 0.4419\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.7041 - accuracy: 0.5109 - val_loss: 0.7082 - val_accuracy: 0.4926\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6959 - accuracy: 0.5261 - val_loss: 0.7077 - val_accuracy: 0.4685\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6875 - accuracy: 0.5427 - val_loss: 0.6955 - val_accuracy: 0.5124\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6805 - accuracy: 0.5569 - val_loss: 0.6924 - val_accuracy: 0.5206\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6742 - accuracy: 0.5698 - val_loss: 0.6833 - val_accuracy: 0.5567\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6690 - accuracy: 0.5828 - val_loss: 0.6814 - val_accuracy: 0.5581\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6640 - accuracy: 0.5899 - val_loss: 0.6779 - val_accuracy: 0.5664\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6596 - accuracy: 0.5994 - val_loss: 0.6729 - val_accuracy: 0.5847\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6550 - accuracy: 0.6093 - val_loss: 0.6710 - val_accuracy: 0.5872\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6506 - accuracy: 0.6195 - val_loss: 0.6664 - val_accuracy: 0.5941\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.6471 - accuracy: 0.6239 - val_loss: 0.6661 - val_accuracy: 0.5948\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6429 - accuracy: 0.6307 - val_loss: 0.6613 - val_accuracy: 0.6029\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6406 - accuracy: 0.6335 - val_loss: 0.6500 - val_accuracy: 0.6266\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6360 - accuracy: 0.6428 - val_loss: 0.6556 - val_accuracy: 0.6082\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6326 - accuracy: 0.6454 - val_loss: 0.6493 - val_accuracy: 0.6216\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6286 - accuracy: 0.6499 - val_loss: 0.6473 - val_accuracy: 0.6240\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6264 - accuracy: 0.6509 - val_loss: 0.6418 - val_accuracy: 0.6353\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6226 - accuracy: 0.6600 - val_loss: 0.6445 - val_accuracy: 0.6261\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6212 - accuracy: 0.6577 - val_loss: 0.6450 - val_accuracy: 0.6236\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6181 - accuracy: 0.6643 - val_loss: 0.6407 - val_accuracy: 0.6292\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.6147 - accuracy: 0.6684 - val_loss: 0.6345 - val_accuracy: 0.6368\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6133 - accuracy: 0.6695 - val_loss: 0.6384 - val_accuracy: 0.6292\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6115 - accuracy: 0.6682 - val_loss: 0.6328 - val_accuracy: 0.6351\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6088 - accuracy: 0.6708 - val_loss: 0.6289 - val_accuracy: 0.6398\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6064 - accuracy: 0.6756 - val_loss: 0.6259 - val_accuracy: 0.6424\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6047 - accuracy: 0.6769 - val_loss: 0.6274 - val_accuracy: 0.6381\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6021 - accuracy: 0.6774 - val_loss: 0.6298 - val_accuracy: 0.6340\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6000 - accuracy: 0.6819 - val_loss: 0.6241 - val_accuracy: 0.6388\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5987 - accuracy: 0.6823 - val_loss: 0.6328 - val_accuracy: 0.6291\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5961 - accuracy: 0.6860 - val_loss: 0.6273 - val_accuracy: 0.6346\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5950 - accuracy: 0.6885 - val_loss: 0.6226 - val_accuracy: 0.6392\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5928 - accuracy: 0.6876 - val_loss: 0.6197 - val_accuracy: 0.6425\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5919 - accuracy: 0.6905 - val_loss: 0.6243 - val_accuracy: 0.6362\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5911 - accuracy: 0.6910 - val_loss: 0.6172 - val_accuracy: 0.6448\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5879 - accuracy: 0.6946 - val_loss: 0.6215 - val_accuracy: 0.6387\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5871 - accuracy: 0.6951 - val_loss: 0.6181 - val_accuracy: 0.6422\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5858 - accuracy: 0.6972 - val_loss: 0.6197 - val_accuracy: 0.6394\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5843 - accuracy: 0.6978 - val_loss: 0.6208 - val_accuracy: 0.6384\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5830 - accuracy: 0.6986 - val_loss: 0.6170 - val_accuracy: 0.6416\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5812 - accuracy: 0.7008 - val_loss: 0.6176 - val_accuracy: 0.6414\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5796 - accuracy: 0.7027 - val_loss: 0.6150 - val_accuracy: 0.6424\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5801 - accuracy: 0.7033 - val_loss: 0.6183 - val_accuracy: 0.6394\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5775 - accuracy: 0.7047 - val_loss: 0.6135 - val_accuracy: 0.6420\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5756 - accuracy: 0.7068 - val_loss: 0.6045 - val_accuracy: 0.6510\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5757 - accuracy: 0.7068 - val_loss: 0.6054 - val_accuracy: 0.6501\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5738 - accuracy: 0.7068 - val_loss: 0.6109 - val_accuracy: 0.6439\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5728 - accuracy: 0.7103 - val_loss: 0.6032 - val_accuracy: 0.6524\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5720 - accuracy: 0.7092 - val_loss: 0.6082 - val_accuracy: 0.6450\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.6775 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.7268 - accuracy: 0.5000 - val_loss: 0.7784 - val_accuracy: 0.1568\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.7041 - accuracy: 0.4989 - val_loss: 0.7375 - val_accuracy: 0.3003\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6989 - accuracy: 0.5116 - val_loss: 0.7266 - val_accuracy: 0.3951\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6922 - accuracy: 0.5300 - val_loss: 0.7198 - val_accuracy: 0.4472\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6872 - accuracy: 0.5467 - val_loss: 0.7131 - val_accuracy: 0.4839\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6827 - accuracy: 0.5590 - val_loss: 0.7089 - val_accuracy: 0.5074\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6779 - accuracy: 0.5747 - val_loss: 0.7029 - val_accuracy: 0.5321\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6736 - accuracy: 0.5846 - val_loss: 0.6970 - val_accuracy: 0.5542\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6691 - accuracy: 0.5939 - val_loss: 0.6940 - val_accuracy: 0.5610\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6662 - accuracy: 0.6008 - val_loss: 0.6912 - val_accuracy: 0.5693\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6619 - accuracy: 0.6079 - val_loss: 0.6873 - val_accuracy: 0.5787\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6585 - accuracy: 0.6133 - val_loss: 0.6819 - val_accuracy: 0.5902\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6552 - accuracy: 0.6196 - val_loss: 0.6797 - val_accuracy: 0.5968\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6527 - accuracy: 0.6219 - val_loss: 0.6758 - val_accuracy: 0.6044\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6495 - accuracy: 0.6284 - val_loss: 0.6718 - val_accuracy: 0.6117\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6474 - accuracy: 0.6297 - val_loss: 0.6676 - val_accuracy: 0.6206\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6442 - accuracy: 0.6326 - val_loss: 0.6657 - val_accuracy: 0.6217\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6421 - accuracy: 0.6346 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6395 - accuracy: 0.6366 - val_loss: 0.6637 - val_accuracy: 0.6242\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6371 - accuracy: 0.6383 - val_loss: 0.6587 - val_accuracy: 0.6310\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6355 - accuracy: 0.6404 - val_loss: 0.6594 - val_accuracy: 0.6290\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6332 - accuracy: 0.6449 - val_loss: 0.6563 - val_accuracy: 0.6328\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6310 - accuracy: 0.6455 - val_loss: 0.6535 - val_accuracy: 0.6354\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6287 - accuracy: 0.6471 - val_loss: 0.6487 - val_accuracy: 0.6422\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6272 - accuracy: 0.6476 - val_loss: 0.6489 - val_accuracy: 0.6404\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6247 - accuracy: 0.6489 - val_loss: 0.6465 - val_accuracy: 0.6433\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6224 - accuracy: 0.6545 - val_loss: 0.6474 - val_accuracy: 0.6422\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6209 - accuracy: 0.6555 - val_loss: 0.6425 - val_accuracy: 0.6467\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6178 - accuracy: 0.6579 - val_loss: 0.6454 - val_accuracy: 0.6433\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6172 - accuracy: 0.6575 - val_loss: 0.6395 - val_accuracy: 0.6476\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6150 - accuracy: 0.6581 - val_loss: 0.6364 - val_accuracy: 0.6517\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6136 - accuracy: 0.6583 - val_loss: 0.6367 - val_accuracy: 0.6500\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6122 - accuracy: 0.6605 - val_loss: 0.6326 - val_accuracy: 0.6535\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6103 - accuracy: 0.6625 - val_loss: 0.6320 - val_accuracy: 0.6533\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6075 - accuracy: 0.6667 - val_loss: 0.6338 - val_accuracy: 0.6501\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6061 - accuracy: 0.6659 - val_loss: 0.6302 - val_accuracy: 0.6525\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6046 - accuracy: 0.6693 - val_loss: 0.6305 - val_accuracy: 0.6508\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6024 - accuracy: 0.6693 - val_loss: 0.6301 - val_accuracy: 0.6510\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6008 - accuracy: 0.6717 - val_loss: 0.6242 - val_accuracy: 0.6584\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6005 - accuracy: 0.6678 - val_loss: 0.6223 - val_accuracy: 0.6598\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5973 - accuracy: 0.6751 - val_loss: 0.6243 - val_accuracy: 0.6556\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5962 - accuracy: 0.6740 - val_loss: 0.6218 - val_accuracy: 0.6573\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5953 - accuracy: 0.6755 - val_loss: 0.6227 - val_accuracy: 0.6550\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5928 - accuracy: 0.6780 - val_loss: 0.6232 - val_accuracy: 0.6533\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5925 - accuracy: 0.6773 - val_loss: 0.6244 - val_accuracy: 0.6512\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5912 - accuracy: 0.6785 - val_loss: 0.6220 - val_accuracy: 0.6534\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.5896 - accuracy: 0.6812 - val_loss: 0.6214 - val_accuracy: 0.6545\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.5880 - accuracy: 0.6804 - val_loss: 0.6242 - val_accuracy: 0.6502\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5867 - accuracy: 0.6821 - val_loss: 0.6164 - val_accuracy: 0.6580\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5856 - accuracy: 0.6848 - val_loss: 0.6156 - val_accuracy: 0.6584\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.7057 - accuracy: 0.5208 - val_loss: 0.6871 - val_accuracy: 0.5195\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6888 - accuracy: 0.5535 - val_loss: 0.6993 - val_accuracy: 0.4567\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6810 - accuracy: 0.5746 - val_loss: 0.7002 - val_accuracy: 0.4553\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6755 - accuracy: 0.5900 - val_loss: 0.6896 - val_accuracy: 0.4929\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6704 - accuracy: 0.6036 - val_loss: 0.6927 - val_accuracy: 0.4898\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6675 - accuracy: 0.6082 - val_loss: 0.6859 - val_accuracy: 0.5147\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6617 - accuracy: 0.6234 - val_loss: 0.6850 - val_accuracy: 0.5206\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.6577 - accuracy: 0.6286 - val_loss: 0.6802 - val_accuracy: 0.5365\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6551 - accuracy: 0.6346 - val_loss: 0.6797 - val_accuracy: 0.5380\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6517 - accuracy: 0.6421 - val_loss: 0.6772 - val_accuracy: 0.5465\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6479 - accuracy: 0.6467 - val_loss: 0.6744 - val_accuracy: 0.5508\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6443 - accuracy: 0.6535 - val_loss: 0.6730 - val_accuracy: 0.5578\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6408 - accuracy: 0.6577 - val_loss: 0.6667 - val_accuracy: 0.5725\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6380 - accuracy: 0.6615 - val_loss: 0.6659 - val_accuracy: 0.5757\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6353 - accuracy: 0.6615 - val_loss: 0.6607 - val_accuracy: 0.5882\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6320 - accuracy: 0.6681 - val_loss: 0.6619 - val_accuracy: 0.5827\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6292 - accuracy: 0.6705 - val_loss: 0.6564 - val_accuracy: 0.5955\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6278 - accuracy: 0.6694 - val_loss: 0.6552 - val_accuracy: 0.5980\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6255 - accuracy: 0.6737 - val_loss: 0.6532 - val_accuracy: 0.6001\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6228 - accuracy: 0.6757 - val_loss: 0.6490 - val_accuracy: 0.6064\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6214 - accuracy: 0.6749 - val_loss: 0.6492 - val_accuracy: 0.6049\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6188 - accuracy: 0.6784 - val_loss: 0.6458 - val_accuracy: 0.6116\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6168 - accuracy: 0.6814 - val_loss: 0.6452 - val_accuracy: 0.6141\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6148 - accuracy: 0.6810 - val_loss: 0.6415 - val_accuracy: 0.6194\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6127 - accuracy: 0.6841 - val_loss: 0.6446 - val_accuracy: 0.6148\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6119 - accuracy: 0.6834 - val_loss: 0.6385 - val_accuracy: 0.6203\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6094 - accuracy: 0.6862 - val_loss: 0.6421 - val_accuracy: 0.6168\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6074 - accuracy: 0.6870 - val_loss: 0.6398 - val_accuracy: 0.6175\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6071 - accuracy: 0.6870 - val_loss: 0.6368 - val_accuracy: 0.6197\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6050 - accuracy: 0.6881 - val_loss: 0.6343 - val_accuracy: 0.6220\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6033 - accuracy: 0.6885 - val_loss: 0.6364 - val_accuracy: 0.6193\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6017 - accuracy: 0.6889 - val_loss: 0.6271 - val_accuracy: 0.6303\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5996 - accuracy: 0.6916 - val_loss: 0.6331 - val_accuracy: 0.6209\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5990 - accuracy: 0.6912 - val_loss: 0.6325 - val_accuracy: 0.6206\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5966 - accuracy: 0.6928 - val_loss: 0.6356 - val_accuracy: 0.6176\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.5964 - accuracy: 0.6933 - val_loss: 0.6289 - val_accuracy: 0.6248\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5942 - accuracy: 0.6968 - val_loss: 0.6293 - val_accuracy: 0.6236\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5933 - accuracy: 0.6970 - val_loss: 0.6266 - val_accuracy: 0.6271\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5914 - accuracy: 0.6978 - val_loss: 0.6319 - val_accuracy: 0.6203\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5904 - accuracy: 0.6962 - val_loss: 0.6290 - val_accuracy: 0.6230\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5878 - accuracy: 0.6983 - val_loss: 0.6277 - val_accuracy: 0.6234\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5883 - accuracy: 0.6984 - val_loss: 0.6265 - val_accuracy: 0.6248\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5870 - accuracy: 0.7004 - val_loss: 0.6252 - val_accuracy: 0.6272\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5864 - accuracy: 0.6982 - val_loss: 0.6235 - val_accuracy: 0.6295\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5845 - accuracy: 0.7007 - val_loss: 0.6284 - val_accuracy: 0.6215\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5831 - accuracy: 0.7022 - val_loss: 0.6250 - val_accuracy: 0.6274\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5820 - accuracy: 0.7021 - val_loss: 0.6241 - val_accuracy: 0.6281\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5816 - accuracy: 0.7011 - val_loss: 0.6231 - val_accuracy: 0.6281\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5807 - accuracy: 0.7034 - val_loss: 0.6240 - val_accuracy: 0.6271\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5784 - accuracy: 0.7036 - val_loss: 0.6238 - val_accuracy: 0.6274\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.7251 - accuracy: 0.4968 - val_loss: 0.7626 - val_accuracy: 0.1402\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.7096 - accuracy: 0.5040 - val_loss: 0.7325 - val_accuracy: 0.2201\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.7001 - accuracy: 0.5230 - val_loss: 0.7171 - val_accuracy: 0.3108\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6930 - accuracy: 0.5391 - val_loss: 0.7139 - val_accuracy: 0.3552\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6891 - accuracy: 0.5477 - val_loss: 0.7065 - val_accuracy: 0.4163\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.6836 - accuracy: 0.5622 - val_loss: 0.7062 - val_accuracy: 0.4297\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6795 - accuracy: 0.5748 - val_loss: 0.7011 - val_accuracy: 0.4620\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6758 - accuracy: 0.5875 - val_loss: 0.6985 - val_accuracy: 0.4752\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6726 - accuracy: 0.5914 - val_loss: 0.6965 - val_accuracy: 0.4855\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6694 - accuracy: 0.6026 - val_loss: 0.6902 - val_accuracy: 0.5085\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6667 - accuracy: 0.6091 - val_loss: 0.6917 - val_accuracy: 0.5028\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6626 - accuracy: 0.6204 - val_loss: 0.6884 - val_accuracy: 0.5169\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6600 - accuracy: 0.6235 - val_loss: 0.6860 - val_accuracy: 0.5278\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6562 - accuracy: 0.6345 - val_loss: 0.6794 - val_accuracy: 0.5524\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6545 - accuracy: 0.6364 - val_loss: 0.6782 - val_accuracy: 0.5560\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6504 - accuracy: 0.6445 - val_loss: 0.6757 - val_accuracy: 0.5624\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6476 - accuracy: 0.6491 - val_loss: 0.6732 - val_accuracy: 0.5672\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6452 - accuracy: 0.6491 - val_loss: 0.6710 - val_accuracy: 0.5704\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6431 - accuracy: 0.6533 - val_loss: 0.6666 - val_accuracy: 0.5808\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6413 - accuracy: 0.6526 - val_loss: 0.6654 - val_accuracy: 0.5834\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6384 - accuracy: 0.6572 - val_loss: 0.6668 - val_accuracy: 0.5766\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.6358 - accuracy: 0.6652 - val_loss: 0.6614 - val_accuracy: 0.5877\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6324 - accuracy: 0.6666 - val_loss: 0.6575 - val_accuracy: 0.5958\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6308 - accuracy: 0.6669 - val_loss: 0.6549 - val_accuracy: 0.5995\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6279 - accuracy: 0.6700 - val_loss: 0.6556 - val_accuracy: 0.5960\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 454us/step - loss: 0.6270 - accuracy: 0.6700 - val_loss: 0.6534 - val_accuracy: 0.5996\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6247 - accuracy: 0.6730 - val_loss: 0.6474 - val_accuracy: 0.6092\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6223 - accuracy: 0.6728 - val_loss: 0.6476 - val_accuracy: 0.6072\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6202 - accuracy: 0.6773 - val_loss: 0.6473 - val_accuracy: 0.6067\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6179 - accuracy: 0.6772 - val_loss: 0.6443 - val_accuracy: 0.6100\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6159 - accuracy: 0.6786 - val_loss: 0.6404 - val_accuracy: 0.6157\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6144 - accuracy: 0.6800 - val_loss: 0.6442 - val_accuracy: 0.6082\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6126 - accuracy: 0.6793 - val_loss: 0.6387 - val_accuracy: 0.6161\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6104 - accuracy: 0.6821 - val_loss: 0.6382 - val_accuracy: 0.6159\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6081 - accuracy: 0.6844 - val_loss: 0.6350 - val_accuracy: 0.6194\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6059 - accuracy: 0.6847 - val_loss: 0.6354 - val_accuracy: 0.6175\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6047 - accuracy: 0.6866 - val_loss: 0.6362 - val_accuracy: 0.6148\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6032 - accuracy: 0.6858 - val_loss: 0.6267 - val_accuracy: 0.6261\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6016 - accuracy: 0.6863 - val_loss: 0.6271 - val_accuracy: 0.6237\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.5988 - accuracy: 0.6878 - val_loss: 0.6283 - val_accuracy: 0.6214\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5976 - accuracy: 0.6880 - val_loss: 0.6331 - val_accuracy: 0.6155\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5951 - accuracy: 0.6918 - val_loss: 0.6239 - val_accuracy: 0.6236\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.5939 - accuracy: 0.6916 - val_loss: 0.6236 - val_accuracy: 0.6245\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5928 - accuracy: 0.6898 - val_loss: 0.6174 - val_accuracy: 0.6310\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5905 - accuracy: 0.6937 - val_loss: 0.6209 - val_accuracy: 0.6283\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.5894 - accuracy: 0.6941 - val_loss: 0.6220 - val_accuracy: 0.6268\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5877 - accuracy: 0.6936 - val_loss: 0.6202 - val_accuracy: 0.6291\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5862 - accuracy: 0.6955 - val_loss: 0.6170 - val_accuracy: 0.6331\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5856 - accuracy: 0.6958 - val_loss: 0.6253 - val_accuracy: 0.6228\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5827 - accuracy: 0.6966 - val_loss: 0.6177 - val_accuracy: 0.6330\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.7272 - accuracy: 0.4685 - val_loss: 0.7354 - val_accuracy: 0.2464\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.7158 - accuracy: 0.4723 - val_loss: 0.7243 - val_accuracy: 0.2819\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.7071 - accuracy: 0.4897 - val_loss: 0.7160 - val_accuracy: 0.3549\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.7025 - accuracy: 0.5036 - val_loss: 0.7121 - val_accuracy: 0.3732\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6958 - accuracy: 0.5152 - val_loss: 0.7086 - val_accuracy: 0.4197\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6921 - accuracy: 0.5283 - val_loss: 0.7071 - val_accuracy: 0.4501\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6885 - accuracy: 0.5332 - val_loss: 0.6974 - val_accuracy: 0.5060\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6849 - accuracy: 0.5440 - val_loss: 0.6953 - val_accuracy: 0.5291\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6816 - accuracy: 0.5537 - val_loss: 0.6933 - val_accuracy: 0.5461\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6782 - accuracy: 0.5651 - val_loss: 0.6918 - val_accuracy: 0.5508\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6746 - accuracy: 0.5763 - val_loss: 0.6892 - val_accuracy: 0.5612\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6718 - accuracy: 0.5809 - val_loss: 0.6894 - val_accuracy: 0.5618\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6700 - accuracy: 0.5865 - val_loss: 0.6855 - val_accuracy: 0.5747\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6676 - accuracy: 0.5963 - val_loss: 0.6856 - val_accuracy: 0.5732\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6651 - accuracy: 0.6006 - val_loss: 0.6837 - val_accuracy: 0.5774\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6630 - accuracy: 0.6074 - val_loss: 0.6804 - val_accuracy: 0.5860\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6596 - accuracy: 0.6147 - val_loss: 0.6755 - val_accuracy: 0.5995\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6574 - accuracy: 0.6196 - val_loss: 0.6756 - val_accuracy: 0.5979\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6550 - accuracy: 0.6265 - val_loss: 0.6708 - val_accuracy: 0.6086\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6525 - accuracy: 0.6289 - val_loss: 0.6729 - val_accuracy: 0.6013\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6503 - accuracy: 0.6327 - val_loss: 0.6703 - val_accuracy: 0.6063\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6493 - accuracy: 0.6352 - val_loss: 0.6647 - val_accuracy: 0.6163\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6467 - accuracy: 0.6393 - val_loss: 0.6618 - val_accuracy: 0.6194\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6442 - accuracy: 0.6417 - val_loss: 0.6629 - val_accuracy: 0.6154\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6423 - accuracy: 0.6445 - val_loss: 0.6627 - val_accuracy: 0.6150\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6404 - accuracy: 0.6489 - val_loss: 0.6586 - val_accuracy: 0.6201\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6370 - accuracy: 0.6542 - val_loss: 0.6582 - val_accuracy: 0.6201\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6359 - accuracy: 0.6550 - val_loss: 0.6571 - val_accuracy: 0.6198\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6324 - accuracy: 0.6606 - val_loss: 0.6560 - val_accuracy: 0.6193\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6320 - accuracy: 0.6582 - val_loss: 0.6574 - val_accuracy: 0.6142\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6292 - accuracy: 0.6629 - val_loss: 0.6567 - val_accuracy: 0.6121\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6276 - accuracy: 0.6670 - val_loss: 0.6489 - val_accuracy: 0.6271\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6255 - accuracy: 0.6690 - val_loss: 0.6478 - val_accuracy: 0.6278\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6241 - accuracy: 0.6688 - val_loss: 0.6449 - val_accuracy: 0.6310\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 463us/step - loss: 0.6209 - accuracy: 0.6738 - val_loss: 0.6443 - val_accuracy: 0.6311\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6189 - accuracy: 0.6746 - val_loss: 0.6442 - val_accuracy: 0.6289\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6177 - accuracy: 0.6771 - val_loss: 0.6454 - val_accuracy: 0.6255\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6150 - accuracy: 0.6777 - val_loss: 0.6443 - val_accuracy: 0.6271\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6141 - accuracy: 0.6786 - val_loss: 0.6443 - val_accuracy: 0.6262\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6125 - accuracy: 0.6829 - val_loss: 0.6445 - val_accuracy: 0.6257\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6104 - accuracy: 0.6826 - val_loss: 0.6348 - val_accuracy: 0.6391\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6088 - accuracy: 0.6871 - val_loss: 0.6360 - val_accuracy: 0.6373\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6070 - accuracy: 0.6876 - val_loss: 0.6359 - val_accuracy: 0.6364\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6047 - accuracy: 0.6891 - val_loss: 0.6318 - val_accuracy: 0.6398\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6037 - accuracy: 0.6900 - val_loss: 0.6340 - val_accuracy: 0.6366\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6017 - accuracy: 0.6922 - val_loss: 0.6314 - val_accuracy: 0.6380\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5999 - accuracy: 0.6935 - val_loss: 0.6303 - val_accuracy: 0.6384\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5979 - accuracy: 0.6974 - val_loss: 0.6313 - val_accuracy: 0.6366\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5962 - accuracy: 0.6968 - val_loss: 0.6291 - val_accuracy: 0.6384\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.5945 - accuracy: 0.6977 - val_loss: 0.6329 - val_accuracy: 0.6353\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.7247 - accuracy: 0.4913 - val_loss: 0.7546 - val_accuracy: 0.2395\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 699us/step - loss: 0.7026 - accuracy: 0.5050 - val_loss: 0.7252 - val_accuracy: 0.3043\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6924 - accuracy: 0.5267 - val_loss: 0.7198 - val_accuracy: 0.3295\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6824 - accuracy: 0.5537 - val_loss: 0.7083 - val_accuracy: 0.4241\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6737 - accuracy: 0.5811 - val_loss: 0.6988 - val_accuracy: 0.4763\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6672 - accuracy: 0.5977 - val_loss: 0.6971 - val_accuracy: 0.4829\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6593 - accuracy: 0.6156 - val_loss: 0.6933 - val_accuracy: 0.5091\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.6540 - accuracy: 0.6294 - val_loss: 0.6850 - val_accuracy: 0.5386\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6489 - accuracy: 0.6400 - val_loss: 0.6823 - val_accuracy: 0.5466\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6431 - accuracy: 0.6502 - val_loss: 0.6763 - val_accuracy: 0.5624\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6393 - accuracy: 0.6546 - val_loss: 0.6710 - val_accuracy: 0.5744\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6356 - accuracy: 0.6590 - val_loss: 0.6695 - val_accuracy: 0.5770\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6329 - accuracy: 0.6638 - val_loss: 0.6626 - val_accuracy: 0.5945\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6283 - accuracy: 0.6666 - val_loss: 0.6610 - val_accuracy: 0.5960\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6261 - accuracy: 0.6683 - val_loss: 0.6569 - val_accuracy: 0.6056\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6228 - accuracy: 0.6702 - val_loss: 0.6541 - val_accuracy: 0.6090\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6183 - accuracy: 0.6757 - val_loss: 0.6530 - val_accuracy: 0.6093\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6161 - accuracy: 0.6777 - val_loss: 0.6491 - val_accuracy: 0.6162\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6130 - accuracy: 0.6819 - val_loss: 0.6450 - val_accuracy: 0.6236\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6106 - accuracy: 0.6802 - val_loss: 0.6480 - val_accuracy: 0.6159\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6083 - accuracy: 0.6840 - val_loss: 0.6397 - val_accuracy: 0.6308\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6051 - accuracy: 0.6861 - val_loss: 0.6393 - val_accuracy: 0.6305\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6035 - accuracy: 0.6871 - val_loss: 0.6370 - val_accuracy: 0.6324\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5991 - accuracy: 0.6896 - val_loss: 0.6382 - val_accuracy: 0.6280\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5975 - accuracy: 0.6896 - val_loss: 0.6272 - val_accuracy: 0.6425\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5944 - accuracy: 0.6913 - val_loss: 0.6284 - val_accuracy: 0.6399\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5933 - accuracy: 0.6932 - val_loss: 0.6241 - val_accuracy: 0.6434\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5903 - accuracy: 0.6974 - val_loss: 0.6166 - val_accuracy: 0.6530\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5883 - accuracy: 0.6964 - val_loss: 0.6207 - val_accuracy: 0.6436\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5865 - accuracy: 0.6983 - val_loss: 0.6202 - val_accuracy: 0.6436\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5839 - accuracy: 0.7001 - val_loss: 0.6214 - val_accuracy: 0.6414\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5822 - accuracy: 0.7000 - val_loss: 0.6212 - val_accuracy: 0.6398\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5808 - accuracy: 0.7004 - val_loss: 0.6209 - val_accuracy: 0.6387\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5789 - accuracy: 0.7020 - val_loss: 0.6184 - val_accuracy: 0.6418\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5765 - accuracy: 0.7046 - val_loss: 0.6127 - val_accuracy: 0.6510\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5745 - accuracy: 0.7058 - val_loss: 0.6135 - val_accuracy: 0.6498\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5724 - accuracy: 0.7078 - val_loss: 0.6112 - val_accuracy: 0.6522\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5709 - accuracy: 0.7098 - val_loss: 0.6017 - val_accuracy: 0.6619\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5704 - accuracy: 0.7101 - val_loss: 0.6054 - val_accuracy: 0.6585\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5676 - accuracy: 0.7109 - val_loss: 0.6078 - val_accuracy: 0.6538\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5659 - accuracy: 0.7125 - val_loss: 0.6095 - val_accuracy: 0.6511\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5651 - accuracy: 0.7140 - val_loss: 0.6090 - val_accuracy: 0.6509\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.5637 - accuracy: 0.7158 - val_loss: 0.6059 - val_accuracy: 0.6534\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.5627 - accuracy: 0.7158 - val_loss: 0.5985 - val_accuracy: 0.6595\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.5597 - accuracy: 0.7193 - val_loss: 0.6078 - val_accuracy: 0.6508\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5593 - accuracy: 0.7183 - val_loss: 0.6069 - val_accuracy: 0.6502\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5586 - accuracy: 0.7191 - val_loss: 0.6026 - val_accuracy: 0.6541\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5568 - accuracy: 0.7193 - val_loss: 0.6097 - val_accuracy: 0.6474\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5551 - accuracy: 0.7225 - val_loss: 0.6076 - val_accuracy: 0.6489\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5536 - accuracy: 0.7222 - val_loss: 0.5992 - val_accuracy: 0.6561\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.7104 - accuracy: 0.4775 - val_loss: 0.7000 - val_accuracy: 0.4757\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6966 - accuracy: 0.5145 - val_loss: 0.7075 - val_accuracy: 0.4408\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6900 - accuracy: 0.5401 - val_loss: 0.7049 - val_accuracy: 0.4740\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6835 - accuracy: 0.5623 - val_loss: 0.7004 - val_accuracy: 0.5166\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6801 - accuracy: 0.5749 - val_loss: 0.6958 - val_accuracy: 0.5344\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6750 - accuracy: 0.5904 - val_loss: 0.6953 - val_accuracy: 0.5404\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6724 - accuracy: 0.5974 - val_loss: 0.6926 - val_accuracy: 0.5494\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6681 - accuracy: 0.6105 - val_loss: 0.6873 - val_accuracy: 0.5652\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6656 - accuracy: 0.6166 - val_loss: 0.6859 - val_accuracy: 0.5683\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6615 - accuracy: 0.6257 - val_loss: 0.6849 - val_accuracy: 0.5697\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6586 - accuracy: 0.6330 - val_loss: 0.6829 - val_accuracy: 0.5745\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6562 - accuracy: 0.6379 - val_loss: 0.6836 - val_accuracy: 0.5703\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6533 - accuracy: 0.6394 - val_loss: 0.6765 - val_accuracy: 0.5868\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6510 - accuracy: 0.6421 - val_loss: 0.6776 - val_accuracy: 0.5822\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6482 - accuracy: 0.6477 - val_loss: 0.6702 - val_accuracy: 0.5984\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6454 - accuracy: 0.6504 - val_loss: 0.6699 - val_accuracy: 0.5963\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6432 - accuracy: 0.6546 - val_loss: 0.6645 - val_accuracy: 0.6074\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6403 - accuracy: 0.6596 - val_loss: 0.6679 - val_accuracy: 0.5974\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6382 - accuracy: 0.6606 - val_loss: 0.6650 - val_accuracy: 0.6013\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6361 - accuracy: 0.6605 - val_loss: 0.6597 - val_accuracy: 0.6112\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6333 - accuracy: 0.6656 - val_loss: 0.6582 - val_accuracy: 0.6117\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6314 - accuracy: 0.6668 - val_loss: 0.6609 - val_accuracy: 0.6044\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6290 - accuracy: 0.6704 - val_loss: 0.6536 - val_accuracy: 0.6154\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6262 - accuracy: 0.6739 - val_loss: 0.6558 - val_accuracy: 0.6093\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6245 - accuracy: 0.6750 - val_loss: 0.6485 - val_accuracy: 0.6196\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6229 - accuracy: 0.6750 - val_loss: 0.6491 - val_accuracy: 0.6176\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6199 - accuracy: 0.6759 - val_loss: 0.6472 - val_accuracy: 0.6167\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6179 - accuracy: 0.6787 - val_loss: 0.6447 - val_accuracy: 0.6184\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6154 - accuracy: 0.6810 - val_loss: 0.6418 - val_accuracy: 0.6199\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6132 - accuracy: 0.6839 - val_loss: 0.6437 - val_accuracy: 0.6102\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6106 - accuracy: 0.6845 - val_loss: 0.6442 - val_accuracy: 0.6081\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6087 - accuracy: 0.6866 - val_loss: 0.6442 - val_accuracy: 0.6079\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6059 - accuracy: 0.6896 - val_loss: 0.6303 - val_accuracy: 0.6218\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6039 - accuracy: 0.6908 - val_loss: 0.6352 - val_accuracy: 0.6166\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6015 - accuracy: 0.6939 - val_loss: 0.6384 - val_accuracy: 0.6154\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5995 - accuracy: 0.6959 - val_loss: 0.6355 - val_accuracy: 0.6175\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5975 - accuracy: 0.6968 - val_loss: 0.6352 - val_accuracy: 0.6194\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5964 - accuracy: 0.6955 - val_loss: 0.6281 - val_accuracy: 0.6283\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5937 - accuracy: 0.6992 - val_loss: 0.6255 - val_accuracy: 0.6300\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.5915 - accuracy: 0.7008 - val_loss: 0.6296 - val_accuracy: 0.6259\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5911 - accuracy: 0.7016 - val_loss: 0.6278 - val_accuracy: 0.6276\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5885 - accuracy: 0.7031 - val_loss: 0.6247 - val_accuracy: 0.6294\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5878 - accuracy: 0.7040 - val_loss: 0.6212 - val_accuracy: 0.6313\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5862 - accuracy: 0.7025 - val_loss: 0.6274 - val_accuracy: 0.6282\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5852 - accuracy: 0.7037 - val_loss: 0.6252 - val_accuracy: 0.6294\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5836 - accuracy: 0.7054 - val_loss: 0.6192 - val_accuracy: 0.6325\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5816 - accuracy: 0.7047 - val_loss: 0.6252 - val_accuracy: 0.6294\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5809 - accuracy: 0.7054 - val_loss: 0.6152 - val_accuracy: 0.6353\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5791 - accuracy: 0.7069 - val_loss: 0.6237 - val_accuracy: 0.6297\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5776 - accuracy: 0.7086 - val_loss: 0.6147 - val_accuracy: 0.6364\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.7189 - accuracy: 0.5029 - val_loss: 0.7507 - val_accuracy: 0.1381\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.7052 - accuracy: 0.5123 - val_loss: 0.7270 - val_accuracy: 0.2355\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6981 - accuracy: 0.5249 - val_loss: 0.7243 - val_accuracy: 0.2893\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6948 - accuracy: 0.5321 - val_loss: 0.7225 - val_accuracy: 0.3298\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6894 - accuracy: 0.5461 - val_loss: 0.7124 - val_accuracy: 0.4132\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6857 - accuracy: 0.5555 - val_loss: 0.7115 - val_accuracy: 0.4251\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6821 - accuracy: 0.5636 - val_loss: 0.7064 - val_accuracy: 0.4537\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6770 - accuracy: 0.5777 - val_loss: 0.7019 - val_accuracy: 0.4838\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6754 - accuracy: 0.5809 - val_loss: 0.7013 - val_accuracy: 0.4961\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6734 - accuracy: 0.5876 - val_loss: 0.6954 - val_accuracy: 0.5236\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6702 - accuracy: 0.5942 - val_loss: 0.6957 - val_accuracy: 0.5185\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6678 - accuracy: 0.6022 - val_loss: 0.6905 - val_accuracy: 0.5375\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6648 - accuracy: 0.6086 - val_loss: 0.6887 - val_accuracy: 0.5448\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6610 - accuracy: 0.6174 - val_loss: 0.6891 - val_accuracy: 0.5414\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6597 - accuracy: 0.6192 - val_loss: 0.6844 - val_accuracy: 0.5556\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6569 - accuracy: 0.6265 - val_loss: 0.6842 - val_accuracy: 0.5548\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6534 - accuracy: 0.6322 - val_loss: 0.6800 - val_accuracy: 0.5672\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6516 - accuracy: 0.6366 - val_loss: 0.6793 - val_accuracy: 0.5697\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6481 - accuracy: 0.6417 - val_loss: 0.6745 - val_accuracy: 0.5807\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6464 - accuracy: 0.6440 - val_loss: 0.6738 - val_accuracy: 0.5830\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6435 - accuracy: 0.6508 - val_loss: 0.6660 - val_accuracy: 0.6036\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6412 - accuracy: 0.6506 - val_loss: 0.6683 - val_accuracy: 0.5973\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6387 - accuracy: 0.6540 - val_loss: 0.6655 - val_accuracy: 0.6027\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6372 - accuracy: 0.6570 - val_loss: 0.6664 - val_accuracy: 0.5986\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6347 - accuracy: 0.6582 - val_loss: 0.6579 - val_accuracy: 0.6125\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6319 - accuracy: 0.6648 - val_loss: 0.6547 - val_accuracy: 0.6173\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6300 - accuracy: 0.6667 - val_loss: 0.6546 - val_accuracy: 0.6151\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6270 - accuracy: 0.6679 - val_loss: 0.6493 - val_accuracy: 0.6238\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6250 - accuracy: 0.6710 - val_loss: 0.6526 - val_accuracy: 0.6142\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6229 - accuracy: 0.6735 - val_loss: 0.6528 - val_accuracy: 0.6134\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6203 - accuracy: 0.6756 - val_loss: 0.6458 - val_accuracy: 0.6256\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6190 - accuracy: 0.6752 - val_loss: 0.6445 - val_accuracy: 0.6265\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6151 - accuracy: 0.6794 - val_loss: 0.6404 - val_accuracy: 0.6332\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6140 - accuracy: 0.6812 - val_loss: 0.6432 - val_accuracy: 0.6268\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6108 - accuracy: 0.6836 - val_loss: 0.6436 - val_accuracy: 0.6255\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.6104 - accuracy: 0.6834 - val_loss: 0.6359 - val_accuracy: 0.6365\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6086 - accuracy: 0.6862 - val_loss: 0.6370 - val_accuracy: 0.6328\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.6064 - accuracy: 0.6886 - val_loss: 0.6341 - val_accuracy: 0.6354\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6044 - accuracy: 0.6889 - val_loss: 0.6353 - val_accuracy: 0.6326\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6029 - accuracy: 0.6893 - val_loss: 0.6330 - val_accuracy: 0.6340\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6007 - accuracy: 0.6907 - val_loss: 0.6316 - val_accuracy: 0.6341\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5993 - accuracy: 0.6913 - val_loss: 0.6296 - val_accuracy: 0.6349\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5966 - accuracy: 0.6943 - val_loss: 0.6270 - val_accuracy: 0.6362\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5937 - accuracy: 0.6959 - val_loss: 0.6291 - val_accuracy: 0.6328\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.5942 - accuracy: 0.6958 - val_loss: 0.6218 - val_accuracy: 0.6407\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.5930 - accuracy: 0.6964 - val_loss: 0.6263 - val_accuracy: 0.6351\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5907 - accuracy: 0.6988 - val_loss: 0.6201 - val_accuracy: 0.6405\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.5883 - accuracy: 0.6981 - val_loss: 0.6161 - val_accuracy: 0.6426\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.5869 - accuracy: 0.7003 - val_loss: 0.6197 - val_accuracy: 0.6386\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.5867 - accuracy: 0.7033 - val_loss: 0.6252 - val_accuracy: 0.6353\n",
      "\n",
      "Training model with sample_size_ratio=0.5...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.1 iterated over 41800 steps satisfies differential privacy with eps = 1.42 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 542us/step - loss: 0.7011 - accuracy: 0.5189 - val_loss: 0.7098 - val_accuracy: 0.4525\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 475us/step - loss: 0.6955 - accuracy: 0.5264 - val_loss: 0.7061 - val_accuracy: 0.4789\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 468us/step - loss: 0.6898 - accuracy: 0.5473 - val_loss: 0.6997 - val_accuracy: 0.5152\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 550us/step - loss: 0.6845 - accuracy: 0.5607 - val_loss: 0.6962 - val_accuracy: 0.5372\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 481us/step - loss: 0.6800 - accuracy: 0.5705 - val_loss: 0.6909 - val_accuracy: 0.5581\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 479us/step - loss: 0.6750 - accuracy: 0.5827 - val_loss: 0.6891 - val_accuracy: 0.5631\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 471us/step - loss: 0.6722 - accuracy: 0.5852 - val_loss: 0.6869 - val_accuracy: 0.5688\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 473us/step - loss: 0.6686 - accuracy: 0.5995 - val_loss: 0.6865 - val_accuracy: 0.5694\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 552us/step - loss: 0.6655 - accuracy: 0.5992 - val_loss: 0.6832 - val_accuracy: 0.5767\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6649 - accuracy: 0.6040 - val_loss: 0.6797 - val_accuracy: 0.5824\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 478us/step - loss: 0.6610 - accuracy: 0.6129 - val_loss: 0.6782 - val_accuracy: 0.5868\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 477us/step - loss: 0.6605 - accuracy: 0.6105 - val_loss: 0.6761 - val_accuracy: 0.5922\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 472us/step - loss: 0.6579 - accuracy: 0.6189 - val_loss: 0.6768 - val_accuracy: 0.5921\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 555us/step - loss: 0.6556 - accuracy: 0.6240 - val_loss: 0.6741 - val_accuracy: 0.5969\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 479us/step - loss: 0.6537 - accuracy: 0.6239 - val_loss: 0.6706 - val_accuracy: 0.6033\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6509 - accuracy: 0.6315 - val_loss: 0.6694 - val_accuracy: 0.6056\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 480us/step - loss: 0.6506 - accuracy: 0.6284 - val_loss: 0.6682 - val_accuracy: 0.6085\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 477us/step - loss: 0.6471 - accuracy: 0.6352 - val_loss: 0.6660 - val_accuracy: 0.6126\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 549us/step - loss: 0.6469 - accuracy: 0.6342 - val_loss: 0.6653 - val_accuracy: 0.6142\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 477us/step - loss: 0.6450 - accuracy: 0.6355 - val_loss: 0.6612 - val_accuracy: 0.6213\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 490us/step - loss: 0.6440 - accuracy: 0.6389 - val_loss: 0.6607 - val_accuracy: 0.6216\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 509us/step - loss: 0.6408 - accuracy: 0.6430 - val_loss: 0.6587 - val_accuracy: 0.6242\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 462us/step - loss: 0.6397 - accuracy: 0.6452 - val_loss: 0.6575 - val_accuracy: 0.6255\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 563us/step - loss: 0.6376 - accuracy: 0.6472 - val_loss: 0.6531 - val_accuracy: 0.6321\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 479us/step - loss: 0.6372 - accuracy: 0.6461 - val_loss: 0.6518 - val_accuracy: 0.6350\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 501us/step - loss: 0.6343 - accuracy: 0.6503 - val_loss: 0.6490 - val_accuracy: 0.6381\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6336 - accuracy: 0.6500 - val_loss: 0.6497 - val_accuracy: 0.6373\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 522us/step - loss: 0.6308 - accuracy: 0.6570 - val_loss: 0.6472 - val_accuracy: 0.6404\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 499us/step - loss: 0.6292 - accuracy: 0.6556 - val_loss: 0.6465 - val_accuracy: 0.6402\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6272 - accuracy: 0.6572 - val_loss: 0.6454 - val_accuracy: 0.6412\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 504us/step - loss: 0.6270 - accuracy: 0.6568 - val_loss: 0.6428 - val_accuracy: 0.6438\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 461us/step - loss: 0.6262 - accuracy: 0.6591 - val_loss: 0.6435 - val_accuracy: 0.6417\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 554us/step - loss: 0.6241 - accuracy: 0.6625 - val_loss: 0.6412 - val_accuracy: 0.6438\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 487us/step - loss: 0.6224 - accuracy: 0.6620 - val_loss: 0.6439 - val_accuracy: 0.6401\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 480us/step - loss: 0.6214 - accuracy: 0.6626 - val_loss: 0.6406 - val_accuracy: 0.6434\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 480us/step - loss: 0.6198 - accuracy: 0.6669 - val_loss: 0.6394 - val_accuracy: 0.6440\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 476us/step - loss: 0.6187 - accuracy: 0.6656 - val_loss: 0.6373 - val_accuracy: 0.6464\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 549us/step - loss: 0.6171 - accuracy: 0.6657 - val_loss: 0.6377 - val_accuracy: 0.6445\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 481us/step - loss: 0.6164 - accuracy: 0.6663 - val_loss: 0.6370 - val_accuracy: 0.6447\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 480us/step - loss: 0.6161 - accuracy: 0.6673 - val_loss: 0.6357 - val_accuracy: 0.6459\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 476us/step - loss: 0.6143 - accuracy: 0.6699 - val_loss: 0.6364 - val_accuracy: 0.6435\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 474us/step - loss: 0.6132 - accuracy: 0.6696 - val_loss: 0.6361 - val_accuracy: 0.6431\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.6107 - accuracy: 0.6734 - val_loss: 0.6331 - val_accuracy: 0.6472\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6092 - accuracy: 0.6757 - val_loss: 0.6306 - val_accuracy: 0.6504\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 472us/step - loss: 0.6102 - accuracy: 0.6677 - val_loss: 0.6279 - val_accuracy: 0.6543\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6090 - accuracy: 0.6737 - val_loss: 0.6289 - val_accuracy: 0.6524\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 538us/step - loss: 0.6073 - accuracy: 0.6728 - val_loss: 0.6319 - val_accuracy: 0.6472\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 508us/step - loss: 0.6051 - accuracy: 0.6751 - val_loss: 0.6323 - val_accuracy: 0.6462\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 513us/step - loss: 0.6040 - accuracy: 0.6763 - val_loss: 0.6294 - val_accuracy: 0.6504\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6041 - accuracy: 0.6786 - val_loss: 0.6290 - val_accuracy: 0.6502\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 554us/step - loss: 0.7485 - accuracy: 0.4829 - val_loss: 0.6014 - val_accuracy: 0.8800\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6981 - accuracy: 0.5145 - val_loss: 0.6672 - val_accuracy: 0.6842\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6884 - accuracy: 0.5425 - val_loss: 0.6890 - val_accuracy: 0.5687\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 608us/step - loss: 0.6839 - accuracy: 0.5539 - val_loss: 0.6974 - val_accuracy: 0.5359\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6831 - accuracy: 0.5612 - val_loss: 0.6965 - val_accuracy: 0.5465\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 507us/step - loss: 0.6785 - accuracy: 0.5666 - val_loss: 0.6957 - val_accuracy: 0.5507\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6761 - accuracy: 0.5760 - val_loss: 0.6935 - val_accuracy: 0.5625\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 600us/step - loss: 0.6740 - accuracy: 0.5840 - val_loss: 0.6919 - val_accuracy: 0.5670\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.6729 - accuracy: 0.5842 - val_loss: 0.6898 - val_accuracy: 0.5717\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.6697 - accuracy: 0.5880 - val_loss: 0.6859 - val_accuracy: 0.5826\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6680 - accuracy: 0.5958 - val_loss: 0.6850 - val_accuracy: 0.5849\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6651 - accuracy: 0.6019 - val_loss: 0.6801 - val_accuracy: 0.5953\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 582us/step - loss: 0.6633 - accuracy: 0.6068 - val_loss: 0.6805 - val_accuracy: 0.5927\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6610 - accuracy: 0.6100 - val_loss: 0.6798 - val_accuracy: 0.5926\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6599 - accuracy: 0.6129 - val_loss: 0.6768 - val_accuracy: 0.5988\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.6578 - accuracy: 0.6164 - val_loss: 0.6759 - val_accuracy: 0.5995\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.6571 - accuracy: 0.6146 - val_loss: 0.6712 - val_accuracy: 0.6073\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 581us/step - loss: 0.6565 - accuracy: 0.6177 - val_loss: 0.6704 - val_accuracy: 0.6072\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6550 - accuracy: 0.6174 - val_loss: 0.6698 - val_accuracy: 0.6068\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6532 - accuracy: 0.6239 - val_loss: 0.6648 - val_accuracy: 0.6164\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 521us/step - loss: 0.6512 - accuracy: 0.6272 - val_loss: 0.6657 - val_accuracy: 0.6119\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6500 - accuracy: 0.6308 - val_loss: 0.6654 - val_accuracy: 0.6111\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6479 - accuracy: 0.6325 - val_loss: 0.6643 - val_accuracy: 0.6120\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 563us/step - loss: 0.6477 - accuracy: 0.6344 - val_loss: 0.6665 - val_accuracy: 0.6047\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 496us/step - loss: 0.6453 - accuracy: 0.6362 - val_loss: 0.6625 - val_accuracy: 0.6132\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6443 - accuracy: 0.6394 - val_loss: 0.6621 - val_accuracy: 0.6111\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 490us/step - loss: 0.6437 - accuracy: 0.6381 - val_loss: 0.6600 - val_accuracy: 0.6143\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6415 - accuracy: 0.6392 - val_loss: 0.6609 - val_accuracy: 0.6110\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6415 - accuracy: 0.6411 - val_loss: 0.6593 - val_accuracy: 0.6131\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.6396 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6184\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6390 - accuracy: 0.6439 - val_loss: 0.6552 - val_accuracy: 0.6190\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6382 - accuracy: 0.6416 - val_loss: 0.6537 - val_accuracy: 0.6199\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6372 - accuracy: 0.6450 - val_loss: 0.6533 - val_accuracy: 0.6200\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.6350 - accuracy: 0.6474 - val_loss: 0.6513 - val_accuracy: 0.6217\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 487us/step - loss: 0.6323 - accuracy: 0.6518 - val_loss: 0.6498 - val_accuracy: 0.6234\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6326 - accuracy: 0.6509 - val_loss: 0.6511 - val_accuracy: 0.6207\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6319 - accuracy: 0.6519 - val_loss: 0.6505 - val_accuracy: 0.6210\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 490us/step - loss: 0.6302 - accuracy: 0.6525 - val_loss: 0.6528 - val_accuracy: 0.6161\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.6286 - accuracy: 0.6572 - val_loss: 0.6501 - val_accuracy: 0.6196\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6280 - accuracy: 0.6568 - val_loss: 0.6490 - val_accuracy: 0.6204\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 487us/step - loss: 0.6266 - accuracy: 0.6583 - val_loss: 0.6447 - val_accuracy: 0.6284\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6267 - accuracy: 0.6598 - val_loss: 0.6466 - val_accuracy: 0.6236\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6243 - accuracy: 0.6582 - val_loss: 0.6456 - val_accuracy: 0.6246\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.6235 - accuracy: 0.6615 - val_loss: 0.6449 - val_accuracy: 0.6245\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6218 - accuracy: 0.6643 - val_loss: 0.6436 - val_accuracy: 0.6262\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6219 - accuracy: 0.6627 - val_loss: 0.6402 - val_accuracy: 0.6312\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 487us/step - loss: 0.6204 - accuracy: 0.6634 - val_loss: 0.6363 - val_accuracy: 0.6371\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6216 - accuracy: 0.6636 - val_loss: 0.6387 - val_accuracy: 0.6325\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.6176 - accuracy: 0.6683 - val_loss: 0.6380 - val_accuracy: 0.6337\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6178 - accuracy: 0.6687 - val_loss: 0.6374 - val_accuracy: 0.6343\n",
      "Epoch 1/50\n",
      "827/836 [============================>.] - ETA: 0s - loss: 0.7671 - accuracy: 0.5208WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 0s 550us/step - loss: 0.7669 - accuracy: 0.5203 - val_loss: 0.8321 - val_accuracy: 0.1303\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.7035 - accuracy: 0.5248 - val_loss: 0.7313 - val_accuracy: 0.3702\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 554us/step - loss: 0.6948 - accuracy: 0.5319 - val_loss: 0.7097 - val_accuracy: 0.4852\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6890 - accuracy: 0.5460 - val_loss: 0.7012 - val_accuracy: 0.5174\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 490us/step - loss: 0.6841 - accuracy: 0.5497 - val_loss: 0.6969 - val_accuracy: 0.5311\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6818 - accuracy: 0.5564 - val_loss: 0.6967 - val_accuracy: 0.5333\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 561us/step - loss: 0.6809 - accuracy: 0.5575 - val_loss: 0.6932 - val_accuracy: 0.5427\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 495us/step - loss: 0.6748 - accuracy: 0.5719 - val_loss: 0.6939 - val_accuracy: 0.5409\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6758 - accuracy: 0.5703 - val_loss: 0.6902 - val_accuracy: 0.5500\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6699 - accuracy: 0.5840 - val_loss: 0.6867 - val_accuracy: 0.5639\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6699 - accuracy: 0.5829 - val_loss: 0.6848 - val_accuracy: 0.5701\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 570us/step - loss: 0.6643 - accuracy: 0.5958 - val_loss: 0.6829 - val_accuracy: 0.5765\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 487us/step - loss: 0.6664 - accuracy: 0.5933 - val_loss: 0.6777 - val_accuracy: 0.5912\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6635 - accuracy: 0.5980 - val_loss: 0.6790 - val_accuracy: 0.5887\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6612 - accuracy: 0.6040 - val_loss: 0.6822 - val_accuracy: 0.5780\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6583 - accuracy: 0.6096 - val_loss: 0.6757 - val_accuracy: 0.5937\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6576 - accuracy: 0.6090 - val_loss: 0.6759 - val_accuracy: 0.5922\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6568 - accuracy: 0.6122 - val_loss: 0.6725 - val_accuracy: 0.5986\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6543 - accuracy: 0.6158 - val_loss: 0.6751 - val_accuracy: 0.5924\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 481us/step - loss: 0.6526 - accuracy: 0.6177 - val_loss: 0.6706 - val_accuracy: 0.6000\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 493us/step - loss: 0.6511 - accuracy: 0.6241 - val_loss: 0.6703 - val_accuracy: 0.6001\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6482 - accuracy: 0.6287 - val_loss: 0.6682 - val_accuracy: 0.6042\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6465 - accuracy: 0.6305 - val_loss: 0.6688 - val_accuracy: 0.6018\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 492us/step - loss: 0.6452 - accuracy: 0.6329 - val_loss: 0.6648 - val_accuracy: 0.6089\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6445 - accuracy: 0.6327 - val_loss: 0.6653 - val_accuracy: 0.6065\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 549us/step - loss: 0.6442 - accuracy: 0.6353 - val_loss: 0.6633 - val_accuracy: 0.6103\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 500us/step - loss: 0.6410 - accuracy: 0.6385 - val_loss: 0.6596 - val_accuracy: 0.6189\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6408 - accuracy: 0.6424 - val_loss: 0.6590 - val_accuracy: 0.6186\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6389 - accuracy: 0.6426 - val_loss: 0.6591 - val_accuracy: 0.6166\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6378 - accuracy: 0.6454 - val_loss: 0.6583 - val_accuracy: 0.6177\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.6367 - accuracy: 0.6467 - val_loss: 0.6566 - val_accuracy: 0.6207\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 492us/step - loss: 0.6348 - accuracy: 0.6512 - val_loss: 0.6546 - val_accuracy: 0.6232\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.6331 - accuracy: 0.6524 - val_loss: 0.6543 - val_accuracy: 0.6229\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 582us/step - loss: 0.6313 - accuracy: 0.6569 - val_loss: 0.6541 - val_accuracy: 0.6220\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6301 - accuracy: 0.6583 - val_loss: 0.6534 - val_accuracy: 0.6228\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6281 - accuracy: 0.6598 - val_loss: 0.6538 - val_accuracy: 0.6208\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6281 - accuracy: 0.6589 - val_loss: 0.6523 - val_accuracy: 0.6221\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6268 - accuracy: 0.6631 - val_loss: 0.6508 - val_accuracy: 0.6246\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6239 - accuracy: 0.6663 - val_loss: 0.6484 - val_accuracy: 0.6287\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6250 - accuracy: 0.6614 - val_loss: 0.6509 - val_accuracy: 0.6227\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6227 - accuracy: 0.6677 - val_loss: 0.6449 - val_accuracy: 0.6314\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6203 - accuracy: 0.6703 - val_loss: 0.6451 - val_accuracy: 0.6305\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6205 - accuracy: 0.6677 - val_loss: 0.6471 - val_accuracy: 0.6276\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6183 - accuracy: 0.6715 - val_loss: 0.6444 - val_accuracy: 0.6310\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.6167 - accuracy: 0.6731 - val_loss: 0.6429 - val_accuracy: 0.6326\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6173 - accuracy: 0.6709 - val_loss: 0.6457 - val_accuracy: 0.6276\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 566us/step - loss: 0.6157 - accuracy: 0.6722 - val_loss: 0.6461 - val_accuracy: 0.6272\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6141 - accuracy: 0.6744 - val_loss: 0.6450 - val_accuracy: 0.6279\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 560us/step - loss: 0.6139 - accuracy: 0.6742 - val_loss: 0.6414 - val_accuracy: 0.6336\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6112 - accuracy: 0.6781 - val_loss: 0.6403 - val_accuracy: 0.6355\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.7020 - accuracy: 0.5321 - val_loss: 0.7681 - val_accuracy: 0.2017\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 586us/step - loss: 0.6873 - accuracy: 0.5472 - val_loss: 0.7246 - val_accuracy: 0.3214\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 592us/step - loss: 0.6834 - accuracy: 0.5539 - val_loss: 0.7101 - val_accuracy: 0.4015\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.6777 - accuracy: 0.5727 - val_loss: 0.7031 - val_accuracy: 0.4563\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6754 - accuracy: 0.5778 - val_loss: 0.7015 - val_accuracy: 0.4777\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.6718 - accuracy: 0.5855 - val_loss: 0.6989 - val_accuracy: 0.4911\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 652us/step - loss: 0.6694 - accuracy: 0.5902 - val_loss: 0.6951 - val_accuracy: 0.5093\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.6674 - accuracy: 0.5966 - val_loss: 0.6889 - val_accuracy: 0.5381\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 586us/step - loss: 0.6647 - accuracy: 0.6015 - val_loss: 0.6883 - val_accuracy: 0.5398\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 550us/step - loss: 0.6620 - accuracy: 0.6072 - val_loss: 0.6879 - val_accuracy: 0.5413\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6613 - accuracy: 0.6069 - val_loss: 0.6865 - val_accuracy: 0.5451\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 595us/step - loss: 0.6594 - accuracy: 0.6118 - val_loss: 0.6819 - val_accuracy: 0.5597\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 580us/step - loss: 0.6554 - accuracy: 0.6203 - val_loss: 0.6815 - val_accuracy: 0.5630\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6551 - accuracy: 0.6255 - val_loss: 0.6799 - val_accuracy: 0.5695\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 582us/step - loss: 0.6525 - accuracy: 0.6257 - val_loss: 0.6781 - val_accuracy: 0.5767\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6525 - accuracy: 0.6274 - val_loss: 0.6803 - val_accuracy: 0.5707\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6507 - accuracy: 0.6263 - val_loss: 0.6778 - val_accuracy: 0.5790\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6483 - accuracy: 0.6329 - val_loss: 0.6772 - val_accuracy: 0.5801\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6487 - accuracy: 0.6320 - val_loss: 0.6746 - val_accuracy: 0.5885\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6449 - accuracy: 0.6377 - val_loss: 0.6719 - val_accuracy: 0.5947\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6434 - accuracy: 0.6371 - val_loss: 0.6712 - val_accuracy: 0.5943\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 592us/step - loss: 0.6430 - accuracy: 0.6413 - val_loss: 0.6705 - val_accuracy: 0.5944\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6404 - accuracy: 0.6484 - val_loss: 0.6691 - val_accuracy: 0.5981\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6392 - accuracy: 0.6441 - val_loss: 0.6673 - val_accuracy: 0.6025\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 580us/step - loss: 0.6386 - accuracy: 0.6497 - val_loss: 0.6661 - val_accuracy: 0.6044\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6367 - accuracy: 0.6490 - val_loss: 0.6632 - val_accuracy: 0.6096\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 578us/step - loss: 0.6371 - accuracy: 0.6468 - val_loss: 0.6643 - val_accuracy: 0.6059\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6343 - accuracy: 0.6531 - val_loss: 0.6617 - val_accuracy: 0.6098\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 563us/step - loss: 0.6334 - accuracy: 0.6545 - val_loss: 0.6620 - val_accuracy: 0.6081\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 698us/step - loss: 0.6312 - accuracy: 0.6582 - val_loss: 0.6612 - val_accuracy: 0.6099\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6304 - accuracy: 0.6589 - val_loss: 0.6576 - val_accuracy: 0.6157\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6290 - accuracy: 0.6576 - val_loss: 0.6574 - val_accuracy: 0.6147\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 599us/step - loss: 0.6280 - accuracy: 0.6611 - val_loss: 0.6585 - val_accuracy: 0.6124\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 674us/step - loss: 0.6260 - accuracy: 0.6640 - val_loss: 0.6542 - val_accuracy: 0.6208\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6257 - accuracy: 0.6613 - val_loss: 0.6518 - val_accuracy: 0.6249\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 654us/step - loss: 0.6241 - accuracy: 0.6651 - val_loss: 0.6541 - val_accuracy: 0.6197\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6217 - accuracy: 0.6693 - val_loss: 0.6535 - val_accuracy: 0.6204\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6215 - accuracy: 0.6665 - val_loss: 0.6491 - val_accuracy: 0.6280\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6194 - accuracy: 0.6699 - val_loss: 0.6501 - val_accuracy: 0.6260\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6180 - accuracy: 0.6697 - val_loss: 0.6488 - val_accuracy: 0.6262\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6157 - accuracy: 0.6729 - val_loss: 0.6474 - val_accuracy: 0.6286\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 581us/step - loss: 0.6148 - accuracy: 0.6741 - val_loss: 0.6453 - val_accuracy: 0.6312\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6122 - accuracy: 0.6782 - val_loss: 0.6471 - val_accuracy: 0.6269\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6128 - accuracy: 0.6750 - val_loss: 0.6478 - val_accuracy: 0.6255\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 585us/step - loss: 0.6116 - accuracy: 0.6754 - val_loss: 0.6429 - val_accuracy: 0.6311\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 574us/step - loss: 0.6106 - accuracy: 0.6742 - val_loss: 0.6419 - val_accuracy: 0.6319\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6097 - accuracy: 0.6769 - val_loss: 0.6402 - val_accuracy: 0.6344\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 604us/step - loss: 0.6072 - accuracy: 0.6807 - val_loss: 0.6441 - val_accuracy: 0.6297\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.6051 - accuracy: 0.6834 - val_loss: 0.6406 - val_accuracy: 0.6340\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6060 - accuracy: 0.6789 - val_loss: 0.6440 - val_accuracy: 0.6299\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 681us/step - loss: 0.7325 - accuracy: 0.4705 - val_loss: 0.7018 - val_accuracy: 0.4574\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.7191 - accuracy: 0.4792 - val_loss: 0.7194 - val_accuracy: 0.4127\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.7103 - accuracy: 0.5013 - val_loss: 0.7159 - val_accuracy: 0.4201\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.7060 - accuracy: 0.5097 - val_loss: 0.7098 - val_accuracy: 0.4557\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.6997 - accuracy: 0.5195 - val_loss: 0.7011 - val_accuracy: 0.5018\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 597us/step - loss: 0.6931 - accuracy: 0.5349 - val_loss: 0.7003 - val_accuracy: 0.5029\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6868 - accuracy: 0.5446 - val_loss: 0.7031 - val_accuracy: 0.4880\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6814 - accuracy: 0.5598 - val_loss: 0.6983 - val_accuracy: 0.5053\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.6811 - accuracy: 0.5659 - val_loss: 0.6914 - val_accuracy: 0.5404\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 590us/step - loss: 0.6740 - accuracy: 0.5808 - val_loss: 0.6870 - val_accuracy: 0.5628\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6734 - accuracy: 0.5822 - val_loss: 0.6859 - val_accuracy: 0.5638\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 584us/step - loss: 0.6680 - accuracy: 0.5939 - val_loss: 0.6857 - val_accuracy: 0.5651\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6639 - accuracy: 0.6009 - val_loss: 0.6842 - val_accuracy: 0.5712\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 593us/step - loss: 0.6617 - accuracy: 0.6085 - val_loss: 0.6790 - val_accuracy: 0.5851\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6580 - accuracy: 0.6151 - val_loss: 0.6772 - val_accuracy: 0.5905\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.6550 - accuracy: 0.6188 - val_loss: 0.6730 - val_accuracy: 0.6037\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6536 - accuracy: 0.6251 - val_loss: 0.6698 - val_accuracy: 0.6091\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6507 - accuracy: 0.6293 - val_loss: 0.6682 - val_accuracy: 0.6095\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 563us/step - loss: 0.6480 - accuracy: 0.6298 - val_loss: 0.6721 - val_accuracy: 0.5976\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6463 - accuracy: 0.6352 - val_loss: 0.6682 - val_accuracy: 0.6040\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.6424 - accuracy: 0.6442 - val_loss: 0.6635 - val_accuracy: 0.6096\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6420 - accuracy: 0.6457 - val_loss: 0.6685 - val_accuracy: 0.5969\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6391 - accuracy: 0.6519 - val_loss: 0.6594 - val_accuracy: 0.6157\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.6361 - accuracy: 0.6557 - val_loss: 0.6610 - val_accuracy: 0.6093\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6354 - accuracy: 0.6552 - val_loss: 0.6585 - val_accuracy: 0.6113\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6329 - accuracy: 0.6618 - val_loss: 0.6529 - val_accuracy: 0.6247\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.6310 - accuracy: 0.6646 - val_loss: 0.6586 - val_accuracy: 0.6096\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 598us/step - loss: 0.6295 - accuracy: 0.6648 - val_loss: 0.6513 - val_accuracy: 0.6234\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6280 - accuracy: 0.6649 - val_loss: 0.6511 - val_accuracy: 0.6209\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.6243 - accuracy: 0.6703 - val_loss: 0.6537 - val_accuracy: 0.6176\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 683us/step - loss: 0.6242 - accuracy: 0.6701 - val_loss: 0.6492 - val_accuracy: 0.6227\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6233 - accuracy: 0.6718 - val_loss: 0.6510 - val_accuracy: 0.6198\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 596us/step - loss: 0.6226 - accuracy: 0.6730 - val_loss: 0.6478 - val_accuracy: 0.6248\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6201 - accuracy: 0.6769 - val_loss: 0.6449 - val_accuracy: 0.6294\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 587us/step - loss: 0.6173 - accuracy: 0.6788 - val_loss: 0.6474 - val_accuracy: 0.6253\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.6164 - accuracy: 0.6813 - val_loss: 0.6448 - val_accuracy: 0.6287\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6157 - accuracy: 0.6817 - val_loss: 0.6388 - val_accuracy: 0.6387\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.6122 - accuracy: 0.6833 - val_loss: 0.6398 - val_accuracy: 0.6360\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 587us/step - loss: 0.6127 - accuracy: 0.6850 - val_loss: 0.6401 - val_accuracy: 0.6355\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.6098 - accuracy: 0.6859 - val_loss: 0.6401 - val_accuracy: 0.6356\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6090 - accuracy: 0.6899 - val_loss: 0.6354 - val_accuracy: 0.6422\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 589us/step - loss: 0.6080 - accuracy: 0.6892 - val_loss: 0.6356 - val_accuracy: 0.6417\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.6077 - accuracy: 0.6883 - val_loss: 0.6384 - val_accuracy: 0.6376\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.6053 - accuracy: 0.6933 - val_loss: 0.6419 - val_accuracy: 0.6335\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6035 - accuracy: 0.6949 - val_loss: 0.6383 - val_accuracy: 0.6381\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 586us/step - loss: 0.6024 - accuracy: 0.6942 - val_loss: 0.6416 - val_accuracy: 0.6337\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6008 - accuracy: 0.6967 - val_loss: 0.6361 - val_accuracy: 0.6397\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.5993 - accuracy: 0.6976 - val_loss: 0.6300 - val_accuracy: 0.6469\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 583us/step - loss: 0.5997 - accuracy: 0.6956 - val_loss: 0.6246 - val_accuracy: 0.6547\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 579us/step - loss: 0.5964 - accuracy: 0.7031 - val_loss: 0.6279 - val_accuracy: 0.6480\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.7094 - accuracy: 0.4787 - val_loss: 0.6794 - val_accuracy: 0.6208\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.7023 - accuracy: 0.4967 - val_loss: 0.7010 - val_accuracy: 0.4476\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.6997 - accuracy: 0.5074 - val_loss: 0.7097 - val_accuracy: 0.3616\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6998 - accuracy: 0.5102 - val_loss: 0.7125 - val_accuracy: 0.3393\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 560us/step - loss: 0.6959 - accuracy: 0.5206 - val_loss: 0.7126 - val_accuracy: 0.3372\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.6964 - accuracy: 0.5164 - val_loss: 0.7115 - val_accuracy: 0.3439\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 644us/step - loss: 0.6926 - accuracy: 0.5332 - val_loss: 0.7101 - val_accuracy: 0.3535\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 568us/step - loss: 0.6925 - accuracy: 0.5338 - val_loss: 0.7098 - val_accuracy: 0.3595\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6915 - accuracy: 0.5344 - val_loss: 0.7087 - val_accuracy: 0.3719\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 616us/step - loss: 0.6905 - accuracy: 0.5424 - val_loss: 0.7077 - val_accuracy: 0.3829\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6870 - accuracy: 0.5495 - val_loss: 0.7058 - val_accuracy: 0.3968\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 549us/step - loss: 0.6866 - accuracy: 0.5551 - val_loss: 0.7032 - val_accuracy: 0.4203\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 559us/step - loss: 0.6848 - accuracy: 0.5569 - val_loss: 0.7017 - val_accuracy: 0.4385\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.6839 - accuracy: 0.5626 - val_loss: 0.7017 - val_accuracy: 0.4435\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6821 - accuracy: 0.5675 - val_loss: 0.7006 - val_accuracy: 0.4571\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 563us/step - loss: 0.6808 - accuracy: 0.5749 - val_loss: 0.6987 - val_accuracy: 0.4763\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6783 - accuracy: 0.5774 - val_loss: 0.6981 - val_accuracy: 0.4828\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6777 - accuracy: 0.5831 - val_loss: 0.6961 - val_accuracy: 0.4960\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.6758 - accuracy: 0.5847 - val_loss: 0.6950 - val_accuracy: 0.5045\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.6744 - accuracy: 0.5937 - val_loss: 0.6925 - val_accuracy: 0.5189\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6730 - accuracy: 0.5929 - val_loss: 0.6918 - val_accuracy: 0.5225\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6705 - accuracy: 0.6018 - val_loss: 0.6909 - val_accuracy: 0.5285\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 552us/step - loss: 0.6702 - accuracy: 0.6041 - val_loss: 0.6897 - val_accuracy: 0.5371\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6681 - accuracy: 0.6123 - val_loss: 0.6896 - val_accuracy: 0.5357\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 552us/step - loss: 0.6660 - accuracy: 0.6164 - val_loss: 0.6888 - val_accuracy: 0.5388\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6646 - accuracy: 0.6123 - val_loss: 0.6897 - val_accuracy: 0.5325\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6622 - accuracy: 0.6247 - val_loss: 0.6897 - val_accuracy: 0.5328\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 537us/step - loss: 0.6609 - accuracy: 0.6255 - val_loss: 0.6899 - val_accuracy: 0.5352\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 536us/step - loss: 0.6596 - accuracy: 0.6266 - val_loss: 0.6879 - val_accuracy: 0.5467\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 537us/step - loss: 0.6580 - accuracy: 0.6309 - val_loss: 0.6857 - val_accuracy: 0.5563\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6562 - accuracy: 0.6372 - val_loss: 0.6849 - val_accuracy: 0.5605\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 556us/step - loss: 0.6549 - accuracy: 0.6382 - val_loss: 0.6827 - val_accuracy: 0.5703\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 541us/step - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6805 - val_accuracy: 0.5777\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 615us/step - loss: 0.6526 - accuracy: 0.6435 - val_loss: 0.6804 - val_accuracy: 0.5775\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 563us/step - loss: 0.6517 - accuracy: 0.6431 - val_loss: 0.6798 - val_accuracy: 0.5780\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6498 - accuracy: 0.6480 - val_loss: 0.6781 - val_accuracy: 0.5827\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 492us/step - loss: 0.6477 - accuracy: 0.6528 - val_loss: 0.6788 - val_accuracy: 0.5786\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 574us/step - loss: 0.6480 - accuracy: 0.6495 - val_loss: 0.6743 - val_accuracy: 0.5949\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 668us/step - loss: 0.6456 - accuracy: 0.6567 - val_loss: 0.6768 - val_accuracy: 0.5839\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 519us/step - loss: 0.6438 - accuracy: 0.6602 - val_loss: 0.6744 - val_accuracy: 0.5911\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 546us/step - loss: 0.6443 - accuracy: 0.6589 - val_loss: 0.6732 - val_accuracy: 0.5948\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6422 - accuracy: 0.6596 - val_loss: 0.6723 - val_accuracy: 0.5975\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 478us/step - loss: 0.6410 - accuracy: 0.6625 - val_loss: 0.6699 - val_accuracy: 0.6031\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6401 - accuracy: 0.6621 - val_loss: 0.6694 - val_accuracy: 0.6032\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 464us/step - loss: 0.6390 - accuracy: 0.6645 - val_loss: 0.6708 - val_accuracy: 0.5976\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 566us/step - loss: 0.6387 - accuracy: 0.6644 - val_loss: 0.6677 - val_accuracy: 0.6042\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 467us/step - loss: 0.6361 - accuracy: 0.6680 - val_loss: 0.6664 - val_accuracy: 0.6058\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 472us/step - loss: 0.6360 - accuracy: 0.6645 - val_loss: 0.6652 - val_accuracy: 0.6078\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.6347 - accuracy: 0.6663 - val_loss: 0.6641 - val_accuracy: 0.6090\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 481us/step - loss: 0.6334 - accuracy: 0.6696 - val_loss: 0.6627 - val_accuracy: 0.6112\n",
      "Epoch 1/50\n",
      "789/836 [===========================>..] - ETA: 0s - loss: 0.7133 - accuracy: 0.5146WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 0s 551us/step - loss: 0.7128 - accuracy: 0.5156 - val_loss: 0.7174 - val_accuracy: 0.3697\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 471us/step - loss: 0.7078 - accuracy: 0.5197 - val_loss: 0.7082 - val_accuracy: 0.4330\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 544us/step - loss: 0.7032 - accuracy: 0.5241 - val_loss: 0.7071 - val_accuracy: 0.4461\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 476us/step - loss: 0.7012 - accuracy: 0.5306 - val_loss: 0.7019 - val_accuracy: 0.4803\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 477us/step - loss: 0.6956 - accuracy: 0.5377 - val_loss: 0.7004 - val_accuracy: 0.4898\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 471us/step - loss: 0.6911 - accuracy: 0.5478 - val_loss: 0.6964 - val_accuracy: 0.5108\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 561us/step - loss: 0.6874 - accuracy: 0.5553 - val_loss: 0.6902 - val_accuracy: 0.5406\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 479us/step - loss: 0.6857 - accuracy: 0.5583 - val_loss: 0.6888 - val_accuracy: 0.5479\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 478us/step - loss: 0.6846 - accuracy: 0.5600 - val_loss: 0.6875 - val_accuracy: 0.5589\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 551us/step - loss: 0.6827 - accuracy: 0.5661 - val_loss: 0.6827 - val_accuracy: 0.5816\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 479us/step - loss: 0.6787 - accuracy: 0.5722 - val_loss: 0.6834 - val_accuracy: 0.5807\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 473us/step - loss: 0.6772 - accuracy: 0.5745 - val_loss: 0.6771 - val_accuracy: 0.6028\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 472us/step - loss: 0.6742 - accuracy: 0.5828 - val_loss: 0.6739 - val_accuracy: 0.6110\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 551us/step - loss: 0.6728 - accuracy: 0.5847 - val_loss: 0.6743 - val_accuracy: 0.6082\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 478us/step - loss: 0.6699 - accuracy: 0.5921 - val_loss: 0.6725 - val_accuracy: 0.6110\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 474us/step - loss: 0.6667 - accuracy: 0.5963 - val_loss: 0.6709 - val_accuracy: 0.6120\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 548us/step - loss: 0.6660 - accuracy: 0.5979 - val_loss: 0.6728 - val_accuracy: 0.6070\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 513us/step - loss: 0.6651 - accuracy: 0.5992 - val_loss: 0.6720 - val_accuracy: 0.6080\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 478us/step - loss: 0.6614 - accuracy: 0.6055 - val_loss: 0.6697 - val_accuracy: 0.6125\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 476us/step - loss: 0.6586 - accuracy: 0.6141 - val_loss: 0.6667 - val_accuracy: 0.6168\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 476us/step - loss: 0.6573 - accuracy: 0.6183 - val_loss: 0.6650 - val_accuracy: 0.6184\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6577 - accuracy: 0.6139 - val_loss: 0.6651 - val_accuracy: 0.6166\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 478us/step - loss: 0.6555 - accuracy: 0.6203 - val_loss: 0.6640 - val_accuracy: 0.6168\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 537us/step - loss: 0.6537 - accuracy: 0.6224 - val_loss: 0.6649 - val_accuracy: 0.6144\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 504us/step - loss: 0.6530 - accuracy: 0.6262 - val_loss: 0.6631 - val_accuracy: 0.6167\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 477us/step - loss: 0.6508 - accuracy: 0.6280 - val_loss: 0.6578 - val_accuracy: 0.6255\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 477us/step - loss: 0.6491 - accuracy: 0.6330 - val_loss: 0.6541 - val_accuracy: 0.6302\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 487us/step - loss: 0.6458 - accuracy: 0.6380 - val_loss: 0.6522 - val_accuracy: 0.6321\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 559us/step - loss: 0.6451 - accuracy: 0.6380 - val_loss: 0.6553 - val_accuracy: 0.6276\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 511us/step - loss: 0.6445 - accuracy: 0.6386 - val_loss: 0.6553 - val_accuracy: 0.6258\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 478us/step - loss: 0.6427 - accuracy: 0.6409 - val_loss: 0.6523 - val_accuracy: 0.6303\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 566us/step - loss: 0.6415 - accuracy: 0.6427 - val_loss: 0.6472 - val_accuracy: 0.6353\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6388 - accuracy: 0.6481 - val_loss: 0.6479 - val_accuracy: 0.6333\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 480us/step - loss: 0.6390 - accuracy: 0.6467 - val_loss: 0.6477 - val_accuracy: 0.6329\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 482us/step - loss: 0.6380 - accuracy: 0.6490 - val_loss: 0.6478 - val_accuracy: 0.6316\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 555us/step - loss: 0.6343 - accuracy: 0.6546 - val_loss: 0.6463 - val_accuracy: 0.6337\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 480us/step - loss: 0.6358 - accuracy: 0.6531 - val_loss: 0.6466 - val_accuracy: 0.6330\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 470us/step - loss: 0.6328 - accuracy: 0.6589 - val_loss: 0.6442 - val_accuracy: 0.6359\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 553us/step - loss: 0.6314 - accuracy: 0.6591 - val_loss: 0.6447 - val_accuracy: 0.6347\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6321 - accuracy: 0.6586 - val_loss: 0.6399 - val_accuracy: 0.6394\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6302 - accuracy: 0.6630 - val_loss: 0.6427 - val_accuracy: 0.6359\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6292 - accuracy: 0.6587 - val_loss: 0.6396 - val_accuracy: 0.6385\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6268 - accuracy: 0.6659 - val_loss: 0.6412 - val_accuracy: 0.6368\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6275 - accuracy: 0.6626 - val_loss: 0.6371 - val_accuracy: 0.6407\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 481us/step - loss: 0.6251 - accuracy: 0.6663 - val_loss: 0.6383 - val_accuracy: 0.6389\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.6246 - accuracy: 0.6673 - val_loss: 0.6387 - val_accuracy: 0.6382\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6237 - accuracy: 0.6676 - val_loss: 0.6372 - val_accuracy: 0.6392\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6222 - accuracy: 0.6708 - val_loss: 0.6344 - val_accuracy: 0.6419\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 548us/step - loss: 0.6202 - accuracy: 0.6721 - val_loss: 0.6318 - val_accuracy: 0.6434\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6190 - accuracy: 0.6729 - val_loss: 0.6377 - val_accuracy: 0.6380\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 555us/step - loss: 0.6964 - accuracy: 0.5203 - val_loss: 0.7372 - val_accuracy: 0.2696\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 480us/step - loss: 0.6938 - accuracy: 0.5269 - val_loss: 0.7279 - val_accuracy: 0.3327\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.6909 - accuracy: 0.5367 - val_loss: 0.7223 - val_accuracy: 0.3703\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 480us/step - loss: 0.6876 - accuracy: 0.5447 - val_loss: 0.7170 - val_accuracy: 0.3971\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 476us/step - loss: 0.6844 - accuracy: 0.5544 - val_loss: 0.7128 - val_accuracy: 0.4172\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 549us/step - loss: 0.6819 - accuracy: 0.5568 - val_loss: 0.7093 - val_accuracy: 0.4416\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 667us/step - loss: 0.6795 - accuracy: 0.5669 - val_loss: 0.7080 - val_accuracy: 0.4594\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 490us/step - loss: 0.6787 - accuracy: 0.5719 - val_loss: 0.7069 - val_accuracy: 0.4713\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6763 - accuracy: 0.5759 - val_loss: 0.7048 - val_accuracy: 0.4819\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6752 - accuracy: 0.5771 - val_loss: 0.7037 - val_accuracy: 0.4908\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 481us/step - loss: 0.6724 - accuracy: 0.5870 - val_loss: 0.7018 - val_accuracy: 0.5071\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 547us/step - loss: 0.6719 - accuracy: 0.5886 - val_loss: 0.7011 - val_accuracy: 0.5155\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 494us/step - loss: 0.6699 - accuracy: 0.5943 - val_loss: 0.6993 - val_accuracy: 0.5213\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 513us/step - loss: 0.6688 - accuracy: 0.5986 - val_loss: 0.7001 - val_accuracy: 0.5170\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6668 - accuracy: 0.6020 - val_loss: 0.6978 - val_accuracy: 0.5255\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 574us/step - loss: 0.6648 - accuracy: 0.6066 - val_loss: 0.6952 - val_accuracy: 0.5339\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6635 - accuracy: 0.6115 - val_loss: 0.6948 - val_accuracy: 0.5337\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 480us/step - loss: 0.6610 - accuracy: 0.6165 - val_loss: 0.6936 - val_accuracy: 0.5372\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 556us/step - loss: 0.6607 - accuracy: 0.6140 - val_loss: 0.6901 - val_accuracy: 0.5454\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6585 - accuracy: 0.6188 - val_loss: 0.6911 - val_accuracy: 0.5395\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 492us/step - loss: 0.6577 - accuracy: 0.6203 - val_loss: 0.6902 - val_accuracy: 0.5411\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 551us/step - loss: 0.6553 - accuracy: 0.6254 - val_loss: 0.6874 - val_accuracy: 0.5509\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 502us/step - loss: 0.6557 - accuracy: 0.6270 - val_loss: 0.6854 - val_accuracy: 0.5573\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 482us/step - loss: 0.6536 - accuracy: 0.6303 - val_loss: 0.6827 - val_accuracy: 0.5643\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6516 - accuracy: 0.6299 - val_loss: 0.6814 - val_accuracy: 0.5667\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.6504 - accuracy: 0.6323 - val_loss: 0.6805 - val_accuracy: 0.5695\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6490 - accuracy: 0.6395 - val_loss: 0.6799 - val_accuracy: 0.5699\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 481us/step - loss: 0.6483 - accuracy: 0.6348 - val_loss: 0.6800 - val_accuracy: 0.5684\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 477us/step - loss: 0.6454 - accuracy: 0.6410 - val_loss: 0.6786 - val_accuracy: 0.5710\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 559us/step - loss: 0.6446 - accuracy: 0.6427 - val_loss: 0.6777 - val_accuracy: 0.5705\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6446 - accuracy: 0.6434 - val_loss: 0.6739 - val_accuracy: 0.5789\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 482us/step - loss: 0.6422 - accuracy: 0.6455 - val_loss: 0.6751 - val_accuracy: 0.5753\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 558us/step - loss: 0.6416 - accuracy: 0.6460 - val_loss: 0.6712 - val_accuracy: 0.5841\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6404 - accuracy: 0.6487 - val_loss: 0.6695 - val_accuracy: 0.5868\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6400 - accuracy: 0.6455 - val_loss: 0.6694 - val_accuracy: 0.5839\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 552us/step - loss: 0.6388 - accuracy: 0.6485 - val_loss: 0.6675 - val_accuracy: 0.5901\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 487us/step - loss: 0.6367 - accuracy: 0.6530 - val_loss: 0.6669 - val_accuracy: 0.5902\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6353 - accuracy: 0.6531 - val_loss: 0.6660 - val_accuracy: 0.5913\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 563us/step - loss: 0.6355 - accuracy: 0.6524 - val_loss: 0.6642 - val_accuracy: 0.5949\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6341 - accuracy: 0.6538 - val_loss: 0.6624 - val_accuracy: 0.5989\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 497us/step - loss: 0.6336 - accuracy: 0.6563 - val_loss: 0.6633 - val_accuracy: 0.5959\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 580us/step - loss: 0.6318 - accuracy: 0.6525 - val_loss: 0.6626 - val_accuracy: 0.5968\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 493us/step - loss: 0.6307 - accuracy: 0.6553 - val_loss: 0.6607 - val_accuracy: 0.5998\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 496us/step - loss: 0.6289 - accuracy: 0.6614 - val_loss: 0.6597 - val_accuracy: 0.6004\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6295 - accuracy: 0.6565 - val_loss: 0.6593 - val_accuracy: 0.5990\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 496us/step - loss: 0.6286 - accuracy: 0.6574 - val_loss: 0.6567 - val_accuracy: 0.6029\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 490us/step - loss: 0.6276 - accuracy: 0.6633 - val_loss: 0.6572 - val_accuracy: 0.6009\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 550us/step - loss: 0.6260 - accuracy: 0.6634 - val_loss: 0.6565 - val_accuracy: 0.6001\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 506us/step - loss: 0.6266 - accuracy: 0.6577 - val_loss: 0.6552 - val_accuracy: 0.6019\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 487us/step - loss: 0.6238 - accuracy: 0.6640 - val_loss: 0.6551 - val_accuracy: 0.6006\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 606us/step - loss: 0.7002 - accuracy: 0.5427 - val_loss: 0.7742 - val_accuracy: 0.2535\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 494us/step - loss: 0.6894 - accuracy: 0.5569 - val_loss: 0.7345 - val_accuracy: 0.3598\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6842 - accuracy: 0.5629 - val_loss: 0.7167 - val_accuracy: 0.4529\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 559us/step - loss: 0.6803 - accuracy: 0.5691 - val_loss: 0.7080 - val_accuracy: 0.4824\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 493us/step - loss: 0.6781 - accuracy: 0.5770 - val_loss: 0.7046 - val_accuracy: 0.4987\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6741 - accuracy: 0.5871 - val_loss: 0.6976 - val_accuracy: 0.5277\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 581us/step - loss: 0.6714 - accuracy: 0.5930 - val_loss: 0.6954 - val_accuracy: 0.5357\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 525us/step - loss: 0.6719 - accuracy: 0.5898 - val_loss: 0.6929 - val_accuracy: 0.5413\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 477us/step - loss: 0.6681 - accuracy: 0.5992 - val_loss: 0.6896 - val_accuracy: 0.5492\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 570us/step - loss: 0.6672 - accuracy: 0.6025 - val_loss: 0.6869 - val_accuracy: 0.5550\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 504us/step - loss: 0.6641 - accuracy: 0.6100 - val_loss: 0.6870 - val_accuracy: 0.5553\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 522us/step - loss: 0.6625 - accuracy: 0.6151 - val_loss: 0.6854 - val_accuracy: 0.5588\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 473us/step - loss: 0.6604 - accuracy: 0.6201 - val_loss: 0.6834 - val_accuracy: 0.5665\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 605us/step - loss: 0.6576 - accuracy: 0.6251 - val_loss: 0.6796 - val_accuracy: 0.5740\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 479us/step - loss: 0.6552 - accuracy: 0.6258 - val_loss: 0.6785 - val_accuracy: 0.5783\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 545us/step - loss: 0.6540 - accuracy: 0.6287 - val_loss: 0.6768 - val_accuracy: 0.5831\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 504us/step - loss: 0.6522 - accuracy: 0.6361 - val_loss: 0.6747 - val_accuracy: 0.5892\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6501 - accuracy: 0.6370 - val_loss: 0.6740 - val_accuracy: 0.5905\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 493us/step - loss: 0.6498 - accuracy: 0.6376 - val_loss: 0.6742 - val_accuracy: 0.5901\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6465 - accuracy: 0.6430 - val_loss: 0.6716 - val_accuracy: 0.5941\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 498us/step - loss: 0.6447 - accuracy: 0.6463 - val_loss: 0.6695 - val_accuracy: 0.5981\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6427 - accuracy: 0.6501 - val_loss: 0.6670 - val_accuracy: 0.6021\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.6412 - accuracy: 0.6522 - val_loss: 0.6656 - val_accuracy: 0.6057\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6398 - accuracy: 0.6519 - val_loss: 0.6646 - val_accuracy: 0.6060\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6376 - accuracy: 0.6560 - val_loss: 0.6615 - val_accuracy: 0.6088\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6370 - accuracy: 0.6548 - val_loss: 0.6602 - val_accuracy: 0.6096\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 499us/step - loss: 0.6358 - accuracy: 0.6605 - val_loss: 0.6605 - val_accuracy: 0.6072\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6339 - accuracy: 0.6647 - val_loss: 0.6587 - val_accuracy: 0.6085\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.6334 - accuracy: 0.6642 - val_loss: 0.6565 - val_accuracy: 0.6111\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6314 - accuracy: 0.6665 - val_loss: 0.6543 - val_accuracy: 0.6137\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 490us/step - loss: 0.6306 - accuracy: 0.6669 - val_loss: 0.6570 - val_accuracy: 0.6102\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6290 - accuracy: 0.6684 - val_loss: 0.6536 - val_accuracy: 0.6138\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 503us/step - loss: 0.6274 - accuracy: 0.6720 - val_loss: 0.6519 - val_accuracy: 0.6157\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6287 - accuracy: 0.6707 - val_loss: 0.6479 - val_accuracy: 0.6219\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 571us/step - loss: 0.6265 - accuracy: 0.6725 - val_loss: 0.6504 - val_accuracy: 0.6171\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 494us/step - loss: 0.6262 - accuracy: 0.6698 - val_loss: 0.6480 - val_accuracy: 0.6210\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 492us/step - loss: 0.6252 - accuracy: 0.6723 - val_loss: 0.6442 - val_accuracy: 0.6260\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 609us/step - loss: 0.6237 - accuracy: 0.6774 - val_loss: 0.6448 - val_accuracy: 0.6237\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 496us/step - loss: 0.6215 - accuracy: 0.6772 - val_loss: 0.6450 - val_accuracy: 0.6222\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 494us/step - loss: 0.6181 - accuracy: 0.6811 - val_loss: 0.6423 - val_accuracy: 0.6256\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 576us/step - loss: 0.6195 - accuracy: 0.6804 - val_loss: 0.6403 - val_accuracy: 0.6278\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 492us/step - loss: 0.6188 - accuracy: 0.6794 - val_loss: 0.6397 - val_accuracy: 0.6278\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6174 - accuracy: 0.6811 - val_loss: 0.6385 - val_accuracy: 0.6291\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6171 - accuracy: 0.6823 - val_loss: 0.6390 - val_accuracy: 0.6268\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 493us/step - loss: 0.6140 - accuracy: 0.6863 - val_loss: 0.6398 - val_accuracy: 0.6251\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 565us/step - loss: 0.6139 - accuracy: 0.6845 - val_loss: 0.6380 - val_accuracy: 0.6273\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 492us/step - loss: 0.6137 - accuracy: 0.6847 - val_loss: 0.6371 - val_accuracy: 0.6283\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6124 - accuracy: 0.6888 - val_loss: 0.6346 - val_accuracy: 0.6312\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6105 - accuracy: 0.6889 - val_loss: 0.6360 - val_accuracy: 0.6292\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 497us/step - loss: 0.6110 - accuracy: 0.6863 - val_loss: 0.6355 - val_accuracy: 0.6294\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 0s 560us/step - loss: 0.7146 - accuracy: 0.5150 - val_loss: 0.8131 - val_accuracy: 0.1350\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.6967 - accuracy: 0.5329 - val_loss: 0.7577 - val_accuracy: 0.2195\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6882 - accuracy: 0.5539 - val_loss: 0.7355 - val_accuracy: 0.3340\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.6835 - accuracy: 0.5661 - val_loss: 0.7229 - val_accuracy: 0.4074\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 0s 501us/step - loss: 0.6807 - accuracy: 0.5745 - val_loss: 0.7184 - val_accuracy: 0.4355\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6792 - accuracy: 0.5855 - val_loss: 0.7146 - val_accuracy: 0.4554\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 0s 566us/step - loss: 0.6747 - accuracy: 0.5916 - val_loss: 0.7134 - val_accuracy: 0.4651\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 0s 496us/step - loss: 0.6724 - accuracy: 0.5948 - val_loss: 0.7091 - val_accuracy: 0.4811\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 0s 496us/step - loss: 0.6705 - accuracy: 0.6019 - val_loss: 0.7060 - val_accuracy: 0.4924\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 0s 575us/step - loss: 0.6697 - accuracy: 0.6028 - val_loss: 0.7037 - val_accuracy: 0.5011\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 0s 493us/step - loss: 0.6689 - accuracy: 0.6095 - val_loss: 0.7015 - val_accuracy: 0.5077\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 0s 493us/step - loss: 0.6674 - accuracy: 0.6106 - val_loss: 0.6975 - val_accuracy: 0.5175\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6641 - accuracy: 0.6146 - val_loss: 0.6948 - val_accuracy: 0.5253\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 0s 492us/step - loss: 0.6619 - accuracy: 0.6210 - val_loss: 0.6937 - val_accuracy: 0.5278\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 0s 487us/step - loss: 0.6601 - accuracy: 0.6234 - val_loss: 0.6907 - val_accuracy: 0.5359\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6577 - accuracy: 0.6279 - val_loss: 0.6894 - val_accuracy: 0.5382\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6571 - accuracy: 0.6302 - val_loss: 0.6873 - val_accuracy: 0.5430\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 0s 562us/step - loss: 0.6527 - accuracy: 0.6376 - val_loss: 0.6830 - val_accuracy: 0.5556\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 0s 495us/step - loss: 0.6523 - accuracy: 0.6373 - val_loss: 0.6821 - val_accuracy: 0.5590\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 0s 482us/step - loss: 0.6498 - accuracy: 0.6376 - val_loss: 0.6778 - val_accuracy: 0.5685\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 0s 577us/step - loss: 0.6492 - accuracy: 0.6409 - val_loss: 0.6773 - val_accuracy: 0.5703\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6474 - accuracy: 0.6444 - val_loss: 0.6757 - val_accuracy: 0.5739\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 0s 483us/step - loss: 0.6462 - accuracy: 0.6452 - val_loss: 0.6738 - val_accuracy: 0.5769\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.6451 - accuracy: 0.6463 - val_loss: 0.6737 - val_accuracy: 0.5783\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 0s 491us/step - loss: 0.6413 - accuracy: 0.6523 - val_loss: 0.6720 - val_accuracy: 0.5810\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6410 - accuracy: 0.6551 - val_loss: 0.6681 - val_accuracy: 0.5876\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 0s 569us/step - loss: 0.6401 - accuracy: 0.6514 - val_loss: 0.6655 - val_accuracy: 0.5911\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 0s 494us/step - loss: 0.6387 - accuracy: 0.6532 - val_loss: 0.6666 - val_accuracy: 0.5891\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 0s 486us/step - loss: 0.6382 - accuracy: 0.6568 - val_loss: 0.6667 - val_accuracy: 0.5895\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 0s 573us/step - loss: 0.6372 - accuracy: 0.6591 - val_loss: 0.6647 - val_accuracy: 0.5926\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 0s 481us/step - loss: 0.6356 - accuracy: 0.6602 - val_loss: 0.6652 - val_accuracy: 0.5926\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 0s 551us/step - loss: 0.6327 - accuracy: 0.6634 - val_loss: 0.6614 - val_accuracy: 0.5991\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 0s 509us/step - loss: 0.6320 - accuracy: 0.6650 - val_loss: 0.6598 - val_accuracy: 0.6021\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6311 - accuracy: 0.6654 - val_loss: 0.6604 - val_accuracy: 0.6012\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6300 - accuracy: 0.6652 - val_loss: 0.6602 - val_accuracy: 0.6015\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6296 - accuracy: 0.6629 - val_loss: 0.6615 - val_accuracy: 0.5996\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 0s 561us/step - loss: 0.6284 - accuracy: 0.6675 - val_loss: 0.6591 - val_accuracy: 0.6028\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 0s 485us/step - loss: 0.6262 - accuracy: 0.6714 - val_loss: 0.6550 - val_accuracy: 0.6083\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 0s 490us/step - loss: 0.6251 - accuracy: 0.6685 - val_loss: 0.6563 - val_accuracy: 0.6054\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 0s 572us/step - loss: 0.6250 - accuracy: 0.6706 - val_loss: 0.6560 - val_accuracy: 0.6053\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 0s 496us/step - loss: 0.6231 - accuracy: 0.6721 - val_loss: 0.6554 - val_accuracy: 0.6062\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 0s 489us/step - loss: 0.6232 - accuracy: 0.6748 - val_loss: 0.6541 - val_accuracy: 0.6084\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6222 - accuracy: 0.6770 - val_loss: 0.6533 - val_accuracy: 0.6100\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 0s 488us/step - loss: 0.6192 - accuracy: 0.6760 - val_loss: 0.6509 - val_accuracy: 0.6146\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 0s 567us/step - loss: 0.6187 - accuracy: 0.6789 - val_loss: 0.6502 - val_accuracy: 0.6151\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 0s 492us/step - loss: 0.6178 - accuracy: 0.6791 - val_loss: 0.6490 - val_accuracy: 0.6176\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 0s 564us/step - loss: 0.6167 - accuracy: 0.6796 - val_loss: 0.6488 - val_accuracy: 0.6177\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 0s 495us/step - loss: 0.6157 - accuracy: 0.6769 - val_loss: 0.6481 - val_accuracy: 0.6187\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 0s 484us/step - loss: 0.6147 - accuracy: 0.6797 - val_loss: 0.6470 - val_accuracy: 0.6200\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 0s 557us/step - loss: 0.6153 - accuracy: 0.6793 - val_loss: 0.6487 - val_accuracy: 0.6177\n",
      "\n",
      "Training model with sample_size_ratio=0.1...\n",
      "DP-SGD with sampling rate = 0.598% and noise_multiplier = 1.1 iterated over 8360 steps satisfies differential privacy with eps = 3.3 and delta = 1e-05.\n",
      "The optimal RDP order is 8.0.\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.5135 - val_loss: 0.6657 - val_accuracy: 0.6224\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 923us/step - loss: 0.7077 - accuracy: 0.5254 - val_loss: 0.6800 - val_accuracy: 0.5748\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 957us/step - loss: 0.7061 - accuracy: 0.5193 - val_loss: 0.6897 - val_accuracy: 0.5431\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 938us/step - loss: 0.7077 - accuracy: 0.5131 - val_loss: 0.6945 - val_accuracy: 0.5256\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 947us/step - loss: 0.7040 - accuracy: 0.5258 - val_loss: 0.6996 - val_accuracy: 0.5051\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 950us/step - loss: 0.7057 - accuracy: 0.5207 - val_loss: 0.7029 - val_accuracy: 0.4950\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 948us/step - loss: 0.7029 - accuracy: 0.5226 - val_loss: 0.7055 - val_accuracy: 0.4830\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.5241 - val_loss: 0.7061 - val_accuracy: 0.4807\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 994us/step - loss: 0.7025 - accuracy: 0.5299 - val_loss: 0.7076 - val_accuracy: 0.4746\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 998us/step - loss: 0.6985 - accuracy: 0.5348 - val_loss: 0.7078 - val_accuracy: 0.4759\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 955us/step - loss: 0.7027 - accuracy: 0.5361 - val_loss: 0.7059 - val_accuracy: 0.4871\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 965us/step - loss: 0.6965 - accuracy: 0.5394 - val_loss: 0.7049 - val_accuracy: 0.4922\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 952us/step - loss: 0.7006 - accuracy: 0.5282 - val_loss: 0.7054 - val_accuracy: 0.4910\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 955us/step - loss: 0.7020 - accuracy: 0.5310 - val_loss: 0.7074 - val_accuracy: 0.4852\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 943us/step - loss: 0.6939 - accuracy: 0.5396 - val_loss: 0.7082 - val_accuracy: 0.4824\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.5308 - val_loss: 0.7066 - val_accuracy: 0.4901\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.5299 - val_loss: 0.7059 - val_accuracy: 0.4940\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 979us/step - loss: 0.6920 - accuracy: 0.5488 - val_loss: 0.7054 - val_accuracy: 0.4962\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 970us/step - loss: 0.6955 - accuracy: 0.5452 - val_loss: 0.7067 - val_accuracy: 0.4918\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 960us/step - loss: 0.6920 - accuracy: 0.5482 - val_loss: 0.7055 - val_accuracy: 0.4963\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 946us/step - loss: 0.6997 - accuracy: 0.5387 - val_loss: 0.7039 - val_accuracy: 0.5027\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 958us/step - loss: 0.6949 - accuracy: 0.5473 - val_loss: 0.7024 - val_accuracy: 0.5092\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 966us/step - loss: 0.6955 - accuracy: 0.5521 - val_loss: 0.7018 - val_accuracy: 0.5120\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 964us/step - loss: 0.6916 - accuracy: 0.5550 - val_loss: 0.7016 - val_accuracy: 0.5129\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 974us/step - loss: 0.6941 - accuracy: 0.5521 - val_loss: 0.7015 - val_accuracy: 0.5147\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.5361 - val_loss: 0.6998 - val_accuracy: 0.5223\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5542 - val_loss: 0.7010 - val_accuracy: 0.5185\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 988us/step - loss: 0.6939 - accuracy: 0.5445 - val_loss: 0.7001 - val_accuracy: 0.5223\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5550 - val_loss: 0.6998 - val_accuracy: 0.5233\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5508 - val_loss: 0.6979 - val_accuracy: 0.5278\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 976us/step - loss: 0.6912 - accuracy: 0.5531 - val_loss: 0.6984 - val_accuracy: 0.5267\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 971us/step - loss: 0.6872 - accuracy: 0.5574 - val_loss: 0.6976 - val_accuracy: 0.5296\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 956us/step - loss: 0.6902 - accuracy: 0.5514 - val_loss: 0.6983 - val_accuracy: 0.5283\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5602 - val_loss: 0.6980 - val_accuracy: 0.5297\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5587 - val_loss: 0.6959 - val_accuracy: 0.5365\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 997us/step - loss: 0.6871 - accuracy: 0.5559 - val_loss: 0.6961 - val_accuracy: 0.5369\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 975us/step - loss: 0.6886 - accuracy: 0.5568 - val_loss: 0.6945 - val_accuracy: 0.5411\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 967us/step - loss: 0.6871 - accuracy: 0.5550 - val_loss: 0.6948 - val_accuracy: 0.5412\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 954us/step - loss: 0.6824 - accuracy: 0.5718 - val_loss: 0.6947 - val_accuracy: 0.5417\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 965us/step - loss: 0.6815 - accuracy: 0.5766 - val_loss: 0.6927 - val_accuracy: 0.5478\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 954us/step - loss: 0.6860 - accuracy: 0.5630 - val_loss: 0.6941 - val_accuracy: 0.5442\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 968us/step - loss: 0.6814 - accuracy: 0.5703 - val_loss: 0.6943 - val_accuracy: 0.5438\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5776 - val_loss: 0.6944 - val_accuracy: 0.5434\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5806 - val_loss: 0.6936 - val_accuracy: 0.5455\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 983us/step - loss: 0.6818 - accuracy: 0.5654 - val_loss: 0.6921 - val_accuracy: 0.5496\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 975us/step - loss: 0.6797 - accuracy: 0.5727 - val_loss: 0.6914 - val_accuracy: 0.5521\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 954us/step - loss: 0.6824 - accuracy: 0.5710 - val_loss: 0.6908 - val_accuracy: 0.5532\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 949us/step - loss: 0.6804 - accuracy: 0.5768 - val_loss: 0.6900 - val_accuracy: 0.5558\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 959us/step - loss: 0.6843 - accuracy: 0.5733 - val_loss: 0.6887 - val_accuracy: 0.5599\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5714 - val_loss: 0.6894 - val_accuracy: 0.5580\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.4905 - val_loss: 0.8450 - val_accuracy: 0.1342\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 935us/step - loss: 0.7256 - accuracy: 0.4927 - val_loss: 0.8146 - val_accuracy: 0.1394\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 945us/step - loss: 0.7185 - accuracy: 0.4955 - val_loss: 0.7918 - val_accuracy: 0.1446\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 940us/step - loss: 0.7214 - accuracy: 0.4916 - val_loss: 0.7731 - val_accuracy: 0.1595\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 944us/step - loss: 0.7125 - accuracy: 0.4920 - val_loss: 0.7591 - val_accuracy: 0.1828\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.4798 - val_loss: 0.7467 - val_accuracy: 0.2247\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.4923 - val_loss: 0.7380 - val_accuracy: 0.2681\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.4910 - val_loss: 0.7309 - val_accuracy: 0.3049\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.4908 - val_loss: 0.7251 - val_accuracy: 0.3352\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.5045 - val_loss: 0.7203 - val_accuracy: 0.3562\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7073 - accuracy: 0.5047 - val_loss: 0.7154 - val_accuracy: 0.3815\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.5002 - val_loss: 0.7131 - val_accuracy: 0.3944\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7101 - accuracy: 0.4933 - val_loss: 0.7116 - val_accuracy: 0.4042\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.4983 - val_loss: 0.7092 - val_accuracy: 0.4182\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.5086 - val_loss: 0.7081 - val_accuracy: 0.4254\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.5007 - val_loss: 0.7073 - val_accuracy: 0.4313\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.5013 - val_loss: 0.7046 - val_accuracy: 0.4460\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.5017 - val_loss: 0.7042 - val_accuracy: 0.4480\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5058 - val_loss: 0.7035 - val_accuracy: 0.4521\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5136 - val_loss: 0.7033 - val_accuracy: 0.4532\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.5026 - val_loss: 0.7029 - val_accuracy: 0.4550\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.5222 - val_loss: 0.7032 - val_accuracy: 0.4535\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.5114 - val_loss: 0.7024 - val_accuracy: 0.4567\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.5148 - val_loss: 0.7015 - val_accuracy: 0.4625\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.5073 - val_loss: 0.7008 - val_accuracy: 0.4680\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.5209 - val_loss: 0.7004 - val_accuracy: 0.4708\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5194 - val_loss: 0.7000 - val_accuracy: 0.4743\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.5136 - val_loss: 0.6986 - val_accuracy: 0.4850\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.5297 - val_loss: 0.6980 - val_accuracy: 0.4894\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5252 - val_loss: 0.6978 - val_accuracy: 0.4901\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.5170 - val_loss: 0.6969 - val_accuracy: 0.4978\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.5279 - val_loss: 0.6970 - val_accuracy: 0.4977\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5316 - val_loss: 0.6958 - val_accuracy: 0.5053\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5232 - val_loss: 0.6954 - val_accuracy: 0.5074\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.5219 - val_loss: 0.6946 - val_accuracy: 0.5129\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.5275 - val_loss: 0.6948 - val_accuracy: 0.5126\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5348 - val_loss: 0.6951 - val_accuracy: 0.5131\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5441 - val_loss: 0.6943 - val_accuracy: 0.5185\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5299 - val_loss: 0.6945 - val_accuracy: 0.5192\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5413 - val_loss: 0.6935 - val_accuracy: 0.5237\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5335 - val_loss: 0.6923 - val_accuracy: 0.5301\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5387 - val_loss: 0.6918 - val_accuracy: 0.5329\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5411 - val_loss: 0.6921 - val_accuracy: 0.5308\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5471 - val_loss: 0.6916 - val_accuracy: 0.5340\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5411 - val_loss: 0.6911 - val_accuracy: 0.5359\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5501 - val_loss: 0.6903 - val_accuracy: 0.5401\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5318 - val_loss: 0.6900 - val_accuracy: 0.5426\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5492 - val_loss: 0.6886 - val_accuracy: 0.5500\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5447 - val_loss: 0.6891 - val_accuracy: 0.5478\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5533 - val_loss: 0.6891 - val_accuracy: 0.5474\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7851 - accuracy: 0.5067 - val_loss: 0.5110 - val_accuracy: 0.8727\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7480 - accuracy: 0.5041 - val_loss: 0.5507 - val_accuracy: 0.8688\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.5131 - val_loss: 0.5853 - val_accuracy: 0.8573\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.5297 - val_loss: 0.6126 - val_accuracy: 0.8340\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.5234 - val_loss: 0.6326 - val_accuracy: 0.7906\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.5228 - val_loss: 0.6492 - val_accuracy: 0.7369\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.5290 - val_loss: 0.6602 - val_accuracy: 0.6911\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.5376 - val_loss: 0.6679 - val_accuracy: 0.6571\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.5336 - val_loss: 0.6751 - val_accuracy: 0.6266\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.5514 - val_loss: 0.6806 - val_accuracy: 0.6008\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.5445 - val_loss: 0.6825 - val_accuracy: 0.5906\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.5333 - val_loss: 0.6833 - val_accuracy: 0.5872\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5546 - val_loss: 0.6867 - val_accuracy: 0.5699\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5520 - val_loss: 0.6864 - val_accuracy: 0.5720\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5426 - val_loss: 0.6859 - val_accuracy: 0.5754\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5533 - val_loss: 0.6845 - val_accuracy: 0.5813\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5508 - val_loss: 0.6837 - val_accuracy: 0.5839\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5557 - val_loss: 0.6841 - val_accuracy: 0.5799\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5641 - val_loss: 0.6840 - val_accuracy: 0.5795\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5624 - val_loss: 0.6843 - val_accuracy: 0.5755\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5503 - val_loss: 0.6824 - val_accuracy: 0.5828\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5613 - val_loss: 0.6819 - val_accuracy: 0.5826\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5553 - val_loss: 0.6811 - val_accuracy: 0.5854\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5652 - val_loss: 0.6808 - val_accuracy: 0.5855\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5587 - val_loss: 0.6809 - val_accuracy: 0.5832\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5723 - val_loss: 0.6789 - val_accuracy: 0.5910\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6778 - val_accuracy: 0.5954\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5708 - val_loss: 0.6779 - val_accuracy: 0.5956\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5794 - val_loss: 0.6773 - val_accuracy: 0.5978\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5804 - val_loss: 0.6757 - val_accuracy: 0.6033\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5744 - val_loss: 0.6750 - val_accuracy: 0.6052\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5731 - val_loss: 0.6753 - val_accuracy: 0.6038\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5794 - val_loss: 0.6735 - val_accuracy: 0.6093\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5764 - val_loss: 0.6727 - val_accuracy: 0.6130\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6772 - accuracy: 0.5847 - val_loss: 0.6725 - val_accuracy: 0.6133\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6779 - accuracy: 0.5824 - val_loss: 0.6716 - val_accuracy: 0.6156\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.5856 - val_loss: 0.6712 - val_accuracy: 0.6164\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.5862 - val_loss: 0.6704 - val_accuracy: 0.6189\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5841 - val_loss: 0.6716 - val_accuracy: 0.6147\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6746 - accuracy: 0.5903 - val_loss: 0.6710 - val_accuracy: 0.6161\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5880 - val_loss: 0.6712 - val_accuracy: 0.6155\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5888 - val_loss: 0.6694 - val_accuracy: 0.6205\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6745 - accuracy: 0.5925 - val_loss: 0.6685 - val_accuracy: 0.6224\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6772 - accuracy: 0.5830 - val_loss: 0.6672 - val_accuracy: 0.6261\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5826 - val_loss: 0.6670 - val_accuracy: 0.6268\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5912 - val_loss: 0.6654 - val_accuracy: 0.6328\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.5927 - val_loss: 0.6650 - val_accuracy: 0.6339\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.6000 - val_loss: 0.6667 - val_accuracy: 0.6277\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.6028 - val_loss: 0.6663 - val_accuracy: 0.6292\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.5888 - val_loss: 0.6650 - val_accuracy: 0.6346\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.5196 - val_loss: 0.5772 - val_accuracy: 0.8681\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.5350 - val_loss: 0.5981 - val_accuracy: 0.8652\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.5310 - val_loss: 0.6126 - val_accuracy: 0.8621\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.5342 - val_loss: 0.6264 - val_accuracy: 0.8571\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.5462 - val_loss: 0.6358 - val_accuracy: 0.8522\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.5436 - val_loss: 0.6434 - val_accuracy: 0.8422\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.5535 - val_loss: 0.6498 - val_accuracy: 0.8277\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5544 - val_loss: 0.6532 - val_accuracy: 0.8158\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5572 - val_loss: 0.6563 - val_accuracy: 0.7990\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.5536 - val_loss: 0.6585 - val_accuracy: 0.7877\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5400 - val_loss: 0.6607 - val_accuracy: 0.7760\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5591 - val_loss: 0.6608 - val_accuracy: 0.7726\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5594 - val_loss: 0.6609 - val_accuracy: 0.7694\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5531 - val_loss: 0.6628 - val_accuracy: 0.7551\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5645 - val_loss: 0.6638 - val_accuracy: 0.7449\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5658 - val_loss: 0.6631 - val_accuracy: 0.7471\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5643 - val_loss: 0.6628 - val_accuracy: 0.7453\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5665 - val_loss: 0.6626 - val_accuracy: 0.7441\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5748 - val_loss: 0.6624 - val_accuracy: 0.7427\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5649 - val_loss: 0.6619 - val_accuracy: 0.7418\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5720 - val_loss: 0.6605 - val_accuracy: 0.7471\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.5830 - val_loss: 0.6622 - val_accuracy: 0.7326\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5671 - val_loss: 0.6607 - val_accuracy: 0.7384\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5843 - val_loss: 0.6592 - val_accuracy: 0.7433\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.5862 - val_loss: 0.6597 - val_accuracy: 0.7367\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5727 - val_loss: 0.6584 - val_accuracy: 0.7432\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.5736 - val_loss: 0.6584 - val_accuracy: 0.7399\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.5837 - val_loss: 0.6587 - val_accuracy: 0.7323\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5809 - val_loss: 0.6570 - val_accuracy: 0.7409\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5736 - val_loss: 0.6572 - val_accuracy: 0.7365\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5852 - val_loss: 0.6562 - val_accuracy: 0.7394\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5843 - val_loss: 0.6565 - val_accuracy: 0.7350\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5708 - val_loss: 0.6565 - val_accuracy: 0.7310\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5759 - val_loss: 0.6564 - val_accuracy: 0.7274\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.5860 - val_loss: 0.6570 - val_accuracy: 0.7174\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.5907 - val_loss: 0.6552 - val_accuracy: 0.7269\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.5938 - val_loss: 0.6552 - val_accuracy: 0.7222\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5929 - val_loss: 0.6550 - val_accuracy: 0.7200\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5888 - val_loss: 0.6542 - val_accuracy: 0.7209\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.6026 - val_loss: 0.6534 - val_accuracy: 0.7218\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.5979 - val_loss: 0.6524 - val_accuracy: 0.7232\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.6054 - val_loss: 0.6514 - val_accuracy: 0.7249\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.5994 - val_loss: 0.6520 - val_accuracy: 0.7174\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.6077 - val_loss: 0.6513 - val_accuracy: 0.7183\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6701 - accuracy: 0.6077 - val_loss: 0.6501 - val_accuracy: 0.7209\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.6036 - val_loss: 0.6511 - val_accuracy: 0.7147\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.6060 - val_loss: 0.6503 - val_accuracy: 0.7154\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6146 - val_loss: 0.6506 - val_accuracy: 0.7110\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.5953 - val_loss: 0.6502 - val_accuracy: 0.7107\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.6045 - val_loss: 0.6494 - val_accuracy: 0.7117\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.4649 - val_loss: 0.6843 - val_accuracy: 0.5141\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.4594 - val_loss: 0.6923 - val_accuracy: 0.4774\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.4596 - val_loss: 0.6993 - val_accuracy: 0.4435\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.4701 - val_loss: 0.7050 - val_accuracy: 0.4110\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.4482 - val_loss: 0.7096 - val_accuracy: 0.3856\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.4682 - val_loss: 0.7136 - val_accuracy: 0.3587\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.4652 - val_loss: 0.7164 - val_accuracy: 0.3418\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.4735 - val_loss: 0.7192 - val_accuracy: 0.3257\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.4695 - val_loss: 0.7210 - val_accuracy: 0.3157\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.4647 - val_loss: 0.7232 - val_accuracy: 0.3037\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.4764 - val_loss: 0.7239 - val_accuracy: 0.2995\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.4764 - val_loss: 0.7247 - val_accuracy: 0.2934\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.4824 - val_loss: 0.7254 - val_accuracy: 0.2899\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.4707 - val_loss: 0.7263 - val_accuracy: 0.2850\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.4755 - val_loss: 0.7258 - val_accuracy: 0.2855\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.4793 - val_loss: 0.7257 - val_accuracy: 0.2840\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.4880 - val_loss: 0.7258 - val_accuracy: 0.2813\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.4865 - val_loss: 0.7253 - val_accuracy: 0.2813\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.4843 - val_loss: 0.7249 - val_accuracy: 0.2802\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.4953 - val_loss: 0.7253 - val_accuracy: 0.2754\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.4834 - val_loss: 0.7251 - val_accuracy: 0.2752\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.4910 - val_loss: 0.7249 - val_accuracy: 0.2771\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.4921 - val_loss: 0.7245 - val_accuracy: 0.2792\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.4993 - val_loss: 0.7243 - val_accuracy: 0.2810\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7061 - accuracy: 0.4927 - val_loss: 0.7238 - val_accuracy: 0.2829\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.4998 - val_loss: 0.7242 - val_accuracy: 0.2805\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.5028 - val_loss: 0.7237 - val_accuracy: 0.2846\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.5105 - val_loss: 0.7228 - val_accuracy: 0.2886\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.4935 - val_loss: 0.7224 - val_accuracy: 0.2904\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7054 - accuracy: 0.5011 - val_loss: 0.7215 - val_accuracy: 0.2944\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.5077 - val_loss: 0.7207 - val_accuracy: 0.2995\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.5021 - val_loss: 0.7198 - val_accuracy: 0.3071\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.5114 - val_loss: 0.7197 - val_accuracy: 0.3085\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.5015 - val_loss: 0.7188 - val_accuracy: 0.3132\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5222 - val_loss: 0.7181 - val_accuracy: 0.3175\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.5138 - val_loss: 0.7173 - val_accuracy: 0.3206\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5191 - val_loss: 0.7169 - val_accuracy: 0.3218\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.5107 - val_loss: 0.7155 - val_accuracy: 0.3287\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.5275 - val_loss: 0.7150 - val_accuracy: 0.3321\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.5118 - val_loss: 0.7151 - val_accuracy: 0.3332\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.5150 - val_loss: 0.7143 - val_accuracy: 0.3378\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5153 - val_loss: 0.7145 - val_accuracy: 0.3384\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.5207 - val_loss: 0.7140 - val_accuracy: 0.3424\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.5200 - val_loss: 0.7132 - val_accuracy: 0.3467\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5333 - val_loss: 0.7131 - val_accuracy: 0.3482\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5191 - val_loss: 0.7126 - val_accuracy: 0.3544\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5320 - val_loss: 0.7117 - val_accuracy: 0.3597\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5331 - val_loss: 0.7104 - val_accuracy: 0.3688\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5383 - val_loss: 0.7097 - val_accuracy: 0.3743\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5320 - val_loss: 0.7094 - val_accuracy: 0.3782\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7835 - accuracy: 0.4974 - val_loss: 0.5446 - val_accuracy: 0.8578\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7599 - accuracy: 0.5011 - val_loss: 0.5736 - val_accuracy: 0.8475\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7491 - accuracy: 0.4890 - val_loss: 0.5995 - val_accuracy: 0.8374\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7398 - accuracy: 0.4856 - val_loss: 0.6216 - val_accuracy: 0.8192\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.4850 - val_loss: 0.6397 - val_accuracy: 0.7906\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.4936 - val_loss: 0.6539 - val_accuracy: 0.7498\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.4860 - val_loss: 0.6655 - val_accuracy: 0.6966\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.4787 - val_loss: 0.6755 - val_accuracy: 0.6372\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.4880 - val_loss: 0.6827 - val_accuracy: 0.5925\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.4886 - val_loss: 0.6889 - val_accuracy: 0.5528\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.4824 - val_loss: 0.6936 - val_accuracy: 0.5182\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.4679 - val_loss: 0.6976 - val_accuracy: 0.4904\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.4815 - val_loss: 0.6997 - val_accuracy: 0.4755\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.4841 - val_loss: 0.7034 - val_accuracy: 0.4465\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7132 - accuracy: 0.4890 - val_loss: 0.7046 - val_accuracy: 0.4366\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.4770 - val_loss: 0.7056 - val_accuracy: 0.4296\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.4802 - val_loss: 0.7073 - val_accuracy: 0.4137\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.5002 - val_loss: 0.7081 - val_accuracy: 0.4071\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.5002 - val_loss: 0.7083 - val_accuracy: 0.4034\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.4920 - val_loss: 0.7088 - val_accuracy: 0.3963\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.4964 - val_loss: 0.7088 - val_accuracy: 0.3949\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.4950 - val_loss: 0.7077 - val_accuracy: 0.4029\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7075 - accuracy: 0.5030 - val_loss: 0.7075 - val_accuracy: 0.4032\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.5064 - val_loss: 0.7077 - val_accuracy: 0.4001\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.5039 - val_loss: 0.7076 - val_accuracy: 0.3987\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.5095 - val_loss: 0.7072 - val_accuracy: 0.4021\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.5090 - val_loss: 0.7071 - val_accuracy: 0.4022\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.4961 - val_loss: 0.7065 - val_accuracy: 0.4059\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.4974 - val_loss: 0.7062 - val_accuracy: 0.4093\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.5194 - val_loss: 0.7059 - val_accuracy: 0.4097\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.5071 - val_loss: 0.7055 - val_accuracy: 0.4114\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.5036 - val_loss: 0.7053 - val_accuracy: 0.4135\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.5034 - val_loss: 0.7052 - val_accuracy: 0.4132\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.5101 - val_loss: 0.7052 - val_accuracy: 0.4140\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7023 - accuracy: 0.5108 - val_loss: 0.7052 - val_accuracy: 0.4156\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.5107 - val_loss: 0.7046 - val_accuracy: 0.4202\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.5099 - val_loss: 0.7041 - val_accuracy: 0.4243\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.5267 - val_loss: 0.7047 - val_accuracy: 0.4241\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.5161 - val_loss: 0.7043 - val_accuracy: 0.4293\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.5178 - val_loss: 0.7033 - val_accuracy: 0.4347\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7006 - accuracy: 0.5228 - val_loss: 0.7023 - val_accuracy: 0.4424\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5217 - val_loss: 0.7023 - val_accuracy: 0.4427\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.5202 - val_loss: 0.7019 - val_accuracy: 0.4476\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5245 - val_loss: 0.7023 - val_accuracy: 0.4466\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5308 - val_loss: 0.7023 - val_accuracy: 0.4476\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5314 - val_loss: 0.7016 - val_accuracy: 0.4532\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.5234 - val_loss: 0.7012 - val_accuracy: 0.4562\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.5250 - val_loss: 0.7009 - val_accuracy: 0.4599\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.5342 - val_loss: 0.7002 - val_accuracy: 0.4649\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.5211 - val_loss: 0.7004 - val_accuracy: 0.4649\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7789 - accuracy: 0.4921 - val_loss: 0.5172 - val_accuracy: 0.8766\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7539 - accuracy: 0.4920 - val_loss: 0.5453 - val_accuracy: 0.8718\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.4936 - val_loss: 0.5698 - val_accuracy: 0.8628\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.4914 - val_loss: 0.5919 - val_accuracy: 0.8527\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7190 - accuracy: 0.4860 - val_loss: 0.6094 - val_accuracy: 0.8350\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.7104 - accuracy: 0.5039 - val_loss: 0.6243 - val_accuracy: 0.8113\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.4936 - val_loss: 0.6369 - val_accuracy: 0.7834\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.4931 - val_loss: 0.6467 - val_accuracy: 0.7527\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.5140 - val_loss: 0.6557 - val_accuracy: 0.7206\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5138 - val_loss: 0.6623 - val_accuracy: 0.6927\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.5245 - val_loss: 0.6671 - val_accuracy: 0.6734\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.5155 - val_loss: 0.6712 - val_accuracy: 0.6517\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5179 - val_loss: 0.6741 - val_accuracy: 0.6311\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5323 - val_loss: 0.6765 - val_accuracy: 0.6140\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5290 - val_loss: 0.6785 - val_accuracy: 0.6006\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5279 - val_loss: 0.6800 - val_accuracy: 0.5871\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5374 - val_loss: 0.6817 - val_accuracy: 0.5767\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.5258 - val_loss: 0.6817 - val_accuracy: 0.5766\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5252 - val_loss: 0.6825 - val_accuracy: 0.5705\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5426 - val_loss: 0.6817 - val_accuracy: 0.5737\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5445 - val_loss: 0.6818 - val_accuracy: 0.5712\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5336 - val_loss: 0.6816 - val_accuracy: 0.5717\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5426 - val_loss: 0.6815 - val_accuracy: 0.5714\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5437 - val_loss: 0.6812 - val_accuracy: 0.5713\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5473 - val_loss: 0.6803 - val_accuracy: 0.5770\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5559 - val_loss: 0.6804 - val_accuracy: 0.5751\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5499 - val_loss: 0.6796 - val_accuracy: 0.5797\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5525 - val_loss: 0.6787 - val_accuracy: 0.5847\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5600 - val_loss: 0.6786 - val_accuracy: 0.5837\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5471 - val_loss: 0.6784 - val_accuracy: 0.5829\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5598 - val_loss: 0.6779 - val_accuracy: 0.5861\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5677 - val_loss: 0.6777 - val_accuracy: 0.5853\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5774 - val_loss: 0.6773 - val_accuracy: 0.5874\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5671 - val_loss: 0.6769 - val_accuracy: 0.5893\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5679 - val_loss: 0.6760 - val_accuracy: 0.5932\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5501 - val_loss: 0.6752 - val_accuracy: 0.5954\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5821 - val_loss: 0.6750 - val_accuracy: 0.5950\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5677 - val_loss: 0.6738 - val_accuracy: 0.6028\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5774 - val_loss: 0.6734 - val_accuracy: 0.6056\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5821 - val_loss: 0.6735 - val_accuracy: 0.6030\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.5778 - val_loss: 0.6731 - val_accuracy: 0.6044\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5727 - val_loss: 0.6720 - val_accuracy: 0.6099\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5723 - val_loss: 0.6719 - val_accuracy: 0.6092\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5755 - val_loss: 0.6712 - val_accuracy: 0.6114\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5858 - val_loss: 0.6708 - val_accuracy: 0.6132\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5879 - val_loss: 0.6703 - val_accuracy: 0.6146\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5920 - val_loss: 0.6702 - val_accuracy: 0.6146\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.5875 - val_loss: 0.6697 - val_accuracy: 0.6174\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5879 - val_loss: 0.6699 - val_accuracy: 0.6166\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5796 - val_loss: 0.6696 - val_accuracy: 0.6161\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7895 - accuracy: 0.4935 - val_loss: 0.5041 - val_accuracy: 0.8706\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7626 - accuracy: 0.4963 - val_loss: 0.5383 - val_accuracy: 0.8614\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.5054 - val_loss: 0.5684 - val_accuracy: 0.8512\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.4936 - val_loss: 0.5944 - val_accuracy: 0.8270\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.4972 - val_loss: 0.6168 - val_accuracy: 0.7966\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.5105 - val_loss: 0.6346 - val_accuracy: 0.7597\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.5150 - val_loss: 0.6475 - val_accuracy: 0.7231\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5206 - val_loss: 0.6589 - val_accuracy: 0.6840\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.5159 - val_loss: 0.6685 - val_accuracy: 0.6206\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.5088 - val_loss: 0.6750 - val_accuracy: 0.5894\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.5112 - val_loss: 0.6804 - val_accuracy: 0.5737\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.5221 - val_loss: 0.6827 - val_accuracy: 0.5633\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5303 - val_loss: 0.6856 - val_accuracy: 0.5495\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5194 - val_loss: 0.6874 - val_accuracy: 0.5389\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5222 - val_loss: 0.6886 - val_accuracy: 0.5309\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5340 - val_loss: 0.6904 - val_accuracy: 0.5225\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5312 - val_loss: 0.6911 - val_accuracy: 0.5208\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5292 - val_loss: 0.6905 - val_accuracy: 0.5250\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5372 - val_loss: 0.6889 - val_accuracy: 0.5353\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5379 - val_loss: 0.6884 - val_accuracy: 0.5406\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5340 - val_loss: 0.6900 - val_accuracy: 0.5305\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5378 - val_loss: 0.6890 - val_accuracy: 0.5379\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5482 - val_loss: 0.6883 - val_accuracy: 0.5434\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5501 - val_loss: 0.6887 - val_accuracy: 0.5422\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5422 - val_loss: 0.6893 - val_accuracy: 0.5390\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5495 - val_loss: 0.6890 - val_accuracy: 0.5415\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6873 - val_accuracy: 0.5504\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5393 - val_loss: 0.6863 - val_accuracy: 0.5559\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5527 - val_loss: 0.6874 - val_accuracy: 0.5497\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5540 - val_loss: 0.6872 - val_accuracy: 0.5496\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5493 - val_loss: 0.6867 - val_accuracy: 0.5507\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5493 - val_loss: 0.6869 - val_accuracy: 0.5496\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5593 - val_loss: 0.6863 - val_accuracy: 0.5520\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5712 - val_loss: 0.6858 - val_accuracy: 0.5528\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5578 - val_loss: 0.6848 - val_accuracy: 0.5567\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5641 - val_loss: 0.6838 - val_accuracy: 0.5599\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5622 - val_loss: 0.6837 - val_accuracy: 0.5584\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5643 - val_loss: 0.6842 - val_accuracy: 0.5532\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5624 - val_loss: 0.6834 - val_accuracy: 0.5552\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5738 - val_loss: 0.6824 - val_accuracy: 0.5582\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5669 - val_loss: 0.6820 - val_accuracy: 0.5589\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5736 - val_loss: 0.6817 - val_accuracy: 0.5590\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5708 - val_loss: 0.6818 - val_accuracy: 0.5572\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5735 - val_loss: 0.6812 - val_accuracy: 0.5588\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.5707 - val_loss: 0.6809 - val_accuracy: 0.5599\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.5867 - val_loss: 0.6802 - val_accuracy: 0.5652\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5807 - val_loss: 0.6804 - val_accuracy: 0.5651\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5671 - val_loss: 0.6793 - val_accuracy: 0.5739\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.5811 - val_loss: 0.6792 - val_accuracy: 0.5750\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.5834 - val_loss: 0.6779 - val_accuracy: 0.5854\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.4854 - val_loss: 0.8414 - val_accuracy: 0.1179\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.4733 - val_loss: 0.8171 - val_accuracy: 0.1198\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.4733 - val_loss: 0.7974 - val_accuracy: 0.1315\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.4740 - val_loss: 0.7811 - val_accuracy: 0.1628\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.4600 - val_loss: 0.7680 - val_accuracy: 0.1841\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.4609 - val_loss: 0.7573 - val_accuracy: 0.2110\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.4643 - val_loss: 0.7490 - val_accuracy: 0.2371\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.4654 - val_loss: 0.7417 - val_accuracy: 0.2627\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.4607 - val_loss: 0.7362 - val_accuracy: 0.2772\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.4701 - val_loss: 0.7310 - val_accuracy: 0.2903\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.4641 - val_loss: 0.7269 - val_accuracy: 0.3002\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.4561 - val_loss: 0.7233 - val_accuracy: 0.3128\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.4699 - val_loss: 0.7209 - val_accuracy: 0.3221\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.4682 - val_loss: 0.7184 - val_accuracy: 0.3354\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.4671 - val_loss: 0.7166 - val_accuracy: 0.3438\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.4776 - val_loss: 0.7146 - val_accuracy: 0.3542\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.4686 - val_loss: 0.7127 - val_accuracy: 0.3650\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.4688 - val_loss: 0.7118 - val_accuracy: 0.3700\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.4770 - val_loss: 0.7111 - val_accuracy: 0.3769\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.4864 - val_loss: 0.7096 - val_accuracy: 0.3901\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.4951 - val_loss: 0.7084 - val_accuracy: 0.4022\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.4886 - val_loss: 0.7082 - val_accuracy: 0.4089\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.4875 - val_loss: 0.7070 - val_accuracy: 0.4207\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.4893 - val_loss: 0.7054 - val_accuracy: 0.4337\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 957us/step - loss: 0.7004 - accuracy: 0.4976 - val_loss: 0.7039 - val_accuracy: 0.4440\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.4989 - val_loss: 0.7027 - val_accuracy: 0.4527\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.4918 - val_loss: 0.7023 - val_accuracy: 0.4558\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.4985 - val_loss: 0.7016 - val_accuracy: 0.4589\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.5022 - val_loss: 0.7019 - val_accuracy: 0.4578\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5108 - val_loss: 0.7024 - val_accuracy: 0.4559\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.5159 - val_loss: 0.7014 - val_accuracy: 0.4633\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.5148 - val_loss: 0.7001 - val_accuracy: 0.4729\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5118 - val_loss: 0.6990 - val_accuracy: 0.4787\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 989us/step - loss: 0.6961 - accuracy: 0.5209 - val_loss: 0.6993 - val_accuracy: 0.4792\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 981us/step - loss: 0.6958 - accuracy: 0.5161 - val_loss: 0.6979 - val_accuracy: 0.4888\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5209 - val_loss: 0.6967 - val_accuracy: 0.4980\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5271 - val_loss: 0.6962 - val_accuracy: 0.5044\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.5146 - val_loss: 0.6963 - val_accuracy: 0.5058\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 981us/step - loss: 0.6919 - accuracy: 0.5226 - val_loss: 0.6956 - val_accuracy: 0.5118\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5361 - val_loss: 0.6953 - val_accuracy: 0.5158\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6947 - val_accuracy: 0.5221\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5346 - val_loss: 0.6938 - val_accuracy: 0.5299\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5293 - val_loss: 0.6930 - val_accuracy: 0.5364\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5394 - val_loss: 0.6928 - val_accuracy: 0.5382\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 998us/step - loss: 0.6883 - accuracy: 0.5394 - val_loss: 0.6923 - val_accuracy: 0.5424\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5465 - val_loss: 0.6910 - val_accuracy: 0.5498\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 989us/step - loss: 0.6873 - accuracy: 0.5404 - val_loss: 0.6902 - val_accuracy: 0.5562\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 970us/step - loss: 0.6862 - accuracy: 0.5490 - val_loss: 0.6897 - val_accuracy: 0.5604\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5529 - val_loss: 0.6887 - val_accuracy: 0.5642\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5540 - val_loss: 0.6875 - val_accuracy: 0.5710\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.8728 - accuracy: 0.5049 - val_loss: 1.2069 - val_accuracy: 0.1170\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 950us/step - loss: 0.8076 - accuracy: 0.5071 - val_loss: 1.0743 - val_accuracy: 0.1172\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 958us/step - loss: 0.7664 - accuracy: 0.5060 - val_loss: 0.9759 - val_accuracy: 0.1177\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 956us/step - loss: 0.7437 - accuracy: 0.5092 - val_loss: 0.9047 - val_accuracy: 0.1183\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.5097 - val_loss: 0.8520 - val_accuracy: 0.1203\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.5073 - val_loss: 0.8150 - val_accuracy: 0.1250\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.5120 - val_loss: 0.7864 - val_accuracy: 0.1508\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 979us/step - loss: 0.7087 - accuracy: 0.5226 - val_loss: 0.7649 - val_accuracy: 0.1869\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.5219 - val_loss: 0.7487 - val_accuracy: 0.2364\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.5047 - val_loss: 0.7371 - val_accuracy: 0.2829\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.5215 - val_loss: 0.7281 - val_accuracy: 0.3410\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5280 - val_loss: 0.7209 - val_accuracy: 0.3805\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.5183 - val_loss: 0.7159 - val_accuracy: 0.4067\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 979us/step - loss: 0.6996 - accuracy: 0.5260 - val_loss: 0.7109 - val_accuracy: 0.4444\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 0s 988us/step - loss: 0.7026 - accuracy: 0.5185 - val_loss: 0.7080 - val_accuracy: 0.4573\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 0s 976us/step - loss: 0.6985 - accuracy: 0.5381 - val_loss: 0.7051 - val_accuracy: 0.4721\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.5209 - val_loss: 0.7036 - val_accuracy: 0.4825\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.5187 - val_loss: 0.7016 - val_accuracy: 0.4938\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5292 - val_loss: 0.6991 - val_accuracy: 0.5036\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 0s 976us/step - loss: 0.6925 - accuracy: 0.5407 - val_loss: 0.6986 - val_accuracy: 0.5070\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 0s 968us/step - loss: 0.6962 - accuracy: 0.5436 - val_loss: 0.6984 - val_accuracy: 0.5097\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 0s 976us/step - loss: 0.6937 - accuracy: 0.5393 - val_loss: 0.6981 - val_accuracy: 0.5126\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.5342 - val_loss: 0.6973 - val_accuracy: 0.5182\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5415 - val_loss: 0.6958 - val_accuracy: 0.5269\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5424 - val_loss: 0.6951 - val_accuracy: 0.5300\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 0s 999us/step - loss: 0.6947 - accuracy: 0.5389 - val_loss: 0.6945 - val_accuracy: 0.5342\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 0s 990us/step - loss: 0.6938 - accuracy: 0.5484 - val_loss: 0.6938 - val_accuracy: 0.5371\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 0s 989us/step - loss: 0.6922 - accuracy: 0.5393 - val_loss: 0.6932 - val_accuracy: 0.5391\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5514 - val_loss: 0.6935 - val_accuracy: 0.5360\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5624 - val_loss: 0.6930 - val_accuracy: 0.5380\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5536 - val_loss: 0.6924 - val_accuracy: 0.5416\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5482 - val_loss: 0.6913 - val_accuracy: 0.5482\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 0s 1000us/step - loss: 0.6888 - accuracy: 0.5535 - val_loss: 0.6898 - val_accuracy: 0.5574\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5518 - val_loss: 0.6903 - val_accuracy: 0.5544\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5508 - val_loss: 0.6902 - val_accuracy: 0.5552\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5587 - val_loss: 0.6897 - val_accuracy: 0.5577\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5583 - val_loss: 0.6875 - val_accuracy: 0.5684\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 0s 988us/step - loss: 0.6832 - accuracy: 0.5650 - val_loss: 0.6875 - val_accuracy: 0.5674\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 0s 964us/step - loss: 0.6840 - accuracy: 0.5636 - val_loss: 0.6877 - val_accuracy: 0.5665\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5821 - val_loss: 0.6862 - val_accuracy: 0.5743\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5628 - val_loss: 0.6868 - val_accuracy: 0.5715\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5725 - val_loss: 0.6867 - val_accuracy: 0.5716\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5770 - val_loss: 0.6870 - val_accuracy: 0.5705\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5664 - val_loss: 0.6860 - val_accuracy: 0.5743\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5695 - val_loss: 0.6848 - val_accuracy: 0.5798\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5843 - val_loss: 0.6841 - val_accuracy: 0.5813\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5807 - val_loss: 0.6840 - val_accuracy: 0.5818\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 0s 989us/step - loss: 0.6775 - accuracy: 0.5798 - val_loss: 0.6829 - val_accuracy: 0.5859\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 0s 970us/step - loss: 0.6776 - accuracy: 0.5800 - val_loss: 0.6813 - val_accuracy: 0.5932\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 0s 964us/step - loss: 0.6801 - accuracy: 0.5774 - val_loss: 0.6814 - val_accuracy: 0.5922\n",
      "\n",
      "Training model with sample_size_ratio=0.05...\n",
      "DP-SGD with sampling rate = 1.2% and noise_multiplier = 1.1 iterated over 4180 steps satisfies differential privacy with eps = 4.84 and delta = 1e-05.\n",
      "The optimal RDP order is 6.0.\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7857 - accuracy: 0.5286 - val_loss: 1.1193 - val_accuracy: 0.1269\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7728 - accuracy: 0.5353 - val_loss: 1.0645 - val_accuracy: 0.1323\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7611 - accuracy: 0.5338 - val_loss: 1.0181 - val_accuracy: 0.1387\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7545 - accuracy: 0.5170 - val_loss: 0.9787 - val_accuracy: 0.1450\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7309 - accuracy: 0.5151 - val_loss: 0.9442 - val_accuracy: 0.1496\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7345 - accuracy: 0.5230 - val_loss: 0.9139 - val_accuracy: 0.1578\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.5305 - val_loss: 0.8892 - val_accuracy: 0.1601\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.5159 - val_loss: 0.8679 - val_accuracy: 0.1650\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.5226 - val_loss: 0.8502 - val_accuracy: 0.1702\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.5107 - val_loss: 0.8345 - val_accuracy: 0.1756\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.4991 - val_loss: 0.8204 - val_accuracy: 0.1848\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.5245 - val_loss: 0.8077 - val_accuracy: 0.1941\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.5065 - val_loss: 0.7982 - val_accuracy: 0.2048\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.5241 - val_loss: 0.7893 - val_accuracy: 0.2261\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7071 - accuracy: 0.5140 - val_loss: 0.7827 - val_accuracy: 0.2416\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.5204 - val_loss: 0.7773 - val_accuracy: 0.2540\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.5099 - val_loss: 0.7717 - val_accuracy: 0.2682\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.5155 - val_loss: 0.7674 - val_accuracy: 0.2802\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.5133 - val_loss: 0.7635 - val_accuracy: 0.2945\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.5174 - val_loss: 0.7596 - val_accuracy: 0.3063\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.5260 - val_loss: 0.7563 - val_accuracy: 0.3146\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.5331 - val_loss: 0.7515 - val_accuracy: 0.3272\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.5148 - val_loss: 0.7477 - val_accuracy: 0.3386\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.5189 - val_loss: 0.7458 - val_accuracy: 0.3446\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7003 - accuracy: 0.5193 - val_loss: 0.7439 - val_accuracy: 0.3497\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.5062 - val_loss: 0.7413 - val_accuracy: 0.3562\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.5211 - val_loss: 0.7405 - val_accuracy: 0.3594\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.5331 - val_loss: 0.7390 - val_accuracy: 0.3646\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.5252 - val_loss: 0.7385 - val_accuracy: 0.3674\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.5230 - val_loss: 0.7366 - val_accuracy: 0.3739\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.5346 - val_loss: 0.7360 - val_accuracy: 0.3762\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5477 - val_loss: 0.7342 - val_accuracy: 0.3828\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5290 - val_loss: 0.7333 - val_accuracy: 0.3860\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5342 - val_loss: 0.7331 - val_accuracy: 0.3881\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.5267 - val_loss: 0.7319 - val_accuracy: 0.3925\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.5327 - val_loss: 0.7322 - val_accuracy: 0.3929\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5219 - val_loss: 0.7320 - val_accuracy: 0.3948\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.5282 - val_loss: 0.7312 - val_accuracy: 0.4003\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5331 - val_loss: 0.7312 - val_accuracy: 0.4015\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.5245 - val_loss: 0.7308 - val_accuracy: 0.4050\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5335 - val_loss: 0.7309 - val_accuracy: 0.4051\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5327 - val_loss: 0.7301 - val_accuracy: 0.4090\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5335 - val_loss: 0.7295 - val_accuracy: 0.4108\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5443 - val_loss: 0.7292 - val_accuracy: 0.4132\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5357 - val_loss: 0.7287 - val_accuracy: 0.4172\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5372 - val_loss: 0.7279 - val_accuracy: 0.4236\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5297 - val_loss: 0.7276 - val_accuracy: 0.4274\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5312 - val_loss: 0.7271 - val_accuracy: 0.4302\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5264 - val_loss: 0.7267 - val_accuracy: 0.4341\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5256 - val_loss: 0.7272 - val_accuracy: 0.4332\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7268 - accuracy: 0.4968 - val_loss: 0.6241 - val_accuracy: 0.8346\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.4968 - val_loss: 0.6386 - val_accuracy: 0.8106\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.4721 - val_loss: 0.6521 - val_accuracy: 0.7646\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7319 - accuracy: 0.4766 - val_loss: 0.6637 - val_accuracy: 0.7123\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7185 - accuracy: 0.5021 - val_loss: 0.6738 - val_accuracy: 0.6519\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7134 - accuracy: 0.5080 - val_loss: 0.6830 - val_accuracy: 0.5808\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.4830 - val_loss: 0.6908 - val_accuracy: 0.5166\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7134 - accuracy: 0.5069 - val_loss: 0.6964 - val_accuracy: 0.4790\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7131 - accuracy: 0.5039 - val_loss: 0.7022 - val_accuracy: 0.4407\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.5058 - val_loss: 0.7081 - val_accuracy: 0.3960\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.5024 - val_loss: 0.7133 - val_accuracy: 0.3639\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7134 - accuracy: 0.4946 - val_loss: 0.7168 - val_accuracy: 0.3425\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.5032 - val_loss: 0.7197 - val_accuracy: 0.3289\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.5189 - val_loss: 0.7228 - val_accuracy: 0.3146\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.5335 - val_loss: 0.7257 - val_accuracy: 0.3019\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7091 - accuracy: 0.5092 - val_loss: 0.7281 - val_accuracy: 0.2907\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.5230 - val_loss: 0.7291 - val_accuracy: 0.2865\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.5062 - val_loss: 0.7308 - val_accuracy: 0.2790\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.5185 - val_loss: 0.7313 - val_accuracy: 0.2761\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.5174 - val_loss: 0.7320 - val_accuracy: 0.2739\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.5099 - val_loss: 0.7323 - val_accuracy: 0.2726\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.5271 - val_loss: 0.7321 - val_accuracy: 0.2742\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.5159 - val_loss: 0.7329 - val_accuracy: 0.2719\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.5107 - val_loss: 0.7336 - val_accuracy: 0.2703\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7088 - accuracy: 0.4916 - val_loss: 0.7342 - val_accuracy: 0.2696\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7100 - accuracy: 0.5050 - val_loss: 0.7340 - val_accuracy: 0.2718\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5234 - val_loss: 0.7342 - val_accuracy: 0.2725\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.5185 - val_loss: 0.7343 - val_accuracy: 0.2735\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.5065 - val_loss: 0.7336 - val_accuracy: 0.2769\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.5103 - val_loss: 0.7336 - val_accuracy: 0.2793\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.5237 - val_loss: 0.7337 - val_accuracy: 0.2815\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5275 - val_loss: 0.7343 - val_accuracy: 0.2822\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.5252 - val_loss: 0.7337 - val_accuracy: 0.2880\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.5133 - val_loss: 0.7336 - val_accuracy: 0.2902\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5185 - val_loss: 0.7331 - val_accuracy: 0.2963\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.5305 - val_loss: 0.7335 - val_accuracy: 0.2971\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.5196 - val_loss: 0.7326 - val_accuracy: 0.3028\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.5290 - val_loss: 0.7331 - val_accuracy: 0.3023\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.5237 - val_loss: 0.7331 - val_accuracy: 0.3039\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.5267 - val_loss: 0.7330 - val_accuracy: 0.3064\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5361 - val_loss: 0.7323 - val_accuracy: 0.3128\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5413 - val_loss: 0.7320 - val_accuracy: 0.3172\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5301 - val_loss: 0.7324 - val_accuracy: 0.3172\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5331 - val_loss: 0.7320 - val_accuracy: 0.3207\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.5275 - val_loss: 0.7307 - val_accuracy: 0.3270\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.5316 - val_loss: 0.7292 - val_accuracy: 0.3355\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5443 - val_loss: 0.7298 - val_accuracy: 0.3358\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.5226 - val_loss: 0.7299 - val_accuracy: 0.3390\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5499 - val_loss: 0.7289 - val_accuracy: 0.3438\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5402 - val_loss: 0.7283 - val_accuracy: 0.3472\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.4976 - val_loss: 0.6621 - val_accuracy: 0.6976\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.4998 - val_loss: 0.6713 - val_accuracy: 0.6532\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.5058 - val_loss: 0.6805 - val_accuracy: 0.5864\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.5103 - val_loss: 0.6876 - val_accuracy: 0.5420\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.5170 - val_loss: 0.6941 - val_accuracy: 0.4950\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7003 - accuracy: 0.5237 - val_loss: 0.7006 - val_accuracy: 0.4497\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.5364 - val_loss: 0.7054 - val_accuracy: 0.4142\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.5088 - val_loss: 0.7097 - val_accuracy: 0.3846\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.5069 - val_loss: 0.7135 - val_accuracy: 0.3639\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.5107 - val_loss: 0.7171 - val_accuracy: 0.3466\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.5069 - val_loss: 0.7195 - val_accuracy: 0.3365\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5323 - val_loss: 0.7216 - val_accuracy: 0.3287\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.5092 - val_loss: 0.7235 - val_accuracy: 0.3195\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.5155 - val_loss: 0.7252 - val_accuracy: 0.3128\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5230 - val_loss: 0.7261 - val_accuracy: 0.3096\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.5215 - val_loss: 0.7285 - val_accuracy: 0.3009\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.5226 - val_loss: 0.7300 - val_accuracy: 0.2959\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.5230 - val_loss: 0.7306 - val_accuracy: 0.2945\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.5077 - val_loss: 0.7317 - val_accuracy: 0.2913\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.5342 - val_loss: 0.7316 - val_accuracy: 0.2918\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.5335 - val_loss: 0.7325 - val_accuracy: 0.2882\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.5207 - val_loss: 0.7328 - val_accuracy: 0.2882\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5361 - val_loss: 0.7340 - val_accuracy: 0.2833\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5133 - val_loss: 0.7332 - val_accuracy: 0.2867\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5249 - val_loss: 0.7340 - val_accuracy: 0.2848\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7036 - accuracy: 0.5290 - val_loss: 0.7342 - val_accuracy: 0.2853\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5357 - val_loss: 0.7338 - val_accuracy: 0.2878\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5264 - val_loss: 0.7348 - val_accuracy: 0.2851\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5293 - val_loss: 0.7342 - val_accuracy: 0.2886\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5421 - val_loss: 0.7344 - val_accuracy: 0.2890\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5308 - val_loss: 0.7345 - val_accuracy: 0.2905\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.5290 - val_loss: 0.7343 - val_accuracy: 0.2925\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5372 - val_loss: 0.7342 - val_accuracy: 0.2935\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.5219 - val_loss: 0.7341 - val_accuracy: 0.2951\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.5443 - val_loss: 0.7338 - val_accuracy: 0.2966\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5368 - val_loss: 0.7340 - val_accuracy: 0.2961\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5458 - val_loss: 0.7334 - val_accuracy: 0.2993\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5473 - val_loss: 0.7322 - val_accuracy: 0.3053\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.5413 - val_loss: 0.7322 - val_accuracy: 0.3062\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5331 - val_loss: 0.7324 - val_accuracy: 0.3064\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5525 - val_loss: 0.7322 - val_accuracy: 0.3072\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5372 - val_loss: 0.7310 - val_accuracy: 0.3123\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5320 - val_loss: 0.7310 - val_accuracy: 0.3128\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5432 - val_loss: 0.7306 - val_accuracy: 0.3160\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5480 - val_loss: 0.7306 - val_accuracy: 0.3163\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5391 - val_loss: 0.7301 - val_accuracy: 0.3201\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5521 - val_loss: 0.7298 - val_accuracy: 0.3230\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5492 - val_loss: 0.7300 - val_accuracy: 0.3222\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5443 - val_loss: 0.7302 - val_accuracy: 0.3223\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5443 - val_loss: 0.7306 - val_accuracy: 0.3209\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.5159 - val_loss: 0.6833 - val_accuracy: 0.6211\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.5125 - val_loss: 0.6894 - val_accuracy: 0.5719\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.4994 - val_loss: 0.6946 - val_accuracy: 0.5265\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.4927 - val_loss: 0.6991 - val_accuracy: 0.4771\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.5204 - val_loss: 0.7031 - val_accuracy: 0.4356\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.5121 - val_loss: 0.7064 - val_accuracy: 0.3963\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.5267 - val_loss: 0.7102 - val_accuracy: 0.3560\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.5166 - val_loss: 0.7127 - val_accuracy: 0.3361\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5178 - val_loss: 0.7154 - val_accuracy: 0.3155\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.5185 - val_loss: 0.7175 - val_accuracy: 0.3040\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.5155 - val_loss: 0.7199 - val_accuracy: 0.2928\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.5387 - val_loss: 0.7216 - val_accuracy: 0.2863\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7067 - accuracy: 0.5039 - val_loss: 0.7233 - val_accuracy: 0.2771\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.5264 - val_loss: 0.7245 - val_accuracy: 0.2716\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.5226 - val_loss: 0.7253 - val_accuracy: 0.2687\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.5364 - val_loss: 0.7272 - val_accuracy: 0.2616\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.5234 - val_loss: 0.7285 - val_accuracy: 0.2575\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.5305 - val_loss: 0.7293 - val_accuracy: 0.2573\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.5264 - val_loss: 0.7299 - val_accuracy: 0.2572\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5361 - val_loss: 0.7311 - val_accuracy: 0.2541\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5331 - val_loss: 0.7310 - val_accuracy: 0.2578\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6996 - accuracy: 0.5346 - val_loss: 0.7309 - val_accuracy: 0.2611\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.5286 - val_loss: 0.7313 - val_accuracy: 0.2616\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.5301 - val_loss: 0.7318 - val_accuracy: 0.2621\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.5293 - val_loss: 0.7322 - val_accuracy: 0.2625\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5424 - val_loss: 0.7323 - val_accuracy: 0.2646\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.5402 - val_loss: 0.7328 - val_accuracy: 0.2653\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5327 - val_loss: 0.7330 - val_accuracy: 0.2664\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5432 - val_loss: 0.7333 - val_accuracy: 0.2677\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5454 - val_loss: 0.7328 - val_accuracy: 0.2705\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.5436 - val_loss: 0.7326 - val_accuracy: 0.2737\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.5275 - val_loss: 0.7324 - val_accuracy: 0.2766\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5379 - val_loss: 0.7326 - val_accuracy: 0.2777\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5383 - val_loss: 0.7327 - val_accuracy: 0.2790\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5342 - val_loss: 0.7328 - val_accuracy: 0.2809\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5316 - val_loss: 0.7323 - val_accuracy: 0.2842\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5342 - val_loss: 0.7322 - val_accuracy: 0.2864\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5443 - val_loss: 0.7324 - val_accuracy: 0.2874\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5462 - val_loss: 0.7318 - val_accuracy: 0.2913\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5368 - val_loss: 0.7317 - val_accuracy: 0.2930\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5596 - val_loss: 0.7318 - val_accuracy: 0.2939\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5394 - val_loss: 0.7320 - val_accuracy: 0.2953\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5503 - val_loss: 0.7317 - val_accuracy: 0.2965\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5548 - val_loss: 0.7317 - val_accuracy: 0.2982\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5570 - val_loss: 0.7312 - val_accuracy: 0.3019\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5398 - val_loss: 0.7311 - val_accuracy: 0.3027\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5406 - val_loss: 0.7311 - val_accuracy: 0.3047\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5518 - val_loss: 0.7310 - val_accuracy: 0.3065\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5477 - val_loss: 0.7310 - val_accuracy: 0.3089\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5484 - val_loss: 0.7313 - val_accuracy: 0.3095\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7835 - accuracy: 0.4759 - val_loss: 0.4841 - val_accuracy: 0.8779\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7654 - accuracy: 0.4845 - val_loss: 0.5012 - val_accuracy: 0.8769\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7503 - accuracy: 0.4830 - val_loss: 0.5184 - val_accuracy: 0.8764\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7400 - accuracy: 0.4845 - val_loss: 0.5344 - val_accuracy: 0.8758\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.5054 - val_loss: 0.5493 - val_accuracy: 0.8746\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.5024 - val_loss: 0.5636 - val_accuracy: 0.8738\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.5073 - val_loss: 0.5775 - val_accuracy: 0.8733\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.5290 - val_loss: 0.5899 - val_accuracy: 0.8717\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.5383 - val_loss: 0.6016 - val_accuracy: 0.8674\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5507 - val_loss: 0.6125 - val_accuracy: 0.8514\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5503 - val_loss: 0.6222 - val_accuracy: 0.8363\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5469 - val_loss: 0.6310 - val_accuracy: 0.8039\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5566 - val_loss: 0.6386 - val_accuracy: 0.7688\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5667 - val_loss: 0.6460 - val_accuracy: 0.7358\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5708 - val_loss: 0.6525 - val_accuracy: 0.7093\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5802 - val_loss: 0.6586 - val_accuracy: 0.6837\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5821 - val_loss: 0.6641 - val_accuracy: 0.6590\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.5888 - val_loss: 0.6690 - val_accuracy: 0.6402\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5723 - val_loss: 0.6734 - val_accuracy: 0.6207\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5892 - val_loss: 0.6773 - val_accuracy: 0.6040\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5914 - val_loss: 0.6810 - val_accuracy: 0.5902\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5862 - val_loss: 0.6840 - val_accuracy: 0.5723\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.5884 - val_loss: 0.6874 - val_accuracy: 0.5581\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.6015 - val_loss: 0.6898 - val_accuracy: 0.5477\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5828 - val_loss: 0.6918 - val_accuracy: 0.5396\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.6045 - val_loss: 0.6941 - val_accuracy: 0.5333\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.6019 - val_loss: 0.6961 - val_accuracy: 0.5277\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5936 - val_loss: 0.6974 - val_accuracy: 0.5241\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.5884 - val_loss: 0.6994 - val_accuracy: 0.5190\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.5981 - val_loss: 0.7005 - val_accuracy: 0.5169\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5832 - val_loss: 0.7015 - val_accuracy: 0.5149\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.6071 - val_loss: 0.7027 - val_accuracy: 0.5119\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.6034 - val_loss: 0.7040 - val_accuracy: 0.5092\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.5996 - val_loss: 0.7045 - val_accuracy: 0.5091\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.5951 - val_loss: 0.7051 - val_accuracy: 0.5091\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.5966 - val_loss: 0.7052 - val_accuracy: 0.5100\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.5873 - val_loss: 0.7054 - val_accuracy: 0.5099\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5884 - val_loss: 0.7058 - val_accuracy: 0.5097\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.6142 - val_loss: 0.7061 - val_accuracy: 0.5098\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.5918 - val_loss: 0.7060 - val_accuracy: 0.5103\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6026 - val_loss: 0.7063 - val_accuracy: 0.5108\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.5963 - val_loss: 0.7065 - val_accuracy: 0.5113\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.6153 - val_loss: 0.7061 - val_accuracy: 0.5127\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.6086 - val_loss: 0.7065 - val_accuracy: 0.5126\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.5910 - val_loss: 0.7068 - val_accuracy: 0.5129\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.6194 - val_loss: 0.7067 - val_accuracy: 0.5132\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.6049 - val_loss: 0.7062 - val_accuracy: 0.5153\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.6015 - val_loss: 0.7061 - val_accuracy: 0.5161\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6194 - val_loss: 0.7059 - val_accuracy: 0.5170\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.6176 - val_loss: 0.7061 - val_accuracy: 0.5172\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.5361 - val_loss: 0.8733 - val_accuracy: 0.1570\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.5342 - val_loss: 0.8590 - val_accuracy: 0.1621\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5529 - val_loss: 0.8460 - val_accuracy: 0.1673\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5477 - val_loss: 0.8345 - val_accuracy: 0.1769\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5383 - val_loss: 0.8245 - val_accuracy: 0.1838\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5529 - val_loss: 0.8150 - val_accuracy: 0.1956\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5533 - val_loss: 0.8067 - val_accuracy: 0.2047\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5574 - val_loss: 0.7991 - val_accuracy: 0.2177\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5563 - val_loss: 0.7920 - val_accuracy: 0.2365\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5626 - val_loss: 0.7853 - val_accuracy: 0.2537\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5544 - val_loss: 0.7793 - val_accuracy: 0.2739\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5413 - val_loss: 0.7736 - val_accuracy: 0.2897\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5566 - val_loss: 0.7687 - val_accuracy: 0.3050\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5533 - val_loss: 0.7641 - val_accuracy: 0.3185\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5622 - val_loss: 0.7600 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5585 - val_loss: 0.7556 - val_accuracy: 0.3466\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5536 - val_loss: 0.7523 - val_accuracy: 0.3562\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5566 - val_loss: 0.7492 - val_accuracy: 0.3702\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5611 - val_loss: 0.7467 - val_accuracy: 0.3795\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5559 - val_loss: 0.7434 - val_accuracy: 0.3888\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6779 - accuracy: 0.5660 - val_loss: 0.7414 - val_accuracy: 0.3950\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.5727 - val_loss: 0.7396 - val_accuracy: 0.4024\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.5686 - val_loss: 0.7376 - val_accuracy: 0.4096\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5589 - val_loss: 0.7356 - val_accuracy: 0.4174\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.5720 - val_loss: 0.7335 - val_accuracy: 0.4260\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.5581 - val_loss: 0.7323 - val_accuracy: 0.4317\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5536 - val_loss: 0.7312 - val_accuracy: 0.4349\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5607 - val_loss: 0.7301 - val_accuracy: 0.4389\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5607 - val_loss: 0.7287 - val_accuracy: 0.4433\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5492 - val_loss: 0.7276 - val_accuracy: 0.4477\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5660 - val_loss: 0.7262 - val_accuracy: 0.4499\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.5682 - val_loss: 0.7255 - val_accuracy: 0.4529\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.5731 - val_loss: 0.7249 - val_accuracy: 0.4558\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5660 - val_loss: 0.7236 - val_accuracy: 0.4614\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5626 - val_loss: 0.7232 - val_accuracy: 0.4632\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5559 - val_loss: 0.7226 - val_accuracy: 0.4653\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.5787 - val_loss: 0.7219 - val_accuracy: 0.4678\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5600 - val_loss: 0.7208 - val_accuracy: 0.4723\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.5716 - val_loss: 0.7202 - val_accuracy: 0.4743\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5746 - val_loss: 0.7200 - val_accuracy: 0.4746\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5693 - val_loss: 0.7194 - val_accuracy: 0.4775\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.5708 - val_loss: 0.7188 - val_accuracy: 0.4799\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5753 - val_loss: 0.7186 - val_accuracy: 0.4804\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5611 - val_loss: 0.7178 - val_accuracy: 0.4826\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5705 - val_loss: 0.7175 - val_accuracy: 0.4835\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.5824 - val_loss: 0.7167 - val_accuracy: 0.4855\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5641 - val_loss: 0.7159 - val_accuracy: 0.4873\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.5708 - val_loss: 0.7151 - val_accuracy: 0.4890\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5664 - val_loss: 0.7150 - val_accuracy: 0.4899\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.5746 - val_loss: 0.7148 - val_accuracy: 0.4912\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.5039 - val_loss: 0.8450 - val_accuracy: 0.1423\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.5088 - val_loss: 0.8364 - val_accuracy: 0.1435\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.5118 - val_loss: 0.8289 - val_accuracy: 0.1462\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.5103 - val_loss: 0.8211 - val_accuracy: 0.1485\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.5069 - val_loss: 0.8149 - val_accuracy: 0.1521\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7244 - accuracy: 0.4927 - val_loss: 0.8091 - val_accuracy: 0.1554\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.5125 - val_loss: 0.8034 - val_accuracy: 0.1585\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.5021 - val_loss: 0.7982 - val_accuracy: 0.1610\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.5107 - val_loss: 0.7938 - val_accuracy: 0.1637\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.4905 - val_loss: 0.7900 - val_accuracy: 0.1671\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.4867 - val_loss: 0.7873 - val_accuracy: 0.1684\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7166 - accuracy: 0.5006 - val_loss: 0.7843 - val_accuracy: 0.1712\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7164 - accuracy: 0.4935 - val_loss: 0.7817 - val_accuracy: 0.1733\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7147 - accuracy: 0.4991 - val_loss: 0.7793 - val_accuracy: 0.1755\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.5043 - val_loss: 0.7771 - val_accuracy: 0.1777\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.5021 - val_loss: 0.7755 - val_accuracy: 0.1793\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7122 - accuracy: 0.5036 - val_loss: 0.7739 - val_accuracy: 0.1817\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.4964 - val_loss: 0.7727 - val_accuracy: 0.1839\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.5024 - val_loss: 0.7708 - val_accuracy: 0.1860\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.5058 - val_loss: 0.7690 - val_accuracy: 0.1883\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.5092 - val_loss: 0.7675 - val_accuracy: 0.1913\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.4923 - val_loss: 0.7663 - val_accuracy: 0.1929\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7127 - accuracy: 0.4916 - val_loss: 0.7647 - val_accuracy: 0.1951\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.4950 - val_loss: 0.7634 - val_accuracy: 0.1974\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7058 - accuracy: 0.5088 - val_loss: 0.7620 - val_accuracy: 0.2002\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.5133 - val_loss: 0.7607 - val_accuracy: 0.2031\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7196 - accuracy: 0.4751 - val_loss: 0.7605 - val_accuracy: 0.2036\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.5065 - val_loss: 0.7598 - val_accuracy: 0.2049\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.5092 - val_loss: 0.7580 - val_accuracy: 0.2082\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.5118 - val_loss: 0.7570 - val_accuracy: 0.2105\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.5002 - val_loss: 0.7560 - val_accuracy: 0.2145\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.5196 - val_loss: 0.7551 - val_accuracy: 0.2185\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7088 - accuracy: 0.5114 - val_loss: 0.7549 - val_accuracy: 0.2193\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.5062 - val_loss: 0.7548 - val_accuracy: 0.2198\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.5032 - val_loss: 0.7551 - val_accuracy: 0.2191\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.5036 - val_loss: 0.7546 - val_accuracy: 0.2212\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7089 - accuracy: 0.4942 - val_loss: 0.7542 - val_accuracy: 0.2229\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.5125 - val_loss: 0.7537 - val_accuracy: 0.2256\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.4931 - val_loss: 0.7535 - val_accuracy: 0.2267\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7019 - accuracy: 0.5136 - val_loss: 0.7534 - val_accuracy: 0.2271\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5245 - val_loss: 0.7532 - val_accuracy: 0.2287\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.5118 - val_loss: 0.7525 - val_accuracy: 0.2313\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.5159 - val_loss: 0.7521 - val_accuracy: 0.2344\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.5050 - val_loss: 0.7518 - val_accuracy: 0.2354\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5095 - val_loss: 0.7512 - val_accuracy: 0.2379\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.5196 - val_loss: 0.7509 - val_accuracy: 0.2390\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5107 - val_loss: 0.7505 - val_accuracy: 0.2406\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.5234 - val_loss: 0.7498 - val_accuracy: 0.2433\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.5095 - val_loss: 0.7492 - val_accuracy: 0.2451\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.5335 - val_loss: 0.7484 - val_accuracy: 0.2472\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.8041 - accuracy: 0.5335 - val_loss: 1.1848 - val_accuracy: 0.1179\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7722 - accuracy: 0.5275 - val_loss: 1.0951 - val_accuracy: 0.1182\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7476 - accuracy: 0.5335 - val_loss: 1.0241 - val_accuracy: 0.1192\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7323 - accuracy: 0.5305 - val_loss: 0.9671 - val_accuracy: 0.1212\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.5394 - val_loss: 0.9208 - val_accuracy: 0.1232\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.5480 - val_loss: 0.8850 - val_accuracy: 0.1246\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.5473 - val_loss: 0.8557 - val_accuracy: 0.1266\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5559 - val_loss: 0.8330 - val_accuracy: 0.1407\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5480 - val_loss: 0.8145 - val_accuracy: 0.1543\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5402 - val_loss: 0.8017 - val_accuracy: 0.1651\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5350 - val_loss: 0.7899 - val_accuracy: 0.1785\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5525 - val_loss: 0.7790 - val_accuracy: 0.1982\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5514 - val_loss: 0.7722 - val_accuracy: 0.2142\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5574 - val_loss: 0.7672 - val_accuracy: 0.2288\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5630 - val_loss: 0.7620 - val_accuracy: 0.2433\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5439 - val_loss: 0.7559 - val_accuracy: 0.2631\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5611 - val_loss: 0.7529 - val_accuracy: 0.2740\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5510 - val_loss: 0.7493 - val_accuracy: 0.2874\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5510 - val_loss: 0.7462 - val_accuracy: 0.2987\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5607 - val_loss: 0.7446 - val_accuracy: 0.3064\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5581 - val_loss: 0.7417 - val_accuracy: 0.3193\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5667 - val_loss: 0.7401 - val_accuracy: 0.3282\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5682 - val_loss: 0.7395 - val_accuracy: 0.3319\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5641 - val_loss: 0.7375 - val_accuracy: 0.3409\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5585 - val_loss: 0.7364 - val_accuracy: 0.3461\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5738 - val_loss: 0.7357 - val_accuracy: 0.3513\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5776 - val_loss: 0.7356 - val_accuracy: 0.3551\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5693 - val_loss: 0.7359 - val_accuracy: 0.3570\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5750 - val_loss: 0.7347 - val_accuracy: 0.3628\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5727 - val_loss: 0.7343 - val_accuracy: 0.3668\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5712 - val_loss: 0.7327 - val_accuracy: 0.3727\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.5850 - val_loss: 0.7308 - val_accuracy: 0.3797\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5667 - val_loss: 0.7298 - val_accuracy: 0.3853\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5880 - val_loss: 0.7291 - val_accuracy: 0.3901\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5615 - val_loss: 0.7287 - val_accuracy: 0.3926\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5641 - val_loss: 0.7268 - val_accuracy: 0.4008\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.5794 - val_loss: 0.7265 - val_accuracy: 0.4047\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5768 - val_loss: 0.7265 - val_accuracy: 0.4069\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5839 - val_loss: 0.7257 - val_accuracy: 0.4134\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.5921 - val_loss: 0.7249 - val_accuracy: 0.4190\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5794 - val_loss: 0.7246 - val_accuracy: 0.4234\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.5936 - val_loss: 0.7233 - val_accuracy: 0.4317\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.5772 - val_loss: 0.7228 - val_accuracy: 0.4367\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.5951 - val_loss: 0.7216 - val_accuracy: 0.4420\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.5955 - val_loss: 0.7217 - val_accuracy: 0.4440\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.5884 - val_loss: 0.7208 - val_accuracy: 0.4489\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.5858 - val_loss: 0.7209 - val_accuracy: 0.4496\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.5880 - val_loss: 0.7206 - val_accuracy: 0.4533\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.6071 - val_loss: 0.7195 - val_accuracy: 0.4584\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.5854 - val_loss: 0.7182 - val_accuracy: 0.4622\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5439 - val_loss: 0.6571 - val_accuracy: 0.7016\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.5376 - val_loss: 0.6660 - val_accuracy: 0.6740\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5402 - val_loss: 0.6737 - val_accuracy: 0.6459\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5548 - val_loss: 0.6807 - val_accuracy: 0.6132\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5701 - val_loss: 0.6869 - val_accuracy: 0.5832\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5593 - val_loss: 0.6927 - val_accuracy: 0.5535\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5465 - val_loss: 0.6976 - val_accuracy: 0.5283\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5626 - val_loss: 0.7016 - val_accuracy: 0.5103\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5671 - val_loss: 0.7053 - val_accuracy: 0.4905\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5551 - val_loss: 0.7079 - val_accuracy: 0.4785\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5634 - val_loss: 0.7105 - val_accuracy: 0.4685\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5473 - val_loss: 0.7133 - val_accuracy: 0.4594\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5634 - val_loss: 0.7148 - val_accuracy: 0.4535\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5686 - val_loss: 0.7165 - val_accuracy: 0.4499\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5671 - val_loss: 0.7183 - val_accuracy: 0.4441\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5649 - val_loss: 0.7194 - val_accuracy: 0.4400\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5690 - val_loss: 0.7203 - val_accuracy: 0.4368\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5742 - val_loss: 0.7214 - val_accuracy: 0.4339\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5757 - val_loss: 0.7221 - val_accuracy: 0.4325\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.5865 - val_loss: 0.7235 - val_accuracy: 0.4281\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5690 - val_loss: 0.7244 - val_accuracy: 0.4250\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5664 - val_loss: 0.7246 - val_accuracy: 0.4243\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5693 - val_loss: 0.7249 - val_accuracy: 0.4240\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5772 - val_loss: 0.7257 - val_accuracy: 0.4214\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5716 - val_loss: 0.7264 - val_accuracy: 0.4192\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5708 - val_loss: 0.7266 - val_accuracy: 0.4186\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5794 - val_loss: 0.7268 - val_accuracy: 0.4193\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5847 - val_loss: 0.7261 - val_accuracy: 0.4221\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.5757 - val_loss: 0.7254 - val_accuracy: 0.4268\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5802 - val_loss: 0.7256 - val_accuracy: 0.4263\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.5813 - val_loss: 0.7256 - val_accuracy: 0.4271\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5675 - val_loss: 0.7257 - val_accuracy: 0.4276\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5716 - val_loss: 0.7251 - val_accuracy: 0.4304\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.5705 - val_loss: 0.7250 - val_accuracy: 0.4316\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5750 - val_loss: 0.7251 - val_accuracy: 0.4315\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5712 - val_loss: 0.7251 - val_accuracy: 0.4317\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5712 - val_loss: 0.7251 - val_accuracy: 0.4323\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.5764 - val_loss: 0.7252 - val_accuracy: 0.4326\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5798 - val_loss: 0.7247 - val_accuracy: 0.4347\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5693 - val_loss: 0.7248 - val_accuracy: 0.4350\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.5768 - val_loss: 0.7243 - val_accuracy: 0.4367\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5708 - val_loss: 0.7234 - val_accuracy: 0.4400\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5802 - val_loss: 0.7231 - val_accuracy: 0.4417\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.5791 - val_loss: 0.7227 - val_accuracy: 0.4435\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5806 - val_loss: 0.7223 - val_accuracy: 0.4456\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.5824 - val_loss: 0.7220 - val_accuracy: 0.4468\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.5727 - val_loss: 0.7215 - val_accuracy: 0.4484\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.5798 - val_loss: 0.7206 - val_accuracy: 0.4524\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5936 - val_loss: 0.7204 - val_accuracy: 0.4538\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.5794 - val_loss: 0.7202 - val_accuracy: 0.4558\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7897 - accuracy: 0.4729 - val_loss: 0.5063 - val_accuracy: 0.8825\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7622 - accuracy: 0.4834 - val_loss: 0.5290 - val_accuracy: 0.8816\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7454 - accuracy: 0.4837 - val_loss: 0.5498 - val_accuracy: 0.8809\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7355 - accuracy: 0.5013 - val_loss: 0.5696 - val_accuracy: 0.8779\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.5002 - val_loss: 0.5877 - val_accuracy: 0.8743\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.5006 - val_loss: 0.6045 - val_accuracy: 0.8650\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7100 - accuracy: 0.5151 - val_loss: 0.6190 - val_accuracy: 0.8547\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.5193 - val_loss: 0.6325 - val_accuracy: 0.8335\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.5080 - val_loss: 0.6447 - val_accuracy: 0.7798\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5364 - val_loss: 0.6551 - val_accuracy: 0.7222\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7043 - accuracy: 0.5196 - val_loss: 0.6636 - val_accuracy: 0.6753\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.5338 - val_loss: 0.6724 - val_accuracy: 0.6273\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.5207 - val_loss: 0.6789 - val_accuracy: 0.5980\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.5406 - val_loss: 0.6855 - val_accuracy: 0.5613\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5566 - val_loss: 0.6913 - val_accuracy: 0.5271\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5379 - val_loss: 0.6948 - val_accuracy: 0.5078\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5533 - val_loss: 0.6991 - val_accuracy: 0.4867\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5458 - val_loss: 0.7022 - val_accuracy: 0.4734\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5361 - val_loss: 0.7050 - val_accuracy: 0.4576\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5402 - val_loss: 0.7078 - val_accuracy: 0.4439\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5615 - val_loss: 0.7096 - val_accuracy: 0.4376\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5320 - val_loss: 0.7114 - val_accuracy: 0.4329\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5630 - val_loss: 0.7133 - val_accuracy: 0.4272\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5488 - val_loss: 0.7156 - val_accuracy: 0.4214\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5828 - val_loss: 0.7167 - val_accuracy: 0.4193\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5794 - val_loss: 0.7173 - val_accuracy: 0.4205\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5607 - val_loss: 0.7173 - val_accuracy: 0.4215\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6765 - accuracy: 0.5783 - val_loss: 0.7181 - val_accuracy: 0.4202\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5712 - val_loss: 0.7190 - val_accuracy: 0.4181\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5761 - val_loss: 0.7194 - val_accuracy: 0.4188\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5742 - val_loss: 0.7188 - val_accuracy: 0.4225\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5701 - val_loss: 0.7181 - val_accuracy: 0.4266\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5712 - val_loss: 0.7183 - val_accuracy: 0.4273\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5593 - val_loss: 0.7181 - val_accuracy: 0.4297\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5705 - val_loss: 0.7180 - val_accuracy: 0.4318\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.5731 - val_loss: 0.7180 - val_accuracy: 0.4328\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5708 - val_loss: 0.7175 - val_accuracy: 0.4354\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5731 - val_loss: 0.7186 - val_accuracy: 0.4326\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.5865 - val_loss: 0.7182 - val_accuracy: 0.4353\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5746 - val_loss: 0.7177 - val_accuracy: 0.4378\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.5664 - val_loss: 0.7180 - val_accuracy: 0.4379\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6769 - accuracy: 0.5787 - val_loss: 0.7174 - val_accuracy: 0.4396\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5667 - val_loss: 0.7169 - val_accuracy: 0.4439\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5746 - val_loss: 0.7159 - val_accuracy: 0.4476\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.5821 - val_loss: 0.7152 - val_accuracy: 0.4514\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5940 - val_loss: 0.7148 - val_accuracy: 0.4547\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5895 - val_loss: 0.7149 - val_accuracy: 0.4552\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5787 - val_loss: 0.7139 - val_accuracy: 0.4584\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5798 - val_loss: 0.7138 - val_accuracy: 0.4593\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5828 - val_loss: 0.7127 - val_accuracy: 0.4632\n"
     ]
    }
   ],
   "source": [
    "# 2. Vary sample_size_ratio\n",
    "results_sample_size = {}\n",
    "eps_sample_size = {}\n",
    "for ssr in sample_size_ratio_values:\n",
    "    print(f\"\\nTraining model with sample_size_ratio={ssr}...\")\n",
    "    X_sub, y_sub = subsample_data(X_train_filtered, y_train_filtered, ssr)\n",
    "    n = len(X_sub)\n",
    "    eps = compute_privacy_budget(n, default_batch_size, default_noise_multiplier, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_sub, y_sub, X_test_filtered, y_test_filtered,\n",
    "        batch_size=default_batch_size, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=default_noise_multiplier\n",
    "    )\n",
    "    results_sample_size[ssr] = compute_statistics(results)\n",
    "    eps_sample_size[ssr] = eps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7f3f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with noise_multiplier=1.1...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1 iterated over 83600 steps satisfies differential privacy with eps = 1.06 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "Epoch 1/50\n",
      "1600/1672 [===========================>..] - ETA: 0s - loss: 0.7019 - accuracy: 0.5115WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.7016 - accuracy: 0.5117 - val_loss: 0.7184 - val_accuracy: 0.3942\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.6920 - accuracy: 0.5322 - val_loss: 0.7046 - val_accuracy: 0.4759\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.6861 - accuracy: 0.5450 - val_loss: 0.7052 - val_accuracy: 0.4857\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6808 - accuracy: 0.5580 - val_loss: 0.7011 - val_accuracy: 0.5096\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 409us/step - loss: 0.6753 - accuracy: 0.5689 - val_loss: 0.6963 - val_accuracy: 0.5349\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6714 - accuracy: 0.5803 - val_loss: 0.6899 - val_accuracy: 0.5559\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.6660 - accuracy: 0.5892 - val_loss: 0.6901 - val_accuracy: 0.5550\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6630 - accuracy: 0.5963 - val_loss: 0.6847 - val_accuracy: 0.5683\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 417us/step - loss: 0.6584 - accuracy: 0.6069 - val_loss: 0.6761 - val_accuracy: 0.5896\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 416us/step - loss: 0.6550 - accuracy: 0.6114 - val_loss: 0.6756 - val_accuracy: 0.5881\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 408us/step - loss: 0.6521 - accuracy: 0.6193 - val_loss: 0.6729 - val_accuracy: 0.5917\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 418us/step - loss: 0.6474 - accuracy: 0.6238 - val_loss: 0.6713 - val_accuracy: 0.5937\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6440 - accuracy: 0.6293 - val_loss: 0.6667 - val_accuracy: 0.6011\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6408 - accuracy: 0.6329 - val_loss: 0.6615 - val_accuracy: 0.6101\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 462us/step - loss: 0.6396 - accuracy: 0.6348 - val_loss: 0.6621 - val_accuracy: 0.6073\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 415us/step - loss: 0.6352 - accuracy: 0.6407 - val_loss: 0.6638 - val_accuracy: 0.6037\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 415us/step - loss: 0.6331 - accuracy: 0.6437 - val_loss: 0.6559 - val_accuracy: 0.6147\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 416us/step - loss: 0.6292 - accuracy: 0.6503 - val_loss: 0.6563 - val_accuracy: 0.6127\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 416us/step - loss: 0.6277 - accuracy: 0.6506 - val_loss: 0.6524 - val_accuracy: 0.6173\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 417us/step - loss: 0.6244 - accuracy: 0.6516 - val_loss: 0.6525 - val_accuracy: 0.6163\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6222 - accuracy: 0.6556 - val_loss: 0.6478 - val_accuracy: 0.6245\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 420us/step - loss: 0.6198 - accuracy: 0.6600 - val_loss: 0.6471 - val_accuracy: 0.6255\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.6186 - accuracy: 0.6583 - val_loss: 0.6463 - val_accuracy: 0.6248\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6164 - accuracy: 0.6598 - val_loss: 0.6455 - val_accuracy: 0.6258\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6137 - accuracy: 0.6643 - val_loss: 0.6402 - val_accuracy: 0.6325\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6110 - accuracy: 0.6672 - val_loss: 0.6434 - val_accuracy: 0.6283\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6096 - accuracy: 0.6683 - val_loss: 0.6395 - val_accuracy: 0.6323\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6081 - accuracy: 0.6704 - val_loss: 0.6402 - val_accuracy: 0.6303\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6056 - accuracy: 0.6696 - val_loss: 0.6374 - val_accuracy: 0.6335\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6032 - accuracy: 0.6739 - val_loss: 0.6264 - val_accuracy: 0.6524\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6017 - accuracy: 0.6756 - val_loss: 0.6346 - val_accuracy: 0.6367\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6001 - accuracy: 0.6760 - val_loss: 0.6333 - val_accuracy: 0.6386\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5987 - accuracy: 0.6759 - val_loss: 0.6277 - val_accuracy: 0.6461\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5963 - accuracy: 0.6794 - val_loss: 0.6275 - val_accuracy: 0.6459\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5948 - accuracy: 0.6801 - val_loss: 0.6284 - val_accuracy: 0.6430\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5933 - accuracy: 0.6816 - val_loss: 0.6235 - val_accuracy: 0.6486\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5915 - accuracy: 0.6868 - val_loss: 0.6224 - val_accuracy: 0.6488\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5897 - accuracy: 0.6870 - val_loss: 0.6214 - val_accuracy: 0.6487\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5880 - accuracy: 0.6856 - val_loss: 0.6243 - val_accuracy: 0.6459\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5865 - accuracy: 0.6871 - val_loss: 0.6270 - val_accuracy: 0.6444\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5847 - accuracy: 0.6917 - val_loss: 0.6255 - val_accuracy: 0.6443\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5839 - accuracy: 0.6931 - val_loss: 0.6263 - val_accuracy: 0.6428\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5820 - accuracy: 0.6955 - val_loss: 0.6188 - val_accuracy: 0.6495\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5803 - accuracy: 0.6953 - val_loss: 0.6176 - val_accuracy: 0.6513\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5788 - accuracy: 0.6972 - val_loss: 0.6120 - val_accuracy: 0.6573\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5774 - accuracy: 0.7002 - val_loss: 0.6111 - val_accuracy: 0.6570\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5760 - accuracy: 0.7004 - val_loss: 0.6182 - val_accuracy: 0.6490\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5751 - accuracy: 0.7010 - val_loss: 0.6147 - val_accuracy: 0.6524\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.5728 - accuracy: 0.7039 - val_loss: 0.6097 - val_accuracy: 0.6559\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5722 - accuracy: 0.7031 - val_loss: 0.6071 - val_accuracy: 0.6598\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.7137 - accuracy: 0.4930 - val_loss: 0.7207 - val_accuracy: 0.3490\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.7000 - accuracy: 0.5211 - val_loss: 0.7126 - val_accuracy: 0.4174\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6873 - accuracy: 0.5516 - val_loss: 0.7006 - val_accuracy: 0.4993\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6794 - accuracy: 0.5721 - val_loss: 0.7009 - val_accuracy: 0.5090\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6735 - accuracy: 0.5872 - val_loss: 0.6926 - val_accuracy: 0.5415\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6676 - accuracy: 0.6033 - val_loss: 0.6850 - val_accuracy: 0.5703\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6629 - accuracy: 0.6140 - val_loss: 0.6845 - val_accuracy: 0.5713\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6601 - accuracy: 0.6182 - val_loss: 0.6762 - val_accuracy: 0.5929\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6559 - accuracy: 0.6275 - val_loss: 0.6754 - val_accuracy: 0.5912\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6516 - accuracy: 0.6361 - val_loss: 0.6713 - val_accuracy: 0.5987\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6483 - accuracy: 0.6436 - val_loss: 0.6707 - val_accuracy: 0.5963\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6446 - accuracy: 0.6505 - val_loss: 0.6682 - val_accuracy: 0.6017\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6408 - accuracy: 0.6554 - val_loss: 0.6656 - val_accuracy: 0.6036\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6378 - accuracy: 0.6580 - val_loss: 0.6640 - val_accuracy: 0.6037\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6339 - accuracy: 0.6611 - val_loss: 0.6569 - val_accuracy: 0.6153\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6312 - accuracy: 0.6670 - val_loss: 0.6562 - val_accuracy: 0.6125\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6285 - accuracy: 0.6679 - val_loss: 0.6536 - val_accuracy: 0.6154\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6249 - accuracy: 0.6715 - val_loss: 0.6498 - val_accuracy: 0.6193\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6218 - accuracy: 0.6754 - val_loss: 0.6507 - val_accuracy: 0.6164\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6180 - accuracy: 0.6786 - val_loss: 0.6416 - val_accuracy: 0.6312\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6156 - accuracy: 0.6810 - val_loss: 0.6448 - val_accuracy: 0.6258\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6132 - accuracy: 0.6809 - val_loss: 0.6385 - val_accuracy: 0.6344\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6096 - accuracy: 0.6824 - val_loss: 0.6375 - val_accuracy: 0.6328\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6067 - accuracy: 0.6866 - val_loss: 0.6309 - val_accuracy: 0.6407\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6046 - accuracy: 0.6888 - val_loss: 0.6367 - val_accuracy: 0.6304\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6028 - accuracy: 0.6885 - val_loss: 0.6362 - val_accuracy: 0.6288\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5998 - accuracy: 0.6900 - val_loss: 0.6288 - val_accuracy: 0.6398\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5980 - accuracy: 0.6909 - val_loss: 0.6270 - val_accuracy: 0.6399\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5963 - accuracy: 0.6911 - val_loss: 0.6351 - val_accuracy: 0.6267\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.5941 - accuracy: 0.6952 - val_loss: 0.6244 - val_accuracy: 0.6388\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5913 - accuracy: 0.6975 - val_loss: 0.6212 - val_accuracy: 0.6418\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5901 - accuracy: 0.6964 - val_loss: 0.6238 - val_accuracy: 0.6368\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.5878 - accuracy: 0.6988 - val_loss: 0.6262 - val_accuracy: 0.6342\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5859 - accuracy: 0.7006 - val_loss: 0.6205 - val_accuracy: 0.6397\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.5841 - accuracy: 0.7008 - val_loss: 0.6254 - val_accuracy: 0.6334\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5833 - accuracy: 0.7010 - val_loss: 0.6128 - val_accuracy: 0.6440\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5809 - accuracy: 0.7048 - val_loss: 0.6161 - val_accuracy: 0.6412\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.5794 - accuracy: 0.7047 - val_loss: 0.6193 - val_accuracy: 0.6373\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5776 - accuracy: 0.7052 - val_loss: 0.6163 - val_accuracy: 0.6393\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5755 - accuracy: 0.7077 - val_loss: 0.6127 - val_accuracy: 0.6420\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5735 - accuracy: 0.7080 - val_loss: 0.6158 - val_accuracy: 0.6385\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5721 - accuracy: 0.7092 - val_loss: 0.6135 - val_accuracy: 0.6396\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5705 - accuracy: 0.7096 - val_loss: 0.6155 - val_accuracy: 0.6365\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5685 - accuracy: 0.7127 - val_loss: 0.6084 - val_accuracy: 0.6429\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5677 - accuracy: 0.7110 - val_loss: 0.6074 - val_accuracy: 0.6427\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5658 - accuracy: 0.7126 - val_loss: 0.6007 - val_accuracy: 0.6508\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5641 - accuracy: 0.7163 - val_loss: 0.6086 - val_accuracy: 0.6426\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5633 - accuracy: 0.7159 - val_loss: 0.6042 - val_accuracy: 0.6469\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.5613 - accuracy: 0.7188 - val_loss: 0.6154 - val_accuracy: 0.6361\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5602 - accuracy: 0.7188 - val_loss: 0.5989 - val_accuracy: 0.6510\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.7996 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.7214 - accuracy: 0.4984 - val_loss: 0.6948 - val_accuracy: 0.5162\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6995 - accuracy: 0.5205 - val_loss: 0.7177 - val_accuracy: 0.3750\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6939 - accuracy: 0.5339 - val_loss: 0.7150 - val_accuracy: 0.4086\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6903 - accuracy: 0.5425 - val_loss: 0.7115 - val_accuracy: 0.4400\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6850 - accuracy: 0.5537 - val_loss: 0.7073 - val_accuracy: 0.4669\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6813 - accuracy: 0.5637 - val_loss: 0.7073 - val_accuracy: 0.4662\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6780 - accuracy: 0.5738 - val_loss: 0.7018 - val_accuracy: 0.4971\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6747 - accuracy: 0.5839 - val_loss: 0.7007 - val_accuracy: 0.5029\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6714 - accuracy: 0.5905 - val_loss: 0.6972 - val_accuracy: 0.5168\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6693 - accuracy: 0.5980 - val_loss: 0.6981 - val_accuracy: 0.5143\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.6647 - accuracy: 0.6074 - val_loss: 0.6955 - val_accuracy: 0.5249\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6615 - accuracy: 0.6126 - val_loss: 0.6899 - val_accuracy: 0.5450\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6579 - accuracy: 0.6210 - val_loss: 0.6854 - val_accuracy: 0.5565\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6553 - accuracy: 0.6285 - val_loss: 0.6854 - val_accuracy: 0.5550\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6520 - accuracy: 0.6328 - val_loss: 0.6801 - val_accuracy: 0.5655\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6495 - accuracy: 0.6380 - val_loss: 0.6805 - val_accuracy: 0.5645\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6469 - accuracy: 0.6416 - val_loss: 0.6761 - val_accuracy: 0.5727\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6437 - accuracy: 0.6481 - val_loss: 0.6729 - val_accuracy: 0.5782\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6393 - accuracy: 0.6537 - val_loss: 0.6694 - val_accuracy: 0.5837\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6376 - accuracy: 0.6561 - val_loss: 0.6726 - val_accuracy: 0.5739\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6344 - accuracy: 0.6597 - val_loss: 0.6662 - val_accuracy: 0.5893\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6324 - accuracy: 0.6616 - val_loss: 0.6644 - val_accuracy: 0.5915\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6302 - accuracy: 0.6618 - val_loss: 0.6556 - val_accuracy: 0.6126\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6264 - accuracy: 0.6652 - val_loss: 0.6570 - val_accuracy: 0.6053\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6239 - accuracy: 0.6683 - val_loss: 0.6565 - val_accuracy: 0.6050\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6220 - accuracy: 0.6683 - val_loss: 0.6537 - val_accuracy: 0.6098\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6185 - accuracy: 0.6729 - val_loss: 0.6496 - val_accuracy: 0.6175\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6164 - accuracy: 0.6742 - val_loss: 0.6515 - val_accuracy: 0.6122\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6145 - accuracy: 0.6745 - val_loss: 0.6452 - val_accuracy: 0.6242\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6123 - accuracy: 0.6760 - val_loss: 0.6417 - val_accuracy: 0.6322\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6108 - accuracy: 0.6767 - val_loss: 0.6493 - val_accuracy: 0.6128\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6076 - accuracy: 0.6785 - val_loss: 0.6382 - val_accuracy: 0.6372\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6050 - accuracy: 0.6808 - val_loss: 0.6391 - val_accuracy: 0.6330\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6033 - accuracy: 0.6820 - val_loss: 0.6362 - val_accuracy: 0.6380\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6008 - accuracy: 0.6842 - val_loss: 0.6357 - val_accuracy: 0.6374\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.5981 - accuracy: 0.6864 - val_loss: 0.6311 - val_accuracy: 0.6441\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.5968 - accuracy: 0.6870 - val_loss: 0.6295 - val_accuracy: 0.6465\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5954 - accuracy: 0.6872 - val_loss: 0.6299 - val_accuracy: 0.6447\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.5918 - accuracy: 0.6881 - val_loss: 0.6284 - val_accuracy: 0.6460\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.5901 - accuracy: 0.6924 - val_loss: 0.6332 - val_accuracy: 0.6375\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5887 - accuracy: 0.6926 - val_loss: 0.6316 - val_accuracy: 0.6394\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5879 - accuracy: 0.6931 - val_loss: 0.6287 - val_accuracy: 0.6430\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5847 - accuracy: 0.6928 - val_loss: 0.6217 - val_accuracy: 0.6529\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5841 - accuracy: 0.6924 - val_loss: 0.6242 - val_accuracy: 0.6478\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5817 - accuracy: 0.6966 - val_loss: 0.6158 - val_accuracy: 0.6601\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.5806 - accuracy: 0.6968 - val_loss: 0.6203 - val_accuracy: 0.6509\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.5783 - accuracy: 0.6986 - val_loss: 0.6188 - val_accuracy: 0.6528\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.5760 - accuracy: 0.7004 - val_loss: 0.6178 - val_accuracy: 0.6523\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5750 - accuracy: 0.7021 - val_loss: 0.6218 - val_accuracy: 0.6461\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5738 - accuracy: 0.7016 - val_loss: 0.6114 - val_accuracy: 0.6596\n",
      "Epoch 1/50\n",
      "1622/1672 [============================>.] - ETA: 0s - loss: 0.7086 - accuracy: 0.5113WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.7086 - accuracy: 0.5114 - val_loss: 0.7209 - val_accuracy: 0.3977\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6979 - accuracy: 0.5321 - val_loss: 0.7092 - val_accuracy: 0.4619\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6895 - accuracy: 0.5469 - val_loss: 0.7024 - val_accuracy: 0.4856\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6837 - accuracy: 0.5629 - val_loss: 0.6981 - val_accuracy: 0.5019\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6770 - accuracy: 0.5768 - val_loss: 0.6882 - val_accuracy: 0.5382\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6718 - accuracy: 0.5903 - val_loss: 0.6807 - val_accuracy: 0.5640\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6667 - accuracy: 0.5975 - val_loss: 0.6772 - val_accuracy: 0.5807\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6612 - accuracy: 0.6067 - val_loss: 0.6757 - val_accuracy: 0.5854\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6573 - accuracy: 0.6154 - val_loss: 0.6713 - val_accuracy: 0.5968\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6538 - accuracy: 0.6219 - val_loss: 0.6679 - val_accuracy: 0.6026\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6508 - accuracy: 0.6263 - val_loss: 0.6631 - val_accuracy: 0.6089\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6483 - accuracy: 0.6316 - val_loss: 0.6626 - val_accuracy: 0.6085\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6444 - accuracy: 0.6374 - val_loss: 0.6677 - val_accuracy: 0.5991\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6406 - accuracy: 0.6443 - val_loss: 0.6545 - val_accuracy: 0.6183\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6376 - accuracy: 0.6469 - val_loss: 0.6547 - val_accuracy: 0.6156\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6360 - accuracy: 0.6478 - val_loss: 0.6547 - val_accuracy: 0.6162\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6332 - accuracy: 0.6512 - val_loss: 0.6531 - val_accuracy: 0.6188\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6296 - accuracy: 0.6585 - val_loss: 0.6474 - val_accuracy: 0.6258\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6275 - accuracy: 0.6597 - val_loss: 0.6483 - val_accuracy: 0.6245\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6261 - accuracy: 0.6610 - val_loss: 0.6357 - val_accuracy: 0.6429\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6222 - accuracy: 0.6638 - val_loss: 0.6468 - val_accuracy: 0.6258\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6203 - accuracy: 0.6664 - val_loss: 0.6398 - val_accuracy: 0.6359\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6169 - accuracy: 0.6706 - val_loss: 0.6344 - val_accuracy: 0.6455\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6147 - accuracy: 0.6741 - val_loss: 0.6342 - val_accuracy: 0.6444\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6126 - accuracy: 0.6751 - val_loss: 0.6357 - val_accuracy: 0.6401\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6112 - accuracy: 0.6773 - val_loss: 0.6324 - val_accuracy: 0.6441\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6088 - accuracy: 0.6797 - val_loss: 0.6318 - val_accuracy: 0.6426\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6059 - accuracy: 0.6836 - val_loss: 0.6330 - val_accuracy: 0.6399\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6043 - accuracy: 0.6841 - val_loss: 0.6293 - val_accuracy: 0.6447\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6032 - accuracy: 0.6822 - val_loss: 0.6305 - val_accuracy: 0.6406\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6007 - accuracy: 0.6881 - val_loss: 0.6288 - val_accuracy: 0.6409\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5990 - accuracy: 0.6891 - val_loss: 0.6255 - val_accuracy: 0.6435\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.5965 - accuracy: 0.6928 - val_loss: 0.6196 - val_accuracy: 0.6519\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5945 - accuracy: 0.6929 - val_loss: 0.6230 - val_accuracy: 0.6456\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5926 - accuracy: 0.6963 - val_loss: 0.6219 - val_accuracy: 0.6475\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.5910 - accuracy: 0.6973 - val_loss: 0.6114 - val_accuracy: 0.6587\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.5891 - accuracy: 0.6989 - val_loss: 0.6164 - val_accuracy: 0.6535\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5874 - accuracy: 0.7011 - val_loss: 0.6104 - val_accuracy: 0.6579\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5853 - accuracy: 0.7017 - val_loss: 0.6155 - val_accuracy: 0.6525\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5837 - accuracy: 0.7032 - val_loss: 0.6098 - val_accuracy: 0.6579\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5817 - accuracy: 0.7054 - val_loss: 0.6056 - val_accuracy: 0.6608\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5793 - accuracy: 0.7064 - val_loss: 0.6084 - val_accuracy: 0.6579\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5781 - accuracy: 0.7067 - val_loss: 0.6139 - val_accuracy: 0.6500\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5773 - accuracy: 0.7084 - val_loss: 0.6092 - val_accuracy: 0.6548\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5753 - accuracy: 0.7081 - val_loss: 0.6063 - val_accuracy: 0.6573\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.5737 - accuracy: 0.7106 - val_loss: 0.6126 - val_accuracy: 0.6480\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.5708 - accuracy: 0.7132 - val_loss: 0.6036 - val_accuracy: 0.6581\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5706 - accuracy: 0.7130 - val_loss: 0.6120 - val_accuracy: 0.6475\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5686 - accuracy: 0.7142 - val_loss: 0.6044 - val_accuracy: 0.6562\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5679 - accuracy: 0.7159 - val_loss: 0.6057 - val_accuracy: 0.6545\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6878 - accuracy: 0.5424 - val_loss: 0.7272 - val_accuracy: 0.3874\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6806 - accuracy: 0.5592 - val_loss: 0.7207 - val_accuracy: 0.4150\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6730 - accuracy: 0.5763 - val_loss: 0.7164 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6686 - accuracy: 0.5920 - val_loss: 0.7089 - val_accuracy: 0.5098\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6630 - accuracy: 0.6041 - val_loss: 0.7014 - val_accuracy: 0.5333\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6592 - accuracy: 0.6130 - val_loss: 0.6927 - val_accuracy: 0.5553\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6553 - accuracy: 0.6256 - val_loss: 0.6893 - val_accuracy: 0.5607\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6512 - accuracy: 0.6329 - val_loss: 0.6844 - val_accuracy: 0.5677\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6483 - accuracy: 0.6373 - val_loss: 0.6864 - val_accuracy: 0.5580\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6460 - accuracy: 0.6368 - val_loss: 0.6776 - val_accuracy: 0.5858\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6438 - accuracy: 0.6406 - val_loss: 0.6754 - val_accuracy: 0.5919\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6405 - accuracy: 0.6482 - val_loss: 0.6735 - val_accuracy: 0.5969\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6383 - accuracy: 0.6485 - val_loss: 0.6685 - val_accuracy: 0.6083\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6352 - accuracy: 0.6498 - val_loss: 0.6658 - val_accuracy: 0.6117\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6330 - accuracy: 0.6520 - val_loss: 0.6653 - val_accuracy: 0.6121\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6303 - accuracy: 0.6563 - val_loss: 0.6598 - val_accuracy: 0.6238\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6284 - accuracy: 0.6570 - val_loss: 0.6622 - val_accuracy: 0.6161\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6257 - accuracy: 0.6571 - val_loss: 0.6573 - val_accuracy: 0.6252\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6223 - accuracy: 0.6630 - val_loss: 0.6496 - val_accuracy: 0.6402\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6208 - accuracy: 0.6631 - val_loss: 0.6543 - val_accuracy: 0.6299\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6188 - accuracy: 0.6648 - val_loss: 0.6502 - val_accuracy: 0.6367\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6158 - accuracy: 0.6680 - val_loss: 0.6490 - val_accuracy: 0.6386\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6142 - accuracy: 0.6694 - val_loss: 0.6455 - val_accuracy: 0.6441\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6125 - accuracy: 0.6680 - val_loss: 0.6428 - val_accuracy: 0.6474\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6107 - accuracy: 0.6698 - val_loss: 0.6457 - val_accuracy: 0.6419\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.6086 - accuracy: 0.6705 - val_loss: 0.6378 - val_accuracy: 0.6516\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6066 - accuracy: 0.6723 - val_loss: 0.6377 - val_accuracy: 0.6506\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6048 - accuracy: 0.6759 - val_loss: 0.6344 - val_accuracy: 0.6559\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6026 - accuracy: 0.6758 - val_loss: 0.6377 - val_accuracy: 0.6491\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6009 - accuracy: 0.6796 - val_loss: 0.6342 - val_accuracy: 0.6545\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5992 - accuracy: 0.6798 - val_loss: 0.6345 - val_accuracy: 0.6531\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5981 - accuracy: 0.6800 - val_loss: 0.6315 - val_accuracy: 0.6563\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.5964 - accuracy: 0.6802 - val_loss: 0.6345 - val_accuracy: 0.6527\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.5949 - accuracy: 0.6814 - val_loss: 0.6339 - val_accuracy: 0.6523\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.5928 - accuracy: 0.6834 - val_loss: 0.6261 - val_accuracy: 0.6627\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5920 - accuracy: 0.6856 - val_loss: 0.6226 - val_accuracy: 0.6698\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.5903 - accuracy: 0.6859 - val_loss: 0.6286 - val_accuracy: 0.6593\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5888 - accuracy: 0.6872 - val_loss: 0.6214 - val_accuracy: 0.6702\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5876 - accuracy: 0.6895 - val_loss: 0.6257 - val_accuracy: 0.6615\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5861 - accuracy: 0.6905 - val_loss: 0.6203 - val_accuracy: 0.6691\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5836 - accuracy: 0.6930 - val_loss: 0.6197 - val_accuracy: 0.6678\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.5835 - accuracy: 0.6926 - val_loss: 0.6198 - val_accuracy: 0.6673\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5820 - accuracy: 0.6946 - val_loss: 0.6237 - val_accuracy: 0.6607\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5803 - accuracy: 0.6968 - val_loss: 0.6171 - val_accuracy: 0.6699\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.5798 - accuracy: 0.6969 - val_loss: 0.6174 - val_accuracy: 0.6685\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.5771 - accuracy: 0.6992 - val_loss: 0.6247 - val_accuracy: 0.6569\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5768 - accuracy: 0.6989 - val_loss: 0.6149 - val_accuracy: 0.6695\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5758 - accuracy: 0.7006 - val_loss: 0.6143 - val_accuracy: 0.6690\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5748 - accuracy: 0.7009 - val_loss: 0.6141 - val_accuracy: 0.6694\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.5732 - accuracy: 0.7042 - val_loss: 0.6100 - val_accuracy: 0.6746\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.7235 - accuracy: 0.4704 - val_loss: 0.7616 - val_accuracy: 0.2708\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.7154 - accuracy: 0.4797 - val_loss: 0.7501 - val_accuracy: 0.2857\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.7090 - accuracy: 0.4913 - val_loss: 0.7385 - val_accuracy: 0.2986\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.7013 - accuracy: 0.5096 - val_loss: 0.7337 - val_accuracy: 0.3087\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6964 - accuracy: 0.5206 - val_loss: 0.7274 - val_accuracy: 0.3440\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6911 - accuracy: 0.5355 - val_loss: 0.7171 - val_accuracy: 0.4020\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6870 - accuracy: 0.5466 - val_loss: 0.7125 - val_accuracy: 0.4350\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6824 - accuracy: 0.5623 - val_loss: 0.7144 - val_accuracy: 0.4510\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6787 - accuracy: 0.5738 - val_loss: 0.7093 - val_accuracy: 0.4723\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6749 - accuracy: 0.5853 - val_loss: 0.7047 - val_accuracy: 0.4848\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6715 - accuracy: 0.5950 - val_loss: 0.7043 - val_accuracy: 0.4883\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6673 - accuracy: 0.6079 - val_loss: 0.6983 - val_accuracy: 0.5068\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6667 - accuracy: 0.6090 - val_loss: 0.6995 - val_accuracy: 0.5070\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6625 - accuracy: 0.6198 - val_loss: 0.7005 - val_accuracy: 0.5054\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6599 - accuracy: 0.6257 - val_loss: 0.6941 - val_accuracy: 0.5228\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6569 - accuracy: 0.6298 - val_loss: 0.6898 - val_accuracy: 0.5373\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6537 - accuracy: 0.6379 - val_loss: 0.6881 - val_accuracy: 0.5446\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6517 - accuracy: 0.6388 - val_loss: 0.6836 - val_accuracy: 0.5567\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6488 - accuracy: 0.6437 - val_loss: 0.6796 - val_accuracy: 0.5671\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6464 - accuracy: 0.6498 - val_loss: 0.6781 - val_accuracy: 0.5704\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6442 - accuracy: 0.6499 - val_loss: 0.6757 - val_accuracy: 0.5743\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6409 - accuracy: 0.6550 - val_loss: 0.6735 - val_accuracy: 0.5767\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6384 - accuracy: 0.6600 - val_loss: 0.6661 - val_accuracy: 0.5875\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6357 - accuracy: 0.6621 - val_loss: 0.6685 - val_accuracy: 0.5838\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6335 - accuracy: 0.6644 - val_loss: 0.6660 - val_accuracy: 0.5879\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6302 - accuracy: 0.6668 - val_loss: 0.6635 - val_accuracy: 0.5931\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6278 - accuracy: 0.6704 - val_loss: 0.6621 - val_accuracy: 0.5966\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6258 - accuracy: 0.6702 - val_loss: 0.6602 - val_accuracy: 0.5999\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6239 - accuracy: 0.6721 - val_loss: 0.6591 - val_accuracy: 0.6025\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6217 - accuracy: 0.6743 - val_loss: 0.6529 - val_accuracy: 0.6104\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6196 - accuracy: 0.6773 - val_loss: 0.6514 - val_accuracy: 0.6122\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6169 - accuracy: 0.6772 - val_loss: 0.6512 - val_accuracy: 0.6119\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6151 - accuracy: 0.6798 - val_loss: 0.6504 - val_accuracy: 0.6122\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6125 - accuracy: 0.6839 - val_loss: 0.6499 - val_accuracy: 0.6116\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6101 - accuracy: 0.6832 - val_loss: 0.6463 - val_accuracy: 0.6138\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6100 - accuracy: 0.6825 - val_loss: 0.6427 - val_accuracy: 0.6165\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6079 - accuracy: 0.6840 - val_loss: 0.6421 - val_accuracy: 0.6163\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6056 - accuracy: 0.6865 - val_loss: 0.6414 - val_accuracy: 0.6158\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6037 - accuracy: 0.6897 - val_loss: 0.6404 - val_accuracy: 0.6168\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6021 - accuracy: 0.6877 - val_loss: 0.6412 - val_accuracy: 0.6162\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6010 - accuracy: 0.6885 - val_loss: 0.6366 - val_accuracy: 0.6201\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5981 - accuracy: 0.6935 - val_loss: 0.6391 - val_accuracy: 0.6175\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5956 - accuracy: 0.6929 - val_loss: 0.6375 - val_accuracy: 0.6183\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5949 - accuracy: 0.6935 - val_loss: 0.6316 - val_accuracy: 0.6255\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5940 - accuracy: 0.6954 - val_loss: 0.6327 - val_accuracy: 0.6239\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5914 - accuracy: 0.6964 - val_loss: 0.6319 - val_accuracy: 0.6247\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5912 - accuracy: 0.6949 - val_loss: 0.6358 - val_accuracy: 0.6200\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5893 - accuracy: 0.6963 - val_loss: 0.6319 - val_accuracy: 0.6246\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5883 - accuracy: 0.6967 - val_loss: 0.6306 - val_accuracy: 0.6260\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5858 - accuracy: 0.7008 - val_loss: 0.6254 - val_accuracy: 0.6319\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.8794 - accuracy: 0.4688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0008s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.7444 - accuracy: 0.5073 - val_loss: 0.7179 - val_accuracy: 0.4271\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.7131 - accuracy: 0.5190 - val_loss: 0.7023 - val_accuracy: 0.4874\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.7046 - accuracy: 0.5301 - val_loss: 0.6938 - val_accuracy: 0.5198\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6921 - accuracy: 0.5496 - val_loss: 0.6848 - val_accuracy: 0.5643\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6870 - accuracy: 0.5587 - val_loss: 0.6837 - val_accuracy: 0.5789\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6796 - accuracy: 0.5688 - val_loss: 0.6796 - val_accuracy: 0.5962\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6722 - accuracy: 0.5833 - val_loss: 0.6698 - val_accuracy: 0.6111\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6683 - accuracy: 0.5907 - val_loss: 0.6683 - val_accuracy: 0.6179\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6617 - accuracy: 0.5992 - val_loss: 0.6641 - val_accuracy: 0.6231\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6573 - accuracy: 0.6089 - val_loss: 0.6618 - val_accuracy: 0.6252\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6538 - accuracy: 0.6153 - val_loss: 0.6540 - val_accuracy: 0.6308\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6492 - accuracy: 0.6222 - val_loss: 0.6549 - val_accuracy: 0.6308\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6457 - accuracy: 0.6294 - val_loss: 0.6532 - val_accuracy: 0.6308\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6425 - accuracy: 0.6333 - val_loss: 0.6459 - val_accuracy: 0.6352\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6396 - accuracy: 0.6349 - val_loss: 0.6405 - val_accuracy: 0.6431\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6348 - accuracy: 0.6435 - val_loss: 0.6400 - val_accuracy: 0.6429\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6328 - accuracy: 0.6460 - val_loss: 0.6407 - val_accuracy: 0.6420\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6295 - accuracy: 0.6494 - val_loss: 0.6346 - val_accuracy: 0.6520\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6275 - accuracy: 0.6545 - val_loss: 0.6407 - val_accuracy: 0.6425\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6238 - accuracy: 0.6597 - val_loss: 0.6296 - val_accuracy: 0.6562\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6219 - accuracy: 0.6621 - val_loss: 0.6311 - val_accuracy: 0.6555\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6179 - accuracy: 0.6662 - val_loss: 0.6323 - val_accuracy: 0.6554\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6161 - accuracy: 0.6673 - val_loss: 0.6239 - val_accuracy: 0.6623\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6148 - accuracy: 0.6688 - val_loss: 0.6223 - val_accuracy: 0.6652\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6115 - accuracy: 0.6712 - val_loss: 0.6292 - val_accuracy: 0.6580\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6097 - accuracy: 0.6753 - val_loss: 0.6253 - val_accuracy: 0.6604\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6072 - accuracy: 0.6776 - val_loss: 0.6194 - val_accuracy: 0.6675\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6067 - accuracy: 0.6767 - val_loss: 0.6145 - val_accuracy: 0.6729\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6038 - accuracy: 0.6823 - val_loss: 0.6251 - val_accuracy: 0.6615\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6016 - accuracy: 0.6825 - val_loss: 0.6133 - val_accuracy: 0.6737\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6010 - accuracy: 0.6836 - val_loss: 0.6158 - val_accuracy: 0.6707\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.5977 - accuracy: 0.6861 - val_loss: 0.6134 - val_accuracy: 0.6731\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5969 - accuracy: 0.6885 - val_loss: 0.6208 - val_accuracy: 0.6634\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5943 - accuracy: 0.6899 - val_loss: 0.6107 - val_accuracy: 0.6737\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5921 - accuracy: 0.6923 - val_loss: 0.6155 - val_accuracy: 0.6694\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5911 - accuracy: 0.6954 - val_loss: 0.6128 - val_accuracy: 0.6712\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5897 - accuracy: 0.6951 - val_loss: 0.6155 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5884 - accuracy: 0.6960 - val_loss: 0.6145 - val_accuracy: 0.6638\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5864 - accuracy: 0.6968 - val_loss: 0.6093 - val_accuracy: 0.6707\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5853 - accuracy: 0.6984 - val_loss: 0.6091 - val_accuracy: 0.6689\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.5836 - accuracy: 0.7008 - val_loss: 0.6022 - val_accuracy: 0.6746\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5815 - accuracy: 0.7045 - val_loss: 0.6103 - val_accuracy: 0.6632\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.5797 - accuracy: 0.7033 - val_loss: 0.6045 - val_accuracy: 0.6678\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5792 - accuracy: 0.7040 - val_loss: 0.6023 - val_accuracy: 0.6688\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5774 - accuracy: 0.7060 - val_loss: 0.6009 - val_accuracy: 0.6699\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 460us/step - loss: 0.5760 - accuracy: 0.7086 - val_loss: 0.6009 - val_accuracy: 0.6697\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5747 - accuracy: 0.7084 - val_loss: 0.6079 - val_accuracy: 0.6617\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5736 - accuracy: 0.7112 - val_loss: 0.6015 - val_accuracy: 0.6685\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.5713 - accuracy: 0.7108 - val_loss: 0.6002 - val_accuracy: 0.6691\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5720 - accuracy: 0.7121 - val_loss: 0.5945 - val_accuracy: 0.6744\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.7227 - accuracy: 0.5224 - val_loss: 0.7276 - val_accuracy: 0.4085\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 420us/step - loss: 0.6972 - accuracy: 0.5412 - val_loss: 0.7111 - val_accuracy: 0.4809\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6885 - accuracy: 0.5601 - val_loss: 0.7106 - val_accuracy: 0.4823\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6802 - accuracy: 0.5731 - val_loss: 0.7011 - val_accuracy: 0.5083\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6740 - accuracy: 0.5878 - val_loss: 0.6966 - val_accuracy: 0.5207\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6668 - accuracy: 0.5995 - val_loss: 0.6951 - val_accuracy: 0.5275\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6629 - accuracy: 0.6071 - val_loss: 0.6863 - val_accuracy: 0.5485\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6578 - accuracy: 0.6204 - val_loss: 0.6852 - val_accuracy: 0.5531\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6548 - accuracy: 0.6226 - val_loss: 0.6796 - val_accuracy: 0.5670\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.6486 - accuracy: 0.6345 - val_loss: 0.6716 - val_accuracy: 0.5796\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6455 - accuracy: 0.6378 - val_loss: 0.6696 - val_accuracy: 0.5831\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6429 - accuracy: 0.6448 - val_loss: 0.6667 - val_accuracy: 0.5876\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6382 - accuracy: 0.6502 - val_loss: 0.6637 - val_accuracy: 0.5916\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6348 - accuracy: 0.6536 - val_loss: 0.6614 - val_accuracy: 0.5948\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6325 - accuracy: 0.6570 - val_loss: 0.6640 - val_accuracy: 0.5916\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6296 - accuracy: 0.6577 - val_loss: 0.6617 - val_accuracy: 0.5936\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6272 - accuracy: 0.6640 - val_loss: 0.6610 - val_accuracy: 0.5948\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6249 - accuracy: 0.6645 - val_loss: 0.6523 - val_accuracy: 0.6075\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6226 - accuracy: 0.6665 - val_loss: 0.6633 - val_accuracy: 0.5923\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6199 - accuracy: 0.6703 - val_loss: 0.6532 - val_accuracy: 0.6047\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6170 - accuracy: 0.6729 - val_loss: 0.6553 - val_accuracy: 0.6032\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6165 - accuracy: 0.6722 - val_loss: 0.6509 - val_accuracy: 0.6095\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6153 - accuracy: 0.6740 - val_loss: 0.6539 - val_accuracy: 0.6049\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6111 - accuracy: 0.6792 - val_loss: 0.6456 - val_accuracy: 0.6163\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6089 - accuracy: 0.6821 - val_loss: 0.6467 - val_accuracy: 0.6150\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6078 - accuracy: 0.6810 - val_loss: 0.6517 - val_accuracy: 0.6090\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6062 - accuracy: 0.6845 - val_loss: 0.6415 - val_accuracy: 0.6216\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6047 - accuracy: 0.6857 - val_loss: 0.6388 - val_accuracy: 0.6255\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6029 - accuracy: 0.6855 - val_loss: 0.6416 - val_accuracy: 0.6218\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6016 - accuracy: 0.6870 - val_loss: 0.6394 - val_accuracy: 0.6260\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5988 - accuracy: 0.6894 - val_loss: 0.6458 - val_accuracy: 0.6183\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5973 - accuracy: 0.6911 - val_loss: 0.6403 - val_accuracy: 0.6258\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.5958 - accuracy: 0.6918 - val_loss: 0.6369 - val_accuracy: 0.6289\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.5951 - accuracy: 0.6930 - val_loss: 0.6363 - val_accuracy: 0.6292\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5935 - accuracy: 0.6928 - val_loss: 0.6328 - val_accuracy: 0.6314\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5913 - accuracy: 0.6954 - val_loss: 0.6240 - val_accuracy: 0.6415\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5900 - accuracy: 0.6961 - val_loss: 0.6358 - val_accuracy: 0.6299\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5893 - accuracy: 0.6972 - val_loss: 0.6298 - val_accuracy: 0.6355\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5874 - accuracy: 0.6994 - val_loss: 0.6318 - val_accuracy: 0.6337\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5847 - accuracy: 0.7006 - val_loss: 0.6261 - val_accuracy: 0.6392\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5856 - accuracy: 0.6987 - val_loss: 0.6326 - val_accuracy: 0.6328\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5833 - accuracy: 0.7010 - val_loss: 0.6319 - val_accuracy: 0.6342\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5821 - accuracy: 0.7016 - val_loss: 0.6267 - val_accuracy: 0.6391\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5812 - accuracy: 0.7037 - val_loss: 0.6287 - val_accuracy: 0.6368\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5799 - accuracy: 0.7031 - val_loss: 0.6280 - val_accuracy: 0.6368\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5782 - accuracy: 0.7046 - val_loss: 0.6273 - val_accuracy: 0.6375\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5768 - accuracy: 0.7058 - val_loss: 0.6210 - val_accuracy: 0.6419\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5761 - accuracy: 0.7054 - val_loss: 0.6290 - val_accuracy: 0.6363\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5743 - accuracy: 0.7082 - val_loss: 0.6321 - val_accuracy: 0.6329\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5733 - accuracy: 0.7097 - val_loss: 0.6228 - val_accuracy: 0.6428\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.7068 - accuracy: 0.4864 - val_loss: 0.7319 - val_accuracy: 0.2196\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6961 - accuracy: 0.5258 - val_loss: 0.7281 - val_accuracy: 0.3107\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6895 - accuracy: 0.5498 - val_loss: 0.7184 - val_accuracy: 0.3887\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6827 - accuracy: 0.5749 - val_loss: 0.7099 - val_accuracy: 0.4535\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6780 - accuracy: 0.5909 - val_loss: 0.7067 - val_accuracy: 0.4709\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6742 - accuracy: 0.6013 - val_loss: 0.7010 - val_accuracy: 0.4925\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.6697 - accuracy: 0.6133 - val_loss: 0.7006 - val_accuracy: 0.4955\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6665 - accuracy: 0.6224 - val_loss: 0.6966 - val_accuracy: 0.5085\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6629 - accuracy: 0.6287 - val_loss: 0.6918 - val_accuracy: 0.5258\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6589 - accuracy: 0.6355 - val_loss: 0.6890 - val_accuracy: 0.5370\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6553 - accuracy: 0.6431 - val_loss: 0.6868 - val_accuracy: 0.5453\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6524 - accuracy: 0.6477 - val_loss: 0.6833 - val_accuracy: 0.5536\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6485 - accuracy: 0.6545 - val_loss: 0.6809 - val_accuracy: 0.5580\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6465 - accuracy: 0.6561 - val_loss: 0.6751 - val_accuracy: 0.5677\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6439 - accuracy: 0.6584 - val_loss: 0.6739 - val_accuracy: 0.5698\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6411 - accuracy: 0.6613 - val_loss: 0.6728 - val_accuracy: 0.5709\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6386 - accuracy: 0.6612 - val_loss: 0.6695 - val_accuracy: 0.5759\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6358 - accuracy: 0.6653 - val_loss: 0.6652 - val_accuracy: 0.5806\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6334 - accuracy: 0.6673 - val_loss: 0.6622 - val_accuracy: 0.5858\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6312 - accuracy: 0.6704 - val_loss: 0.6623 - val_accuracy: 0.5856\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6291 - accuracy: 0.6699 - val_loss: 0.6631 - val_accuracy: 0.5850\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6268 - accuracy: 0.6750 - val_loss: 0.6546 - val_accuracy: 0.5978\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6245 - accuracy: 0.6761 - val_loss: 0.6600 - val_accuracy: 0.5897\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6224 - accuracy: 0.6771 - val_loss: 0.6534 - val_accuracy: 0.5988\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6213 - accuracy: 0.6777 - val_loss: 0.6536 - val_accuracy: 0.5987\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6194 - accuracy: 0.6769 - val_loss: 0.6491 - val_accuracy: 0.6040\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6178 - accuracy: 0.6790 - val_loss: 0.6489 - val_accuracy: 0.6040\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6151 - accuracy: 0.6839 - val_loss: 0.6485 - val_accuracy: 0.6037\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6135 - accuracy: 0.6823 - val_loss: 0.6476 - val_accuracy: 0.6041\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6120 - accuracy: 0.6847 - val_loss: 0.6446 - val_accuracy: 0.6056\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 452us/step - loss: 0.6098 - accuracy: 0.6844 - val_loss: 0.6393 - val_accuracy: 0.6120\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6082 - accuracy: 0.6863 - val_loss: 0.6374 - val_accuracy: 0.6146\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6065 - accuracy: 0.6869 - val_loss: 0.6376 - val_accuracy: 0.6135\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6050 - accuracy: 0.6886 - val_loss: 0.6332 - val_accuracy: 0.6163\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6033 - accuracy: 0.6898 - val_loss: 0.6343 - val_accuracy: 0.6156\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6016 - accuracy: 0.6916 - val_loss: 0.6344 - val_accuracy: 0.6157\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6010 - accuracy: 0.6903 - val_loss: 0.6389 - val_accuracy: 0.6123\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.5989 - accuracy: 0.6934 - val_loss: 0.6290 - val_accuracy: 0.6204\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5983 - accuracy: 0.6932 - val_loss: 0.6295 - val_accuracy: 0.6197\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5972 - accuracy: 0.6938 - val_loss: 0.6329 - val_accuracy: 0.6164\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5949 - accuracy: 0.6961 - val_loss: 0.6232 - val_accuracy: 0.6229\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5939 - accuracy: 0.6956 - val_loss: 0.6314 - val_accuracy: 0.6169\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.5924 - accuracy: 0.6977 - val_loss: 0.6298 - val_accuracy: 0.6177\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5903 - accuracy: 0.6999 - val_loss: 0.6365 - val_accuracy: 0.6134\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5891 - accuracy: 0.7015 - val_loss: 0.6188 - val_accuracy: 0.6258\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.5881 - accuracy: 0.7006 - val_loss: 0.6266 - val_accuracy: 0.6195\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5876 - accuracy: 0.7004 - val_loss: 0.6201 - val_accuracy: 0.6240\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5861 - accuracy: 0.7024 - val_loss: 0.6283 - val_accuracy: 0.6183\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.5842 - accuracy: 0.7045 - val_loss: 0.6281 - val_accuracy: 0.6174\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5836 - accuracy: 0.7044 - val_loss: 0.6281 - val_accuracy: 0.6166\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.7232 - accuracy: 0.4977 - val_loss: 0.6979 - val_accuracy: 0.4785\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.7012 - accuracy: 0.5247 - val_loss: 0.7115 - val_accuracy: 0.4057\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6950 - accuracy: 0.5368 - val_loss: 0.7045 - val_accuracy: 0.4640\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6891 - accuracy: 0.5495 - val_loss: 0.6990 - val_accuracy: 0.4993\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6829 - accuracy: 0.5623 - val_loss: 0.6936 - val_accuracy: 0.5256\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6781 - accuracy: 0.5745 - val_loss: 0.6879 - val_accuracy: 0.5588\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6734 - accuracy: 0.5843 - val_loss: 0.6873 - val_accuracy: 0.5616\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 451us/step - loss: 0.6687 - accuracy: 0.5963 - val_loss: 0.6812 - val_accuracy: 0.5862\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6653 - accuracy: 0.6057 - val_loss: 0.6797 - val_accuracy: 0.5929\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6604 - accuracy: 0.6153 - val_loss: 0.6789 - val_accuracy: 0.5945\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6579 - accuracy: 0.6218 - val_loss: 0.6724 - val_accuracy: 0.6072\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6531 - accuracy: 0.6307 - val_loss: 0.6709 - val_accuracy: 0.6103\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6498 - accuracy: 0.6364 - val_loss: 0.6637 - val_accuracy: 0.6192\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6463 - accuracy: 0.6418 - val_loss: 0.6602 - val_accuracy: 0.6234\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6436 - accuracy: 0.6472 - val_loss: 0.6607 - val_accuracy: 0.6210\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6396 - accuracy: 0.6511 - val_loss: 0.6602 - val_accuracy: 0.6207\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6368 - accuracy: 0.6569 - val_loss: 0.6580 - val_accuracy: 0.6238\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6327 - accuracy: 0.6613 - val_loss: 0.6531 - val_accuracy: 0.6299\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6312 - accuracy: 0.6629 - val_loss: 0.6542 - val_accuracy: 0.6255\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.6282 - accuracy: 0.6671 - val_loss: 0.6495 - val_accuracy: 0.6294\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6242 - accuracy: 0.6720 - val_loss: 0.6487 - val_accuracy: 0.6292\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6223 - accuracy: 0.6708 - val_loss: 0.6419 - val_accuracy: 0.6389\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.6207 - accuracy: 0.6746 - val_loss: 0.6335 - val_accuracy: 0.6490\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6172 - accuracy: 0.6796 - val_loss: 0.6417 - val_accuracy: 0.6367\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6155 - accuracy: 0.6788 - val_loss: 0.6288 - val_accuracy: 0.6511\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6122 - accuracy: 0.6819 - val_loss: 0.6369 - val_accuracy: 0.6404\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6100 - accuracy: 0.6856 - val_loss: 0.6370 - val_accuracy: 0.6388\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6079 - accuracy: 0.6877 - val_loss: 0.6286 - val_accuracy: 0.6459\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6061 - accuracy: 0.6884 - val_loss: 0.6293 - val_accuracy: 0.6437\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6046 - accuracy: 0.6893 - val_loss: 0.6238 - val_accuracy: 0.6486\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6020 - accuracy: 0.6931 - val_loss: 0.6209 - val_accuracy: 0.6496\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6004 - accuracy: 0.6942 - val_loss: 0.6244 - val_accuracy: 0.6440\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5982 - accuracy: 0.6955 - val_loss: 0.6168 - val_accuracy: 0.6508\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5958 - accuracy: 0.6985 - val_loss: 0.6190 - val_accuracy: 0.6472\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5951 - accuracy: 0.6984 - val_loss: 0.6175 - val_accuracy: 0.6486\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5925 - accuracy: 0.6988 - val_loss: 0.6171 - val_accuracy: 0.6489\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5906 - accuracy: 0.7002 - val_loss: 0.6166 - val_accuracy: 0.6480\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5883 - accuracy: 0.7037 - val_loss: 0.6158 - val_accuracy: 0.6482\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5873 - accuracy: 0.7044 - val_loss: 0.6121 - val_accuracy: 0.6527\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5863 - accuracy: 0.7030 - val_loss: 0.6141 - val_accuracy: 0.6495\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5836 - accuracy: 0.7055 - val_loss: 0.6140 - val_accuracy: 0.6489\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5819 - accuracy: 0.7065 - val_loss: 0.6064 - val_accuracy: 0.6593\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5808 - accuracy: 0.7078 - val_loss: 0.6158 - val_accuracy: 0.6450\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5797 - accuracy: 0.7086 - val_loss: 0.6125 - val_accuracy: 0.6487\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5782 - accuracy: 0.7096 - val_loss: 0.6128 - val_accuracy: 0.6479\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5766 - accuracy: 0.7102 - val_loss: 0.6035 - val_accuracy: 0.6592\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5763 - accuracy: 0.7112 - val_loss: 0.6075 - val_accuracy: 0.6538\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5732 - accuracy: 0.7133 - val_loss: 0.6045 - val_accuracy: 0.6568\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5719 - accuracy: 0.7145 - val_loss: 0.6053 - val_accuracy: 0.6549\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.5710 - accuracy: 0.7150 - val_loss: 0.6119 - val_accuracy: 0.6467\n",
      "\n",
      "Training model with noise_multiplier=1.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.5 iterated over 83600 steps satisfies differential privacy with eps = 0.643 and delta = 1e-05.\n",
      "The optimal RDP order is 32.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6972 - accuracy: 0.5332 - val_loss: 0.7110 - val_accuracy: 0.4579\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6845 - accuracy: 0.5636 - val_loss: 0.7021 - val_accuracy: 0.5017\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6755 - accuracy: 0.5841 - val_loss: 0.6967 - val_accuracy: 0.5305\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6680 - accuracy: 0.5999 - val_loss: 0.6869 - val_accuracy: 0.5631\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6623 - accuracy: 0.6146 - val_loss: 0.6816 - val_accuracy: 0.5749\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6551 - accuracy: 0.6269 - val_loss: 0.6739 - val_accuracy: 0.5854\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6502 - accuracy: 0.6323 - val_loss: 0.6700 - val_accuracy: 0.5908\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6454 - accuracy: 0.6415 - val_loss: 0.6682 - val_accuracy: 0.5931\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6402 - accuracy: 0.6519 - val_loss: 0.6583 - val_accuracy: 0.6071\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6359 - accuracy: 0.6578 - val_loss: 0.6558 - val_accuracy: 0.6112\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6309 - accuracy: 0.6633 - val_loss: 0.6541 - val_accuracy: 0.6159\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6274 - accuracy: 0.6646 - val_loss: 0.6483 - val_accuracy: 0.6259\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6229 - accuracy: 0.6722 - val_loss: 0.6495 - val_accuracy: 0.6226\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6199 - accuracy: 0.6721 - val_loss: 0.6422 - val_accuracy: 0.6334\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6171 - accuracy: 0.6781 - val_loss: 0.6463 - val_accuracy: 0.6239\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6133 - accuracy: 0.6799 - val_loss: 0.6375 - val_accuracy: 0.6356\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6102 - accuracy: 0.6851 - val_loss: 0.6381 - val_accuracy: 0.6339\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6057 - accuracy: 0.6863 - val_loss: 0.6327 - val_accuracy: 0.6396\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6049 - accuracy: 0.6882 - val_loss: 0.6329 - val_accuracy: 0.6383\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6023 - accuracy: 0.6917 - val_loss: 0.6231 - val_accuracy: 0.6474\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6001 - accuracy: 0.6929 - val_loss: 0.6280 - val_accuracy: 0.6420\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5973 - accuracy: 0.6955 - val_loss: 0.6166 - val_accuracy: 0.6528\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5949 - accuracy: 0.6960 - val_loss: 0.6206 - val_accuracy: 0.6486\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5929 - accuracy: 0.6970 - val_loss: 0.6200 - val_accuracy: 0.6485\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5910 - accuracy: 0.7019 - val_loss: 0.6172 - val_accuracy: 0.6501\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5890 - accuracy: 0.7012 - val_loss: 0.6146 - val_accuracy: 0.6517\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5874 - accuracy: 0.7017 - val_loss: 0.6213 - val_accuracy: 0.6464\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5854 - accuracy: 0.7041 - val_loss: 0.6116 - val_accuracy: 0.6528\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5832 - accuracy: 0.7074 - val_loss: 0.6107 - val_accuracy: 0.6524\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5816 - accuracy: 0.7082 - val_loss: 0.6098 - val_accuracy: 0.6512\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5799 - accuracy: 0.7076 - val_loss: 0.6139 - val_accuracy: 0.6481\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5786 - accuracy: 0.7087 - val_loss: 0.6075 - val_accuracy: 0.6533\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5763 - accuracy: 0.7116 - val_loss: 0.6054 - val_accuracy: 0.6556\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5748 - accuracy: 0.7142 - val_loss: 0.6081 - val_accuracy: 0.6522\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5738 - accuracy: 0.7109 - val_loss: 0.6038 - val_accuracy: 0.6560\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.5721 - accuracy: 0.7126 - val_loss: 0.6051 - val_accuracy: 0.6555\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5696 - accuracy: 0.7167 - val_loss: 0.6033 - val_accuracy: 0.6576\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5684 - accuracy: 0.7170 - val_loss: 0.6025 - val_accuracy: 0.6584\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5666 - accuracy: 0.7187 - val_loss: 0.6090 - val_accuracy: 0.6532\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5657 - accuracy: 0.7190 - val_loss: 0.6047 - val_accuracy: 0.6565\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5652 - accuracy: 0.7189 - val_loss: 0.6022 - val_accuracy: 0.6586\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5620 - accuracy: 0.7197 - val_loss: 0.6047 - val_accuracy: 0.6568\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.5620 - accuracy: 0.7207 - val_loss: 0.5937 - val_accuracy: 0.6657\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5609 - accuracy: 0.7220 - val_loss: 0.6038 - val_accuracy: 0.6571\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5591 - accuracy: 0.7210 - val_loss: 0.6021 - val_accuracy: 0.6579\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5581 - accuracy: 0.7221 - val_loss: 0.5930 - val_accuracy: 0.6649\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.5567 - accuracy: 0.7242 - val_loss: 0.6032 - val_accuracy: 0.6559\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5560 - accuracy: 0.7227 - val_loss: 0.5985 - val_accuracy: 0.6596\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5555 - accuracy: 0.7236 - val_loss: 0.5999 - val_accuracy: 0.6581\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5544 - accuracy: 0.7224 - val_loss: 0.5985 - val_accuracy: 0.6591\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6874 - accuracy: 0.5537 - val_loss: 0.6772 - val_accuracy: 0.5841\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6708 - accuracy: 0.5918 - val_loss: 0.6793 - val_accuracy: 0.5807\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6633 - accuracy: 0.6073 - val_loss: 0.6756 - val_accuracy: 0.6018\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.6559 - accuracy: 0.6206 - val_loss: 0.6754 - val_accuracy: 0.5977\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6501 - accuracy: 0.6349 - val_loss: 0.6675 - val_accuracy: 0.6117\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6433 - accuracy: 0.6443 - val_loss: 0.6538 - val_accuracy: 0.6371\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6401 - accuracy: 0.6494 - val_loss: 0.6570 - val_accuracy: 0.6239\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6342 - accuracy: 0.6617 - val_loss: 0.6600 - val_accuracy: 0.6154\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6310 - accuracy: 0.6649 - val_loss: 0.6572 - val_accuracy: 0.6147\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6280 - accuracy: 0.6698 - val_loss: 0.6483 - val_accuracy: 0.6287\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6241 - accuracy: 0.6759 - val_loss: 0.6420 - val_accuracy: 0.6365\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6196 - accuracy: 0.6809 - val_loss: 0.6457 - val_accuracy: 0.6261\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6168 - accuracy: 0.6814 - val_loss: 0.6405 - val_accuracy: 0.6303\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6137 - accuracy: 0.6870 - val_loss: 0.6362 - val_accuracy: 0.6364\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6090 - accuracy: 0.6921 - val_loss: 0.6348 - val_accuracy: 0.6351\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6071 - accuracy: 0.6928 - val_loss: 0.6294 - val_accuracy: 0.6453\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6040 - accuracy: 0.6941 - val_loss: 0.6334 - val_accuracy: 0.6345\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6009 - accuracy: 0.6981 - val_loss: 0.6309 - val_accuracy: 0.6372\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5983 - accuracy: 0.7025 - val_loss: 0.6237 - val_accuracy: 0.6513\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5951 - accuracy: 0.7032 - val_loss: 0.6226 - val_accuracy: 0.6504\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5936 - accuracy: 0.7023 - val_loss: 0.6259 - val_accuracy: 0.6430\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.5918 - accuracy: 0.7049 - val_loss: 0.6163 - val_accuracy: 0.6550\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5894 - accuracy: 0.7068 - val_loss: 0.6245 - val_accuracy: 0.6413\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.5872 - accuracy: 0.7104 - val_loss: 0.6185 - val_accuracy: 0.6496\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5858 - accuracy: 0.7097 - val_loss: 0.6131 - val_accuracy: 0.6548\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5833 - accuracy: 0.7118 - val_loss: 0.6145 - val_accuracy: 0.6525\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5822 - accuracy: 0.7117 - val_loss: 0.6172 - val_accuracy: 0.6480\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5806 - accuracy: 0.7136 - val_loss: 0.6160 - val_accuracy: 0.6491\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5778 - accuracy: 0.7163 - val_loss: 0.6136 - val_accuracy: 0.6510\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5774 - accuracy: 0.7136 - val_loss: 0.6065 - val_accuracy: 0.6575\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5741 - accuracy: 0.7164 - val_loss: 0.6158 - val_accuracy: 0.6479\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5732 - accuracy: 0.7173 - val_loss: 0.6089 - val_accuracy: 0.6543\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.5708 - accuracy: 0.7201 - val_loss: 0.6012 - val_accuracy: 0.6613\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.5705 - accuracy: 0.7172 - val_loss: 0.6131 - val_accuracy: 0.6485\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5683 - accuracy: 0.7224 - val_loss: 0.6069 - val_accuracy: 0.6544\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.5674 - accuracy: 0.7213 - val_loss: 0.6059 - val_accuracy: 0.6547\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5656 - accuracy: 0.7226 - val_loss: 0.6015 - val_accuracy: 0.6583\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5650 - accuracy: 0.7239 - val_loss: 0.6035 - val_accuracy: 0.6561\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.5626 - accuracy: 0.7236 - val_loss: 0.6092 - val_accuracy: 0.6490\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5618 - accuracy: 0.7222 - val_loss: 0.6098 - val_accuracy: 0.6478\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.5603 - accuracy: 0.7243 - val_loss: 0.6108 - val_accuracy: 0.6462\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5590 - accuracy: 0.7236 - val_loss: 0.6083 - val_accuracy: 0.6492\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5580 - accuracy: 0.7253 - val_loss: 0.5992 - val_accuracy: 0.6577\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5563 - accuracy: 0.7270 - val_loss: 0.6105 - val_accuracy: 0.6468\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5555 - accuracy: 0.7262 - val_loss: 0.6083 - val_accuracy: 0.6491\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5546 - accuracy: 0.7260 - val_loss: 0.6101 - val_accuracy: 0.6475\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5538 - accuracy: 0.7271 - val_loss: 0.5977 - val_accuracy: 0.6595\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5533 - accuracy: 0.7250 - val_loss: 0.5991 - val_accuracy: 0.6589\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5513 - accuracy: 0.7292 - val_loss: 0.6077 - val_accuracy: 0.6492\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5503 - accuracy: 0.7273 - val_loss: 0.6019 - val_accuracy: 0.6559\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.7229 - accuracy: 0.4755 - val_loss: 0.6446 - val_accuracy: 0.8392\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6999 - accuracy: 0.5022 - val_loss: 0.6825 - val_accuracy: 0.5926\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6922 - accuracy: 0.5252 - val_loss: 0.6884 - val_accuracy: 0.5444\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6862 - accuracy: 0.5476 - val_loss: 0.6870 - val_accuracy: 0.5591\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6833 - accuracy: 0.5544 - val_loss: 0.6841 - val_accuracy: 0.5767\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6782 - accuracy: 0.5679 - val_loss: 0.6814 - val_accuracy: 0.5866\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6750 - accuracy: 0.5775 - val_loss: 0.6780 - val_accuracy: 0.5983\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6716 - accuracy: 0.5839 - val_loss: 0.6746 - val_accuracy: 0.6112\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6680 - accuracy: 0.5937 - val_loss: 0.6718 - val_accuracy: 0.6194\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6652 - accuracy: 0.6019 - val_loss: 0.6697 - val_accuracy: 0.6234\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6628 - accuracy: 0.6043 - val_loss: 0.6660 - val_accuracy: 0.6316\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6590 - accuracy: 0.6115 - val_loss: 0.6663 - val_accuracy: 0.6288\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6559 - accuracy: 0.6177 - val_loss: 0.6668 - val_accuracy: 0.6257\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 466us/step - loss: 0.6546 - accuracy: 0.6214 - val_loss: 0.6637 - val_accuracy: 0.6305\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6512 - accuracy: 0.6236 - val_loss: 0.6606 - val_accuracy: 0.6360\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6487 - accuracy: 0.6304 - val_loss: 0.6620 - val_accuracy: 0.6316\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.6470 - accuracy: 0.6299 - val_loss: 0.6562 - val_accuracy: 0.6408\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6438 - accuracy: 0.6347 - val_loss: 0.6525 - val_accuracy: 0.6469\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6422 - accuracy: 0.6397 - val_loss: 0.6518 - val_accuracy: 0.6462\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 422us/step - loss: 0.6393 - accuracy: 0.6424 - val_loss: 0.6490 - val_accuracy: 0.6489\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6380 - accuracy: 0.6446 - val_loss: 0.6454 - val_accuracy: 0.6533\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6354 - accuracy: 0.6448 - val_loss: 0.6443 - val_accuracy: 0.6531\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6337 - accuracy: 0.6478 - val_loss: 0.6453 - val_accuracy: 0.6491\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6317 - accuracy: 0.6494 - val_loss: 0.6455 - val_accuracy: 0.6478\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6297 - accuracy: 0.6556 - val_loss: 0.6427 - val_accuracy: 0.6496\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6270 - accuracy: 0.6562 - val_loss: 0.6378 - val_accuracy: 0.6563\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 419us/step - loss: 0.6258 - accuracy: 0.6582 - val_loss: 0.6372 - val_accuracy: 0.6559\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 423us/step - loss: 0.6234 - accuracy: 0.6608 - val_loss: 0.6392 - val_accuracy: 0.6489\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6219 - accuracy: 0.6628 - val_loss: 0.6336 - val_accuracy: 0.6556\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 425us/step - loss: 0.6200 - accuracy: 0.6624 - val_loss: 0.6365 - val_accuracy: 0.6501\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6178 - accuracy: 0.6660 - val_loss: 0.6347 - val_accuracy: 0.6507\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6168 - accuracy: 0.6666 - val_loss: 0.6310 - val_accuracy: 0.6527\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6154 - accuracy: 0.6704 - val_loss: 0.6298 - val_accuracy: 0.6528\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.6137 - accuracy: 0.6715 - val_loss: 0.6288 - val_accuracy: 0.6529\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 424us/step - loss: 0.6117 - accuracy: 0.6708 - val_loss: 0.6272 - val_accuracy: 0.6528\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6090 - accuracy: 0.6739 - val_loss: 0.6293 - val_accuracy: 0.6495\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6077 - accuracy: 0.6763 - val_loss: 0.6266 - val_accuracy: 0.6500\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6071 - accuracy: 0.6771 - val_loss: 0.6269 - val_accuracy: 0.6474\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6055 - accuracy: 0.6787 - val_loss: 0.6258 - val_accuracy: 0.6481\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6040 - accuracy: 0.6797 - val_loss: 0.6232 - val_accuracy: 0.6506\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6014 - accuracy: 0.6843 - val_loss: 0.6242 - val_accuracy: 0.6482\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6001 - accuracy: 0.6850 - val_loss: 0.6214 - val_accuracy: 0.6516\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.5979 - accuracy: 0.6865 - val_loss: 0.6248 - val_accuracy: 0.6447\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5969 - accuracy: 0.6880 - val_loss: 0.6170 - val_accuracy: 0.6548\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5947 - accuracy: 0.6892 - val_loss: 0.6213 - val_accuracy: 0.6491\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.5947 - accuracy: 0.6887 - val_loss: 0.6179 - val_accuracy: 0.6514\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5928 - accuracy: 0.6917 - val_loss: 0.6191 - val_accuracy: 0.6491\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5915 - accuracy: 0.6925 - val_loss: 0.6171 - val_accuracy: 0.6501\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5896 - accuracy: 0.6946 - val_loss: 0.6149 - val_accuracy: 0.6527\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5877 - accuracy: 0.6956 - val_loss: 0.6135 - val_accuracy: 0.6543\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.7121 - accuracy: 0.5255 - val_loss: 0.6872 - val_accuracy: 0.5236\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6884 - accuracy: 0.5576 - val_loss: 0.6870 - val_accuracy: 0.5306\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6801 - accuracy: 0.5712 - val_loss: 0.6815 - val_accuracy: 0.5500\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6739 - accuracy: 0.5836 - val_loss: 0.6812 - val_accuracy: 0.5520\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6684 - accuracy: 0.5927 - val_loss: 0.6753 - val_accuracy: 0.5748\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6640 - accuracy: 0.6036 - val_loss: 0.6689 - val_accuracy: 0.5871\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6584 - accuracy: 0.6150 - val_loss: 0.6653 - val_accuracy: 0.5935\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6541 - accuracy: 0.6210 - val_loss: 0.6654 - val_accuracy: 0.5943\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.6488 - accuracy: 0.6264 - val_loss: 0.6594 - val_accuracy: 0.6054\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6457 - accuracy: 0.6305 - val_loss: 0.6611 - val_accuracy: 0.6002\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6431 - accuracy: 0.6382 - val_loss: 0.6559 - val_accuracy: 0.6058\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 427us/step - loss: 0.6401 - accuracy: 0.6402 - val_loss: 0.6490 - val_accuracy: 0.6150\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6361 - accuracy: 0.6460 - val_loss: 0.6476 - val_accuracy: 0.6142\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 428us/step - loss: 0.6340 - accuracy: 0.6480 - val_loss: 0.6453 - val_accuracy: 0.6165\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6308 - accuracy: 0.6548 - val_loss: 0.6481 - val_accuracy: 0.6115\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6279 - accuracy: 0.6570 - val_loss: 0.6393 - val_accuracy: 0.6205\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 429us/step - loss: 0.6242 - accuracy: 0.6604 - val_loss: 0.6435 - val_accuracy: 0.6153\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6225 - accuracy: 0.6626 - val_loss: 0.6417 - val_accuracy: 0.6155\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6204 - accuracy: 0.6660 - val_loss: 0.6381 - val_accuracy: 0.6172\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6172 - accuracy: 0.6694 - val_loss: 0.6359 - val_accuracy: 0.6165\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6149 - accuracy: 0.6705 - val_loss: 0.6367 - val_accuracy: 0.6148\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6123 - accuracy: 0.6727 - val_loss: 0.6329 - val_accuracy: 0.6163\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6099 - accuracy: 0.6765 - val_loss: 0.6323 - val_accuracy: 0.6171\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6078 - accuracy: 0.6752 - val_loss: 0.6238 - val_accuracy: 0.6273\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6055 - accuracy: 0.6796 - val_loss: 0.6276 - val_accuracy: 0.6238\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6040 - accuracy: 0.6811 - val_loss: 0.6208 - val_accuracy: 0.6344\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6020 - accuracy: 0.6839 - val_loss: 0.6261 - val_accuracy: 0.6274\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 431us/step - loss: 0.5999 - accuracy: 0.6851 - val_loss: 0.6175 - val_accuracy: 0.6380\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 458us/step - loss: 0.5980 - accuracy: 0.6859 - val_loss: 0.6131 - val_accuracy: 0.6415\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5966 - accuracy: 0.6885 - val_loss: 0.6156 - val_accuracy: 0.6391\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.5938 - accuracy: 0.6907 - val_loss: 0.6225 - val_accuracy: 0.6324\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5919 - accuracy: 0.6920 - val_loss: 0.6218 - val_accuracy: 0.6322\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5899 - accuracy: 0.6934 - val_loss: 0.6077 - val_accuracy: 0.6456\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5882 - accuracy: 0.6945 - val_loss: 0.6197 - val_accuracy: 0.6346\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5882 - accuracy: 0.6959 - val_loss: 0.6211 - val_accuracy: 0.6322\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5860 - accuracy: 0.6958 - val_loss: 0.6079 - val_accuracy: 0.6424\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5844 - accuracy: 0.6985 - val_loss: 0.6110 - val_accuracy: 0.6403\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.5826 - accuracy: 0.6994 - val_loss: 0.6117 - val_accuracy: 0.6395\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.5812 - accuracy: 0.6981 - val_loss: 0.6152 - val_accuracy: 0.6374\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5784 - accuracy: 0.7033 - val_loss: 0.6152 - val_accuracy: 0.6373\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5774 - accuracy: 0.7017 - val_loss: 0.6054 - val_accuracy: 0.6468\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.5762 - accuracy: 0.7040 - val_loss: 0.6065 - val_accuracy: 0.6465\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5760 - accuracy: 0.7058 - val_loss: 0.6060 - val_accuracy: 0.6471\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.5723 - accuracy: 0.7079 - val_loss: 0.6041 - val_accuracy: 0.6480\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5729 - accuracy: 0.7058 - val_loss: 0.6076 - val_accuracy: 0.6455\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.5707 - accuracy: 0.7074 - val_loss: 0.6148 - val_accuracy: 0.6394\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.5696 - accuracy: 0.7091 - val_loss: 0.6098 - val_accuracy: 0.6438\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5674 - accuracy: 0.7109 - val_loss: 0.6117 - val_accuracy: 0.6409\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.5659 - accuracy: 0.7118 - val_loss: 0.6056 - val_accuracy: 0.6481\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5654 - accuracy: 0.7117 - val_loss: 0.6050 - val_accuracy: 0.6479\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6944 - accuracy: 0.5412 - val_loss: 0.7212 - val_accuracy: 0.3754\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6866 - accuracy: 0.5549 - val_loss: 0.7065 - val_accuracy: 0.4557\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6821 - accuracy: 0.5631 - val_loss: 0.7025 - val_accuracy: 0.4736\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6788 - accuracy: 0.5698 - val_loss: 0.7013 - val_accuracy: 0.4814\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6758 - accuracy: 0.5833 - val_loss: 0.6962 - val_accuracy: 0.5015\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6721 - accuracy: 0.5916 - val_loss: 0.6894 - val_accuracy: 0.5186\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6682 - accuracy: 0.6032 - val_loss: 0.6903 - val_accuracy: 0.5180\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6648 - accuracy: 0.6120 - val_loss: 0.6871 - val_accuracy: 0.5259\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6615 - accuracy: 0.6169 - val_loss: 0.6839 - val_accuracy: 0.5317\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6606 - accuracy: 0.6186 - val_loss: 0.6828 - val_accuracy: 0.5326\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6571 - accuracy: 0.6283 - val_loss: 0.6790 - val_accuracy: 0.5381\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6548 - accuracy: 0.6309 - val_loss: 0.6796 - val_accuracy: 0.5374\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6527 - accuracy: 0.6340 - val_loss: 0.6746 - val_accuracy: 0.5521\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6502 - accuracy: 0.6399 - val_loss: 0.6741 - val_accuracy: 0.5523\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6472 - accuracy: 0.6446 - val_loss: 0.6715 - val_accuracy: 0.5601\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6457 - accuracy: 0.6451 - val_loss: 0.6712 - val_accuracy: 0.5598\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6428 - accuracy: 0.6509 - val_loss: 0.6693 - val_accuracy: 0.5650\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6408 - accuracy: 0.6545 - val_loss: 0.6650 - val_accuracy: 0.5737\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6378 - accuracy: 0.6583 - val_loss: 0.6607 - val_accuracy: 0.5829\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6356 - accuracy: 0.6623 - val_loss: 0.6624 - val_accuracy: 0.5780\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6327 - accuracy: 0.6657 - val_loss: 0.6595 - val_accuracy: 0.5816\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6308 - accuracy: 0.6649 - val_loss: 0.6572 - val_accuracy: 0.5844\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6282 - accuracy: 0.6710 - val_loss: 0.6570 - val_accuracy: 0.5831\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6258 - accuracy: 0.6725 - val_loss: 0.6510 - val_accuracy: 0.5926\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6238 - accuracy: 0.6753 - val_loss: 0.6548 - val_accuracy: 0.5849\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6216 - accuracy: 0.6755 - val_loss: 0.6479 - val_accuracy: 0.5939\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6188 - accuracy: 0.6807 - val_loss: 0.6501 - val_accuracy: 0.5905\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6169 - accuracy: 0.6805 - val_loss: 0.6470 - val_accuracy: 0.5937\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6142 - accuracy: 0.6813 - val_loss: 0.6442 - val_accuracy: 0.5971\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6120 - accuracy: 0.6850 - val_loss: 0.6430 - val_accuracy: 0.5985\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6099 - accuracy: 0.6851 - val_loss: 0.6431 - val_accuracy: 0.5976\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6085 - accuracy: 0.6866 - val_loss: 0.6392 - val_accuracy: 0.6023\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6065 - accuracy: 0.6894 - val_loss: 0.6359 - val_accuracy: 0.6073\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6032 - accuracy: 0.6909 - val_loss: 0.6351 - val_accuracy: 0.6084\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6027 - accuracy: 0.6893 - val_loss: 0.6300 - val_accuracy: 0.6124\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5998 - accuracy: 0.6925 - val_loss: 0.6339 - val_accuracy: 0.6083\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5988 - accuracy: 0.6929 - val_loss: 0.6338 - val_accuracy: 0.6068\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5969 - accuracy: 0.6950 - val_loss: 0.6345 - val_accuracy: 0.6049\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5958 - accuracy: 0.6950 - val_loss: 0.6300 - val_accuracy: 0.6071\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5925 - accuracy: 0.6983 - val_loss: 0.6223 - val_accuracy: 0.6156\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5911 - accuracy: 0.6993 - val_loss: 0.6264 - val_accuracy: 0.6096\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.5894 - accuracy: 0.6995 - val_loss: 0.6208 - val_accuracy: 0.6200\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5876 - accuracy: 0.7005 - val_loss: 0.6229 - val_accuracy: 0.6165\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5867 - accuracy: 0.7002 - val_loss: 0.6233 - val_accuracy: 0.6177\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5847 - accuracy: 0.7034 - val_loss: 0.6241 - val_accuracy: 0.6173\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5832 - accuracy: 0.7027 - val_loss: 0.6187 - val_accuracy: 0.6217\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5822 - accuracy: 0.7036 - val_loss: 0.6168 - val_accuracy: 0.6231\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5798 - accuracy: 0.7043 - val_loss: 0.6110 - val_accuracy: 0.6304\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5788 - accuracy: 0.7073 - val_loss: 0.6205 - val_accuracy: 0.6203\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5772 - accuracy: 0.7064 - val_loss: 0.6172 - val_accuracy: 0.6221\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.7064 - accuracy: 0.5209 - val_loss: 0.6596 - val_accuracy: 0.6888\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6774 - accuracy: 0.5792 - val_loss: 0.6951 - val_accuracy: 0.4997\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6742 - accuracy: 0.5928 - val_loss: 0.6998 - val_accuracy: 0.4881\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6703 - accuracy: 0.6017 - val_loss: 0.6959 - val_accuracy: 0.5120\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6680 - accuracy: 0.6102 - val_loss: 0.6941 - val_accuracy: 0.5208\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6637 - accuracy: 0.6245 - val_loss: 0.6911 - val_accuracy: 0.5308\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6613 - accuracy: 0.6278 - val_loss: 0.6868 - val_accuracy: 0.5435\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6592 - accuracy: 0.6331 - val_loss: 0.6871 - val_accuracy: 0.5425\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6570 - accuracy: 0.6376 - val_loss: 0.6830 - val_accuracy: 0.5509\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6534 - accuracy: 0.6455 - val_loss: 0.6829 - val_accuracy: 0.5497\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6507 - accuracy: 0.6497 - val_loss: 0.6818 - val_accuracy: 0.5523\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6492 - accuracy: 0.6513 - val_loss: 0.6779 - val_accuracy: 0.5563\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6461 - accuracy: 0.6565 - val_loss: 0.6737 - val_accuracy: 0.5639\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6443 - accuracy: 0.6573 - val_loss: 0.6709 - val_accuracy: 0.5705\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6421 - accuracy: 0.6603 - val_loss: 0.6699 - val_accuracy: 0.5747\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6398 - accuracy: 0.6644 - val_loss: 0.6644 - val_accuracy: 0.5816\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6375 - accuracy: 0.6645 - val_loss: 0.6674 - val_accuracy: 0.5765\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6346 - accuracy: 0.6688 - val_loss: 0.6652 - val_accuracy: 0.5791\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6321 - accuracy: 0.6708 - val_loss: 0.6634 - val_accuracy: 0.5847\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6298 - accuracy: 0.6741 - val_loss: 0.6599 - val_accuracy: 0.5910\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6265 - accuracy: 0.6756 - val_loss: 0.6595 - val_accuracy: 0.5914\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6254 - accuracy: 0.6763 - val_loss: 0.6519 - val_accuracy: 0.5999\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6227 - accuracy: 0.6768 - val_loss: 0.6523 - val_accuracy: 0.5991\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6206 - accuracy: 0.6808 - val_loss: 0.6505 - val_accuracy: 0.5999\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6178 - accuracy: 0.6821 - val_loss: 0.6484 - val_accuracy: 0.6039\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6163 - accuracy: 0.6835 - val_loss: 0.6471 - val_accuracy: 0.6061\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6137 - accuracy: 0.6857 - val_loss: 0.6439 - val_accuracy: 0.6107\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6121 - accuracy: 0.6862 - val_loss: 0.6410 - val_accuracy: 0.6127\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6099 - accuracy: 0.6888 - val_loss: 0.6395 - val_accuracy: 0.6128\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6078 - accuracy: 0.6872 - val_loss: 0.6415 - val_accuracy: 0.6107\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6054 - accuracy: 0.6908 - val_loss: 0.6386 - val_accuracy: 0.6123\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6040 - accuracy: 0.6912 - val_loss: 0.6356 - val_accuracy: 0.6165\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6017 - accuracy: 0.6935 - val_loss: 0.6297 - val_accuracy: 0.6235\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6015 - accuracy: 0.6922 - val_loss: 0.6323 - val_accuracy: 0.6200\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5990 - accuracy: 0.6950 - val_loss: 0.6310 - val_accuracy: 0.6214\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5973 - accuracy: 0.6956 - val_loss: 0.6335 - val_accuracy: 0.6178\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 455us/step - loss: 0.5948 - accuracy: 0.6985 - val_loss: 0.6266 - val_accuracy: 0.6266\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5933 - accuracy: 0.6982 - val_loss: 0.6280 - val_accuracy: 0.6237\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5925 - accuracy: 0.6997 - val_loss: 0.6273 - val_accuracy: 0.6245\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5901 - accuracy: 0.6999 - val_loss: 0.6244 - val_accuracy: 0.6278\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.5876 - accuracy: 0.7028 - val_loss: 0.6239 - val_accuracy: 0.6280\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 430us/step - loss: 0.5865 - accuracy: 0.7034 - val_loss: 0.6226 - val_accuracy: 0.6294\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.5865 - accuracy: 0.7035 - val_loss: 0.6156 - val_accuracy: 0.6386\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.5843 - accuracy: 0.7052 - val_loss: 0.6172 - val_accuracy: 0.6361\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5824 - accuracy: 0.7066 - val_loss: 0.6202 - val_accuracy: 0.6332\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 432us/step - loss: 0.5818 - accuracy: 0.7067 - val_loss: 0.6230 - val_accuracy: 0.6270\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5807 - accuracy: 0.7053 - val_loss: 0.6202 - val_accuracy: 0.6311\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 426us/step - loss: 0.5784 - accuracy: 0.7079 - val_loss: 0.6181 - val_accuracy: 0.6320\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5773 - accuracy: 0.7082 - val_loss: 0.6177 - val_accuracy: 0.6321\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.5756 - accuracy: 0.7106 - val_loss: 0.6128 - val_accuracy: 0.6371\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.7105 - accuracy: 0.5154 - val_loss: 0.7174 - val_accuracy: 0.4477\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6943 - accuracy: 0.5435 - val_loss: 0.7045 - val_accuracy: 0.5264\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6824 - accuracy: 0.5674 - val_loss: 0.6911 - val_accuracy: 0.5687\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 453us/step - loss: 0.6762 - accuracy: 0.5769 - val_loss: 0.6903 - val_accuracy: 0.5745\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6682 - accuracy: 0.5935 - val_loss: 0.6821 - val_accuracy: 0.5908\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6645 - accuracy: 0.6001 - val_loss: 0.6791 - val_accuracy: 0.5996\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6603 - accuracy: 0.6064 - val_loss: 0.6752 - val_accuracy: 0.6091\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6558 - accuracy: 0.6150 - val_loss: 0.6745 - val_accuracy: 0.6106\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6518 - accuracy: 0.6231 - val_loss: 0.6685 - val_accuracy: 0.6184\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6484 - accuracy: 0.6259 - val_loss: 0.6702 - val_accuracy: 0.6151\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6446 - accuracy: 0.6306 - val_loss: 0.6678 - val_accuracy: 0.6177\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6421 - accuracy: 0.6359 - val_loss: 0.6623 - val_accuracy: 0.6253\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6385 - accuracy: 0.6399 - val_loss: 0.6593 - val_accuracy: 0.6284\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6349 - accuracy: 0.6457 - val_loss: 0.6560 - val_accuracy: 0.6329\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6332 - accuracy: 0.6466 - val_loss: 0.6556 - val_accuracy: 0.6334\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6304 - accuracy: 0.6508 - val_loss: 0.6555 - val_accuracy: 0.6344\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6266 - accuracy: 0.6515 - val_loss: 0.6516 - val_accuracy: 0.6381\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6248 - accuracy: 0.6569 - val_loss: 0.6469 - val_accuracy: 0.6440\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6225 - accuracy: 0.6587 - val_loss: 0.6476 - val_accuracy: 0.6424\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6202 - accuracy: 0.6644 - val_loss: 0.6485 - val_accuracy: 0.6382\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6186 - accuracy: 0.6627 - val_loss: 0.6435 - val_accuracy: 0.6449\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6152 - accuracy: 0.6664 - val_loss: 0.6424 - val_accuracy: 0.6445\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6127 - accuracy: 0.6709 - val_loss: 0.6463 - val_accuracy: 0.6382\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6114 - accuracy: 0.6734 - val_loss: 0.6393 - val_accuracy: 0.6459\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6086 - accuracy: 0.6754 - val_loss: 0.6352 - val_accuracy: 0.6485\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6074 - accuracy: 0.6740 - val_loss: 0.6335 - val_accuracy: 0.6504\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6040 - accuracy: 0.6769 - val_loss: 0.6278 - val_accuracy: 0.6572\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6023 - accuracy: 0.6785 - val_loss: 0.6307 - val_accuracy: 0.6528\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6007 - accuracy: 0.6815 - val_loss: 0.6293 - val_accuracy: 0.6538\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.5966 - accuracy: 0.6857 - val_loss: 0.6272 - val_accuracy: 0.6569\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5963 - accuracy: 0.6854 - val_loss: 0.6244 - val_accuracy: 0.6614\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.5948 - accuracy: 0.6857 - val_loss: 0.6252 - val_accuracy: 0.6592\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5929 - accuracy: 0.6868 - val_loss: 0.6226 - val_accuracy: 0.6625\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5912 - accuracy: 0.6890 - val_loss: 0.6218 - val_accuracy: 0.6627\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.5879 - accuracy: 0.6941 - val_loss: 0.6217 - val_accuracy: 0.6605\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.5865 - accuracy: 0.6941 - val_loss: 0.6166 - val_accuracy: 0.6683\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5860 - accuracy: 0.6935 - val_loss: 0.6153 - val_accuracy: 0.6689\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5837 - accuracy: 0.6937 - val_loss: 0.6188 - val_accuracy: 0.6613\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5816 - accuracy: 0.6985 - val_loss: 0.6162 - val_accuracy: 0.6638\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 465us/step - loss: 0.5799 - accuracy: 0.7001 - val_loss: 0.6130 - val_accuracy: 0.6676\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.5780 - accuracy: 0.6993 - val_loss: 0.6148 - val_accuracy: 0.6635\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5771 - accuracy: 0.7014 - val_loss: 0.6139 - val_accuracy: 0.6637\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.5743 - accuracy: 0.7027 - val_loss: 0.6156 - val_accuracy: 0.6603\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5723 - accuracy: 0.7041 - val_loss: 0.6185 - val_accuracy: 0.6543\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5710 - accuracy: 0.7069 - val_loss: 0.6144 - val_accuracy: 0.6590\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.5706 - accuracy: 0.7062 - val_loss: 0.6124 - val_accuracy: 0.6606\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5685 - accuracy: 0.7083 - val_loss: 0.6181 - val_accuracy: 0.6528\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5669 - accuracy: 0.7097 - val_loss: 0.6163 - val_accuracy: 0.6535\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5651 - accuracy: 0.7108 - val_loss: 0.6134 - val_accuracy: 0.6559\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.5632 - accuracy: 0.7127 - val_loss: 0.6096 - val_accuracy: 0.6593\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.7172 - accuracy: 0.5289 - val_loss: 0.7478 - val_accuracy: 0.3585\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6818 - accuracy: 0.5587 - val_loss: 0.7010 - val_accuracy: 0.5087\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6769 - accuracy: 0.5684 - val_loss: 0.6906 - val_accuracy: 0.5433\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6718 - accuracy: 0.5797 - val_loss: 0.6874 - val_accuracy: 0.5500\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6682 - accuracy: 0.5908 - val_loss: 0.6797 - val_accuracy: 0.5713\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 434us/step - loss: 0.6642 - accuracy: 0.5965 - val_loss: 0.6815 - val_accuracy: 0.5659\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6610 - accuracy: 0.6049 - val_loss: 0.6769 - val_accuracy: 0.5780\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6581 - accuracy: 0.6074 - val_loss: 0.6740 - val_accuracy: 0.5865\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6545 - accuracy: 0.6190 - val_loss: 0.6681 - val_accuracy: 0.6054\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6525 - accuracy: 0.6193 - val_loss: 0.6705 - val_accuracy: 0.6005\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6500 - accuracy: 0.6274 - val_loss: 0.6687 - val_accuracy: 0.6064\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6466 - accuracy: 0.6317 - val_loss: 0.6668 - val_accuracy: 0.6089\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6438 - accuracy: 0.6370 - val_loss: 0.6609 - val_accuracy: 0.6214\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6424 - accuracy: 0.6378 - val_loss: 0.6619 - val_accuracy: 0.6199\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6388 - accuracy: 0.6438 - val_loss: 0.6589 - val_accuracy: 0.6234\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6373 - accuracy: 0.6462 - val_loss: 0.6584 - val_accuracy: 0.6228\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6338 - accuracy: 0.6488 - val_loss: 0.6517 - val_accuracy: 0.6298\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6328 - accuracy: 0.6512 - val_loss: 0.6533 - val_accuracy: 0.6271\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.6295 - accuracy: 0.6568 - val_loss: 0.6478 - val_accuracy: 0.6322\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6270 - accuracy: 0.6603 - val_loss: 0.6508 - val_accuracy: 0.6287\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6259 - accuracy: 0.6601 - val_loss: 0.6517 - val_accuracy: 0.6246\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6224 - accuracy: 0.6637 - val_loss: 0.6489 - val_accuracy: 0.6272\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 439us/step - loss: 0.6207 - accuracy: 0.6688 - val_loss: 0.6438 - val_accuracy: 0.6319\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6178 - accuracy: 0.6693 - val_loss: 0.6462 - val_accuracy: 0.6268\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6160 - accuracy: 0.6727 - val_loss: 0.6410 - val_accuracy: 0.6329\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6137 - accuracy: 0.6748 - val_loss: 0.6373 - val_accuracy: 0.6352\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6122 - accuracy: 0.6753 - val_loss: 0.6403 - val_accuracy: 0.6314\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6098 - accuracy: 0.6780 - val_loss: 0.6360 - val_accuracy: 0.6357\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6085 - accuracy: 0.6779 - val_loss: 0.6341 - val_accuracy: 0.6368\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 435us/step - loss: 0.6057 - accuracy: 0.6821 - val_loss: 0.6330 - val_accuracy: 0.6374\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6040 - accuracy: 0.6820 - val_loss: 0.6300 - val_accuracy: 0.6399\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 438us/step - loss: 0.6017 - accuracy: 0.6865 - val_loss: 0.6226 - val_accuracy: 0.6490\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5996 - accuracy: 0.6868 - val_loss: 0.6244 - val_accuracy: 0.6467\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5983 - accuracy: 0.6886 - val_loss: 0.6289 - val_accuracy: 0.6405\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.5971 - accuracy: 0.6903 - val_loss: 0.6251 - val_accuracy: 0.6447\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5937 - accuracy: 0.6919 - val_loss: 0.6197 - val_accuracy: 0.6508\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5918 - accuracy: 0.6950 - val_loss: 0.6222 - val_accuracy: 0.6457\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.5896 - accuracy: 0.6981 - val_loss: 0.6235 - val_accuracy: 0.6428\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5880 - accuracy: 0.6973 - val_loss: 0.6226 - val_accuracy: 0.6428\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5866 - accuracy: 0.6970 - val_loss: 0.6211 - val_accuracy: 0.6434\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.5843 - accuracy: 0.7011 - val_loss: 0.6277 - val_accuracy: 0.6324\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5832 - accuracy: 0.7018 - val_loss: 0.6168 - val_accuracy: 0.6470\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5814 - accuracy: 0.7047 - val_loss: 0.6172 - val_accuracy: 0.6464\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5790 - accuracy: 0.7055 - val_loss: 0.6152 - val_accuracy: 0.6480\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.5777 - accuracy: 0.7051 - val_loss: 0.6167 - val_accuracy: 0.6454\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5760 - accuracy: 0.7073 - val_loss: 0.6124 - val_accuracy: 0.6509\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.5748 - accuracy: 0.7090 - val_loss: 0.6101 - val_accuracy: 0.6534\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 447us/step - loss: 0.5734 - accuracy: 0.7102 - val_loss: 0.6061 - val_accuracy: 0.6590\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5714 - accuracy: 0.7113 - val_loss: 0.6137 - val_accuracy: 0.6477\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5690 - accuracy: 0.7141 - val_loss: 0.6079 - val_accuracy: 0.6548\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.7108 - accuracy: 0.4911 - val_loss: 0.7023 - val_accuracy: 0.4447\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.7006 - accuracy: 0.5099 - val_loss: 0.7157 - val_accuracy: 0.3520\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6937 - accuracy: 0.5335 - val_loss: 0.7106 - val_accuracy: 0.3957\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6884 - accuracy: 0.5449 - val_loss: 0.7090 - val_accuracy: 0.4084\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6841 - accuracy: 0.5589 - val_loss: 0.7067 - val_accuracy: 0.4301\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6807 - accuracy: 0.5694 - val_loss: 0.7004 - val_accuracy: 0.4793\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6771 - accuracy: 0.5802 - val_loss: 0.6974 - val_accuracy: 0.5001\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6729 - accuracy: 0.5932 - val_loss: 0.6971 - val_accuracy: 0.5054\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6705 - accuracy: 0.5983 - val_loss: 0.6955 - val_accuracy: 0.5138\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6655 - accuracy: 0.6089 - val_loss: 0.6927 - val_accuracy: 0.5212\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6634 - accuracy: 0.6140 - val_loss: 0.6895 - val_accuracy: 0.5294\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6591 - accuracy: 0.6257 - val_loss: 0.6843 - val_accuracy: 0.5501\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6570 - accuracy: 0.6286 - val_loss: 0.6853 - val_accuracy: 0.5454\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6531 - accuracy: 0.6361 - val_loss: 0.6781 - val_accuracy: 0.5639\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6502 - accuracy: 0.6416 - val_loss: 0.6786 - val_accuracy: 0.5619\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6468 - accuracy: 0.6460 - val_loss: 0.6750 - val_accuracy: 0.5785\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.6442 - accuracy: 0.6475 - val_loss: 0.6726 - val_accuracy: 0.5868\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.6413 - accuracy: 0.6544 - val_loss: 0.6711 - val_accuracy: 0.5903\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6385 - accuracy: 0.6573 - val_loss: 0.6695 - val_accuracy: 0.5943\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6358 - accuracy: 0.6609 - val_loss: 0.6694 - val_accuracy: 0.5925\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6338 - accuracy: 0.6623 - val_loss: 0.6645 - val_accuracy: 0.6021\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6313 - accuracy: 0.6664 - val_loss: 0.6651 - val_accuracy: 0.5990\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6288 - accuracy: 0.6693 - val_loss: 0.6644 - val_accuracy: 0.5989\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6258 - accuracy: 0.6711 - val_loss: 0.6603 - val_accuracy: 0.6056\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6243 - accuracy: 0.6720 - val_loss: 0.6560 - val_accuracy: 0.6096\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6219 - accuracy: 0.6749 - val_loss: 0.6557 - val_accuracy: 0.6090\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6195 - accuracy: 0.6808 - val_loss: 0.6519 - val_accuracy: 0.6137\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6171 - accuracy: 0.6811 - val_loss: 0.6486 - val_accuracy: 0.6171\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6153 - accuracy: 0.6819 - val_loss: 0.6526 - val_accuracy: 0.6102\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6122 - accuracy: 0.6836 - val_loss: 0.6477 - val_accuracy: 0.6145\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6109 - accuracy: 0.6850 - val_loss: 0.6456 - val_accuracy: 0.6168\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6096 - accuracy: 0.6862 - val_loss: 0.6490 - val_accuracy: 0.6142\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6077 - accuracy: 0.6885 - val_loss: 0.6456 - val_accuracy: 0.6174\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6053 - accuracy: 0.6900 - val_loss: 0.6463 - val_accuracy: 0.6167\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6037 - accuracy: 0.6888 - val_loss: 0.6444 - val_accuracy: 0.6186\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6017 - accuracy: 0.6919 - val_loss: 0.6404 - val_accuracy: 0.6230\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6001 - accuracy: 0.6926 - val_loss: 0.6338 - val_accuracy: 0.6297\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5982 - accuracy: 0.6948 - val_loss: 0.6381 - val_accuracy: 0.6263\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5959 - accuracy: 0.6949 - val_loss: 0.6349 - val_accuracy: 0.6283\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5951 - accuracy: 0.6950 - val_loss: 0.6355 - val_accuracy: 0.6280\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5931 - accuracy: 0.6976 - val_loss: 0.6319 - val_accuracy: 0.6299\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5922 - accuracy: 0.6971 - val_loss: 0.6353 - val_accuracy: 0.6283\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5896 - accuracy: 0.7007 - val_loss: 0.6337 - val_accuracy: 0.6291\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5888 - accuracy: 0.7001 - val_loss: 0.6321 - val_accuracy: 0.6312\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5882 - accuracy: 0.6996 - val_loss: 0.6299 - val_accuracy: 0.6315\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5855 - accuracy: 0.7035 - val_loss: 0.6335 - val_accuracy: 0.6298\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5845 - accuracy: 0.7011 - val_loss: 0.6279 - val_accuracy: 0.6316\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.5831 - accuracy: 0.7043 - val_loss: 0.6310 - val_accuracy: 0.6300\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.5813 - accuracy: 0.7051 - val_loss: 0.6248 - val_accuracy: 0.6334\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5798 - accuracy: 0.7071 - val_loss: 0.6257 - val_accuracy: 0.6330\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.7035 - accuracy: 0.5193 - val_loss: 0.7182 - val_accuracy: 0.3435\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6856 - accuracy: 0.5508 - val_loss: 0.6885 - val_accuracy: 0.5263\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6756 - accuracy: 0.5746 - val_loss: 0.6847 - val_accuracy: 0.5746\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6680 - accuracy: 0.5924 - val_loss: 0.6763 - val_accuracy: 0.6035\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6582 - accuracy: 0.6142 - val_loss: 0.6690 - val_accuracy: 0.6157\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6510 - accuracy: 0.6299 - val_loss: 0.6645 - val_accuracy: 0.6165\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6450 - accuracy: 0.6406 - val_loss: 0.6567 - val_accuracy: 0.6269\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6401 - accuracy: 0.6463 - val_loss: 0.6552 - val_accuracy: 0.6265\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6355 - accuracy: 0.6518 - val_loss: 0.6417 - val_accuracy: 0.6528\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6302 - accuracy: 0.6589 - val_loss: 0.6431 - val_accuracy: 0.6408\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6259 - accuracy: 0.6639 - val_loss: 0.6432 - val_accuracy: 0.6372\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6219 - accuracy: 0.6683 - val_loss: 0.6385 - val_accuracy: 0.6409\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6176 - accuracy: 0.6726 - val_loss: 0.6295 - val_accuracy: 0.6555\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6153 - accuracy: 0.6737 - val_loss: 0.6256 - val_accuracy: 0.6595\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6124 - accuracy: 0.6764 - val_loss: 0.6265 - val_accuracy: 0.6528\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6094 - accuracy: 0.6786 - val_loss: 0.6243 - val_accuracy: 0.6537\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6066 - accuracy: 0.6806 - val_loss: 0.6221 - val_accuracy: 0.6545\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6037 - accuracy: 0.6828 - val_loss: 0.6187 - val_accuracy: 0.6565\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6007 - accuracy: 0.6894 - val_loss: 0.6184 - val_accuracy: 0.6541\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5970 - accuracy: 0.6906 - val_loss: 0.6197 - val_accuracy: 0.6497\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.5940 - accuracy: 0.6928 - val_loss: 0.6096 - val_accuracy: 0.6627\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.5910 - accuracy: 0.6948 - val_loss: 0.6090 - val_accuracy: 0.6617\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5888 - accuracy: 0.6965 - val_loss: 0.6056 - val_accuracy: 0.6636\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5864 - accuracy: 0.6981 - val_loss: 0.6112 - val_accuracy: 0.6551\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5837 - accuracy: 0.6998 - val_loss: 0.6032 - val_accuracy: 0.6639\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5828 - accuracy: 0.7018 - val_loss: 0.6103 - val_accuracy: 0.6517\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.5802 - accuracy: 0.7050 - val_loss: 0.6027 - val_accuracy: 0.6598\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5785 - accuracy: 0.7066 - val_loss: 0.6026 - val_accuracy: 0.6576\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5768 - accuracy: 0.7082 - val_loss: 0.5987 - val_accuracy: 0.6610\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5740 - accuracy: 0.7088 - val_loss: 0.5970 - val_accuracy: 0.6616\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5731 - accuracy: 0.7098 - val_loss: 0.5986 - val_accuracy: 0.6574\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5712 - accuracy: 0.7117 - val_loss: 0.5972 - val_accuracy: 0.6582\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5700 - accuracy: 0.7150 - val_loss: 0.6070 - val_accuracy: 0.6465\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5680 - accuracy: 0.7143 - val_loss: 0.6004 - val_accuracy: 0.6522\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5673 - accuracy: 0.7164 - val_loss: 0.5986 - val_accuracy: 0.6532\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5651 - accuracy: 0.7186 - val_loss: 0.5958 - val_accuracy: 0.6555\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5642 - accuracy: 0.7170 - val_loss: 0.5899 - val_accuracy: 0.6615\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.5634 - accuracy: 0.7185 - val_loss: 0.5902 - val_accuracy: 0.6602\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5617 - accuracy: 0.7191 - val_loss: 0.5960 - val_accuracy: 0.6545\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5601 - accuracy: 0.7214 - val_loss: 0.5972 - val_accuracy: 0.6522\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5588 - accuracy: 0.7225 - val_loss: 0.5941 - val_accuracy: 0.6553\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5581 - accuracy: 0.7225 - val_loss: 0.5997 - val_accuracy: 0.6500\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5554 - accuracy: 0.7240 - val_loss: 0.5900 - val_accuracy: 0.6581\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5543 - accuracy: 0.7263 - val_loss: 0.5917 - val_accuracy: 0.6560\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5530 - accuracy: 0.7261 - val_loss: 0.5945 - val_accuracy: 0.6523\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5529 - accuracy: 0.7263 - val_loss: 0.5889 - val_accuracy: 0.6580\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5520 - accuracy: 0.7268 - val_loss: 0.5898 - val_accuracy: 0.6562\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5501 - accuracy: 0.7275 - val_loss: 0.5956 - val_accuracy: 0.6516\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5492 - accuracy: 0.7287 - val_loss: 0.5967 - val_accuracy: 0.6506\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5478 - accuracy: 0.7314 - val_loss: 0.5927 - val_accuracy: 0.6533\n",
      "\n",
      "Training model with noise_multiplier=2.0...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.0 iterated over 83600 steps satisfies differential privacy with eps = 0.449 and delta = 1e-05.\n",
      "The optimal RDP order is 53.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.7092 - accuracy: 0.5027 - val_loss: 0.7064 - val_accuracy: 0.3849\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6923 - accuracy: 0.5384 - val_loss: 0.7177 - val_accuracy: 0.3567\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6856 - accuracy: 0.5576 - val_loss: 0.7111 - val_accuracy: 0.4265\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6805 - accuracy: 0.5701 - val_loss: 0.7079 - val_accuracy: 0.4543\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6757 - accuracy: 0.5841 - val_loss: 0.7031 - val_accuracy: 0.4745\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6718 - accuracy: 0.5918 - val_loss: 0.6990 - val_accuracy: 0.4959\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6686 - accuracy: 0.6032 - val_loss: 0.6911 - val_accuracy: 0.5257\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 433us/step - loss: 0.6663 - accuracy: 0.6071 - val_loss: 0.6907 - val_accuracy: 0.5286\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6626 - accuracy: 0.6170 - val_loss: 0.6855 - val_accuracy: 0.5479\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6596 - accuracy: 0.6200 - val_loss: 0.6803 - val_accuracy: 0.5611\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.6573 - accuracy: 0.6261 - val_loss: 0.6851 - val_accuracy: 0.5477\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6542 - accuracy: 0.6321 - val_loss: 0.6777 - val_accuracy: 0.5668\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6527 - accuracy: 0.6323 - val_loss: 0.6776 - val_accuracy: 0.5660\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6501 - accuracy: 0.6396 - val_loss: 0.6730 - val_accuracy: 0.5761\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6484 - accuracy: 0.6392 - val_loss: 0.6743 - val_accuracy: 0.5730\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 448us/step - loss: 0.6459 - accuracy: 0.6436 - val_loss: 0.6721 - val_accuracy: 0.5786\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6436 - accuracy: 0.6458 - val_loss: 0.6665 - val_accuracy: 0.5883\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6414 - accuracy: 0.6489 - val_loss: 0.6665 - val_accuracy: 0.5874\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6397 - accuracy: 0.6506 - val_loss: 0.6669 - val_accuracy: 0.5862\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.6369 - accuracy: 0.6536 - val_loss: 0.6664 - val_accuracy: 0.5861\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6356 - accuracy: 0.6546 - val_loss: 0.6580 - val_accuracy: 0.5998\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6327 - accuracy: 0.6594 - val_loss: 0.6591 - val_accuracy: 0.5977\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 440us/step - loss: 0.6321 - accuracy: 0.6602 - val_loss: 0.6598 - val_accuracy: 0.5959\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6301 - accuracy: 0.6609 - val_loss: 0.6539 - val_accuracy: 0.6039\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6276 - accuracy: 0.6634 - val_loss: 0.6542 - val_accuracy: 0.6030\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6259 - accuracy: 0.6621 - val_loss: 0.6477 - val_accuracy: 0.6119\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6229 - accuracy: 0.6684 - val_loss: 0.6507 - val_accuracy: 0.6062\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 437us/step - loss: 0.6221 - accuracy: 0.6703 - val_loss: 0.6527 - val_accuracy: 0.6035\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6199 - accuracy: 0.6696 - val_loss: 0.6488 - val_accuracy: 0.6084\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6183 - accuracy: 0.6711 - val_loss: 0.6441 - val_accuracy: 0.6132\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6167 - accuracy: 0.6740 - val_loss: 0.6514 - val_accuracy: 0.6032\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6151 - accuracy: 0.6716 - val_loss: 0.6413 - val_accuracy: 0.6147\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6131 - accuracy: 0.6749 - val_loss: 0.6425 - val_accuracy: 0.6127\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6102 - accuracy: 0.6777 - val_loss: 0.6398 - val_accuracy: 0.6186\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6095 - accuracy: 0.6785 - val_loss: 0.6372 - val_accuracy: 0.6198\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6071 - accuracy: 0.6800 - val_loss: 0.6357 - val_accuracy: 0.6210\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6061 - accuracy: 0.6796 - val_loss: 0.6382 - val_accuracy: 0.6175\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6050 - accuracy: 0.6806 - val_loss: 0.6344 - val_accuracy: 0.6211\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6035 - accuracy: 0.6829 - val_loss: 0.6302 - val_accuracy: 0.6281\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.6020 - accuracy: 0.6829 - val_loss: 0.6315 - val_accuracy: 0.6259\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.6000 - accuracy: 0.6855 - val_loss: 0.6322 - val_accuracy: 0.6238\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5978 - accuracy: 0.6876 - val_loss: 0.6308 - val_accuracy: 0.6259\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5970 - accuracy: 0.6862 - val_loss: 0.6277 - val_accuracy: 0.6292\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5959 - accuracy: 0.6884 - val_loss: 0.6250 - val_accuracy: 0.6336\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.5937 - accuracy: 0.6907 - val_loss: 0.6319 - val_accuracy: 0.6244\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5925 - accuracy: 0.6911 - val_loss: 0.6316 - val_accuracy: 0.6245\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5909 - accuracy: 0.6915 - val_loss: 0.6249 - val_accuracy: 0.6315\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5896 - accuracy: 0.6930 - val_loss: 0.6228 - val_accuracy: 0.6336\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5885 - accuracy: 0.6944 - val_loss: 0.6249 - val_accuracy: 0.6307\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5865 - accuracy: 0.6960 - val_loss: 0.6216 - val_accuracy: 0.6344\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.7242 - accuracy: 0.5318 - val_loss: 0.7725 - val_accuracy: 0.1843\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6830 - accuracy: 0.5688 - val_loss: 0.7068 - val_accuracy: 0.4695\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6767 - accuracy: 0.5941 - val_loss: 0.6940 - val_accuracy: 0.5378\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6713 - accuracy: 0.6111 - val_loss: 0.6882 - val_accuracy: 0.5592\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6674 - accuracy: 0.6186 - val_loss: 0.6877 - val_accuracy: 0.5583\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6625 - accuracy: 0.6336 - val_loss: 0.6822 - val_accuracy: 0.5649\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6591 - accuracy: 0.6418 - val_loss: 0.6786 - val_accuracy: 0.5691\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6558 - accuracy: 0.6475 - val_loss: 0.6754 - val_accuracy: 0.5741\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6516 - accuracy: 0.6560 - val_loss: 0.6736 - val_accuracy: 0.5750\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6477 - accuracy: 0.6625 - val_loss: 0.6682 - val_accuracy: 0.5852\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6439 - accuracy: 0.6675 - val_loss: 0.6645 - val_accuracy: 0.5914\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6392 - accuracy: 0.6756 - val_loss: 0.6591 - val_accuracy: 0.6021\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6354 - accuracy: 0.6789 - val_loss: 0.6607 - val_accuracy: 0.5965\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6322 - accuracy: 0.6818 - val_loss: 0.6543 - val_accuracy: 0.6057\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 456us/step - loss: 0.6281 - accuracy: 0.6871 - val_loss: 0.6521 - val_accuracy: 0.6078\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6239 - accuracy: 0.6914 - val_loss: 0.6521 - val_accuracy: 0.6048\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6215 - accuracy: 0.6916 - val_loss: 0.6458 - val_accuracy: 0.6183\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6174 - accuracy: 0.6959 - val_loss: 0.6409 - val_accuracy: 0.6270\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6149 - accuracy: 0.6964 - val_loss: 0.6382 - val_accuracy: 0.6303\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6120 - accuracy: 0.6980 - val_loss: 0.6352 - val_accuracy: 0.6337\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6085 - accuracy: 0.7010 - val_loss: 0.6351 - val_accuracy: 0.6321\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6064 - accuracy: 0.7007 - val_loss: 0.6306 - val_accuracy: 0.6370\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6029 - accuracy: 0.7043 - val_loss: 0.6297 - val_accuracy: 0.6362\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6005 - accuracy: 0.7064 - val_loss: 0.6224 - val_accuracy: 0.6458\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5984 - accuracy: 0.7067 - val_loss: 0.6248 - val_accuracy: 0.6401\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.5947 - accuracy: 0.7089 - val_loss: 0.6195 - val_accuracy: 0.6445\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5925 - accuracy: 0.7094 - val_loss: 0.6210 - val_accuracy: 0.6408\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5897 - accuracy: 0.7084 - val_loss: 0.6150 - val_accuracy: 0.6465\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5873 - accuracy: 0.7135 - val_loss: 0.6193 - val_accuracy: 0.6402\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5849 - accuracy: 0.7128 - val_loss: 0.6150 - val_accuracy: 0.6447\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5827 - accuracy: 0.7128 - val_loss: 0.6117 - val_accuracy: 0.6470\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5805 - accuracy: 0.7138 - val_loss: 0.6158 - val_accuracy: 0.6403\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 436us/step - loss: 0.5788 - accuracy: 0.7157 - val_loss: 0.6147 - val_accuracy: 0.6399\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5763 - accuracy: 0.7154 - val_loss: 0.6167 - val_accuracy: 0.6372\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5758 - accuracy: 0.7164 - val_loss: 0.6108 - val_accuracy: 0.6431\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5736 - accuracy: 0.7173 - val_loss: 0.6030 - val_accuracy: 0.6528\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5713 - accuracy: 0.7174 - val_loss: 0.6083 - val_accuracy: 0.6454\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5691 - accuracy: 0.7212 - val_loss: 0.6069 - val_accuracy: 0.6466\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.5677 - accuracy: 0.7195 - val_loss: 0.6011 - val_accuracy: 0.6545\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5659 - accuracy: 0.7225 - val_loss: 0.6065 - val_accuracy: 0.6465\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5654 - accuracy: 0.7211 - val_loss: 0.6138 - val_accuracy: 0.6376\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5631 - accuracy: 0.7227 - val_loss: 0.6005 - val_accuracy: 0.6541\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5617 - accuracy: 0.7241 - val_loss: 0.6033 - val_accuracy: 0.6501\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5609 - accuracy: 0.7239 - val_loss: 0.6030 - val_accuracy: 0.6507\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 468us/step - loss: 0.5591 - accuracy: 0.7253 - val_loss: 0.6027 - val_accuracy: 0.6500\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.5575 - accuracy: 0.7262 - val_loss: 0.6004 - val_accuracy: 0.6521\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.5571 - accuracy: 0.7249 - val_loss: 0.5986 - val_accuracy: 0.6532\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5554 - accuracy: 0.7268 - val_loss: 0.5984 - val_accuracy: 0.6532\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5546 - accuracy: 0.7279 - val_loss: 0.5924 - val_accuracy: 0.6601\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 464us/step - loss: 0.5527 - accuracy: 0.7284 - val_loss: 0.5949 - val_accuracy: 0.6562\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 461us/step - loss: 0.6962 - accuracy: 0.5504 - val_loss: 0.7183 - val_accuracy: 0.3868\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6854 - accuracy: 0.5659 - val_loss: 0.7152 - val_accuracy: 0.4255\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6769 - accuracy: 0.5832 - val_loss: 0.7044 - val_accuracy: 0.4828\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6711 - accuracy: 0.5952 - val_loss: 0.7025 - val_accuracy: 0.4960\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6637 - accuracy: 0.6074 - val_loss: 0.6894 - val_accuracy: 0.5380\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.6569 - accuracy: 0.6184 - val_loss: 0.6824 - val_accuracy: 0.5624\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6491 - accuracy: 0.6330 - val_loss: 0.6759 - val_accuracy: 0.5757\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6453 - accuracy: 0.6385 - val_loss: 0.6730 - val_accuracy: 0.5819\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6400 - accuracy: 0.6478 - val_loss: 0.6692 - val_accuracy: 0.5875\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6362 - accuracy: 0.6503 - val_loss: 0.6657 - val_accuracy: 0.5935\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6332 - accuracy: 0.6518 - val_loss: 0.6635 - val_accuracy: 0.5966\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 457us/step - loss: 0.6281 - accuracy: 0.6608 - val_loss: 0.6508 - val_accuracy: 0.6204\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6266 - accuracy: 0.6612 - val_loss: 0.6564 - val_accuracy: 0.6065\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6229 - accuracy: 0.6651 - val_loss: 0.6546 - val_accuracy: 0.6093\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6196 - accuracy: 0.6672 - val_loss: 0.6505 - val_accuracy: 0.6156\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6172 - accuracy: 0.6713 - val_loss: 0.6519 - val_accuracy: 0.6109\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6143 - accuracy: 0.6717 - val_loss: 0.6482 - val_accuracy: 0.6152\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6119 - accuracy: 0.6758 - val_loss: 0.6372 - val_accuracy: 0.6339\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 459us/step - loss: 0.6092 - accuracy: 0.6763 - val_loss: 0.6414 - val_accuracy: 0.6251\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6066 - accuracy: 0.6785 - val_loss: 0.6436 - val_accuracy: 0.6200\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6047 - accuracy: 0.6800 - val_loss: 0.6415 - val_accuracy: 0.6230\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6022 - accuracy: 0.6812 - val_loss: 0.6365 - val_accuracy: 0.6321\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6001 - accuracy: 0.6842 - val_loss: 0.6389 - val_accuracy: 0.6274\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5987 - accuracy: 0.6840 - val_loss: 0.6326 - val_accuracy: 0.6360\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.5969 - accuracy: 0.6852 - val_loss: 0.6354 - val_accuracy: 0.6321\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5952 - accuracy: 0.6848 - val_loss: 0.6299 - val_accuracy: 0.6385\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5931 - accuracy: 0.6868 - val_loss: 0.6330 - val_accuracy: 0.6344\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.5912 - accuracy: 0.6905 - val_loss: 0.6251 - val_accuracy: 0.6447\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5899 - accuracy: 0.6915 - val_loss: 0.6277 - val_accuracy: 0.6408\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5883 - accuracy: 0.6916 - val_loss: 0.6286 - val_accuracy: 0.6395\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.5867 - accuracy: 0.6933 - val_loss: 0.6198 - val_accuracy: 0.6489\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5860 - accuracy: 0.6911 - val_loss: 0.6242 - val_accuracy: 0.6428\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5835 - accuracy: 0.6937 - val_loss: 0.6244 - val_accuracy: 0.6430\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5823 - accuracy: 0.6959 - val_loss: 0.6246 - val_accuracy: 0.6429\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5799 - accuracy: 0.6965 - val_loss: 0.6229 - val_accuracy: 0.6445\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5787 - accuracy: 0.6987 - val_loss: 0.6245 - val_accuracy: 0.6423\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5787 - accuracy: 0.6985 - val_loss: 0.6250 - val_accuracy: 0.6417\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5768 - accuracy: 0.6989 - val_loss: 0.6262 - val_accuracy: 0.6404\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5751 - accuracy: 0.7016 - val_loss: 0.6283 - val_accuracy: 0.6383\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5751 - accuracy: 0.7008 - val_loss: 0.6188 - val_accuracy: 0.6481\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5734 - accuracy: 0.7034 - val_loss: 0.6167 - val_accuracy: 0.6499\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5721 - accuracy: 0.7023 - val_loss: 0.6178 - val_accuracy: 0.6483\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5713 - accuracy: 0.7045 - val_loss: 0.6188 - val_accuracy: 0.6483\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5693 - accuracy: 0.7070 - val_loss: 0.6202 - val_accuracy: 0.6475\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5669 - accuracy: 0.7085 - val_loss: 0.6211 - val_accuracy: 0.6469\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5671 - accuracy: 0.7069 - val_loss: 0.6217 - val_accuracy: 0.6462\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5658 - accuracy: 0.7074 - val_loss: 0.6230 - val_accuracy: 0.6454\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5653 - accuracy: 0.7059 - val_loss: 0.6154 - val_accuracy: 0.6525\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5644 - accuracy: 0.7106 - val_loss: 0.6197 - val_accuracy: 0.6493\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5631 - accuracy: 0.7094 - val_loss: 0.6168 - val_accuracy: 0.6513\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.7226 - accuracy: 0.5111 - val_loss: 0.7613 - val_accuracy: 0.1498\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.7022 - accuracy: 0.5237 - val_loss: 0.7354 - val_accuracy: 0.2166\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6901 - accuracy: 0.5493 - val_loss: 0.7251 - val_accuracy: 0.3376\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6813 - accuracy: 0.5718 - val_loss: 0.7158 - val_accuracy: 0.4121\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6734 - accuracy: 0.5910 - val_loss: 0.6977 - val_accuracy: 0.4978\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6663 - accuracy: 0.6083 - val_loss: 0.6935 - val_accuracy: 0.5161\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6601 - accuracy: 0.6194 - val_loss: 0.6930 - val_accuracy: 0.5232\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6555 - accuracy: 0.6278 - val_loss: 0.6831 - val_accuracy: 0.5584\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6508 - accuracy: 0.6352 - val_loss: 0.6783 - val_accuracy: 0.5747\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6471 - accuracy: 0.6439 - val_loss: 0.6754 - val_accuracy: 0.5835\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6431 - accuracy: 0.6476 - val_loss: 0.6680 - val_accuracy: 0.6013\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6397 - accuracy: 0.6508 - val_loss: 0.6685 - val_accuracy: 0.6008\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6353 - accuracy: 0.6562 - val_loss: 0.6634 - val_accuracy: 0.6086\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6321 - accuracy: 0.6596 - val_loss: 0.6660 - val_accuracy: 0.6037\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6292 - accuracy: 0.6622 - val_loss: 0.6605 - val_accuracy: 0.6132\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6259 - accuracy: 0.6653 - val_loss: 0.6562 - val_accuracy: 0.6228\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6216 - accuracy: 0.6699 - val_loss: 0.6515 - val_accuracy: 0.6287\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6194 - accuracy: 0.6717 - val_loss: 0.6482 - val_accuracy: 0.6310\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6163 - accuracy: 0.6741 - val_loss: 0.6473 - val_accuracy: 0.6307\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6129 - accuracy: 0.6798 - val_loss: 0.6430 - val_accuracy: 0.6372\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6117 - accuracy: 0.6771 - val_loss: 0.6447 - val_accuracy: 0.6314\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6084 - accuracy: 0.6777 - val_loss: 0.6303 - val_accuracy: 0.6533\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6069 - accuracy: 0.6794 - val_loss: 0.6369 - val_accuracy: 0.6438\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6037 - accuracy: 0.6837 - val_loss: 0.6283 - val_accuracy: 0.6520\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6020 - accuracy: 0.6858 - val_loss: 0.6382 - val_accuracy: 0.6392\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5993 - accuracy: 0.6876 - val_loss: 0.6311 - val_accuracy: 0.6448\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5974 - accuracy: 0.6883 - val_loss: 0.6281 - val_accuracy: 0.6464\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5951 - accuracy: 0.6887 - val_loss: 0.6352 - val_accuracy: 0.6375\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5930 - accuracy: 0.6906 - val_loss: 0.6259 - val_accuracy: 0.6461\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5911 - accuracy: 0.6943 - val_loss: 0.6242 - val_accuracy: 0.6472\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5886 - accuracy: 0.6954 - val_loss: 0.6206 - val_accuracy: 0.6491\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5872 - accuracy: 0.6960 - val_loss: 0.6218 - val_accuracy: 0.6471\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5850 - accuracy: 0.6987 - val_loss: 0.6211 - val_accuracy: 0.6470\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5830 - accuracy: 0.6960 - val_loss: 0.6180 - val_accuracy: 0.6511\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5817 - accuracy: 0.7012 - val_loss: 0.6141 - val_accuracy: 0.6543\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5801 - accuracy: 0.7004 - val_loss: 0.6240 - val_accuracy: 0.6445\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5796 - accuracy: 0.7004 - val_loss: 0.6179 - val_accuracy: 0.6506\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5772 - accuracy: 0.7032 - val_loss: 0.6143 - val_accuracy: 0.6558\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5750 - accuracy: 0.7068 - val_loss: 0.6148 - val_accuracy: 0.6561\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5740 - accuracy: 0.7060 - val_loss: 0.6195 - val_accuracy: 0.6478\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5720 - accuracy: 0.7067 - val_loss: 0.6181 - val_accuracy: 0.6499\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5696 - accuracy: 0.7094 - val_loss: 0.6168 - val_accuracy: 0.6513\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5691 - accuracy: 0.7100 - val_loss: 0.6088 - val_accuracy: 0.6601\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5683 - accuracy: 0.7104 - val_loss: 0.6104 - val_accuracy: 0.6576\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5662 - accuracy: 0.7121 - val_loss: 0.6066 - val_accuracy: 0.6618\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5642 - accuracy: 0.7145 - val_loss: 0.6084 - val_accuracy: 0.6575\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5641 - accuracy: 0.7146 - val_loss: 0.6112 - val_accuracy: 0.6537\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.5620 - accuracy: 0.7140 - val_loss: 0.6061 - val_accuracy: 0.6585\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5614 - accuracy: 0.7145 - val_loss: 0.6054 - val_accuracy: 0.6595\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5592 - accuracy: 0.7157 - val_loss: 0.6095 - val_accuracy: 0.6545\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6945 - accuracy: 0.5248 - val_loss: 0.7098 - val_accuracy: 0.4336\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6897 - accuracy: 0.5370 - val_loss: 0.7043 - val_accuracy: 0.4766\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6829 - accuracy: 0.5516 - val_loss: 0.6956 - val_accuracy: 0.5271\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6803 - accuracy: 0.5585 - val_loss: 0.6939 - val_accuracy: 0.5399\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6743 - accuracy: 0.5749 - val_loss: 0.6907 - val_accuracy: 0.5514\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6721 - accuracy: 0.5784 - val_loss: 0.6880 - val_accuracy: 0.5619\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6688 - accuracy: 0.5873 - val_loss: 0.6810 - val_accuracy: 0.5806\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6651 - accuracy: 0.5952 - val_loss: 0.6855 - val_accuracy: 0.5686\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6612 - accuracy: 0.6040 - val_loss: 0.6797 - val_accuracy: 0.5820\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6587 - accuracy: 0.6079 - val_loss: 0.6779 - val_accuracy: 0.5862\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6573 - accuracy: 0.6115 - val_loss: 0.6731 - val_accuracy: 0.5974\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6534 - accuracy: 0.6173 - val_loss: 0.6730 - val_accuracy: 0.5953\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6510 - accuracy: 0.6237 - val_loss: 0.6690 - val_accuracy: 0.6002\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6487 - accuracy: 0.6257 - val_loss: 0.6665 - val_accuracy: 0.6031\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6461 - accuracy: 0.6313 - val_loss: 0.6645 - val_accuracy: 0.6048\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6434 - accuracy: 0.6351 - val_loss: 0.6648 - val_accuracy: 0.6025\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6409 - accuracy: 0.6388 - val_loss: 0.6576 - val_accuracy: 0.6161\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6391 - accuracy: 0.6392 - val_loss: 0.6612 - val_accuracy: 0.6083\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 467us/step - loss: 0.6362 - accuracy: 0.6449 - val_loss: 0.6579 - val_accuracy: 0.6135\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6349 - accuracy: 0.6453 - val_loss: 0.6522 - val_accuracy: 0.6238\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6319 - accuracy: 0.6463 - val_loss: 0.6545 - val_accuracy: 0.6189\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6283 - accuracy: 0.6537 - val_loss: 0.6528 - val_accuracy: 0.6206\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6275 - accuracy: 0.6535 - val_loss: 0.6451 - val_accuracy: 0.6295\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6253 - accuracy: 0.6562 - val_loss: 0.6473 - val_accuracy: 0.6265\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6227 - accuracy: 0.6573 - val_loss: 0.6451 - val_accuracy: 0.6293\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6205 - accuracy: 0.6608 - val_loss: 0.6431 - val_accuracy: 0.6313\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6190 - accuracy: 0.6615 - val_loss: 0.6389 - val_accuracy: 0.6357\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6162 - accuracy: 0.6650 - val_loss: 0.6391 - val_accuracy: 0.6336\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6155 - accuracy: 0.6662 - val_loss: 0.6371 - val_accuracy: 0.6363\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6130 - accuracy: 0.6693 - val_loss: 0.6339 - val_accuracy: 0.6401\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6095 - accuracy: 0.6735 - val_loss: 0.6360 - val_accuracy: 0.6364\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6088 - accuracy: 0.6727 - val_loss: 0.6279 - val_accuracy: 0.6465\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6071 - accuracy: 0.6742 - val_loss: 0.6348 - val_accuracy: 0.6371\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6049 - accuracy: 0.6771 - val_loss: 0.6307 - val_accuracy: 0.6414\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6039 - accuracy: 0.6761 - val_loss: 0.6245 - val_accuracy: 0.6482\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6024 - accuracy: 0.6790 - val_loss: 0.6263 - val_accuracy: 0.6444\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.6007 - accuracy: 0.6807 - val_loss: 0.6307 - val_accuracy: 0.6389\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5986 - accuracy: 0.6843 - val_loss: 0.6239 - val_accuracy: 0.6461\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5966 - accuracy: 0.6871 - val_loss: 0.6235 - val_accuracy: 0.6454\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5956 - accuracy: 0.6867 - val_loss: 0.6207 - val_accuracy: 0.6471\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5938 - accuracy: 0.6902 - val_loss: 0.6162 - val_accuracy: 0.6513\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5923 - accuracy: 0.6922 - val_loss: 0.6119 - val_accuracy: 0.6558\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5908 - accuracy: 0.6926 - val_loss: 0.6192 - val_accuracy: 0.6455\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5894 - accuracy: 0.6938 - val_loss: 0.6132 - val_accuracy: 0.6524\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5877 - accuracy: 0.6945 - val_loss: 0.6156 - val_accuracy: 0.6488\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5882 - accuracy: 0.6922 - val_loss: 0.6134 - val_accuracy: 0.6498\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5852 - accuracy: 0.6987 - val_loss: 0.6126 - val_accuracy: 0.6501\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5849 - accuracy: 0.6982 - val_loss: 0.6148 - val_accuracy: 0.6461\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5835 - accuracy: 0.6989 - val_loss: 0.6143 - val_accuracy: 0.6451\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5826 - accuracy: 0.7031 - val_loss: 0.6061 - val_accuracy: 0.6582\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.7080 - accuracy: 0.5067 - val_loss: 0.7446 - val_accuracy: 0.2825\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.7002 - accuracy: 0.5201 - val_loss: 0.7270 - val_accuracy: 0.3426\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6944 - accuracy: 0.5340 - val_loss: 0.7228 - val_accuracy: 0.3909\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6897 - accuracy: 0.5469 - val_loss: 0.7165 - val_accuracy: 0.4386\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6844 - accuracy: 0.5629 - val_loss: 0.7115 - val_accuracy: 0.4821\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6802 - accuracy: 0.5720 - val_loss: 0.7059 - val_accuracy: 0.5069\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6763 - accuracy: 0.5842 - val_loss: 0.7017 - val_accuracy: 0.5210\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6723 - accuracy: 0.5972 - val_loss: 0.6978 - val_accuracy: 0.5306\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6685 - accuracy: 0.6025 - val_loss: 0.6946 - val_accuracy: 0.5362\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6657 - accuracy: 0.6096 - val_loss: 0.6908 - val_accuracy: 0.5404\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6614 - accuracy: 0.6207 - val_loss: 0.6883 - val_accuracy: 0.5437\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6593 - accuracy: 0.6207 - val_loss: 0.6832 - val_accuracy: 0.5510\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6558 - accuracy: 0.6278 - val_loss: 0.6797 - val_accuracy: 0.5572\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6539 - accuracy: 0.6298 - val_loss: 0.6799 - val_accuracy: 0.5556\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6502 - accuracy: 0.6384 - val_loss: 0.6745 - val_accuracy: 0.5645\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6470 - accuracy: 0.6400 - val_loss: 0.6734 - val_accuracy: 0.5672\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6443 - accuracy: 0.6455 - val_loss: 0.6649 - val_accuracy: 0.5865\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6415 - accuracy: 0.6481 - val_loss: 0.6669 - val_accuracy: 0.5826\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.6385 - accuracy: 0.6526 - val_loss: 0.6625 - val_accuracy: 0.5911\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6362 - accuracy: 0.6536 - val_loss: 0.6634 - val_accuracy: 0.5897\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6342 - accuracy: 0.6575 - val_loss: 0.6581 - val_accuracy: 0.6009\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6319 - accuracy: 0.6589 - val_loss: 0.6535 - val_accuracy: 0.6085\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.6284 - accuracy: 0.6620 - val_loss: 0.6559 - val_accuracy: 0.6037\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6263 - accuracy: 0.6656 - val_loss: 0.6537 - val_accuracy: 0.6069\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.6245 - accuracy: 0.6651 - val_loss: 0.6477 - val_accuracy: 0.6175\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6222 - accuracy: 0.6676 - val_loss: 0.6438 - val_accuracy: 0.6229\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6190 - accuracy: 0.6727 - val_loss: 0.6441 - val_accuracy: 0.6217\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6178 - accuracy: 0.6717 - val_loss: 0.6472 - val_accuracy: 0.6156\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6156 - accuracy: 0.6738 - val_loss: 0.6409 - val_accuracy: 0.6249\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 470us/step - loss: 0.6127 - accuracy: 0.6771 - val_loss: 0.6409 - val_accuracy: 0.6234\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6108 - accuracy: 0.6801 - val_loss: 0.6341 - val_accuracy: 0.6359\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6091 - accuracy: 0.6811 - val_loss: 0.6327 - val_accuracy: 0.6363\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6069 - accuracy: 0.6834 - val_loss: 0.6342 - val_accuracy: 0.6325\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.6047 - accuracy: 0.6850 - val_loss: 0.6304 - val_accuracy: 0.6386\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6027 - accuracy: 0.6877 - val_loss: 0.6285 - val_accuracy: 0.6405\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 442us/step - loss: 0.6008 - accuracy: 0.6884 - val_loss: 0.6260 - val_accuracy: 0.6436\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5999 - accuracy: 0.6883 - val_loss: 0.6248 - val_accuracy: 0.6434\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5977 - accuracy: 0.6917 - val_loss: 0.6273 - val_accuracy: 0.6396\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5956 - accuracy: 0.6932 - val_loss: 0.6297 - val_accuracy: 0.6356\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5935 - accuracy: 0.6948 - val_loss: 0.6172 - val_accuracy: 0.6507\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5927 - accuracy: 0.6969 - val_loss: 0.6206 - val_accuracy: 0.6450\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5916 - accuracy: 0.6960 - val_loss: 0.6201 - val_accuracy: 0.6446\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5897 - accuracy: 0.6959 - val_loss: 0.6193 - val_accuracy: 0.6443\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 444us/step - loss: 0.5885 - accuracy: 0.6995 - val_loss: 0.6173 - val_accuracy: 0.6459\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5871 - accuracy: 0.7006 - val_loss: 0.6210 - val_accuracy: 0.6420\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5844 - accuracy: 0.7011 - val_loss: 0.6171 - val_accuracy: 0.6454\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5825 - accuracy: 0.7042 - val_loss: 0.6115 - val_accuracy: 0.6501\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5815 - accuracy: 0.7045 - val_loss: 0.6106 - val_accuracy: 0.6509\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 443us/step - loss: 0.5800 - accuracy: 0.7050 - val_loss: 0.6118 - val_accuracy: 0.6493\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.5785 - accuracy: 0.7050 - val_loss: 0.6146 - val_accuracy: 0.6469\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.7316 - accuracy: 0.4773 - val_loss: 0.6960 - val_accuracy: 0.5145\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.7043 - accuracy: 0.5084 - val_loss: 0.7012 - val_accuracy: 0.4815\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6942 - accuracy: 0.5312 - val_loss: 0.6950 - val_accuracy: 0.5026\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6875 - accuracy: 0.5471 - val_loss: 0.6921 - val_accuracy: 0.5184\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6799 - accuracy: 0.5615 - val_loss: 0.6795 - val_accuracy: 0.5781\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6740 - accuracy: 0.5756 - val_loss: 0.6766 - val_accuracy: 0.5841\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 441us/step - loss: 0.6675 - accuracy: 0.5879 - val_loss: 0.6724 - val_accuracy: 0.5929\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6631 - accuracy: 0.5990 - val_loss: 0.6668 - val_accuracy: 0.6057\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6584 - accuracy: 0.6097 - val_loss: 0.6648 - val_accuracy: 0.6075\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6534 - accuracy: 0.6189 - val_loss: 0.6600 - val_accuracy: 0.6176\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6484 - accuracy: 0.6268 - val_loss: 0.6552 - val_accuracy: 0.6293\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6445 - accuracy: 0.6318 - val_loss: 0.6521 - val_accuracy: 0.6333\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6402 - accuracy: 0.6392 - val_loss: 0.6507 - val_accuracy: 0.6328\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6357 - accuracy: 0.6457 - val_loss: 0.6446 - val_accuracy: 0.6422\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.6337 - accuracy: 0.6486 - val_loss: 0.6451 - val_accuracy: 0.6378\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6304 - accuracy: 0.6549 - val_loss: 0.6406 - val_accuracy: 0.6430\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6277 - accuracy: 0.6568 - val_loss: 0.6419 - val_accuracy: 0.6398\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6237 - accuracy: 0.6630 - val_loss: 0.6386 - val_accuracy: 0.6409\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6202 - accuracy: 0.6671 - val_loss: 0.6379 - val_accuracy: 0.6402\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6195 - accuracy: 0.6671 - val_loss: 0.6336 - val_accuracy: 0.6455\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6161 - accuracy: 0.6709 - val_loss: 0.6319 - val_accuracy: 0.6454\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6144 - accuracy: 0.6729 - val_loss: 0.6307 - val_accuracy: 0.6448\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6128 - accuracy: 0.6715 - val_loss: 0.6258 - val_accuracy: 0.6522\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6105 - accuracy: 0.6779 - val_loss: 0.6321 - val_accuracy: 0.6392\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6073 - accuracy: 0.6805 - val_loss: 0.6260 - val_accuracy: 0.6474\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6054 - accuracy: 0.6820 - val_loss: 0.6229 - val_accuracy: 0.6499\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6035 - accuracy: 0.6814 - val_loss: 0.6233 - val_accuracy: 0.6475\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6009 - accuracy: 0.6858 - val_loss: 0.6208 - val_accuracy: 0.6482\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5999 - accuracy: 0.6859 - val_loss: 0.6191 - val_accuracy: 0.6491\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5986 - accuracy: 0.6869 - val_loss: 0.6172 - val_accuracy: 0.6498\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.5956 - accuracy: 0.6906 - val_loss: 0.6206 - val_accuracy: 0.6425\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5935 - accuracy: 0.6922 - val_loss: 0.6137 - val_accuracy: 0.6513\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 446us/step - loss: 0.5916 - accuracy: 0.6927 - val_loss: 0.6195 - val_accuracy: 0.6407\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5905 - accuracy: 0.6932 - val_loss: 0.6184 - val_accuracy: 0.6412\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5886 - accuracy: 0.6970 - val_loss: 0.6113 - val_accuracy: 0.6502\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5871 - accuracy: 0.6960 - val_loss: 0.6151 - val_accuracy: 0.6430\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5854 - accuracy: 0.6990 - val_loss: 0.6072 - val_accuracy: 0.6543\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5843 - accuracy: 0.6991 - val_loss: 0.6096 - val_accuracy: 0.6495\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5818 - accuracy: 0.7016 - val_loss: 0.6149 - val_accuracy: 0.6407\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5802 - accuracy: 0.7041 - val_loss: 0.6111 - val_accuracy: 0.6462\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.5793 - accuracy: 0.7041 - val_loss: 0.6105 - val_accuracy: 0.6467\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5772 - accuracy: 0.7073 - val_loss: 0.6082 - val_accuracy: 0.6497\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5766 - accuracy: 0.7075 - val_loss: 0.6107 - val_accuracy: 0.6451\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.5762 - accuracy: 0.7068 - val_loss: 0.6089 - val_accuracy: 0.6489\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.5737 - accuracy: 0.7105 - val_loss: 0.6116 - val_accuracy: 0.6439\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5713 - accuracy: 0.7111 - val_loss: 0.6077 - val_accuracy: 0.6496\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.5707 - accuracy: 0.7129 - val_loss: 0.6063 - val_accuracy: 0.6504\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5697 - accuracy: 0.7114 - val_loss: 0.6064 - val_accuracy: 0.6495\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5687 - accuracy: 0.7120 - val_loss: 0.6043 - val_accuracy: 0.6506\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5667 - accuracy: 0.7123 - val_loss: 0.6079 - val_accuracy: 0.6469\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.7188 - accuracy: 0.5132 - val_loss: 0.7469 - val_accuracy: 0.2117\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.7044 - accuracy: 0.5217 - val_loss: 0.7220 - val_accuracy: 0.2957\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6983 - accuracy: 0.5348 - val_loss: 0.7146 - val_accuracy: 0.3581\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6929 - accuracy: 0.5442 - val_loss: 0.7102 - val_accuracy: 0.4094\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6857 - accuracy: 0.5594 - val_loss: 0.7049 - val_accuracy: 0.4452\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6811 - accuracy: 0.5711 - val_loss: 0.7055 - val_accuracy: 0.4501\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6769 - accuracy: 0.5814 - val_loss: 0.6991 - val_accuracy: 0.4903\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6737 - accuracy: 0.5902 - val_loss: 0.6968 - val_accuracy: 0.5241\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6685 - accuracy: 0.5980 - val_loss: 0.6944 - val_accuracy: 0.5419\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6660 - accuracy: 0.6073 - val_loss: 0.6883 - val_accuracy: 0.5684\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6611 - accuracy: 0.6181 - val_loss: 0.6854 - val_accuracy: 0.5789\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6593 - accuracy: 0.6218 - val_loss: 0.6824 - val_accuracy: 0.5829\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6541 - accuracy: 0.6332 - val_loss: 0.6784 - val_accuracy: 0.5873\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6524 - accuracy: 0.6362 - val_loss: 0.6768 - val_accuracy: 0.5902\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6489 - accuracy: 0.6413 - val_loss: 0.6746 - val_accuracy: 0.5934\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6471 - accuracy: 0.6455 - val_loss: 0.6713 - val_accuracy: 0.5970\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6438 - accuracy: 0.6511 - val_loss: 0.6720 - val_accuracy: 0.5956\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6409 - accuracy: 0.6565 - val_loss: 0.6647 - val_accuracy: 0.6059\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6392 - accuracy: 0.6580 - val_loss: 0.6667 - val_accuracy: 0.6009\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6354 - accuracy: 0.6636 - val_loss: 0.6622 - val_accuracy: 0.6089\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6336 - accuracy: 0.6687 - val_loss: 0.6626 - val_accuracy: 0.6071\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6308 - accuracy: 0.6717 - val_loss: 0.6595 - val_accuracy: 0.6102\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6283 - accuracy: 0.6730 - val_loss: 0.6590 - val_accuracy: 0.6098\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6256 - accuracy: 0.6760 - val_loss: 0.6539 - val_accuracy: 0.6143\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6237 - accuracy: 0.6749 - val_loss: 0.6553 - val_accuracy: 0.6126\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6213 - accuracy: 0.6809 - val_loss: 0.6520 - val_accuracy: 0.6148\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6190 - accuracy: 0.6822 - val_loss: 0.6495 - val_accuracy: 0.6194\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6164 - accuracy: 0.6827 - val_loss: 0.6494 - val_accuracy: 0.6200\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6148 - accuracy: 0.6848 - val_loss: 0.6445 - val_accuracy: 0.6262\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6117 - accuracy: 0.6884 - val_loss: 0.6427 - val_accuracy: 0.6265\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6101 - accuracy: 0.6879 - val_loss: 0.6430 - val_accuracy: 0.6248\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6074 - accuracy: 0.6909 - val_loss: 0.6384 - val_accuracy: 0.6299\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6049 - accuracy: 0.6924 - val_loss: 0.6356 - val_accuracy: 0.6332\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6030 - accuracy: 0.6939 - val_loss: 0.6355 - val_accuracy: 0.6332\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6005 - accuracy: 0.6965 - val_loss: 0.6305 - val_accuracy: 0.6388\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5993 - accuracy: 0.6953 - val_loss: 0.6309 - val_accuracy: 0.6371\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5974 - accuracy: 0.6978 - val_loss: 0.6329 - val_accuracy: 0.6332\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5945 - accuracy: 0.7003 - val_loss: 0.6283 - val_accuracy: 0.6383\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5940 - accuracy: 0.7004 - val_loss: 0.6272 - val_accuracy: 0.6380\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5920 - accuracy: 0.6998 - val_loss: 0.6295 - val_accuracy: 0.6349\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5904 - accuracy: 0.7022 - val_loss: 0.6277 - val_accuracy: 0.6359\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5873 - accuracy: 0.7051 - val_loss: 0.6293 - val_accuracy: 0.6341\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5869 - accuracy: 0.7037 - val_loss: 0.6278 - val_accuracy: 0.6352\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.5845 - accuracy: 0.7068 - val_loss: 0.6250 - val_accuracy: 0.6387\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5832 - accuracy: 0.7079 - val_loss: 0.6199 - val_accuracy: 0.6436\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5805 - accuracy: 0.7095 - val_loss: 0.6185 - val_accuracy: 0.6449\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5800 - accuracy: 0.7084 - val_loss: 0.6219 - val_accuracy: 0.6414\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.5777 - accuracy: 0.7111 - val_loss: 0.6241 - val_accuracy: 0.6396\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5776 - accuracy: 0.7115 - val_loss: 0.6182 - val_accuracy: 0.6437\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5762 - accuracy: 0.7115 - val_loss: 0.6159 - val_accuracy: 0.6454\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.7484 - accuracy: 0.4913 - val_loss: 0.7866 - val_accuracy: 0.1666\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.7176 - accuracy: 0.4903 - val_loss: 0.7521 - val_accuracy: 0.2293\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.7070 - accuracy: 0.5128 - val_loss: 0.7430 - val_accuracy: 0.3064\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6996 - accuracy: 0.5276 - val_loss: 0.7334 - val_accuracy: 0.3604\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6937 - accuracy: 0.5419 - val_loss: 0.7266 - val_accuracy: 0.3890\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6886 - accuracy: 0.5540 - val_loss: 0.7208 - val_accuracy: 0.4162\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6836 - accuracy: 0.5691 - val_loss: 0.7150 - val_accuracy: 0.4384\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6801 - accuracy: 0.5801 - val_loss: 0.7098 - val_accuracy: 0.4584\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6756 - accuracy: 0.5906 - val_loss: 0.7049 - val_accuracy: 0.4714\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6719 - accuracy: 0.5996 - val_loss: 0.7025 - val_accuracy: 0.4821\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6680 - accuracy: 0.6083 - val_loss: 0.6999 - val_accuracy: 0.4922\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6654 - accuracy: 0.6137 - val_loss: 0.6966 - val_accuracy: 0.5015\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6612 - accuracy: 0.6252 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6580 - accuracy: 0.6330 - val_loss: 0.6897 - val_accuracy: 0.5278\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6551 - accuracy: 0.6374 - val_loss: 0.6897 - val_accuracy: 0.5268\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6520 - accuracy: 0.6434 - val_loss: 0.6839 - val_accuracy: 0.5374\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6502 - accuracy: 0.6440 - val_loss: 0.6802 - val_accuracy: 0.5430\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6455 - accuracy: 0.6521 - val_loss: 0.6775 - val_accuracy: 0.5459\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6427 - accuracy: 0.6548 - val_loss: 0.6749 - val_accuracy: 0.5489\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6412 - accuracy: 0.6553 - val_loss: 0.6722 - val_accuracy: 0.5545\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6377 - accuracy: 0.6599 - val_loss: 0.6734 - val_accuracy: 0.5539\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6358 - accuracy: 0.6609 - val_loss: 0.6686 - val_accuracy: 0.5620\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6327 - accuracy: 0.6636 - val_loss: 0.6659 - val_accuracy: 0.5664\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6291 - accuracy: 0.6698 - val_loss: 0.6643 - val_accuracy: 0.5670\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6281 - accuracy: 0.6667 - val_loss: 0.6631 - val_accuracy: 0.5684\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6254 - accuracy: 0.6699 - val_loss: 0.6594 - val_accuracy: 0.5727\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6233 - accuracy: 0.6702 - val_loss: 0.6539 - val_accuracy: 0.5814\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6207 - accuracy: 0.6728 - val_loss: 0.6546 - val_accuracy: 0.5787\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6170 - accuracy: 0.6758 - val_loss: 0.6508 - val_accuracy: 0.5833\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6161 - accuracy: 0.6752 - val_loss: 0.6473 - val_accuracy: 0.5887\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6133 - accuracy: 0.6770 - val_loss: 0.6450 - val_accuracy: 0.5923\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 477us/step - loss: 0.6120 - accuracy: 0.6763 - val_loss: 0.6468 - val_accuracy: 0.5892\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6097 - accuracy: 0.6787 - val_loss: 0.6432 - val_accuracy: 0.5927\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6078 - accuracy: 0.6806 - val_loss: 0.6389 - val_accuracy: 0.6009\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6046 - accuracy: 0.6818 - val_loss: 0.6386 - val_accuracy: 0.6015\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6033 - accuracy: 0.6834 - val_loss: 0.6412 - val_accuracy: 0.5958\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6016 - accuracy: 0.6832 - val_loss: 0.6326 - val_accuracy: 0.6145\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5988 - accuracy: 0.6847 - val_loss: 0.6323 - val_accuracy: 0.6154\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5977 - accuracy: 0.6865 - val_loss: 0.6310 - val_accuracy: 0.6174\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5967 - accuracy: 0.6848 - val_loss: 0.6279 - val_accuracy: 0.6203\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5939 - accuracy: 0.6874 - val_loss: 0.6266 - val_accuracy: 0.6217\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 449us/step - loss: 0.5920 - accuracy: 0.6892 - val_loss: 0.6323 - val_accuracy: 0.6152\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5911 - accuracy: 0.6901 - val_loss: 0.6232 - val_accuracy: 0.6244\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.5884 - accuracy: 0.6910 - val_loss: 0.6262 - val_accuracy: 0.6207\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5869 - accuracy: 0.6939 - val_loss: 0.6286 - val_accuracy: 0.6185\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5857 - accuracy: 0.6940 - val_loss: 0.6281 - val_accuracy: 0.6184\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5841 - accuracy: 0.6951 - val_loss: 0.6227 - val_accuracy: 0.6215\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 476us/step - loss: 0.5835 - accuracy: 0.6934 - val_loss: 0.6230 - val_accuracy: 0.6211\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5813 - accuracy: 0.6969 - val_loss: 0.6197 - val_accuracy: 0.6242\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.5798 - accuracy: 0.6974 - val_loss: 0.6175 - val_accuracy: 0.6266\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.7068 - accuracy: 0.5080 - val_loss: 0.7091 - val_accuracy: 0.4135\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6890 - accuracy: 0.5377 - val_loss: 0.7090 - val_accuracy: 0.4462\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6823 - accuracy: 0.5567 - val_loss: 0.6971 - val_accuracy: 0.5097\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6757 - accuracy: 0.5726 - val_loss: 0.6909 - val_accuracy: 0.5425\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6704 - accuracy: 0.5852 - val_loss: 0.6845 - val_accuracy: 0.5619\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 473us/step - loss: 0.6658 - accuracy: 0.5982 - val_loss: 0.6804 - val_accuracy: 0.5757\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6615 - accuracy: 0.6078 - val_loss: 0.6768 - val_accuracy: 0.5838\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6581 - accuracy: 0.6160 - val_loss: 0.6780 - val_accuracy: 0.5800\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6549 - accuracy: 0.6240 - val_loss: 0.6780 - val_accuracy: 0.5772\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6508 - accuracy: 0.6310 - val_loss: 0.6716 - val_accuracy: 0.5939\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6463 - accuracy: 0.6401 - val_loss: 0.6663 - val_accuracy: 0.6071\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6430 - accuracy: 0.6445 - val_loss: 0.6618 - val_accuracy: 0.6153\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.6390 - accuracy: 0.6519 - val_loss: 0.6596 - val_accuracy: 0.6174\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6368 - accuracy: 0.6548 - val_loss: 0.6561 - val_accuracy: 0.6203\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6338 - accuracy: 0.6598 - val_loss: 0.6577 - val_accuracy: 0.6156\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6311 - accuracy: 0.6624 - val_loss: 0.6508 - val_accuracy: 0.6242\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.6285 - accuracy: 0.6626 - val_loss: 0.6498 - val_accuracy: 0.6249\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6263 - accuracy: 0.6678 - val_loss: 0.6461 - val_accuracy: 0.6284\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6236 - accuracy: 0.6720 - val_loss: 0.6426 - val_accuracy: 0.6324\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6211 - accuracy: 0.6738 - val_loss: 0.6388 - val_accuracy: 0.6367\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6199 - accuracy: 0.6715 - val_loss: 0.6453 - val_accuracy: 0.6277\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6176 - accuracy: 0.6772 - val_loss: 0.6325 - val_accuracy: 0.6409\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6153 - accuracy: 0.6799 - val_loss: 0.6352 - val_accuracy: 0.6344\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6128 - accuracy: 0.6814 - val_loss: 0.6315 - val_accuracy: 0.6371\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6112 - accuracy: 0.6831 - val_loss: 0.6285 - val_accuracy: 0.6396\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6087 - accuracy: 0.6844 - val_loss: 0.6295 - val_accuracy: 0.6365\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6064 - accuracy: 0.6851 - val_loss: 0.6282 - val_accuracy: 0.6377\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6038 - accuracy: 0.6907 - val_loss: 0.6310 - val_accuracy: 0.6352\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6028 - accuracy: 0.6923 - val_loss: 0.6204 - val_accuracy: 0.6437\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6006 - accuracy: 0.6931 - val_loss: 0.6217 - val_accuracy: 0.6416\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5984 - accuracy: 0.6953 - val_loss: 0.6151 - val_accuracy: 0.6483\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.5959 - accuracy: 0.6976 - val_loss: 0.6172 - val_accuracy: 0.6444\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.5939 - accuracy: 0.6997 - val_loss: 0.6211 - val_accuracy: 0.6399\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5920 - accuracy: 0.7004 - val_loss: 0.6189 - val_accuracy: 0.6409\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5903 - accuracy: 0.7023 - val_loss: 0.6105 - val_accuracy: 0.6514\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.5891 - accuracy: 0.7029 - val_loss: 0.6169 - val_accuracy: 0.6407\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5881 - accuracy: 0.7034 - val_loss: 0.6182 - val_accuracy: 0.6381\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.5854 - accuracy: 0.7049 - val_loss: 0.6118 - val_accuracy: 0.6461\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5846 - accuracy: 0.7057 - val_loss: 0.6092 - val_accuracy: 0.6471\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5835 - accuracy: 0.7073 - val_loss: 0.6115 - val_accuracy: 0.6438\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 478us/step - loss: 0.5815 - accuracy: 0.7086 - val_loss: 0.6092 - val_accuracy: 0.6447\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 445us/step - loss: 0.5805 - accuracy: 0.7094 - val_loss: 0.6134 - val_accuracy: 0.6398\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5789 - accuracy: 0.7112 - val_loss: 0.6023 - val_accuracy: 0.6461\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.5772 - accuracy: 0.7123 - val_loss: 0.6043 - val_accuracy: 0.6424\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 450us/step - loss: 0.5760 - accuracy: 0.7130 - val_loss: 0.6070 - val_accuracy: 0.6396\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5754 - accuracy: 0.7125 - val_loss: 0.6053 - val_accuracy: 0.6401\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5733 - accuracy: 0.7149 - val_loss: 0.6075 - val_accuracy: 0.6382\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5720 - accuracy: 0.7168 - val_loss: 0.6046 - val_accuracy: 0.6395\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5709 - accuracy: 0.7143 - val_loss: 0.6080 - val_accuracy: 0.6359\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5705 - accuracy: 0.7142 - val_loss: 0.6048 - val_accuracy: 0.6385\n",
      "\n",
      "Training model with noise_multiplier=2.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.5 iterated over 83600 steps satisfies differential privacy with eps = 0.35 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.7111 - accuracy: 0.5005 - val_loss: 0.6766 - val_accuracy: 0.6257\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6939 - accuracy: 0.5316 - val_loss: 0.6999 - val_accuracy: 0.4784\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6880 - accuracy: 0.5458 - val_loss: 0.7020 - val_accuracy: 0.4872\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6837 - accuracy: 0.5601 - val_loss: 0.7015 - val_accuracy: 0.5039\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6799 - accuracy: 0.5718 - val_loss: 0.6984 - val_accuracy: 0.5235\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6753 - accuracy: 0.5850 - val_loss: 0.6954 - val_accuracy: 0.5364\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6714 - accuracy: 0.5951 - val_loss: 0.6904 - val_accuracy: 0.5531\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6685 - accuracy: 0.6048 - val_loss: 0.6866 - val_accuracy: 0.5642\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6660 - accuracy: 0.6091 - val_loss: 0.6858 - val_accuracy: 0.5680\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6634 - accuracy: 0.6147 - val_loss: 0.6829 - val_accuracy: 0.5762\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6603 - accuracy: 0.6236 - val_loss: 0.6813 - val_accuracy: 0.5808\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6581 - accuracy: 0.6269 - val_loss: 0.6788 - val_accuracy: 0.5853\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6558 - accuracy: 0.6329 - val_loss: 0.6767 - val_accuracy: 0.5896\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6523 - accuracy: 0.6399 - val_loss: 0.6753 - val_accuracy: 0.5932\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6501 - accuracy: 0.6445 - val_loss: 0.6742 - val_accuracy: 0.5960\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6473 - accuracy: 0.6487 - val_loss: 0.6711 - val_accuracy: 0.6032\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6454 - accuracy: 0.6487 - val_loss: 0.6685 - val_accuracy: 0.6073\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6427 - accuracy: 0.6535 - val_loss: 0.6681 - val_accuracy: 0.6063\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6414 - accuracy: 0.6572 - val_loss: 0.6668 - val_accuracy: 0.6092\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6391 - accuracy: 0.6588 - val_loss: 0.6587 - val_accuracy: 0.6251\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6375 - accuracy: 0.6594 - val_loss: 0.6582 - val_accuracy: 0.6250\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6351 - accuracy: 0.6651 - val_loss: 0.6595 - val_accuracy: 0.6219\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6327 - accuracy: 0.6658 - val_loss: 0.6551 - val_accuracy: 0.6288\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6313 - accuracy: 0.6657 - val_loss: 0.6542 - val_accuracy: 0.6299\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6295 - accuracy: 0.6697 - val_loss: 0.6562 - val_accuracy: 0.6260\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6273 - accuracy: 0.6718 - val_loss: 0.6554 - val_accuracy: 0.6259\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.6255 - accuracy: 0.6742 - val_loss: 0.6502 - val_accuracy: 0.6330\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6238 - accuracy: 0.6755 - val_loss: 0.6508 - val_accuracy: 0.6304\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6221 - accuracy: 0.6754 - val_loss: 0.6488 - val_accuracy: 0.6349\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6206 - accuracy: 0.6766 - val_loss: 0.6468 - val_accuracy: 0.6377\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6182 - accuracy: 0.6805 - val_loss: 0.6456 - val_accuracy: 0.6387\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6166 - accuracy: 0.6818 - val_loss: 0.6397 - val_accuracy: 0.6445\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6145 - accuracy: 0.6836 - val_loss: 0.6390 - val_accuracy: 0.6447\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6128 - accuracy: 0.6851 - val_loss: 0.6399 - val_accuracy: 0.6428\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6118 - accuracy: 0.6867 - val_loss: 0.6372 - val_accuracy: 0.6460\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6091 - accuracy: 0.6876 - val_loss: 0.6352 - val_accuracy: 0.6477\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6081 - accuracy: 0.6882 - val_loss: 0.6349 - val_accuracy: 0.6464\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6056 - accuracy: 0.6899 - val_loss: 0.6355 - val_accuracy: 0.6455\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6037 - accuracy: 0.6930 - val_loss: 0.6323 - val_accuracy: 0.6480\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6027 - accuracy: 0.6930 - val_loss: 0.6313 - val_accuracy: 0.6488\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6011 - accuracy: 0.6927 - val_loss: 0.6335 - val_accuracy: 0.6458\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5998 - accuracy: 0.6943 - val_loss: 0.6307 - val_accuracy: 0.6498\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.5980 - accuracy: 0.6948 - val_loss: 0.6335 - val_accuracy: 0.6457\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 701us/step - loss: 0.5963 - accuracy: 0.6972 - val_loss: 0.6305 - val_accuracy: 0.6489\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5952 - accuracy: 0.7001 - val_loss: 0.6288 - val_accuracy: 0.6499\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5932 - accuracy: 0.7012 - val_loss: 0.6193 - val_accuracy: 0.6608\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5918 - accuracy: 0.7010 - val_loss: 0.6258 - val_accuracy: 0.6510\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5899 - accuracy: 0.7022 - val_loss: 0.6294 - val_accuracy: 0.6464\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5892 - accuracy: 0.7028 - val_loss: 0.6222 - val_accuracy: 0.6538\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5866 - accuracy: 0.7059 - val_loss: 0.6225 - val_accuracy: 0.6535\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.7336 - accuracy: 0.5112 - val_loss: 0.7924 - val_accuracy: 0.1407\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.7088 - accuracy: 0.4999 - val_loss: 0.7399 - val_accuracy: 0.1686\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.7040 - accuracy: 0.5016 - val_loss: 0.7266 - val_accuracy: 0.1908\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6993 - accuracy: 0.5124 - val_loss: 0.7202 - val_accuracy: 0.2131\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6964 - accuracy: 0.5231 - val_loss: 0.7179 - val_accuracy: 0.2414\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6941 - accuracy: 0.5272 - val_loss: 0.7141 - val_accuracy: 0.2862\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6906 - accuracy: 0.5377 - val_loss: 0.7111 - val_accuracy: 0.3306\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6888 - accuracy: 0.5444 - val_loss: 0.7099 - val_accuracy: 0.3569\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6850 - accuracy: 0.5569 - val_loss: 0.7068 - val_accuracy: 0.4002\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6827 - accuracy: 0.5598 - val_loss: 0.7057 - val_accuracy: 0.4183\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6807 - accuracy: 0.5678 - val_loss: 0.7036 - val_accuracy: 0.4421\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6772 - accuracy: 0.5789 - val_loss: 0.7003 - val_accuracy: 0.4692\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6746 - accuracy: 0.5834 - val_loss: 0.6974 - val_accuracy: 0.4911\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6718 - accuracy: 0.5922 - val_loss: 0.6963 - val_accuracy: 0.5016\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6693 - accuracy: 0.6013 - val_loss: 0.6955 - val_accuracy: 0.5092\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6662 - accuracy: 0.6056 - val_loss: 0.6929 - val_accuracy: 0.5242\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6641 - accuracy: 0.6140 - val_loss: 0.6873 - val_accuracy: 0.5544\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6605 - accuracy: 0.6226 - val_loss: 0.6845 - val_accuracy: 0.5696\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6583 - accuracy: 0.6287 - val_loss: 0.6822 - val_accuracy: 0.5774\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6560 - accuracy: 0.6293 - val_loss: 0.6787 - val_accuracy: 0.5907\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6531 - accuracy: 0.6356 - val_loss: 0.6776 - val_accuracy: 0.5923\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6508 - accuracy: 0.6403 - val_loss: 0.6734 - val_accuracy: 0.6027\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6479 - accuracy: 0.6479 - val_loss: 0.6713 - val_accuracy: 0.6058\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6461 - accuracy: 0.6482 - val_loss: 0.6692 - val_accuracy: 0.6090\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6419 - accuracy: 0.6564 - val_loss: 0.6637 - val_accuracy: 0.6204\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6395 - accuracy: 0.6610 - val_loss: 0.6578 - val_accuracy: 0.6337\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6376 - accuracy: 0.6640 - val_loss: 0.6578 - val_accuracy: 0.6301\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6351 - accuracy: 0.6640 - val_loss: 0.6534 - val_accuracy: 0.6380\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6319 - accuracy: 0.6697 - val_loss: 0.6511 - val_accuracy: 0.6409\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6308 - accuracy: 0.6678 - val_loss: 0.6533 - val_accuracy: 0.6324\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6257 - accuracy: 0.6746 - val_loss: 0.6492 - val_accuracy: 0.6405\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6253 - accuracy: 0.6751 - val_loss: 0.6479 - val_accuracy: 0.6404\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6215 - accuracy: 0.6788 - val_loss: 0.6440 - val_accuracy: 0.6479\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6199 - accuracy: 0.6799 - val_loss: 0.6399 - val_accuracy: 0.6560\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6164 - accuracy: 0.6837 - val_loss: 0.6371 - val_accuracy: 0.6586\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6142 - accuracy: 0.6858 - val_loss: 0.6360 - val_accuracy: 0.6568\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6115 - accuracy: 0.6889 - val_loss: 0.6353 - val_accuracy: 0.6556\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6089 - accuracy: 0.6907 - val_loss: 0.6275 - val_accuracy: 0.6688\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6058 - accuracy: 0.6934 - val_loss: 0.6285 - val_accuracy: 0.6637\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6045 - accuracy: 0.6915 - val_loss: 0.6256 - val_accuracy: 0.6669\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6021 - accuracy: 0.6950 - val_loss: 0.6297 - val_accuracy: 0.6580\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5992 - accuracy: 0.6972 - val_loss: 0.6262 - val_accuracy: 0.6621\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5966 - accuracy: 0.6997 - val_loss: 0.6204 - val_accuracy: 0.6687\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5946 - accuracy: 0.7002 - val_loss: 0.6192 - val_accuracy: 0.6690\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5926 - accuracy: 0.7025 - val_loss: 0.6213 - val_accuracy: 0.6631\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5901 - accuracy: 0.7035 - val_loss: 0.6153 - val_accuracy: 0.6713\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5884 - accuracy: 0.7034 - val_loss: 0.6142 - val_accuracy: 0.6708\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.5856 - accuracy: 0.7082 - val_loss: 0.6139 - val_accuracy: 0.6697\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5837 - accuracy: 0.7065 - val_loss: 0.6089 - val_accuracy: 0.6739\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5823 - accuracy: 0.7088 - val_loss: 0.6109 - val_accuracy: 0.6712\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.7142 - accuracy: 0.5034 - val_loss: 0.7209 - val_accuracy: 0.3409\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.7073 - accuracy: 0.5147 - val_loss: 0.7169 - val_accuracy: 0.3573\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6986 - accuracy: 0.5351 - val_loss: 0.7040 - val_accuracy: 0.4225\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6933 - accuracy: 0.5410 - val_loss: 0.7013 - val_accuracy: 0.4454\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6872 - accuracy: 0.5558 - val_loss: 0.6954 - val_accuracy: 0.4910\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6803 - accuracy: 0.5699 - val_loss: 0.6894 - val_accuracy: 0.5248\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6774 - accuracy: 0.5734 - val_loss: 0.6907 - val_accuracy: 0.5214\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6717 - accuracy: 0.5848 - val_loss: 0.6871 - val_accuracy: 0.5391\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6689 - accuracy: 0.5932 - val_loss: 0.6822 - val_accuracy: 0.5579\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6643 - accuracy: 0.6025 - val_loss: 0.6828 - val_accuracy: 0.5565\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6603 - accuracy: 0.6128 - val_loss: 0.6759 - val_accuracy: 0.5795\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6565 - accuracy: 0.6169 - val_loss: 0.6755 - val_accuracy: 0.5778\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6528 - accuracy: 0.6214 - val_loss: 0.6709 - val_accuracy: 0.5866\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6505 - accuracy: 0.6257 - val_loss: 0.6658 - val_accuracy: 0.5976\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6461 - accuracy: 0.6339 - val_loss: 0.6638 - val_accuracy: 0.6032\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6432 - accuracy: 0.6351 - val_loss: 0.6602 - val_accuracy: 0.6105\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6403 - accuracy: 0.6419 - val_loss: 0.6528 - val_accuracy: 0.6214\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6367 - accuracy: 0.6465 - val_loss: 0.6501 - val_accuracy: 0.6234\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6343 - accuracy: 0.6499 - val_loss: 0.6476 - val_accuracy: 0.6271\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6305 - accuracy: 0.6538 - val_loss: 0.6457 - val_accuracy: 0.6290\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6279 - accuracy: 0.6567 - val_loss: 0.6441 - val_accuracy: 0.6300\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6253 - accuracy: 0.6596 - val_loss: 0.6406 - val_accuracy: 0.6344\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6228 - accuracy: 0.6619 - val_loss: 0.6454 - val_accuracy: 0.6280\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6208 - accuracy: 0.6614 - val_loss: 0.6391 - val_accuracy: 0.6353\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6193 - accuracy: 0.6661 - val_loss: 0.6322 - val_accuracy: 0.6436\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 699us/step - loss: 0.6173 - accuracy: 0.6659 - val_loss: 0.6367 - val_accuracy: 0.6370\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6148 - accuracy: 0.6667 - val_loss: 0.6330 - val_accuracy: 0.6407\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6119 - accuracy: 0.6721 - val_loss: 0.6360 - val_accuracy: 0.6361\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.6100 - accuracy: 0.6729 - val_loss: 0.6271 - val_accuracy: 0.6480\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6079 - accuracy: 0.6743 - val_loss: 0.6273 - val_accuracy: 0.6461\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6063 - accuracy: 0.6753 - val_loss: 0.6247 - val_accuracy: 0.6502\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6045 - accuracy: 0.6764 - val_loss: 0.6217 - val_accuracy: 0.6540\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6031 - accuracy: 0.6776 - val_loss: 0.6217 - val_accuracy: 0.6531\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.6009 - accuracy: 0.6807 - val_loss: 0.6221 - val_accuracy: 0.6513\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6004 - accuracy: 0.6813 - val_loss: 0.6199 - val_accuracy: 0.6543\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5965 - accuracy: 0.6848 - val_loss: 0.6236 - val_accuracy: 0.6478\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5964 - accuracy: 0.6831 - val_loss: 0.6175 - val_accuracy: 0.6551\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5936 - accuracy: 0.6877 - val_loss: 0.6184 - val_accuracy: 0.6534\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5927 - accuracy: 0.6863 - val_loss: 0.6271 - val_accuracy: 0.6388\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5913 - accuracy: 0.6904 - val_loss: 0.6206 - val_accuracy: 0.6472\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 483us/step - loss: 0.5892 - accuracy: 0.6906 - val_loss: 0.6142 - val_accuracy: 0.6554\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5891 - accuracy: 0.6898 - val_loss: 0.6115 - val_accuracy: 0.6586\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5872 - accuracy: 0.6908 - val_loss: 0.6100 - val_accuracy: 0.6594\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5859 - accuracy: 0.6928 - val_loss: 0.6142 - val_accuracy: 0.6537\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5839 - accuracy: 0.6942 - val_loss: 0.6132 - val_accuracy: 0.6544\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5821 - accuracy: 0.6974 - val_loss: 0.6090 - val_accuracy: 0.6590\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5815 - accuracy: 0.6958 - val_loss: 0.6168 - val_accuracy: 0.6495\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5796 - accuracy: 0.6982 - val_loss: 0.6147 - val_accuracy: 0.6510\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5784 - accuracy: 0.7002 - val_loss: 0.6098 - val_accuracy: 0.6574\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5791 - accuracy: 0.6980 - val_loss: 0.6158 - val_accuracy: 0.6497\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.7164 - accuracy: 0.5073 - val_loss: 0.7454 - val_accuracy: 0.3350\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.7017 - accuracy: 0.5118 - val_loss: 0.7187 - val_accuracy: 0.4695\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6952 - accuracy: 0.5258 - val_loss: 0.7132 - val_accuracy: 0.5071\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6901 - accuracy: 0.5385 - val_loss: 0.7057 - val_accuracy: 0.5352\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6854 - accuracy: 0.5516 - val_loss: 0.6994 - val_accuracy: 0.5584\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6810 - accuracy: 0.5631 - val_loss: 0.6990 - val_accuracy: 0.5602\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6758 - accuracy: 0.5747 - val_loss: 0.6980 - val_accuracy: 0.5616\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6719 - accuracy: 0.5839 - val_loss: 0.6935 - val_accuracy: 0.5712\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6695 - accuracy: 0.5895 - val_loss: 0.6916 - val_accuracy: 0.5748\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6661 - accuracy: 0.5981 - val_loss: 0.6846 - val_accuracy: 0.5883\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6632 - accuracy: 0.6042 - val_loss: 0.6853 - val_accuracy: 0.5869\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6596 - accuracy: 0.6104 - val_loss: 0.6817 - val_accuracy: 0.5957\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6566 - accuracy: 0.6180 - val_loss: 0.6789 - val_accuracy: 0.6012\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6545 - accuracy: 0.6174 - val_loss: 0.6760 - val_accuracy: 0.6080\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6522 - accuracy: 0.6245 - val_loss: 0.6764 - val_accuracy: 0.6056\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6496 - accuracy: 0.6272 - val_loss: 0.6723 - val_accuracy: 0.6123\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6476 - accuracy: 0.6316 - val_loss: 0.6738 - val_accuracy: 0.6096\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.6448 - accuracy: 0.6383 - val_loss: 0.6699 - val_accuracy: 0.6141\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6420 - accuracy: 0.6388 - val_loss: 0.6658 - val_accuracy: 0.6194\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6401 - accuracy: 0.6434 - val_loss: 0.6640 - val_accuracy: 0.6214\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6384 - accuracy: 0.6456 - val_loss: 0.6645 - val_accuracy: 0.6198\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6355 - accuracy: 0.6503 - val_loss: 0.6614 - val_accuracy: 0.6222\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6337 - accuracy: 0.6517 - val_loss: 0.6580 - val_accuracy: 0.6268\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6311 - accuracy: 0.6555 - val_loss: 0.6591 - val_accuracy: 0.6231\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6301 - accuracy: 0.6580 - val_loss: 0.6588 - val_accuracy: 0.6236\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6277 - accuracy: 0.6603 - val_loss: 0.6538 - val_accuracy: 0.6286\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6250 - accuracy: 0.6627 - val_loss: 0.6518 - val_accuracy: 0.6319\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6247 - accuracy: 0.6629 - val_loss: 0.6531 - val_accuracy: 0.6286\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6225 - accuracy: 0.6675 - val_loss: 0.6478 - val_accuracy: 0.6354\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.6200 - accuracy: 0.6693 - val_loss: 0.6467 - val_accuracy: 0.6356\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6183 - accuracy: 0.6711 - val_loss: 0.6480 - val_accuracy: 0.6344\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6168 - accuracy: 0.6707 - val_loss: 0.6447 - val_accuracy: 0.6357\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6150 - accuracy: 0.6735 - val_loss: 0.6449 - val_accuracy: 0.6349\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6134 - accuracy: 0.6756 - val_loss: 0.6383 - val_accuracy: 0.6426\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6123 - accuracy: 0.6757 - val_loss: 0.6411 - val_accuracy: 0.6374\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6107 - accuracy: 0.6788 - val_loss: 0.6389 - val_accuracy: 0.6391\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6087 - accuracy: 0.6801 - val_loss: 0.6369 - val_accuracy: 0.6416\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6080 - accuracy: 0.6819 - val_loss: 0.6357 - val_accuracy: 0.6425\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6057 - accuracy: 0.6820 - val_loss: 0.6376 - val_accuracy: 0.6388\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6049 - accuracy: 0.6828 - val_loss: 0.6311 - val_accuracy: 0.6478\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6023 - accuracy: 0.6852 - val_loss: 0.6347 - val_accuracy: 0.6402\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6013 - accuracy: 0.6868 - val_loss: 0.6317 - val_accuracy: 0.6450\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5991 - accuracy: 0.6877 - val_loss: 0.6328 - val_accuracy: 0.6428\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.5972 - accuracy: 0.6903 - val_loss: 0.6293 - val_accuracy: 0.6493\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5968 - accuracy: 0.6896 - val_loss: 0.6299 - val_accuracy: 0.6459\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5950 - accuracy: 0.6926 - val_loss: 0.6246 - val_accuracy: 0.6532\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5949 - accuracy: 0.6934 - val_loss: 0.6233 - val_accuracy: 0.6533\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5929 - accuracy: 0.6936 - val_loss: 0.6249 - val_accuracy: 0.6499\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.5921 - accuracy: 0.6942 - val_loss: 0.6203 - val_accuracy: 0.6544\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5903 - accuracy: 0.6972 - val_loss: 0.6266 - val_accuracy: 0.6469\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.7325 - accuracy: 0.5057 - val_loss: 0.7113 - val_accuracy: 0.4529\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.7121 - accuracy: 0.5210 - val_loss: 0.7151 - val_accuracy: 0.4497\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.7049 - accuracy: 0.5325 - val_loss: 0.7143 - val_accuracy: 0.4714\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6955 - accuracy: 0.5477 - val_loss: 0.7052 - val_accuracy: 0.5183\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6922 - accuracy: 0.5519 - val_loss: 0.7077 - val_accuracy: 0.5041\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6864 - accuracy: 0.5643 - val_loss: 0.7006 - val_accuracy: 0.5307\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6810 - accuracy: 0.5702 - val_loss: 0.7001 - val_accuracy: 0.5311\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6773 - accuracy: 0.5816 - val_loss: 0.6912 - val_accuracy: 0.5576\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6728 - accuracy: 0.5914 - val_loss: 0.6897 - val_accuracy: 0.5598\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6690 - accuracy: 0.5950 - val_loss: 0.6893 - val_accuracy: 0.5591\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6661 - accuracy: 0.6033 - val_loss: 0.6840 - val_accuracy: 0.5727\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6612 - accuracy: 0.6126 - val_loss: 0.6815 - val_accuracy: 0.5812\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6584 - accuracy: 0.6180 - val_loss: 0.6796 - val_accuracy: 0.5876\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6555 - accuracy: 0.6232 - val_loss: 0.6773 - val_accuracy: 0.5915\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6521 - accuracy: 0.6290 - val_loss: 0.6769 - val_accuracy: 0.5925\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6485 - accuracy: 0.6354 - val_loss: 0.6730 - val_accuracy: 0.6016\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6456 - accuracy: 0.6391 - val_loss: 0.6687 - val_accuracy: 0.6101\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.6429 - accuracy: 0.6444 - val_loss: 0.6653 - val_accuracy: 0.6134\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6401 - accuracy: 0.6460 - val_loss: 0.6656 - val_accuracy: 0.6111\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 482us/step - loss: 0.6372 - accuracy: 0.6535 - val_loss: 0.6652 - val_accuracy: 0.6102\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6342 - accuracy: 0.6570 - val_loss: 0.6642 - val_accuracy: 0.6099\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 481us/step - loss: 0.6323 - accuracy: 0.6596 - val_loss: 0.6560 - val_accuracy: 0.6201\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 469us/step - loss: 0.6296 - accuracy: 0.6618 - val_loss: 0.6554 - val_accuracy: 0.6189\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6256 - accuracy: 0.6673 - val_loss: 0.6462 - val_accuracy: 0.6355\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6232 - accuracy: 0.6691 - val_loss: 0.6515 - val_accuracy: 0.6208\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6218 - accuracy: 0.6708 - val_loss: 0.6490 - val_accuracy: 0.6240\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6203 - accuracy: 0.6720 - val_loss: 0.6448 - val_accuracy: 0.6293\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 475us/step - loss: 0.6171 - accuracy: 0.6752 - val_loss: 0.6424 - val_accuracy: 0.6330\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6139 - accuracy: 0.6789 - val_loss: 0.6404 - val_accuracy: 0.6352\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6116 - accuracy: 0.6815 - val_loss: 0.6393 - val_accuracy: 0.6363\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6100 - accuracy: 0.6806 - val_loss: 0.6402 - val_accuracy: 0.6329\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6092 - accuracy: 0.6808 - val_loss: 0.6366 - val_accuracy: 0.6397\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 471us/step - loss: 0.6058 - accuracy: 0.6855 - val_loss: 0.6331 - val_accuracy: 0.6454\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6040 - accuracy: 0.6878 - val_loss: 0.6287 - val_accuracy: 0.6528\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6017 - accuracy: 0.6884 - val_loss: 0.6288 - val_accuracy: 0.6501\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 479us/step - loss: 0.5998 - accuracy: 0.6890 - val_loss: 0.6271 - val_accuracy: 0.6513\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5970 - accuracy: 0.6928 - val_loss: 0.6297 - val_accuracy: 0.6460\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5965 - accuracy: 0.6932 - val_loss: 0.6314 - val_accuracy: 0.6417\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 472us/step - loss: 0.5948 - accuracy: 0.6923 - val_loss: 0.6247 - val_accuracy: 0.6509\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5928 - accuracy: 0.6960 - val_loss: 0.6241 - val_accuracy: 0.6513\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5911 - accuracy: 0.6952 - val_loss: 0.6248 - val_accuracy: 0.6483\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5897 - accuracy: 0.6984 - val_loss: 0.6223 - val_accuracy: 0.6521\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.5870 - accuracy: 0.6999 - val_loss: 0.6248 - val_accuracy: 0.6476\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5863 - accuracy: 0.7014 - val_loss: 0.6248 - val_accuracy: 0.6468\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5850 - accuracy: 0.7007 - val_loss: 0.6190 - val_accuracy: 0.6543\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5820 - accuracy: 0.7009 - val_loss: 0.6164 - val_accuracy: 0.6568\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5802 - accuracy: 0.7054 - val_loss: 0.6174 - val_accuracy: 0.6552\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5795 - accuracy: 0.7051 - val_loss: 0.6143 - val_accuracy: 0.6574\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5779 - accuracy: 0.7061 - val_loss: 0.6204 - val_accuracy: 0.6481\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5761 - accuracy: 0.7084 - val_loss: 0.6147 - val_accuracy: 0.6551\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6983 - accuracy: 0.5326 - val_loss: 0.7002 - val_accuracy: 0.4826\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6888 - accuracy: 0.5473 - val_loss: 0.6970 - val_accuracy: 0.5050\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6827 - accuracy: 0.5636 - val_loss: 0.6964 - val_accuracy: 0.5100\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6760 - accuracy: 0.5744 - val_loss: 0.6889 - val_accuracy: 0.5495\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6710 - accuracy: 0.5818 - val_loss: 0.6819 - val_accuracy: 0.5741\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6673 - accuracy: 0.5918 - val_loss: 0.6765 - val_accuracy: 0.5914\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6626 - accuracy: 0.5992 - val_loss: 0.6722 - val_accuracy: 0.6038\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6588 - accuracy: 0.6051 - val_loss: 0.6712 - val_accuracy: 0.6074\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6533 - accuracy: 0.6167 - val_loss: 0.6618 - val_accuracy: 0.6216\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6502 - accuracy: 0.6194 - val_loss: 0.6648 - val_accuracy: 0.6148\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6459 - accuracy: 0.6256 - val_loss: 0.6619 - val_accuracy: 0.6189\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6435 - accuracy: 0.6311 - val_loss: 0.6553 - val_accuracy: 0.6255\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6399 - accuracy: 0.6356 - val_loss: 0.6558 - val_accuracy: 0.6249\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6372 - accuracy: 0.6390 - val_loss: 0.6493 - val_accuracy: 0.6328\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6334 - accuracy: 0.6437 - val_loss: 0.6473 - val_accuracy: 0.6356\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6311 - accuracy: 0.6474 - val_loss: 0.6442 - val_accuracy: 0.6397\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6294 - accuracy: 0.6497 - val_loss: 0.6424 - val_accuracy: 0.6425\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6259 - accuracy: 0.6522 - val_loss: 0.6421 - val_accuracy: 0.6415\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6236 - accuracy: 0.6549 - val_loss: 0.6402 - val_accuracy: 0.6451\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - -1s -417us/step - loss: 0.6207 - accuracy: 0.6591 - val_loss: 0.6385 - val_accuracy: 0.6449\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6193 - accuracy: 0.6581 - val_loss: 0.6352 - val_accuracy: 0.6464\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6164 - accuracy: 0.6635 - val_loss: 0.6298 - val_accuracy: 0.6523\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6134 - accuracy: 0.6680 - val_loss: 0.6340 - val_accuracy: 0.6453\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6115 - accuracy: 0.6685 - val_loss: 0.6311 - val_accuracy: 0.6465\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6102 - accuracy: 0.6685 - val_loss: 0.6290 - val_accuracy: 0.6474\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6090 - accuracy: 0.6700 - val_loss: 0.6274 - val_accuracy: 0.6477\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6058 - accuracy: 0.6743 - val_loss: 0.6262 - val_accuracy: 0.6472\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6044 - accuracy: 0.6737 - val_loss: 0.6227 - val_accuracy: 0.6492\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6030 - accuracy: 0.6752 - val_loss: 0.6254 - val_accuracy: 0.6455\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6007 - accuracy: 0.6792 - val_loss: 0.6276 - val_accuracy: 0.6413\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5979 - accuracy: 0.6830 - val_loss: 0.6215 - val_accuracy: 0.6464\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5968 - accuracy: 0.6805 - val_loss: 0.6169 - val_accuracy: 0.6534\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5951 - accuracy: 0.6835 - val_loss: 0.6098 - val_accuracy: 0.6646\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5943 - accuracy: 0.6840 - val_loss: 0.6162 - val_accuracy: 0.6548\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5920 - accuracy: 0.6868 - val_loss: 0.6173 - val_accuracy: 0.6514\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5908 - accuracy: 0.6885 - val_loss: 0.6182 - val_accuracy: 0.6501\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5886 - accuracy: 0.6901 - val_loss: 0.6165 - val_accuracy: 0.6524\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5881 - accuracy: 0.6925 - val_loss: 0.6139 - val_accuracy: 0.6555\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5864 - accuracy: 0.6915 - val_loss: 0.6175 - val_accuracy: 0.6495\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5837 - accuracy: 0.6952 - val_loss: 0.6088 - val_accuracy: 0.6610\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5836 - accuracy: 0.6950 - val_loss: 0.6117 - val_accuracy: 0.6566\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.5817 - accuracy: 0.6995 - val_loss: 0.6143 - val_accuracy: 0.6531\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5807 - accuracy: 0.6968 - val_loss: 0.6119 - val_accuracy: 0.6551\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5783 - accuracy: 0.7003 - val_loss: 0.6151 - val_accuracy: 0.6518\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.5775 - accuracy: 0.7021 - val_loss: 0.6166 - val_accuracy: 0.6499\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5751 - accuracy: 0.7027 - val_loss: 0.6054 - val_accuracy: 0.6624\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5741 - accuracy: 0.7039 - val_loss: 0.6062 - val_accuracy: 0.6619\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5738 - accuracy: 0.7049 - val_loss: 0.6054 - val_accuracy: 0.6629\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5712 - accuracy: 0.7075 - val_loss: 0.6096 - val_accuracy: 0.6571\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.5706 - accuracy: 0.7088 - val_loss: 0.6045 - val_accuracy: 0.6631\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.7047 - accuracy: 0.5104 - val_loss: 0.7099 - val_accuracy: 0.4372\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6987 - accuracy: 0.5204 - val_loss: 0.7069 - val_accuracy: 0.4686\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6944 - accuracy: 0.5275 - val_loss: 0.6975 - val_accuracy: 0.5215\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6896 - accuracy: 0.5391 - val_loss: 0.6940 - val_accuracy: 0.5373\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6854 - accuracy: 0.5481 - val_loss: 0.6937 - val_accuracy: 0.5388\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6837 - accuracy: 0.5529 - val_loss: 0.6894 - val_accuracy: 0.5520\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6794 - accuracy: 0.5638 - val_loss: 0.6870 - val_accuracy: 0.5601\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6757 - accuracy: 0.5731 - val_loss: 0.6849 - val_accuracy: 0.5671\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6732 - accuracy: 0.5803 - val_loss: 0.6838 - val_accuracy: 0.5712\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.6686 - accuracy: 0.5887 - val_loss: 0.6783 - val_accuracy: 0.5828\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6670 - accuracy: 0.5915 - val_loss: 0.6749 - val_accuracy: 0.5915\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6637 - accuracy: 0.6000 - val_loss: 0.6733 - val_accuracy: 0.5946\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6621 - accuracy: 0.6033 - val_loss: 0.6699 - val_accuracy: 0.6019\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6593 - accuracy: 0.6098 - val_loss: 0.6663 - val_accuracy: 0.6068\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6573 - accuracy: 0.6152 - val_loss: 0.6677 - val_accuracy: 0.6023\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6544 - accuracy: 0.6202 - val_loss: 0.6618 - val_accuracy: 0.6132\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6522 - accuracy: 0.6238 - val_loss: 0.6647 - val_accuracy: 0.6059\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6509 - accuracy: 0.6268 - val_loss: 0.6594 - val_accuracy: 0.6144\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6479 - accuracy: 0.6312 - val_loss: 0.6563 - val_accuracy: 0.6196\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6462 - accuracy: 0.6339 - val_loss: 0.6594 - val_accuracy: 0.6117\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6435 - accuracy: 0.6397 - val_loss: 0.6554 - val_accuracy: 0.6197\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6414 - accuracy: 0.6421 - val_loss: 0.6556 - val_accuracy: 0.6186\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6384 - accuracy: 0.6473 - val_loss: 0.6538 - val_accuracy: 0.6206\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6365 - accuracy: 0.6492 - val_loss: 0.6428 - val_accuracy: 0.6391\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6355 - accuracy: 0.6502 - val_loss: 0.6472 - val_accuracy: 0.6284\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6329 - accuracy: 0.6555 - val_loss: 0.6438 - val_accuracy: 0.6334\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6317 - accuracy: 0.6538 - val_loss: 0.6393 - val_accuracy: 0.6403\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6293 - accuracy: 0.6585 - val_loss: 0.6441 - val_accuracy: 0.6313\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6277 - accuracy: 0.6591 - val_loss: 0.6422 - val_accuracy: 0.6326\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6254 - accuracy: 0.6640 - val_loss: 0.6341 - val_accuracy: 0.6435\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6245 - accuracy: 0.6641 - val_loss: 0.6424 - val_accuracy: 0.6299\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6233 - accuracy: 0.6658 - val_loss: 0.6345 - val_accuracy: 0.6413\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6206 - accuracy: 0.6700 - val_loss: 0.6385 - val_accuracy: 0.6360\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6189 - accuracy: 0.6700 - val_loss: 0.6370 - val_accuracy: 0.6366\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6185 - accuracy: 0.6706 - val_loss: 0.6354 - val_accuracy: 0.6376\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6156 - accuracy: 0.6709 - val_loss: 0.6351 - val_accuracy: 0.6372\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6146 - accuracy: 0.6732 - val_loss: 0.6353 - val_accuracy: 0.6371\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6135 - accuracy: 0.6748 - val_loss: 0.6272 - val_accuracy: 0.6450\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6111 - accuracy: 0.6784 - val_loss: 0.6334 - val_accuracy: 0.6376\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6094 - accuracy: 0.6796 - val_loss: 0.6311 - val_accuracy: 0.6382\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6091 - accuracy: 0.6791 - val_loss: 0.6288 - val_accuracy: 0.6407\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6069 - accuracy: 0.6804 - val_loss: 0.6303 - val_accuracy: 0.6378\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6051 - accuracy: 0.6806 - val_loss: 0.6281 - val_accuracy: 0.6410\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6037 - accuracy: 0.6828 - val_loss: 0.6332 - val_accuracy: 0.6345\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6019 - accuracy: 0.6840 - val_loss: 0.6289 - val_accuracy: 0.6398\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6008 - accuracy: 0.6874 - val_loss: 0.6243 - val_accuracy: 0.6430\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6000 - accuracy: 0.6865 - val_loss: 0.6272 - val_accuracy: 0.6389\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5975 - accuracy: 0.6890 - val_loss: 0.6236 - val_accuracy: 0.6427\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.5961 - accuracy: 0.6903 - val_loss: 0.6238 - val_accuracy: 0.6414\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5949 - accuracy: 0.6911 - val_loss: 0.6268 - val_accuracy: 0.6377\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.7235 - accuracy: 0.5178 - val_loss: 0.6783 - val_accuracy: 0.5958\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6882 - accuracy: 0.5561 - val_loss: 0.7100 - val_accuracy: 0.4411\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6823 - accuracy: 0.5705 - val_loss: 0.7118 - val_accuracy: 0.4395\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6782 - accuracy: 0.5815 - val_loss: 0.7046 - val_accuracy: 0.4602\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6720 - accuracy: 0.5979 - val_loss: 0.6984 - val_accuracy: 0.4835\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.6670 - accuracy: 0.6091 - val_loss: 0.6963 - val_accuracy: 0.4858\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6630 - accuracy: 0.6174 - val_loss: 0.6880 - val_accuracy: 0.5077\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6593 - accuracy: 0.6254 - val_loss: 0.6813 - val_accuracy: 0.5203\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6544 - accuracy: 0.6342 - val_loss: 0.6837 - val_accuracy: 0.5170\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6508 - accuracy: 0.6421 - val_loss: 0.6790 - val_accuracy: 0.5257\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6473 - accuracy: 0.6480 - val_loss: 0.6709 - val_accuracy: 0.5464\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 480us/step - loss: 0.6431 - accuracy: 0.6536 - val_loss: 0.6728 - val_accuracy: 0.5414\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6408 - accuracy: 0.6599 - val_loss: 0.6637 - val_accuracy: 0.5633\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.6365 - accuracy: 0.6635 - val_loss: 0.6646 - val_accuracy: 0.5593\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6348 - accuracy: 0.6628 - val_loss: 0.6671 - val_accuracy: 0.5540\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6316 - accuracy: 0.6671 - val_loss: 0.6590 - val_accuracy: 0.5768\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6286 - accuracy: 0.6710 - val_loss: 0.6576 - val_accuracy: 0.5783\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6257 - accuracy: 0.6751 - val_loss: 0.6537 - val_accuracy: 0.5855\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6232 - accuracy: 0.6791 - val_loss: 0.6537 - val_accuracy: 0.5855\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.6210 - accuracy: 0.6779 - val_loss: 0.6475 - val_accuracy: 0.5985\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6186 - accuracy: 0.6809 - val_loss: 0.6514 - val_accuracy: 0.5887\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6157 - accuracy: 0.6826 - val_loss: 0.6460 - val_accuracy: 0.6007\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6131 - accuracy: 0.6863 - val_loss: 0.6469 - val_accuracy: 0.5977\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.6114 - accuracy: 0.6874 - val_loss: 0.6369 - val_accuracy: 0.6156\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.6095 - accuracy: 0.6890 - val_loss: 0.6413 - val_accuracy: 0.6089\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6072 - accuracy: 0.6894 - val_loss: 0.6422 - val_accuracy: 0.6074\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6042 - accuracy: 0.6941 - val_loss: 0.6368 - val_accuracy: 0.6144\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6024 - accuracy: 0.6927 - val_loss: 0.6306 - val_accuracy: 0.6205\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6003 - accuracy: 0.6958 - val_loss: 0.6297 - val_accuracy: 0.6210\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5984 - accuracy: 0.6964 - val_loss: 0.6278 - val_accuracy: 0.6235\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5963 - accuracy: 0.6986 - val_loss: 0.6345 - val_accuracy: 0.6146\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5945 - accuracy: 0.6984 - val_loss: 0.6280 - val_accuracy: 0.6226\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5922 - accuracy: 0.7005 - val_loss: 0.6251 - val_accuracy: 0.6256\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5916 - accuracy: 0.7000 - val_loss: 0.6272 - val_accuracy: 0.6221\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5883 - accuracy: 0.7043 - val_loss: 0.6230 - val_accuracy: 0.6269\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5870 - accuracy: 0.7036 - val_loss: 0.6269 - val_accuracy: 0.6207\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5846 - accuracy: 0.7062 - val_loss: 0.6180 - val_accuracy: 0.6328\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5836 - accuracy: 0.7062 - val_loss: 0.6220 - val_accuracy: 0.6271\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5819 - accuracy: 0.7065 - val_loss: 0.6197 - val_accuracy: 0.6300\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5800 - accuracy: 0.7072 - val_loss: 0.6096 - val_accuracy: 0.6382\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5789 - accuracy: 0.7093 - val_loss: 0.6141 - val_accuracy: 0.6326\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.5772 - accuracy: 0.7111 - val_loss: 0.6131 - val_accuracy: 0.6326\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5763 - accuracy: 0.7106 - val_loss: 0.6160 - val_accuracy: 0.6291\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5739 - accuracy: 0.7122 - val_loss: 0.6168 - val_accuracy: 0.6279\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5743 - accuracy: 0.7117 - val_loss: 0.6077 - val_accuracy: 0.6388\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5715 - accuracy: 0.7144 - val_loss: 0.6188 - val_accuracy: 0.6251\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5706 - accuracy: 0.7137 - val_loss: 0.6133 - val_accuracy: 0.6303\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5687 - accuracy: 0.7155 - val_loss: 0.6154 - val_accuracy: 0.6270\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5684 - accuracy: 0.7150 - val_loss: 0.6110 - val_accuracy: 0.6344\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5671 - accuracy: 0.7149 - val_loss: 0.6098 - val_accuracy: 0.6349\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.7119 - accuracy: 0.5166 - val_loss: 0.7125 - val_accuracy: 0.4829\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6973 - accuracy: 0.5365 - val_loss: 0.7051 - val_accuracy: 0.5262\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.6890 - accuracy: 0.5530 - val_loss: 0.6920 - val_accuracy: 0.5666\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6790 - accuracy: 0.5713 - val_loss: 0.6875 - val_accuracy: 0.5758\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6708 - accuracy: 0.5873 - val_loss: 0.6779 - val_accuracy: 0.5927\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6626 - accuracy: 0.6015 - val_loss: 0.6724 - val_accuracy: 0.6038\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.6554 - accuracy: 0.6145 - val_loss: 0.6703 - val_accuracy: 0.6057\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6509 - accuracy: 0.6248 - val_loss: 0.6704 - val_accuracy: 0.6068\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6462 - accuracy: 0.6321 - val_loss: 0.6647 - val_accuracy: 0.6148\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6422 - accuracy: 0.6364 - val_loss: 0.6606 - val_accuracy: 0.6228\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6396 - accuracy: 0.6424 - val_loss: 0.6607 - val_accuracy: 0.6226\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6356 - accuracy: 0.6473 - val_loss: 0.6579 - val_accuracy: 0.6286\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6338 - accuracy: 0.6520 - val_loss: 0.6546 - val_accuracy: 0.6321\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.6302 - accuracy: 0.6533 - val_loss: 0.6507 - val_accuracy: 0.6364\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6267 - accuracy: 0.6609 - val_loss: 0.6471 - val_accuracy: 0.6417\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6244 - accuracy: 0.6634 - val_loss: 0.6504 - val_accuracy: 0.6355\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6225 - accuracy: 0.6638 - val_loss: 0.6444 - val_accuracy: 0.6459\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6186 - accuracy: 0.6698 - val_loss: 0.6503 - val_accuracy: 0.6344\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6163 - accuracy: 0.6697 - val_loss: 0.6393 - val_accuracy: 0.6517\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6140 - accuracy: 0.6733 - val_loss: 0.6375 - val_accuracy: 0.6529\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6111 - accuracy: 0.6767 - val_loss: 0.6356 - val_accuracy: 0.6542\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6082 - accuracy: 0.6795 - val_loss: 0.6389 - val_accuracy: 0.6477\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6062 - accuracy: 0.6821 - val_loss: 0.6275 - val_accuracy: 0.6612\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6051 - accuracy: 0.6842 - val_loss: 0.6376 - val_accuracy: 0.6448\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6025 - accuracy: 0.6884 - val_loss: 0.6337 - val_accuracy: 0.6475\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6001 - accuracy: 0.6867 - val_loss: 0.6331 - val_accuracy: 0.6460\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.5979 - accuracy: 0.6892 - val_loss: 0.6332 - val_accuracy: 0.6443\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5966 - accuracy: 0.6905 - val_loss: 0.6268 - val_accuracy: 0.6500\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.5947 - accuracy: 0.6921 - val_loss: 0.6251 - val_accuracy: 0.6504\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5924 - accuracy: 0.6919 - val_loss: 0.6274 - val_accuracy: 0.6477\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5904 - accuracy: 0.6946 - val_loss: 0.6252 - val_accuracy: 0.6493\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.5879 - accuracy: 0.6991 - val_loss: 0.6234 - val_accuracy: 0.6506\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5872 - accuracy: 0.6970 - val_loss: 0.6238 - val_accuracy: 0.6488\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5849 - accuracy: 0.7008 - val_loss: 0.6240 - val_accuracy: 0.6476\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5823 - accuracy: 0.7029 - val_loss: 0.6214 - val_accuracy: 0.6497\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.5807 - accuracy: 0.7051 - val_loss: 0.6207 - val_accuracy: 0.6509\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.5806 - accuracy: 0.7017 - val_loss: 0.6125 - val_accuracy: 0.6626\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5783 - accuracy: 0.7062 - val_loss: 0.6143 - val_accuracy: 0.6601\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.5767 - accuracy: 0.7056 - val_loss: 0.6266 - val_accuracy: 0.6413\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.5738 - accuracy: 0.7082 - val_loss: 0.6091 - val_accuracy: 0.6653\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5738 - accuracy: 0.7070 - val_loss: 0.6102 - val_accuracy: 0.6644\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5720 - accuracy: 0.7093 - val_loss: 0.6111 - val_accuracy: 0.6617\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5701 - accuracy: 0.7107 - val_loss: 0.6109 - val_accuracy: 0.6623\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5680 - accuracy: 0.7134 - val_loss: 0.6163 - val_accuracy: 0.6566\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5668 - accuracy: 0.7137 - val_loss: 0.6129 - val_accuracy: 0.6610\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5667 - accuracy: 0.7111 - val_loss: 0.6152 - val_accuracy: 0.6585\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5639 - accuracy: 0.7155 - val_loss: 0.6153 - val_accuracy: 0.6581\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5626 - accuracy: 0.7170 - val_loss: 0.6085 - val_accuracy: 0.6657\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.5617 - accuracy: 0.7165 - val_loss: 0.6128 - val_accuracy: 0.6597\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.5601 - accuracy: 0.7179 - val_loss: 0.6137 - val_accuracy: 0.6586\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.6668 - accuracy: 0.5938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.7282 - accuracy: 0.4471 - val_loss: 0.7653 - val_accuracy: 0.1647\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.7197 - accuracy: 0.4591 - val_loss: 0.7597 - val_accuracy: 0.1467\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.7138 - accuracy: 0.4685 - val_loss: 0.7505 - val_accuracy: 0.1438\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.7071 - accuracy: 0.4839 - val_loss: 0.7476 - val_accuracy: 0.1347\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.7019 - accuracy: 0.4989 - val_loss: 0.7436 - val_accuracy: 0.1326\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6968 - accuracy: 0.5116 - val_loss: 0.7376 - val_accuracy: 0.1413\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6933 - accuracy: 0.5220 - val_loss: 0.7341 - val_accuracy: 0.1530\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6886 - accuracy: 0.5403 - val_loss: 0.7297 - val_accuracy: 0.1849\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6852 - accuracy: 0.5519 - val_loss: 0.7261 - val_accuracy: 0.2307\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.6815 - accuracy: 0.5685 - val_loss: 0.7199 - val_accuracy: 0.2799\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6772 - accuracy: 0.5858 - val_loss: 0.7152 - val_accuracy: 0.3531\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6744 - accuracy: 0.5961 - val_loss: 0.7115 - val_accuracy: 0.4006\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6711 - accuracy: 0.6082 - val_loss: 0.7095 - val_accuracy: 0.4205\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6674 - accuracy: 0.6205 - val_loss: 0.7044 - val_accuracy: 0.4534\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6643 - accuracy: 0.6302 - val_loss: 0.7037 - val_accuracy: 0.4672\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6610 - accuracy: 0.6352 - val_loss: 0.6977 - val_accuracy: 0.5045\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6574 - accuracy: 0.6464 - val_loss: 0.6979 - val_accuracy: 0.5113\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6549 - accuracy: 0.6490 - val_loss: 0.6913 - val_accuracy: 0.5401\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6515 - accuracy: 0.6568 - val_loss: 0.6899 - val_accuracy: 0.5448\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6488 - accuracy: 0.6609 - val_loss: 0.6852 - val_accuracy: 0.5603\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6452 - accuracy: 0.6675 - val_loss: 0.6844 - val_accuracy: 0.5612\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6435 - accuracy: 0.6677 - val_loss: 0.6834 - val_accuracy: 0.5632\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6412 - accuracy: 0.6676 - val_loss: 0.6773 - val_accuracy: 0.5770\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6375 - accuracy: 0.6716 - val_loss: 0.6764 - val_accuracy: 0.5778\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6358 - accuracy: 0.6754 - val_loss: 0.6750 - val_accuracy: 0.5804\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6334 - accuracy: 0.6762 - val_loss: 0.6700 - val_accuracy: 0.5905\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6307 - accuracy: 0.6777 - val_loss: 0.6686 - val_accuracy: 0.5921\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6276 - accuracy: 0.6811 - val_loss: 0.6674 - val_accuracy: 0.5948\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6266 - accuracy: 0.6818 - val_loss: 0.6645 - val_accuracy: 0.5998\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6238 - accuracy: 0.6829 - val_loss: 0.6598 - val_accuracy: 0.6078\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6214 - accuracy: 0.6850 - val_loss: 0.6600 - val_accuracy: 0.6062\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6186 - accuracy: 0.6868 - val_loss: 0.6530 - val_accuracy: 0.6166\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6167 - accuracy: 0.6886 - val_loss: 0.6535 - val_accuracy: 0.6147\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6143 - accuracy: 0.6908 - val_loss: 0.6525 - val_accuracy: 0.6156\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6127 - accuracy: 0.6894 - val_loss: 0.6521 - val_accuracy: 0.6154\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6100 - accuracy: 0.6911 - val_loss: 0.6477 - val_accuracy: 0.6216\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6089 - accuracy: 0.6922 - val_loss: 0.6405 - val_accuracy: 0.6295\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6066 - accuracy: 0.6939 - val_loss: 0.6444 - val_accuracy: 0.6242\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.6050 - accuracy: 0.6957 - val_loss: 0.6427 - val_accuracy: 0.6258\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6032 - accuracy: 0.6948 - val_loss: 0.6430 - val_accuracy: 0.6245\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6016 - accuracy: 0.6960 - val_loss: 0.6367 - val_accuracy: 0.6318\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5998 - accuracy: 0.6969 - val_loss: 0.6393 - val_accuracy: 0.6278\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5976 - accuracy: 0.6997 - val_loss: 0.6419 - val_accuracy: 0.6240\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5961 - accuracy: 0.6982 - val_loss: 0.6366 - val_accuracy: 0.6288\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5942 - accuracy: 0.6991 - val_loss: 0.6321 - val_accuracy: 0.6331\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5920 - accuracy: 0.7029 - val_loss: 0.6358 - val_accuracy: 0.6284\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5917 - accuracy: 0.7000 - val_loss: 0.6337 - val_accuracy: 0.6304\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5898 - accuracy: 0.7036 - val_loss: 0.6325 - val_accuracy: 0.6309\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5887 - accuracy: 0.7031 - val_loss: 0.6249 - val_accuracy: 0.6375\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5888 - accuracy: 0.7017 - val_loss: 0.6245 - val_accuracy: 0.6372\n"
     ]
    }
   ],
   "source": [
    "# 3. Vary noise_multiplier\n",
    "results_noise_multiplier = {}\n",
    "eps_noise_multiplier = {}\n",
    "for noise in noise_multiplier_values:\n",
    "    print(f\"\\nTraining model with noise_multiplier={noise}...\")\n",
    "    n = len(X_train_filtered)\n",
    "    eps = compute_privacy_budget(n, default_batch_size, noise, epochs, delta)\n",
    "    results = run_iterations(\n",
    "        X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "        batch_size=default_batch_size, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "        num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=noise\n",
    "    )\n",
    "    results_noise_multiplier[noise] = compute_statistics(results)\n",
    "    eps_noise_multiplier[noise] = eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a13266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to 'results/CDP_parameter_results.csv'\n",
      "\n",
      "Results (Averages):\n",
      "                No DP (mean)  batch_size=16 (=0.85) (mean)  \\\n",
      "ROC AUC              0.9012                         0.7561   \n",
      "Accuracy             0.8100                         0.5498   \n",
      "Precision            0.3662                         0.1820   \n",
      "Recall               0.8524                         0.8145   \n",
      "F1 Score             0.5122                         0.2975   \n",
      "Type I Error         0.1957                         0.4852   \n",
      "Type II Error        0.1476                         0.1855   \n",
      "\n",
      "               batch_size=32 (=1.06) (mean)  batch_size=64 (=1.42) (mean)  \\\n",
      "ROC AUC                               0.7304                         0.7057   \n",
      "Accuracy                              0.4832                         0.3686   \n",
      "Precision                             0.1654                         0.1465   \n",
      "Recall                                0.8438                         0.9051   \n",
      "F1 Score                              0.2765                         0.2520   \n",
      "Type I Error                          0.5645                         0.7025   \n",
      "Type II Error                         0.1562                         0.0949   \n",
      "\n",
      "               batch_size=128 (=2.01) (mean)  \\\n",
      "ROC AUC                                0.6830   \n",
      "Accuracy                               0.2541   \n",
      "Precision                              0.1327   \n",
      "Recall                                 0.9560   \n",
      "F1 Score                               0.2326   \n",
      "Type I Error                           0.8389   \n",
      "Type II Error                          0.0440   \n",
      "\n",
      "               sample_size_ratio=1 (=1.06) (mean)  \\\n",
      "ROC AUC                                     0.7284   \n",
      "Accuracy                                    0.4747   \n",
      "Precision                                   0.1635   \n",
      "Recall                                      0.8466   \n",
      "F1 Score                                    0.2740   \n",
      "Type I Error                                0.5746   \n",
      "Type II Error                               0.1534   \n",
      "\n",
      "               sample_size_ratio=0.5 (=1.42) (mean)  \\\n",
      "ROC AUC                                       0.7070   \n",
      "Accuracy                                      0.3912   \n",
      "Precision                                     0.1497   \n",
      "Recall                                        0.8926   \n",
      "F1 Score                                      0.2562   \n",
      "Type I Error                                  0.6752   \n",
      "Type II Error                                 0.1074   \n",
      "\n",
      "               sample_size_ratio=0.1 (=3.30) (mean)  \\\n",
      "ROC AUC                                       0.6341   \n",
      "Accuracy                                      0.1279   \n",
      "Precision                                     0.1181   \n",
      "Recall                                        0.9972   \n",
      "F1 Score                                      0.2111   \n",
      "Type I Error                                  0.9873   \n",
      "Type II Error                                 0.0028   \n",
      "\n",
      "               sample_size_ratio=0.05 (=4.84) (mean)  \\\n",
      "ROC AUC                                        0.6088   \n",
      "Accuracy                                       0.1176   \n",
      "Precision                                      0.1171   \n",
      "Recall                                         0.9998   \n",
      "F1 Score                                       0.2096   \n",
      "Type I Error                                   0.9992   \n",
      "Type II Error                                  0.0002   \n",
      "\n",
      "               noise_multiplier=1.1 (=1.06) (mean)  \\\n",
      "ROC AUC                                      0.7319   \n",
      "Accuracy                                     0.4923   \n",
      "Precision                                    0.1673   \n",
      "Recall                                       0.8391   \n",
      "F1 Score                                     0.2790   \n",
      "Type I Error                                 0.5536   \n",
      "Type II Error                                0.1609   \n",
      "\n",
      "               noise_multiplier=1.5 (=0.64) (mean)  \\\n",
      "ROC AUC                                      0.7350   \n",
      "Accuracy                                     0.5008   \n",
      "Precision                                    0.1695   \n",
      "Recall                                       0.8365   \n",
      "F1 Score                                     0.2819   \n",
      "Type I Error                                 0.5437   \n",
      "Type II Error                                0.1635   \n",
      "\n",
      "               noise_multiplier=2.0 (=0.45) (mean)  \\\n",
      "ROC AUC                                      0.7339   \n",
      "Accuracy                                     0.4897   \n",
      "Precision                                    0.1671   \n",
      "Recall                                       0.8426   \n",
      "F1 Score                                     0.2788   \n",
      "Type I Error                                 0.5570   \n",
      "Type II Error                                0.1574   \n",
      "\n",
      "               noise_multiplier=2.5 (=0.35) (mean)  \n",
      "ROC AUC                                      0.7299  \n",
      "Accuracy                                     0.4765  \n",
      "Precision                                    0.1643  \n",
      "Recall                                       0.8491  \n",
      "F1 Score                                     0.2752  \n",
      "Type I Error                                 0.5729  \n",
      "Type II Error                                0.1509  \n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "results_stats = {\n",
    "    'batch_size': results_batch_size,\n",
    "    'sample_size_ratio': results_sample_size,\n",
    "    'noise_multiplier': results_noise_multiplier\n",
    "}\n",
    "data = {}\n",
    "\n",
    "# Add results for non-DP model\n",
    "data['No DP (mean)'] = results_no_dp_stats['mean']\n",
    "data['No DP (min)'] = results_no_dp_stats['min']\n",
    "data['No DP (max)'] = results_no_dp_stats['max']\n",
    "\n",
    "# Add results for DP models\n",
    "for param, stats_dict in results_stats.items():\n",
    "    for value, stats in stats_dict.items():\n",
    "        # Get the corresponding epsilon value based on the parameter\n",
    "        if param == 'batch_size':\n",
    "            eps = eps_batch_size.get(value, float('inf'))\n",
    "        elif param == 'sample_size_ratio':\n",
    "            eps = eps_sample_size.get(value, float('inf'))\n",
    "        else:  # noise_multiplier\n",
    "            eps = eps_noise_multiplier.get(value, float('inf'))\n",
    "        \n",
    "        # Format the model name with epsilon (if finite)\n",
    "        model = f'{param}={value} (={eps:.2f})' if eps != float('inf') else f'{param}={value}'\n",
    "        data[f'{model} (mean)'] = stats['mean']\n",
    "        data[f'{model} (min)'] = stats['min']\n",
    "        data[f'{model} (max)'] = stats['max']\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(data).round(4)\n",
    "results_df.to_csv('results/CDP_parameter_results.csv')\n",
    "print(\"\\nResults saved to 'results/CDP_parameter_results.csv'\")\n",
    "print(\"\\nResults (Averages):\\n\", results_df[[col for col in results_df.columns if 'mean' in col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a322053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot results, including No DP model\n",
    "def plot_parameter_results(stats_dict, eps_dict, param_name, colors, no_dp_stats):\n",
    "    metrics = list(no_dp_stats['mean'].keys())\n",
    "    values = list(stats_dict.keys())\n",
    "    n_metrics = len(metrics)\n",
    "    n_values = len(values) + 1  # +1 for No DP\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x_positions = np.arange(n_metrics)\n",
    "    \n",
    "    # Plot No DP model\n",
    "    means = []\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    for metric in metrics:\n",
    "        means.append(no_dp_stats['mean'][metric])\n",
    "        mins.append(no_dp_stats['min'][metric])\n",
    "        maxs.append(no_dp_stats['max'][metric])\n",
    "    \n",
    "    plt.scatter(x_positions + (0 - (n_values-1)/2) * 0.15, means, \n",
    "                color=colors[0], label='No DP', s=100)\n",
    "    for metric_idx in range(n_metrics):\n",
    "        plt.vlines(x_positions[metric_idx] + (0 - (n_values-1)/2) * 0.15, \n",
    "                   mins[metric_idx], maxs[metric_idx], \n",
    "                   color=colors[0], linestyle='-', linewidth=1)\n",
    "    \n",
    "    # Plot results varying the parameter\n",
    "    for value_idx, value in enumerate(values, start=1):\n",
    "        means = []\n",
    "        mins = []\n",
    "        maxs = []\n",
    "        for metric in metrics:\n",
    "            means.append(stats_dict[value]['mean'][metric])\n",
    "            mins.append(stats_dict[value]['min'][metric])\n",
    "            maxs.append(stats_dict[value]['max'][metric])\n",
    "        \n",
    "        plt.scatter(x_positions + (value_idx - (n_values-1)/2) * 0.15, means, \n",
    "                    color=colors[value_idx], label=f'{param_name}={value} (={eps_dict[value]:.2f})', s=100)\n",
    "        for metric_idx in range(n_metrics):\n",
    "            plt.vlines(x_positions[metric_idx] + (value_idx - (n_values-1)/2) * 0.15, \n",
    "                       mins[metric_idx], maxs[metric_idx], \n",
    "                       color=colors[value_idx], linestyle='-', linewidth=1)\n",
    "    \n",
    "    plt.xticks(x_positions, metrics, rotation=45)\n",
    "    plt.title(f'Effect of Varying {param_name} on Model Performance')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(title=f'{param_name} Values', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/Effect_of_{param_name}_with_No_DP.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93697b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define colors\n",
    "colors = ['#0d4e9e', '#ffc520', '#7b9ca0', '#242624', '#cc7b4f']\n",
    "\n",
    "# Plot results\n",
    "plot_parameter_results(results_batch_size, eps_batch_size, 'batch_size', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_sample_size, eps_sample_size, 'sample_size_ratio', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_noise_multiplier, eps_noise_multiplier, 'noise_multiplier', colors, results_no_dp_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
