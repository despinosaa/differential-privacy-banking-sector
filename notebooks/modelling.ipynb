{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\"><strong>Differential Privacy Strategies for Data Analytics in the Banking Sector</strong></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  Universidad de los Andes<br>\n",
    "  Author: Daniela Espinosa 202022615<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve,precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "from boruta import BorutaPy\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 33)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/danie/OneDrive/Documentos/1 UNIANDES/10 semestre/Tesis/differential-privacy-banking-sector/data/processed/bank-processed.csv', sep=',')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['y'])\n",
    "Y = data['y']\n",
    "\n",
    "numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'y']\n",
    "\n",
    "scale = StandardScaler()\n",
    "X[numeric_cols] = scale.fit_transform(X[numeric_cols])\n",
    "\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Unbalanced Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39922</td>\n",
       "      <td>88.30152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5289</td>\n",
       "      <td>11.69848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   percent\n",
       "0  39922  88.30152\n",
       "1   5289  11.69848"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = pd.DataFrame(Y.value_counts())\n",
    "stat['percent'] = stat/Y.shape[0]*100\n",
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resample, Y_resample = smote_enn.fit_resample(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39280</td>\n",
       "      <td>54.51013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32780</td>\n",
       "      <td>45.48987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   percent\n",
       "1  39280  54.51013\n",
       "0  32780  45.48987"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat2 = pd.DataFrame(Y_resample.value_counts())\n",
    "stat2['percent'] = stat2/Y_resample.shape[0]*100\n",
    "stat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Selection**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boruta Algorithm (wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t32\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t32\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t32\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t32\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t32\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t32\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t32\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t28\n",
      "Tentative: \t4\n",
      "Rejected: \t0\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t28\n",
      "Tentative: \t4\n",
      "Rejected: \t0\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t28\n",
      "Tentative: \t4\n",
      "Rejected: \t0\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t28\n",
      "Tentative: \t4\n",
      "Rejected: \t0\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t29\n",
      "Tentative: \t3\n",
      "Rejected: \t0\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t29\n",
      "Tentative: \t3\n",
      "Rejected: \t0\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t29\n",
      "Tentative: \t3\n",
      "Rejected: \t0\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t29\n",
      "Tentative: \t3\n",
      "Rejected: \t0\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t1\n",
      "Rejected: \t0\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t0\n",
      "Rejected: \t0\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t0\n",
      "Rejected: \t0\n"
     ]
    }
   ],
   "source": [
    "# Asegurar que X_resample sea un DataFrame con nombres de columnas\n",
    "if not isinstance(X_resample, pd.DataFrame):\n",
    "    X_resample = pd.DataFrame(X_resample, columns=X.columns)\n",
    "\n",
    "# Asegurar que Y_resample sea un array 1D\n",
    "if not isinstance(Y_resample, pd.Series):\n",
    "    Y_resample = pd.Series(Y_resample)\n",
    "\n",
    "# Inicializar el modelo de XGBoost asegurando compatibilidad\n",
    "rf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Configurar BorutaPy\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42)\n",
    "\n",
    "# Ajustar BorutaPy asegurando que Y_resample sea 1D\n",
    "feat_selector.fit(X_resample.values, Y_resample.values.ravel())\n",
    "\n",
    "# Obtener las características seleccionadas\n",
    "X_filtered = X.columns[feat_selector.support_].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VERSIÓN INICIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logit...\n",
      "Best params for Logit: {'C': 100}\n",
      "Best ROC AUC score for Logit: 0.967235\n",
      "Training Lasso...\n",
      "Best params for Lasso: {'C': 100, 'penalty': 'l1'}\n",
      "Best ROC AUC score for Lasso: 0.967235\n",
      "Training Ridge...\n",
      "Best params for Ridge: {'C': 100, 'penalty': 'l2'}\n",
      "Best ROC AUC score for Ridge: 0.967235\n",
      "Training ElasticNet...\n",
      "Best params for ElasticNet: {'C': 100, 'l1_ratio': 0.1, 'penalty': 'elasticnet'}\n",
      "Best ROC AUC score for ElasticNet: 0.967235\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for XGBoost: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200}\n",
      "Best ROC AUC score for XGBoost: 0.997685\n",
      "Training RandomForest...\n",
      "Best params for RandomForest: {'max_depth': None, 'n_estimators': 200}\n",
      "Best ROC AUC score for RandomForest: 0.997219\n",
      "\n",
      "Best overall model: XGBoost with ROC AUC: 0.997685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir modelos\n",
    "models = { \n",
    "    'Logit': LogisticRegression(solver='saga', max_iter=10000, penalty='l2'),\n",
    "    'Lasso': LogisticRegression(solver='saga', max_iter=10000),\n",
    "    'Ridge': LogisticRegression(solver='saga', max_iter=10000),\n",
    "    'ElasticNet': LogisticRegression(solver='saga', max_iter=10000),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, random_state=42),  # <-- Cambio aquí\n",
    "    'RandomForest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Definir hiperparámetros\n",
    "param_grids = {\n",
    "    'Logit': {'C': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Lasso': {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1']},\n",
    "    'Ridge': {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l2']},\n",
    "    'ElasticNet': {'C': [0.01, 0.1, 1, 10, 100], 'l1_ratio': [0.1, 0.5, 0.9], 'penalty': ['elasticnet']},\n",
    "    'XGBoost': {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
    "}\n",
    "\n",
    "# Validación cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_models = {}\n",
    "best_scores = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f'Training {model_name}...')\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grids[model_name], cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    # Si es XGBoost, pasamos `eval_metric` dentro de `fit()`\n",
    "    if model_name == \"XGBoost\":\n",
    "        grid_search.fit(X_resample[X_filtered], Y_resample.ravel(), eval_metric='logloss')\n",
    "    else:\n",
    "        grid_search.fit(X_resample[X_filtered], Y_resample.ravel())\n",
    "    \n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    best_scores[model_name] = grid_search.best_score_\n",
    "    \n",
    "    print(f'Best params for {model_name}: {grid_search.best_params_}')\n",
    "    print(f'Best ROC AUC score for {model_name}: {grid_search.best_score_:.6f}')\n",
    "\n",
    "# Seleccionar el mejor modelo basado en la métrica ROC AUC\n",
    "best_model_name = max(best_scores, key=best_scores.get)\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f'\\nBest overall model: {best_model_name} with ROC AUC: {best_scores[best_model_name]:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9661616720115006\n",
      "Precision: 0.8897715988083416\n",
      "Recall: 0.8212648945921174\n",
      "F1 Score: 0.8541468064823642\n",
      "Confusion Matrix:\n",
      "[[7841  111]\n",
      " [ 195  896]]\n",
      "Error Tipo 1 (Falsos Positivos): 111\n",
      "Error Tipo 2 (Falsos Negativos): 195\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del mejor modelo\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test_split[X_filtered])\n",
    "\n",
    "# Calcular métricas adicionales\n",
    "accuracy = accuracy_score(y_test_split, y_pred)\n",
    "precision = precision_score(y_test_split, y_pred)\n",
    "recall = recall_score(y_test_split, y_pred)\n",
    "f1 = f1_score(y_test_split, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test_split, y_pred)\n",
    "false_positive = conf_matrix[0][1]  # Error Tipo 1\n",
    "false_negative = conf_matrix[1][0]  # Error Tipo 2\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Error Tipo 1 (Falsos Positivos): {false_positive}')\n",
    "print(f'Error Tipo 2 (Falsos Negativos): {false_negative}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VERSIÓN MEJORADA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos clásicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos clásicos\n",
    "models = { \n",
    "    'Logit': LogisticRegression(solver='saga', max_iter=10000, penalty='l2'),\n",
    "    'Lasso': LogisticRegression(solver='saga', max_iter=10000, penalty='l1'),\n",
    "    'Ridge': LogisticRegression(solver='saga', max_iter=10000, penalty='l2'),\n",
    "    'ElasticNet': LogisticRegression(solver='saga', max_iter=10000, penalty='elasticnet', l1_ratio=0.5),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Definir hiperparámetros\n",
    "param_grids = {\n",
    "    'Logit': {'C': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Lasso': {'C': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Ridge': {'C': [0.01, 0.1, 1, 10, 100]},\n",
    "    'ElasticNet': {'C': [0.01, 0.1, 1, 10, 100], 'l1_ratio': [0.1, 0.5, 0.9]},\n",
    "    'XGBoost': {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento + cross validation + metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para almacenar resultados\n",
    "results = {}\n",
    "\n",
    "plt.figure(figsize=(10, 8))  # Inicializar la figura para las curvas ROC\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f'Training {model_name}...')\n",
    "    \n",
    "    # Hacer búsqueda de hiperparámetros\n",
    "    grid_search = GridSearchCV(model, param_grids[model_name], cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    if model_name == \"XGBoost\":\n",
    "        grid_search.fit(X_resample[X_filtered], Y_resample.ravel(), eval_metric='logloss')\n",
    "    else:\n",
    "        grid_search.fit(X_resample[X_filtered], Y_resample.ravel())\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Obtener predicciones finales con el mejor modelo\n",
    "    y_pred = cross_val_predict(best_model, X_resample[X_filtered], Y_resample.ravel(), cv=5, n_jobs=-1)\n",
    "    y_prob = cross_val_predict(best_model, X_resample[X_filtered], Y_resample.ravel(), cv=5, method=\"predict_proba\")[:, 1]\n",
    "    \n",
    "    # Calcular matriz de confusión y errores tipo I y II\n",
    "    conf_matrix = confusion_matrix(Y_resample, y_pred)\n",
    "    actual_negatives = conf_matrix[0].sum()\n",
    "    actual_positives = conf_matrix[1].sum()\n",
    "\n",
    "    false_positive = conf_matrix[0][1]  \n",
    "    false_negative = conf_matrix[1][0]  \n",
    "\n",
    "    false_positive_pct = (false_positive / actual_negatives) * 100\n",
    "    false_negative_pct = (false_negative / actual_positives) * 100\n",
    "\n",
    "    # Guardar métricas\n",
    "    results[model_name] = {\n",
    "        'Best Params': grid_search.best_params_,\n",
    "        'Accuracy': accuracy_score(Y_resample, y_pred),\n",
    "        'Precision': precision_score(Y_resample, y_pred),\n",
    "        'Recall': recall_score(Y_resample, y_pred),\n",
    "        'F1 Score': f1_score(Y_resample, y_pred),\n",
    "        'Type I Error': false_positive_pct,\n",
    "        'Type II Error': false_negative_pct,\n",
    "        'ROC AUC': roc_auc_score(Y_resample, y_prob)\n",
    "    }\n",
    "\n",
    "    # Curva ROC\n",
    "    fpr, tpr, _ = roc_curve(Y_resample, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {results[model_name]['ROC AUC']:.2f})\")\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Models ROC curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar tabla de métricas\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def build_model(input_shape, learning_rate=0.001, dropout_rate=0.2, units=64, activation='relu', hidden_layers=2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation=activation, input_shape=(input_shape,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(hidden_layers - 1):  \n",
    "        model.add(Dense(units, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "# Parámetros de la red neuronal\n",
    "params = {'learning_rate': 0.001, 'dropout_rate': 0.2, 'units': 128, 'activation': 'relu', 'hidden_layers': 3}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "X_resample_np = X_resample[X_filtered].to_numpy()\n",
    "Y_resample_np = Y_resample.to_numpy()\n",
    "\n",
    "train_losses, val_losses, train_auc, val_auc = [], [], [], []\n",
    "y_true_all, y_pred_all, y_prob_all = [], [], []\n",
    "\n",
    "for train_index, val_index in kf.split(X_resample_np):\n",
    "    X_train, X_val = X_resample_np[train_index], X_resample_np[val_index]\n",
    "    Y_train, Y_val = Y_resample_np[train_index], Y_resample_np[val_index]\n",
    "    \n",
    "    model = build_model(input_shape=X_train.shape[1], **params)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        epochs=50, batch_size=32,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    train_losses.append(history.history['loss'])\n",
    "    val_losses.append(history.history['val_loss'])\n",
    "    train_auc.append(history.history['auc'])\n",
    "    val_auc.append(history.history['val_auc'])\n",
    "\n",
    "    # Guardar predicciones en el set de validación\n",
    "    y_true_all.extend(Y_val)\n",
    "    y_pred_all.extend((model.predict(X_val) > 0.5).astype(int).ravel())\n",
    "    y_prob_all.extend(model.predict(X_val).ravel())\n",
    "\n",
    "# Convertir listas a arrays numpy\n",
    "y_true_all = np.array(y_true_all)\n",
    "y_pred_all = np.array(y_pred_all)\n",
    "y_prob_all = np.array(y_prob_all)\n",
    "\n",
    "# Calcular métricas finales en validación\n",
    "conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "actual_negatives = conf_matrix[0].sum()\n",
    "actual_positives = conf_matrix[1].sum()\n",
    "\n",
    "false_positive = conf_matrix[0][1]  \n",
    "false_negative = conf_matrix[1][0]  \n",
    "\n",
    "false_positive_pct = (false_positive / actual_negatives) * 100\n",
    "false_negative_pct = (false_negative / actual_positives) * 100\n",
    "\n",
    "roc_auc = roc_auc_score(y_true_all, y_prob_all)\n",
    "accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "precision = precision_score(y_true_all, y_pred_all)\n",
    "recall = recall_score(y_true_all, y_pred_all)\n",
    "f1 = f1_score(y_true_all, y_pred_all)\n",
    "\n",
    "# Guardar métricas en el diccionario de resultados\n",
    "results['Neural Network'] = {\n",
    "    'ROC AUC': roc_auc,\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1,\n",
    "    'Type I Error': false_positive_pct,\n",
    "    'Type II Error': false_negative_pct\n",
    "}\n",
    "\n",
    "# Graficar curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_true_all, y_prob_all)\n",
    "plt.plot(fpr, tpr, label=f\"Neural Network (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "# Graficar evolución de loss y AUC\n",
    "epochs = range(1, len(train_losses[0]) + 1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Pérdida (Loss)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, np.mean(train_losses, axis=0), 'b-', label='Training Loss')\n",
    "plt.plot(epochs, np.mean(val_losses, axis=0), 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Evolución de la Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, np.mean(train_auc, axis=0), 'b-', label='Training AUC')\n",
    "plt.plot(epochs, np.mean(val_auc, axis=0), 'r-', label='Validation AUC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Evolución del AUC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Mostrar tabla de métricas\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(df_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
