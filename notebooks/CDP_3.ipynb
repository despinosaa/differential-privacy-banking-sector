{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bfa3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58d679f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 33)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "data_path = 'C:/Users/danie/OneDrive/Documentos/1 UNIANDES/10 semestre/Tesis/differential-privacy-banking-sector/data/processed/bank-processed.csv'\n",
    "data = pd.read_csv(data_path, sep=',')\n",
    "print(data.shape)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y']\n",
    "\n",
    "# Define numeric columns\n",
    "numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Scale numeric columns\n",
    "scale = MinMaxScaler()\n",
    "X[numeric_cols] = scale.fit_transform(X[numeric_cols])\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa08b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTEENN for class balancing\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_resample, y_resample = smoteenn.fit_resample(X_train, y_train)\n",
    "X_resample = pd.DataFrame(X_resample, columns=X.columns)\n",
    "y_resample = pd.Series(y_resample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94445cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive\\Documentos\\1 UNIANDES\\10 semestre\\Tesis\\differential-privacy-banking-sector\\cdp\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 26\n"
     ]
    }
   ],
   "source": [
    "# Feature selection with BorutaPy\n",
    "rf = xgb.XGBClassifier(eval_metric='logloss')\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
    "feat_selector.fit(X_resample.values, y_resample.values.ravel())\n",
    "X_filtered = X.columns[feat_selector.support_].tolist()\n",
    "print(f\"Selected features: {len(X_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data with selected features\n",
    "X_train_filtered = X_resample[X_filtered].values\n",
    "X_test_filtered = X_test[X_filtered].values\n",
    "y_train_filtered = y_resample.values\n",
    "y_test_filtered = y_test.values\n",
    "\n",
    "# Neural network parameters\n",
    "input_size = len(X_filtered)\n",
    "hidden_units = 64\n",
    "hidden_layers = 2\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n",
    "n_iterations = 10\n",
    "l2_norm_clip = 1.0\n",
    "\n",
    "# Define parameter values to test\n",
    "batch_size_values = [16, 32, 64, 128]\n",
    "sample_size_ratio_values = [1, 0.5, 0.1, 0.05]\n",
    "target_eps_values = [0.5, 1.0, 2.0]  # Target epsilon values for better control\n",
    "\n",
    "# Fixed default values\n",
    "default_batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177d5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute privacy budget and adjust noise_multiplier\n",
    "def adjust_noise_multiplier(n, batch_size, epochs, target_eps, delta=1e-5, max_iterations=100):\n",
    "    low, high = 0.1, 10.0  # Initial range for noise_multiplier\n",
    "    for _ in range(max_iterations):\n",
    "        noise_multiplier = (low + high) / 2\n",
    "        eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "            n=n, batch_size=batch_size, noise_multiplier=noise_multiplier,\n",
    "            epochs=epochs, delta=delta\n",
    "        )[0]\n",
    "        if abs(eps - target_eps) < 0.01:  # Convergence criterion\n",
    "            return noise_multiplier, eps\n",
    "        elif eps > target_eps:\n",
    "            low = noise_multiplier\n",
    "        else:\n",
    "            high = noise_multiplier\n",
    "    return noise_multiplier, eps  # Return best approximation if not converged\n",
    "\n",
    "# Define neural network model\n",
    "def create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=False,\n",
    "                 num_microbatches=None, l2_norm_clip=l2_norm_clip, noise_multiplier=1.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation='relu', input_shape=(input_size,)))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if use_dp:\n",
    "        optimizer = DPKerasSGDOptimizer(\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "            num_microbatches=num_microbatches,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to train model\n",
    "def train_model(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=False,\n",
    "                num_microbatches=None, l2_norm_clip=l2_norm_clip, noise_multiplier=1.1):\n",
    "    model = create_model(input_size, hidden_units, hidden_layers, dropout_rate, use_dp=use_dp,\n",
    "                         num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "                         noise_multiplier=noise_multiplier)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    \n",
    "    y_pred_prob_test = model.predict(X_test, batch_size=batch_size).flatten()\n",
    "    y_pred_test = (y_pred_prob_test > 0.4).astype(int)\n",
    "    \n",
    "    return y_pred_prob_test, y_pred_test\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(y_true, y_pred, y_pred_prob):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    actual_negatives, actual_positives = conf_matrix[0].sum(), conf_matrix[1].sum()\n",
    "    false_positive_rate = conf_matrix[0][1] / actual_negatives if actual_negatives > 0 else 0\n",
    "    false_negative_rate = conf_matrix[1][0] / actual_positives if actual_positives > 0 else 0\n",
    "    return {\n",
    "        'ROC AUC': roc_auc_score(y_true, y_pred_prob),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Type I Error': false_positive_rate,\n",
    "        'Type II Error': false_negative_rate\n",
    "    }\n",
    "\n",
    "# Function to run multiple iterations\n",
    "def run_iterations(X_train, y_train, X_test, y_test, batch_size, epochs, use_dp, n_iterations,\n",
    "                   num_microbatches, l2_norm_clip, noise_multiplier):\n",
    "    results = []\n",
    "    for _ in range(n_iterations):\n",
    "        y_pred_prob_test, y_pred_test = train_model(\n",
    "            X_train, y_train, X_test, y_test, batch_size, epochs, use_dp=use_dp,\n",
    "            num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier\n",
    "        )\n",
    "        result = evaluate_model(y_test, y_pred_test, y_pred_prob_test)\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to compute statistics\n",
    "def compute_statistics(df):\n",
    "    stats = {\n",
    "        'mean': df.mean(),\n",
    "        'min': df.min(),\n",
    "        'max': df.max()\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "# Function to subsample training data\n",
    "def subsample_data(X, y, sample_size_ratio, random_state=42):\n",
    "    if sample_size_ratio >= 1.0:\n",
    "        return X, y\n",
    "    n_samples = int(len(X) * sample_size_ratio)\n",
    "    idx = np.random.choice(len(X), n_samples, replace=False)\n",
    "    return X[idx], y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa1e7982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model without DP...\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 893us/step - loss: 0.5825 - accuracy: 0.6829 - val_loss: 0.6078 - val_accuracy: 0.6684\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.4519 - accuracy: 0.7876 - val_loss: 0.5303 - val_accuracy: 0.7481\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 929us/step - loss: 0.3729 - accuracy: 0.8428 - val_loss: 0.5640 - val_accuracy: 0.7496\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 992us/step - loss: 0.3168 - accuracy: 0.8757 - val_loss: 0.5102 - val_accuracy: 0.8047\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.2889 - accuracy: 0.8883 - val_loss: 0.4939 - val_accuracy: 0.8159\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.2743 - accuracy: 0.8948 - val_loss: 0.4694 - val_accuracy: 0.8274\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.2662 - accuracy: 0.8979 - val_loss: 0.5224 - val_accuracy: 0.8038\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 815us/step - loss: 0.2608 - accuracy: 0.8989 - val_loss: 0.4646 - val_accuracy: 0.8267\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 822us/step - loss: 0.2565 - accuracy: 0.9016 - val_loss: 0.4946 - val_accuracy: 0.8129\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.2525 - accuracy: 0.9033 - val_loss: 0.4756 - val_accuracy: 0.8209\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.2487 - accuracy: 0.9044 - val_loss: 0.4868 - val_accuracy: 0.8138\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.2463 - accuracy: 0.9054 - val_loss: 0.4754 - val_accuracy: 0.8225\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 804us/step - loss: 0.2437 - accuracy: 0.9065 - val_loss: 0.4572 - val_accuracy: 0.8265\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 818us/step - loss: 0.2410 - accuracy: 0.9080 - val_loss: 0.4771 - val_accuracy: 0.8170\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.2383 - accuracy: 0.9076 - val_loss: 0.5397 - val_accuracy: 0.7942\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 813us/step - loss: 0.2368 - accuracy: 0.9097 - val_loss: 0.4989 - val_accuracy: 0.8097\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.2342 - accuracy: 0.9102 - val_loss: 0.4981 - val_accuracy: 0.8088\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.2324 - accuracy: 0.9113 - val_loss: 0.4359 - val_accuracy: 0.8343\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.2310 - accuracy: 0.9115 - val_loss: 0.4746 - val_accuracy: 0.8174\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.2286 - accuracy: 0.9121 - val_loss: 0.5160 - val_accuracy: 0.7995\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.2275 - accuracy: 0.9120 - val_loss: 0.4766 - val_accuracy: 0.8164\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.2256 - accuracy: 0.9138 - val_loss: 0.4394 - val_accuracy: 0.8325\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.2239 - accuracy: 0.9140 - val_loss: 0.4354 - val_accuracy: 0.8348\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.2229 - accuracy: 0.9136 - val_loss: 0.4521 - val_accuracy: 0.8248\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.2213 - accuracy: 0.9145 - val_loss: 0.4746 - val_accuracy: 0.8183\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.2201 - accuracy: 0.9156 - val_loss: 0.4466 - val_accuracy: 0.8308\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.2179 - accuracy: 0.9163 - val_loss: 0.4346 - val_accuracy: 0.8305\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.2174 - accuracy: 0.9159 - val_loss: 0.4640 - val_accuracy: 0.8216\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 968us/step - loss: 0.2158 - accuracy: 0.9168 - val_loss: 0.4768 - val_accuracy: 0.8188\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 812us/step - loss: 0.2151 - accuracy: 0.9176 - val_loss: 0.4610 - val_accuracy: 0.8237\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 875us/step - loss: 0.2144 - accuracy: 0.9173 - val_loss: 0.4836 - val_accuracy: 0.8143\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2128 - accuracy: 0.9168 - val_loss: 0.4671 - val_accuracy: 0.8206\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 862us/step - loss: 0.2112 - accuracy: 0.9186 - val_loss: 0.4670 - val_accuracy: 0.8225\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 823us/step - loss: 0.2116 - accuracy: 0.9180 - val_loss: 0.4630 - val_accuracy: 0.8251\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 925us/step - loss: 0.2097 - accuracy: 0.9197 - val_loss: 0.4566 - val_accuracy: 0.8236\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.2100 - accuracy: 0.9197 - val_loss: 0.4746 - val_accuracy: 0.8184\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.2082 - accuracy: 0.9193 - val_loss: 0.4482 - val_accuracy: 0.8325\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 829us/step - loss: 0.2081 - accuracy: 0.9198 - val_loss: 0.4831 - val_accuracy: 0.8195\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.2066 - accuracy: 0.9207 - val_loss: 0.4505 - val_accuracy: 0.8274\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.2057 - accuracy: 0.9215 - val_loss: 0.4609 - val_accuracy: 0.8263\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.2047 - accuracy: 0.9216 - val_loss: 0.4518 - val_accuracy: 0.8297\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.2046 - accuracy: 0.9219 - val_loss: 0.4494 - val_accuracy: 0.8303\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.2040 - accuracy: 0.9225 - val_loss: 0.4577 - val_accuracy: 0.8301\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 736us/step - loss: 0.2020 - accuracy: 0.9226 - val_loss: 0.4447 - val_accuracy: 0.8325\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 878us/step - loss: 0.2019 - accuracy: 0.9222 - val_loss: 0.4777 - val_accuracy: 0.8215\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.2015 - accuracy: 0.9228 - val_loss: 0.4612 - val_accuracy: 0.8253\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.2010 - accuracy: 0.9229 - val_loss: 0.4628 - val_accuracy: 0.8235\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.1994 - accuracy: 0.9231 - val_loss: 0.4386 - val_accuracy: 0.8358\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.1995 - accuracy: 0.9241 - val_loss: 0.4763 - val_accuracy: 0.8219\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.1990 - accuracy: 0.9244 - val_loss: 0.4513 - val_accuracy: 0.8284\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.5818 - accuracy: 0.6805 - val_loss: 0.5889 - val_accuracy: 0.6813\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.4593 - accuracy: 0.7819 - val_loss: 0.5773 - val_accuracy: 0.7109\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.3825 - accuracy: 0.8342 - val_loss: 0.4933 - val_accuracy: 0.7998\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.3256 - accuracy: 0.8712 - val_loss: 0.5049 - val_accuracy: 0.8088\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.2956 - accuracy: 0.8861 - val_loss: 0.4980 - val_accuracy: 0.8158\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.2810 - accuracy: 0.8929 - val_loss: 0.4732 - val_accuracy: 0.8259\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.2735 - accuracy: 0.8970 - val_loss: 0.4797 - val_accuracy: 0.8228\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.2671 - accuracy: 0.8988 - val_loss: 0.4738 - val_accuracy: 0.8234\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.2621 - accuracy: 0.9005 - val_loss: 0.5279 - val_accuracy: 0.8036\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.2588 - accuracy: 0.9023 - val_loss: 0.4967 - val_accuracy: 0.8146\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.2552 - accuracy: 0.9031 - val_loss: 0.5052 - val_accuracy: 0.8101\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.2520 - accuracy: 0.9045 - val_loss: 0.4710 - val_accuracy: 0.8212\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.2494 - accuracy: 0.9054 - val_loss: 0.4619 - val_accuracy: 0.8234\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.2465 - accuracy: 0.9071 - val_loss: 0.4514 - val_accuracy: 0.8299\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.2436 - accuracy: 0.9078 - val_loss: 0.4653 - val_accuracy: 0.8243\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.2412 - accuracy: 0.9081 - val_loss: 0.4713 - val_accuracy: 0.8186\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.2394 - accuracy: 0.9090 - val_loss: 0.4646 - val_accuracy: 0.8219\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.2375 - accuracy: 0.9097 - val_loss: 0.4486 - val_accuracy: 0.8262\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.2351 - accuracy: 0.9115 - val_loss: 0.4367 - val_accuracy: 0.8315\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 744us/step - loss: 0.2333 - accuracy: 0.9110 - val_loss: 0.4813 - val_accuracy: 0.8132\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.2320 - accuracy: 0.9112 - val_loss: 0.4770 - val_accuracy: 0.8130\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.2300 - accuracy: 0.9127 - val_loss: 0.5156 - val_accuracy: 0.8019\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.2286 - accuracy: 0.9131 - val_loss: 0.4580 - val_accuracy: 0.8198\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.2270 - accuracy: 0.9133 - val_loss: 0.4770 - val_accuracy: 0.8176\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.2251 - accuracy: 0.9145 - val_loss: 0.4292 - val_accuracy: 0.8332\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.2244 - accuracy: 0.9135 - val_loss: 0.4444 - val_accuracy: 0.8257\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.2228 - accuracy: 0.9156 - val_loss: 0.4689 - val_accuracy: 0.8158\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.2216 - accuracy: 0.9155 - val_loss: 0.4869 - val_accuracy: 0.8109\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.2200 - accuracy: 0.9157 - val_loss: 0.4556 - val_accuracy: 0.8240\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.2190 - accuracy: 0.9160 - val_loss: 0.4561 - val_accuracy: 0.8193\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.2179 - accuracy: 0.9163 - val_loss: 0.4901 - val_accuracy: 0.8087\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.2170 - accuracy: 0.9169 - val_loss: 0.4516 - val_accuracy: 0.8265\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.2153 - accuracy: 0.9177 - val_loss: 0.4601 - val_accuracy: 0.8230\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 854us/step - loss: 0.2145 - accuracy: 0.9177 - val_loss: 0.4618 - val_accuracy: 0.8224\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2136 - accuracy: 0.9179 - val_loss: 0.4700 - val_accuracy: 0.8226\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2123 - accuracy: 0.9184 - val_loss: 0.4574 - val_accuracy: 0.8231\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2116 - accuracy: 0.9194 - val_loss: 0.4506 - val_accuracy: 0.8246\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2113 - accuracy: 0.9200 - val_loss: 0.4181 - val_accuracy: 0.8357\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2104 - accuracy: 0.9190 - val_loss: 0.4418 - val_accuracy: 0.8270\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2096 - accuracy: 0.9204 - val_loss: 0.4881 - val_accuracy: 0.8094\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2083 - accuracy: 0.9199 - val_loss: 0.4185 - val_accuracy: 0.8391\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2075 - accuracy: 0.9203 - val_loss: 0.4271 - val_accuracy: 0.8361\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2073 - accuracy: 0.9202 - val_loss: 0.4766 - val_accuracy: 0.8160\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2068 - accuracy: 0.9201 - val_loss: 0.4264 - val_accuracy: 0.8369\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2053 - accuracy: 0.9216 - val_loss: 0.4746 - val_accuracy: 0.8215\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2053 - accuracy: 0.9206 - val_loss: 0.4861 - val_accuracy: 0.8164\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2047 - accuracy: 0.9216 - val_loss: 0.4687 - val_accuracy: 0.8236\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2042 - accuracy: 0.9215 - val_loss: 0.4502 - val_accuracy: 0.8314\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2030 - accuracy: 0.9221 - val_loss: 0.4994 - val_accuracy: 0.8167\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2029 - accuracy: 0.9226 - val_loss: 0.4788 - val_accuracy: 0.8219\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5792 - accuracy: 0.6951 - val_loss: 0.5501 - val_accuracy: 0.7136\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.4615 - accuracy: 0.7838 - val_loss: 0.5616 - val_accuracy: 0.7129\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.3842 - accuracy: 0.8354 - val_loss: 0.5324 - val_accuracy: 0.7626\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.3247 - accuracy: 0.8725 - val_loss: 0.5298 - val_accuracy: 0.7860\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2913 - accuracy: 0.8879 - val_loss: 0.4732 - val_accuracy: 0.8231\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2746 - accuracy: 0.8960 - val_loss: 0.5805 - val_accuracy: 0.7779\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2672 - accuracy: 0.8985 - val_loss: 0.4655 - val_accuracy: 0.8241\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2606 - accuracy: 0.9004 - val_loss: 0.4959 - val_accuracy: 0.8130\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2555 - accuracy: 0.9023 - val_loss: 0.4902 - val_accuracy: 0.8150\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2526 - accuracy: 0.9042 - val_loss: 0.4866 - val_accuracy: 0.8173\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2490 - accuracy: 0.9040 - val_loss: 0.4818 - val_accuracy: 0.8162\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2463 - accuracy: 0.9062 - val_loss: 0.4610 - val_accuracy: 0.8248\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2432 - accuracy: 0.9068 - val_loss: 0.4983 - val_accuracy: 0.8101\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2404 - accuracy: 0.9078 - val_loss: 0.4330 - val_accuracy: 0.8341\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2388 - accuracy: 0.9079 - val_loss: 0.4697 - val_accuracy: 0.8215\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2364 - accuracy: 0.9096 - val_loss: 0.4551 - val_accuracy: 0.8244\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2342 - accuracy: 0.9095 - val_loss: 0.4478 - val_accuracy: 0.8278\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2327 - accuracy: 0.9109 - val_loss: 0.4316 - val_accuracy: 0.8342\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2298 - accuracy: 0.9114 - val_loss: 0.4693 - val_accuracy: 0.8200\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2286 - accuracy: 0.9124 - val_loss: 0.4580 - val_accuracy: 0.8238\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2265 - accuracy: 0.9135 - val_loss: 0.4825 - val_accuracy: 0.8152\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2252 - accuracy: 0.9140 - val_loss: 0.4411 - val_accuracy: 0.8291\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2234 - accuracy: 0.9149 - val_loss: 0.4355 - val_accuracy: 0.8310\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2221 - accuracy: 0.9145 - val_loss: 0.4303 - val_accuracy: 0.8331\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2204 - accuracy: 0.9161 - val_loss: 0.4560 - val_accuracy: 0.8235\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2197 - accuracy: 0.9155 - val_loss: 0.4652 - val_accuracy: 0.8189\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2174 - accuracy: 0.9162 - val_loss: 0.5019 - val_accuracy: 0.8040\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2167 - accuracy: 0.9168 - val_loss: 0.4807 - val_accuracy: 0.8130\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2157 - accuracy: 0.9179 - val_loss: 0.4748 - val_accuracy: 0.8205\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2143 - accuracy: 0.9175 - val_loss: 0.4506 - val_accuracy: 0.8228\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2133 - accuracy: 0.9186 - val_loss: 0.5028 - val_accuracy: 0.8064\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2121 - accuracy: 0.9195 - val_loss: 0.4602 - val_accuracy: 0.8207\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2107 - accuracy: 0.9185 - val_loss: 0.4416 - val_accuracy: 0.8311\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2098 - accuracy: 0.9207 - val_loss: 0.4958 - val_accuracy: 0.8118\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2083 - accuracy: 0.9200 - val_loss: 0.4861 - val_accuracy: 0.8164\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2076 - accuracy: 0.9205 - val_loss: 0.4816 - val_accuracy: 0.8174\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2065 - accuracy: 0.9209 - val_loss: 0.4491 - val_accuracy: 0.8278\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2056 - accuracy: 0.9214 - val_loss: 0.4432 - val_accuracy: 0.8294\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2053 - accuracy: 0.9209 - val_loss: 0.4651 - val_accuracy: 0.8241\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2039 - accuracy: 0.9221 - val_loss: 0.4602 - val_accuracy: 0.8270\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2037 - accuracy: 0.9229 - val_loss: 0.4890 - val_accuracy: 0.8163\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2028 - accuracy: 0.9216 - val_loss: 0.4465 - val_accuracy: 0.8284\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2025 - accuracy: 0.9222 - val_loss: 0.4762 - val_accuracy: 0.8169\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2016 - accuracy: 0.9230 - val_loss: 0.4651 - val_accuracy: 0.8245\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2004 - accuracy: 0.9244 - val_loss: 0.4883 - val_accuracy: 0.8163\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2006 - accuracy: 0.9224 - val_loss: 0.4669 - val_accuracy: 0.8262\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.1989 - accuracy: 0.9227 - val_loss: 0.4672 - val_accuracy: 0.8276\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.1985 - accuracy: 0.9242 - val_loss: 0.4467 - val_accuracy: 0.8311\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.1980 - accuracy: 0.9241 - val_loss: 0.4609 - val_accuracy: 0.8284\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.1987 - accuracy: 0.9241 - val_loss: 0.4825 - val_accuracy: 0.8160\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.5778 - accuracy: 0.6952 - val_loss: 0.5480 - val_accuracy: 0.7145\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.4622 - accuracy: 0.7806 - val_loss: 0.5366 - val_accuracy: 0.7360\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.3954 - accuracy: 0.8243 - val_loss: 0.4691 - val_accuracy: 0.8087\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.3369 - accuracy: 0.8640 - val_loss: 0.5579 - val_accuracy: 0.7694\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.3014 - accuracy: 0.8849 - val_loss: 0.4738 - val_accuracy: 0.8232\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2824 - accuracy: 0.8932 - val_loss: 0.4880 - val_accuracy: 0.8189\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2727 - accuracy: 0.8965 - val_loss: 0.4725 - val_accuracy: 0.8242\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2671 - accuracy: 0.8979 - val_loss: 0.4635 - val_accuracy: 0.8268\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2621 - accuracy: 0.8997 - val_loss: 0.4928 - val_accuracy: 0.8151\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2591 - accuracy: 0.9014 - val_loss: 0.4272 - val_accuracy: 0.8391\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2561 - accuracy: 0.9031 - val_loss: 0.4984 - val_accuracy: 0.8132\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2524 - accuracy: 0.9033 - val_loss: 0.5097 - val_accuracy: 0.8088\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2505 - accuracy: 0.9058 - val_loss: 0.5043 - val_accuracy: 0.8090\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2479 - accuracy: 0.9053 - val_loss: 0.4459 - val_accuracy: 0.8285\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2461 - accuracy: 0.9065 - val_loss: 0.4666 - val_accuracy: 0.8221\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2442 - accuracy: 0.9068 - val_loss: 0.4305 - val_accuracy: 0.8353\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2421 - accuracy: 0.9082 - val_loss: 0.4807 - val_accuracy: 0.8170\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2413 - accuracy: 0.9084 - val_loss: 0.4378 - val_accuracy: 0.8310\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2397 - accuracy: 0.9094 - val_loss: 0.4888 - val_accuracy: 0.8134\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2381 - accuracy: 0.9088 - val_loss: 0.5340 - val_accuracy: 0.7981\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2365 - accuracy: 0.9097 - val_loss: 0.4547 - val_accuracy: 0.8251\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2349 - accuracy: 0.9103 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2340 - accuracy: 0.9100 - val_loss: 0.4505 - val_accuracy: 0.8234\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2321 - accuracy: 0.9116 - val_loss: 0.4649 - val_accuracy: 0.8216\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2311 - accuracy: 0.9104 - val_loss: 0.4642 - val_accuracy: 0.8213\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2302 - accuracy: 0.9118 - val_loss: 0.4488 - val_accuracy: 0.8249\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2285 - accuracy: 0.9120 - val_loss: 0.4776 - val_accuracy: 0.8198\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2276 - accuracy: 0.9127 - val_loss: 0.4500 - val_accuracy: 0.8296\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2269 - accuracy: 0.9126 - val_loss: 0.4904 - val_accuracy: 0.8121\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2255 - accuracy: 0.9134 - val_loss: 0.4447 - val_accuracy: 0.8267\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2248 - accuracy: 0.9138 - val_loss: 0.4508 - val_accuracy: 0.8289\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2234 - accuracy: 0.9140 - val_loss: 0.4864 - val_accuracy: 0.8140\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2227 - accuracy: 0.9141 - val_loss: 0.4557 - val_accuracy: 0.8256\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2213 - accuracy: 0.9148 - val_loss: 0.4581 - val_accuracy: 0.8255\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2208 - accuracy: 0.9150 - val_loss: 0.4405 - val_accuracy: 0.8298\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2195 - accuracy: 0.9154 - val_loss: 0.4642 - val_accuracy: 0.8274\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2188 - accuracy: 0.9158 - val_loss: 0.4648 - val_accuracy: 0.8231\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2180 - accuracy: 0.9158 - val_loss: 0.4639 - val_accuracy: 0.8245\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2168 - accuracy: 0.9167 - val_loss: 0.4662 - val_accuracy: 0.8243\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2157 - accuracy: 0.9168 - val_loss: 0.5032 - val_accuracy: 0.8085\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2150 - accuracy: 0.9171 - val_loss: 0.5049 - val_accuracy: 0.8096\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2138 - accuracy: 0.9176 - val_loss: 0.4751 - val_accuracy: 0.8238\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2133 - accuracy: 0.9177 - val_loss: 0.4583 - val_accuracy: 0.8236\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2125 - accuracy: 0.9183 - val_loss: 0.4481 - val_accuracy: 0.8295\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2117 - accuracy: 0.9187 - val_loss: 0.4659 - val_accuracy: 0.8242\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2101 - accuracy: 0.9190 - val_loss: 0.4692 - val_accuracy: 0.8186\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2100 - accuracy: 0.9185 - val_loss: 0.4656 - val_accuracy: 0.8246\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2089 - accuracy: 0.9201 - val_loss: 0.4675 - val_accuracy: 0.8269\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2085 - accuracy: 0.9195 - val_loss: 0.4386 - val_accuracy: 0.8355\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2084 - accuracy: 0.9207 - val_loss: 0.5005 - val_accuracy: 0.8137\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5674 - accuracy: 0.7111 - val_loss: 0.5795 - val_accuracy: 0.6747\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.4371 - accuracy: 0.8001 - val_loss: 0.5213 - val_accuracy: 0.7554\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.3568 - accuracy: 0.8517 - val_loss: 0.4940 - val_accuracy: 0.8013\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.3088 - accuracy: 0.8785 - val_loss: 0.5122 - val_accuracy: 0.8024\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2835 - accuracy: 0.8922 - val_loss: 0.5721 - val_accuracy: 0.7794\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.2724 - accuracy: 0.8965 - val_loss: 0.4831 - val_accuracy: 0.8220\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.2645 - accuracy: 0.8992 - val_loss: 0.5067 - val_accuracy: 0.8117\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 5s 3ms/step - loss: 0.2591 - accuracy: 0.9017 - val_loss: 0.4702 - val_accuracy: 0.8253\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.2560 - accuracy: 0.9031 - val_loss: 0.4921 - val_accuracy: 0.8162\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.2521 - accuracy: 0.9051 - val_loss: 0.5588 - val_accuracy: 0.7876\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.2484 - accuracy: 0.9047 - val_loss: 0.5217 - val_accuracy: 0.8011\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 778us/step - loss: 0.2455 - accuracy: 0.9063 - val_loss: 0.4729 - val_accuracy: 0.8214\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 843us/step - loss: 0.2433 - accuracy: 0.9073 - val_loss: 0.4669 - val_accuracy: 0.8213\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 883us/step - loss: 0.2414 - accuracy: 0.9091 - val_loss: 0.5111 - val_accuracy: 0.8029\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 808us/step - loss: 0.2396 - accuracy: 0.9091 - val_loss: 0.4830 - val_accuracy: 0.8155\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2376 - accuracy: 0.9088 - val_loss: 0.4977 - val_accuracy: 0.8085\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 4s 2ms/step - loss: 0.2354 - accuracy: 0.9105 - val_loss: 0.4574 - val_accuracy: 0.8238\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2330 - accuracy: 0.9109 - val_loss: 0.5016 - val_accuracy: 0.8063\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2316 - accuracy: 0.9111 - val_loss: 0.5093 - val_accuracy: 0.8048\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.2296 - accuracy: 0.9123 - val_loss: 0.4952 - val_accuracy: 0.8064\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2279 - accuracy: 0.9126 - val_loss: 0.4502 - val_accuracy: 0.8240\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 937us/step - loss: 0.2263 - accuracy: 0.9143 - val_loss: 0.4658 - val_accuracy: 0.8179\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 883us/step - loss: 0.2246 - accuracy: 0.9144 - val_loss: 0.4858 - val_accuracy: 0.8132\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 774us/step - loss: 0.2230 - accuracy: 0.9144 - val_loss: 0.4504 - val_accuracy: 0.8278\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 877us/step - loss: 0.2220 - accuracy: 0.9148 - val_loss: 0.4659 - val_accuracy: 0.8220\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 857us/step - loss: 0.2200 - accuracy: 0.9161 - val_loss: 0.4108 - val_accuracy: 0.8413\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 851us/step - loss: 0.2189 - accuracy: 0.9157 - val_loss: 0.4931 - val_accuracy: 0.8122\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 804us/step - loss: 0.2178 - accuracy: 0.9175 - val_loss: 0.4753 - val_accuracy: 0.8176\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 844us/step - loss: 0.2161 - accuracy: 0.9179 - val_loss: 0.4245 - val_accuracy: 0.8381\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 837us/step - loss: 0.2150 - accuracy: 0.9173 - val_loss: 0.4341 - val_accuracy: 0.8367\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 841us/step - loss: 0.2145 - accuracy: 0.9173 - val_loss: 0.4859 - val_accuracy: 0.8144\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 860us/step - loss: 0.2125 - accuracy: 0.9189 - val_loss: 0.4908 - val_accuracy: 0.8123\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 865us/step - loss: 0.2117 - accuracy: 0.9183 - val_loss: 0.4971 - val_accuracy: 0.8104\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 2s 904us/step - loss: 0.2111 - accuracy: 0.9204 - val_loss: 0.4469 - val_accuracy: 0.8291\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 2s 920us/step - loss: 0.2101 - accuracy: 0.9192 - val_loss: 0.4618 - val_accuracy: 0.8262\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.2089 - accuracy: 0.9201 - val_loss: 0.4698 - val_accuracy: 0.8220\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.2080 - accuracy: 0.9201 - val_loss: 0.4643 - val_accuracy: 0.8254\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 808us/step - loss: 0.2072 - accuracy: 0.9213 - val_loss: 0.4804 - val_accuracy: 0.8209\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.2062 - accuracy: 0.9209 - val_loss: 0.4336 - val_accuracy: 0.8356\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 782us/step - loss: 0.2058 - accuracy: 0.9219 - val_loss: 0.4381 - val_accuracy: 0.8329\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 776us/step - loss: 0.2045 - accuracy: 0.9213 - val_loss: 0.5062 - val_accuracy: 0.8077\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.2034 - accuracy: 0.9228 - val_loss: 0.4756 - val_accuracy: 0.8198\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 815us/step - loss: 0.2023 - accuracy: 0.9233 - val_loss: 0.4760 - val_accuracy: 0.8182\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.2026 - accuracy: 0.9228 - val_loss: 0.4607 - val_accuracy: 0.8262\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 816us/step - loss: 0.2002 - accuracy: 0.9236 - val_loss: 0.4532 - val_accuracy: 0.8322\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.1996 - accuracy: 0.9243 - val_loss: 0.4391 - val_accuracy: 0.8337\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 782us/step - loss: 0.1992 - accuracy: 0.9254 - val_loss: 0.4670 - val_accuracy: 0.8257\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.1997 - accuracy: 0.9235 - val_loss: 0.4692 - val_accuracy: 0.8241\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.1982 - accuracy: 0.9249 - val_loss: 0.4704 - val_accuracy: 0.8244\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.1972 - accuracy: 0.9246 - val_loss: 0.4742 - val_accuracy: 0.8254\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 827us/step - loss: 0.5698 - accuracy: 0.6979 - val_loss: 0.6168 - val_accuracy: 0.6539\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 783us/step - loss: 0.4632 - accuracy: 0.7802 - val_loss: 0.5112 - val_accuracy: 0.7544\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 785us/step - loss: 0.3794 - accuracy: 0.8375 - val_loss: 0.4541 - val_accuracy: 0.8174\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 770us/step - loss: 0.3177 - accuracy: 0.8748 - val_loss: 0.4624 - val_accuracy: 0.8209\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.2863 - accuracy: 0.8906 - val_loss: 0.4681 - val_accuracy: 0.8217\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 783us/step - loss: 0.2715 - accuracy: 0.8954 - val_loss: 0.4826 - val_accuracy: 0.8159\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.2638 - accuracy: 0.8987 - val_loss: 0.4708 - val_accuracy: 0.8185\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.2588 - accuracy: 0.9003 - val_loss: 0.4956 - val_accuracy: 0.8085\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.2538 - accuracy: 0.9035 - val_loss: 0.4849 - val_accuracy: 0.8118\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 929us/step - loss: 0.2511 - accuracy: 0.9037 - val_loss: 0.4847 - val_accuracy: 0.8117\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 851us/step - loss: 0.2481 - accuracy: 0.9049 - val_loss: 0.4412 - val_accuracy: 0.8280\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.2450 - accuracy: 0.9059 - val_loss: 0.4789 - val_accuracy: 0.8122\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.2417 - accuracy: 0.9068 - val_loss: 0.4914 - val_accuracy: 0.8053\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 831us/step - loss: 0.2389 - accuracy: 0.9088 - val_loss: 0.4721 - val_accuracy: 0.8146\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.2366 - accuracy: 0.9094 - val_loss: 0.4493 - val_accuracy: 0.8248\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.2348 - accuracy: 0.9098 - val_loss: 0.4361 - val_accuracy: 0.8283\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 797us/step - loss: 0.2321 - accuracy: 0.9117 - val_loss: 0.4590 - val_accuracy: 0.8190\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 869us/step - loss: 0.2304 - accuracy: 0.9115 - val_loss: 0.4755 - val_accuracy: 0.8151\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 844us/step - loss: 0.2273 - accuracy: 0.9125 - val_loss: 0.4881 - val_accuracy: 0.8082\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.2261 - accuracy: 0.9129 - val_loss: 0.4315 - val_accuracy: 0.8284\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.2245 - accuracy: 0.9134 - val_loss: 0.4665 - val_accuracy: 0.8180\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.2220 - accuracy: 0.9148 - val_loss: 0.4575 - val_accuracy: 0.8164\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.2200 - accuracy: 0.9157 - val_loss: 0.4408 - val_accuracy: 0.8265\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.2186 - accuracy: 0.9159 - val_loss: 0.4324 - val_accuracy: 0.8339\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.2173 - accuracy: 0.9167 - val_loss: 0.4788 - val_accuracy: 0.8110\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.2152 - accuracy: 0.9174 - val_loss: 0.4888 - val_accuracy: 0.8081\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.2136 - accuracy: 0.9181 - val_loss: 0.4752 - val_accuracy: 0.8171\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.2129 - accuracy: 0.9185 - val_loss: 0.4504 - val_accuracy: 0.8252\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.2111 - accuracy: 0.9189 - val_loss: 0.4485 - val_accuracy: 0.8237\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.2097 - accuracy: 0.9194 - val_loss: 0.4261 - val_accuracy: 0.8343\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 2s 910us/step - loss: 0.2083 - accuracy: 0.9199 - val_loss: 0.4624 - val_accuracy: 0.8203\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.2081 - accuracy: 0.9199 - val_loss: 0.4547 - val_accuracy: 0.8231\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.2068 - accuracy: 0.9200 - val_loss: 0.4554 - val_accuracy: 0.8207\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.2057 - accuracy: 0.9204 - val_loss: 0.4923 - val_accuracy: 0.8105\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.2059 - accuracy: 0.9210 - val_loss: 0.4405 - val_accuracy: 0.8286\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.2036 - accuracy: 0.9215 - val_loss: 0.4589 - val_accuracy: 0.8242\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.2029 - accuracy: 0.9221 - val_loss: 0.4674 - val_accuracy: 0.8211\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 844us/step - loss: 0.2016 - accuracy: 0.9225 - val_loss: 0.4515 - val_accuracy: 0.8236\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.2012 - accuracy: 0.9220 - val_loss: 0.4260 - val_accuracy: 0.8339\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 889us/step - loss: 0.2002 - accuracy: 0.9221 - val_loss: 0.4840 - val_accuracy: 0.8136\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 803us/step - loss: 0.1998 - accuracy: 0.9231 - val_loss: 0.4603 - val_accuracy: 0.8269\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.1996 - accuracy: 0.9230 - val_loss: 0.4277 - val_accuracy: 0.8361\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.1989 - accuracy: 0.9229 - val_loss: 0.4550 - val_accuracy: 0.8249\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.1976 - accuracy: 0.9237 - val_loss: 0.4522 - val_accuracy: 0.8256\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 846us/step - loss: 0.1969 - accuracy: 0.9235 - val_loss: 0.4530 - val_accuracy: 0.8284\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 818us/step - loss: 0.1967 - accuracy: 0.9239 - val_loss: 0.4621 - val_accuracy: 0.8272\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 811us/step - loss: 0.1958 - accuracy: 0.9256 - val_loss: 0.4868 - val_accuracy: 0.8213\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 853us/step - loss: 0.1954 - accuracy: 0.9246 - val_loss: 0.4786 - val_accuracy: 0.8193\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.1952 - accuracy: 0.9252 - val_loss: 0.4413 - val_accuracy: 0.8320\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.1935 - accuracy: 0.9255 - val_loss: 0.4498 - val_accuracy: 0.8300\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5724 - accuracy: 0.6942 - val_loss: 0.5699 - val_accuracy: 0.6949\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 983us/step - loss: 0.4526 - accuracy: 0.7856 - val_loss: 0.5454 - val_accuracy: 0.7328\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.3750 - accuracy: 0.8375 - val_loss: 0.5127 - val_accuracy: 0.7851\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 772us/step - loss: 0.3178 - accuracy: 0.8761 - val_loss: 0.4855 - val_accuracy: 0.8200\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.2887 - accuracy: 0.8897 - val_loss: 0.4781 - val_accuracy: 0.8246\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.2759 - accuracy: 0.8965 - val_loss: 0.5059 - val_accuracy: 0.8165\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.2670 - accuracy: 0.8984 - val_loss: 0.5011 - val_accuracy: 0.8161\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.2613 - accuracy: 0.9016 - val_loss: 0.4563 - val_accuracy: 0.8320\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.2559 - accuracy: 0.9026 - val_loss: 0.4861 - val_accuracy: 0.8205\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.2537 - accuracy: 0.9051 - val_loss: 0.4937 - val_accuracy: 0.8155\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.2496 - accuracy: 0.9070 - val_loss: 0.4793 - val_accuracy: 0.8222\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.2468 - accuracy: 0.9066 - val_loss: 0.5262 - val_accuracy: 0.8034\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.2441 - accuracy: 0.9082 - val_loss: 0.4600 - val_accuracy: 0.8253\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.2415 - accuracy: 0.9093 - val_loss: 0.4659 - val_accuracy: 0.8226\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.2399 - accuracy: 0.9089 - val_loss: 0.4765 - val_accuracy: 0.8182\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.2371 - accuracy: 0.9102 - val_loss: 0.4616 - val_accuracy: 0.8228\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 784us/step - loss: 0.2348 - accuracy: 0.9105 - val_loss: 0.4783 - val_accuracy: 0.8158\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.2326 - accuracy: 0.9118 - val_loss: 0.4272 - val_accuracy: 0.8377\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.2306 - accuracy: 0.9129 - val_loss: 0.4762 - val_accuracy: 0.8171\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 797us/step - loss: 0.2291 - accuracy: 0.9133 - val_loss: 0.4773 - val_accuracy: 0.8162\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2266 - accuracy: 0.9143 - val_loss: 0.4756 - val_accuracy: 0.8211\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.2257 - accuracy: 0.9153 - val_loss: 0.4706 - val_accuracy: 0.8207\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 2s 960us/step - loss: 0.2233 - accuracy: 0.9154 - val_loss: 0.4495 - val_accuracy: 0.8288\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.2229 - accuracy: 0.9163 - val_loss: 0.4533 - val_accuracy: 0.8240\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 753us/step - loss: 0.2213 - accuracy: 0.9166 - val_loss: 0.4441 - val_accuracy: 0.8259\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.2196 - accuracy: 0.9171 - val_loss: 0.4431 - val_accuracy: 0.8319\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.2185 - accuracy: 0.9177 - val_loss: 0.4790 - val_accuracy: 0.8176\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.2163 - accuracy: 0.9182 - val_loss: 0.4576 - val_accuracy: 0.8255\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 2s 949us/step - loss: 0.2161 - accuracy: 0.9180 - val_loss: 0.4390 - val_accuracy: 0.8332\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.2147 - accuracy: 0.9187 - val_loss: 0.4436 - val_accuracy: 0.8316\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 843us/step - loss: 0.2133 - accuracy: 0.9202 - val_loss: 0.4544 - val_accuracy: 0.8284\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.2121 - accuracy: 0.9190 - val_loss: 0.4872 - val_accuracy: 0.8150\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.2106 - accuracy: 0.9200 - val_loss: 0.4563 - val_accuracy: 0.8270\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 813us/step - loss: 0.2096 - accuracy: 0.9208 - val_loss: 0.4773 - val_accuracy: 0.8178\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.2087 - accuracy: 0.9211 - val_loss: 0.5076 - val_accuracy: 0.8086\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.2072 - accuracy: 0.9216 - val_loss: 0.4672 - val_accuracy: 0.8235\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.2069 - accuracy: 0.9214 - val_loss: 0.4806 - val_accuracy: 0.8183\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.2056 - accuracy: 0.9223 - val_loss: 0.4514 - val_accuracy: 0.8275\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.2053 - accuracy: 0.9225 - val_loss: 0.4628 - val_accuracy: 0.8270\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.2039 - accuracy: 0.9230 - val_loss: 0.4829 - val_accuracy: 0.8182\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.2029 - accuracy: 0.9241 - val_loss: 0.4475 - val_accuracy: 0.8326\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.2018 - accuracy: 0.9229 - val_loss: 0.4414 - val_accuracy: 0.8348\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.2008 - accuracy: 0.9230 - val_loss: 0.4702 - val_accuracy: 0.8242\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.2008 - accuracy: 0.9242 - val_loss: 0.5012 - val_accuracy: 0.8141\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.1995 - accuracy: 0.9239 - val_loss: 0.4627 - val_accuracy: 0.8285\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.1983 - accuracy: 0.9242 - val_loss: 0.5114 - val_accuracy: 0.8143\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.1974 - accuracy: 0.9246 - val_loss: 0.4781 - val_accuracy: 0.8225\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.1969 - accuracy: 0.9253 - val_loss: 0.4843 - val_accuracy: 0.8216\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.1967 - accuracy: 0.9245 - val_loss: 0.4558 - val_accuracy: 0.8304\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.1957 - accuracy: 0.9250 - val_loss: 0.4942 - val_accuracy: 0.8213\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5954 - accuracy: 0.6802 - val_loss: 0.5994 - val_accuracy: 0.6586\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.4652 - accuracy: 0.7784 - val_loss: 0.5695 - val_accuracy: 0.7086\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.3860 - accuracy: 0.8294 - val_loss: 0.4808 - val_accuracy: 0.7953\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.3250 - accuracy: 0.8703 - val_loss: 0.4612 - val_accuracy: 0.8235\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 940us/step - loss: 0.2921 - accuracy: 0.8898 - val_loss: 0.5183 - val_accuracy: 0.8022\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.2764 - accuracy: 0.8942 - val_loss: 0.5464 - val_accuracy: 0.7921\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.2677 - accuracy: 0.8983 - val_loss: 0.4701 - val_accuracy: 0.8263\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.2615 - accuracy: 0.9010 - val_loss: 0.4726 - val_accuracy: 0.8237\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.2574 - accuracy: 0.9026 - val_loss: 0.5111 - val_accuracy: 0.8096\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.2539 - accuracy: 0.9037 - val_loss: 0.4934 - val_accuracy: 0.8153\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 2s 916us/step - loss: 0.2501 - accuracy: 0.9054 - val_loss: 0.4505 - val_accuracy: 0.8314\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.2480 - accuracy: 0.9055 - val_loss: 0.4484 - val_accuracy: 0.8325\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.2447 - accuracy: 0.9068 - val_loss: 0.5063 - val_accuracy: 0.8054\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.2424 - accuracy: 0.9082 - val_loss: 0.4581 - val_accuracy: 0.8254\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.2394 - accuracy: 0.9095 - val_loss: 0.4675 - val_accuracy: 0.8231\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.2381 - accuracy: 0.9086 - val_loss: 0.4848 - val_accuracy: 0.8164\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.2354 - accuracy: 0.9104 - val_loss: 0.4549 - val_accuracy: 0.8254\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.2338 - accuracy: 0.9108 - val_loss: 0.4403 - val_accuracy: 0.8320\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.2324 - accuracy: 0.9106 - val_loss: 0.5017 - val_accuracy: 0.8060\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.2302 - accuracy: 0.9122 - val_loss: 0.4401 - val_accuracy: 0.8337\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.2283 - accuracy: 0.9128 - val_loss: 0.4501 - val_accuracy: 0.8283\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 827us/step - loss: 0.2268 - accuracy: 0.9128 - val_loss: 0.4586 - val_accuracy: 0.8232\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 852us/step - loss: 0.2253 - accuracy: 0.9132 - val_loss: 0.4820 - val_accuracy: 0.8143\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 784us/step - loss: 0.2241 - accuracy: 0.9142 - val_loss: 0.4745 - val_accuracy: 0.8183\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 820us/step - loss: 0.2220 - accuracy: 0.9136 - val_loss: 0.4828 - val_accuracy: 0.8155\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 779us/step - loss: 0.2213 - accuracy: 0.9151 - val_loss: 0.4385 - val_accuracy: 0.8326\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 2s 985us/step - loss: 0.2200 - accuracy: 0.9154 - val_loss: 0.4844 - val_accuracy: 0.8116\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 828us/step - loss: 0.2186 - accuracy: 0.9155 - val_loss: 0.4495 - val_accuracy: 0.8289\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.2175 - accuracy: 0.9168 - val_loss: 0.4863 - val_accuracy: 0.8098\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.2157 - accuracy: 0.9173 - val_loss: 0.4363 - val_accuracy: 0.8345\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.2150 - accuracy: 0.9163 - val_loss: 0.5019 - val_accuracy: 0.8047\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.2136 - accuracy: 0.9181 - val_loss: 0.4470 - val_accuracy: 0.8300\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.2128 - accuracy: 0.9184 - val_loss: 0.4451 - val_accuracy: 0.8285\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 768us/step - loss: 0.2116 - accuracy: 0.9184 - val_loss: 0.4740 - val_accuracy: 0.8203\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 854us/step - loss: 0.2106 - accuracy: 0.9187 - val_loss: 0.4431 - val_accuracy: 0.8325\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 809us/step - loss: 0.2104 - accuracy: 0.9197 - val_loss: 0.4342 - val_accuracy: 0.8353\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.2097 - accuracy: 0.9194 - val_loss: 0.4741 - val_accuracy: 0.8226\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.2087 - accuracy: 0.9201 - val_loss: 0.4484 - val_accuracy: 0.8306\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 832us/step - loss: 0.2071 - accuracy: 0.9197 - val_loss: 0.4844 - val_accuracy: 0.8144\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.2070 - accuracy: 0.9201 - val_loss: 0.5113 - val_accuracy: 0.8086\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.2068 - accuracy: 0.9207 - val_loss: 0.5141 - val_accuracy: 0.8035\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.2043 - accuracy: 0.9215 - val_loss: 0.4415 - val_accuracy: 0.8316\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.2046 - accuracy: 0.9215 - val_loss: 0.4559 - val_accuracy: 0.8265\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.2036 - accuracy: 0.9228 - val_loss: 0.4629 - val_accuracy: 0.8238\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.2024 - accuracy: 0.9225 - val_loss: 0.4579 - val_accuracy: 0.8246\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.2018 - accuracy: 0.9224 - val_loss: 0.4780 - val_accuracy: 0.8203\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.2022 - accuracy: 0.9222 - val_loss: 0.4881 - val_accuracy: 0.8173\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.2005 - accuracy: 0.9233 - val_loss: 0.4583 - val_accuracy: 0.8237\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.2008 - accuracy: 0.9234 - val_loss: 0.4669 - val_accuracy: 0.8249\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.1987 - accuracy: 0.9241 - val_loss: 0.4715 - val_accuracy: 0.8220\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5729 - accuracy: 0.7002 - val_loss: 0.5517 - val_accuracy: 0.7119\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 809us/step - loss: 0.4503 - accuracy: 0.7911 - val_loss: 0.5828 - val_accuracy: 0.7050\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.3717 - accuracy: 0.8431 - val_loss: 0.4891 - val_accuracy: 0.7973\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.3130 - accuracy: 0.8777 - val_loss: 0.4674 - val_accuracy: 0.8209\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.2849 - accuracy: 0.8914 - val_loss: 0.4982 - val_accuracy: 0.8115\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.2706 - accuracy: 0.8983 - val_loss: 0.4783 - val_accuracy: 0.8221\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 736us/step - loss: 0.2624 - accuracy: 0.9003 - val_loss: 0.4719 - val_accuracy: 0.8230\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.2579 - accuracy: 0.9018 - val_loss: 0.5090 - val_accuracy: 0.8085\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.2532 - accuracy: 0.9045 - val_loss: 0.4516 - val_accuracy: 0.8304\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.2495 - accuracy: 0.9054 - val_loss: 0.4817 - val_accuracy: 0.8163\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.2467 - accuracy: 0.9070 - val_loss: 0.4345 - val_accuracy: 0.8337\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.2439 - accuracy: 0.9081 - val_loss: 0.4628 - val_accuracy: 0.8209\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.2423 - accuracy: 0.9095 - val_loss: 0.4488 - val_accuracy: 0.8306\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.2397 - accuracy: 0.9085 - val_loss: 0.4704 - val_accuracy: 0.8179\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 699us/step - loss: 0.2382 - accuracy: 0.9097 - val_loss: 0.4805 - val_accuracy: 0.8137\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 774us/step - loss: 0.2354 - accuracy: 0.9112 - val_loss: 0.4546 - val_accuracy: 0.8230\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.2348 - accuracy: 0.9122 - val_loss: 0.4699 - val_accuracy: 0.8178\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.2316 - accuracy: 0.9122 - val_loss: 0.4248 - val_accuracy: 0.8330\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.2305 - accuracy: 0.9129 - val_loss: 0.4352 - val_accuracy: 0.8285\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.2287 - accuracy: 0.9131 - val_loss: 0.4323 - val_accuracy: 0.8313\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.2274 - accuracy: 0.9140 - val_loss: 0.4404 - val_accuracy: 0.8293\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.2250 - accuracy: 0.9143 - val_loss: 0.4734 - val_accuracy: 0.8176\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 877us/step - loss: 0.2233 - accuracy: 0.9155 - val_loss: 0.4461 - val_accuracy: 0.8276\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 2s 941us/step - loss: 0.2224 - accuracy: 0.9154 - val_loss: 0.4273 - val_accuracy: 0.8316\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 812us/step - loss: 0.2205 - accuracy: 0.9161 - val_loss: 0.4256 - val_accuracy: 0.8325\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 765us/step - loss: 0.2196 - accuracy: 0.9172 - val_loss: 0.4776 - val_accuracy: 0.8186\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.2188 - accuracy: 0.9166 - val_loss: 0.4211 - val_accuracy: 0.8357\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.2175 - accuracy: 0.9173 - val_loss: 0.4615 - val_accuracy: 0.8196\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.2158 - accuracy: 0.9176 - val_loss: 0.4328 - val_accuracy: 0.8341\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 817us/step - loss: 0.2154 - accuracy: 0.9174 - val_loss: 0.4763 - val_accuracy: 0.8189\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.2143 - accuracy: 0.9182 - val_loss: 0.4373 - val_accuracy: 0.8339\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.2126 - accuracy: 0.9189 - val_loss: 0.4537 - val_accuracy: 0.8247\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.2117 - accuracy: 0.9192 - val_loss: 0.4874 - val_accuracy: 0.8158\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 781us/step - loss: 0.2110 - accuracy: 0.9193 - val_loss: 0.4643 - val_accuracy: 0.8216\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 806us/step - loss: 0.2094 - accuracy: 0.9209 - val_loss: 0.4890 - val_accuracy: 0.8137\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.2091 - accuracy: 0.9197 - val_loss: 0.4404 - val_accuracy: 0.8335\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.2083 - accuracy: 0.9200 - val_loss: 0.4893 - val_accuracy: 0.8144\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.2081 - accuracy: 0.9205 - val_loss: 0.4584 - val_accuracy: 0.8254\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.2067 - accuracy: 0.9210 - val_loss: 0.4431 - val_accuracy: 0.8320\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.2056 - accuracy: 0.9216 - val_loss: 0.4349 - val_accuracy: 0.8325\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.2057 - accuracy: 0.9211 - val_loss: 0.4347 - val_accuracy: 0.8352\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.2043 - accuracy: 0.9217 - val_loss: 0.4588 - val_accuracy: 0.8296\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.2030 - accuracy: 0.9223 - val_loss: 0.4890 - val_accuracy: 0.8152\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.2035 - accuracy: 0.9221 - val_loss: 0.4517 - val_accuracy: 0.8280\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 742us/step - loss: 0.2025 - accuracy: 0.9227 - val_loss: 0.4747 - val_accuracy: 0.8225\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.2017 - accuracy: 0.9222 - val_loss: 0.4764 - val_accuracy: 0.8183\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.2015 - accuracy: 0.9227 - val_loss: 0.4229 - val_accuracy: 0.8379\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.2010 - accuracy: 0.9229 - val_loss: 0.4476 - val_accuracy: 0.8294\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.1997 - accuracy: 0.9240 - val_loss: 0.4392 - val_accuracy: 0.8348\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.2006 - accuracy: 0.9238 - val_loss: 0.4560 - val_accuracy: 0.8274\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.5712 - accuracy: 0.7081 - val_loss: 0.6176 - val_accuracy: 0.6403\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.4520 - accuracy: 0.7852 - val_loss: 0.5311 - val_accuracy: 0.7422\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.3695 - accuracy: 0.8433 - val_loss: 0.5029 - val_accuracy: 0.7916\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 854us/step - loss: 0.3156 - accuracy: 0.8769 - val_loss: 0.4821 - val_accuracy: 0.8186\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 918us/step - loss: 0.2881 - accuracy: 0.8908 - val_loss: 0.4848 - val_accuracy: 0.8205\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 819us/step - loss: 0.2740 - accuracy: 0.8952 - val_loss: 0.5189 - val_accuracy: 0.8090\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 736us/step - loss: 0.2677 - accuracy: 0.8975 - val_loss: 0.4828 - val_accuracy: 0.8231\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.2619 - accuracy: 0.9011 - val_loss: 0.4919 - val_accuracy: 0.8213\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.2584 - accuracy: 0.9024 - val_loss: 0.4885 - val_accuracy: 0.8205\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 819us/step - loss: 0.2546 - accuracy: 0.9041 - val_loss: 0.4812 - val_accuracy: 0.8231\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.2511 - accuracy: 0.9047 - val_loss: 0.4807 - val_accuracy: 0.8204\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 827us/step - loss: 0.2475 - accuracy: 0.9054 - val_loss: 0.4598 - val_accuracy: 0.8307\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.2441 - accuracy: 0.9069 - val_loss: 0.4864 - val_accuracy: 0.8194\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.2414 - accuracy: 0.9079 - val_loss: 0.4666 - val_accuracy: 0.8261\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 841us/step - loss: 0.2394 - accuracy: 0.9090 - val_loss: 0.4298 - val_accuracy: 0.8389\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.2381 - accuracy: 0.9088 - val_loss: 0.4924 - val_accuracy: 0.8142\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 779us/step - loss: 0.2348 - accuracy: 0.9095 - val_loss: 0.4622 - val_accuracy: 0.8264\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.2320 - accuracy: 0.9115 - val_loss: 0.4784 - val_accuracy: 0.8185\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.2301 - accuracy: 0.9124 - val_loss: 0.4997 - val_accuracy: 0.8125\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 2s 902us/step - loss: 0.2288 - accuracy: 0.9117 - val_loss: 0.4495 - val_accuracy: 0.8308\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.2266 - accuracy: 0.9122 - val_loss: 0.4870 - val_accuracy: 0.8116\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.2251 - accuracy: 0.9142 - val_loss: 0.5012 - val_accuracy: 0.8108\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.2228 - accuracy: 0.9137 - val_loss: 0.4628 - val_accuracy: 0.8262\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.2227 - accuracy: 0.9150 - val_loss: 0.4646 - val_accuracy: 0.8253\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.2196 - accuracy: 0.9148 - val_loss: 0.4348 - val_accuracy: 0.8334\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.2190 - accuracy: 0.9154 - val_loss: 0.4743 - val_accuracy: 0.8206\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.2184 - accuracy: 0.9154 - val_loss: 0.4266 - val_accuracy: 0.8376\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 787us/step - loss: 0.2160 - accuracy: 0.9168 - val_loss: 0.4812 - val_accuracy: 0.8173\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.2151 - accuracy: 0.9174 - val_loss: 0.4786 - val_accuracy: 0.8190\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.2146 - accuracy: 0.9172 - val_loss: 0.5137 - val_accuracy: 0.8052\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.2124 - accuracy: 0.9179 - val_loss: 0.4669 - val_accuracy: 0.8244\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.2115 - accuracy: 0.9182 - val_loss: 0.4688 - val_accuracy: 0.8238\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.2105 - accuracy: 0.9189 - val_loss: 0.4392 - val_accuracy: 0.8340\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.2095 - accuracy: 0.9204 - val_loss: 0.4447 - val_accuracy: 0.8278\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.2082 - accuracy: 0.9193 - val_loss: 0.5123 - val_accuracy: 0.8106\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.2071 - accuracy: 0.9200 - val_loss: 0.5084 - val_accuracy: 0.8040\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.2069 - accuracy: 0.9202 - val_loss: 0.4560 - val_accuracy: 0.8225\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.2056 - accuracy: 0.9202 - val_loss: 0.4611 - val_accuracy: 0.8262\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.2050 - accuracy: 0.9207 - val_loss: 0.4851 - val_accuracy: 0.8195\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 883us/step - loss: 0.2035 - accuracy: 0.9219 - val_loss: 0.4419 - val_accuracy: 0.8357\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.2027 - accuracy: 0.9218 - val_loss: 0.4893 - val_accuracy: 0.8173\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.2028 - accuracy: 0.9219 - val_loss: 0.4630 - val_accuracy: 0.8215\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 851us/step - loss: 0.2015 - accuracy: 0.9224 - val_loss: 0.4526 - val_accuracy: 0.8274\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 846us/step - loss: 0.2008 - accuracy: 0.9222 - val_loss: 0.4144 - val_accuracy: 0.8435\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.2000 - accuracy: 0.9227 - val_loss: 0.4626 - val_accuracy: 0.8290\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 828us/step - loss: 0.1998 - accuracy: 0.9234 - val_loss: 0.4736 - val_accuracy: 0.8247\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 801us/step - loss: 0.1987 - accuracy: 0.9233 - val_loss: 0.4494 - val_accuracy: 0.8294\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 815us/step - loss: 0.1985 - accuracy: 0.9241 - val_loss: 0.4806 - val_accuracy: 0.8186\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 832us/step - loss: 0.1974 - accuracy: 0.9248 - val_loss: 0.4768 - val_accuracy: 0.8210\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 842us/step - loss: 0.1969 - accuracy: 0.9240 - val_loss: 0.4119 - val_accuracy: 0.8452\n"
     ]
    }
   ],
   "source": [
    "# Train model without DP\n",
    "print(\"Training model without DP...\")\n",
    "results_no_dp = run_iterations(\n",
    "    X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "    batch_size=default_batch_size, epochs=epochs, use_dp=False, n_iterations=n_iterations,\n",
    "    num_microbatches=None, l2_norm_clip=None, noise_multiplier=None\n",
    ")\n",
    "results_no_dp_stats = compute_statistics(results_no_dp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f3c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with batch_size=16, target_eps=0.5...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 5.05 iterated over 167200 steps satisfies differential privacy with eps = 0.122 and delta = 1e-05.\n",
      "The optimal RDP order is 256.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 2.5749999999999997 iterated over 167200 steps satisfies differential privacy with eps = 0.263 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.3375 iterated over 167200 steps satisfies differential privacy with eps = 0.585 and delta = 1e-05.\n",
      "The optimal RDP order is 28.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.9562499999999998 iterated over 167200 steps satisfies differential privacy with eps = 0.329 and delta = 1e-05.\n",
      "The optimal RDP order is 61.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.6468749999999999 iterated over 167200 steps satisfies differential privacy with eps = 0.419 and delta = 1e-05.\n",
      "The optimal RDP order is 43.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.4921875 iterated over 167200 steps satisfies differential privacy with eps = 0.488 and delta = 1e-05.\n",
      "The optimal RDP order is 35.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.41484375 iterated over 167200 steps satisfies differential privacy with eps = 0.535 and delta = 1e-05.\n",
      "The optimal RDP order is 31.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.453515625 iterated over 167200 steps satisfies differential privacy with eps = 0.51 and delta = 1e-05.\n",
      "The optimal RDP order is 33.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.4728515625 iterated over 167200 steps satisfies differential privacy with eps = 0.499 and delta = 1e-05.\n",
      "The optimal RDP order is 34.0.\n",
      "Epoch 1/50\n",
      "   1/3344 [..............................] - ETA: 0s - loss: 0.7578 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.7273 - accuracy: 0.4763 - val_loss: 0.7369 - val_accuracy: 0.2799\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.7024 - accuracy: 0.5158 - val_loss: 0.7207 - val_accuracy: 0.3962\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.6904 - accuracy: 0.5465 - val_loss: 0.7120 - val_accuracy: 0.4610\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.6797 - accuracy: 0.5714 - val_loss: 0.7020 - val_accuracy: 0.5101\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.6707 - accuracy: 0.5953 - val_loss: 0.6927 - val_accuracy: 0.5431\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.6624 - accuracy: 0.6113 - val_loss: 0.6877 - val_accuracy: 0.5615\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 452us/step - loss: 0.6547 - accuracy: 0.6268 - val_loss: 0.6797 - val_accuracy: 0.5787\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.6482 - accuracy: 0.6406 - val_loss: 0.6724 - val_accuracy: 0.5905\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 449us/step - loss: 0.6418 - accuracy: 0.6503 - val_loss: 0.6701 - val_accuracy: 0.5891\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.6353 - accuracy: 0.6558 - val_loss: 0.6621 - val_accuracy: 0.6002\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.6309 - accuracy: 0.6609 - val_loss: 0.6477 - val_accuracy: 0.6249\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.6243 - accuracy: 0.6697 - val_loss: 0.6470 - val_accuracy: 0.6201\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.6206 - accuracy: 0.6728 - val_loss: 0.6423 - val_accuracy: 0.6283\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.6148 - accuracy: 0.6789 - val_loss: 0.6481 - val_accuracy: 0.6166\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.6100 - accuracy: 0.6824 - val_loss: 0.6343 - val_accuracy: 0.6388\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.6050 - accuracy: 0.6873 - val_loss: 0.6295 - val_accuracy: 0.6435\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.6011 - accuracy: 0.6900 - val_loss: 0.6381 - val_accuracy: 0.6270\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.5975 - accuracy: 0.6939 - val_loss: 0.6379 - val_accuracy: 0.6272\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.5942 - accuracy: 0.6943 - val_loss: 0.6303 - val_accuracy: 0.6381\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5909 - accuracy: 0.6998 - val_loss: 0.6216 - val_accuracy: 0.6493\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5881 - accuracy: 0.7002 - val_loss: 0.6287 - val_accuracy: 0.6404\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.5845 - accuracy: 0.7020 - val_loss: 0.6206 - val_accuracy: 0.6479\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5810 - accuracy: 0.7054 - val_loss: 0.6145 - val_accuracy: 0.6531\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5787 - accuracy: 0.7058 - val_loss: 0.6283 - val_accuracy: 0.6402\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 455us/step - loss: 0.5761 - accuracy: 0.7081 - val_loss: 0.6151 - val_accuracy: 0.6513\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.5733 - accuracy: 0.7113 - val_loss: 0.6110 - val_accuracy: 0.6550\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.5719 - accuracy: 0.7117 - val_loss: 0.6041 - val_accuracy: 0.6628\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.5688 - accuracy: 0.7128 - val_loss: 0.6237 - val_accuracy: 0.6425\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.5659 - accuracy: 0.7152 - val_loss: 0.6043 - val_accuracy: 0.6644\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5644 - accuracy: 0.7166 - val_loss: 0.6122 - val_accuracy: 0.6562\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.5611 - accuracy: 0.7193 - val_loss: 0.6093 - val_accuracy: 0.6617\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.5601 - accuracy: 0.7196 - val_loss: 0.6137 - val_accuracy: 0.6573\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 454us/step - loss: 0.5575 - accuracy: 0.7203 - val_loss: 0.6239 - val_accuracy: 0.6449\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.5558 - accuracy: 0.7199 - val_loss: 0.6068 - val_accuracy: 0.6621\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.5541 - accuracy: 0.7218 - val_loss: 0.6141 - val_accuracy: 0.6568\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.5521 - accuracy: 0.7244 - val_loss: 0.6026 - val_accuracy: 0.6626\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.5504 - accuracy: 0.7249 - val_loss: 0.5948 - val_accuracy: 0.6702\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.5492 - accuracy: 0.7244 - val_loss: 0.6007 - val_accuracy: 0.6653\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.5475 - accuracy: 0.7271 - val_loss: 0.6079 - val_accuracy: 0.6602\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.5452 - accuracy: 0.7278 - val_loss: 0.6099 - val_accuracy: 0.6596\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.5446 - accuracy: 0.7271 - val_loss: 0.6111 - val_accuracy: 0.6597\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.5424 - accuracy: 0.7277 - val_loss: 0.5992 - val_accuracy: 0.6669\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.5413 - accuracy: 0.7288 - val_loss: 0.6008 - val_accuracy: 0.6668\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5391 - accuracy: 0.7316 - val_loss: 0.6220 - val_accuracy: 0.6512\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.5381 - accuracy: 0.7305 - val_loss: 0.6108 - val_accuracy: 0.6612\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.5375 - accuracy: 0.7319 - val_loss: 0.6046 - val_accuracy: 0.6656\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5360 - accuracy: 0.7319 - val_loss: 0.5996 - val_accuracy: 0.6678\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.5330 - accuracy: 0.7335 - val_loss: 0.6104 - val_accuracy: 0.6615\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.5316 - accuracy: 0.7363 - val_loss: 0.5966 - val_accuracy: 0.6701\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5307 - accuracy: 0.7360 - val_loss: 0.6106 - val_accuracy: 0.6597\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.7142 - accuracy: 0.5038 - val_loss: 0.7257 - val_accuracy: 0.3567\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.6971 - accuracy: 0.5318 - val_loss: 0.7125 - val_accuracy: 0.4439\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.6843 - accuracy: 0.5609 - val_loss: 0.6958 - val_accuracy: 0.5153\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.6734 - accuracy: 0.5823 - val_loss: 0.6897 - val_accuracy: 0.5517\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.6646 - accuracy: 0.6034 - val_loss: 0.6905 - val_accuracy: 0.5516\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.6570 - accuracy: 0.6211 - val_loss: 0.6805 - val_accuracy: 0.5770\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.6500 - accuracy: 0.6360 - val_loss: 0.6815 - val_accuracy: 0.5744\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.6437 - accuracy: 0.6442 - val_loss: 0.6669 - val_accuracy: 0.6119\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.6371 - accuracy: 0.6545 - val_loss: 0.6722 - val_accuracy: 0.5985\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.6322 - accuracy: 0.6615 - val_loss: 0.6654 - val_accuracy: 0.6092\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.6267 - accuracy: 0.6690 - val_loss: 0.6574 - val_accuracy: 0.6211\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.6221 - accuracy: 0.6718 - val_loss: 0.6555 - val_accuracy: 0.6265\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.6173 - accuracy: 0.6790 - val_loss: 0.6575 - val_accuracy: 0.6222\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.6129 - accuracy: 0.6811 - val_loss: 0.6375 - val_accuracy: 0.6507\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.6082 - accuracy: 0.6894 - val_loss: 0.6458 - val_accuracy: 0.6370\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.6041 - accuracy: 0.6916 - val_loss: 0.6400 - val_accuracy: 0.6430\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.6004 - accuracy: 0.6911 - val_loss: 0.6399 - val_accuracy: 0.6424\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5965 - accuracy: 0.6972 - val_loss: 0.6314 - val_accuracy: 0.6513\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.5936 - accuracy: 0.6962 - val_loss: 0.6293 - val_accuracy: 0.6523\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.5897 - accuracy: 0.6999 - val_loss: 0.6243 - val_accuracy: 0.6549\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5875 - accuracy: 0.7003 - val_loss: 0.6265 - val_accuracy: 0.6517\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5836 - accuracy: 0.7041 - val_loss: 0.6250 - val_accuracy: 0.6512\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.5814 - accuracy: 0.7037 - val_loss: 0.6292 - val_accuracy: 0.6476\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.5776 - accuracy: 0.7073 - val_loss: 0.6207 - val_accuracy: 0.6574\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5743 - accuracy: 0.7088 - val_loss: 0.6205 - val_accuracy: 0.6585\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5726 - accuracy: 0.7099 - val_loss: 0.6111 - val_accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.5700 - accuracy: 0.7113 - val_loss: 0.6026 - val_accuracy: 0.6720\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.5668 - accuracy: 0.7145 - val_loss: 0.6214 - val_accuracy: 0.6607\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.5649 - accuracy: 0.7155 - val_loss: 0.6112 - val_accuracy: 0.6679\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.5632 - accuracy: 0.7163 - val_loss: 0.6039 - val_accuracy: 0.6743\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.5606 - accuracy: 0.7181 - val_loss: 0.6064 - val_accuracy: 0.6729\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5580 - accuracy: 0.7205 - val_loss: 0.6222 - val_accuracy: 0.6582\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.5558 - accuracy: 0.7214 - val_loss: 0.6121 - val_accuracy: 0.6670\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.5553 - accuracy: 0.7207 - val_loss: 0.6073 - val_accuracy: 0.6728\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5530 - accuracy: 0.7236 - val_loss: 0.6112 - val_accuracy: 0.6688\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5512 - accuracy: 0.7221 - val_loss: 0.6108 - val_accuracy: 0.6696\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.5483 - accuracy: 0.7265 - val_loss: 0.6160 - val_accuracy: 0.6653\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.5470 - accuracy: 0.7242 - val_loss: 0.6083 - val_accuracy: 0.6711\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 673us/step - loss: 0.5448 - accuracy: 0.7267 - val_loss: 0.6104 - val_accuracy: 0.6697\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 3s 877us/step - loss: 0.5438 - accuracy: 0.7263 - val_loss: 0.6024 - val_accuracy: 0.6761\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 4s 1ms/step - loss: 0.5424 - accuracy: 0.7264 - val_loss: 0.6090 - val_accuracy: 0.6705\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 733us/step - loss: 0.5402 - accuracy: 0.7281 - val_loss: 0.6068 - val_accuracy: 0.6725\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 728us/step - loss: 0.5394 - accuracy: 0.7301 - val_loss: 0.6078 - val_accuracy: 0.6722\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 3s 822us/step - loss: 0.5374 - accuracy: 0.7303 - val_loss: 0.6073 - val_accuracy: 0.6736\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.5357 - accuracy: 0.7303 - val_loss: 0.5990 - val_accuracy: 0.6794\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 3s 873us/step - loss: 0.5342 - accuracy: 0.7330 - val_loss: 0.6149 - val_accuracy: 0.6674\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 3s 947us/step - loss: 0.5331 - accuracy: 0.7328 - val_loss: 0.6117 - val_accuracy: 0.6696\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.5321 - accuracy: 0.7329 - val_loss: 0.6105 - val_accuracy: 0.6719\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 697us/step - loss: 0.5309 - accuracy: 0.7327 - val_loss: 0.6020 - val_accuracy: 0.6773\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 684us/step - loss: 0.5291 - accuracy: 0.7356 - val_loss: 0.6088 - val_accuracy: 0.6742\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 687us/step - loss: 0.6958 - accuracy: 0.5109 - val_loss: 0.6954 - val_accuracy: 0.5151\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 3s 832us/step - loss: 0.6832 - accuracy: 0.5509 - val_loss: 0.6947 - val_accuracy: 0.5342\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 690us/step - loss: 0.6746 - accuracy: 0.5783 - val_loss: 0.6824 - val_accuracy: 0.5802\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.6676 - accuracy: 0.5990 - val_loss: 0.6714 - val_accuracy: 0.6132\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.6601 - accuracy: 0.6179 - val_loss: 0.6668 - val_accuracy: 0.6219\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.6540 - accuracy: 0.6248 - val_loss: 0.6601 - val_accuracy: 0.6319\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 677us/step - loss: 0.6473 - accuracy: 0.6371 - val_loss: 0.6547 - val_accuracy: 0.6428\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 595us/step - loss: 0.6426 - accuracy: 0.6425 - val_loss: 0.6556 - val_accuracy: 0.6351\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 687us/step - loss: 0.6389 - accuracy: 0.6469 - val_loss: 0.6469 - val_accuracy: 0.6459\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.6331 - accuracy: 0.6534 - val_loss: 0.6432 - val_accuracy: 0.6475\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 653us/step - loss: 0.6284 - accuracy: 0.6579 - val_loss: 0.6438 - val_accuracy: 0.6407\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 641us/step - loss: 0.6246 - accuracy: 0.6622 - val_loss: 0.6414 - val_accuracy: 0.6378\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.6201 - accuracy: 0.6665 - val_loss: 0.6373 - val_accuracy: 0.6378\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.6163 - accuracy: 0.6700 - val_loss: 0.6317 - val_accuracy: 0.6443\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.6124 - accuracy: 0.6743 - val_loss: 0.6270 - val_accuracy: 0.6511\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 625us/step - loss: 0.6073 - accuracy: 0.6804 - val_loss: 0.6203 - val_accuracy: 0.6612\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.6040 - accuracy: 0.6835 - val_loss: 0.6207 - val_accuracy: 0.6586\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.6008 - accuracy: 0.6860 - val_loss: 0.6190 - val_accuracy: 0.6594\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 712us/step - loss: 0.5971 - accuracy: 0.6896 - val_loss: 0.6130 - val_accuracy: 0.6635\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 3s 831us/step - loss: 0.5936 - accuracy: 0.6937 - val_loss: 0.6154 - val_accuracy: 0.6590\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 3s 752us/step - loss: 0.5900 - accuracy: 0.6973 - val_loss: 0.6181 - val_accuracy: 0.6552\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.5871 - accuracy: 0.6994 - val_loss: 0.6110 - val_accuracy: 0.6604\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.5850 - accuracy: 0.7012 - val_loss: 0.6087 - val_accuracy: 0.6601\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 664us/step - loss: 0.5823 - accuracy: 0.7040 - val_loss: 0.6186 - val_accuracy: 0.6482\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 746us/step - loss: 0.5796 - accuracy: 0.7062 - val_loss: 0.6097 - val_accuracy: 0.6550\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 642us/step - loss: 0.5779 - accuracy: 0.7077 - val_loss: 0.6077 - val_accuracy: 0.6563\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 595us/step - loss: 0.5756 - accuracy: 0.7081 - val_loss: 0.6002 - val_accuracy: 0.6644\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.5732 - accuracy: 0.7113 - val_loss: 0.6006 - val_accuracy: 0.6654\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.5707 - accuracy: 0.7125 - val_loss: 0.6084 - val_accuracy: 0.6553\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5679 - accuracy: 0.7128 - val_loss: 0.6137 - val_accuracy: 0.6464\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.5665 - accuracy: 0.7157 - val_loss: 0.6036 - val_accuracy: 0.6603\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.5646 - accuracy: 0.7158 - val_loss: 0.6082 - val_accuracy: 0.6528\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.5621 - accuracy: 0.7180 - val_loss: 0.6027 - val_accuracy: 0.6601\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5597 - accuracy: 0.7184 - val_loss: 0.6042 - val_accuracy: 0.6576\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.5583 - accuracy: 0.7205 - val_loss: 0.6089 - val_accuracy: 0.6520\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.5561 - accuracy: 0.7221 - val_loss: 0.5988 - val_accuracy: 0.6608\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.5545 - accuracy: 0.7217 - val_loss: 0.6002 - val_accuracy: 0.6596\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.5527 - accuracy: 0.7237 - val_loss: 0.5851 - val_accuracy: 0.6701\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5515 - accuracy: 0.7227 - val_loss: 0.5998 - val_accuracy: 0.6583\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 487us/step - loss: 0.5499 - accuracy: 0.7249 - val_loss: 0.6064 - val_accuracy: 0.6522\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5480 - accuracy: 0.7249 - val_loss: 0.5973 - val_accuracy: 0.6583\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5463 - accuracy: 0.7257 - val_loss: 0.6065 - val_accuracy: 0.6491\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.5441 - accuracy: 0.7273 - val_loss: 0.5920 - val_accuracy: 0.6614\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.5426 - accuracy: 0.7290 - val_loss: 0.6104 - val_accuracy: 0.6436\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.5410 - accuracy: 0.7294 - val_loss: 0.6013 - val_accuracy: 0.6514\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.5390 - accuracy: 0.7296 - val_loss: 0.6124 - val_accuracy: 0.6424\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.5382 - accuracy: 0.7308 - val_loss: 0.6106 - val_accuracy: 0.6440\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5372 - accuracy: 0.7303 - val_loss: 0.6021 - val_accuracy: 0.6517\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5358 - accuracy: 0.7317 - val_loss: 0.6003 - val_accuracy: 0.6543\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.5340 - accuracy: 0.7331 - val_loss: 0.6045 - val_accuracy: 0.6507\n",
      "Epoch 1/50\n",
      "3306/3344 [============================>.] - ETA: 0s - loss: 0.6893 - accuracy: 0.5498WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.6892 - accuracy: 0.5500 - val_loss: 0.7182 - val_accuracy: 0.3846\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.6777 - accuracy: 0.5841 - val_loss: 0.7113 - val_accuracy: 0.4625\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.6690 - accuracy: 0.6095 - val_loss: 0.6984 - val_accuracy: 0.5207\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.6617 - accuracy: 0.6263 - val_loss: 0.6967 - val_accuracy: 0.5285\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.6558 - accuracy: 0.6399 - val_loss: 0.6825 - val_accuracy: 0.5719\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.6502 - accuracy: 0.6487 - val_loss: 0.6853 - val_accuracy: 0.5613\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.6444 - accuracy: 0.6576 - val_loss: 0.6752 - val_accuracy: 0.5908\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.6394 - accuracy: 0.6631 - val_loss: 0.6712 - val_accuracy: 0.5966\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.6339 - accuracy: 0.6662 - val_loss: 0.6640 - val_accuracy: 0.6059\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 625us/step - loss: 0.6300 - accuracy: 0.6721 - val_loss: 0.6589 - val_accuracy: 0.6121\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 678us/step - loss: 0.6256 - accuracy: 0.6765 - val_loss: 0.6596 - val_accuracy: 0.6084\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 3s 769us/step - loss: 0.6205 - accuracy: 0.6777 - val_loss: 0.6534 - val_accuracy: 0.6148\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 3s 765us/step - loss: 0.6154 - accuracy: 0.6829 - val_loss: 0.6462 - val_accuracy: 0.6210\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.6113 - accuracy: 0.6842 - val_loss: 0.6462 - val_accuracy: 0.6190\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.6060 - accuracy: 0.6883 - val_loss: 0.6329 - val_accuracy: 0.6410\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.6014 - accuracy: 0.6914 - val_loss: 0.6299 - val_accuracy: 0.6437\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.5994 - accuracy: 0.6931 - val_loss: 0.6273 - val_accuracy: 0.6461\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5957 - accuracy: 0.6938 - val_loss: 0.6322 - val_accuracy: 0.6346\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.5937 - accuracy: 0.6955 - val_loss: 0.6297 - val_accuracy: 0.6374\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.5902 - accuracy: 0.6988 - val_loss: 0.6261 - val_accuracy: 0.6441\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.5877 - accuracy: 0.6985 - val_loss: 0.6215 - val_accuracy: 0.6461\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.5832 - accuracy: 0.7013 - val_loss: 0.6267 - val_accuracy: 0.6425\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.5811 - accuracy: 0.7022 - val_loss: 0.6185 - val_accuracy: 0.6486\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 646us/step - loss: 0.5780 - accuracy: 0.7051 - val_loss: 0.6256 - val_accuracy: 0.6396\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.5753 - accuracy: 0.7056 - val_loss: 0.6205 - val_accuracy: 0.6468\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.5727 - accuracy: 0.7089 - val_loss: 0.6310 - val_accuracy: 0.6347\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.5717 - accuracy: 0.7095 - val_loss: 0.6239 - val_accuracy: 0.6451\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5703 - accuracy: 0.7091 - val_loss: 0.6097 - val_accuracy: 0.6629\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5669 - accuracy: 0.7112 - val_loss: 0.6043 - val_accuracy: 0.6650\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.5653 - accuracy: 0.7126 - val_loss: 0.6110 - val_accuracy: 0.6590\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 595us/step - loss: 0.5626 - accuracy: 0.7157 - val_loss: 0.6145 - val_accuracy: 0.6539\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 654us/step - loss: 0.5609 - accuracy: 0.7127 - val_loss: 0.6129 - val_accuracy: 0.6533\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5594 - accuracy: 0.7154 - val_loss: 0.6124 - val_accuracy: 0.6543\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 1s 448us/step - loss: 0.5582 - accuracy: 0.7176 - val_loss: 0.6124 - val_accuracy: 0.6540\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.5556 - accuracy: 0.7176 - val_loss: 0.6045 - val_accuracy: 0.6624\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 1s 445us/step - loss: 0.5542 - accuracy: 0.7182 - val_loss: 0.6122 - val_accuracy: 0.6528\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.5529 - accuracy: 0.7175 - val_loss: 0.5976 - val_accuracy: 0.6644\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.5509 - accuracy: 0.7188 - val_loss: 0.6146 - val_accuracy: 0.6533\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.5503 - accuracy: 0.7190 - val_loss: 0.6070 - val_accuracy: 0.6593\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.5476 - accuracy: 0.7208 - val_loss: 0.6119 - val_accuracy: 0.6559\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 460us/step - loss: 0.5466 - accuracy: 0.7197 - val_loss: 0.6131 - val_accuracy: 0.6534\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 468us/step - loss: 0.5444 - accuracy: 0.7216 - val_loss: 0.6030 - val_accuracy: 0.6605\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.5433 - accuracy: 0.7247 - val_loss: 0.6049 - val_accuracy: 0.6591\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 450us/step - loss: 0.5423 - accuracy: 0.7240 - val_loss: 0.6128 - val_accuracy: 0.6535\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5405 - accuracy: 0.7238 - val_loss: 0.6052 - val_accuracy: 0.6591\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.5397 - accuracy: 0.7238 - val_loss: 0.6064 - val_accuracy: 0.6582\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.5383 - accuracy: 0.7253 - val_loss: 0.6002 - val_accuracy: 0.6618\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 458us/step - loss: 0.5361 - accuracy: 0.7278 - val_loss: 0.6048 - val_accuracy: 0.6594\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.5343 - accuracy: 0.7273 - val_loss: 0.5987 - val_accuracy: 0.6644\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.5347 - accuracy: 0.7276 - val_loss: 0.6012 - val_accuracy: 0.6628\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.6722 - accuracy: 0.5779 - val_loss: 0.6703 - val_accuracy: 0.6133\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.6580 - accuracy: 0.6079 - val_loss: 0.6648 - val_accuracy: 0.6225\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.6493 - accuracy: 0.6248 - val_loss: 0.6551 - val_accuracy: 0.6374\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.6410 - accuracy: 0.6386 - val_loss: 0.6527 - val_accuracy: 0.6375\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 665us/step - loss: 0.6343 - accuracy: 0.6470 - val_loss: 0.6498 - val_accuracy: 0.6361\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 472us/step - loss: 0.6275 - accuracy: 0.6554 - val_loss: 0.6473 - val_accuracy: 0.6352\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.6225 - accuracy: 0.6618 - val_loss: 0.6379 - val_accuracy: 0.6464\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.6167 - accuracy: 0.6700 - val_loss: 0.6363 - val_accuracy: 0.6471\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.6122 - accuracy: 0.6732 - val_loss: 0.6264 - val_accuracy: 0.6550\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.6073 - accuracy: 0.6758 - val_loss: 0.6238 - val_accuracy: 0.6542\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.6028 - accuracy: 0.6810 - val_loss: 0.6279 - val_accuracy: 0.6476\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.5980 - accuracy: 0.6863 - val_loss: 0.6239 - val_accuracy: 0.6493\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 490us/step - loss: 0.5947 - accuracy: 0.6899 - val_loss: 0.6244 - val_accuracy: 0.6460\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.5911 - accuracy: 0.6938 - val_loss: 0.6233 - val_accuracy: 0.6464\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5880 - accuracy: 0.6944 - val_loss: 0.6200 - val_accuracy: 0.6461\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.5847 - accuracy: 0.6976 - val_loss: 0.6106 - val_accuracy: 0.6555\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.5803 - accuracy: 0.7023 - val_loss: 0.6151 - val_accuracy: 0.6472\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.5779 - accuracy: 0.7033 - val_loss: 0.6043 - val_accuracy: 0.6605\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.5744 - accuracy: 0.7073 - val_loss: 0.5972 - val_accuracy: 0.6662\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5730 - accuracy: 0.7075 - val_loss: 0.6100 - val_accuracy: 0.6534\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.5694 - accuracy: 0.7105 - val_loss: 0.6000 - val_accuracy: 0.6600\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.5670 - accuracy: 0.7129 - val_loss: 0.5986 - val_accuracy: 0.6610\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5642 - accuracy: 0.7148 - val_loss: 0.6005 - val_accuracy: 0.6580\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.5621 - accuracy: 0.7171 - val_loss: 0.5999 - val_accuracy: 0.6579\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.5597 - accuracy: 0.7167 - val_loss: 0.6128 - val_accuracy: 0.6429\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.5587 - accuracy: 0.7173 - val_loss: 0.6079 - val_accuracy: 0.6471\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.5553 - accuracy: 0.7214 - val_loss: 0.6054 - val_accuracy: 0.6501\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5536 - accuracy: 0.7209 - val_loss: 0.5990 - val_accuracy: 0.6556\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.5522 - accuracy: 0.7206 - val_loss: 0.5913 - val_accuracy: 0.6617\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.5491 - accuracy: 0.7231 - val_loss: 0.6103 - val_accuracy: 0.6437\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.5486 - accuracy: 0.7232 - val_loss: 0.6070 - val_accuracy: 0.6477\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.5464 - accuracy: 0.7249 - val_loss: 0.5958 - val_accuracy: 0.6586\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5445 - accuracy: 0.7269 - val_loss: 0.6110 - val_accuracy: 0.6428\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.5434 - accuracy: 0.7267 - val_loss: 0.6119 - val_accuracy: 0.6422\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 646us/step - loss: 0.5417 - accuracy: 0.7259 - val_loss: 0.6028 - val_accuracy: 0.6507\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.5395 - accuracy: 0.7291 - val_loss: 0.5996 - val_accuracy: 0.6548\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.5388 - accuracy: 0.7303 - val_loss: 0.6025 - val_accuracy: 0.6511\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5369 - accuracy: 0.7307 - val_loss: 0.6065 - val_accuracy: 0.6480\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 634us/step - loss: 0.5364 - accuracy: 0.7310 - val_loss: 0.6049 - val_accuracy: 0.6501\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.5351 - accuracy: 0.7313 - val_loss: 0.5952 - val_accuracy: 0.6597\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.5335 - accuracy: 0.7314 - val_loss: 0.6099 - val_accuracy: 0.6453\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5318 - accuracy: 0.7317 - val_loss: 0.6026 - val_accuracy: 0.6534\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.5299 - accuracy: 0.7339 - val_loss: 0.6001 - val_accuracy: 0.6556\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.5291 - accuracy: 0.7353 - val_loss: 0.6083 - val_accuracy: 0.6488\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.5290 - accuracy: 0.7340 - val_loss: 0.5932 - val_accuracy: 0.6660\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.5271 - accuracy: 0.7348 - val_loss: 0.5995 - val_accuracy: 0.6584\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.5265 - accuracy: 0.7361 - val_loss: 0.6113 - val_accuracy: 0.6466\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5243 - accuracy: 0.7372 - val_loss: 0.5953 - val_accuracy: 0.6637\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.5233 - accuracy: 0.7373 - val_loss: 0.6014 - val_accuracy: 0.6579\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5223 - accuracy: 0.7366 - val_loss: 0.6098 - val_accuracy: 0.6500\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.6963 - accuracy: 0.5314 - val_loss: 0.7053 - val_accuracy: 0.4773\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.6811 - accuracy: 0.5642 - val_loss: 0.6909 - val_accuracy: 0.5561\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.6694 - accuracy: 0.6004 - val_loss: 0.6824 - val_accuracy: 0.5850\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.6582 - accuracy: 0.6254 - val_loss: 0.6719 - val_accuracy: 0.6095\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.6488 - accuracy: 0.6414 - val_loss: 0.6637 - val_accuracy: 0.6224\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.6407 - accuracy: 0.6567 - val_loss: 0.6536 - val_accuracy: 0.6372\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 485us/step - loss: 0.6342 - accuracy: 0.6649 - val_loss: 0.6524 - val_accuracy: 0.6349\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.6278 - accuracy: 0.6730 - val_loss: 0.6489 - val_accuracy: 0.6364\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.6232 - accuracy: 0.6765 - val_loss: 0.6408 - val_accuracy: 0.6454\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.6180 - accuracy: 0.6805 - val_loss: 0.6379 - val_accuracy: 0.6447\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.6120 - accuracy: 0.6879 - val_loss: 0.6224 - val_accuracy: 0.6594\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 453us/step - loss: 0.6079 - accuracy: 0.6905 - val_loss: 0.6309 - val_accuracy: 0.6475\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 493us/step - loss: 0.6036 - accuracy: 0.6939 - val_loss: 0.6242 - val_accuracy: 0.6519\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.5986 - accuracy: 0.6973 - val_loss: 0.6061 - val_accuracy: 0.6687\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.5951 - accuracy: 0.7001 - val_loss: 0.6192 - val_accuracy: 0.6512\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 470us/step - loss: 0.5911 - accuracy: 0.7031 - val_loss: 0.6142 - val_accuracy: 0.6529\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5882 - accuracy: 0.7032 - val_loss: 0.6054 - val_accuracy: 0.6631\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.5843 - accuracy: 0.7066 - val_loss: 0.6084 - val_accuracy: 0.6568\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 478us/step - loss: 0.5811 - accuracy: 0.7079 - val_loss: 0.6176 - val_accuracy: 0.6465\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.5780 - accuracy: 0.7085 - val_loss: 0.5997 - val_accuracy: 0.6631\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.5751 - accuracy: 0.7110 - val_loss: 0.6079 - val_accuracy: 0.6508\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.5741 - accuracy: 0.7095 - val_loss: 0.6020 - val_accuracy: 0.6580\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.5702 - accuracy: 0.7129 - val_loss: 0.5958 - val_accuracy: 0.6639\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 635us/step - loss: 0.5678 - accuracy: 0.7162 - val_loss: 0.6056 - val_accuracy: 0.6507\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.5666 - accuracy: 0.7153 - val_loss: 0.6032 - val_accuracy: 0.6541\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5632 - accuracy: 0.7172 - val_loss: 0.6031 - val_accuracy: 0.6521\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.5612 - accuracy: 0.7184 - val_loss: 0.6007 - val_accuracy: 0.6538\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.5589 - accuracy: 0.7181 - val_loss: 0.6111 - val_accuracy: 0.6425\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.5567 - accuracy: 0.7192 - val_loss: 0.6069 - val_accuracy: 0.6464\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.5550 - accuracy: 0.7199 - val_loss: 0.6051 - val_accuracy: 0.6472\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5525 - accuracy: 0.7208 - val_loss: 0.6044 - val_accuracy: 0.6465\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5516 - accuracy: 0.7207 - val_loss: 0.5969 - val_accuracy: 0.6532\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.5487 - accuracy: 0.7238 - val_loss: 0.5991 - val_accuracy: 0.6518\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 509us/step - loss: 0.5476 - accuracy: 0.7246 - val_loss: 0.5915 - val_accuracy: 0.6565\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 484us/step - loss: 0.5451 - accuracy: 0.7235 - val_loss: 0.5917 - val_accuracy: 0.6560\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.5429 - accuracy: 0.7235 - val_loss: 0.5936 - val_accuracy: 0.6542\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.5411 - accuracy: 0.7258 - val_loss: 0.5891 - val_accuracy: 0.6585\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.5396 - accuracy: 0.7268 - val_loss: 0.5961 - val_accuracy: 0.6524\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.5381 - accuracy: 0.7293 - val_loss: 0.6024 - val_accuracy: 0.6470\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.5369 - accuracy: 0.7284 - val_loss: 0.5951 - val_accuracy: 0.6543\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.5353 - accuracy: 0.7280 - val_loss: 0.6019 - val_accuracy: 0.6478\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5335 - accuracy: 0.7296 - val_loss: 0.5958 - val_accuracy: 0.6541\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.5331 - accuracy: 0.7297 - val_loss: 0.6005 - val_accuracy: 0.6492\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 639us/step - loss: 0.5320 - accuracy: 0.7312 - val_loss: 0.5928 - val_accuracy: 0.6570\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 503us/step - loss: 0.5288 - accuracy: 0.7343 - val_loss: 0.5856 - val_accuracy: 0.6610\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 498us/step - loss: 0.5281 - accuracy: 0.7342 - val_loss: 0.5985 - val_accuracy: 0.6516\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.5273 - accuracy: 0.7326 - val_loss: 0.5979 - val_accuracy: 0.6527\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 462us/step - loss: 0.5262 - accuracy: 0.7345 - val_loss: 0.6019 - val_accuracy: 0.6492\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.5242 - accuracy: 0.7357 - val_loss: 0.5994 - val_accuracy: 0.6522\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 480us/step - loss: 0.5245 - accuracy: 0.7345 - val_loss: 0.5881 - val_accuracy: 0.6611\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.6746 - accuracy: 0.5821 - val_loss: 0.6872 - val_accuracy: 0.5321\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.6621 - accuracy: 0.6127 - val_loss: 0.6792 - val_accuracy: 0.5688\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.6535 - accuracy: 0.6293 - val_loss: 0.6708 - val_accuracy: 0.5988\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.6457 - accuracy: 0.6448 - val_loss: 0.6591 - val_accuracy: 0.6309\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.6381 - accuracy: 0.6573 - val_loss: 0.6481 - val_accuracy: 0.6492\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 477us/step - loss: 0.6313 - accuracy: 0.6655 - val_loss: 0.6476 - val_accuracy: 0.6446\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.6250 - accuracy: 0.6736 - val_loss: 0.6377 - val_accuracy: 0.6600\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 469us/step - loss: 0.6188 - accuracy: 0.6774 - val_loss: 0.6445 - val_accuracy: 0.6349\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.6131 - accuracy: 0.6828 - val_loss: 0.6362 - val_accuracy: 0.6455\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.6083 - accuracy: 0.6859 - val_loss: 0.6259 - val_accuracy: 0.6591\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.6020 - accuracy: 0.6920 - val_loss: 0.6309 - val_accuracy: 0.6455\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5976 - accuracy: 0.6938 - val_loss: 0.6226 - val_accuracy: 0.6552\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5939 - accuracy: 0.6952 - val_loss: 0.6132 - val_accuracy: 0.6662\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.5893 - accuracy: 0.6993 - val_loss: 0.6200 - val_accuracy: 0.6529\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5853 - accuracy: 0.7035 - val_loss: 0.6092 - val_accuracy: 0.6659\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.5817 - accuracy: 0.7066 - val_loss: 0.6144 - val_accuracy: 0.6581\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.5777 - accuracy: 0.7070 - val_loss: 0.6072 - val_accuracy: 0.6650\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5746 - accuracy: 0.7113 - val_loss: 0.5962 - val_accuracy: 0.6789\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 479us/step - loss: 0.5710 - accuracy: 0.7128 - val_loss: 0.6015 - val_accuracy: 0.6686\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5679 - accuracy: 0.7144 - val_loss: 0.6003 - val_accuracy: 0.6687\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.5647 - accuracy: 0.7157 - val_loss: 0.6049 - val_accuracy: 0.6612\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.5612 - accuracy: 0.7185 - val_loss: 0.6022 - val_accuracy: 0.6622\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.5595 - accuracy: 0.7195 - val_loss: 0.5895 - val_accuracy: 0.6734\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 456us/step - loss: 0.5551 - accuracy: 0.7236 - val_loss: 0.5990 - val_accuracy: 0.6618\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5540 - accuracy: 0.7253 - val_loss: 0.5916 - val_accuracy: 0.6688\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.5513 - accuracy: 0.7253 - val_loss: 0.6042 - val_accuracy: 0.6544\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 3s 945us/step - loss: 0.5494 - accuracy: 0.7270 - val_loss: 0.5947 - val_accuracy: 0.6629\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.5470 - accuracy: 0.7283 - val_loss: 0.6072 - val_accuracy: 0.6528\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 715us/step - loss: 0.5446 - accuracy: 0.7296 - val_loss: 0.5959 - val_accuracy: 0.6611\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 668us/step - loss: 0.5433 - accuracy: 0.7296 - val_loss: 0.5951 - val_accuracy: 0.6616\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 3s 928us/step - loss: 0.5412 - accuracy: 0.7312 - val_loss: 0.6004 - val_accuracy: 0.6569\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 3s 898us/step - loss: 0.5384 - accuracy: 0.7333 - val_loss: 0.6013 - val_accuracy: 0.6562\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 3s 1ms/step - loss: 0.5375 - accuracy: 0.7321 - val_loss: 0.6013 - val_accuracy: 0.6564\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 3s 944us/step - loss: 0.5347 - accuracy: 0.7351 - val_loss: 0.6086 - val_accuracy: 0.6496\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.5319 - accuracy: 0.7378 - val_loss: 0.6021 - val_accuracy: 0.6561\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 494us/step - loss: 0.5315 - accuracy: 0.7387 - val_loss: 0.5873 - val_accuracy: 0.6674\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 3s 832us/step - loss: 0.5300 - accuracy: 0.7371 - val_loss: 0.5889 - val_accuracy: 0.6664\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 3s 781us/step - loss: 0.5281 - accuracy: 0.7373 - val_loss: 0.6039 - val_accuracy: 0.6549\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 701us/step - loss: 0.5266 - accuracy: 0.7400 - val_loss: 0.6116 - val_accuracy: 0.6495\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.5252 - accuracy: 0.7396 - val_loss: 0.5951 - val_accuracy: 0.6629\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.5233 - accuracy: 0.7425 - val_loss: 0.5882 - val_accuracy: 0.6710\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.5216 - accuracy: 0.7424 - val_loss: 0.6016 - val_accuracy: 0.6568\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.5191 - accuracy: 0.7432 - val_loss: 0.5974 - val_accuracy: 0.6622\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5183 - accuracy: 0.7450 - val_loss: 0.6000 - val_accuracy: 0.6598\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.5175 - accuracy: 0.7451 - val_loss: 0.6060 - val_accuracy: 0.6548\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.5159 - accuracy: 0.7457 - val_loss: 0.5776 - val_accuracy: 0.6796\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 3s 990us/step - loss: 0.5147 - accuracy: 0.7462 - val_loss: 0.5946 - val_accuracy: 0.6645\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 736us/step - loss: 0.5130 - accuracy: 0.7473 - val_loss: 0.5990 - val_accuracy: 0.6619\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 3s 817us/step - loss: 0.5128 - accuracy: 0.7469 - val_loss: 0.6017 - val_accuracy: 0.6597\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.5121 - accuracy: 0.7470 - val_loss: 0.6007 - val_accuracy: 0.6615\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 595us/step - loss: 0.7088 - accuracy: 0.5179 - val_loss: 0.7290 - val_accuracy: 0.4494\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.6929 - accuracy: 0.5384 - val_loss: 0.7131 - val_accuracy: 0.4923\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.6818 - accuracy: 0.5593 - val_loss: 0.7019 - val_accuracy: 0.5232\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.6732 - accuracy: 0.5778 - val_loss: 0.6948 - val_accuracy: 0.5465\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.6669 - accuracy: 0.5908 - val_loss: 0.6868 - val_accuracy: 0.5705\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 741us/step - loss: 0.6613 - accuracy: 0.6034 - val_loss: 0.6777 - val_accuracy: 0.5813\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.6546 - accuracy: 0.6162 - val_loss: 0.6778 - val_accuracy: 0.5765\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.6501 - accuracy: 0.6256 - val_loss: 0.6766 - val_accuracy: 0.5785\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 695us/step - loss: 0.6456 - accuracy: 0.6344 - val_loss: 0.6766 - val_accuracy: 0.5762\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.6414 - accuracy: 0.6407 - val_loss: 0.6706 - val_accuracy: 0.5810\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.6364 - accuracy: 0.6508 - val_loss: 0.6632 - val_accuracy: 0.5903\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 678us/step - loss: 0.6328 - accuracy: 0.6565 - val_loss: 0.6623 - val_accuracy: 0.5890\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 677us/step - loss: 0.6298 - accuracy: 0.6607 - val_loss: 0.6623 - val_accuracy: 0.5903\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.6259 - accuracy: 0.6674 - val_loss: 0.6546 - val_accuracy: 0.6103\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.6217 - accuracy: 0.6707 - val_loss: 0.6636 - val_accuracy: 0.5895\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.6186 - accuracy: 0.6751 - val_loss: 0.6556 - val_accuracy: 0.6049\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.6149 - accuracy: 0.6786 - val_loss: 0.6515 - val_accuracy: 0.6132\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.6123 - accuracy: 0.6809 - val_loss: 0.6596 - val_accuracy: 0.6004\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 685us/step - loss: 0.6076 - accuracy: 0.6846 - val_loss: 0.6550 - val_accuracy: 0.6063\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.6049 - accuracy: 0.6870 - val_loss: 0.6415 - val_accuracy: 0.6226\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.6022 - accuracy: 0.6905 - val_loss: 0.6418 - val_accuracy: 0.6213\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5978 - accuracy: 0.6928 - val_loss: 0.6411 - val_accuracy: 0.6215\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.5952 - accuracy: 0.6957 - val_loss: 0.6395 - val_accuracy: 0.6230\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.5927 - accuracy: 0.6963 - val_loss: 0.6339 - val_accuracy: 0.6278\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5902 - accuracy: 0.6987 - val_loss: 0.6379 - val_accuracy: 0.6232\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5872 - accuracy: 0.7020 - val_loss: 0.6280 - val_accuracy: 0.6320\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.5847 - accuracy: 0.7032 - val_loss: 0.6339 - val_accuracy: 0.6270\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5817 - accuracy: 0.7052 - val_loss: 0.6302 - val_accuracy: 0.6303\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.5797 - accuracy: 0.7069 - val_loss: 0.6271 - val_accuracy: 0.6322\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.5765 - accuracy: 0.7058 - val_loss: 0.6195 - val_accuracy: 0.6366\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.5746 - accuracy: 0.7094 - val_loss: 0.6338 - val_accuracy: 0.6263\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.5729 - accuracy: 0.7112 - val_loss: 0.6320 - val_accuracy: 0.6266\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5700 - accuracy: 0.7114 - val_loss: 0.6134 - val_accuracy: 0.6401\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.5684 - accuracy: 0.7113 - val_loss: 0.6250 - val_accuracy: 0.6297\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.5665 - accuracy: 0.7133 - val_loss: 0.6248 - val_accuracy: 0.6297\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.5636 - accuracy: 0.7165 - val_loss: 0.6315 - val_accuracy: 0.6237\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 696us/step - loss: 0.5617 - accuracy: 0.7169 - val_loss: 0.6287 - val_accuracy: 0.6260\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.5599 - accuracy: 0.7180 - val_loss: 0.6202 - val_accuracy: 0.6331\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.5574 - accuracy: 0.7186 - val_loss: 0.6105 - val_accuracy: 0.6417\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.5567 - accuracy: 0.7181 - val_loss: 0.6139 - val_accuracy: 0.6382\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 658us/step - loss: 0.5553 - accuracy: 0.7198 - val_loss: 0.6250 - val_accuracy: 0.6301\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 639us/step - loss: 0.5534 - accuracy: 0.7207 - val_loss: 0.6244 - val_accuracy: 0.6315\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 715us/step - loss: 0.5504 - accuracy: 0.7221 - val_loss: 0.6263 - val_accuracy: 0.6316\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 693us/step - loss: 0.5497 - accuracy: 0.7226 - val_loss: 0.6289 - val_accuracy: 0.6301\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 3s 766us/step - loss: 0.5491 - accuracy: 0.7238 - val_loss: 0.6132 - val_accuracy: 0.6394\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 3s 790us/step - loss: 0.5455 - accuracy: 0.7243 - val_loss: 0.6004 - val_accuracy: 0.6478\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.5441 - accuracy: 0.7271 - val_loss: 0.6085 - val_accuracy: 0.6437\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.5430 - accuracy: 0.7266 - val_loss: 0.6215 - val_accuracy: 0.6375\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.5414 - accuracy: 0.7284 - val_loss: 0.6192 - val_accuracy: 0.6386\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.5406 - accuracy: 0.7264 - val_loss: 0.6118 - val_accuracy: 0.6440\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.6808 - accuracy: 0.5759 - val_loss: 0.6996 - val_accuracy: 0.5434\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.6672 - accuracy: 0.6038 - val_loss: 0.6864 - val_accuracy: 0.5860\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.6582 - accuracy: 0.6208 - val_loss: 0.6777 - val_accuracy: 0.6071\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.6506 - accuracy: 0.6353 - val_loss: 0.6611 - val_accuracy: 0.6381\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.6430 - accuracy: 0.6457 - val_loss: 0.6652 - val_accuracy: 0.6274\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.6382 - accuracy: 0.6522 - val_loss: 0.6494 - val_accuracy: 0.6507\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.6328 - accuracy: 0.6595 - val_loss: 0.6485 - val_accuracy: 0.6470\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.6283 - accuracy: 0.6648 - val_loss: 0.6422 - val_accuracy: 0.6509\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.6231 - accuracy: 0.6712 - val_loss: 0.6447 - val_accuracy: 0.6430\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 502us/step - loss: 0.6184 - accuracy: 0.6731 - val_loss: 0.6407 - val_accuracy: 0.6461\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.6149 - accuracy: 0.6759 - val_loss: 0.6333 - val_accuracy: 0.6512\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.6107 - accuracy: 0.6804 - val_loss: 0.6343 - val_accuracy: 0.6466\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.6064 - accuracy: 0.6828 - val_loss: 0.6364 - val_accuracy: 0.6403\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.6027 - accuracy: 0.6886 - val_loss: 0.6256 - val_accuracy: 0.6512\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5994 - accuracy: 0.6916 - val_loss: 0.6191 - val_accuracy: 0.6571\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5960 - accuracy: 0.6929 - val_loss: 0.6147 - val_accuracy: 0.6587\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5913 - accuracy: 0.6971 - val_loss: 0.6110 - val_accuracy: 0.6611\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.5890 - accuracy: 0.6989 - val_loss: 0.6202 - val_accuracy: 0.6500\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.5862 - accuracy: 0.7004 - val_loss: 0.6133 - val_accuracy: 0.6579\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.5831 - accuracy: 0.7036 - val_loss: 0.6089 - val_accuracy: 0.6653\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 635us/step - loss: 0.5805 - accuracy: 0.7050 - val_loss: 0.6098 - val_accuracy: 0.6649\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5776 - accuracy: 0.7071 - val_loss: 0.6160 - val_accuracy: 0.6549\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.5747 - accuracy: 0.7101 - val_loss: 0.5935 - val_accuracy: 0.6765\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.5717 - accuracy: 0.7102 - val_loss: 0.6026 - val_accuracy: 0.6687\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.5692 - accuracy: 0.7132 - val_loss: 0.6069 - val_accuracy: 0.6649\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.5667 - accuracy: 0.7152 - val_loss: 0.5990 - val_accuracy: 0.6705\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.5639 - accuracy: 0.7173 - val_loss: 0.6058 - val_accuracy: 0.6626\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.5614 - accuracy: 0.7168 - val_loss: 0.5961 - val_accuracy: 0.6675\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.5595 - accuracy: 0.7191 - val_loss: 0.6174 - val_accuracy: 0.6496\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.5579 - accuracy: 0.7194 - val_loss: 0.5936 - val_accuracy: 0.6679\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.5550 - accuracy: 0.7224 - val_loss: 0.6051 - val_accuracy: 0.6589\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.5526 - accuracy: 0.7233 - val_loss: 0.6027 - val_accuracy: 0.6601\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5515 - accuracy: 0.7239 - val_loss: 0.5999 - val_accuracy: 0.6608\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.5488 - accuracy: 0.7259 - val_loss: 0.6124 - val_accuracy: 0.6497\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5461 - accuracy: 0.7290 - val_loss: 0.6011 - val_accuracy: 0.6593\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5448 - accuracy: 0.7283 - val_loss: 0.5969 - val_accuracy: 0.6614\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.5431 - accuracy: 0.7280 - val_loss: 0.6078 - val_accuracy: 0.6483\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.5397 - accuracy: 0.7311 - val_loss: 0.5896 - val_accuracy: 0.6656\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 652us/step - loss: 0.5384 - accuracy: 0.7304 - val_loss: 0.5950 - val_accuracy: 0.6615\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 669us/step - loss: 0.5360 - accuracy: 0.7312 - val_loss: 0.5986 - val_accuracy: 0.6577\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.5352 - accuracy: 0.7312 - val_loss: 0.6099 - val_accuracy: 0.6434\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.5350 - accuracy: 0.7308 - val_loss: 0.5968 - val_accuracy: 0.6582\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.5326 - accuracy: 0.7337 - val_loss: 0.6084 - val_accuracy: 0.6466\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.5303 - accuracy: 0.7342 - val_loss: 0.5850 - val_accuracy: 0.6642\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.5283 - accuracy: 0.7355 - val_loss: 0.5800 - val_accuracy: 0.6666\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 647us/step - loss: 0.5272 - accuracy: 0.7372 - val_loss: 0.6109 - val_accuracy: 0.6431\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 667us/step - loss: 0.5252 - accuracy: 0.7351 - val_loss: 0.6055 - val_accuracy: 0.6493\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.5238 - accuracy: 0.7364 - val_loss: 0.5788 - val_accuracy: 0.6677\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.5234 - accuracy: 0.7379 - val_loss: 0.5986 - val_accuracy: 0.6547\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5222 - accuracy: 0.7395 - val_loss: 0.5859 - val_accuracy: 0.6628\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.7415 - accuracy: 0.4778 - val_loss: 0.7055 - val_accuracy: 0.4476\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 666us/step - loss: 0.7057 - accuracy: 0.5064 - val_loss: 0.7015 - val_accuracy: 0.4649\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 712us/step - loss: 0.6930 - accuracy: 0.5287 - val_loss: 0.6960 - val_accuracy: 0.5351\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.6838 - accuracy: 0.5478 - val_loss: 0.6828 - val_accuracy: 0.6036\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.6751 - accuracy: 0.5653 - val_loss: 0.6801 - val_accuracy: 0.6039\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.6671 - accuracy: 0.5860 - val_loss: 0.6629 - val_accuracy: 0.6540\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 655us/step - loss: 0.6610 - accuracy: 0.5978 - val_loss: 0.6635 - val_accuracy: 0.6362\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.6530 - accuracy: 0.6139 - val_loss: 0.6572 - val_accuracy: 0.6384\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.6470 - accuracy: 0.6256 - val_loss: 0.6493 - val_accuracy: 0.6453\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.6413 - accuracy: 0.6317 - val_loss: 0.6511 - val_accuracy: 0.6368\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.6339 - accuracy: 0.6402 - val_loss: 0.6447 - val_accuracy: 0.6417\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.6266 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6420\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.6213 - accuracy: 0.6539 - val_loss: 0.6295 - val_accuracy: 0.6547\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.6163 - accuracy: 0.6588 - val_loss: 0.6285 - val_accuracy: 0.6514\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.6119 - accuracy: 0.6637 - val_loss: 0.6264 - val_accuracy: 0.6517\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.6073 - accuracy: 0.6671 - val_loss: 0.6255 - val_accuracy: 0.6498\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.6027 - accuracy: 0.6729 - val_loss: 0.6169 - val_accuracy: 0.6643\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5987 - accuracy: 0.6764 - val_loss: 0.6188 - val_accuracy: 0.6601\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 624us/step - loss: 0.5950 - accuracy: 0.6834 - val_loss: 0.6088 - val_accuracy: 0.6713\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.5904 - accuracy: 0.6868 - val_loss: 0.6068 - val_accuracy: 0.6694\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.5868 - accuracy: 0.6904 - val_loss: 0.6173 - val_accuracy: 0.6533\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.5835 - accuracy: 0.6974 - val_loss: 0.6092 - val_accuracy: 0.6590\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.5805 - accuracy: 0.7000 - val_loss: 0.6062 - val_accuracy: 0.6592\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.5777 - accuracy: 0.7034 - val_loss: 0.5983 - val_accuracy: 0.6638\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5741 - accuracy: 0.7062 - val_loss: 0.6048 - val_accuracy: 0.6558\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5718 - accuracy: 0.7094 - val_loss: 0.5967 - val_accuracy: 0.6600\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.5684 - accuracy: 0.7123 - val_loss: 0.6070 - val_accuracy: 0.6498\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.5643 - accuracy: 0.7171 - val_loss: 0.5981 - val_accuracy: 0.6558\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 507us/step - loss: 0.5627 - accuracy: 0.7169 - val_loss: 0.5902 - val_accuracy: 0.6595\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.5597 - accuracy: 0.7193 - val_loss: 0.6002 - val_accuracy: 0.6528\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 504us/step - loss: 0.5578 - accuracy: 0.7212 - val_loss: 0.5959 - val_accuracy: 0.6559\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 483us/step - loss: 0.5547 - accuracy: 0.7228 - val_loss: 0.6040 - val_accuracy: 0.6491\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 497us/step - loss: 0.5520 - accuracy: 0.7245 - val_loss: 0.6018 - val_accuracy: 0.6501\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.5495 - accuracy: 0.7257 - val_loss: 0.6047 - val_accuracy: 0.6480\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 459us/step - loss: 0.5471 - accuracy: 0.7275 - val_loss: 0.5923 - val_accuracy: 0.6544\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 481us/step - loss: 0.5458 - accuracy: 0.7270 - val_loss: 0.5953 - val_accuracy: 0.6527\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 499us/step - loss: 0.5426 - accuracy: 0.7295 - val_loss: 0.5877 - val_accuracy: 0.6560\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5405 - accuracy: 0.7286 - val_loss: 0.5973 - val_accuracy: 0.6509\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 488us/step - loss: 0.5388 - accuracy: 0.7311 - val_loss: 0.5918 - val_accuracy: 0.6554\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.5353 - accuracy: 0.7323 - val_loss: 0.5849 - val_accuracy: 0.6584\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.5352 - accuracy: 0.7314 - val_loss: 0.6021 - val_accuracy: 0.6498\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5316 - accuracy: 0.7347 - val_loss: 0.5796 - val_accuracy: 0.6619\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.5304 - accuracy: 0.7343 - val_loss: 0.5909 - val_accuracy: 0.6555\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5279 - accuracy: 0.7351 - val_loss: 0.5954 - val_accuracy: 0.6538\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 495us/step - loss: 0.5259 - accuracy: 0.7356 - val_loss: 0.5878 - val_accuracy: 0.6570\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 496us/step - loss: 0.5259 - accuracy: 0.7351 - val_loss: 0.5908 - val_accuracy: 0.6550\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 489us/step - loss: 0.5236 - accuracy: 0.7383 - val_loss: 0.5924 - val_accuracy: 0.6538\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.5222 - accuracy: 0.7384 - val_loss: 0.5965 - val_accuracy: 0.6524\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 514us/step - loss: 0.5207 - accuracy: 0.7379 - val_loss: 0.5929 - val_accuracy: 0.6539\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5183 - accuracy: 0.7403 - val_loss: 0.5973 - val_accuracy: 0.6521\n",
      "\n",
      "Training model with batch_size=16, target_eps=1.0...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 5.05 iterated over 167200 steps satisfies differential privacy with eps = 0.122 and delta = 1e-05.\n",
      "The optimal RDP order is 256.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 2.5749999999999997 iterated over 167200 steps satisfies differential privacy with eps = 0.263 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.3375 iterated over 167200 steps satisfies differential privacy with eps = 0.585 and delta = 1e-05.\n",
      "The optimal RDP order is 28.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 0.71875 iterated over 167200 steps satisfies differential privacy with eps = 2.24 and delta = 1e-05.\n",
      "The optimal RDP order is 7.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.028125 iterated over 167200 steps satisfies differential privacy with eps = 0.959 and delta = 1e-05.\n",
      "The optimal RDP order is 16.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 0.8734375 iterated over 167200 steps satisfies differential privacy with eps = 1.38 and delta = 1e-05.\n",
      "The optimal RDP order is 11.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 0.9507812499999999 iterated over 167200 steps satisfies differential privacy with eps = 1.13 and delta = 1e-05.\n",
      "The optimal RDP order is 14.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 0.9894531249999999 iterated over 167200 steps satisfies differential privacy with eps = 1.03 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.0087890625 iterated over 167200 steps satisfies differential privacy with eps = 1.01 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.01845703125 iterated over 167200 steps satisfies differential privacy with eps = 0.972 and delta = 1e-05.\n",
      "The optimal RDP order is 16.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.013623046875 iterated over 167200 steps satisfies differential privacy with eps = 0.991 and delta = 1e-05.\n",
      "The optimal RDP order is 16.0.\n",
      "Epoch 1/50\n",
      "3283/3344 [============================>.] - ETA: 0s - loss: 0.7041 - accuracy: 0.5336WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0014s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.7039 - accuracy: 0.5340 - val_loss: 0.7071 - val_accuracy: 0.5095\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.6836 - accuracy: 0.5661 - val_loss: 0.6878 - val_accuracy: 0.5641\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.6707 - accuracy: 0.5889 - val_loss: 0.6799 - val_accuracy: 0.5820\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.6616 - accuracy: 0.6072 - val_loss: 0.6817 - val_accuracy: 0.5804\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.6537 - accuracy: 0.6251 - val_loss: 0.6611 - val_accuracy: 0.6244\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.6459 - accuracy: 0.6374 - val_loss: 0.6713 - val_accuracy: 0.6008\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.6398 - accuracy: 0.6431 - val_loss: 0.6610 - val_accuracy: 0.6225\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.6331 - accuracy: 0.6540 - val_loss: 0.6549 - val_accuracy: 0.6335\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.6277 - accuracy: 0.6600 - val_loss: 0.6496 - val_accuracy: 0.6387\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.6228 - accuracy: 0.6665 - val_loss: 0.6453 - val_accuracy: 0.6433\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.6187 - accuracy: 0.6711 - val_loss: 0.6365 - val_accuracy: 0.6529\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 645us/step - loss: 0.6132 - accuracy: 0.6784 - val_loss: 0.6418 - val_accuracy: 0.6456\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.6086 - accuracy: 0.6803 - val_loss: 0.6364 - val_accuracy: 0.6501\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.6046 - accuracy: 0.6861 - val_loss: 0.6272 - val_accuracy: 0.6589\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5989 - accuracy: 0.6927 - val_loss: 0.6266 - val_accuracy: 0.6580\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.5958 - accuracy: 0.6935 - val_loss: 0.6184 - val_accuracy: 0.6644\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 527us/step - loss: 0.5918 - accuracy: 0.6975 - val_loss: 0.6245 - val_accuracy: 0.6555\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5880 - accuracy: 0.7007 - val_loss: 0.6166 - val_accuracy: 0.6621\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.5837 - accuracy: 0.7060 - val_loss: 0.6186 - val_accuracy: 0.6584\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.5814 - accuracy: 0.7058 - val_loss: 0.6193 - val_accuracy: 0.6561\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 694us/step - loss: 0.5782 - accuracy: 0.7087 - val_loss: 0.6187 - val_accuracy: 0.6544\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5741 - accuracy: 0.7126 - val_loss: 0.6088 - val_accuracy: 0.6656\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5713 - accuracy: 0.7147 - val_loss: 0.6114 - val_accuracy: 0.6624\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5681 - accuracy: 0.7164 - val_loss: 0.6126 - val_accuracy: 0.6592\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5644 - accuracy: 0.7201 - val_loss: 0.6110 - val_accuracy: 0.6598\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 648us/step - loss: 0.5621 - accuracy: 0.7205 - val_loss: 0.5991 - val_accuracy: 0.6683\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.5594 - accuracy: 0.7217 - val_loss: 0.6066 - val_accuracy: 0.6607\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 670us/step - loss: 0.5576 - accuracy: 0.7247 - val_loss: 0.5969 - val_accuracy: 0.6704\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5552 - accuracy: 0.7243 - val_loss: 0.6065 - val_accuracy: 0.6603\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5526 - accuracy: 0.7273 - val_loss: 0.6011 - val_accuracy: 0.6658\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.5504 - accuracy: 0.7283 - val_loss: 0.6016 - val_accuracy: 0.6644\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.5479 - accuracy: 0.7280 - val_loss: 0.6033 - val_accuracy: 0.6628\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 486us/step - loss: 0.5452 - accuracy: 0.7309 - val_loss: 0.6005 - val_accuracy: 0.6652\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 501us/step - loss: 0.5439 - accuracy: 0.7299 - val_loss: 0.6061 - val_accuracy: 0.6602\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5409 - accuracy: 0.7319 - val_loss: 0.6132 - val_accuracy: 0.6548\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 475us/step - loss: 0.5389 - accuracy: 0.7325 - val_loss: 0.5993 - val_accuracy: 0.6669\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.5379 - accuracy: 0.7330 - val_loss: 0.5910 - val_accuracy: 0.6730\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.5350 - accuracy: 0.7346 - val_loss: 0.5936 - val_accuracy: 0.6707\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.5332 - accuracy: 0.7363 - val_loss: 0.6003 - val_accuracy: 0.6664\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.5310 - accuracy: 0.7355 - val_loss: 0.5943 - val_accuracy: 0.6696\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 471us/step - loss: 0.5294 - accuracy: 0.7361 - val_loss: 0.6038 - val_accuracy: 0.6644\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.5282 - accuracy: 0.7384 - val_loss: 0.6122 - val_accuracy: 0.6568\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.5260 - accuracy: 0.7377 - val_loss: 0.5939 - val_accuracy: 0.6704\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.5246 - accuracy: 0.7390 - val_loss: 0.5990 - val_accuracy: 0.6656\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5230 - accuracy: 0.7394 - val_loss: 0.5999 - val_accuracy: 0.6650\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.5217 - accuracy: 0.7409 - val_loss: 0.5951 - val_accuracy: 0.6674\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.5202 - accuracy: 0.7423 - val_loss: 0.5998 - val_accuracy: 0.6631\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.5190 - accuracy: 0.7421 - val_loss: 0.5889 - val_accuracy: 0.6723\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.5168 - accuracy: 0.7434 - val_loss: 0.5918 - val_accuracy: 0.6680\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 742us/step - loss: 0.5151 - accuracy: 0.7444 - val_loss: 0.5924 - val_accuracy: 0.6673\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 685us/step - loss: 0.7216 - accuracy: 0.5245 - val_loss: 0.7333 - val_accuracy: 0.3081\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.6891 - accuracy: 0.5586 - val_loss: 0.7137 - val_accuracy: 0.4341\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 673us/step - loss: 0.6786 - accuracy: 0.5842 - val_loss: 0.7060 - val_accuracy: 0.4683\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.6691 - accuracy: 0.6058 - val_loss: 0.6956 - val_accuracy: 0.5016\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 3s 865us/step - loss: 0.6621 - accuracy: 0.6217 - val_loss: 0.6895 - val_accuracy: 0.5138\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 3s 981us/step - loss: 0.6555 - accuracy: 0.6309 - val_loss: 0.6833 - val_accuracy: 0.5314\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 3s 769us/step - loss: 0.6490 - accuracy: 0.6418 - val_loss: 0.6776 - val_accuracy: 0.5394\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 674us/step - loss: 0.6435 - accuracy: 0.6489 - val_loss: 0.6747 - val_accuracy: 0.5440\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 656us/step - loss: 0.6379 - accuracy: 0.6547 - val_loss: 0.6664 - val_accuracy: 0.5563\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.6336 - accuracy: 0.6582 - val_loss: 0.6592 - val_accuracy: 0.5688\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 3s 752us/step - loss: 0.6287 - accuracy: 0.6640 - val_loss: 0.6581 - val_accuracy: 0.5687\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.6238 - accuracy: 0.6663 - val_loss: 0.6540 - val_accuracy: 0.5760\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.6191 - accuracy: 0.6713 - val_loss: 0.6487 - val_accuracy: 0.5877\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.6150 - accuracy: 0.6756 - val_loss: 0.6482 - val_accuracy: 0.5890\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.6112 - accuracy: 0.6765 - val_loss: 0.6411 - val_accuracy: 0.6035\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.6071 - accuracy: 0.6818 - val_loss: 0.6427 - val_accuracy: 0.5998\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.6036 - accuracy: 0.6840 - val_loss: 0.6393 - val_accuracy: 0.6075\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5996 - accuracy: 0.6847 - val_loss: 0.6370 - val_accuracy: 0.6116\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.5963 - accuracy: 0.6895 - val_loss: 0.6300 - val_accuracy: 0.6211\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.5920 - accuracy: 0.6931 - val_loss: 0.6419 - val_accuracy: 0.6030\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 601us/step - loss: 0.5896 - accuracy: 0.6941 - val_loss: 0.6290 - val_accuracy: 0.6211\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.5866 - accuracy: 0.6967 - val_loss: 0.6293 - val_accuracy: 0.6198\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.5824 - accuracy: 0.6998 - val_loss: 0.6151 - val_accuracy: 0.6360\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.5808 - accuracy: 0.7015 - val_loss: 0.6237 - val_accuracy: 0.6252\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.5775 - accuracy: 0.7044 - val_loss: 0.6164 - val_accuracy: 0.6353\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.5740 - accuracy: 0.7053 - val_loss: 0.6101 - val_accuracy: 0.6413\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.5729 - accuracy: 0.7055 - val_loss: 0.6187 - val_accuracy: 0.6319\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.5703 - accuracy: 0.7075 - val_loss: 0.6181 - val_accuracy: 0.6331\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5664 - accuracy: 0.7102 - val_loss: 0.5989 - val_accuracy: 0.6575\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 542us/step - loss: 0.5638 - accuracy: 0.7124 - val_loss: 0.6148 - val_accuracy: 0.6363\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.5615 - accuracy: 0.7146 - val_loss: 0.6085 - val_accuracy: 0.6449\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.5586 - accuracy: 0.7158 - val_loss: 0.6060 - val_accuracy: 0.6512\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.5569 - accuracy: 0.7161 - val_loss: 0.6214 - val_accuracy: 0.6322\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.5545 - accuracy: 0.7187 - val_loss: 0.6062 - val_accuracy: 0.6528\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5518 - accuracy: 0.7231 - val_loss: 0.6084 - val_accuracy: 0.6495\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.5497 - accuracy: 0.7201 - val_loss: 0.6136 - val_accuracy: 0.6446\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.5476 - accuracy: 0.7237 - val_loss: 0.6050 - val_accuracy: 0.6543\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5460 - accuracy: 0.7234 - val_loss: 0.6024 - val_accuracy: 0.6569\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.5431 - accuracy: 0.7267 - val_loss: 0.6055 - val_accuracy: 0.6532\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.5415 - accuracy: 0.7273 - val_loss: 0.5997 - val_accuracy: 0.6577\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.5400 - accuracy: 0.7284 - val_loss: 0.6129 - val_accuracy: 0.6492\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.5378 - accuracy: 0.7303 - val_loss: 0.5904 - val_accuracy: 0.6676\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.5356 - accuracy: 0.7305 - val_loss: 0.6024 - val_accuracy: 0.6568\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.5342 - accuracy: 0.7314 - val_loss: 0.5875 - val_accuracy: 0.6707\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.5337 - accuracy: 0.7321 - val_loss: 0.5946 - val_accuracy: 0.6649\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5305 - accuracy: 0.7331 - val_loss: 0.6058 - val_accuracy: 0.6564\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.5293 - accuracy: 0.7342 - val_loss: 0.6016 - val_accuracy: 0.6606\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5269 - accuracy: 0.7354 - val_loss: 0.5958 - val_accuracy: 0.6659\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5253 - accuracy: 0.7378 - val_loss: 0.5955 - val_accuracy: 0.6662\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.5252 - accuracy: 0.7370 - val_loss: 0.6125 - val_accuracy: 0.6537\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 626us/step - loss: 0.7036 - accuracy: 0.5284 - val_loss: 0.7007 - val_accuracy: 0.4330\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.6849 - accuracy: 0.5664 - val_loss: 0.6881 - val_accuracy: 0.5248\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.6726 - accuracy: 0.5949 - val_loss: 0.6832 - val_accuracy: 0.5515\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 717us/step - loss: 0.6613 - accuracy: 0.6210 - val_loss: 0.6653 - val_accuracy: 0.6238\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 506us/step - loss: 0.6539 - accuracy: 0.6344 - val_loss: 0.6643 - val_accuracy: 0.6199\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 492us/step - loss: 0.6473 - accuracy: 0.6482 - val_loss: 0.6588 - val_accuracy: 0.6295\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.6406 - accuracy: 0.6591 - val_loss: 0.6579 - val_accuracy: 0.6256\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.6344 - accuracy: 0.6633 - val_loss: 0.6539 - val_accuracy: 0.6291\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 500us/step - loss: 0.6282 - accuracy: 0.6732 - val_loss: 0.6451 - val_accuracy: 0.6408\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.6227 - accuracy: 0.6773 - val_loss: 0.6392 - val_accuracy: 0.6440\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.6170 - accuracy: 0.6810 - val_loss: 0.6423 - val_accuracy: 0.6349\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.6114 - accuracy: 0.6874 - val_loss: 0.6352 - val_accuracy: 0.6393\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.6068 - accuracy: 0.6887 - val_loss: 0.6257 - val_accuracy: 0.6514\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.6016 - accuracy: 0.6928 - val_loss: 0.6269 - val_accuracy: 0.6448\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.5983 - accuracy: 0.6960 - val_loss: 0.6259 - val_accuracy: 0.6435\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5935 - accuracy: 0.7001 - val_loss: 0.6165 - val_accuracy: 0.6511\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.5891 - accuracy: 0.7020 - val_loss: 0.6135 - val_accuracy: 0.6524\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.5859 - accuracy: 0.7027 - val_loss: 0.6185 - val_accuracy: 0.6441\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.5830 - accuracy: 0.7040 - val_loss: 0.6141 - val_accuracy: 0.6469\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.5793 - accuracy: 0.7082 - val_loss: 0.6195 - val_accuracy: 0.6394\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.5758 - accuracy: 0.7096 - val_loss: 0.6032 - val_accuracy: 0.6553\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.5728 - accuracy: 0.7125 - val_loss: 0.6111 - val_accuracy: 0.6457\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5698 - accuracy: 0.7138 - val_loss: 0.6130 - val_accuracy: 0.6430\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.5675 - accuracy: 0.7144 - val_loss: 0.6004 - val_accuracy: 0.6544\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 624us/step - loss: 0.5654 - accuracy: 0.7165 - val_loss: 0.6056 - val_accuracy: 0.6480\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.5634 - accuracy: 0.7157 - val_loss: 0.6062 - val_accuracy: 0.6458\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.5600 - accuracy: 0.7189 - val_loss: 0.5991 - val_accuracy: 0.6522\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.5589 - accuracy: 0.7194 - val_loss: 0.5852 - val_accuracy: 0.6638\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 635us/step - loss: 0.5562 - accuracy: 0.7218 - val_loss: 0.6017 - val_accuracy: 0.6466\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5537 - accuracy: 0.7242 - val_loss: 0.5973 - val_accuracy: 0.6492\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.5536 - accuracy: 0.7210 - val_loss: 0.5990 - val_accuracy: 0.6466\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.5511 - accuracy: 0.7237 - val_loss: 0.6082 - val_accuracy: 0.6388\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.5476 - accuracy: 0.7269 - val_loss: 0.6048 - val_accuracy: 0.6410\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.5472 - accuracy: 0.7253 - val_loss: 0.5895 - val_accuracy: 0.6553\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.5451 - accuracy: 0.7285 - val_loss: 0.6020 - val_accuracy: 0.6425\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.5434 - accuracy: 0.7277 - val_loss: 0.6035 - val_accuracy: 0.6396\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 634us/step - loss: 0.5415 - accuracy: 0.7303 - val_loss: 0.5994 - val_accuracy: 0.6431\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.5395 - accuracy: 0.7290 - val_loss: 0.6034 - val_accuracy: 0.6389\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.5384 - accuracy: 0.7304 - val_loss: 0.5923 - val_accuracy: 0.6516\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.5367 - accuracy: 0.7296 - val_loss: 0.6064 - val_accuracy: 0.6353\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.5350 - accuracy: 0.7315 - val_loss: 0.5892 - val_accuracy: 0.6547\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.5337 - accuracy: 0.7318 - val_loss: 0.6194 - val_accuracy: 0.6253\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 665us/step - loss: 0.5328 - accuracy: 0.7328 - val_loss: 0.5992 - val_accuracy: 0.6439\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.5310 - accuracy: 0.7345 - val_loss: 0.5870 - val_accuracy: 0.6569\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.5296 - accuracy: 0.7349 - val_loss: 0.5956 - val_accuracy: 0.6479\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 551us/step - loss: 0.5286 - accuracy: 0.7362 - val_loss: 0.5989 - val_accuracy: 0.6451\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.5271 - accuracy: 0.7354 - val_loss: 0.5970 - val_accuracy: 0.6475\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.5247 - accuracy: 0.7381 - val_loss: 0.6001 - val_accuracy: 0.6446\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5243 - accuracy: 0.7372 - val_loss: 0.5942 - val_accuracy: 0.6512\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 656us/step - loss: 0.5218 - accuracy: 0.7392 - val_loss: 0.5927 - val_accuracy: 0.6523\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 662us/step - loss: 0.7025 - accuracy: 0.5279 - val_loss: 0.7309 - val_accuracy: 0.2363\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.6875 - accuracy: 0.5479 - val_loss: 0.7144 - val_accuracy: 0.3797\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 645us/step - loss: 0.6801 - accuracy: 0.5624 - val_loss: 0.7029 - val_accuracy: 0.4953\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 604us/step - loss: 0.6720 - accuracy: 0.5836 - val_loss: 0.7024 - val_accuracy: 0.5029\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 3s 758us/step - loss: 0.6665 - accuracy: 0.5911 - val_loss: 0.6984 - val_accuracy: 0.5168\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.6608 - accuracy: 0.6086 - val_loss: 0.6894 - val_accuracy: 0.5453\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.6547 - accuracy: 0.6197 - val_loss: 0.6933 - val_accuracy: 0.5319\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 526us/step - loss: 0.6498 - accuracy: 0.6265 - val_loss: 0.6841 - val_accuracy: 0.5644\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 641us/step - loss: 0.6450 - accuracy: 0.6340 - val_loss: 0.6772 - val_accuracy: 0.5828\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.6405 - accuracy: 0.6396 - val_loss: 0.6758 - val_accuracy: 0.5842\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.6362 - accuracy: 0.6424 - val_loss: 0.6667 - val_accuracy: 0.6019\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.6317 - accuracy: 0.6476 - val_loss: 0.6676 - val_accuracy: 0.5955\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.6272 - accuracy: 0.6555 - val_loss: 0.6614 - val_accuracy: 0.6070\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.6236 - accuracy: 0.6582 - val_loss: 0.6572 - val_accuracy: 0.6134\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.6196 - accuracy: 0.6598 - val_loss: 0.6545 - val_accuracy: 0.6148\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 697us/step - loss: 0.6161 - accuracy: 0.6632 - val_loss: 0.6496 - val_accuracy: 0.6226\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.6125 - accuracy: 0.6669 - val_loss: 0.6481 - val_accuracy: 0.6240\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.6091 - accuracy: 0.6678 - val_loss: 0.6428 - val_accuracy: 0.6313\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.6064 - accuracy: 0.6737 - val_loss: 0.6362 - val_accuracy: 0.6399\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.6037 - accuracy: 0.6722 - val_loss: 0.6416 - val_accuracy: 0.6319\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.6000 - accuracy: 0.6776 - val_loss: 0.6294 - val_accuracy: 0.6517\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 624us/step - loss: 0.5976 - accuracy: 0.6796 - val_loss: 0.6298 - val_accuracy: 0.6499\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 692us/step - loss: 0.5942 - accuracy: 0.6819 - val_loss: 0.6345 - val_accuracy: 0.6426\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.5927 - accuracy: 0.6839 - val_loss: 0.6285 - val_accuracy: 0.6509\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 639us/step - loss: 0.5896 - accuracy: 0.6848 - val_loss: 0.6235 - val_accuracy: 0.6566\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 668us/step - loss: 0.5871 - accuracy: 0.6871 - val_loss: 0.6323 - val_accuracy: 0.6447\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 684us/step - loss: 0.5852 - accuracy: 0.6883 - val_loss: 0.6301 - val_accuracy: 0.6481\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.5823 - accuracy: 0.6905 - val_loss: 0.6239 - val_accuracy: 0.6531\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5806 - accuracy: 0.6915 - val_loss: 0.6258 - val_accuracy: 0.6503\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 652us/step - loss: 0.5786 - accuracy: 0.6941 - val_loss: 0.6292 - val_accuracy: 0.6460\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.5767 - accuracy: 0.6964 - val_loss: 0.6344 - val_accuracy: 0.6399\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.5740 - accuracy: 0.6988 - val_loss: 0.6185 - val_accuracy: 0.6534\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 711us/step - loss: 0.5724 - accuracy: 0.6999 - val_loss: 0.6255 - val_accuracy: 0.6470\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.5695 - accuracy: 0.7028 - val_loss: 0.6165 - val_accuracy: 0.6538\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.5676 - accuracy: 0.7042 - val_loss: 0.6204 - val_accuracy: 0.6506\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5660 - accuracy: 0.7056 - val_loss: 0.6196 - val_accuracy: 0.6519\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.5642 - accuracy: 0.7059 - val_loss: 0.6255 - val_accuracy: 0.6480\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 729us/step - loss: 0.5622 - accuracy: 0.7083 - val_loss: 0.6098 - val_accuracy: 0.6619\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.5605 - accuracy: 0.7118 - val_loss: 0.6204 - val_accuracy: 0.6529\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.5593 - accuracy: 0.7114 - val_loss: 0.6198 - val_accuracy: 0.6551\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 520us/step - loss: 0.5566 - accuracy: 0.7128 - val_loss: 0.6150 - val_accuracy: 0.6603\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5560 - accuracy: 0.7141 - val_loss: 0.6229 - val_accuracy: 0.6549\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.5542 - accuracy: 0.7152 - val_loss: 0.6151 - val_accuracy: 0.6618\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5528 - accuracy: 0.7165 - val_loss: 0.6173 - val_accuracy: 0.6606\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5508 - accuracy: 0.7167 - val_loss: 0.6253 - val_accuracy: 0.6554\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.5500 - accuracy: 0.7183 - val_loss: 0.6094 - val_accuracy: 0.6685\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.5482 - accuracy: 0.7195 - val_loss: 0.6089 - val_accuracy: 0.6692\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5471 - accuracy: 0.7202 - val_loss: 0.6085 - val_accuracy: 0.6697\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.5449 - accuracy: 0.7232 - val_loss: 0.6135 - val_accuracy: 0.6665\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 508us/step - loss: 0.5442 - accuracy: 0.7235 - val_loss: 0.6202 - val_accuracy: 0.6624\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.7182 - accuracy: 0.5122 - val_loss: 0.7172 - val_accuracy: 0.4695\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.6945 - accuracy: 0.5449 - val_loss: 0.7004 - val_accuracy: 0.5198\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.6816 - accuracy: 0.5686 - val_loss: 0.6863 - val_accuracy: 0.5591\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 669us/step - loss: 0.6746 - accuracy: 0.5825 - val_loss: 0.6841 - val_accuracy: 0.5760\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.6642 - accuracy: 0.6019 - val_loss: 0.6756 - val_accuracy: 0.5903\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.6587 - accuracy: 0.6137 - val_loss: 0.6718 - val_accuracy: 0.5935\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.6495 - accuracy: 0.6283 - val_loss: 0.6638 - val_accuracy: 0.6102\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 656us/step - loss: 0.6424 - accuracy: 0.6378 - val_loss: 0.6596 - val_accuracy: 0.6086\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.6332 - accuracy: 0.6485 - val_loss: 0.6629 - val_accuracy: 0.6010\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.6274 - accuracy: 0.6576 - val_loss: 0.6507 - val_accuracy: 0.6214\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 531us/step - loss: 0.6228 - accuracy: 0.6638 - val_loss: 0.6429 - val_accuracy: 0.6325\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.6155 - accuracy: 0.6685 - val_loss: 0.6413 - val_accuracy: 0.6308\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.6108 - accuracy: 0.6739 - val_loss: 0.6409 - val_accuracy: 0.6279\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.6068 - accuracy: 0.6757 - val_loss: 0.6389 - val_accuracy: 0.6269\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.6024 - accuracy: 0.6810 - val_loss: 0.6247 - val_accuracy: 0.6433\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5985 - accuracy: 0.6833 - val_loss: 0.6318 - val_accuracy: 0.6341\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.5939 - accuracy: 0.6882 - val_loss: 0.6242 - val_accuracy: 0.6395\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.5888 - accuracy: 0.6919 - val_loss: 0.6195 - val_accuracy: 0.6423\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.5863 - accuracy: 0.6941 - val_loss: 0.6251 - val_accuracy: 0.6359\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 668us/step - loss: 0.5833 - accuracy: 0.6964 - val_loss: 0.6203 - val_accuracy: 0.6374\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5792 - accuracy: 0.7016 - val_loss: 0.6254 - val_accuracy: 0.6336\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.5768 - accuracy: 0.6997 - val_loss: 0.6123 - val_accuracy: 0.6471\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.5735 - accuracy: 0.7043 - val_loss: 0.6105 - val_accuracy: 0.6490\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.5697 - accuracy: 0.7062 - val_loss: 0.6167 - val_accuracy: 0.6434\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.5676 - accuracy: 0.7079 - val_loss: 0.6155 - val_accuracy: 0.6437\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.5654 - accuracy: 0.7093 - val_loss: 0.6210 - val_accuracy: 0.6389\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.5629 - accuracy: 0.7121 - val_loss: 0.6148 - val_accuracy: 0.6449\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.5605 - accuracy: 0.7147 - val_loss: 0.6131 - val_accuracy: 0.6461\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.5588 - accuracy: 0.7135 - val_loss: 0.6045 - val_accuracy: 0.6538\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.5555 - accuracy: 0.7177 - val_loss: 0.6126 - val_accuracy: 0.6466\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.5527 - accuracy: 0.7189 - val_loss: 0.6034 - val_accuracy: 0.6549\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.5514 - accuracy: 0.7172 - val_loss: 0.6043 - val_accuracy: 0.6547\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5503 - accuracy: 0.7194 - val_loss: 0.6013 - val_accuracy: 0.6568\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 699us/step - loss: 0.5471 - accuracy: 0.7226 - val_loss: 0.6001 - val_accuracy: 0.6576\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.5452 - accuracy: 0.7237 - val_loss: 0.6063 - val_accuracy: 0.6531\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.5435 - accuracy: 0.7237 - val_loss: 0.6122 - val_accuracy: 0.6490\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.5421 - accuracy: 0.7259 - val_loss: 0.6005 - val_accuracy: 0.6590\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.5391 - accuracy: 0.7268 - val_loss: 0.5968 - val_accuracy: 0.6617\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.5379 - accuracy: 0.7293 - val_loss: 0.6020 - val_accuracy: 0.6570\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.5377 - accuracy: 0.7271 - val_loss: 0.6036 - val_accuracy: 0.6559\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.5353 - accuracy: 0.7276 - val_loss: 0.6079 - val_accuracy: 0.6525\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5334 - accuracy: 0.7296 - val_loss: 0.6071 - val_accuracy: 0.6534\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.5323 - accuracy: 0.7297 - val_loss: 0.6056 - val_accuracy: 0.6547\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.5298 - accuracy: 0.7304 - val_loss: 0.6029 - val_accuracy: 0.6561\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.5288 - accuracy: 0.7316 - val_loss: 0.6024 - val_accuracy: 0.6564\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5273 - accuracy: 0.7331 - val_loss: 0.5818 - val_accuracy: 0.6725\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.5276 - accuracy: 0.7318 - val_loss: 0.6045 - val_accuracy: 0.6551\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.5246 - accuracy: 0.7350 - val_loss: 0.5909 - val_accuracy: 0.6670\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 519us/step - loss: 0.5226 - accuracy: 0.7363 - val_loss: 0.5998 - val_accuracy: 0.6595\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5216 - accuracy: 0.7357 - val_loss: 0.6064 - val_accuracy: 0.6538\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.7001 - accuracy: 0.5396 - val_loss: 0.6983 - val_accuracy: 0.4987\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.6792 - accuracy: 0.5695 - val_loss: 0.6863 - val_accuracy: 0.5500\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 521us/step - loss: 0.6684 - accuracy: 0.5896 - val_loss: 0.6813 - val_accuracy: 0.5666\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 550us/step - loss: 0.6572 - accuracy: 0.6090 - val_loss: 0.6729 - val_accuracy: 0.5897\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.6501 - accuracy: 0.6216 - val_loss: 0.6646 - val_accuracy: 0.6079\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.6419 - accuracy: 0.6325 - val_loss: 0.6551 - val_accuracy: 0.6219\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 670us/step - loss: 0.6359 - accuracy: 0.6426 - val_loss: 0.6546 - val_accuracy: 0.6185\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.6292 - accuracy: 0.6484 - val_loss: 0.6462 - val_accuracy: 0.6314\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.6248 - accuracy: 0.6508 - val_loss: 0.6470 - val_accuracy: 0.6258\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.6196 - accuracy: 0.6596 - val_loss: 0.6396 - val_accuracy: 0.6336\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.6153 - accuracy: 0.6626 - val_loss: 0.6385 - val_accuracy: 0.6315\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.6114 - accuracy: 0.6646 - val_loss: 0.6395 - val_accuracy: 0.6273\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.6064 - accuracy: 0.6701 - val_loss: 0.6272 - val_accuracy: 0.6434\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 615us/step - loss: 0.6023 - accuracy: 0.6765 - val_loss: 0.6278 - val_accuracy: 0.6419\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 727us/step - loss: 0.5989 - accuracy: 0.6766 - val_loss: 0.6212 - val_accuracy: 0.6495\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 660us/step - loss: 0.5958 - accuracy: 0.6800 - val_loss: 0.6169 - val_accuracy: 0.6518\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.5937 - accuracy: 0.6807 - val_loss: 0.6229 - val_accuracy: 0.6445\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.5904 - accuracy: 0.6867 - val_loss: 0.6287 - val_accuracy: 0.6366\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.5878 - accuracy: 0.6897 - val_loss: 0.6139 - val_accuracy: 0.6495\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 491us/step - loss: 0.5843 - accuracy: 0.6928 - val_loss: 0.6295 - val_accuracy: 0.6339\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 543us/step - loss: 0.5826 - accuracy: 0.6913 - val_loss: 0.6086 - val_accuracy: 0.6537\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5810 - accuracy: 0.6937 - val_loss: 0.6071 - val_accuracy: 0.6541\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 513us/step - loss: 0.5785 - accuracy: 0.6965 - val_loss: 0.6113 - val_accuracy: 0.6506\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5770 - accuracy: 0.6965 - val_loss: 0.6229 - val_accuracy: 0.6404\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5732 - accuracy: 0.7008 - val_loss: 0.6112 - val_accuracy: 0.6506\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 535us/step - loss: 0.5716 - accuracy: 0.7014 - val_loss: 0.6103 - val_accuracy: 0.6514\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.5699 - accuracy: 0.7042 - val_loss: 0.6089 - val_accuracy: 0.6519\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 655us/step - loss: 0.5688 - accuracy: 0.7048 - val_loss: 0.6214 - val_accuracy: 0.6407\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 642us/step - loss: 0.5661 - accuracy: 0.7061 - val_loss: 0.6171 - val_accuracy: 0.6451\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 505us/step - loss: 0.5647 - accuracy: 0.7074 - val_loss: 0.6122 - val_accuracy: 0.6492\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.5628 - accuracy: 0.7093 - val_loss: 0.6197 - val_accuracy: 0.6438\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 529us/step - loss: 0.5615 - accuracy: 0.7097 - val_loss: 0.6161 - val_accuracy: 0.6477\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.5592 - accuracy: 0.7129 - val_loss: 0.6063 - val_accuracy: 0.6558\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.5580 - accuracy: 0.7119 - val_loss: 0.6081 - val_accuracy: 0.6548\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5558 - accuracy: 0.7130 - val_loss: 0.6186 - val_accuracy: 0.6460\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 530us/step - loss: 0.5544 - accuracy: 0.7174 - val_loss: 0.5972 - val_accuracy: 0.6652\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.5539 - accuracy: 0.7149 - val_loss: 0.6067 - val_accuracy: 0.6574\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5515 - accuracy: 0.7178 - val_loss: 0.6114 - val_accuracy: 0.6534\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.5500 - accuracy: 0.7203 - val_loss: 0.6027 - val_accuracy: 0.6607\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.5500 - accuracy: 0.7184 - val_loss: 0.6212 - val_accuracy: 0.6448\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.5477 - accuracy: 0.7186 - val_loss: 0.6093 - val_accuracy: 0.6562\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5469 - accuracy: 0.7210 - val_loss: 0.6175 - val_accuracy: 0.6481\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 3s 862us/step - loss: 0.5458 - accuracy: 0.7209 - val_loss: 0.6015 - val_accuracy: 0.6624\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.5440 - accuracy: 0.7224 - val_loss: 0.6243 - val_accuracy: 0.6433\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5416 - accuracy: 0.7231 - val_loss: 0.6157 - val_accuracy: 0.6502\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 615us/step - loss: 0.5425 - accuracy: 0.7230 - val_loss: 0.6079 - val_accuracy: 0.6579\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.5408 - accuracy: 0.7222 - val_loss: 0.6025 - val_accuracy: 0.6617\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.5390 - accuracy: 0.7251 - val_loss: 0.6072 - val_accuracy: 0.6591\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5376 - accuracy: 0.7255 - val_loss: 0.6082 - val_accuracy: 0.6577\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5377 - accuracy: 0.7269 - val_loss: 0.5987 - val_accuracy: 0.6639\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.6996 - accuracy: 0.5070 - val_loss: 0.7245 - val_accuracy: 0.2734\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.6888 - accuracy: 0.5325 - val_loss: 0.7089 - val_accuracy: 0.4241\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.6793 - accuracy: 0.5631 - val_loss: 0.6950 - val_accuracy: 0.5159\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 655us/step - loss: 0.6714 - accuracy: 0.5814 - val_loss: 0.6848 - val_accuracy: 0.5565\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.6644 - accuracy: 0.5966 - val_loss: 0.6770 - val_accuracy: 0.5831\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 625us/step - loss: 0.6572 - accuracy: 0.6123 - val_loss: 0.6721 - val_accuracy: 0.5924\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.6513 - accuracy: 0.6206 - val_loss: 0.6617 - val_accuracy: 0.6095\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.6456 - accuracy: 0.6289 - val_loss: 0.6503 - val_accuracy: 0.6417\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.6410 - accuracy: 0.6357 - val_loss: 0.6504 - val_accuracy: 0.6410\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.6353 - accuracy: 0.6430 - val_loss: 0.6483 - val_accuracy: 0.6426\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.6329 - accuracy: 0.6453 - val_loss: 0.6423 - val_accuracy: 0.6493\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.6293 - accuracy: 0.6506 - val_loss: 0.6400 - val_accuracy: 0.6495\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.6247 - accuracy: 0.6555 - val_loss: 0.6364 - val_accuracy: 0.6506\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 522us/step - loss: 0.6211 - accuracy: 0.6572 - val_loss: 0.6308 - val_accuracy: 0.6539\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 699us/step - loss: 0.6180 - accuracy: 0.6620 - val_loss: 0.6323 - val_accuracy: 0.6474\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 653us/step - loss: 0.6145 - accuracy: 0.6673 - val_loss: 0.6344 - val_accuracy: 0.6412\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.6121 - accuracy: 0.6693 - val_loss: 0.6258 - val_accuracy: 0.6491\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.6103 - accuracy: 0.6694 - val_loss: 0.6275 - val_accuracy: 0.6438\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.6075 - accuracy: 0.6725 - val_loss: 0.6232 - val_accuracy: 0.6497\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 661us/step - loss: 0.6031 - accuracy: 0.6785 - val_loss: 0.6241 - val_accuracy: 0.6468\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 524us/step - loss: 0.6017 - accuracy: 0.6812 - val_loss: 0.6202 - val_accuracy: 0.6509\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.5991 - accuracy: 0.6824 - val_loss: 0.6091 - val_accuracy: 0.6702\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.5965 - accuracy: 0.6839 - val_loss: 0.6138 - val_accuracy: 0.6587\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.5928 - accuracy: 0.6891 - val_loss: 0.6220 - val_accuracy: 0.6444\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 655us/step - loss: 0.5912 - accuracy: 0.6890 - val_loss: 0.6137 - val_accuracy: 0.6561\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.5888 - accuracy: 0.6929 - val_loss: 0.6218 - val_accuracy: 0.6417\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.5875 - accuracy: 0.6944 - val_loss: 0.6142 - val_accuracy: 0.6513\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 670us/step - loss: 0.5858 - accuracy: 0.6960 - val_loss: 0.6082 - val_accuracy: 0.6598\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5816 - accuracy: 0.6991 - val_loss: 0.6182 - val_accuracy: 0.6414\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.5802 - accuracy: 0.7020 - val_loss: 0.6129 - val_accuracy: 0.6491\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.5774 - accuracy: 0.7042 - val_loss: 0.6132 - val_accuracy: 0.6479\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.5753 - accuracy: 0.7058 - val_loss: 0.6057 - val_accuracy: 0.6548\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.5744 - accuracy: 0.7048 - val_loss: 0.6185 - val_accuracy: 0.6372\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.5721 - accuracy: 0.7076 - val_loss: 0.6054 - val_accuracy: 0.6520\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.5705 - accuracy: 0.7091 - val_loss: 0.6164 - val_accuracy: 0.6373\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.5682 - accuracy: 0.7123 - val_loss: 0.6008 - val_accuracy: 0.6556\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.5656 - accuracy: 0.7142 - val_loss: 0.6142 - val_accuracy: 0.6386\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5640 - accuracy: 0.7162 - val_loss: 0.6026 - val_accuracy: 0.6517\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.5616 - accuracy: 0.7147 - val_loss: 0.5994 - val_accuracy: 0.6544\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 552us/step - loss: 0.5599 - accuracy: 0.7156 - val_loss: 0.6116 - val_accuracy: 0.6391\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.5587 - accuracy: 0.7184 - val_loss: 0.6084 - val_accuracy: 0.6431\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 681us/step - loss: 0.5575 - accuracy: 0.7195 - val_loss: 0.6134 - val_accuracy: 0.6373\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 3s 917us/step - loss: 0.5552 - accuracy: 0.7207 - val_loss: 0.6133 - val_accuracy: 0.6375\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 3s 944us/step - loss: 0.5541 - accuracy: 0.7199 - val_loss: 0.6082 - val_accuracy: 0.6443\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 4s 1ms/step - loss: 0.5528 - accuracy: 0.7228 - val_loss: 0.6153 - val_accuracy: 0.6378\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 3s 948us/step - loss: 0.5511 - accuracy: 0.7228 - val_loss: 0.6184 - val_accuracy: 0.6352\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 3s 978us/step - loss: 0.5491 - accuracy: 0.7247 - val_loss: 0.6145 - val_accuracy: 0.6391\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 3s 878us/step - loss: 0.5486 - accuracy: 0.7242 - val_loss: 0.6147 - val_accuracy: 0.6389\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 661us/step - loss: 0.5469 - accuracy: 0.7256 - val_loss: 0.6108 - val_accuracy: 0.6419\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 4s 1ms/step - loss: 0.5450 - accuracy: 0.7254 - val_loss: 0.6138 - val_accuracy: 0.6394\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 3s 798us/step - loss: 0.7052 - accuracy: 0.4993 - val_loss: 0.7264 - val_accuracy: 0.3068\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 3s 869us/step - loss: 0.6945 - accuracy: 0.5154 - val_loss: 0.7135 - val_accuracy: 0.4045\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 698us/step - loss: 0.6875 - accuracy: 0.5392 - val_loss: 0.7121 - val_accuracy: 0.4203\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 684us/step - loss: 0.6821 - accuracy: 0.5552 - val_loss: 0.7032 - val_accuracy: 0.4876\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.6772 - accuracy: 0.5692 - val_loss: 0.7044 - val_accuracy: 0.5065\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.6707 - accuracy: 0.5877 - val_loss: 0.7003 - val_accuracy: 0.5347\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.6662 - accuracy: 0.5950 - val_loss: 0.6924 - val_accuracy: 0.5555\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.6603 - accuracy: 0.6102 - val_loss: 0.6833 - val_accuracy: 0.5754\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.6551 - accuracy: 0.6205 - val_loss: 0.6800 - val_accuracy: 0.5802\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 648us/step - loss: 0.6503 - accuracy: 0.6276 - val_loss: 0.6732 - val_accuracy: 0.5894\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 604us/step - loss: 0.6470 - accuracy: 0.6317 - val_loss: 0.6641 - val_accuracy: 0.6161\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.6432 - accuracy: 0.6361 - val_loss: 0.6666 - val_accuracy: 0.6150\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.6391 - accuracy: 0.6434 - val_loss: 0.6603 - val_accuracy: 0.6297\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 601us/step - loss: 0.6347 - accuracy: 0.6478 - val_loss: 0.6592 - val_accuracy: 0.6312\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.6310 - accuracy: 0.6521 - val_loss: 0.6591 - val_accuracy: 0.6328\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 595us/step - loss: 0.6267 - accuracy: 0.6549 - val_loss: 0.6476 - val_accuracy: 0.6474\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.6227 - accuracy: 0.6600 - val_loss: 0.6478 - val_accuracy: 0.6474\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.6190 - accuracy: 0.6633 - val_loss: 0.6410 - val_accuracy: 0.6548\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 745us/step - loss: 0.6155 - accuracy: 0.6656 - val_loss: 0.6409 - val_accuracy: 0.6537\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.6120 - accuracy: 0.6700 - val_loss: 0.6402 - val_accuracy: 0.6528\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.6087 - accuracy: 0.6744 - val_loss: 0.6370 - val_accuracy: 0.6555\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.6048 - accuracy: 0.6770 - val_loss: 0.6443 - val_accuracy: 0.6454\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 533us/step - loss: 0.6022 - accuracy: 0.6795 - val_loss: 0.6394 - val_accuracy: 0.6512\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.5986 - accuracy: 0.6811 - val_loss: 0.6300 - val_accuracy: 0.6614\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.5957 - accuracy: 0.6854 - val_loss: 0.6333 - val_accuracy: 0.6537\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 646us/step - loss: 0.5915 - accuracy: 0.6881 - val_loss: 0.6321 - val_accuracy: 0.6519\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.5894 - accuracy: 0.6906 - val_loss: 0.6179 - val_accuracy: 0.6596\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 610us/step - loss: 0.5854 - accuracy: 0.6921 - val_loss: 0.6217 - val_accuracy: 0.6562\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.5827 - accuracy: 0.6971 - val_loss: 0.6155 - val_accuracy: 0.6619\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 670us/step - loss: 0.5796 - accuracy: 0.6965 - val_loss: 0.6142 - val_accuracy: 0.6637\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5771 - accuracy: 0.7000 - val_loss: 0.6207 - val_accuracy: 0.6574\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.5746 - accuracy: 0.7021 - val_loss: 0.6184 - val_accuracy: 0.6589\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5713 - accuracy: 0.7039 - val_loss: 0.6218 - val_accuracy: 0.6521\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.5685 - accuracy: 0.7055 - val_loss: 0.6175 - val_accuracy: 0.6556\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 680us/step - loss: 0.5668 - accuracy: 0.7063 - val_loss: 0.6117 - val_accuracy: 0.6607\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.5632 - accuracy: 0.7132 - val_loss: 0.6077 - val_accuracy: 0.6635\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5603 - accuracy: 0.7129 - val_loss: 0.6054 - val_accuracy: 0.6647\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.5582 - accuracy: 0.7144 - val_loss: 0.6210 - val_accuracy: 0.6457\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 670us/step - loss: 0.5560 - accuracy: 0.7160 - val_loss: 0.6053 - val_accuracy: 0.6628\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.5541 - accuracy: 0.7168 - val_loss: 0.5973 - val_accuracy: 0.6716\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 3s 787us/step - loss: 0.5522 - accuracy: 0.7195 - val_loss: 0.5976 - val_accuracy: 0.6712\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.5511 - accuracy: 0.7194 - val_loss: 0.6019 - val_accuracy: 0.6638\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5478 - accuracy: 0.7213 - val_loss: 0.6053 - val_accuracy: 0.6575\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.5470 - accuracy: 0.7243 - val_loss: 0.5941 - val_accuracy: 0.6725\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 554us/step - loss: 0.5440 - accuracy: 0.7248 - val_loss: 0.6025 - val_accuracy: 0.6587\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.5438 - accuracy: 0.7256 - val_loss: 0.5965 - val_accuracy: 0.6677\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5410 - accuracy: 0.7285 - val_loss: 0.5972 - val_accuracy: 0.6671\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.5397 - accuracy: 0.7302 - val_loss: 0.6084 - val_accuracy: 0.6497\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5365 - accuracy: 0.7299 - val_loss: 0.6043 - val_accuracy: 0.6533\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5360 - accuracy: 0.7313 - val_loss: 0.6019 - val_accuracy: 0.6556\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.7035 - accuracy: 0.5121 - val_loss: 0.7230 - val_accuracy: 0.2437\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.6891 - accuracy: 0.5472 - val_loss: 0.7065 - val_accuracy: 0.4507\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.6762 - accuracy: 0.5865 - val_loss: 0.6902 - val_accuracy: 0.5365\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 672us/step - loss: 0.6648 - accuracy: 0.6172 - val_loss: 0.6753 - val_accuracy: 0.5956\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 693us/step - loss: 0.6566 - accuracy: 0.6348 - val_loss: 0.6766 - val_accuracy: 0.5863\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 623us/step - loss: 0.6492 - accuracy: 0.6456 - val_loss: 0.6671 - val_accuracy: 0.6049\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.6424 - accuracy: 0.6575 - val_loss: 0.6630 - val_accuracy: 0.6098\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 666us/step - loss: 0.6367 - accuracy: 0.6648 - val_loss: 0.6593 - val_accuracy: 0.6133\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 633us/step - loss: 0.6307 - accuracy: 0.6708 - val_loss: 0.6492 - val_accuracy: 0.6259\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.6256 - accuracy: 0.6770 - val_loss: 0.6493 - val_accuracy: 0.6224\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.6191 - accuracy: 0.6811 - val_loss: 0.6257 - val_accuracy: 0.6614\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.6144 - accuracy: 0.6847 - val_loss: 0.6409 - val_accuracy: 0.6247\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 722us/step - loss: 0.6089 - accuracy: 0.6881 - val_loss: 0.6279 - val_accuracy: 0.6429\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 635us/step - loss: 0.6029 - accuracy: 0.6915 - val_loss: 0.6222 - val_accuracy: 0.6479\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 682us/step - loss: 0.5985 - accuracy: 0.6954 - val_loss: 0.6200 - val_accuracy: 0.6488\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 729us/step - loss: 0.5940 - accuracy: 0.6984 - val_loss: 0.6295 - val_accuracy: 0.6335\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 3s 784us/step - loss: 0.5900 - accuracy: 0.6986 - val_loss: 0.6150 - val_accuracy: 0.6538\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.5860 - accuracy: 0.7038 - val_loss: 0.6182 - val_accuracy: 0.6465\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 656us/step - loss: 0.5831 - accuracy: 0.7051 - val_loss: 0.6104 - val_accuracy: 0.6552\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 713us/step - loss: 0.5791 - accuracy: 0.7080 - val_loss: 0.6153 - val_accuracy: 0.6483\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 660us/step - loss: 0.5759 - accuracy: 0.7099 - val_loss: 0.6066 - val_accuracy: 0.6544\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.5733 - accuracy: 0.7108 - val_loss: 0.5961 - val_accuracy: 0.6579\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.5704 - accuracy: 0.7137 - val_loss: 0.6018 - val_accuracy: 0.6537\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5677 - accuracy: 0.7138 - val_loss: 0.6071 - val_accuracy: 0.6488\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 544us/step - loss: 0.5640 - accuracy: 0.7142 - val_loss: 0.6038 - val_accuracy: 0.6512\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.5609 - accuracy: 0.7180 - val_loss: 0.5925 - val_accuracy: 0.6608\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.5585 - accuracy: 0.7179 - val_loss: 0.5962 - val_accuracy: 0.6575\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 559us/step - loss: 0.5560 - accuracy: 0.7196 - val_loss: 0.5933 - val_accuracy: 0.6613\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5530 - accuracy: 0.7215 - val_loss: 0.6058 - val_accuracy: 0.6493\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.5526 - accuracy: 0.7194 - val_loss: 0.5892 - val_accuracy: 0.6664\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.5490 - accuracy: 0.7226 - val_loss: 0.6000 - val_accuracy: 0.6565\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.5477 - accuracy: 0.7240 - val_loss: 0.5956 - val_accuracy: 0.6615\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 518us/step - loss: 0.5442 - accuracy: 0.7264 - val_loss: 0.5861 - val_accuracy: 0.6696\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5432 - accuracy: 0.7265 - val_loss: 0.6015 - val_accuracy: 0.6563\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.5407 - accuracy: 0.7273 - val_loss: 0.5944 - val_accuracy: 0.6635\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 557us/step - loss: 0.5381 - accuracy: 0.7303 - val_loss: 0.5927 - val_accuracy: 0.6652\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 523us/step - loss: 0.5363 - accuracy: 0.7296 - val_loss: 0.6069 - val_accuracy: 0.6495\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.5337 - accuracy: 0.7322 - val_loss: 0.5887 - val_accuracy: 0.6680\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.5319 - accuracy: 0.7339 - val_loss: 0.5973 - val_accuracy: 0.6587\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 511us/step - loss: 0.5299 - accuracy: 0.7335 - val_loss: 0.5754 - val_accuracy: 0.6791\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.5287 - accuracy: 0.7346 - val_loss: 0.6029 - val_accuracy: 0.6533\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.5270 - accuracy: 0.7359 - val_loss: 0.5936 - val_accuracy: 0.6618\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.5260 - accuracy: 0.7370 - val_loss: 0.5880 - val_accuracy: 0.6657\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5235 - accuracy: 0.7393 - val_loss: 0.5973 - val_accuracy: 0.6581\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.5226 - accuracy: 0.7390 - val_loss: 0.5930 - val_accuracy: 0.6611\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.5209 - accuracy: 0.7402 - val_loss: 0.5862 - val_accuracy: 0.6665\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 516us/step - loss: 0.5189 - accuracy: 0.7407 - val_loss: 0.5967 - val_accuracy: 0.6575\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.5176 - accuracy: 0.7420 - val_loss: 0.5917 - val_accuracy: 0.6606\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 525us/step - loss: 0.5160 - accuracy: 0.7425 - val_loss: 0.5764 - val_accuracy: 0.6738\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.5145 - accuracy: 0.7436 - val_loss: 0.5948 - val_accuracy: 0.6576\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 537us/step - loss: 0.7010 - accuracy: 0.5491 - val_loss: 0.7160 - val_accuracy: 0.4292\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.6773 - accuracy: 0.5876 - val_loss: 0.6964 - val_accuracy: 0.5222\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 711us/step - loss: 0.6626 - accuracy: 0.6159 - val_loss: 0.6890 - val_accuracy: 0.5414\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 3s 812us/step - loss: 0.6515 - accuracy: 0.6377 - val_loss: 0.6552 - val_accuracy: 0.6046\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.6440 - accuracy: 0.6465 - val_loss: 0.6645 - val_accuracy: 0.5894\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 553us/step - loss: 0.6364 - accuracy: 0.6581 - val_loss: 0.6543 - val_accuracy: 0.6047\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.6308 - accuracy: 0.6636 - val_loss: 0.6530 - val_accuracy: 0.6064\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 727us/step - loss: 0.6241 - accuracy: 0.6716 - val_loss: 0.6483 - val_accuracy: 0.6144\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.6181 - accuracy: 0.6791 - val_loss: 0.6426 - val_accuracy: 0.6222\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.6137 - accuracy: 0.6829 - val_loss: 0.6338 - val_accuracy: 0.6360\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 549us/step - loss: 0.6081 - accuracy: 0.6881 - val_loss: 0.6390 - val_accuracy: 0.6287\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.6047 - accuracy: 0.6917 - val_loss: 0.6314 - val_accuracy: 0.6391\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 688us/step - loss: 0.6001 - accuracy: 0.6945 - val_loss: 0.6267 - val_accuracy: 0.6435\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 610us/step - loss: 0.5967 - accuracy: 0.6977 - val_loss: 0.6317 - val_accuracy: 0.6385\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 528us/step - loss: 0.5936 - accuracy: 0.7003 - val_loss: 0.6280 - val_accuracy: 0.6419\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 653us/step - loss: 0.5895 - accuracy: 0.7027 - val_loss: 0.6298 - val_accuracy: 0.6397\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.5859 - accuracy: 0.7045 - val_loss: 0.6272 - val_accuracy: 0.6404\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 683us/step - loss: 0.5831 - accuracy: 0.7066 - val_loss: 0.6226 - val_accuracy: 0.6439\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.5808 - accuracy: 0.7086 - val_loss: 0.6202 - val_accuracy: 0.6461\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 548us/step - loss: 0.5773 - accuracy: 0.7117 - val_loss: 0.6141 - val_accuracy: 0.6521\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.5744 - accuracy: 0.7131 - val_loss: 0.6103 - val_accuracy: 0.6535\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.5723 - accuracy: 0.7150 - val_loss: 0.6118 - val_accuracy: 0.6517\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.5704 - accuracy: 0.7152 - val_loss: 0.6168 - val_accuracy: 0.6479\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 639us/step - loss: 0.5666 - accuracy: 0.7175 - val_loss: 0.6025 - val_accuracy: 0.6583\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.5646 - accuracy: 0.7190 - val_loss: 0.6112 - val_accuracy: 0.6511\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.5624 - accuracy: 0.7197 - val_loss: 0.6099 - val_accuracy: 0.6522\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.5593 - accuracy: 0.7223 - val_loss: 0.6085 - val_accuracy: 0.6534\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5584 - accuracy: 0.7218 - val_loss: 0.6058 - val_accuracy: 0.6547\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 510us/step - loss: 0.5559 - accuracy: 0.7256 - val_loss: 0.6175 - val_accuracy: 0.6453\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.5527 - accuracy: 0.7257 - val_loss: 0.6083 - val_accuracy: 0.6509\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5513 - accuracy: 0.7259 - val_loss: 0.6095 - val_accuracy: 0.6491\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.5482 - accuracy: 0.7273 - val_loss: 0.6127 - val_accuracy: 0.6466\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.5476 - accuracy: 0.7273 - val_loss: 0.5964 - val_accuracy: 0.6619\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.5454 - accuracy: 0.7290 - val_loss: 0.6069 - val_accuracy: 0.6520\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.5431 - accuracy: 0.7303 - val_loss: 0.5909 - val_accuracy: 0.6667\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.5426 - accuracy: 0.7300 - val_loss: 0.6048 - val_accuracy: 0.6529\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.5407 - accuracy: 0.7327 - val_loss: 0.6003 - val_accuracy: 0.6571\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.5387 - accuracy: 0.7329 - val_loss: 0.5925 - val_accuracy: 0.6643\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 538us/step - loss: 0.5373 - accuracy: 0.7326 - val_loss: 0.5993 - val_accuracy: 0.6577\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.5346 - accuracy: 0.7343 - val_loss: 0.5986 - val_accuracy: 0.6584\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 651us/step - loss: 0.5329 - accuracy: 0.7364 - val_loss: 0.6025 - val_accuracy: 0.6556\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.5307 - accuracy: 0.7379 - val_loss: 0.6091 - val_accuracy: 0.6514\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 677us/step - loss: 0.5308 - accuracy: 0.7364 - val_loss: 0.5937 - val_accuracy: 0.6640\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 669us/step - loss: 0.5289 - accuracy: 0.7369 - val_loss: 0.6030 - val_accuracy: 0.6562\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 679us/step - loss: 0.5270 - accuracy: 0.7370 - val_loss: 0.5978 - val_accuracy: 0.6615\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 620us/step - loss: 0.5257 - accuracy: 0.7396 - val_loss: 0.5839 - val_accuracy: 0.6751\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5244 - accuracy: 0.7393 - val_loss: 0.6041 - val_accuracy: 0.6570\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.5234 - accuracy: 0.7397 - val_loss: 0.6011 - val_accuracy: 0.6598\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 620us/step - loss: 0.5211 - accuracy: 0.7419 - val_loss: 0.5967 - val_accuracy: 0.6643\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.5209 - accuracy: 0.7411 - val_loss: 0.6088 - val_accuracy: 0.6535\n",
      "\n",
      "Training model with batch_size=16, target_eps=2.0...\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 5.05 iterated over 167200 steps satisfies differential privacy with eps = 0.122 and delta = 1e-05.\n",
      "The optimal RDP order is 256.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 2.5749999999999997 iterated over 167200 steps satisfies differential privacy with eps = 0.263 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.3375 iterated over 167200 steps satisfies differential privacy with eps = 0.585 and delta = 1e-05.\n",
      "The optimal RDP order is 28.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 0.71875 iterated over 167200 steps satisfies differential privacy with eps = 2.24 and delta = 1e-05.\n",
      "The optimal RDP order is 7.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 1.028125 iterated over 167200 steps satisfies differential privacy with eps = 0.959 and delta = 1e-05.\n",
      "The optimal RDP order is 16.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 0.8734375 iterated over 167200 steps satisfies differential privacy with eps = 1.38 and delta = 1e-05.\n",
      "The optimal RDP order is 11.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 0.79609375 iterated over 167200 steps satisfies differential privacy with eps = 1.7 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 0.757421875 iterated over 167200 steps satisfies differential privacy with eps = 1.94 and delta = 1e-05.\n",
      "The optimal RDP order is 8.0.\n",
      "DP-SGD with sampling rate = 0.0299% and noise_multiplier = 0.7380859375 iterated over 167200 steps satisfies differential privacy with eps = 2 and delta = 1e-05.\n",
      "The optimal RDP order is 8.0.\n",
      "Epoch 1/50\n",
      "   1/3344 [..............................] - ETA: 0s - loss: 0.7378 - accuracy: 0.3750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.6879 - accuracy: 0.5245 - val_loss: 0.7144 - val_accuracy: 0.3059\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 563us/step - loss: 0.6804 - accuracy: 0.5507 - val_loss: 0.7026 - val_accuracy: 0.4625\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.6731 - accuracy: 0.5753 - val_loss: 0.6941 - val_accuracy: 0.5431\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.6662 - accuracy: 0.5980 - val_loss: 0.6876 - val_accuracy: 0.5756\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 534us/step - loss: 0.6601 - accuracy: 0.6152 - val_loss: 0.6828 - val_accuracy: 0.5932\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 568us/step - loss: 0.6543 - accuracy: 0.6282 - val_loss: 0.6808 - val_accuracy: 0.5973\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.6494 - accuracy: 0.6350 - val_loss: 0.6738 - val_accuracy: 0.6152\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.6448 - accuracy: 0.6460 - val_loss: 0.6679 - val_accuracy: 0.6239\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.6404 - accuracy: 0.6532 - val_loss: 0.6664 - val_accuracy: 0.6245\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 654us/step - loss: 0.6355 - accuracy: 0.6589 - val_loss: 0.6545 - val_accuracy: 0.6426\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.6309 - accuracy: 0.6625 - val_loss: 0.6509 - val_accuracy: 0.6461\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.6270 - accuracy: 0.6654 - val_loss: 0.6519 - val_accuracy: 0.6408\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.6238 - accuracy: 0.6660 - val_loss: 0.6432 - val_accuracy: 0.6532\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.6195 - accuracy: 0.6723 - val_loss: 0.6411 - val_accuracy: 0.6528\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 540us/step - loss: 0.6159 - accuracy: 0.6723 - val_loss: 0.6385 - val_accuracy: 0.6538\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.6113 - accuracy: 0.6777 - val_loss: 0.6388 - val_accuracy: 0.6517\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 634us/step - loss: 0.6080 - accuracy: 0.6785 - val_loss: 0.6317 - val_accuracy: 0.6595\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.6040 - accuracy: 0.6836 - val_loss: 0.6323 - val_accuracy: 0.6544\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.6019 - accuracy: 0.6823 - val_loss: 0.6267 - val_accuracy: 0.6590\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.5980 - accuracy: 0.6851 - val_loss: 0.6289 - val_accuracy: 0.6542\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.5952 - accuracy: 0.6886 - val_loss: 0.6245 - val_accuracy: 0.6585\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5922 - accuracy: 0.6901 - val_loss: 0.6167 - val_accuracy: 0.6636\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 615us/step - loss: 0.5890 - accuracy: 0.6926 - val_loss: 0.6187 - val_accuracy: 0.6603\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.5871 - accuracy: 0.6952 - val_loss: 0.6102 - val_accuracy: 0.6705\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.5837 - accuracy: 0.6980 - val_loss: 0.6090 - val_accuracy: 0.6688\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 714us/step - loss: 0.5821 - accuracy: 0.7012 - val_loss: 0.6148 - val_accuracy: 0.6614\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 672us/step - loss: 0.5777 - accuracy: 0.7019 - val_loss: 0.6103 - val_accuracy: 0.6650\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.5753 - accuracy: 0.7048 - val_loss: 0.6105 - val_accuracy: 0.6631\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.5730 - accuracy: 0.7053 - val_loss: 0.6083 - val_accuracy: 0.6639\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 561us/step - loss: 0.5704 - accuracy: 0.7083 - val_loss: 0.6194 - val_accuracy: 0.6532\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 683us/step - loss: 0.5681 - accuracy: 0.7102 - val_loss: 0.6112 - val_accuracy: 0.6585\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 639us/step - loss: 0.5671 - accuracy: 0.7105 - val_loss: 0.6004 - val_accuracy: 0.6658\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 582us/step - loss: 0.5645 - accuracy: 0.7145 - val_loss: 0.6063 - val_accuracy: 0.6608\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.5619 - accuracy: 0.7151 - val_loss: 0.6068 - val_accuracy: 0.6601\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 634us/step - loss: 0.5603 - accuracy: 0.7165 - val_loss: 0.6138 - val_accuracy: 0.6539\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.5582 - accuracy: 0.7172 - val_loss: 0.6001 - val_accuracy: 0.6647\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.5567 - accuracy: 0.7198 - val_loss: 0.6026 - val_accuracy: 0.6639\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 677us/step - loss: 0.5537 - accuracy: 0.7208 - val_loss: 0.6171 - val_accuracy: 0.6518\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 646us/step - loss: 0.5515 - accuracy: 0.7232 - val_loss: 0.6160 - val_accuracy: 0.6538\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 668us/step - loss: 0.5504 - accuracy: 0.7233 - val_loss: 0.5957 - val_accuracy: 0.6706\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 671us/step - loss: 0.5485 - accuracy: 0.7229 - val_loss: 0.5968 - val_accuracy: 0.6699\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.5462 - accuracy: 0.7257 - val_loss: 0.5985 - val_accuracy: 0.6687\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 572us/step - loss: 0.5440 - accuracy: 0.7268 - val_loss: 0.6075 - val_accuracy: 0.6623\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.5437 - accuracy: 0.7280 - val_loss: 0.5954 - val_accuracy: 0.6718\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.5412 - accuracy: 0.7280 - val_loss: 0.5971 - val_accuracy: 0.6710\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.5395 - accuracy: 0.7296 - val_loss: 0.5987 - val_accuracy: 0.6702\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 601us/step - loss: 0.5381 - accuracy: 0.7291 - val_loss: 0.6084 - val_accuracy: 0.6631\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 532us/step - loss: 0.5367 - accuracy: 0.7312 - val_loss: 0.6053 - val_accuracy: 0.6659\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 517us/step - loss: 0.5351 - accuracy: 0.7332 - val_loss: 0.6168 - val_accuracy: 0.6576\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 536us/step - loss: 0.5339 - accuracy: 0.7329 - val_loss: 0.5978 - val_accuracy: 0.6726\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 700us/step - loss: 0.6975 - accuracy: 0.5560 - val_loss: 0.7130 - val_accuracy: 0.4401\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 647us/step - loss: 0.6754 - accuracy: 0.5866 - val_loss: 0.6997 - val_accuracy: 0.5126\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 645us/step - loss: 0.6656 - accuracy: 0.6118 - val_loss: 0.6916 - val_accuracy: 0.5453\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.6580 - accuracy: 0.6291 - val_loss: 0.6730 - val_accuracy: 0.6029\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 703us/step - loss: 0.6499 - accuracy: 0.6452 - val_loss: 0.6667 - val_accuracy: 0.6131\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 677us/step - loss: 0.6431 - accuracy: 0.6536 - val_loss: 0.6645 - val_accuracy: 0.6119\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 688us/step - loss: 0.6364 - accuracy: 0.6635 - val_loss: 0.6531 - val_accuracy: 0.6298\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 653us/step - loss: 0.6313 - accuracy: 0.6672 - val_loss: 0.6558 - val_accuracy: 0.6187\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 652us/step - loss: 0.6249 - accuracy: 0.6721 - val_loss: 0.6490 - val_accuracy: 0.6284\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.6192 - accuracy: 0.6797 - val_loss: 0.6420 - val_accuracy: 0.6392\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.6140 - accuracy: 0.6817 - val_loss: 0.6285 - val_accuracy: 0.6598\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 644us/step - loss: 0.6098 - accuracy: 0.6821 - val_loss: 0.6273 - val_accuracy: 0.6576\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 675us/step - loss: 0.6048 - accuracy: 0.6876 - val_loss: 0.6279 - val_accuracy: 0.6535\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 709us/step - loss: 0.6011 - accuracy: 0.6879 - val_loss: 0.6251 - val_accuracy: 0.6551\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 640us/step - loss: 0.5970 - accuracy: 0.6913 - val_loss: 0.6195 - val_accuracy: 0.6597\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 684us/step - loss: 0.5940 - accuracy: 0.6968 - val_loss: 0.6208 - val_accuracy: 0.6554\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 648us/step - loss: 0.5893 - accuracy: 0.6972 - val_loss: 0.6082 - val_accuracy: 0.6700\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 644us/step - loss: 0.5869 - accuracy: 0.6999 - val_loss: 0.6088 - val_accuracy: 0.6664\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 662us/step - loss: 0.5827 - accuracy: 0.7041 - val_loss: 0.6140 - val_accuracy: 0.6564\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.5790 - accuracy: 0.7062 - val_loss: 0.6120 - val_accuracy: 0.6579\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.5771 - accuracy: 0.7068 - val_loss: 0.6096 - val_accuracy: 0.6586\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.5738 - accuracy: 0.7096 - val_loss: 0.6084 - val_accuracy: 0.6600\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 625us/step - loss: 0.5703 - accuracy: 0.7123 - val_loss: 0.5986 - val_accuracy: 0.6696\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 708us/step - loss: 0.5670 - accuracy: 0.7152 - val_loss: 0.6041 - val_accuracy: 0.6602\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 641us/step - loss: 0.5663 - accuracy: 0.7158 - val_loss: 0.6045 - val_accuracy: 0.6579\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 649us/step - loss: 0.5637 - accuracy: 0.7186 - val_loss: 0.5950 - val_accuracy: 0.6680\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5609 - accuracy: 0.7187 - val_loss: 0.5967 - val_accuracy: 0.6648\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 620us/step - loss: 0.5582 - accuracy: 0.7203 - val_loss: 0.5912 - val_accuracy: 0.6689\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 3s 872us/step - loss: 0.5567 - accuracy: 0.7202 - val_loss: 0.6026 - val_accuracy: 0.6571\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 655us/step - loss: 0.5540 - accuracy: 0.7238 - val_loss: 0.6044 - val_accuracy: 0.6556\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.5526 - accuracy: 0.7242 - val_loss: 0.6137 - val_accuracy: 0.6486\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 604us/step - loss: 0.5500 - accuracy: 0.7235 - val_loss: 0.5995 - val_accuracy: 0.6606\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 645us/step - loss: 0.5487 - accuracy: 0.7249 - val_loss: 0.5829 - val_accuracy: 0.6742\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.5465 - accuracy: 0.7276 - val_loss: 0.6028 - val_accuracy: 0.6579\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.5446 - accuracy: 0.7279 - val_loss: 0.5900 - val_accuracy: 0.6683\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.5419 - accuracy: 0.7290 - val_loss: 0.5925 - val_accuracy: 0.6665\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5406 - accuracy: 0.7294 - val_loss: 0.5920 - val_accuracy: 0.6670\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 545us/step - loss: 0.5397 - accuracy: 0.7310 - val_loss: 0.5967 - val_accuracy: 0.6624\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.5376 - accuracy: 0.7323 - val_loss: 0.5952 - val_accuracy: 0.6642\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 620us/step - loss: 0.5346 - accuracy: 0.7305 - val_loss: 0.5843 - val_accuracy: 0.6711\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.5333 - accuracy: 0.7322 - val_loss: 0.5924 - val_accuracy: 0.6676\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.5321 - accuracy: 0.7329 - val_loss: 0.5975 - val_accuracy: 0.6646\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.5305 - accuracy: 0.7341 - val_loss: 0.5835 - val_accuracy: 0.6721\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 651us/step - loss: 0.5290 - accuracy: 0.7356 - val_loss: 0.5946 - val_accuracy: 0.6659\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 655us/step - loss: 0.5267 - accuracy: 0.7365 - val_loss: 0.5886 - val_accuracy: 0.6695\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 658us/step - loss: 0.5244 - accuracy: 0.7373 - val_loss: 0.6012 - val_accuracy: 0.6632\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.5240 - accuracy: 0.7379 - val_loss: 0.5972 - val_accuracy: 0.6646\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.5217 - accuracy: 0.7384 - val_loss: 0.5912 - val_accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.5201 - accuracy: 0.7384 - val_loss: 0.5915 - val_accuracy: 0.6656\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.5191 - accuracy: 0.7411 - val_loss: 0.5923 - val_accuracy: 0.6644\n",
      "Epoch 1/50\n",
      "3308/3344 [============================>.] - ETA: 0s - loss: 0.7113 - accuracy: 0.4916WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3344/3344 [==============================] - 2s 605us/step - loss: 0.7113 - accuracy: 0.4916 - val_loss: 0.7170 - val_accuracy: 0.4226\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.6922 - accuracy: 0.5349 - val_loss: 0.7003 - val_accuracy: 0.4870\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 626us/step - loss: 0.6752 - accuracy: 0.5805 - val_loss: 0.6822 - val_accuracy: 0.5531\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 633us/step - loss: 0.6623 - accuracy: 0.6106 - val_loss: 0.6755 - val_accuracy: 0.5683\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.6525 - accuracy: 0.6278 - val_loss: 0.6609 - val_accuracy: 0.5964\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 564us/step - loss: 0.6448 - accuracy: 0.6426 - val_loss: 0.6710 - val_accuracy: 0.5719\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.6373 - accuracy: 0.6545 - val_loss: 0.6536 - val_accuracy: 0.6011\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 581us/step - loss: 0.6313 - accuracy: 0.6638 - val_loss: 0.6632 - val_accuracy: 0.5785\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.6257 - accuracy: 0.6680 - val_loss: 0.6418 - val_accuracy: 0.6113\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 682us/step - loss: 0.6203 - accuracy: 0.6745 - val_loss: 0.6384 - val_accuracy: 0.6135\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 663us/step - loss: 0.6144 - accuracy: 0.6797 - val_loss: 0.6337 - val_accuracy: 0.6164\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 637us/step - loss: 0.6096 - accuracy: 0.6831 - val_loss: 0.6436 - val_accuracy: 0.6019\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 672us/step - loss: 0.6054 - accuracy: 0.6869 - val_loss: 0.6344 - val_accuracy: 0.6117\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.6010 - accuracy: 0.6888 - val_loss: 0.6239 - val_accuracy: 0.6246\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.5963 - accuracy: 0.6925 - val_loss: 0.6275 - val_accuracy: 0.6184\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.5926 - accuracy: 0.6976 - val_loss: 0.6178 - val_accuracy: 0.6311\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.5884 - accuracy: 0.7010 - val_loss: 0.6269 - val_accuracy: 0.6180\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 620us/step - loss: 0.5854 - accuracy: 0.7011 - val_loss: 0.6194 - val_accuracy: 0.6300\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.5819 - accuracy: 0.7040 - val_loss: 0.6161 - val_accuracy: 0.6336\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 652us/step - loss: 0.5780 - accuracy: 0.7056 - val_loss: 0.6126 - val_accuracy: 0.6371\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.5753 - accuracy: 0.7099 - val_loss: 0.6249 - val_accuracy: 0.6229\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.5720 - accuracy: 0.7126 - val_loss: 0.6254 - val_accuracy: 0.6225\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 3s 753us/step - loss: 0.5697 - accuracy: 0.7115 - val_loss: 0.6191 - val_accuracy: 0.6305\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 695us/step - loss: 0.5674 - accuracy: 0.7133 - val_loss: 0.6147 - val_accuracy: 0.6354\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 3s 872us/step - loss: 0.5652 - accuracy: 0.7154 - val_loss: 0.5941 - val_accuracy: 0.6542\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 3s 832us/step - loss: 0.5622 - accuracy: 0.7173 - val_loss: 0.6037 - val_accuracy: 0.6460\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 660us/step - loss: 0.5596 - accuracy: 0.7205 - val_loss: 0.6049 - val_accuracy: 0.6444\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.5575 - accuracy: 0.7179 - val_loss: 0.6001 - val_accuracy: 0.6491\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 621us/step - loss: 0.5542 - accuracy: 0.7219 - val_loss: 0.6128 - val_accuracy: 0.6367\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 635us/step - loss: 0.5528 - accuracy: 0.7230 - val_loss: 0.6018 - val_accuracy: 0.6477\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.5511 - accuracy: 0.7223 - val_loss: 0.6136 - val_accuracy: 0.6357\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.5486 - accuracy: 0.7237 - val_loss: 0.6091 - val_accuracy: 0.6405\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 562us/step - loss: 0.5464 - accuracy: 0.7273 - val_loss: 0.6081 - val_accuracy: 0.6410\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 547us/step - loss: 0.5448 - accuracy: 0.7270 - val_loss: 0.6120 - val_accuracy: 0.6380\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 515us/step - loss: 0.5431 - accuracy: 0.7271 - val_loss: 0.6066 - val_accuracy: 0.6446\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5409 - accuracy: 0.7294 - val_loss: 0.6079 - val_accuracy: 0.6444\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 541us/step - loss: 0.5388 - accuracy: 0.7314 - val_loss: 0.6076 - val_accuracy: 0.6441\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 566us/step - loss: 0.5373 - accuracy: 0.7307 - val_loss: 0.6025 - val_accuracy: 0.6489\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 652us/step - loss: 0.5352 - accuracy: 0.7319 - val_loss: 0.5977 - val_accuracy: 0.6528\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 695us/step - loss: 0.5345 - accuracy: 0.7338 - val_loss: 0.5931 - val_accuracy: 0.6573\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 3s 817us/step - loss: 0.5333 - accuracy: 0.7341 - val_loss: 0.5904 - val_accuracy: 0.6605\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 3s 836us/step - loss: 0.5310 - accuracy: 0.7355 - val_loss: 0.6006 - val_accuracy: 0.6512\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 3s 827us/step - loss: 0.5302 - accuracy: 0.7343 - val_loss: 0.6025 - val_accuracy: 0.6504\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 3s 839us/step - loss: 0.5275 - accuracy: 0.7367 - val_loss: 0.6093 - val_accuracy: 0.6458\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 711us/step - loss: 0.5267 - accuracy: 0.7373 - val_loss: 0.6084 - val_accuracy: 0.6477\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 732us/step - loss: 0.5249 - accuracy: 0.7364 - val_loss: 0.5930 - val_accuracy: 0.6604\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 656us/step - loss: 0.5245 - accuracy: 0.7400 - val_loss: 0.5986 - val_accuracy: 0.6558\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 693us/step - loss: 0.5223 - accuracy: 0.7412 - val_loss: 0.6208 - val_accuracy: 0.6397\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 688us/step - loss: 0.5216 - accuracy: 0.7403 - val_loss: 0.5968 - val_accuracy: 0.6596\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 725us/step - loss: 0.5200 - accuracy: 0.7417 - val_loss: 0.5996 - val_accuracy: 0.6568\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 3s 748us/step - loss: 0.7185 - accuracy: 0.5124 - val_loss: 0.7081 - val_accuracy: 0.4503\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 3s 850us/step - loss: 0.6863 - accuracy: 0.5557 - val_loss: 0.7129 - val_accuracy: 0.4527\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 3s 796us/step - loss: 0.6780 - accuracy: 0.5787 - val_loss: 0.7071 - val_accuracy: 0.4863\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 721us/step - loss: 0.6723 - accuracy: 0.5932 - val_loss: 0.6976 - val_accuracy: 0.5280\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 3s 830us/step - loss: 0.6643 - accuracy: 0.6135 - val_loss: 0.6918 - val_accuracy: 0.5461\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 3s 945us/step - loss: 0.6607 - accuracy: 0.6195 - val_loss: 0.6888 - val_accuracy: 0.5530\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 722us/step - loss: 0.6551 - accuracy: 0.6325 - val_loss: 0.6837 - val_accuracy: 0.5656\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 3s 791us/step - loss: 0.6512 - accuracy: 0.6385 - val_loss: 0.6775 - val_accuracy: 0.5754\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 675us/step - loss: 0.6447 - accuracy: 0.6503 - val_loss: 0.6738 - val_accuracy: 0.5783\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 679us/step - loss: 0.6408 - accuracy: 0.6538 - val_loss: 0.6651 - val_accuracy: 0.5921\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.6342 - accuracy: 0.6645 - val_loss: 0.6592 - val_accuracy: 0.6013\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 745us/step - loss: 0.6312 - accuracy: 0.6640 - val_loss: 0.6576 - val_accuracy: 0.6010\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 3s 764us/step - loss: 0.6260 - accuracy: 0.6700 - val_loss: 0.6518 - val_accuracy: 0.6082\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 3s 753us/step - loss: 0.6215 - accuracy: 0.6751 - val_loss: 0.6481 - val_accuracy: 0.6126\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 3s 776us/step - loss: 0.6182 - accuracy: 0.6776 - val_loss: 0.6431 - val_accuracy: 0.6168\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 686us/step - loss: 0.6142 - accuracy: 0.6809 - val_loss: 0.6506 - val_accuracy: 0.6036\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.6105 - accuracy: 0.6826 - val_loss: 0.6511 - val_accuracy: 0.6011\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 650us/step - loss: 0.6068 - accuracy: 0.6836 - val_loss: 0.6279 - val_accuracy: 0.6277\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 737us/step - loss: 0.6033 - accuracy: 0.6884 - val_loss: 0.6324 - val_accuracy: 0.6196\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 3s 937us/step - loss: 0.6005 - accuracy: 0.6882 - val_loss: 0.6365 - val_accuracy: 0.6142\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 4s 1ms/step - loss: 0.5973 - accuracy: 0.6925 - val_loss: 0.6334 - val_accuracy: 0.6158\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 681us/step - loss: 0.5945 - accuracy: 0.6933 - val_loss: 0.6318 - val_accuracy: 0.6168\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.5914 - accuracy: 0.6964 - val_loss: 0.6230 - val_accuracy: 0.6249\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 615us/step - loss: 0.5886 - accuracy: 0.6979 - val_loss: 0.6277 - val_accuracy: 0.6189\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 570us/step - loss: 0.5861 - accuracy: 0.6995 - val_loss: 0.6264 - val_accuracy: 0.6192\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 578us/step - loss: 0.5836 - accuracy: 0.7027 - val_loss: 0.6207 - val_accuracy: 0.6235\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5816 - accuracy: 0.7031 - val_loss: 0.6273 - val_accuracy: 0.6179\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.5786 - accuracy: 0.7048 - val_loss: 0.6171 - val_accuracy: 0.6247\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5770 - accuracy: 0.7049 - val_loss: 0.6096 - val_accuracy: 0.6326\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.5748 - accuracy: 0.7076 - val_loss: 0.6183 - val_accuracy: 0.6239\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.5723 - accuracy: 0.7085 - val_loss: 0.6166 - val_accuracy: 0.6249\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5700 - accuracy: 0.7103 - val_loss: 0.6048 - val_accuracy: 0.6364\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 730us/step - loss: 0.5685 - accuracy: 0.7117 - val_loss: 0.6052 - val_accuracy: 0.6359\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.5654 - accuracy: 0.7121 - val_loss: 0.6207 - val_accuracy: 0.6211\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 687us/step - loss: 0.5637 - accuracy: 0.7139 - val_loss: 0.6098 - val_accuracy: 0.6309\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 664us/step - loss: 0.5626 - accuracy: 0.7135 - val_loss: 0.6136 - val_accuracy: 0.6294\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 703us/step - loss: 0.5609 - accuracy: 0.7155 - val_loss: 0.6009 - val_accuracy: 0.6377\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 696us/step - loss: 0.5597 - accuracy: 0.7171 - val_loss: 0.6095 - val_accuracy: 0.6312\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 659us/step - loss: 0.5577 - accuracy: 0.7174 - val_loss: 0.6185 - val_accuracy: 0.6255\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 638us/step - loss: 0.5556 - accuracy: 0.7201 - val_loss: 0.6201 - val_accuracy: 0.6241\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 708us/step - loss: 0.5542 - accuracy: 0.7191 - val_loss: 0.6039 - val_accuracy: 0.6367\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 648us/step - loss: 0.5519 - accuracy: 0.7204 - val_loss: 0.6195 - val_accuracy: 0.6241\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 631us/step - loss: 0.5511 - accuracy: 0.7206 - val_loss: 0.6115 - val_accuracy: 0.6299\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 644us/step - loss: 0.5491 - accuracy: 0.7223 - val_loss: 0.6167 - val_accuracy: 0.6266\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.5482 - accuracy: 0.7227 - val_loss: 0.5966 - val_accuracy: 0.6438\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.5465 - accuracy: 0.7227 - val_loss: 0.5986 - val_accuracy: 0.6417\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 556us/step - loss: 0.5460 - accuracy: 0.7237 - val_loss: 0.6097 - val_accuracy: 0.6311\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 629us/step - loss: 0.5438 - accuracy: 0.7235 - val_loss: 0.6029 - val_accuracy: 0.6392\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 604us/step - loss: 0.5429 - accuracy: 0.7244 - val_loss: 0.6174 - val_accuracy: 0.6270\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.5410 - accuracy: 0.7266 - val_loss: 0.5939 - val_accuracy: 0.6472\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 689us/step - loss: 0.7175 - accuracy: 0.5217 - val_loss: 0.7159 - val_accuracy: 0.4553\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 679us/step - loss: 0.6957 - accuracy: 0.5508 - val_loss: 0.7068 - val_accuracy: 0.5043\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 669us/step - loss: 0.6808 - accuracy: 0.5776 - val_loss: 0.6996 - val_accuracy: 0.5336\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.6727 - accuracy: 0.5921 - val_loss: 0.6908 - val_accuracy: 0.5540\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 3s 783us/step - loss: 0.6622 - accuracy: 0.6125 - val_loss: 0.6848 - val_accuracy: 0.5661\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 732us/step - loss: 0.6533 - accuracy: 0.6265 - val_loss: 0.6679 - val_accuracy: 0.5924\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 719us/step - loss: 0.6458 - accuracy: 0.6388 - val_loss: 0.6636 - val_accuracy: 0.5978\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 711us/step - loss: 0.6385 - accuracy: 0.6524 - val_loss: 0.6566 - val_accuracy: 0.6058\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 624us/step - loss: 0.6333 - accuracy: 0.6582 - val_loss: 0.6543 - val_accuracy: 0.6080\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 626us/step - loss: 0.6272 - accuracy: 0.6672 - val_loss: 0.6534 - val_accuracy: 0.6074\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.6210 - accuracy: 0.6731 - val_loss: 0.6487 - val_accuracy: 0.6100\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.6160 - accuracy: 0.6789 - val_loss: 0.6491 - val_accuracy: 0.6078\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.6114 - accuracy: 0.6796 - val_loss: 0.6414 - val_accuracy: 0.6130\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 646us/step - loss: 0.6066 - accuracy: 0.6878 - val_loss: 0.6298 - val_accuracy: 0.6214\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 659us/step - loss: 0.6032 - accuracy: 0.6884 - val_loss: 0.6293 - val_accuracy: 0.6196\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 712us/step - loss: 0.5996 - accuracy: 0.6901 - val_loss: 0.6347 - val_accuracy: 0.6137\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 673us/step - loss: 0.5933 - accuracy: 0.6973 - val_loss: 0.6373 - val_accuracy: 0.6086\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.5909 - accuracy: 0.6988 - val_loss: 0.6265 - val_accuracy: 0.6206\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 678us/step - loss: 0.5870 - accuracy: 0.7027 - val_loss: 0.6206 - val_accuracy: 0.6260\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 679us/step - loss: 0.5840 - accuracy: 0.7034 - val_loss: 0.6268 - val_accuracy: 0.6183\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5795 - accuracy: 0.7066 - val_loss: 0.6219 - val_accuracy: 0.6239\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5767 - accuracy: 0.7105 - val_loss: 0.6250 - val_accuracy: 0.6216\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 569us/step - loss: 0.5727 - accuracy: 0.7117 - val_loss: 0.6210 - val_accuracy: 0.6269\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5707 - accuracy: 0.7132 - val_loss: 0.6197 - val_accuracy: 0.6282\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 634us/step - loss: 0.5673 - accuracy: 0.7152 - val_loss: 0.6136 - val_accuracy: 0.6339\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 611us/step - loss: 0.5652 - accuracy: 0.7155 - val_loss: 0.6181 - val_accuracy: 0.6313\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.5621 - accuracy: 0.7188 - val_loss: 0.6054 - val_accuracy: 0.6403\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.5594 - accuracy: 0.7178 - val_loss: 0.6084 - val_accuracy: 0.6374\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 597us/step - loss: 0.5568 - accuracy: 0.7195 - val_loss: 0.6219 - val_accuracy: 0.6268\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.5541 - accuracy: 0.7205 - val_loss: 0.5977 - val_accuracy: 0.6460\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.5519 - accuracy: 0.7217 - val_loss: 0.6166 - val_accuracy: 0.6293\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.5496 - accuracy: 0.7236 - val_loss: 0.6075 - val_accuracy: 0.6374\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.5483 - accuracy: 0.7250 - val_loss: 0.6029 - val_accuracy: 0.6410\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 591us/step - loss: 0.5449 - accuracy: 0.7266 - val_loss: 0.6023 - val_accuracy: 0.6435\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.5437 - accuracy: 0.7268 - val_loss: 0.6067 - val_accuracy: 0.6417\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.5416 - accuracy: 0.7276 - val_loss: 0.6163 - val_accuracy: 0.6341\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 576us/step - loss: 0.5398 - accuracy: 0.7279 - val_loss: 0.6213 - val_accuracy: 0.6302\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.5378 - accuracy: 0.7289 - val_loss: 0.6113 - val_accuracy: 0.6395\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 571us/step - loss: 0.5359 - accuracy: 0.7300 - val_loss: 0.6077 - val_accuracy: 0.6417\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.5334 - accuracy: 0.7322 - val_loss: 0.5987 - val_accuracy: 0.6483\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.5328 - accuracy: 0.7337 - val_loss: 0.5995 - val_accuracy: 0.6477\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 558us/step - loss: 0.5305 - accuracy: 0.7328 - val_loss: 0.6077 - val_accuracy: 0.6423\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.5288 - accuracy: 0.7360 - val_loss: 0.6141 - val_accuracy: 0.6382\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.5274 - accuracy: 0.7348 - val_loss: 0.5969 - val_accuracy: 0.6493\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 567us/step - loss: 0.5261 - accuracy: 0.7357 - val_loss: 0.5945 - val_accuracy: 0.6521\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 590us/step - loss: 0.5254 - accuracy: 0.7356 - val_loss: 0.5966 - val_accuracy: 0.6513\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 609us/step - loss: 0.5222 - accuracy: 0.7392 - val_loss: 0.6079 - val_accuracy: 0.6427\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.5213 - accuracy: 0.7382 - val_loss: 0.5987 - val_accuracy: 0.6503\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.5199 - accuracy: 0.7393 - val_loss: 0.6062 - val_accuracy: 0.6449\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 642us/step - loss: 0.5186 - accuracy: 0.7398 - val_loss: 0.5973 - val_accuracy: 0.6527\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 607us/step - loss: 0.6984 - accuracy: 0.5387 - val_loss: 0.7032 - val_accuracy: 0.4975\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 555us/step - loss: 0.6710 - accuracy: 0.5865 - val_loss: 0.6870 - val_accuracy: 0.5506\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 573us/step - loss: 0.6603 - accuracy: 0.6080 - val_loss: 0.6791 - val_accuracy: 0.5775\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.6518 - accuracy: 0.6245 - val_loss: 0.6678 - val_accuracy: 0.6015\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.6434 - accuracy: 0.6382 - val_loss: 0.6563 - val_accuracy: 0.6204\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 646us/step - loss: 0.6378 - accuracy: 0.6468 - val_loss: 0.6527 - val_accuracy: 0.6225\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 579us/step - loss: 0.6311 - accuracy: 0.6547 - val_loss: 0.6536 - val_accuracy: 0.6176\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 574us/step - loss: 0.6261 - accuracy: 0.6597 - val_loss: 0.6446 - val_accuracy: 0.6284\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 580us/step - loss: 0.6199 - accuracy: 0.6655 - val_loss: 0.6334 - val_accuracy: 0.6427\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 546us/step - loss: 0.6166 - accuracy: 0.6684 - val_loss: 0.6292 - val_accuracy: 0.6446\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.6118 - accuracy: 0.6763 - val_loss: 0.6264 - val_accuracy: 0.6468\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.6071 - accuracy: 0.6766 - val_loss: 0.6283 - val_accuracy: 0.6420\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.6037 - accuracy: 0.6824 - val_loss: 0.6268 - val_accuracy: 0.6416\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 593us/step - loss: 0.6001 - accuracy: 0.6846 - val_loss: 0.6249 - val_accuracy: 0.6422\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 594us/step - loss: 0.5965 - accuracy: 0.6882 - val_loss: 0.6079 - val_accuracy: 0.6619\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 539us/step - loss: 0.5926 - accuracy: 0.6914 - val_loss: 0.6086 - val_accuracy: 0.6574\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 627us/step - loss: 0.5896 - accuracy: 0.6955 - val_loss: 0.6141 - val_accuracy: 0.6465\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5856 - accuracy: 0.6971 - val_loss: 0.6114 - val_accuracy: 0.6467\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 598us/step - loss: 0.5830 - accuracy: 0.6994 - val_loss: 0.6300 - val_accuracy: 0.6311\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 586us/step - loss: 0.5787 - accuracy: 0.7042 - val_loss: 0.6137 - val_accuracy: 0.6457\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.5763 - accuracy: 0.7041 - val_loss: 0.6089 - val_accuracy: 0.6500\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 588us/step - loss: 0.5733 - accuracy: 0.7080 - val_loss: 0.6023 - val_accuracy: 0.6563\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5718 - accuracy: 0.7081 - val_loss: 0.5960 - val_accuracy: 0.6615\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 637us/step - loss: 0.5695 - accuracy: 0.7109 - val_loss: 0.6097 - val_accuracy: 0.6502\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 577us/step - loss: 0.5671 - accuracy: 0.7116 - val_loss: 0.6132 - val_accuracy: 0.6465\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 610us/step - loss: 0.5638 - accuracy: 0.7139 - val_loss: 0.6069 - val_accuracy: 0.6501\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 686us/step - loss: 0.5617 - accuracy: 0.7152 - val_loss: 0.6156 - val_accuracy: 0.6427\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 670us/step - loss: 0.5601 - accuracy: 0.7149 - val_loss: 0.6047 - val_accuracy: 0.6517\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 653us/step - loss: 0.5582 - accuracy: 0.7168 - val_loss: 0.6030 - val_accuracy: 0.6541\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 3s 906us/step - loss: 0.5557 - accuracy: 0.7177 - val_loss: 0.6073 - val_accuracy: 0.6500\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 696us/step - loss: 0.5533 - accuracy: 0.7207 - val_loss: 0.6082 - val_accuracy: 0.6486\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 587us/step - loss: 0.5513 - accuracy: 0.7207 - val_loss: 0.5990 - val_accuracy: 0.6580\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 651us/step - loss: 0.5504 - accuracy: 0.7224 - val_loss: 0.6082 - val_accuracy: 0.6502\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 683us/step - loss: 0.5480 - accuracy: 0.7217 - val_loss: 0.6032 - val_accuracy: 0.6561\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 583us/step - loss: 0.5451 - accuracy: 0.7247 - val_loss: 0.5848 - val_accuracy: 0.6679\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 585us/step - loss: 0.5442 - accuracy: 0.7248 - val_loss: 0.6007 - val_accuracy: 0.6580\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.5430 - accuracy: 0.7267 - val_loss: 0.6055 - val_accuracy: 0.6559\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 589us/step - loss: 0.5403 - accuracy: 0.7260 - val_loss: 0.6036 - val_accuracy: 0.6579\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.5391 - accuracy: 0.7278 - val_loss: 0.6078 - val_accuracy: 0.6551\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 628us/step - loss: 0.5378 - accuracy: 0.7289 - val_loss: 0.6027 - val_accuracy: 0.6593\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.5366 - accuracy: 0.7285 - val_loss: 0.5935 - val_accuracy: 0.6657\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.5338 - accuracy: 0.7325 - val_loss: 0.5966 - val_accuracy: 0.6644\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 614us/step - loss: 0.5327 - accuracy: 0.7327 - val_loss: 0.5993 - val_accuracy: 0.6637\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.5312 - accuracy: 0.7327 - val_loss: 0.6106 - val_accuracy: 0.6562\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5297 - accuracy: 0.7330 - val_loss: 0.6151 - val_accuracy: 0.6524\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 606us/step - loss: 0.5280 - accuracy: 0.7351 - val_loss: 0.5941 - val_accuracy: 0.6685\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.5268 - accuracy: 0.7354 - val_loss: 0.5975 - val_accuracy: 0.6653\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 725us/step - loss: 0.5251 - accuracy: 0.7364 - val_loss: 0.5919 - val_accuracy: 0.6709\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.5243 - accuracy: 0.7359 - val_loss: 0.5998 - val_accuracy: 0.6642\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 645us/step - loss: 0.5228 - accuracy: 0.7380 - val_loss: 0.6065 - val_accuracy: 0.6602\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 645us/step - loss: 0.7143 - accuracy: 0.5035 - val_loss: 0.7227 - val_accuracy: 0.3441\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 3s 884us/step - loss: 0.6931 - accuracy: 0.5439 - val_loss: 0.7122 - val_accuracy: 0.4285\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 693us/step - loss: 0.6792 - accuracy: 0.5748 - val_loss: 0.6955 - val_accuracy: 0.5319\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 681us/step - loss: 0.6710 - accuracy: 0.5944 - val_loss: 0.6938 - val_accuracy: 0.5462\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 668us/step - loss: 0.6621 - accuracy: 0.6154 - val_loss: 0.6922 - val_accuracy: 0.5527\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 658us/step - loss: 0.6555 - accuracy: 0.6260 - val_loss: 0.6749 - val_accuracy: 0.5975\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.6487 - accuracy: 0.6408 - val_loss: 0.6763 - val_accuracy: 0.5946\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 660us/step - loss: 0.6430 - accuracy: 0.6458 - val_loss: 0.6659 - val_accuracy: 0.6062\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 691us/step - loss: 0.6366 - accuracy: 0.6540 - val_loss: 0.6652 - val_accuracy: 0.6046\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.6302 - accuracy: 0.6622 - val_loss: 0.6579 - val_accuracy: 0.6143\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 560us/step - loss: 0.6264 - accuracy: 0.6656 - val_loss: 0.6556 - val_accuracy: 0.6167\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 2s 636us/step - loss: 0.6213 - accuracy: 0.6689 - val_loss: 0.6415 - val_accuracy: 0.6371\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 647us/step - loss: 0.6156 - accuracy: 0.6725 - val_loss: 0.6309 - val_accuracy: 0.6531\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 2s 665us/step - loss: 0.6127 - accuracy: 0.6753 - val_loss: 0.6376 - val_accuracy: 0.6399\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 681us/step - loss: 0.6092 - accuracy: 0.6784 - val_loss: 0.6322 - val_accuracy: 0.6458\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 687us/step - loss: 0.6051 - accuracy: 0.6820 - val_loss: 0.6331 - val_accuracy: 0.6433\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 643us/step - loss: 0.6021 - accuracy: 0.6845 - val_loss: 0.6349 - val_accuracy: 0.6403\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.5985 - accuracy: 0.6875 - val_loss: 0.6252 - val_accuracy: 0.6509\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.5959 - accuracy: 0.6905 - val_loss: 0.6217 - val_accuracy: 0.6511\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 2s 603us/step - loss: 0.5937 - accuracy: 0.6909 - val_loss: 0.6277 - val_accuracy: 0.6433\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 704us/step - loss: 0.5903 - accuracy: 0.6925 - val_loss: 0.6154 - val_accuracy: 0.6530\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 2s 689us/step - loss: 0.5898 - accuracy: 0.6920 - val_loss: 0.6197 - val_accuracy: 0.6479\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 2s 565us/step - loss: 0.5862 - accuracy: 0.6953 - val_loss: 0.6268 - val_accuracy: 0.6413\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.5841 - accuracy: 0.6978 - val_loss: 0.6259 - val_accuracy: 0.6404\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 584us/step - loss: 0.5823 - accuracy: 0.6990 - val_loss: 0.6304 - val_accuracy: 0.6371\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 592us/step - loss: 0.5798 - accuracy: 0.7010 - val_loss: 0.6214 - val_accuracy: 0.6418\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 632us/step - loss: 0.5769 - accuracy: 0.7016 - val_loss: 0.6142 - val_accuracy: 0.6482\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 681us/step - loss: 0.5757 - accuracy: 0.7011 - val_loss: 0.6271 - val_accuracy: 0.6356\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.5733 - accuracy: 0.7054 - val_loss: 0.6164 - val_accuracy: 0.6474\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 2s 684us/step - loss: 0.5704 - accuracy: 0.7087 - val_loss: 0.6215 - val_accuracy: 0.6412\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 2s 630us/step - loss: 0.5699 - accuracy: 0.7073 - val_loss: 0.6264 - val_accuracy: 0.6362\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 618us/step - loss: 0.5675 - accuracy: 0.7106 - val_loss: 0.6311 - val_accuracy: 0.6332\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 2s 613us/step - loss: 0.5651 - accuracy: 0.7121 - val_loss: 0.6136 - val_accuracy: 0.6532\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 2s 608us/step - loss: 0.5642 - accuracy: 0.7109 - val_loss: 0.6059 - val_accuracy: 0.6601\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 2s 728us/step - loss: 0.5626 - accuracy: 0.7133 - val_loss: 0.6280 - val_accuracy: 0.6418\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 601us/step - loss: 0.5616 - accuracy: 0.7126 - val_loss: 0.6077 - val_accuracy: 0.6571\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 602us/step - loss: 0.5591 - accuracy: 0.7142 - val_loss: 0.6038 - val_accuracy: 0.6601\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.5581 - accuracy: 0.7153 - val_loss: 0.6177 - val_accuracy: 0.6504\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 653us/step - loss: 0.5559 - accuracy: 0.7169 - val_loss: 0.6084 - val_accuracy: 0.6561\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 733us/step - loss: 0.5547 - accuracy: 0.7166 - val_loss: 0.6148 - val_accuracy: 0.6517\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 617us/step - loss: 0.5530 - accuracy: 0.7181 - val_loss: 0.6039 - val_accuracy: 0.6587\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 599us/step - loss: 0.5518 - accuracy: 0.7198 - val_loss: 0.6128 - val_accuracy: 0.6522\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 669us/step - loss: 0.5507 - accuracy: 0.7202 - val_loss: 0.6103 - val_accuracy: 0.6551\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 650us/step - loss: 0.5483 - accuracy: 0.7204 - val_loss: 0.6181 - val_accuracy: 0.6502\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 673us/step - loss: 0.5472 - accuracy: 0.7236 - val_loss: 0.6199 - val_accuracy: 0.6498\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 612us/step - loss: 0.5454 - accuracy: 0.7225 - val_loss: 0.6180 - val_accuracy: 0.6509\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5446 - accuracy: 0.7242 - val_loss: 0.6130 - val_accuracy: 0.6535\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 653us/step - loss: 0.5433 - accuracy: 0.7231 - val_loss: 0.6147 - val_accuracy: 0.6537\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 622us/step - loss: 0.5423 - accuracy: 0.7243 - val_loss: 0.6120 - val_accuracy: 0.6543\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 600us/step - loss: 0.5417 - accuracy: 0.7245 - val_loss: 0.6135 - val_accuracy: 0.6533\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 658us/step - loss: 0.6936 - accuracy: 0.5334 - val_loss: 0.7099 - val_accuracy: 0.4452\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 619us/step - loss: 0.6778 - accuracy: 0.5758 - val_loss: 0.6922 - val_accuracy: 0.5243\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 661us/step - loss: 0.6669 - accuracy: 0.6014 - val_loss: 0.6806 - val_accuracy: 0.5568\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 712us/step - loss: 0.6585 - accuracy: 0.6176 - val_loss: 0.6791 - val_accuracy: 0.5611\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 3s 762us/step - loss: 0.6503 - accuracy: 0.6325 - val_loss: 0.6649 - val_accuracy: 0.5884\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 3s 836us/step - loss: 0.6405 - accuracy: 0.6478 - val_loss: 0.6710 - val_accuracy: 0.5818\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 3s 810us/step - loss: 0.6338 - accuracy: 0.6553 - val_loss: 0.6581 - val_accuracy: 0.5979\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.6270 - accuracy: 0.6662 - val_loss: 0.6583 - val_accuracy: 0.5988\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 2s 657us/step - loss: 0.6213 - accuracy: 0.6681 - val_loss: 0.6527 - val_accuracy: 0.6042\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 2s 682us/step - loss: 0.6154 - accuracy: 0.6736 - val_loss: 0.6367 - val_accuracy: 0.6277\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 2s 663us/step - loss: 0.6104 - accuracy: 0.6798 - val_loss: 0.6406 - val_accuracy: 0.6204\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 3s 875us/step - loss: 0.6066 - accuracy: 0.6812 - val_loss: 0.6400 - val_accuracy: 0.6209\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 2s 668us/step - loss: 0.6014 - accuracy: 0.6851 - val_loss: 0.6218 - val_accuracy: 0.6438\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 3s 822us/step - loss: 0.5980 - accuracy: 0.6861 - val_loss: 0.6247 - val_accuracy: 0.6385\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 2s 713us/step - loss: 0.5936 - accuracy: 0.6897 - val_loss: 0.6250 - val_accuracy: 0.6375\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 2s 748us/step - loss: 0.5913 - accuracy: 0.6917 - val_loss: 0.6174 - val_accuracy: 0.6458\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 2s 616us/step - loss: 0.5880 - accuracy: 0.6934 - val_loss: 0.6149 - val_accuracy: 0.6491\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 2s 704us/step - loss: 0.5844 - accuracy: 0.6967 - val_loss: 0.6247 - val_accuracy: 0.6377\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 2s 689us/step - loss: 0.5804 - accuracy: 0.7005 - val_loss: 0.6241 - val_accuracy: 0.6375\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 3s 806us/step - loss: 0.5779 - accuracy: 0.7027 - val_loss: 0.6194 - val_accuracy: 0.6417\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 2s 700us/step - loss: 0.5750 - accuracy: 0.7025 - val_loss: 0.6197 - val_accuracy: 0.6389\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 3s 1ms/step - loss: 0.5713 - accuracy: 0.7069 - val_loss: 0.6132 - val_accuracy: 0.6422\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 3s 923us/step - loss: 0.5685 - accuracy: 0.7103 - val_loss: 0.6132 - val_accuracy: 0.6415\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 2s 710us/step - loss: 0.5661 - accuracy: 0.7112 - val_loss: 0.6167 - val_accuracy: 0.6374\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 2s 703us/step - loss: 0.5640 - accuracy: 0.7123 - val_loss: 0.6189 - val_accuracy: 0.6354\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 2s 680us/step - loss: 0.5608 - accuracy: 0.7145 - val_loss: 0.6013 - val_accuracy: 0.6529\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 2s 690us/step - loss: 0.5583 - accuracy: 0.7176 - val_loss: 0.5963 - val_accuracy: 0.6604\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 2s 644us/step - loss: 0.5566 - accuracy: 0.7181 - val_loss: 0.6092 - val_accuracy: 0.6433\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 3s 750us/step - loss: 0.5542 - accuracy: 0.7185 - val_loss: 0.6086 - val_accuracy: 0.6453\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 3s 804us/step - loss: 0.5513 - accuracy: 0.7216 - val_loss: 0.6104 - val_accuracy: 0.6430\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 3s 784us/step - loss: 0.5496 - accuracy: 0.7226 - val_loss: 0.5888 - val_accuracy: 0.6659\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 2s 575us/step - loss: 0.5477 - accuracy: 0.7238 - val_loss: 0.6013 - val_accuracy: 0.6540\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 3s 832us/step - loss: 0.5463 - accuracy: 0.7249 - val_loss: 0.6048 - val_accuracy: 0.6504\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 4s 1ms/step - loss: 0.5441 - accuracy: 0.7267 - val_loss: 0.6005 - val_accuracy: 0.6551\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 3s 926us/step - loss: 0.5420 - accuracy: 0.7270 - val_loss: 0.6012 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 2s 722us/step - loss: 0.5403 - accuracy: 0.7272 - val_loss: 0.5944 - val_accuracy: 0.6623\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 2s 734us/step - loss: 0.5396 - accuracy: 0.7297 - val_loss: 0.6011 - val_accuracy: 0.6580\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 3s 773us/step - loss: 0.5362 - accuracy: 0.7312 - val_loss: 0.6016 - val_accuracy: 0.6581\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 2s 656us/step - loss: 0.5348 - accuracy: 0.7315 - val_loss: 0.5954 - val_accuracy: 0.6632\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 2s 679us/step - loss: 0.5332 - accuracy: 0.7335 - val_loss: 0.6006 - val_accuracy: 0.6590\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 2s 637us/step - loss: 0.5328 - accuracy: 0.7331 - val_loss: 0.5938 - val_accuracy: 0.6647\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 2s 676us/step - loss: 0.5309 - accuracy: 0.7339 - val_loss: 0.6106 - val_accuracy: 0.6511\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 2s 691us/step - loss: 0.5299 - accuracy: 0.7338 - val_loss: 0.6041 - val_accuracy: 0.6564\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 2s 673us/step - loss: 0.5269 - accuracy: 0.7367 - val_loss: 0.5987 - val_accuracy: 0.6611\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 678us/step - loss: 0.5257 - accuracy: 0.7365 - val_loss: 0.5965 - val_accuracy: 0.6633\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 675us/step - loss: 0.5243 - accuracy: 0.7373 - val_loss: 0.5873 - val_accuracy: 0.6707\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 692us/step - loss: 0.5230 - accuracy: 0.7391 - val_loss: 0.6146 - val_accuracy: 0.6502\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 699us/step - loss: 0.5214 - accuracy: 0.7387 - val_loss: 0.5915 - val_accuracy: 0.6685\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 692us/step - loss: 0.5203 - accuracy: 0.7402 - val_loss: 0.5994 - val_accuracy: 0.6624\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 670us/step - loss: 0.5190 - accuracy: 0.7422 - val_loss: 0.5954 - val_accuracy: 0.6652\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 2s 718us/step - loss: 0.7252 - accuracy: 0.4980 - val_loss: 0.7302 - val_accuracy: 0.2201\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 2s 694us/step - loss: 0.6852 - accuracy: 0.5520 - val_loss: 0.7217 - val_accuracy: 0.2869\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 2s 688us/step - loss: 0.6763 - accuracy: 0.5817 - val_loss: 0.7166 - val_accuracy: 0.3498\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 2s 715us/step - loss: 0.6691 - accuracy: 0.6026 - val_loss: 0.7061 - val_accuracy: 0.4179\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 2s 689us/step - loss: 0.6617 - accuracy: 0.6235 - val_loss: 0.6974 - val_accuracy: 0.4708\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 2s 687us/step - loss: 0.6546 - accuracy: 0.6457 - val_loss: 0.6927 - val_accuracy: 0.4904\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 2s 675us/step - loss: 0.6472 - accuracy: 0.6576 - val_loss: 0.6772 - val_accuracy: 0.5524\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 3s 1ms/step - loss: 0.6417 - accuracy: 0.6669 - val_loss: 0.6792 - val_accuracy: 0.5463\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 3s 1ms/step - loss: 0.6361 - accuracy: 0.6753 - val_loss: 0.6767 - val_accuracy: 0.5516\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 3s 1ms/step - loss: 0.6294 - accuracy: 0.6833 - val_loss: 0.6671 - val_accuracy: 0.5708\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 5s 1ms/step - loss: 0.6232 - accuracy: 0.6900 - val_loss: 0.6639 - val_accuracy: 0.5756\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 3s 1ms/step - loss: 0.6186 - accuracy: 0.6914 - val_loss: 0.6576 - val_accuracy: 0.5860\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 3s 807us/step - loss: 0.6134 - accuracy: 0.6947 - val_loss: 0.6529 - val_accuracy: 0.5913\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 3s 782us/step - loss: 0.6080 - accuracy: 0.6982 - val_loss: 0.6497 - val_accuracy: 0.5944\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 3s 751us/step - loss: 0.6030 - accuracy: 0.7004 - val_loss: 0.6473 - val_accuracy: 0.5980\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 3s 855us/step - loss: 0.5990 - accuracy: 0.7032 - val_loss: 0.6426 - val_accuracy: 0.6036\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 3s 800us/step - loss: 0.5939 - accuracy: 0.7055 - val_loss: 0.6370 - val_accuracy: 0.6114\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 3s 792us/step - loss: 0.5901 - accuracy: 0.7074 - val_loss: 0.6340 - val_accuracy: 0.6146\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 3s 832us/step - loss: 0.5862 - accuracy: 0.7082 - val_loss: 0.6293 - val_accuracy: 0.6193\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 3s 816us/step - loss: 0.5820 - accuracy: 0.7119 - val_loss: 0.6319 - val_accuracy: 0.6166\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 3s 787us/step - loss: 0.5781 - accuracy: 0.7142 - val_loss: 0.6150 - val_accuracy: 0.6331\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 3s 789us/step - loss: 0.5760 - accuracy: 0.7114 - val_loss: 0.6083 - val_accuracy: 0.6404\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 3s 835us/step - loss: 0.5727 - accuracy: 0.7153 - val_loss: 0.6118 - val_accuracy: 0.6365\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 3s 818us/step - loss: 0.5687 - accuracy: 0.7158 - val_loss: 0.6229 - val_accuracy: 0.6241\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 3s 853us/step - loss: 0.5660 - accuracy: 0.7176 - val_loss: 0.6194 - val_accuracy: 0.6274\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 3s 820us/step - loss: 0.5636 - accuracy: 0.7206 - val_loss: 0.6130 - val_accuracy: 0.6340\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 3s 783us/step - loss: 0.5617 - accuracy: 0.7197 - val_loss: 0.6100 - val_accuracy: 0.6363\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 3s 853us/step - loss: 0.5594 - accuracy: 0.7207 - val_loss: 0.6187 - val_accuracy: 0.6278\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 3s 922us/step - loss: 0.5558 - accuracy: 0.7232 - val_loss: 0.6110 - val_accuracy: 0.6351\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 3s 790us/step - loss: 0.5542 - accuracy: 0.7227 - val_loss: 0.6024 - val_accuracy: 0.6426\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 3s 825us/step - loss: 0.5502 - accuracy: 0.7275 - val_loss: 0.6032 - val_accuracy: 0.6413\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 3s 862us/step - loss: 0.5488 - accuracy: 0.7272 - val_loss: 0.6012 - val_accuracy: 0.6423\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 3s 804us/step - loss: 0.5477 - accuracy: 0.7267 - val_loss: 0.5916 - val_accuracy: 0.6532\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 3s 802us/step - loss: 0.5454 - accuracy: 0.7277 - val_loss: 0.5967 - val_accuracy: 0.6487\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 3s 838us/step - loss: 0.5435 - accuracy: 0.7299 - val_loss: 0.5984 - val_accuracy: 0.6459\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 3s 790us/step - loss: 0.5400 - accuracy: 0.7318 - val_loss: 0.6045 - val_accuracy: 0.6396\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 3s 804us/step - loss: 0.5389 - accuracy: 0.7317 - val_loss: 0.6019 - val_accuracy: 0.6430\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 3s 802us/step - loss: 0.5376 - accuracy: 0.7328 - val_loss: 0.6003 - val_accuracy: 0.6450\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 3s 830us/step - loss: 0.5359 - accuracy: 0.7333 - val_loss: 0.6117 - val_accuracy: 0.6333\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 3s 817us/step - loss: 0.5338 - accuracy: 0.7359 - val_loss: 0.5999 - val_accuracy: 0.6456\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 3s 773us/step - loss: 0.5317 - accuracy: 0.7356 - val_loss: 0.6176 - val_accuracy: 0.6291\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 3s 784us/step - loss: 0.5290 - accuracy: 0.7376 - val_loss: 0.6008 - val_accuracy: 0.6444\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 3s 807us/step - loss: 0.5279 - accuracy: 0.7373 - val_loss: 0.6168 - val_accuracy: 0.6291\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 3s 765us/step - loss: 0.5264 - accuracy: 0.7401 - val_loss: 0.6037 - val_accuracy: 0.6426\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 3s 796us/step - loss: 0.5248 - accuracy: 0.7385 - val_loss: 0.6035 - val_accuracy: 0.6427\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 3s 818us/step - loss: 0.5240 - accuracy: 0.7399 - val_loss: 0.5943 - val_accuracy: 0.6528\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 3s 794us/step - loss: 0.5219 - accuracy: 0.7423 - val_loss: 0.5902 - val_accuracy: 0.6565\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 3s 811us/step - loss: 0.5198 - accuracy: 0.7440 - val_loss: 0.5970 - val_accuracy: 0.6525\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 3s 822us/step - loss: 0.5186 - accuracy: 0.7423 - val_loss: 0.5962 - val_accuracy: 0.6525\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 3s 837us/step - loss: 0.5174 - accuracy: 0.7436 - val_loss: 0.6058 - val_accuracy: 0.6457\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 3s 868us/step - loss: 0.6896 - accuracy: 0.5492 - val_loss: 0.6981 - val_accuracy: 0.5128\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 3s 903us/step - loss: 0.6720 - accuracy: 0.5916 - val_loss: 0.6904 - val_accuracy: 0.5577\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 3s 807us/step - loss: 0.6581 - accuracy: 0.6175 - val_loss: 0.6720 - val_accuracy: 0.5957\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 3s 777us/step - loss: 0.6496 - accuracy: 0.6374 - val_loss: 0.6667 - val_accuracy: 0.6018\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 3s 788us/step - loss: 0.6411 - accuracy: 0.6490 - val_loss: 0.6638 - val_accuracy: 0.6052\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 3s 789us/step - loss: 0.6323 - accuracy: 0.6594 - val_loss: 0.6568 - val_accuracy: 0.6147\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 3s 878us/step - loss: 0.6265 - accuracy: 0.6650 - val_loss: 0.6423 - val_accuracy: 0.6293\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 3s 823us/step - loss: 0.6212 - accuracy: 0.6717 - val_loss: 0.6379 - val_accuracy: 0.6336\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 3s 797us/step - loss: 0.6163 - accuracy: 0.6730 - val_loss: 0.6406 - val_accuracy: 0.6311\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 3s 813us/step - loss: 0.6108 - accuracy: 0.6791 - val_loss: 0.6335 - val_accuracy: 0.6393\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 3s 818us/step - loss: 0.6054 - accuracy: 0.6850 - val_loss: 0.6325 - val_accuracy: 0.6401\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 3s 832us/step - loss: 0.6006 - accuracy: 0.6879 - val_loss: 0.6358 - val_accuracy: 0.6367\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 3s 792us/step - loss: 0.5966 - accuracy: 0.6904 - val_loss: 0.6147 - val_accuracy: 0.6535\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 3s 843us/step - loss: 0.5935 - accuracy: 0.6921 - val_loss: 0.6241 - val_accuracy: 0.6437\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 3s 838us/step - loss: 0.5894 - accuracy: 0.6970 - val_loss: 0.6248 - val_accuracy: 0.6427\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 3s 776us/step - loss: 0.5843 - accuracy: 0.7015 - val_loss: 0.6208 - val_accuracy: 0.6445\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 3s 808us/step - loss: 0.5828 - accuracy: 0.7034 - val_loss: 0.6227 - val_accuracy: 0.6414\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 3s 830us/step - loss: 0.5782 - accuracy: 0.7059 - val_loss: 0.6254 - val_accuracy: 0.6386\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 3s 848us/step - loss: 0.5743 - accuracy: 0.7073 - val_loss: 0.6192 - val_accuracy: 0.6434\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 3s 813us/step - loss: 0.5710 - accuracy: 0.7096 - val_loss: 0.6221 - val_accuracy: 0.6386\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 3s 826us/step - loss: 0.5689 - accuracy: 0.7116 - val_loss: 0.6162 - val_accuracy: 0.6424\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 3s 769us/step - loss: 0.5661 - accuracy: 0.7133 - val_loss: 0.6116 - val_accuracy: 0.6471\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 3s 869us/step - loss: 0.5625 - accuracy: 0.7163 - val_loss: 0.6176 - val_accuracy: 0.6406\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 3s 837us/step - loss: 0.5598 - accuracy: 0.7178 - val_loss: 0.6039 - val_accuracy: 0.6537\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 3s 865us/step - loss: 0.5576 - accuracy: 0.7194 - val_loss: 0.6190 - val_accuracy: 0.6394\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 3s 838us/step - loss: 0.5546 - accuracy: 0.7209 - val_loss: 0.5935 - val_accuracy: 0.6624\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 3s 907us/step - loss: 0.5530 - accuracy: 0.7217 - val_loss: 0.6104 - val_accuracy: 0.6461\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 3s 819us/step - loss: 0.5506 - accuracy: 0.7241 - val_loss: 0.6072 - val_accuracy: 0.6488\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 3s 818us/step - loss: 0.5489 - accuracy: 0.7234 - val_loss: 0.6020 - val_accuracy: 0.6521\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 3s 813us/step - loss: 0.5455 - accuracy: 0.7255 - val_loss: 0.6062 - val_accuracy: 0.6477\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 3s 844us/step - loss: 0.5435 - accuracy: 0.7272 - val_loss: 0.6065 - val_accuracy: 0.6476\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 3s 803us/step - loss: 0.5425 - accuracy: 0.7276 - val_loss: 0.6031 - val_accuracy: 0.6510\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 3s 787us/step - loss: 0.5406 - accuracy: 0.7292 - val_loss: 0.6039 - val_accuracy: 0.6508\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 3s 843us/step - loss: 0.5373 - accuracy: 0.7317 - val_loss: 0.6057 - val_accuracy: 0.6496\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 3s 835us/step - loss: 0.5367 - accuracy: 0.7302 - val_loss: 0.5846 - val_accuracy: 0.6659\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 3s 928us/step - loss: 0.5354 - accuracy: 0.7318 - val_loss: 0.6154 - val_accuracy: 0.6456\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 3s 935us/step - loss: 0.5333 - accuracy: 0.7321 - val_loss: 0.6160 - val_accuracy: 0.6457\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 8s 3ms/step - loss: 0.5322 - accuracy: 0.7330 - val_loss: 0.6053 - val_accuracy: 0.6521\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 4s 1ms/step - loss: 0.5305 - accuracy: 0.7340 - val_loss: 0.6041 - val_accuracy: 0.6523\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 3s 894us/step - loss: 0.5282 - accuracy: 0.7347 - val_loss: 0.6066 - val_accuracy: 0.6518\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 3s 876us/step - loss: 0.5271 - accuracy: 0.7339 - val_loss: 0.6049 - val_accuracy: 0.6541\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 3s 829us/step - loss: 0.5251 - accuracy: 0.7374 - val_loss: 0.5981 - val_accuracy: 0.6596\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 3s 931us/step - loss: 0.5251 - accuracy: 0.7358 - val_loss: 0.5852 - val_accuracy: 0.6683\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 3s 822us/step - loss: 0.5233 - accuracy: 0.7377 - val_loss: 0.5980 - val_accuracy: 0.6608\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 2s 465us/step - loss: 0.5218 - accuracy: 0.7382 - val_loss: 0.5912 - val_accuracy: 0.6652\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 2s 512us/step - loss: 0.5207 - accuracy: 0.7398 - val_loss: 0.5968 - val_accuracy: 0.6627\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 2s 482us/step - loss: 0.5190 - accuracy: 0.7387 - val_loss: 0.6085 - val_accuracy: 0.6550\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 2s 474us/step - loss: 0.5181 - accuracy: 0.7408 - val_loss: 0.6011 - val_accuracy: 0.6604\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 2s 461us/step - loss: 0.5169 - accuracy: 0.7413 - val_loss: 0.6083 - val_accuracy: 0.6556\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 2s 596us/step - loss: 0.5157 - accuracy: 0.7429 - val_loss: 0.5852 - val_accuracy: 0.6709\n",
      "\n",
      "Training model with batch_size=32, target_eps=0.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 5.05 iterated over 83600 steps satisfies differential privacy with eps = 0.167 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.5749999999999997 iterated over 83600 steps satisfies differential privacy with eps = 0.34 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.3375 iterated over 83600 steps satisfies differential privacy with eps = 0.763 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.9562499999999998 iterated over 83600 steps satisfies differential privacy with eps = 0.46 and delta = 1e-05.\n",
      "The optimal RDP order is 51.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.6468749999999999 iterated over 83600 steps satisfies differential privacy with eps = 0.566 and delta = 1e-05.\n",
      "The optimal RDP order is 39.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.8015624999999997 iterated over 83600 steps satisfies differential privacy with eps = 0.507 and delta = 1e-05.\n",
      "The optimal RDP order is 46.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.7387 - accuracy: 0.4930 - val_loss: 0.7537 - val_accuracy: 0.2242\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.7186 - accuracy: 0.4996 - val_loss: 0.7297 - val_accuracy: 0.2966\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.7090 - accuracy: 0.5159 - val_loss: 0.7254 - val_accuracy: 0.3462\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6998 - accuracy: 0.5307 - val_loss: 0.7191 - val_accuracy: 0.4064\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6907 - accuracy: 0.5448 - val_loss: 0.7072 - val_accuracy: 0.4943\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6861 - accuracy: 0.5545 - val_loss: 0.7007 - val_accuracy: 0.5252\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6815 - accuracy: 0.5659 - val_loss: 0.6982 - val_accuracy: 0.5346\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6767 - accuracy: 0.5752 - val_loss: 0.6947 - val_accuracy: 0.5458\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6712 - accuracy: 0.5857 - val_loss: 0.6899 - val_accuracy: 0.5546\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6679 - accuracy: 0.5919 - val_loss: 0.6854 - val_accuracy: 0.5664\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6635 - accuracy: 0.6013 - val_loss: 0.6814 - val_accuracy: 0.5754\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6601 - accuracy: 0.6074 - val_loss: 0.6810 - val_accuracy: 0.5765\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6564 - accuracy: 0.6111 - val_loss: 0.6774 - val_accuracy: 0.5829\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6528 - accuracy: 0.6183 - val_loss: 0.6718 - val_accuracy: 0.5953\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6489 - accuracy: 0.6261 - val_loss: 0.6691 - val_accuracy: 0.5995\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6457 - accuracy: 0.6296 - val_loss: 0.6660 - val_accuracy: 0.6018\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6434 - accuracy: 0.6314 - val_loss: 0.6651 - val_accuracy: 0.6031\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6400 - accuracy: 0.6364 - val_loss: 0.6622 - val_accuracy: 0.6091\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6369 - accuracy: 0.6402 - val_loss: 0.6596 - val_accuracy: 0.6151\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6333 - accuracy: 0.6442 - val_loss: 0.6579 - val_accuracy: 0.6175\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6318 - accuracy: 0.6457 - val_loss: 0.6529 - val_accuracy: 0.6242\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6294 - accuracy: 0.6499 - val_loss: 0.6529 - val_accuracy: 0.6221\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6271 - accuracy: 0.6501 - val_loss: 0.6485 - val_accuracy: 0.6258\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6247 - accuracy: 0.6529 - val_loss: 0.6476 - val_accuracy: 0.6249\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6231 - accuracy: 0.6559 - val_loss: 0.6474 - val_accuracy: 0.6229\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6195 - accuracy: 0.6595 - val_loss: 0.6436 - val_accuracy: 0.6265\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.6176 - accuracy: 0.6587 - val_loss: 0.6412 - val_accuracy: 0.6287\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6148 - accuracy: 0.6601 - val_loss: 0.6436 - val_accuracy: 0.6235\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6138 - accuracy: 0.6628 - val_loss: 0.6378 - val_accuracy: 0.6313\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6111 - accuracy: 0.6653 - val_loss: 0.6336 - val_accuracy: 0.6368\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6091 - accuracy: 0.6668 - val_loss: 0.6348 - val_accuracy: 0.6328\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6072 - accuracy: 0.6702 - val_loss: 0.6375 - val_accuracy: 0.6288\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6051 - accuracy: 0.6727 - val_loss: 0.6372 - val_accuracy: 0.6277\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6038 - accuracy: 0.6731 - val_loss: 0.6285 - val_accuracy: 0.6404\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6009 - accuracy: 0.6757 - val_loss: 0.6356 - val_accuracy: 0.6303\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5998 - accuracy: 0.6784 - val_loss: 0.6311 - val_accuracy: 0.6357\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5987 - accuracy: 0.6775 - val_loss: 0.6266 - val_accuracy: 0.6401\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5959 - accuracy: 0.6817 - val_loss: 0.6221 - val_accuracy: 0.6472\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5936 - accuracy: 0.6831 - val_loss: 0.6236 - val_accuracy: 0.6429\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5920 - accuracy: 0.6846 - val_loss: 0.6220 - val_accuracy: 0.6425\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5901 - accuracy: 0.6881 - val_loss: 0.6177 - val_accuracy: 0.6465\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5881 - accuracy: 0.6889 - val_loss: 0.6211 - val_accuracy: 0.6419\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5870 - accuracy: 0.6900 - val_loss: 0.6207 - val_accuracy: 0.6418\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5841 - accuracy: 0.6914 - val_loss: 0.6208 - val_accuracy: 0.6409\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5833 - accuracy: 0.6926 - val_loss: 0.6183 - val_accuracy: 0.6425\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5817 - accuracy: 0.6943 - val_loss: 0.6142 - val_accuracy: 0.6479\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 869us/step - loss: 0.5801 - accuracy: 0.6954 - val_loss: 0.6184 - val_accuracy: 0.6415\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5789 - accuracy: 0.6972 - val_loss: 0.6166 - val_accuracy: 0.6444\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 814us/step - loss: 0.5776 - accuracy: 0.6966 - val_loss: 0.6138 - val_accuracy: 0.6483\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.5766 - accuracy: 0.6988 - val_loss: 0.6146 - val_accuracy: 0.6479\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.7059 - accuracy: 0.5256 - val_loss: 0.7414 - val_accuracy: 0.2644\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.6871 - accuracy: 0.5460 - val_loss: 0.7093 - val_accuracy: 0.4390\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 797us/step - loss: 0.6802 - accuracy: 0.5682 - val_loss: 0.7023 - val_accuracy: 0.4804\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.6750 - accuracy: 0.5829 - val_loss: 0.6979 - val_accuracy: 0.4983\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6711 - accuracy: 0.5945 - val_loss: 0.6936 - val_accuracy: 0.5148\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.6673 - accuracy: 0.6046 - val_loss: 0.6921 - val_accuracy: 0.5195\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6625 - accuracy: 0.6155 - val_loss: 0.6868 - val_accuracy: 0.5347\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.6585 - accuracy: 0.6248 - val_loss: 0.6825 - val_accuracy: 0.5496\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.6547 - accuracy: 0.6318 - val_loss: 0.6784 - val_accuracy: 0.5656\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6502 - accuracy: 0.6420 - val_loss: 0.6752 - val_accuracy: 0.5777\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.6478 - accuracy: 0.6469 - val_loss: 0.6699 - val_accuracy: 0.5970\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.6435 - accuracy: 0.6518 - val_loss: 0.6682 - val_accuracy: 0.6046\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6407 - accuracy: 0.6550 - val_loss: 0.6613 - val_accuracy: 0.6211\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6373 - accuracy: 0.6578 - val_loss: 0.6571 - val_accuracy: 0.6261\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.6345 - accuracy: 0.6627 - val_loss: 0.6548 - val_accuracy: 0.6276\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6311 - accuracy: 0.6655 - val_loss: 0.6499 - val_accuracy: 0.6315\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.6284 - accuracy: 0.6666 - val_loss: 0.6474 - val_accuracy: 0.6310\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.6254 - accuracy: 0.6704 - val_loss: 0.6460 - val_accuracy: 0.6294\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6225 - accuracy: 0.6733 - val_loss: 0.6426 - val_accuracy: 0.6307\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6202 - accuracy: 0.6761 - val_loss: 0.6427 - val_accuracy: 0.6266\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.6188 - accuracy: 0.6754 - val_loss: 0.6420 - val_accuracy: 0.6248\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6152 - accuracy: 0.6798 - val_loss: 0.6401 - val_accuracy: 0.6252\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.6141 - accuracy: 0.6794 - val_loss: 0.6410 - val_accuracy: 0.6219\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6111 - accuracy: 0.6840 - val_loss: 0.6369 - val_accuracy: 0.6260\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6098 - accuracy: 0.6828 - val_loss: 0.6337 - val_accuracy: 0.6283\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.6080 - accuracy: 0.6860 - val_loss: 0.6311 - val_accuracy: 0.6302\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6053 - accuracy: 0.6862 - val_loss: 0.6343 - val_accuracy: 0.6251\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6025 - accuracy: 0.6891 - val_loss: 0.6282 - val_accuracy: 0.6298\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6017 - accuracy: 0.6902 - val_loss: 0.6296 - val_accuracy: 0.6267\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 753us/step - loss: 0.5995 - accuracy: 0.6932 - val_loss: 0.6275 - val_accuracy: 0.6268\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5974 - accuracy: 0.6956 - val_loss: 0.6314 - val_accuracy: 0.6247\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5962 - accuracy: 0.6945 - val_loss: 0.6231 - val_accuracy: 0.6332\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5945 - accuracy: 0.6963 - val_loss: 0.6214 - val_accuracy: 0.6344\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.5927 - accuracy: 0.6986 - val_loss: 0.6187 - val_accuracy: 0.6372\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.5912 - accuracy: 0.6999 - val_loss: 0.6210 - val_accuracy: 0.6350\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.5892 - accuracy: 0.6994 - val_loss: 0.6192 - val_accuracy: 0.6366\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.5882 - accuracy: 0.7014 - val_loss: 0.6206 - val_accuracy: 0.6359\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.5864 - accuracy: 0.7021 - val_loss: 0.6160 - val_accuracy: 0.6407\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.5844 - accuracy: 0.7053 - val_loss: 0.6182 - val_accuracy: 0.6376\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 719us/step - loss: 0.5837 - accuracy: 0.7029 - val_loss: 0.6196 - val_accuracy: 0.6366\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.5814 - accuracy: 0.7066 - val_loss: 0.6099 - val_accuracy: 0.6468\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5791 - accuracy: 0.7092 - val_loss: 0.6115 - val_accuracy: 0.6453\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.5775 - accuracy: 0.7100 - val_loss: 0.6174 - val_accuracy: 0.6362\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.5757 - accuracy: 0.7101 - val_loss: 0.6148 - val_accuracy: 0.6384\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.5752 - accuracy: 0.7087 - val_loss: 0.6125 - val_accuracy: 0.6406\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 708us/step - loss: 0.5732 - accuracy: 0.7127 - val_loss: 0.6151 - val_accuracy: 0.6382\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.5722 - accuracy: 0.7131 - val_loss: 0.6126 - val_accuracy: 0.6409\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.5711 - accuracy: 0.7122 - val_loss: 0.6109 - val_accuracy: 0.6420\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.5687 - accuracy: 0.7162 - val_loss: 0.6086 - val_accuracy: 0.6448\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.5684 - accuracy: 0.7159 - val_loss: 0.6059 - val_accuracy: 0.6474\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.7125 - accuracy: 0.5304 - val_loss: 0.7382 - val_accuracy: 0.3818\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6966 - accuracy: 0.5513 - val_loss: 0.7295 - val_accuracy: 0.4368\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 778us/step - loss: 0.6865 - accuracy: 0.5708 - val_loss: 0.7184 - val_accuracy: 0.4741\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 701us/step - loss: 0.6752 - accuracy: 0.5912 - val_loss: 0.7113 - val_accuracy: 0.5139\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6674 - accuracy: 0.6062 - val_loss: 0.6960 - val_accuracy: 0.5503\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6566 - accuracy: 0.6252 - val_loss: 0.6899 - val_accuracy: 0.5583\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.6521 - accuracy: 0.6356 - val_loss: 0.6820 - val_accuracy: 0.5685\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6449 - accuracy: 0.6463 - val_loss: 0.6760 - val_accuracy: 0.5761\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6398 - accuracy: 0.6533 - val_loss: 0.6739 - val_accuracy: 0.5787\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6357 - accuracy: 0.6599 - val_loss: 0.6610 - val_accuracy: 0.6038\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6302 - accuracy: 0.6666 - val_loss: 0.6657 - val_accuracy: 0.5910\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6253 - accuracy: 0.6704 - val_loss: 0.6574 - val_accuracy: 0.6082\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6217 - accuracy: 0.6742 - val_loss: 0.6607 - val_accuracy: 0.6032\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.6173 - accuracy: 0.6788 - val_loss: 0.6530 - val_accuracy: 0.6182\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6141 - accuracy: 0.6805 - val_loss: 0.6450 - val_accuracy: 0.6324\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6112 - accuracy: 0.6840 - val_loss: 0.6470 - val_accuracy: 0.6288\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6078 - accuracy: 0.6866 - val_loss: 0.6416 - val_accuracy: 0.6387\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6043 - accuracy: 0.6895 - val_loss: 0.6362 - val_accuracy: 0.6446\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6025 - accuracy: 0.6913 - val_loss: 0.6364 - val_accuracy: 0.6428\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5993 - accuracy: 0.6945 - val_loss: 0.6355 - val_accuracy: 0.6427\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5971 - accuracy: 0.6944 - val_loss: 0.6373 - val_accuracy: 0.6416\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5945 - accuracy: 0.6953 - val_loss: 0.6315 - val_accuracy: 0.6451\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5928 - accuracy: 0.6981 - val_loss: 0.6273 - val_accuracy: 0.6474\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.5889 - accuracy: 0.7000 - val_loss: 0.6266 - val_accuracy: 0.6467\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.5879 - accuracy: 0.7000 - val_loss: 0.6212 - val_accuracy: 0.6490\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5845 - accuracy: 0.7033 - val_loss: 0.6311 - val_accuracy: 0.6420\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5832 - accuracy: 0.7026 - val_loss: 0.6210 - val_accuracy: 0.6470\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5818 - accuracy: 0.7041 - val_loss: 0.6180 - val_accuracy: 0.6485\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5792 - accuracy: 0.7067 - val_loss: 0.6248 - val_accuracy: 0.6441\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5781 - accuracy: 0.7069 - val_loss: 0.6236 - val_accuracy: 0.6441\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.5767 - accuracy: 0.7062 - val_loss: 0.6170 - val_accuracy: 0.6488\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5748 - accuracy: 0.7096 - val_loss: 0.6158 - val_accuracy: 0.6491\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5732 - accuracy: 0.7108 - val_loss: 0.6121 - val_accuracy: 0.6532\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5712 - accuracy: 0.7103 - val_loss: 0.6135 - val_accuracy: 0.6518\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5706 - accuracy: 0.7114 - val_loss: 0.6172 - val_accuracy: 0.6490\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5679 - accuracy: 0.7121 - val_loss: 0.6149 - val_accuracy: 0.6510\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.5672 - accuracy: 0.7140 - val_loss: 0.6141 - val_accuracy: 0.6513\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.5648 - accuracy: 0.7165 - val_loss: 0.6097 - val_accuracy: 0.6559\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5648 - accuracy: 0.7150 - val_loss: 0.6150 - val_accuracy: 0.6504\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5632 - accuracy: 0.7151 - val_loss: 0.6131 - val_accuracy: 0.6518\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.5622 - accuracy: 0.7147 - val_loss: 0.6079 - val_accuracy: 0.6575\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.5610 - accuracy: 0.7189 - val_loss: 0.6136 - val_accuracy: 0.6516\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5594 - accuracy: 0.7175 - val_loss: 0.6105 - val_accuracy: 0.6553\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5585 - accuracy: 0.7187 - val_loss: 0.6082 - val_accuracy: 0.6569\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5569 - accuracy: 0.7198 - val_loss: 0.6039 - val_accuracy: 0.6595\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5556 - accuracy: 0.7204 - val_loss: 0.6025 - val_accuracy: 0.6611\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5550 - accuracy: 0.7217 - val_loss: 0.6065 - val_accuracy: 0.6575\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5528 - accuracy: 0.7222 - val_loss: 0.6064 - val_accuracy: 0.6581\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5520 - accuracy: 0.7235 - val_loss: 0.6059 - val_accuracy: 0.6587\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5512 - accuracy: 0.7231 - val_loss: 0.6086 - val_accuracy: 0.6563\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.7058 - accuracy: 0.5051 - val_loss: 0.7311 - val_accuracy: 0.2092\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.7023 - accuracy: 0.5077 - val_loss: 0.7284 - val_accuracy: 0.2321\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.7007 - accuracy: 0.5127 - val_loss: 0.7258 - val_accuracy: 0.2546\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6967 - accuracy: 0.5170 - val_loss: 0.7238 - val_accuracy: 0.2789\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.6950 - accuracy: 0.5211 - val_loss: 0.7199 - val_accuracy: 0.3259\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6925 - accuracy: 0.5268 - val_loss: 0.7184 - val_accuracy: 0.3499\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 820us/step - loss: 0.6909 - accuracy: 0.5360 - val_loss: 0.7176 - val_accuracy: 0.3665\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6885 - accuracy: 0.5378 - val_loss: 0.7187 - val_accuracy: 0.3726\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6865 - accuracy: 0.5438 - val_loss: 0.7159 - val_accuracy: 0.4000\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6847 - accuracy: 0.5483 - val_loss: 0.7128 - val_accuracy: 0.4360\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6834 - accuracy: 0.5514 - val_loss: 0.7118 - val_accuracy: 0.4473\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6811 - accuracy: 0.5567 - val_loss: 0.7089 - val_accuracy: 0.4642\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6800 - accuracy: 0.5642 - val_loss: 0.7083 - val_accuracy: 0.4703\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6775 - accuracy: 0.5667 - val_loss: 0.7064 - val_accuracy: 0.4809\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6775 - accuracy: 0.5689 - val_loss: 0.7062 - val_accuracy: 0.4850\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6753 - accuracy: 0.5771 - val_loss: 0.7024 - val_accuracy: 0.5014\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6729 - accuracy: 0.5818 - val_loss: 0.7013 - val_accuracy: 0.5070\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6715 - accuracy: 0.5844 - val_loss: 0.6993 - val_accuracy: 0.5149\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6709 - accuracy: 0.5869 - val_loss: 0.6970 - val_accuracy: 0.5245\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6686 - accuracy: 0.5923 - val_loss: 0.6957 - val_accuracy: 0.5291\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6676 - accuracy: 0.5942 - val_loss: 0.6943 - val_accuracy: 0.5353\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6658 - accuracy: 0.6000 - val_loss: 0.6942 - val_accuracy: 0.5367\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6638 - accuracy: 0.6060 - val_loss: 0.6915 - val_accuracy: 0.5473\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6628 - accuracy: 0.6071 - val_loss: 0.6902 - val_accuracy: 0.5535\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6616 - accuracy: 0.6086 - val_loss: 0.6884 - val_accuracy: 0.5589\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6590 - accuracy: 0.6130 - val_loss: 0.6854 - val_accuracy: 0.5686\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6582 - accuracy: 0.6137 - val_loss: 0.6843 - val_accuracy: 0.5708\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6567 - accuracy: 0.6190 - val_loss: 0.6823 - val_accuracy: 0.5769\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6546 - accuracy: 0.6217 - val_loss: 0.6837 - val_accuracy: 0.5725\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6537 - accuracy: 0.6219 - val_loss: 0.6818 - val_accuracy: 0.5772\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6521 - accuracy: 0.6242 - val_loss: 0.6815 - val_accuracy: 0.5783\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6494 - accuracy: 0.6271 - val_loss: 0.6787 - val_accuracy: 0.5847\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6487 - accuracy: 0.6301 - val_loss: 0.6760 - val_accuracy: 0.5916\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6475 - accuracy: 0.6293 - val_loss: 0.6751 - val_accuracy: 0.5934\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.6449 - accuracy: 0.6362 - val_loss: 0.6727 - val_accuracy: 0.5987\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6439 - accuracy: 0.6337 - val_loss: 0.6699 - val_accuracy: 0.6041\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6421 - accuracy: 0.6365 - val_loss: 0.6686 - val_accuracy: 0.6065\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6409 - accuracy: 0.6377 - val_loss: 0.6628 - val_accuracy: 0.6174\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6396 - accuracy: 0.6407 - val_loss: 0.6642 - val_accuracy: 0.6131\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6377 - accuracy: 0.6418 - val_loss: 0.6653 - val_accuracy: 0.6109\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6358 - accuracy: 0.6420 - val_loss: 0.6610 - val_accuracy: 0.6185\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6351 - accuracy: 0.6441 - val_loss: 0.6578 - val_accuracy: 0.6240\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6321 - accuracy: 0.6491 - val_loss: 0.6606 - val_accuracy: 0.6172\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6309 - accuracy: 0.6485 - val_loss: 0.6578 - val_accuracy: 0.6215\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6300 - accuracy: 0.6471 - val_loss: 0.6560 - val_accuracy: 0.6235\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.6277 - accuracy: 0.6523 - val_loss: 0.6559 - val_accuracy: 0.6229\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6264 - accuracy: 0.6516 - val_loss: 0.6566 - val_accuracy: 0.6204\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.6249 - accuracy: 0.6560 - val_loss: 0.6520 - val_accuracy: 0.6278\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6237 - accuracy: 0.6548 - val_loss: 0.6500 - val_accuracy: 0.6309\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6227 - accuracy: 0.6549 - val_loss: 0.6507 - val_accuracy: 0.6286\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.7374 - accuracy: 0.4913 - val_loss: 0.7137 - val_accuracy: 0.4141\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.7194 - accuracy: 0.5062 - val_loss: 0.7085 - val_accuracy: 0.4532\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.7096 - accuracy: 0.5197 - val_loss: 0.7051 - val_accuracy: 0.4469\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6992 - accuracy: 0.5306 - val_loss: 0.7002 - val_accuracy: 0.4639\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6912 - accuracy: 0.5438 - val_loss: 0.6978 - val_accuracy: 0.4811\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6853 - accuracy: 0.5533 - val_loss: 0.6937 - val_accuracy: 0.4985\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6798 - accuracy: 0.5651 - val_loss: 0.6916 - val_accuracy: 0.5088\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6737 - accuracy: 0.5757 - val_loss: 0.6896 - val_accuracy: 0.5162\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6690 - accuracy: 0.5842 - val_loss: 0.6789 - val_accuracy: 0.5713\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6654 - accuracy: 0.5922 - val_loss: 0.6724 - val_accuracy: 0.5927\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 708us/step - loss: 0.6587 - accuracy: 0.6078 - val_loss: 0.6689 - val_accuracy: 0.5959\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.6534 - accuracy: 0.6196 - val_loss: 0.6666 - val_accuracy: 0.5964\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6499 - accuracy: 0.6209 - val_loss: 0.6644 - val_accuracy: 0.6033\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 2s 981us/step - loss: 0.6464 - accuracy: 0.6285 - val_loss: 0.6599 - val_accuracy: 0.6132\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 772us/step - loss: 0.6424 - accuracy: 0.6351 - val_loss: 0.6533 - val_accuracy: 0.6236\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6384 - accuracy: 0.6420 - val_loss: 0.6534 - val_accuracy: 0.6220\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.6361 - accuracy: 0.6486 - val_loss: 0.6557 - val_accuracy: 0.6153\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.6310 - accuracy: 0.6546 - val_loss: 0.6527 - val_accuracy: 0.6187\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.6287 - accuracy: 0.6575 - val_loss: 0.6491 - val_accuracy: 0.6250\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.6267 - accuracy: 0.6593 - val_loss: 0.6470 - val_accuracy: 0.6265\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.6238 - accuracy: 0.6658 - val_loss: 0.6393 - val_accuracy: 0.6378\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.6203 - accuracy: 0.6677 - val_loss: 0.6407 - val_accuracy: 0.6326\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6184 - accuracy: 0.6699 - val_loss: 0.6417 - val_accuracy: 0.6300\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.6155 - accuracy: 0.6735 - val_loss: 0.6343 - val_accuracy: 0.6410\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.6131 - accuracy: 0.6774 - val_loss: 0.6407 - val_accuracy: 0.6294\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.6099 - accuracy: 0.6798 - val_loss: 0.6380 - val_accuracy: 0.6321\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6071 - accuracy: 0.6826 - val_loss: 0.6313 - val_accuracy: 0.6417\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6066 - accuracy: 0.6823 - val_loss: 0.6270 - val_accuracy: 0.6462\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6037 - accuracy: 0.6873 - val_loss: 0.6299 - val_accuracy: 0.6415\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6016 - accuracy: 0.6880 - val_loss: 0.6231 - val_accuracy: 0.6472\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.5992 - accuracy: 0.6917 - val_loss: 0.6239 - val_accuracy: 0.6460\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.5982 - accuracy: 0.6915 - val_loss: 0.6165 - val_accuracy: 0.6516\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.5960 - accuracy: 0.6929 - val_loss: 0.6267 - val_accuracy: 0.6404\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 812us/step - loss: 0.5947 - accuracy: 0.6939 - val_loss: 0.6240 - val_accuracy: 0.6437\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.5916 - accuracy: 0.6966 - val_loss: 0.6193 - val_accuracy: 0.6482\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5898 - accuracy: 0.6996 - val_loss: 0.6263 - val_accuracy: 0.6377\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.5884 - accuracy: 0.6994 - val_loss: 0.6174 - val_accuracy: 0.6469\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.5866 - accuracy: 0.7015 - val_loss: 0.6150 - val_accuracy: 0.6501\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.5848 - accuracy: 0.7028 - val_loss: 0.6156 - val_accuracy: 0.6479\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5830 - accuracy: 0.7037 - val_loss: 0.6185 - val_accuracy: 0.6438\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.5827 - accuracy: 0.7046 - val_loss: 0.6193 - val_accuracy: 0.6426\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 719us/step - loss: 0.5805 - accuracy: 0.7055 - val_loss: 0.6145 - val_accuracy: 0.6487\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.5782 - accuracy: 0.7071 - val_loss: 0.6135 - val_accuracy: 0.6493\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.5768 - accuracy: 0.7082 - val_loss: 0.6150 - val_accuracy: 0.6471\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.5755 - accuracy: 0.7090 - val_loss: 0.6080 - val_accuracy: 0.6543\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.5737 - accuracy: 0.7113 - val_loss: 0.6043 - val_accuracy: 0.6565\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.5718 - accuracy: 0.7140 - val_loss: 0.6136 - val_accuracy: 0.6470\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.5709 - accuracy: 0.7146 - val_loss: 0.6134 - val_accuracy: 0.6475\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.5689 - accuracy: 0.7157 - val_loss: 0.6080 - val_accuracy: 0.6524\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.5673 - accuracy: 0.7155 - val_loss: 0.6108 - val_accuracy: 0.6490\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6808 - accuracy: 0.5746 - val_loss: 0.6878 - val_accuracy: 0.5488\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.6709 - accuracy: 0.5987 - val_loss: 0.6877 - val_accuracy: 0.5523\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6648 - accuracy: 0.6097 - val_loss: 0.6854 - val_accuracy: 0.5593\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 813us/step - loss: 0.6589 - accuracy: 0.6223 - val_loss: 0.6789 - val_accuracy: 0.5765\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.6546 - accuracy: 0.6337 - val_loss: 0.6773 - val_accuracy: 0.5797\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.6522 - accuracy: 0.6347 - val_loss: 0.6762 - val_accuracy: 0.5803\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.6487 - accuracy: 0.6443 - val_loss: 0.6739 - val_accuracy: 0.5848\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.6458 - accuracy: 0.6451 - val_loss: 0.6680 - val_accuracy: 0.5966\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6424 - accuracy: 0.6531 - val_loss: 0.6661 - val_accuracy: 0.5980\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.6388 - accuracy: 0.6597 - val_loss: 0.6628 - val_accuracy: 0.6029\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.6367 - accuracy: 0.6599 - val_loss: 0.6628 - val_accuracy: 0.6001\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6336 - accuracy: 0.6654 - val_loss: 0.6583 - val_accuracy: 0.6072\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 823us/step - loss: 0.6311 - accuracy: 0.6655 - val_loss: 0.6578 - val_accuracy: 0.6061\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.6280 - accuracy: 0.6719 - val_loss: 0.6565 - val_accuracy: 0.6077\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6257 - accuracy: 0.6713 - val_loss: 0.6544 - val_accuracy: 0.6102\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.6232 - accuracy: 0.6746 - val_loss: 0.6498 - val_accuracy: 0.6153\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 778us/step - loss: 0.6220 - accuracy: 0.6746 - val_loss: 0.6489 - val_accuracy: 0.6146\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 701us/step - loss: 0.6189 - accuracy: 0.6776 - val_loss: 0.6488 - val_accuracy: 0.6117\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 822us/step - loss: 0.6171 - accuracy: 0.6786 - val_loss: 0.6450 - val_accuracy: 0.6173\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 772us/step - loss: 0.6150 - accuracy: 0.6813 - val_loss: 0.6446 - val_accuracy: 0.6157\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.6118 - accuracy: 0.6825 - val_loss: 0.6426 - val_accuracy: 0.6176\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.6106 - accuracy: 0.6823 - val_loss: 0.6419 - val_accuracy: 0.6173\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6083 - accuracy: 0.6866 - val_loss: 0.6368 - val_accuracy: 0.6255\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.6064 - accuracy: 0.6870 - val_loss: 0.6358 - val_accuracy: 0.6263\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.6036 - accuracy: 0.6915 - val_loss: 0.6390 - val_accuracy: 0.6201\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.6026 - accuracy: 0.6887 - val_loss: 0.6380 - val_accuracy: 0.6218\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.5998 - accuracy: 0.6932 - val_loss: 0.6338 - val_accuracy: 0.6265\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.5986 - accuracy: 0.6924 - val_loss: 0.6360 - val_accuracy: 0.6232\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.5958 - accuracy: 0.6954 - val_loss: 0.6284 - val_accuracy: 0.6304\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.5941 - accuracy: 0.6954 - val_loss: 0.6257 - val_accuracy: 0.6324\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5930 - accuracy: 0.6968 - val_loss: 0.6303 - val_accuracy: 0.6273\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5903 - accuracy: 0.6979 - val_loss: 0.6246 - val_accuracy: 0.6329\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5883 - accuracy: 0.6992 - val_loss: 0.6260 - val_accuracy: 0.6295\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5882 - accuracy: 0.6986 - val_loss: 0.6193 - val_accuracy: 0.6378\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5853 - accuracy: 0.7026 - val_loss: 0.6259 - val_accuracy: 0.6287\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.5839 - accuracy: 0.7016 - val_loss: 0.6222 - val_accuracy: 0.6322\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5823 - accuracy: 0.7048 - val_loss: 0.6176 - val_accuracy: 0.6383\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5802 - accuracy: 0.7056 - val_loss: 0.6198 - val_accuracy: 0.6345\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5785 - accuracy: 0.7056 - val_loss: 0.6165 - val_accuracy: 0.6364\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5764 - accuracy: 0.7073 - val_loss: 0.6205 - val_accuracy: 0.6321\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5741 - accuracy: 0.7096 - val_loss: 0.6232 - val_accuracy: 0.6300\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5730 - accuracy: 0.7109 - val_loss: 0.6133 - val_accuracy: 0.6378\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5716 - accuracy: 0.7114 - val_loss: 0.6171 - val_accuracy: 0.6342\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5697 - accuracy: 0.7126 - val_loss: 0.6158 - val_accuracy: 0.6349\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5680 - accuracy: 0.7135 - val_loss: 0.6161 - val_accuracy: 0.6354\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5669 - accuracy: 0.7140 - val_loss: 0.6045 - val_accuracy: 0.6476\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.5653 - accuracy: 0.7140 - val_loss: 0.6094 - val_accuracy: 0.6412\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5632 - accuracy: 0.7164 - val_loss: 0.6120 - val_accuracy: 0.6382\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5617 - accuracy: 0.7171 - val_loss: 0.6148 - val_accuracy: 0.6352\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5606 - accuracy: 0.7177 - val_loss: 0.6115 - val_accuracy: 0.6382\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.7487 - accuracy: 0.5192 - val_loss: 0.7645 - val_accuracy: 0.2600\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6921 - accuracy: 0.5220 - val_loss: 0.7077 - val_accuracy: 0.4543\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6876 - accuracy: 0.5345 - val_loss: 0.7026 - val_accuracy: 0.4830\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6829 - accuracy: 0.5430 - val_loss: 0.6950 - val_accuracy: 0.5165\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6795 - accuracy: 0.5516 - val_loss: 0.6912 - val_accuracy: 0.5396\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6758 - accuracy: 0.5652 - val_loss: 0.6880 - val_accuracy: 0.5504\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6720 - accuracy: 0.5724 - val_loss: 0.6900 - val_accuracy: 0.5416\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.6689 - accuracy: 0.5770 - val_loss: 0.6857 - val_accuracy: 0.5541\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6647 - accuracy: 0.5876 - val_loss: 0.6793 - val_accuracy: 0.5710\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 788us/step - loss: 0.6625 - accuracy: 0.5947 - val_loss: 0.6778 - val_accuracy: 0.5732\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6589 - accuracy: 0.6002 - val_loss: 0.6773 - val_accuracy: 0.5747\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 807us/step - loss: 0.6557 - accuracy: 0.6046 - val_loss: 0.6737 - val_accuracy: 0.5822\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.6522 - accuracy: 0.6132 - val_loss: 0.6729 - val_accuracy: 0.5820\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.6504 - accuracy: 0.6170 - val_loss: 0.6673 - val_accuracy: 0.5911\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6464 - accuracy: 0.6207 - val_loss: 0.6663 - val_accuracy: 0.5912\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6438 - accuracy: 0.6273 - val_loss: 0.6594 - val_accuracy: 0.6051\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6407 - accuracy: 0.6288 - val_loss: 0.6568 - val_accuracy: 0.6068\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6380 - accuracy: 0.6327 - val_loss: 0.6565 - val_accuracy: 0.6059\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6364 - accuracy: 0.6341 - val_loss: 0.6559 - val_accuracy: 0.6050\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6328 - accuracy: 0.6398 - val_loss: 0.6509 - val_accuracy: 0.6132\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6306 - accuracy: 0.6425 - val_loss: 0.6496 - val_accuracy: 0.6124\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6285 - accuracy: 0.6450 - val_loss: 0.6529 - val_accuracy: 0.6052\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6256 - accuracy: 0.6495 - val_loss: 0.6447 - val_accuracy: 0.6157\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6223 - accuracy: 0.6537 - val_loss: 0.6426 - val_accuracy: 0.6169\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6202 - accuracy: 0.6539 - val_loss: 0.6432 - val_accuracy: 0.6152\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.6180 - accuracy: 0.6566 - val_loss: 0.6433 - val_accuracy: 0.6135\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6162 - accuracy: 0.6578 - val_loss: 0.6387 - val_accuracy: 0.6190\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6137 - accuracy: 0.6586 - val_loss: 0.6397 - val_accuracy: 0.6166\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6121 - accuracy: 0.6639 - val_loss: 0.6371 - val_accuracy: 0.6193\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6100 - accuracy: 0.6663 - val_loss: 0.6350 - val_accuracy: 0.6214\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6076 - accuracy: 0.6702 - val_loss: 0.6313 - val_accuracy: 0.6267\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6058 - accuracy: 0.6691 - val_loss: 0.6365 - val_accuracy: 0.6173\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6052 - accuracy: 0.6709 - val_loss: 0.6335 - val_accuracy: 0.6226\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6022 - accuracy: 0.6726 - val_loss: 0.6308 - val_accuracy: 0.6247\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6003 - accuracy: 0.6788 - val_loss: 0.6301 - val_accuracy: 0.6251\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5985 - accuracy: 0.6790 - val_loss: 0.6235 - val_accuracy: 0.6314\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5964 - accuracy: 0.6816 - val_loss: 0.6260 - val_accuracy: 0.6283\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.5947 - accuracy: 0.6812 - val_loss: 0.6245 - val_accuracy: 0.6291\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5934 - accuracy: 0.6826 - val_loss: 0.6326 - val_accuracy: 0.6189\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.5919 - accuracy: 0.6839 - val_loss: 0.6194 - val_accuracy: 0.6345\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5904 - accuracy: 0.6866 - val_loss: 0.6193 - val_accuracy: 0.6352\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5884 - accuracy: 0.6884 - val_loss: 0.6266 - val_accuracy: 0.6263\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5874 - accuracy: 0.6880 - val_loss: 0.6238 - val_accuracy: 0.6293\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5862 - accuracy: 0.6905 - val_loss: 0.6248 - val_accuracy: 0.6278\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5845 - accuracy: 0.6901 - val_loss: 0.6239 - val_accuracy: 0.6289\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5838 - accuracy: 0.6911 - val_loss: 0.6149 - val_accuracy: 0.6402\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5804 - accuracy: 0.6942 - val_loss: 0.6274 - val_accuracy: 0.6241\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5799 - accuracy: 0.6953 - val_loss: 0.6134 - val_accuracy: 0.6423\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.5790 - accuracy: 0.6951 - val_loss: 0.6150 - val_accuracy: 0.6376\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5778 - accuracy: 0.6975 - val_loss: 0.6183 - val_accuracy: 0.6328\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.7060 - accuracy: 0.5216 - val_loss: 0.6898 - val_accuracy: 0.5288\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6891 - accuracy: 0.5440 - val_loss: 0.6989 - val_accuracy: 0.5049\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6831 - accuracy: 0.5565 - val_loss: 0.6967 - val_accuracy: 0.5124\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6788 - accuracy: 0.5673 - val_loss: 0.6901 - val_accuracy: 0.5326\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6750 - accuracy: 0.5739 - val_loss: 0.6821 - val_accuracy: 0.5614\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6699 - accuracy: 0.5815 - val_loss: 0.6786 - val_accuracy: 0.5725\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6654 - accuracy: 0.5924 - val_loss: 0.6773 - val_accuracy: 0.5781\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6620 - accuracy: 0.6002 - val_loss: 0.6760 - val_accuracy: 0.5835\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6577 - accuracy: 0.6083 - val_loss: 0.6714 - val_accuracy: 0.5957\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6550 - accuracy: 0.6149 - val_loss: 0.6681 - val_accuracy: 0.6023\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6513 - accuracy: 0.6199 - val_loss: 0.6664 - val_accuracy: 0.6061\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6479 - accuracy: 0.6277 - val_loss: 0.6625 - val_accuracy: 0.6134\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6453 - accuracy: 0.6330 - val_loss: 0.6661 - val_accuracy: 0.6059\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6425 - accuracy: 0.6354 - val_loss: 0.6610 - val_accuracy: 0.6156\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6393 - accuracy: 0.6404 - val_loss: 0.6593 - val_accuracy: 0.6193\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6371 - accuracy: 0.6430 - val_loss: 0.6559 - val_accuracy: 0.6242\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6354 - accuracy: 0.6475 - val_loss: 0.6503 - val_accuracy: 0.6326\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6324 - accuracy: 0.6530 - val_loss: 0.6462 - val_accuracy: 0.6382\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6300 - accuracy: 0.6558 - val_loss: 0.6473 - val_accuracy: 0.6351\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6266 - accuracy: 0.6586 - val_loss: 0.6515 - val_accuracy: 0.6283\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6252 - accuracy: 0.6620 - val_loss: 0.6478 - val_accuracy: 0.6321\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6226 - accuracy: 0.6651 - val_loss: 0.6437 - val_accuracy: 0.6356\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6188 - accuracy: 0.6704 - val_loss: 0.6413 - val_accuracy: 0.6362\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6178 - accuracy: 0.6704 - val_loss: 0.6453 - val_accuracy: 0.6311\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6161 - accuracy: 0.6722 - val_loss: 0.6368 - val_accuracy: 0.6410\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 893us/step - loss: 0.6145 - accuracy: 0.6755 - val_loss: 0.6365 - val_accuracy: 0.6402\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6109 - accuracy: 0.6799 - val_loss: 0.6423 - val_accuracy: 0.6309\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6086 - accuracy: 0.6831 - val_loss: 0.6303 - val_accuracy: 0.6450\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.6054 - accuracy: 0.6878 - val_loss: 0.6318 - val_accuracy: 0.6414\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6041 - accuracy: 0.6871 - val_loss: 0.6328 - val_accuracy: 0.6394\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.6015 - accuracy: 0.6899 - val_loss: 0.6343 - val_accuracy: 0.6374\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.5996 - accuracy: 0.6921 - val_loss: 0.6336 - val_accuracy: 0.6370\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.5972 - accuracy: 0.6951 - val_loss: 0.6375 - val_accuracy: 0.6305\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.5954 - accuracy: 0.6958 - val_loss: 0.6246 - val_accuracy: 0.6419\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.5931 - accuracy: 0.6981 - val_loss: 0.6212 - val_accuracy: 0.6440\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 800us/step - loss: 0.5914 - accuracy: 0.7004 - val_loss: 0.6175 - val_accuracy: 0.6471\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.5906 - accuracy: 0.7007 - val_loss: 0.6203 - val_accuracy: 0.6446\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.5883 - accuracy: 0.7025 - val_loss: 0.6191 - val_accuracy: 0.6446\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.5867 - accuracy: 0.7040 - val_loss: 0.6132 - val_accuracy: 0.6512\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.5851 - accuracy: 0.7064 - val_loss: 0.6245 - val_accuracy: 0.6382\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.5840 - accuracy: 0.7065 - val_loss: 0.6133 - val_accuracy: 0.6517\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5810 - accuracy: 0.7101 - val_loss: 0.6196 - val_accuracy: 0.6436\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.5792 - accuracy: 0.7093 - val_loss: 0.6162 - val_accuracy: 0.6472\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.5778 - accuracy: 0.7110 - val_loss: 0.6155 - val_accuracy: 0.6487\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.5767 - accuracy: 0.7132 - val_loss: 0.6187 - val_accuracy: 0.6459\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.5737 - accuracy: 0.7141 - val_loss: 0.6163 - val_accuracy: 0.6469\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.5731 - accuracy: 0.7165 - val_loss: 0.6102 - val_accuracy: 0.6522\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.5726 - accuracy: 0.7142 - val_loss: 0.6122 - val_accuracy: 0.6503\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.5720 - accuracy: 0.7149 - val_loss: 0.6173 - val_accuracy: 0.6465\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.5681 - accuracy: 0.7199 - val_loss: 0.6084 - val_accuracy: 0.6527\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.7102 - accuracy: 0.4988 - val_loss: 0.7298 - val_accuracy: 0.2932\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.6997 - accuracy: 0.5195 - val_loss: 0.7215 - val_accuracy: 0.3626\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.6927 - accuracy: 0.5392 - val_loss: 0.7164 - val_accuracy: 0.4073\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 854us/step - loss: 0.6869 - accuracy: 0.5543 - val_loss: 0.7107 - val_accuracy: 0.4575\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6811 - accuracy: 0.5695 - val_loss: 0.7020 - val_accuracy: 0.5109\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.6763 - accuracy: 0.5824 - val_loss: 0.6972 - val_accuracy: 0.5386\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6700 - accuracy: 0.5954 - val_loss: 0.6917 - val_accuracy: 0.5581\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.6649 - accuracy: 0.6092 - val_loss: 0.6847 - val_accuracy: 0.5823\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.6601 - accuracy: 0.6185 - val_loss: 0.6816 - val_accuracy: 0.5882\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6549 - accuracy: 0.6316 - val_loss: 0.6733 - val_accuracy: 0.6058\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6513 - accuracy: 0.6370 - val_loss: 0.6729 - val_accuracy: 0.6042\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 792us/step - loss: 0.6458 - accuracy: 0.6476 - val_loss: 0.6716 - val_accuracy: 0.6039\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.6413 - accuracy: 0.6556 - val_loss: 0.6598 - val_accuracy: 0.6258\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.6378 - accuracy: 0.6578 - val_loss: 0.6586 - val_accuracy: 0.6236\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 753us/step - loss: 0.6340 - accuracy: 0.6649 - val_loss: 0.6572 - val_accuracy: 0.6250\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.6295 - accuracy: 0.6695 - val_loss: 0.6494 - val_accuracy: 0.6374\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 719us/step - loss: 0.6274 - accuracy: 0.6722 - val_loss: 0.6512 - val_accuracy: 0.6331\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 796us/step - loss: 0.6247 - accuracy: 0.6733 - val_loss: 0.6495 - val_accuracy: 0.6339\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 895us/step - loss: 0.6215 - accuracy: 0.6792 - val_loss: 0.6485 - val_accuracy: 0.6335\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 867us/step - loss: 0.6185 - accuracy: 0.6810 - val_loss: 0.6407 - val_accuracy: 0.6428\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.6159 - accuracy: 0.6828 - val_loss: 0.6383 - val_accuracy: 0.6462\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6131 - accuracy: 0.6876 - val_loss: 0.6428 - val_accuracy: 0.6361\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6107 - accuracy: 0.6893 - val_loss: 0.6362 - val_accuracy: 0.6456\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.6087 - accuracy: 0.6910 - val_loss: 0.6360 - val_accuracy: 0.6454\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.6067 - accuracy: 0.6891 - val_loss: 0.6309 - val_accuracy: 0.6530\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 847us/step - loss: 0.6038 - accuracy: 0.6933 - val_loss: 0.6336 - val_accuracy: 0.6474\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6019 - accuracy: 0.6943 - val_loss: 0.6228 - val_accuracy: 0.6637\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.5992 - accuracy: 0.6963 - val_loss: 0.6343 - val_accuracy: 0.6429\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5976 - accuracy: 0.6964 - val_loss: 0.6194 - val_accuracy: 0.6652\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.5953 - accuracy: 0.6996 - val_loss: 0.6221 - val_accuracy: 0.6597\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.5932 - accuracy: 0.7004 - val_loss: 0.6233 - val_accuracy: 0.6573\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.5917 - accuracy: 0.7030 - val_loss: 0.6190 - val_accuracy: 0.6613\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5888 - accuracy: 0.7046 - val_loss: 0.6147 - val_accuracy: 0.6640\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5880 - accuracy: 0.7043 - val_loss: 0.6201 - val_accuracy: 0.6571\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.5863 - accuracy: 0.7037 - val_loss: 0.6105 - val_accuracy: 0.6685\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.5835 - accuracy: 0.7080 - val_loss: 0.6084 - val_accuracy: 0.6692\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.5821 - accuracy: 0.7087 - val_loss: 0.6105 - val_accuracy: 0.6656\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.5807 - accuracy: 0.7089 - val_loss: 0.6168 - val_accuracy: 0.6555\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.5799 - accuracy: 0.7091 - val_loss: 0.6160 - val_accuracy: 0.6548\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.5780 - accuracy: 0.7108 - val_loss: 0.6124 - val_accuracy: 0.6584\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.5774 - accuracy: 0.7098 - val_loss: 0.6156 - val_accuracy: 0.6527\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.5757 - accuracy: 0.7123 - val_loss: 0.6081 - val_accuracy: 0.6611\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.5739 - accuracy: 0.7138 - val_loss: 0.6098 - val_accuracy: 0.6586\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5715 - accuracy: 0.7145 - val_loss: 0.6078 - val_accuracy: 0.6598\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5700 - accuracy: 0.7166 - val_loss: 0.6080 - val_accuracy: 0.6603\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5694 - accuracy: 0.7165 - val_loss: 0.6054 - val_accuracy: 0.6624\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 742us/step - loss: 0.5676 - accuracy: 0.7166 - val_loss: 0.6060 - val_accuracy: 0.6622\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.5668 - accuracy: 0.7166 - val_loss: 0.6062 - val_accuracy: 0.6624\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.5642 - accuracy: 0.7190 - val_loss: 0.6029 - val_accuracy: 0.6650\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5642 - accuracy: 0.7177 - val_loss: 0.6083 - val_accuracy: 0.6605\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6966 - accuracy: 0.5270 - val_loss: 0.7020 - val_accuracy: 0.4576\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.6888 - accuracy: 0.5486 - val_loss: 0.7098 - val_accuracy: 0.4312\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6841 - accuracy: 0.5611 - val_loss: 0.7094 - val_accuracy: 0.4453\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6798 - accuracy: 0.5740 - val_loss: 0.7037 - val_accuracy: 0.5134\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6760 - accuracy: 0.5867 - val_loss: 0.6989 - val_accuracy: 0.5392\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6728 - accuracy: 0.5963 - val_loss: 0.6977 - val_accuracy: 0.5411\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6690 - accuracy: 0.6046 - val_loss: 0.6969 - val_accuracy: 0.5440\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6653 - accuracy: 0.6150 - val_loss: 0.6933 - val_accuracy: 0.5529\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6613 - accuracy: 0.6231 - val_loss: 0.6888 - val_accuracy: 0.5635\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6582 - accuracy: 0.6286 - val_loss: 0.6869 - val_accuracy: 0.5661\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6559 - accuracy: 0.6333 - val_loss: 0.6850 - val_accuracy: 0.5707\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.6543 - accuracy: 0.6319 - val_loss: 0.6791 - val_accuracy: 0.5835\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6502 - accuracy: 0.6423 - val_loss: 0.6755 - val_accuracy: 0.5915\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6468 - accuracy: 0.6462 - val_loss: 0.6744 - val_accuracy: 0.5943\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6445 - accuracy: 0.6506 - val_loss: 0.6715 - val_accuracy: 0.5986\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6430 - accuracy: 0.6519 - val_loss: 0.6709 - val_accuracy: 0.6001\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6393 - accuracy: 0.6581 - val_loss: 0.6713 - val_accuracy: 0.5985\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6365 - accuracy: 0.6583 - val_loss: 0.6618 - val_accuracy: 0.6123\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6342 - accuracy: 0.6603 - val_loss: 0.6636 - val_accuracy: 0.6094\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6311 - accuracy: 0.6654 - val_loss: 0.6624 - val_accuracy: 0.6102\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6281 - accuracy: 0.6675 - val_loss: 0.6611 - val_accuracy: 0.6115\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6257 - accuracy: 0.6703 - val_loss: 0.6587 - val_accuracy: 0.6128\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6238 - accuracy: 0.6708 - val_loss: 0.6579 - val_accuracy: 0.6135\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6217 - accuracy: 0.6718 - val_loss: 0.6539 - val_accuracy: 0.6185\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6198 - accuracy: 0.6740 - val_loss: 0.6553 - val_accuracy: 0.6165\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6178 - accuracy: 0.6753 - val_loss: 0.6447 - val_accuracy: 0.6323\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6143 - accuracy: 0.6784 - val_loss: 0.6467 - val_accuracy: 0.6282\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6127 - accuracy: 0.6800 - val_loss: 0.6447 - val_accuracy: 0.6308\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.6114 - accuracy: 0.6799 - val_loss: 0.6465 - val_accuracy: 0.6272\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6096 - accuracy: 0.6819 - val_loss: 0.6453 - val_accuracy: 0.6297\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6071 - accuracy: 0.6835 - val_loss: 0.6417 - val_accuracy: 0.6333\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6061 - accuracy: 0.6834 - val_loss: 0.6450 - val_accuracy: 0.6295\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6035 - accuracy: 0.6853 - val_loss: 0.6430 - val_accuracy: 0.6322\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6016 - accuracy: 0.6879 - val_loss: 0.6405 - val_accuracy: 0.6351\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6002 - accuracy: 0.6866 - val_loss: 0.6330 - val_accuracy: 0.6437\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5986 - accuracy: 0.6877 - val_loss: 0.6337 - val_accuracy: 0.6424\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.5964 - accuracy: 0.6916 - val_loss: 0.6303 - val_accuracy: 0.6467\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.5955 - accuracy: 0.6901 - val_loss: 0.6320 - val_accuracy: 0.6435\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5933 - accuracy: 0.6923 - val_loss: 0.6327 - val_accuracy: 0.6419\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5926 - accuracy: 0.6915 - val_loss: 0.6311 - val_accuracy: 0.6436\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5907 - accuracy: 0.6944 - val_loss: 0.6281 - val_accuracy: 0.6501\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5888 - accuracy: 0.6963 - val_loss: 0.6249 - val_accuracy: 0.6548\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.5873 - accuracy: 0.6976 - val_loss: 0.6288 - val_accuracy: 0.6479\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.5856 - accuracy: 0.6976 - val_loss: 0.6355 - val_accuracy: 0.6345\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5845 - accuracy: 0.6990 - val_loss: 0.6279 - val_accuracy: 0.6493\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5830 - accuracy: 0.6996 - val_loss: 0.6229 - val_accuracy: 0.6571\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5820 - accuracy: 0.7004 - val_loss: 0.6216 - val_accuracy: 0.6604\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.5800 - accuracy: 0.7010 - val_loss: 0.6288 - val_accuracy: 0.6490\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5787 - accuracy: 0.7035 - val_loss: 0.6197 - val_accuracy: 0.6628\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5764 - accuracy: 0.7055 - val_loss: 0.6219 - val_accuracy: 0.6600\n",
      "\n",
      "Training model with batch_size=32, target_eps=1.0...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 5.05 iterated over 83600 steps satisfies differential privacy with eps = 0.167 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.5749999999999997 iterated over 83600 steps satisfies differential privacy with eps = 0.34 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.3375 iterated over 83600 steps satisfies differential privacy with eps = 0.763 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.71875 iterated over 83600 steps satisfies differential privacy with eps = 2.77 and delta = 1e-05.\n",
      "The optimal RDP order is 7.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.028125 iterated over 83600 steps satisfies differential privacy with eps = 1.22 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1828124999999998 iterated over 83600 steps satisfies differential privacy with eps = 0.938 and delta = 1e-05.\n",
      "The optimal RDP order is 20.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.10546875 iterated over 83600 steps satisfies differential privacy with eps = 1.05 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.144140625 iterated over 83600 steps satisfies differential privacy with eps = 0.991 and delta = 1e-05.\n",
      "The optimal RDP order is 18.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.7195 - accuracy: 0.4835 - val_loss: 0.6835 - val_accuracy: 0.5642\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.7004 - accuracy: 0.5029 - val_loss: 0.7124 - val_accuracy: 0.3262\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6952 - accuracy: 0.5186 - val_loss: 0.7108 - val_accuracy: 0.3432\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6913 - accuracy: 0.5304 - val_loss: 0.7075 - val_accuracy: 0.3874\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6875 - accuracy: 0.5405 - val_loss: 0.7038 - val_accuracy: 0.4449\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6853 - accuracy: 0.5521 - val_loss: 0.7025 - val_accuracy: 0.4746\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6818 - accuracy: 0.5644 - val_loss: 0.6994 - val_accuracy: 0.4994\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6781 - accuracy: 0.5793 - val_loss: 0.6967 - val_accuracy: 0.5123\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6764 - accuracy: 0.5821 - val_loss: 0.6944 - val_accuracy: 0.5225\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.6725 - accuracy: 0.5963 - val_loss: 0.6896 - val_accuracy: 0.5456\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6699 - accuracy: 0.6063 - val_loss: 0.6884 - val_accuracy: 0.5529\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6669 - accuracy: 0.6151 - val_loss: 0.6868 - val_accuracy: 0.5622\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6648 - accuracy: 0.6216 - val_loss: 0.6828 - val_accuracy: 0.5847\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.6627 - accuracy: 0.6272 - val_loss: 0.6806 - val_accuracy: 0.5949\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 699us/step - loss: 0.6597 - accuracy: 0.6340 - val_loss: 0.6789 - val_accuracy: 0.5971\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6578 - accuracy: 0.6351 - val_loss: 0.6742 - val_accuracy: 0.6125\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6550 - accuracy: 0.6467 - val_loss: 0.6734 - val_accuracy: 0.6134\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6522 - accuracy: 0.6486 - val_loss: 0.6703 - val_accuracy: 0.6198\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6502 - accuracy: 0.6557 - val_loss: 0.6696 - val_accuracy: 0.6179\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6477 - accuracy: 0.6564 - val_loss: 0.6676 - val_accuracy: 0.6205\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6450 - accuracy: 0.6607 - val_loss: 0.6648 - val_accuracy: 0.6258\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6423 - accuracy: 0.6640 - val_loss: 0.6606 - val_accuracy: 0.6340\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6394 - accuracy: 0.6691 - val_loss: 0.6589 - val_accuracy: 0.6364\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6374 - accuracy: 0.6713 - val_loss: 0.6562 - val_accuracy: 0.6401\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6352 - accuracy: 0.6722 - val_loss: 0.6539 - val_accuracy: 0.6434\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.6326 - accuracy: 0.6766 - val_loss: 0.6511 - val_accuracy: 0.6454\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6298 - accuracy: 0.6808 - val_loss: 0.6459 - val_accuracy: 0.6540\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6274 - accuracy: 0.6794 - val_loss: 0.6433 - val_accuracy: 0.6555\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6244 - accuracy: 0.6845 - val_loss: 0.6431 - val_accuracy: 0.6520\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6223 - accuracy: 0.6868 - val_loss: 0.6385 - val_accuracy: 0.6579\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6201 - accuracy: 0.6882 - val_loss: 0.6360 - val_accuracy: 0.6594\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.6175 - accuracy: 0.6889 - val_loss: 0.6331 - val_accuracy: 0.6606\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6141 - accuracy: 0.6938 - val_loss: 0.6317 - val_accuracy: 0.6600\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6125 - accuracy: 0.6950 - val_loss: 0.6304 - val_accuracy: 0.6580\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6098 - accuracy: 0.6945 - val_loss: 0.6265 - val_accuracy: 0.6595\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6079 - accuracy: 0.6979 - val_loss: 0.6210 - val_accuracy: 0.6670\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 805us/step - loss: 0.6046 - accuracy: 0.6999 - val_loss: 0.6244 - val_accuracy: 0.6586\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 854us/step - loss: 0.6036 - accuracy: 0.6997 - val_loss: 0.6256 - val_accuracy: 0.6542\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 816us/step - loss: 0.6012 - accuracy: 0.7028 - val_loss: 0.6224 - val_accuracy: 0.6566\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.5994 - accuracy: 0.7018 - val_loss: 0.6167 - val_accuracy: 0.6637\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.5980 - accuracy: 0.7038 - val_loss: 0.6165 - val_accuracy: 0.6619\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.5952 - accuracy: 0.7044 - val_loss: 0.6138 - val_accuracy: 0.6639\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.5934 - accuracy: 0.7068 - val_loss: 0.6182 - val_accuracy: 0.6553\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5922 - accuracy: 0.7073 - val_loss: 0.6175 - val_accuracy: 0.6554\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.5902 - accuracy: 0.7067 - val_loss: 0.6101 - val_accuracy: 0.6638\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.5881 - accuracy: 0.7092 - val_loss: 0.6123 - val_accuracy: 0.6587\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.5864 - accuracy: 0.7089 - val_loss: 0.6069 - val_accuracy: 0.6646\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 831us/step - loss: 0.5845 - accuracy: 0.7109 - val_loss: 0.6069 - val_accuracy: 0.6624\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.5838 - accuracy: 0.7094 - val_loss: 0.6056 - val_accuracy: 0.6628\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.5807 - accuracy: 0.7136 - val_loss: 0.6082 - val_accuracy: 0.6590\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 824us/step - loss: 0.7062 - accuracy: 0.5241 - val_loss: 0.7050 - val_accuracy: 0.4709\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.6898 - accuracy: 0.5491 - val_loss: 0.7162 - val_accuracy: 0.4360\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.6857 - accuracy: 0.5639 - val_loss: 0.7117 - val_accuracy: 0.4544\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6821 - accuracy: 0.5702 - val_loss: 0.7101 - val_accuracy: 0.4646\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.6770 - accuracy: 0.5863 - val_loss: 0.7077 - val_accuracy: 0.4813\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6731 - accuracy: 0.5984 - val_loss: 0.7017 - val_accuracy: 0.5150\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6690 - accuracy: 0.6058 - val_loss: 0.6981 - val_accuracy: 0.5331\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6658 - accuracy: 0.6151 - val_loss: 0.6892 - val_accuracy: 0.5583\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6612 - accuracy: 0.6238 - val_loss: 0.6929 - val_accuracy: 0.5520\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.6577 - accuracy: 0.6327 - val_loss: 0.6847 - val_accuracy: 0.5655\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.6558 - accuracy: 0.6365 - val_loss: 0.6865 - val_accuracy: 0.5620\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6532 - accuracy: 0.6422 - val_loss: 0.6831 - val_accuracy: 0.5683\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.6522 - accuracy: 0.6443 - val_loss: 0.6785 - val_accuracy: 0.5753\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.6493 - accuracy: 0.6477 - val_loss: 0.6761 - val_accuracy: 0.5792\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 829us/step - loss: 0.6474 - accuracy: 0.6520 - val_loss: 0.6773 - val_accuracy: 0.5771\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.6442 - accuracy: 0.6558 - val_loss: 0.6765 - val_accuracy: 0.5782\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.6422 - accuracy: 0.6572 - val_loss: 0.6717 - val_accuracy: 0.5856\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6404 - accuracy: 0.6608 - val_loss: 0.6682 - val_accuracy: 0.5914\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.6375 - accuracy: 0.6648 - val_loss: 0.6643 - val_accuracy: 0.5991\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6362 - accuracy: 0.6661 - val_loss: 0.6676 - val_accuracy: 0.5917\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6339 - accuracy: 0.6690 - val_loss: 0.6602 - val_accuracy: 0.6054\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6323 - accuracy: 0.6697 - val_loss: 0.6616 - val_accuracy: 0.6035\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 736us/step - loss: 0.6308 - accuracy: 0.6700 - val_loss: 0.6540 - val_accuracy: 0.6113\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.6279 - accuracy: 0.6736 - val_loss: 0.6560 - val_accuracy: 0.6104\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6256 - accuracy: 0.6760 - val_loss: 0.6618 - val_accuracy: 0.6030\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.6246 - accuracy: 0.6763 - val_loss: 0.6575 - val_accuracy: 0.6094\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6216 - accuracy: 0.6776 - val_loss: 0.6528 - val_accuracy: 0.6134\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.6201 - accuracy: 0.6811 - val_loss: 0.6503 - val_accuracy: 0.6183\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.6181 - accuracy: 0.6817 - val_loss: 0.6495 - val_accuracy: 0.6194\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 805us/step - loss: 0.6160 - accuracy: 0.6822 - val_loss: 0.6471 - val_accuracy: 0.6234\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.6149 - accuracy: 0.6856 - val_loss: 0.6463 - val_accuracy: 0.6248\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6133 - accuracy: 0.6848 - val_loss: 0.6437 - val_accuracy: 0.6283\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6117 - accuracy: 0.6874 - val_loss: 0.6442 - val_accuracy: 0.6273\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 742us/step - loss: 0.6105 - accuracy: 0.6855 - val_loss: 0.6430 - val_accuracy: 0.6289\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.6066 - accuracy: 0.6902 - val_loss: 0.6375 - val_accuracy: 0.6347\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.6061 - accuracy: 0.6922 - val_loss: 0.6406 - val_accuracy: 0.6300\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6047 - accuracy: 0.6910 - val_loss: 0.6418 - val_accuracy: 0.6284\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.6022 - accuracy: 0.6938 - val_loss: 0.6399 - val_accuracy: 0.6301\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 699us/step - loss: 0.6020 - accuracy: 0.6925 - val_loss: 0.6393 - val_accuracy: 0.6303\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.6004 - accuracy: 0.6948 - val_loss: 0.6321 - val_accuracy: 0.6372\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.5987 - accuracy: 0.6965 - val_loss: 0.6354 - val_accuracy: 0.6321\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.5975 - accuracy: 0.6939 - val_loss: 0.6319 - val_accuracy: 0.6357\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.5959 - accuracy: 0.6987 - val_loss: 0.6299 - val_accuracy: 0.6368\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.5940 - accuracy: 0.6995 - val_loss: 0.6306 - val_accuracy: 0.6353\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.5915 - accuracy: 0.7019 - val_loss: 0.6305 - val_accuracy: 0.6352\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.5912 - accuracy: 0.7028 - val_loss: 0.6254 - val_accuracy: 0.6407\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.5903 - accuracy: 0.7008 - val_loss: 0.6234 - val_accuracy: 0.6425\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 822us/step - loss: 0.5872 - accuracy: 0.7028 - val_loss: 0.6279 - val_accuracy: 0.6372\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.5867 - accuracy: 0.7045 - val_loss: 0.6222 - val_accuracy: 0.6436\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5857 - accuracy: 0.7045 - val_loss: 0.6232 - val_accuracy: 0.6419\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.8310 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.7411 - accuracy: 0.4798 - val_loss: 0.6829 - val_accuracy: 0.5708\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.6992 - accuracy: 0.5129 - val_loss: 0.7036 - val_accuracy: 0.4586\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6886 - accuracy: 0.5415 - val_loss: 0.6926 - val_accuracy: 0.5390\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6800 - accuracy: 0.5657 - val_loss: 0.6908 - val_accuracy: 0.5523\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6747 - accuracy: 0.5788 - val_loss: 0.6843 - val_accuracy: 0.5750\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6681 - accuracy: 0.5966 - val_loss: 0.6857 - val_accuracy: 0.5726\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6629 - accuracy: 0.6074 - val_loss: 0.6757 - val_accuracy: 0.5949\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6592 - accuracy: 0.6161 - val_loss: 0.6775 - val_accuracy: 0.5902\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6536 - accuracy: 0.6280 - val_loss: 0.6684 - val_accuracy: 0.6070\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6500 - accuracy: 0.6328 - val_loss: 0.6709 - val_accuracy: 0.6025\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6470 - accuracy: 0.6371 - val_loss: 0.6660 - val_accuracy: 0.6053\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6428 - accuracy: 0.6448 - val_loss: 0.6599 - val_accuracy: 0.6103\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6401 - accuracy: 0.6491 - val_loss: 0.6573 - val_accuracy: 0.6112\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6363 - accuracy: 0.6524 - val_loss: 0.6559 - val_accuracy: 0.6117\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6333 - accuracy: 0.6567 - val_loss: 0.6519 - val_accuracy: 0.6171\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6310 - accuracy: 0.6601 - val_loss: 0.6504 - val_accuracy: 0.6183\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.6282 - accuracy: 0.6636 - val_loss: 0.6500 - val_accuracy: 0.6176\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.6254 - accuracy: 0.6668 - val_loss: 0.6472 - val_accuracy: 0.6203\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6224 - accuracy: 0.6690 - val_loss: 0.6472 - val_accuracy: 0.6221\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6206 - accuracy: 0.6701 - val_loss: 0.6414 - val_accuracy: 0.6292\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6179 - accuracy: 0.6722 - val_loss: 0.6391 - val_accuracy: 0.6304\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.6159 - accuracy: 0.6752 - val_loss: 0.6379 - val_accuracy: 0.6276\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6128 - accuracy: 0.6780 - val_loss: 0.6365 - val_accuracy: 0.6268\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6100 - accuracy: 0.6784 - val_loss: 0.6347 - val_accuracy: 0.6267\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6090 - accuracy: 0.6789 - val_loss: 0.6356 - val_accuracy: 0.6246\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6071 - accuracy: 0.6805 - val_loss: 0.6341 - val_accuracy: 0.6267\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6041 - accuracy: 0.6844 - val_loss: 0.6337 - val_accuracy: 0.6276\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6029 - accuracy: 0.6851 - val_loss: 0.6292 - val_accuracy: 0.6330\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.6008 - accuracy: 0.6863 - val_loss: 0.6294 - val_accuracy: 0.6320\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5990 - accuracy: 0.6889 - val_loss: 0.6247 - val_accuracy: 0.6365\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.5966 - accuracy: 0.6892 - val_loss: 0.6230 - val_accuracy: 0.6371\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.5953 - accuracy: 0.6920 - val_loss: 0.6218 - val_accuracy: 0.6378\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5936 - accuracy: 0.6930 - val_loss: 0.6205 - val_accuracy: 0.6396\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.5914 - accuracy: 0.6941 - val_loss: 0.6150 - val_accuracy: 0.6438\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5905 - accuracy: 0.6952 - val_loss: 0.6198 - val_accuracy: 0.6406\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5885 - accuracy: 0.6973 - val_loss: 0.6197 - val_accuracy: 0.6398\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5871 - accuracy: 0.6980 - val_loss: 0.6190 - val_accuracy: 0.6402\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5865 - accuracy: 0.6986 - val_loss: 0.6184 - val_accuracy: 0.6396\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5855 - accuracy: 0.6985 - val_loss: 0.6156 - val_accuracy: 0.6409\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.5828 - accuracy: 0.7019 - val_loss: 0.6134 - val_accuracy: 0.6412\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 744us/step - loss: 0.5806 - accuracy: 0.7038 - val_loss: 0.6116 - val_accuracy: 0.6419\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5803 - accuracy: 0.7042 - val_loss: 0.6117 - val_accuracy: 0.6401\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5792 - accuracy: 0.7038 - val_loss: 0.6104 - val_accuracy: 0.6410\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.5771 - accuracy: 0.7062 - val_loss: 0.6120 - val_accuracy: 0.6392\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.5768 - accuracy: 0.7044 - val_loss: 0.6108 - val_accuracy: 0.6399\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5763 - accuracy: 0.7072 - val_loss: 0.6093 - val_accuracy: 0.6425\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.5744 - accuracy: 0.7080 - val_loss: 0.6132 - val_accuracy: 0.6388\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.5726 - accuracy: 0.7080 - val_loss: 0.6133 - val_accuracy: 0.6394\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.5721 - accuracy: 0.7091 - val_loss: 0.6096 - val_accuracy: 0.6433\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5717 - accuracy: 0.7087 - val_loss: 0.6109 - val_accuracy: 0.6428\n",
      "Epoch 1/50\n",
      "1645/1672 [============================>.] - ETA: 0s - loss: 0.7036 - accuracy: 0.5049WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.7035 - accuracy: 0.5050 - val_loss: 0.7220 - val_accuracy: 0.3393\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6966 - accuracy: 0.5200 - val_loss: 0.7094 - val_accuracy: 0.4148\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6917 - accuracy: 0.5327 - val_loss: 0.7049 - val_accuracy: 0.4441\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6879 - accuracy: 0.5444 - val_loss: 0.7020 - val_accuracy: 0.4715\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6831 - accuracy: 0.5559 - val_loss: 0.6976 - val_accuracy: 0.5017\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6790 - accuracy: 0.5688 - val_loss: 0.6970 - val_accuracy: 0.5056\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6745 - accuracy: 0.5831 - val_loss: 0.6907 - val_accuracy: 0.5369\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6701 - accuracy: 0.5911 - val_loss: 0.6862 - val_accuracy: 0.5559\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.6667 - accuracy: 0.6007 - val_loss: 0.6848 - val_accuracy: 0.5601\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6637 - accuracy: 0.6097 - val_loss: 0.6820 - val_accuracy: 0.5651\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.6599 - accuracy: 0.6181 - val_loss: 0.6785 - val_accuracy: 0.5726\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6560 - accuracy: 0.6247 - val_loss: 0.6770 - val_accuracy: 0.5758\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6537 - accuracy: 0.6295 - val_loss: 0.6721 - val_accuracy: 0.5869\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6505 - accuracy: 0.6361 - val_loss: 0.6693 - val_accuracy: 0.5917\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6465 - accuracy: 0.6435 - val_loss: 0.6668 - val_accuracy: 0.5994\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6447 - accuracy: 0.6470 - val_loss: 0.6631 - val_accuracy: 0.6069\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6410 - accuracy: 0.6513 - val_loss: 0.6616 - val_accuracy: 0.6101\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6378 - accuracy: 0.6546 - val_loss: 0.6581 - val_accuracy: 0.6164\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6348 - accuracy: 0.6592 - val_loss: 0.6530 - val_accuracy: 0.6266\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6332 - accuracy: 0.6617 - val_loss: 0.6520 - val_accuracy: 0.6270\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.6300 - accuracy: 0.6635 - val_loss: 0.6502 - val_accuracy: 0.6284\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6279 - accuracy: 0.6638 - val_loss: 0.6490 - val_accuracy: 0.6290\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.6251 - accuracy: 0.6697 - val_loss: 0.6485 - val_accuracy: 0.6288\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6221 - accuracy: 0.6704 - val_loss: 0.6441 - val_accuracy: 0.6337\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6201 - accuracy: 0.6700 - val_loss: 0.6435 - val_accuracy: 0.6329\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6184 - accuracy: 0.6752 - val_loss: 0.6393 - val_accuracy: 0.6398\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6149 - accuracy: 0.6781 - val_loss: 0.6370 - val_accuracy: 0.6422\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6127 - accuracy: 0.6785 - val_loss: 0.6315 - val_accuracy: 0.6470\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6112 - accuracy: 0.6780 - val_loss: 0.6314 - val_accuracy: 0.6465\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6090 - accuracy: 0.6812 - val_loss: 0.6292 - val_accuracy: 0.6474\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6072 - accuracy: 0.6824 - val_loss: 0.6237 - val_accuracy: 0.6555\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6048 - accuracy: 0.6856 - val_loss: 0.6247 - val_accuracy: 0.6500\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6031 - accuracy: 0.6844 - val_loss: 0.6232 - val_accuracy: 0.6537\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6016 - accuracy: 0.6867 - val_loss: 0.6225 - val_accuracy: 0.6540\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6009 - accuracy: 0.6890 - val_loss: 0.6255 - val_accuracy: 0.6461\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5984 - accuracy: 0.6890 - val_loss: 0.6173 - val_accuracy: 0.6607\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5981 - accuracy: 0.6879 - val_loss: 0.6195 - val_accuracy: 0.6559\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.5956 - accuracy: 0.6915 - val_loss: 0.6177 - val_accuracy: 0.6580\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5939 - accuracy: 0.6915 - val_loss: 0.6200 - val_accuracy: 0.6532\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5935 - accuracy: 0.6929 - val_loss: 0.6136 - val_accuracy: 0.6618\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5919 - accuracy: 0.6942 - val_loss: 0.6190 - val_accuracy: 0.6522\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5903 - accuracy: 0.6928 - val_loss: 0.6150 - val_accuracy: 0.6580\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5887 - accuracy: 0.6954 - val_loss: 0.6152 - val_accuracy: 0.6576\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.5878 - accuracy: 0.6958 - val_loss: 0.6119 - val_accuracy: 0.6603\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.5871 - accuracy: 0.6954 - val_loss: 0.6124 - val_accuracy: 0.6595\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5851 - accuracy: 0.6982 - val_loss: 0.6115 - val_accuracy: 0.6597\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.5840 - accuracy: 0.6997 - val_loss: 0.6119 - val_accuracy: 0.6581\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.5825 - accuracy: 0.7007 - val_loss: 0.6153 - val_accuracy: 0.6543\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 732us/step - loss: 0.5825 - accuracy: 0.6989 - val_loss: 0.6094 - val_accuracy: 0.6584\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.5807 - accuracy: 0.7020 - val_loss: 0.6115 - val_accuracy: 0.6563\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.7284 - accuracy: 0.4906 - val_loss: 0.7293 - val_accuracy: 0.3794\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.7165 - accuracy: 0.5063 - val_loss: 0.7207 - val_accuracy: 0.4302\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.7065 - accuracy: 0.5219 - val_loss: 0.7121 - val_accuracy: 0.4799\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.6985 - accuracy: 0.5330 - val_loss: 0.7014 - val_accuracy: 0.5258\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.6893 - accuracy: 0.5520 - val_loss: 0.6939 - val_accuracy: 0.5467\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.6826 - accuracy: 0.5644 - val_loss: 0.6897 - val_accuracy: 0.5586\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.6787 - accuracy: 0.5764 - val_loss: 0.6876 - val_accuracy: 0.5654\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.6713 - accuracy: 0.5884 - val_loss: 0.6796 - val_accuracy: 0.5854\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 744us/step - loss: 0.6677 - accuracy: 0.5946 - val_loss: 0.6829 - val_accuracy: 0.5760\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6633 - accuracy: 0.6030 - val_loss: 0.6724 - val_accuracy: 0.5980\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.6593 - accuracy: 0.6131 - val_loss: 0.6711 - val_accuracy: 0.5959\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6549 - accuracy: 0.6206 - val_loss: 0.6724 - val_accuracy: 0.5910\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 774us/step - loss: 0.6519 - accuracy: 0.6241 - val_loss: 0.6652 - val_accuracy: 0.6001\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6506 - accuracy: 0.6288 - val_loss: 0.6648 - val_accuracy: 0.5992\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 842us/step - loss: 0.6461 - accuracy: 0.6360 - val_loss: 0.6623 - val_accuracy: 0.6037\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 796us/step - loss: 0.6427 - accuracy: 0.6392 - val_loss: 0.6588 - val_accuracy: 0.6073\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.6410 - accuracy: 0.6431 - val_loss: 0.6585 - val_accuracy: 0.6057\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.6383 - accuracy: 0.6480 - val_loss: 0.6566 - val_accuracy: 0.6085\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6356 - accuracy: 0.6517 - val_loss: 0.6597 - val_accuracy: 0.6036\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6338 - accuracy: 0.6543 - val_loss: 0.6550 - val_accuracy: 0.6084\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.6308 - accuracy: 0.6582 - val_loss: 0.6497 - val_accuracy: 0.6165\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6273 - accuracy: 0.6618 - val_loss: 0.6476 - val_accuracy: 0.6185\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6255 - accuracy: 0.6631 - val_loss: 0.6445 - val_accuracy: 0.6217\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.6237 - accuracy: 0.6681 - val_loss: 0.6464 - val_accuracy: 0.6179\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.6218 - accuracy: 0.6704 - val_loss: 0.6419 - val_accuracy: 0.6228\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6203 - accuracy: 0.6699 - val_loss: 0.6442 - val_accuracy: 0.6183\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6174 - accuracy: 0.6766 - val_loss: 0.6374 - val_accuracy: 0.6259\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.6150 - accuracy: 0.6760 - val_loss: 0.6378 - val_accuracy: 0.6234\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6132 - accuracy: 0.6794 - val_loss: 0.6380 - val_accuracy: 0.6210\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6103 - accuracy: 0.6819 - val_loss: 0.6358 - val_accuracy: 0.6226\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 798us/step - loss: 0.6088 - accuracy: 0.6837 - val_loss: 0.6361 - val_accuracy: 0.6213\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6063 - accuracy: 0.6853 - val_loss: 0.6325 - val_accuracy: 0.6250\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.6053 - accuracy: 0.6869 - val_loss: 0.6331 - val_accuracy: 0.6248\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.6033 - accuracy: 0.6874 - val_loss: 0.6270 - val_accuracy: 0.6328\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 811us/step - loss: 0.6002 - accuracy: 0.6927 - val_loss: 0.6304 - val_accuracy: 0.6256\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.5990 - accuracy: 0.6950 - val_loss: 0.6281 - val_accuracy: 0.6281\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.5968 - accuracy: 0.6933 - val_loss: 0.6246 - val_accuracy: 0.6328\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 732us/step - loss: 0.5948 - accuracy: 0.6975 - val_loss: 0.6217 - val_accuracy: 0.6362\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 765us/step - loss: 0.5941 - accuracy: 0.6991 - val_loss: 0.6245 - val_accuracy: 0.6321\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.5922 - accuracy: 0.6988 - val_loss: 0.6200 - val_accuracy: 0.6366\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.5900 - accuracy: 0.7016 - val_loss: 0.6239 - val_accuracy: 0.6310\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.5884 - accuracy: 0.7029 - val_loss: 0.6200 - val_accuracy: 0.6345\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.5869 - accuracy: 0.7052 - val_loss: 0.6189 - val_accuracy: 0.6347\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.5844 - accuracy: 0.7066 - val_loss: 0.6155 - val_accuracy: 0.6368\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.5837 - accuracy: 0.7064 - val_loss: 0.6172 - val_accuracy: 0.6350\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.5818 - accuracy: 0.7081 - val_loss: 0.6162 - val_accuracy: 0.6349\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.5800 - accuracy: 0.7106 - val_loss: 0.6200 - val_accuracy: 0.6303\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 802us/step - loss: 0.5785 - accuracy: 0.7111 - val_loss: 0.6132 - val_accuracy: 0.6364\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.5771 - accuracy: 0.7115 - val_loss: 0.6175 - val_accuracy: 0.6322\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 719us/step - loss: 0.5768 - accuracy: 0.7102 - val_loss: 0.6088 - val_accuracy: 0.6435\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 774us/step - loss: 0.7033 - accuracy: 0.5100 - val_loss: 0.6960 - val_accuracy: 0.4931\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 871us/step - loss: 0.6946 - accuracy: 0.5340 - val_loss: 0.6978 - val_accuracy: 0.4985\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6869 - accuracy: 0.5531 - val_loss: 0.6939 - val_accuracy: 0.5348\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 836us/step - loss: 0.6821 - accuracy: 0.5682 - val_loss: 0.6862 - val_accuracy: 0.5801\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6784 - accuracy: 0.5800 - val_loss: 0.6861 - val_accuracy: 0.5765\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.6731 - accuracy: 0.5938 - val_loss: 0.6797 - val_accuracy: 0.5984\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.6701 - accuracy: 0.6015 - val_loss: 0.6785 - val_accuracy: 0.5995\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.6656 - accuracy: 0.6144 - val_loss: 0.6732 - val_accuracy: 0.6188\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.6619 - accuracy: 0.6236 - val_loss: 0.6721 - val_accuracy: 0.6150\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 789us/step - loss: 0.6589 - accuracy: 0.6299 - val_loss: 0.6642 - val_accuracy: 0.6310\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6561 - accuracy: 0.6352 - val_loss: 0.6612 - val_accuracy: 0.6313\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.6511 - accuracy: 0.6433 - val_loss: 0.6599 - val_accuracy: 0.6293\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.6492 - accuracy: 0.6462 - val_loss: 0.6562 - val_accuracy: 0.6350\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6454 - accuracy: 0.6555 - val_loss: 0.6533 - val_accuracy: 0.6378\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6423 - accuracy: 0.6579 - val_loss: 0.6511 - val_accuracy: 0.6391\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6394 - accuracy: 0.6651 - val_loss: 0.6494 - val_accuracy: 0.6376\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6373 - accuracy: 0.6674 - val_loss: 0.6437 - val_accuracy: 0.6454\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.6343 - accuracy: 0.6700 - val_loss: 0.6436 - val_accuracy: 0.6414\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.6313 - accuracy: 0.6748 - val_loss: 0.6434 - val_accuracy: 0.6377\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6285 - accuracy: 0.6764 - val_loss: 0.6394 - val_accuracy: 0.6428\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6259 - accuracy: 0.6791 - val_loss: 0.6354 - val_accuracy: 0.6492\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6241 - accuracy: 0.6814 - val_loss: 0.6330 - val_accuracy: 0.6521\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6215 - accuracy: 0.6824 - val_loss: 0.6337 - val_accuracy: 0.6499\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.6197 - accuracy: 0.6834 - val_loss: 0.6300 - val_accuracy: 0.6548\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6168 - accuracy: 0.6873 - val_loss: 0.6276 - val_accuracy: 0.6562\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6151 - accuracy: 0.6885 - val_loss: 0.6253 - val_accuracy: 0.6575\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6133 - accuracy: 0.6897 - val_loss: 0.6260 - val_accuracy: 0.6551\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6114 - accuracy: 0.6926 - val_loss: 0.6205 - val_accuracy: 0.6610\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.6096 - accuracy: 0.6928 - val_loss: 0.6213 - val_accuracy: 0.6575\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 781us/step - loss: 0.6068 - accuracy: 0.6958 - val_loss: 0.6195 - val_accuracy: 0.6575\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6056 - accuracy: 0.6951 - val_loss: 0.6210 - val_accuracy: 0.6538\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6042 - accuracy: 0.6975 - val_loss: 0.6202 - val_accuracy: 0.6530\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6016 - accuracy: 0.6979 - val_loss: 0.6142 - val_accuracy: 0.6585\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6004 - accuracy: 0.7000 - val_loss: 0.6121 - val_accuracy: 0.6607\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.5993 - accuracy: 0.7000 - val_loss: 0.6159 - val_accuracy: 0.6547\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5974 - accuracy: 0.6996 - val_loss: 0.6130 - val_accuracy: 0.6569\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.5964 - accuracy: 0.7031 - val_loss: 0.6118 - val_accuracy: 0.6572\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5946 - accuracy: 0.7011 - val_loss: 0.6143 - val_accuracy: 0.6527\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5924 - accuracy: 0.7048 - val_loss: 0.6062 - val_accuracy: 0.6614\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5924 - accuracy: 0.7046 - val_loss: 0.6113 - val_accuracy: 0.6540\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.5895 - accuracy: 0.7069 - val_loss: 0.6043 - val_accuracy: 0.6612\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5888 - accuracy: 0.7069 - val_loss: 0.6029 - val_accuracy: 0.6612\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5883 - accuracy: 0.7070 - val_loss: 0.6103 - val_accuracy: 0.6524\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5861 - accuracy: 0.7082 - val_loss: 0.6079 - val_accuracy: 0.6543\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.5842 - accuracy: 0.7096 - val_loss: 0.6039 - val_accuracy: 0.6569\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5835 - accuracy: 0.7083 - val_loss: 0.6080 - val_accuracy: 0.6516\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5818 - accuracy: 0.7107 - val_loss: 0.6084 - val_accuracy: 0.6504\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.5813 - accuracy: 0.7112 - val_loss: 0.6060 - val_accuracy: 0.6522\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5791 - accuracy: 0.7135 - val_loss: 0.6032 - val_accuracy: 0.6545\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.5799 - accuracy: 0.7120 - val_loss: 0.5973 - val_accuracy: 0.6586\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.7103 - accuracy: 0.5117 - val_loss: 0.7020 - val_accuracy: 0.4765\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6978 - accuracy: 0.5228 - val_loss: 0.7017 - val_accuracy: 0.4909\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6879 - accuracy: 0.5406 - val_loss: 0.7032 - val_accuracy: 0.4998\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6822 - accuracy: 0.5551 - val_loss: 0.6932 - val_accuracy: 0.5299\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6786 - accuracy: 0.5640 - val_loss: 0.6911 - val_accuracy: 0.5400\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6729 - accuracy: 0.5764 - val_loss: 0.6873 - val_accuracy: 0.5461\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6675 - accuracy: 0.5873 - val_loss: 0.6840 - val_accuracy: 0.5531\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6635 - accuracy: 0.5986 - val_loss: 0.6734 - val_accuracy: 0.5705\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6610 - accuracy: 0.6027 - val_loss: 0.6752 - val_accuracy: 0.5674\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6571 - accuracy: 0.6092 - val_loss: 0.6757 - val_accuracy: 0.5665\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6532 - accuracy: 0.6214 - val_loss: 0.6731 - val_accuracy: 0.5708\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6492 - accuracy: 0.6278 - val_loss: 0.6673 - val_accuracy: 0.5803\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6467 - accuracy: 0.6344 - val_loss: 0.6682 - val_accuracy: 0.5812\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6432 - accuracy: 0.6407 - val_loss: 0.6591 - val_accuracy: 0.5932\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6407 - accuracy: 0.6437 - val_loss: 0.6549 - val_accuracy: 0.6008\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6383 - accuracy: 0.6474 - val_loss: 0.6580 - val_accuracy: 0.5939\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6363 - accuracy: 0.6529 - val_loss: 0.6551 - val_accuracy: 0.5974\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6320 - accuracy: 0.6576 - val_loss: 0.6535 - val_accuracy: 0.6000\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6292 - accuracy: 0.6640 - val_loss: 0.6493 - val_accuracy: 0.6116\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6283 - accuracy: 0.6648 - val_loss: 0.6428 - val_accuracy: 0.6258\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.6250 - accuracy: 0.6676 - val_loss: 0.6445 - val_accuracy: 0.6231\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6229 - accuracy: 0.6713 - val_loss: 0.6408 - val_accuracy: 0.6287\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.6203 - accuracy: 0.6740 - val_loss: 0.6367 - val_accuracy: 0.6337\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.6186 - accuracy: 0.6766 - val_loss: 0.6364 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6161 - accuracy: 0.6799 - val_loss: 0.6356 - val_accuracy: 0.6318\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6143 - accuracy: 0.6822 - val_loss: 0.6377 - val_accuracy: 0.6288\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6120 - accuracy: 0.6846 - val_loss: 0.6303 - val_accuracy: 0.6364\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6090 - accuracy: 0.6875 - val_loss: 0.6365 - val_accuracy: 0.6289\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6075 - accuracy: 0.6900 - val_loss: 0.6312 - val_accuracy: 0.6336\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6051 - accuracy: 0.6905 - val_loss: 0.6247 - val_accuracy: 0.6401\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6040 - accuracy: 0.6962 - val_loss: 0.6301 - val_accuracy: 0.6341\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6013 - accuracy: 0.6952 - val_loss: 0.6287 - val_accuracy: 0.6329\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5990 - accuracy: 0.7000 - val_loss: 0.6323 - val_accuracy: 0.6291\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5981 - accuracy: 0.7001 - val_loss: 0.6181 - val_accuracy: 0.6434\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.5965 - accuracy: 0.7015 - val_loss: 0.6246 - val_accuracy: 0.6360\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.5943 - accuracy: 0.7040 - val_loss: 0.6212 - val_accuracy: 0.6404\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.5921 - accuracy: 0.7031 - val_loss: 0.6228 - val_accuracy: 0.6384\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5901 - accuracy: 0.7065 - val_loss: 0.6216 - val_accuracy: 0.6398\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.5892 - accuracy: 0.7058 - val_loss: 0.6178 - val_accuracy: 0.6444\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.5878 - accuracy: 0.7083 - val_loss: 0.6192 - val_accuracy: 0.6423\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.5860 - accuracy: 0.7094 - val_loss: 0.6184 - val_accuracy: 0.6428\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5834 - accuracy: 0.7094 - val_loss: 0.6155 - val_accuracy: 0.6451\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5820 - accuracy: 0.7110 - val_loss: 0.6144 - val_accuracy: 0.6461\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.5813 - accuracy: 0.7120 - val_loss: 0.6117 - val_accuracy: 0.6479\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.5787 - accuracy: 0.7125 - val_loss: 0.6086 - val_accuracy: 0.6500\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5782 - accuracy: 0.7121 - val_loss: 0.6122 - val_accuracy: 0.6464\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5764 - accuracy: 0.7141 - val_loss: 0.6078 - val_accuracy: 0.6508\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.5751 - accuracy: 0.7156 - val_loss: 0.6080 - val_accuracy: 0.6527\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5736 - accuracy: 0.7164 - val_loss: 0.6106 - val_accuracy: 0.6486\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.5716 - accuracy: 0.7162 - val_loss: 0.6080 - val_accuracy: 0.6534\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.7158 - accuracy: 0.5022 - val_loss: 0.7371 - val_accuracy: 0.3399\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 953us/step - loss: 0.7058 - accuracy: 0.5164 - val_loss: 0.7282 - val_accuracy: 0.3785\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 864us/step - loss: 0.7006 - accuracy: 0.5277 - val_loss: 0.7237 - val_accuracy: 0.3936\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.6950 - accuracy: 0.5380 - val_loss: 0.7202 - val_accuracy: 0.4075\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.6907 - accuracy: 0.5465 - val_loss: 0.7136 - val_accuracy: 0.4305\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.6866 - accuracy: 0.5517 - val_loss: 0.7102 - val_accuracy: 0.4426\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6818 - accuracy: 0.5684 - val_loss: 0.7091 - val_accuracy: 0.4547\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 778us/step - loss: 0.6766 - accuracy: 0.5773 - val_loss: 0.7052 - val_accuracy: 0.4772\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 794us/step - loss: 0.6723 - accuracy: 0.5895 - val_loss: 0.6979 - val_accuracy: 0.5014\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6679 - accuracy: 0.6008 - val_loss: 0.6988 - val_accuracy: 0.5049\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6653 - accuracy: 0.6051 - val_loss: 0.6952 - val_accuracy: 0.5185\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 789us/step - loss: 0.6618 - accuracy: 0.6126 - val_loss: 0.6901 - val_accuracy: 0.5328\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 784us/step - loss: 0.6580 - accuracy: 0.6230 - val_loss: 0.6868 - val_accuracy: 0.5403\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6558 - accuracy: 0.6275 - val_loss: 0.6832 - val_accuracy: 0.5473\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6527 - accuracy: 0.6339 - val_loss: 0.6795 - val_accuracy: 0.5570\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.6504 - accuracy: 0.6367 - val_loss: 0.6804 - val_accuracy: 0.5538\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.6480 - accuracy: 0.6435 - val_loss: 0.6773 - val_accuracy: 0.5632\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 822us/step - loss: 0.6447 - accuracy: 0.6469 - val_loss: 0.6719 - val_accuracy: 0.5785\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.6417 - accuracy: 0.6531 - val_loss: 0.6674 - val_accuracy: 0.5874\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6396 - accuracy: 0.6544 - val_loss: 0.6699 - val_accuracy: 0.5813\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 772us/step - loss: 0.6366 - accuracy: 0.6582 - val_loss: 0.6691 - val_accuracy: 0.5814\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.6341 - accuracy: 0.6622 - val_loss: 0.6667 - val_accuracy: 0.5840\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.6321 - accuracy: 0.6659 - val_loss: 0.6629 - val_accuracy: 0.5911\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 805us/step - loss: 0.6294 - accuracy: 0.6669 - val_loss: 0.6583 - val_accuracy: 0.6010\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.6280 - accuracy: 0.6697 - val_loss: 0.6560 - val_accuracy: 0.6029\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 782us/step - loss: 0.6252 - accuracy: 0.6711 - val_loss: 0.6569 - val_accuracy: 0.6001\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 770us/step - loss: 0.6227 - accuracy: 0.6761 - val_loss: 0.6540 - val_accuracy: 0.6039\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 822us/step - loss: 0.6201 - accuracy: 0.6779 - val_loss: 0.6514 - val_accuracy: 0.6079\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.6172 - accuracy: 0.6808 - val_loss: 0.6479 - val_accuracy: 0.6104\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 784us/step - loss: 0.6152 - accuracy: 0.6788 - val_loss: 0.6474 - val_accuracy: 0.6104\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.6133 - accuracy: 0.6825 - val_loss: 0.6444 - val_accuracy: 0.6144\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.6120 - accuracy: 0.6835 - val_loss: 0.6470 - val_accuracy: 0.6110\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 865us/step - loss: 0.6090 - accuracy: 0.6860 - val_loss: 0.6397 - val_accuracy: 0.6199\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.6073 - accuracy: 0.6874 - val_loss: 0.6355 - val_accuracy: 0.6246\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6045 - accuracy: 0.6906 - val_loss: 0.6351 - val_accuracy: 0.6246\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 765us/step - loss: 0.6022 - accuracy: 0.6925 - val_loss: 0.6350 - val_accuracy: 0.6248\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.6018 - accuracy: 0.6929 - val_loss: 0.6346 - val_accuracy: 0.6244\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 776us/step - loss: 0.5982 - accuracy: 0.6941 - val_loss: 0.6342 - val_accuracy: 0.6241\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.5965 - accuracy: 0.6965 - val_loss: 0.6336 - val_accuracy: 0.6239\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.5956 - accuracy: 0.6966 - val_loss: 0.6255 - val_accuracy: 0.6312\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.5932 - accuracy: 0.6995 - val_loss: 0.6302 - val_accuracy: 0.6261\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.5923 - accuracy: 0.6991 - val_loss: 0.6215 - val_accuracy: 0.6350\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.5905 - accuracy: 0.7011 - val_loss: 0.6312 - val_accuracy: 0.6236\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.5887 - accuracy: 0.7002 - val_loss: 0.6270 - val_accuracy: 0.6276\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 795us/step - loss: 0.5876 - accuracy: 0.7009 - val_loss: 0.6220 - val_accuracy: 0.6321\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.5860 - accuracy: 0.7034 - val_loss: 0.6238 - val_accuracy: 0.6292\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 805us/step - loss: 0.5848 - accuracy: 0.7020 - val_loss: 0.6195 - val_accuracy: 0.6326\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.5825 - accuracy: 0.7056 - val_loss: 0.6254 - val_accuracy: 0.6276\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 770us/step - loss: 0.5808 - accuracy: 0.7047 - val_loss: 0.6227 - val_accuracy: 0.6281\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 857us/step - loss: 0.5793 - accuracy: 0.7084 - val_loss: 0.6099 - val_accuracy: 0.6430\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.6998 - accuracy: 0.5298 - val_loss: 0.7136 - val_accuracy: 0.4384\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.6854 - accuracy: 0.5589 - val_loss: 0.7071 - val_accuracy: 0.4780\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.6756 - accuracy: 0.5830 - val_loss: 0.6935 - val_accuracy: 0.5307\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 753us/step - loss: 0.6668 - accuracy: 0.5997 - val_loss: 0.6877 - val_accuracy: 0.5534\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 753us/step - loss: 0.6596 - accuracy: 0.6148 - val_loss: 0.6778 - val_accuracy: 0.5770\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.6519 - accuracy: 0.6288 - val_loss: 0.6718 - val_accuracy: 0.5876\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.6473 - accuracy: 0.6351 - val_loss: 0.6667 - val_accuracy: 0.5962\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.6427 - accuracy: 0.6420 - val_loss: 0.6622 - val_accuracy: 0.6009\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.6382 - accuracy: 0.6512 - val_loss: 0.6569 - val_accuracy: 0.6060\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6335 - accuracy: 0.6569 - val_loss: 0.6530 - val_accuracy: 0.6086\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.6297 - accuracy: 0.6614 - val_loss: 0.6482 - val_accuracy: 0.6135\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6256 - accuracy: 0.6663 - val_loss: 0.6420 - val_accuracy: 0.6222\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.6223 - accuracy: 0.6684 - val_loss: 0.6426 - val_accuracy: 0.6197\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 735us/step - loss: 0.6189 - accuracy: 0.6729 - val_loss: 0.6389 - val_accuracy: 0.6228\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 818us/step - loss: 0.6162 - accuracy: 0.6763 - val_loss: 0.6392 - val_accuracy: 0.6199\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.6131 - accuracy: 0.6789 - val_loss: 0.6361 - val_accuracy: 0.6222\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.6116 - accuracy: 0.6793 - val_loss: 0.6340 - val_accuracy: 0.6242\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.6089 - accuracy: 0.6831 - val_loss: 0.6329 - val_accuracy: 0.6247\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6060 - accuracy: 0.6855 - val_loss: 0.6315 - val_accuracy: 0.6239\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6036 - accuracy: 0.6871 - val_loss: 0.6276 - val_accuracy: 0.6268\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6017 - accuracy: 0.6887 - val_loss: 0.6303 - val_accuracy: 0.6198\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.5998 - accuracy: 0.6938 - val_loss: 0.6267 - val_accuracy: 0.6244\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5974 - accuracy: 0.6926 - val_loss: 0.6275 - val_accuracy: 0.6214\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.5959 - accuracy: 0.6960 - val_loss: 0.6261 - val_accuracy: 0.6217\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.5934 - accuracy: 0.6981 - val_loss: 0.6221 - val_accuracy: 0.6270\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.5914 - accuracy: 0.7001 - val_loss: 0.6208 - val_accuracy: 0.6281\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.5892 - accuracy: 0.7008 - val_loss: 0.6172 - val_accuracy: 0.6318\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5877 - accuracy: 0.7014 - val_loss: 0.6222 - val_accuracy: 0.6239\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5859 - accuracy: 0.7053 - val_loss: 0.6153 - val_accuracy: 0.6305\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.5843 - accuracy: 0.7044 - val_loss: 0.6077 - val_accuracy: 0.6359\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.5836 - accuracy: 0.7054 - val_loss: 0.6155 - val_accuracy: 0.6276\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5809 - accuracy: 0.7062 - val_loss: 0.6102 - val_accuracy: 0.6313\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.5796 - accuracy: 0.7072 - val_loss: 0.6156 - val_accuracy: 0.6257\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5774 - accuracy: 0.7103 - val_loss: 0.6095 - val_accuracy: 0.6291\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5758 - accuracy: 0.7114 - val_loss: 0.6115 - val_accuracy: 0.6279\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5750 - accuracy: 0.7123 - val_loss: 0.6085 - val_accuracy: 0.6297\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.5729 - accuracy: 0.7133 - val_loss: 0.6061 - val_accuracy: 0.6304\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5716 - accuracy: 0.7132 - val_loss: 0.6100 - val_accuracy: 0.6276\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.5702 - accuracy: 0.7155 - val_loss: 0.6141 - val_accuracy: 0.6232\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.5686 - accuracy: 0.7149 - val_loss: 0.6137 - val_accuracy: 0.6237\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5680 - accuracy: 0.7157 - val_loss: 0.6031 - val_accuracy: 0.6320\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.5660 - accuracy: 0.7159 - val_loss: 0.6141 - val_accuracy: 0.6238\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 699us/step - loss: 0.5648 - accuracy: 0.7197 - val_loss: 0.6065 - val_accuracy: 0.6294\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5638 - accuracy: 0.7182 - val_loss: 0.6120 - val_accuracy: 0.6242\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.5620 - accuracy: 0.7192 - val_loss: 0.6128 - val_accuracy: 0.6234\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5613 - accuracy: 0.7202 - val_loss: 0.6090 - val_accuracy: 0.6271\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.5607 - accuracy: 0.7207 - val_loss: 0.6044 - val_accuracy: 0.6319\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.5588 - accuracy: 0.7205 - val_loss: 0.6013 - val_accuracy: 0.6353\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.5584 - accuracy: 0.7229 - val_loss: 0.6093 - val_accuracy: 0.6265\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5573 - accuracy: 0.7232 - val_loss: 0.5998 - val_accuracy: 0.6362\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6987 - accuracy: 0.5442 - val_loss: 0.6901 - val_accuracy: 0.5545\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.6890 - accuracy: 0.5546 - val_loss: 0.6830 - val_accuracy: 0.5732\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6832 - accuracy: 0.5622 - val_loss: 0.6789 - val_accuracy: 0.5802\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6767 - accuracy: 0.5762 - val_loss: 0.6720 - val_accuracy: 0.5973\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6718 - accuracy: 0.5860 - val_loss: 0.6751 - val_accuracy: 0.5821\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6652 - accuracy: 0.5963 - val_loss: 0.6608 - val_accuracy: 0.6161\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6606 - accuracy: 0.6066 - val_loss: 0.6609 - val_accuracy: 0.6117\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6561 - accuracy: 0.6153 - val_loss: 0.6654 - val_accuracy: 0.5966\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6517 - accuracy: 0.6214 - val_loss: 0.6533 - val_accuracy: 0.6213\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6480 - accuracy: 0.6270 - val_loss: 0.6527 - val_accuracy: 0.6193\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6451 - accuracy: 0.6334 - val_loss: 0.6466 - val_accuracy: 0.6297\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6432 - accuracy: 0.6317 - val_loss: 0.6483 - val_accuracy: 0.6237\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6393 - accuracy: 0.6383 - val_loss: 0.6487 - val_accuracy: 0.6226\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6354 - accuracy: 0.6452 - val_loss: 0.6430 - val_accuracy: 0.6301\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6334 - accuracy: 0.6460 - val_loss: 0.6434 - val_accuracy: 0.6267\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6320 - accuracy: 0.6496 - val_loss: 0.6385 - val_accuracy: 0.6331\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 800us/step - loss: 0.6299 - accuracy: 0.6531 - val_loss: 0.6365 - val_accuracy: 0.6340\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6243 - accuracy: 0.6591 - val_loss: 0.6338 - val_accuracy: 0.6388\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6231 - accuracy: 0.6617 - val_loss: 0.6337 - val_accuracy: 0.6393\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6214 - accuracy: 0.6639 - val_loss: 0.6318 - val_accuracy: 0.6428\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6184 - accuracy: 0.6666 - val_loss: 0.6359 - val_accuracy: 0.6325\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.6169 - accuracy: 0.6673 - val_loss: 0.6337 - val_accuracy: 0.6355\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6151 - accuracy: 0.6692 - val_loss: 0.6255 - val_accuracy: 0.6474\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6124 - accuracy: 0.6715 - val_loss: 0.6263 - val_accuracy: 0.6441\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6095 - accuracy: 0.6766 - val_loss: 0.6276 - val_accuracy: 0.6399\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6083 - accuracy: 0.6773 - val_loss: 0.6272 - val_accuracy: 0.6389\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6064 - accuracy: 0.6777 - val_loss: 0.6189 - val_accuracy: 0.6514\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.6043 - accuracy: 0.6799 - val_loss: 0.6202 - val_accuracy: 0.6455\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6030 - accuracy: 0.6826 - val_loss: 0.6276 - val_accuracy: 0.6304\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6020 - accuracy: 0.6829 - val_loss: 0.6182 - val_accuracy: 0.6449\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5992 - accuracy: 0.6848 - val_loss: 0.6254 - val_accuracy: 0.6332\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5982 - accuracy: 0.6862 - val_loss: 0.6181 - val_accuracy: 0.6431\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.5958 - accuracy: 0.6890 - val_loss: 0.6172 - val_accuracy: 0.6437\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.5944 - accuracy: 0.6899 - val_loss: 0.6208 - val_accuracy: 0.6373\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5928 - accuracy: 0.6923 - val_loss: 0.6167 - val_accuracy: 0.6416\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5904 - accuracy: 0.6938 - val_loss: 0.6200 - val_accuracy: 0.6357\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5889 - accuracy: 0.6940 - val_loss: 0.6219 - val_accuracy: 0.6336\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.5885 - accuracy: 0.6966 - val_loss: 0.6200 - val_accuracy: 0.6351\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.5872 - accuracy: 0.6956 - val_loss: 0.6081 - val_accuracy: 0.6545\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.5845 - accuracy: 0.6993 - val_loss: 0.6143 - val_accuracy: 0.6392\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.5845 - accuracy: 0.6990 - val_loss: 0.6138 - val_accuracy: 0.6386\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5815 - accuracy: 0.7019 - val_loss: 0.6043 - val_accuracy: 0.6563\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.5817 - accuracy: 0.7014 - val_loss: 0.6051 - val_accuracy: 0.6535\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.5799 - accuracy: 0.7028 - val_loss: 0.6205 - val_accuracy: 0.6260\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.5794 - accuracy: 0.7019 - val_loss: 0.6120 - val_accuracy: 0.6408\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5767 - accuracy: 0.7064 - val_loss: 0.6100 - val_accuracy: 0.6435\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5756 - accuracy: 0.7063 - val_loss: 0.6185 - val_accuracy: 0.6281\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.5743 - accuracy: 0.7091 - val_loss: 0.6115 - val_accuracy: 0.6405\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5727 - accuracy: 0.7095 - val_loss: 0.6064 - val_accuracy: 0.6470\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.5715 - accuracy: 0.7086 - val_loss: 0.6083 - val_accuracy: 0.6443\n",
      "\n",
      "Training model with batch_size=32, target_eps=2.0...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 5.05 iterated over 83600 steps satisfies differential privacy with eps = 0.167 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.5749999999999997 iterated over 83600 steps satisfies differential privacy with eps = 0.34 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.3375 iterated over 83600 steps satisfies differential privacy with eps = 0.763 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.71875 iterated over 83600 steps satisfies differential privacy with eps = 2.77 and delta = 1e-05.\n",
      "The optimal RDP order is 7.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.028125 iterated over 83600 steps satisfies differential privacy with eps = 1.22 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.8734375 iterated over 83600 steps satisfies differential privacy with eps = 1.7 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.79609375 iterated over 83600 steps satisfies differential privacy with eps = 2.12 and delta = 1e-05.\n",
      "The optimal RDP order is 8.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.834765625 iterated over 83600 steps satisfies differential privacy with eps = 1.89 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.8154296875 iterated over 83600 steps satisfies differential privacy with eps = 1.96 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.80576171875 iterated over 83600 steps satisfies differential privacy with eps = 2.08 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.810595703125 iterated over 83600 steps satisfies differential privacy with eps = 2.01 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.7117 - accuracy: 0.5272 - val_loss: 0.7237 - val_accuracy: 0.4661\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.6882 - accuracy: 0.5502 - val_loss: 0.7031 - val_accuracy: 0.5651\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 798us/step - loss: 0.6817 - accuracy: 0.5661 - val_loss: 0.6922 - val_accuracy: 0.5803\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.6764 - accuracy: 0.5780 - val_loss: 0.6897 - val_accuracy: 0.5703\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6711 - accuracy: 0.5900 - val_loss: 0.6878 - val_accuracy: 0.5625\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 2s 961us/step - loss: 0.6676 - accuracy: 0.5963 - val_loss: 0.6828 - val_accuracy: 0.5702\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 883us/step - loss: 0.6626 - accuracy: 0.6093 - val_loss: 0.6789 - val_accuracy: 0.5860\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6592 - accuracy: 0.6149 - val_loss: 0.6736 - val_accuracy: 0.5991\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.6551 - accuracy: 0.6217 - val_loss: 0.6701 - val_accuracy: 0.5988\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.6511 - accuracy: 0.6284 - val_loss: 0.6700 - val_accuracy: 0.5955\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6470 - accuracy: 0.6338 - val_loss: 0.6655 - val_accuracy: 0.6048\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6436 - accuracy: 0.6372 - val_loss: 0.6628 - val_accuracy: 0.6103\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.6409 - accuracy: 0.6442 - val_loss: 0.6557 - val_accuracy: 0.6234\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6378 - accuracy: 0.6477 - val_loss: 0.6546 - val_accuracy: 0.6261\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 842us/step - loss: 0.6353 - accuracy: 0.6503 - val_loss: 0.6542 - val_accuracy: 0.6247\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 749us/step - loss: 0.6324 - accuracy: 0.6543 - val_loss: 0.6529 - val_accuracy: 0.6259\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 765us/step - loss: 0.6299 - accuracy: 0.6533 - val_loss: 0.6524 - val_accuracy: 0.6258\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6275 - accuracy: 0.6598 - val_loss: 0.6464 - val_accuracy: 0.6344\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 757us/step - loss: 0.6246 - accuracy: 0.6631 - val_loss: 0.6494 - val_accuracy: 0.6273\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.6234 - accuracy: 0.6635 - val_loss: 0.6427 - val_accuracy: 0.6352\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 701us/step - loss: 0.6211 - accuracy: 0.6646 - val_loss: 0.6433 - val_accuracy: 0.6330\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6195 - accuracy: 0.6677 - val_loss: 0.6406 - val_accuracy: 0.6359\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.6160 - accuracy: 0.6716 - val_loss: 0.6425 - val_accuracy: 0.6310\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 799us/step - loss: 0.6140 - accuracy: 0.6715 - val_loss: 0.6410 - val_accuracy: 0.6314\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 815us/step - loss: 0.6134 - accuracy: 0.6718 - val_loss: 0.6285 - val_accuracy: 0.6483\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6099 - accuracy: 0.6777 - val_loss: 0.6342 - val_accuracy: 0.6401\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.6082 - accuracy: 0.6784 - val_loss: 0.6355 - val_accuracy: 0.6371\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6068 - accuracy: 0.6777 - val_loss: 0.6336 - val_accuracy: 0.6406\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 785us/step - loss: 0.6047 - accuracy: 0.6804 - val_loss: 0.6367 - val_accuracy: 0.6360\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.6033 - accuracy: 0.6816 - val_loss: 0.6296 - val_accuracy: 0.6462\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.6014 - accuracy: 0.6831 - val_loss: 0.6346 - val_accuracy: 0.6402\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 850us/step - loss: 0.6002 - accuracy: 0.6844 - val_loss: 0.6294 - val_accuracy: 0.6465\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.5991 - accuracy: 0.6848 - val_loss: 0.6328 - val_accuracy: 0.6431\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 770us/step - loss: 0.5974 - accuracy: 0.6870 - val_loss: 0.6242 - val_accuracy: 0.6513\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.5955 - accuracy: 0.6874 - val_loss: 0.6279 - val_accuracy: 0.6478\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5925 - accuracy: 0.6913 - val_loss: 0.6284 - val_accuracy: 0.6471\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 742us/step - loss: 0.5915 - accuracy: 0.6915 - val_loss: 0.6258 - val_accuracy: 0.6488\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 744us/step - loss: 0.5903 - accuracy: 0.6923 - val_loss: 0.6284 - val_accuracy: 0.6462\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.5890 - accuracy: 0.6937 - val_loss: 0.6241 - val_accuracy: 0.6502\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.5863 - accuracy: 0.6966 - val_loss: 0.6242 - val_accuracy: 0.6492\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.5857 - accuracy: 0.6956 - val_loss: 0.6237 - val_accuracy: 0.6492\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.5841 - accuracy: 0.6952 - val_loss: 0.6205 - val_accuracy: 0.6512\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.5828 - accuracy: 0.6987 - val_loss: 0.6181 - val_accuracy: 0.6535\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 785us/step - loss: 0.5810 - accuracy: 0.6995 - val_loss: 0.6193 - val_accuracy: 0.6516\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5801 - accuracy: 0.6999 - val_loss: 0.6164 - val_accuracy: 0.6561\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 781us/step - loss: 0.5782 - accuracy: 0.6989 - val_loss: 0.6157 - val_accuracy: 0.6580\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5766 - accuracy: 0.7028 - val_loss: 0.6161 - val_accuracy: 0.6575\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 809us/step - loss: 0.5766 - accuracy: 0.7004 - val_loss: 0.6163 - val_accuracy: 0.6577\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.5744 - accuracy: 0.7043 - val_loss: 0.6179 - val_accuracy: 0.6556\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.5730 - accuracy: 0.7068 - val_loss: 0.6095 - val_accuracy: 0.6642\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.7035 - accuracy: 0.5339 - val_loss: 0.6462 - val_accuracy: 0.7025\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 827us/step - loss: 0.6662 - accuracy: 0.5888 - val_loss: 0.6653 - val_accuracy: 0.6113\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.6585 - accuracy: 0.6033 - val_loss: 0.6614 - val_accuracy: 0.6178\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 804us/step - loss: 0.6520 - accuracy: 0.6140 - val_loss: 0.6491 - val_accuracy: 0.6467\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.6451 - accuracy: 0.6270 - val_loss: 0.6452 - val_accuracy: 0.6506\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6383 - accuracy: 0.6390 - val_loss: 0.6388 - val_accuracy: 0.6579\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.6333 - accuracy: 0.6447 - val_loss: 0.6400 - val_accuracy: 0.6525\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.6276 - accuracy: 0.6535 - val_loss: 0.6322 - val_accuracy: 0.6604\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.6229 - accuracy: 0.6602 - val_loss: 0.6283 - val_accuracy: 0.6624\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 768us/step - loss: 0.6193 - accuracy: 0.6640 - val_loss: 0.6278 - val_accuracy: 0.6591\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.6159 - accuracy: 0.6666 - val_loss: 0.6240 - val_accuracy: 0.6594\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.6128 - accuracy: 0.6708 - val_loss: 0.6217 - val_accuracy: 0.6593\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.6094 - accuracy: 0.6759 - val_loss: 0.6267 - val_accuracy: 0.6493\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 721us/step - loss: 0.6065 - accuracy: 0.6786 - val_loss: 0.6218 - val_accuracy: 0.6538\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.6036 - accuracy: 0.6799 - val_loss: 0.6186 - val_accuracy: 0.6545\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.6019 - accuracy: 0.6825 - val_loss: 0.6203 - val_accuracy: 0.6500\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.5983 - accuracy: 0.6868 - val_loss: 0.6110 - val_accuracy: 0.6604\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.5973 - accuracy: 0.6867 - val_loss: 0.6133 - val_accuracy: 0.6530\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 869us/step - loss: 0.5942 - accuracy: 0.6899 - val_loss: 0.6153 - val_accuracy: 0.6475\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.5916 - accuracy: 0.6925 - val_loss: 0.6099 - val_accuracy: 0.6529\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.5894 - accuracy: 0.6953 - val_loss: 0.6081 - val_accuracy: 0.6555\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5880 - accuracy: 0.6952 - val_loss: 0.6083 - val_accuracy: 0.6550\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.5862 - accuracy: 0.6959 - val_loss: 0.6044 - val_accuracy: 0.6593\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.5846 - accuracy: 0.6977 - val_loss: 0.6048 - val_accuracy: 0.6590\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.5819 - accuracy: 0.6995 - val_loss: 0.6057 - val_accuracy: 0.6560\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.5802 - accuracy: 0.7028 - val_loss: 0.6082 - val_accuracy: 0.6519\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5792 - accuracy: 0.7028 - val_loss: 0.6032 - val_accuracy: 0.6576\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.5761 - accuracy: 0.7061 - val_loss: 0.6049 - val_accuracy: 0.6545\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5743 - accuracy: 0.7070 - val_loss: 0.6044 - val_accuracy: 0.6552\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.5734 - accuracy: 0.7085 - val_loss: 0.6018 - val_accuracy: 0.6566\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.5720 - accuracy: 0.7086 - val_loss: 0.6072 - val_accuracy: 0.6517\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5701 - accuracy: 0.7097 - val_loss: 0.5993 - val_accuracy: 0.6589\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.5689 - accuracy: 0.7118 - val_loss: 0.6047 - val_accuracy: 0.6528\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5676 - accuracy: 0.7120 - val_loss: 0.6039 - val_accuracy: 0.6535\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.5651 - accuracy: 0.7137 - val_loss: 0.5991 - val_accuracy: 0.6568\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.5633 - accuracy: 0.7148 - val_loss: 0.6018 - val_accuracy: 0.6543\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5632 - accuracy: 0.7153 - val_loss: 0.5941 - val_accuracy: 0.6618\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5610 - accuracy: 0.7177 - val_loss: 0.5953 - val_accuracy: 0.6606\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 785us/step - loss: 0.5610 - accuracy: 0.7175 - val_loss: 0.5910 - val_accuracy: 0.6647\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.5588 - accuracy: 0.7187 - val_loss: 0.5970 - val_accuracy: 0.6593\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 819us/step - loss: 0.5577 - accuracy: 0.7203 - val_loss: 0.5941 - val_accuracy: 0.6622\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.5565 - accuracy: 0.7203 - val_loss: 0.5933 - val_accuracy: 0.6616\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 753us/step - loss: 0.5544 - accuracy: 0.7225 - val_loss: 0.5904 - val_accuracy: 0.6631\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.5531 - accuracy: 0.7229 - val_loss: 0.5935 - val_accuracy: 0.6611\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5529 - accuracy: 0.7232 - val_loss: 0.5979 - val_accuracy: 0.6559\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.5514 - accuracy: 0.7238 - val_loss: 0.5967 - val_accuracy: 0.6564\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.5510 - accuracy: 0.7245 - val_loss: 0.5927 - val_accuracy: 0.6590\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.5483 - accuracy: 0.7274 - val_loss: 0.6015 - val_accuracy: 0.6500\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5480 - accuracy: 0.7268 - val_loss: 0.5961 - val_accuracy: 0.6545\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.5466 - accuracy: 0.7266 - val_loss: 0.5938 - val_accuracy: 0.6555\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.6185 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.7128 - accuracy: 0.4985 - val_loss: 0.7424 - val_accuracy: 0.2574\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.7013 - accuracy: 0.5019 - val_loss: 0.7258 - val_accuracy: 0.3212\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 768us/step - loss: 0.6962 - accuracy: 0.5131 - val_loss: 0.7198 - val_accuracy: 0.3431\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.6912 - accuracy: 0.5241 - val_loss: 0.7156 - val_accuracy: 0.3646\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.6856 - accuracy: 0.5400 - val_loss: 0.7130 - val_accuracy: 0.3998\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6816 - accuracy: 0.5516 - val_loss: 0.7039 - val_accuracy: 0.4658\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6774 - accuracy: 0.5650 - val_loss: 0.6971 - val_accuracy: 0.5153\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6730 - accuracy: 0.5787 - val_loss: 0.6945 - val_accuracy: 0.5410\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6687 - accuracy: 0.5915 - val_loss: 0.6863 - val_accuracy: 0.5779\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6648 - accuracy: 0.6009 - val_loss: 0.6837 - val_accuracy: 0.5896\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6622 - accuracy: 0.6084 - val_loss: 0.6801 - val_accuracy: 0.6023\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6593 - accuracy: 0.6156 - val_loss: 0.6759 - val_accuracy: 0.6157\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.6557 - accuracy: 0.6223 - val_loss: 0.6758 - val_accuracy: 0.6135\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.6534 - accuracy: 0.6272 - val_loss: 0.6724 - val_accuracy: 0.6209\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6500 - accuracy: 0.6335 - val_loss: 0.6720 - val_accuracy: 0.6185\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.6484 - accuracy: 0.6371 - val_loss: 0.6702 - val_accuracy: 0.6205\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.6452 - accuracy: 0.6425 - val_loss: 0.6671 - val_accuracy: 0.6244\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6420 - accuracy: 0.6491 - val_loss: 0.6628 - val_accuracy: 0.6307\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6393 - accuracy: 0.6507 - val_loss: 0.6651 - val_accuracy: 0.6240\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 751us/step - loss: 0.6370 - accuracy: 0.6543 - val_loss: 0.6595 - val_accuracy: 0.6330\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.6348 - accuracy: 0.6564 - val_loss: 0.6573 - val_accuracy: 0.6365\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6320 - accuracy: 0.6626 - val_loss: 0.6586 - val_accuracy: 0.6321\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.6289 - accuracy: 0.6645 - val_loss: 0.6548 - val_accuracy: 0.6376\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6266 - accuracy: 0.6672 - val_loss: 0.6529 - val_accuracy: 0.6391\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6247 - accuracy: 0.6680 - val_loss: 0.6505 - val_accuracy: 0.6407\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.6219 - accuracy: 0.6735 - val_loss: 0.6458 - val_accuracy: 0.6479\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6197 - accuracy: 0.6754 - val_loss: 0.6435 - val_accuracy: 0.6508\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6177 - accuracy: 0.6769 - val_loss: 0.6463 - val_accuracy: 0.6430\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6160 - accuracy: 0.6771 - val_loss: 0.6444 - val_accuracy: 0.6458\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6129 - accuracy: 0.6823 - val_loss: 0.6404 - val_accuracy: 0.6510\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.6105 - accuracy: 0.6823 - val_loss: 0.6364 - val_accuracy: 0.6558\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6094 - accuracy: 0.6843 - val_loss: 0.6343 - val_accuracy: 0.6585\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6068 - accuracy: 0.6873 - val_loss: 0.6346 - val_accuracy: 0.6565\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6054 - accuracy: 0.6872 - val_loss: 0.6358 - val_accuracy: 0.6544\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.6023 - accuracy: 0.6905 - val_loss: 0.6296 - val_accuracy: 0.6622\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.5999 - accuracy: 0.6919 - val_loss: 0.6351 - val_accuracy: 0.6519\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5997 - accuracy: 0.6925 - val_loss: 0.6308 - val_accuracy: 0.6573\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.5962 - accuracy: 0.6967 - val_loss: 0.6260 - val_accuracy: 0.6631\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5956 - accuracy: 0.6950 - val_loss: 0.6213 - val_accuracy: 0.6685\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5941 - accuracy: 0.6951 - val_loss: 0.6191 - val_accuracy: 0.6694\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5908 - accuracy: 0.6989 - val_loss: 0.6206 - val_accuracy: 0.6664\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.5893 - accuracy: 0.7002 - val_loss: 0.6154 - val_accuracy: 0.6706\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5879 - accuracy: 0.7026 - val_loss: 0.6186 - val_accuracy: 0.6657\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.5866 - accuracy: 0.7023 - val_loss: 0.6171 - val_accuracy: 0.6657\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5846 - accuracy: 0.7041 - val_loss: 0.6177 - val_accuracy: 0.6636\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.5832 - accuracy: 0.7046 - val_loss: 0.6064 - val_accuracy: 0.6757\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5812 - accuracy: 0.7076 - val_loss: 0.6145 - val_accuracy: 0.6626\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5802 - accuracy: 0.7098 - val_loss: 0.6154 - val_accuracy: 0.6607\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.5784 - accuracy: 0.7095 - val_loss: 0.6109 - val_accuracy: 0.6660\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 806us/step - loss: 0.5767 - accuracy: 0.7107 - val_loss: 0.6111 - val_accuracy: 0.6635\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.6927 - accuracy: 0.5387 - val_loss: 0.7383 - val_accuracy: 0.2720\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6851 - accuracy: 0.5510 - val_loss: 0.7196 - val_accuracy: 0.3850\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.6813 - accuracy: 0.5646 - val_loss: 0.7128 - val_accuracy: 0.4254\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6768 - accuracy: 0.5807 - val_loss: 0.7070 - val_accuracy: 0.4615\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6710 - accuracy: 0.5950 - val_loss: 0.7013 - val_accuracy: 0.4889\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6697 - accuracy: 0.5984 - val_loss: 0.6984 - val_accuracy: 0.5023\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 888us/step - loss: 0.6654 - accuracy: 0.6094 - val_loss: 0.6968 - val_accuracy: 0.5102\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 829us/step - loss: 0.6625 - accuracy: 0.6154 - val_loss: 0.6934 - val_accuracy: 0.5210\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 874us/step - loss: 0.6587 - accuracy: 0.6216 - val_loss: 0.6902 - val_accuracy: 0.5317\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 2s 929us/step - loss: 0.6548 - accuracy: 0.6310 - val_loss: 0.6863 - val_accuracy: 0.5440\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 868us/step - loss: 0.6520 - accuracy: 0.6365 - val_loss: 0.6826 - val_accuracy: 0.5526\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 787us/step - loss: 0.6489 - accuracy: 0.6399 - val_loss: 0.6854 - val_accuracy: 0.5484\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 788us/step - loss: 0.6465 - accuracy: 0.6409 - val_loss: 0.6770 - val_accuracy: 0.5633\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.6433 - accuracy: 0.6476 - val_loss: 0.6733 - val_accuracy: 0.5709\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 784us/step - loss: 0.6407 - accuracy: 0.6519 - val_loss: 0.6734 - val_accuracy: 0.5701\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.6393 - accuracy: 0.6523 - val_loss: 0.6718 - val_accuracy: 0.5736\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 810us/step - loss: 0.6363 - accuracy: 0.6534 - val_loss: 0.6679 - val_accuracy: 0.5814\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 794us/step - loss: 0.6333 - accuracy: 0.6588 - val_loss: 0.6656 - val_accuracy: 0.5859\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 782us/step - loss: 0.6310 - accuracy: 0.6594 - val_loss: 0.6616 - val_accuracy: 0.5907\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 811us/step - loss: 0.6290 - accuracy: 0.6628 - val_loss: 0.6631 - val_accuracy: 0.5898\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 863us/step - loss: 0.6260 - accuracy: 0.6656 - val_loss: 0.6559 - val_accuracy: 0.5985\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 803us/step - loss: 0.6229 - accuracy: 0.6668 - val_loss: 0.6571 - val_accuracy: 0.5969\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.6215 - accuracy: 0.6687 - val_loss: 0.6534 - val_accuracy: 0.6016\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.6192 - accuracy: 0.6710 - val_loss: 0.6543 - val_accuracy: 0.6005\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 823us/step - loss: 0.6170 - accuracy: 0.6731 - val_loss: 0.6470 - val_accuracy: 0.6100\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.6149 - accuracy: 0.6761 - val_loss: 0.6472 - val_accuracy: 0.6100\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 776us/step - loss: 0.6126 - accuracy: 0.6772 - val_loss: 0.6461 - val_accuracy: 0.6106\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.6112 - accuracy: 0.6794 - val_loss: 0.6441 - val_accuracy: 0.6128\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.6091 - accuracy: 0.6775 - val_loss: 0.6367 - val_accuracy: 0.6203\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 789us/step - loss: 0.6065 - accuracy: 0.6826 - val_loss: 0.6418 - val_accuracy: 0.6154\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 801us/step - loss: 0.6058 - accuracy: 0.6810 - val_loss: 0.6365 - val_accuracy: 0.6193\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 787us/step - loss: 0.6041 - accuracy: 0.6829 - val_loss: 0.6343 - val_accuracy: 0.6216\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 884us/step - loss: 0.6018 - accuracy: 0.6852 - val_loss: 0.6301 - val_accuracy: 0.6248\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 775us/step - loss: 0.6005 - accuracy: 0.6846 - val_loss: 0.6336 - val_accuracy: 0.6209\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 795us/step - loss: 0.5980 - accuracy: 0.6889 - val_loss: 0.6317 - val_accuracy: 0.6225\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5975 - accuracy: 0.6873 - val_loss: 0.6315 - val_accuracy: 0.6226\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 775us/step - loss: 0.5950 - accuracy: 0.6893 - val_loss: 0.6255 - val_accuracy: 0.6262\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.5934 - accuracy: 0.6927 - val_loss: 0.6295 - val_accuracy: 0.6237\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 829us/step - loss: 0.5917 - accuracy: 0.6922 - val_loss: 0.6292 - val_accuracy: 0.6234\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 2s 913us/step - loss: 0.5903 - accuracy: 0.6931 - val_loss: 0.6264 - val_accuracy: 0.6245\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 872us/step - loss: 0.5903 - accuracy: 0.6924 - val_loss: 0.6284 - val_accuracy: 0.6222\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.5874 - accuracy: 0.6951 - val_loss: 0.6218 - val_accuracy: 0.6269\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.5859 - accuracy: 0.6955 - val_loss: 0.6250 - val_accuracy: 0.6236\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 2s 910us/step - loss: 0.5845 - accuracy: 0.6977 - val_loss: 0.6159 - val_accuracy: 0.6328\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 791us/step - loss: 0.5835 - accuracy: 0.6999 - val_loss: 0.6266 - val_accuracy: 0.6231\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 803us/step - loss: 0.5821 - accuracy: 0.7004 - val_loss: 0.6214 - val_accuracy: 0.6261\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 800us/step - loss: 0.5802 - accuracy: 0.7005 - val_loss: 0.6187 - val_accuracy: 0.6292\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 779us/step - loss: 0.5783 - accuracy: 0.7029 - val_loss: 0.6228 - val_accuracy: 0.6268\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.5778 - accuracy: 0.7022 - val_loss: 0.6151 - val_accuracy: 0.6370\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 764us/step - loss: 0.5764 - accuracy: 0.7036 - val_loss: 0.6161 - val_accuracy: 0.6354\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 807us/step - loss: 0.7005 - accuracy: 0.5356 - val_loss: 0.6833 - val_accuracy: 0.5877\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 782us/step - loss: 0.6864 - accuracy: 0.5601 - val_loss: 0.6979 - val_accuracy: 0.5198\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 811us/step - loss: 0.6794 - accuracy: 0.5735 - val_loss: 0.6914 - val_accuracy: 0.5414\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 790us/step - loss: 0.6752 - accuracy: 0.5842 - val_loss: 0.6860 - val_accuracy: 0.5544\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 772us/step - loss: 0.6707 - accuracy: 0.5937 - val_loss: 0.6788 - val_accuracy: 0.5766\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 870us/step - loss: 0.6655 - accuracy: 0.6047 - val_loss: 0.6749 - val_accuracy: 0.5927\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 802us/step - loss: 0.6612 - accuracy: 0.6122 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 736us/step - loss: 0.6583 - accuracy: 0.6175 - val_loss: 0.6685 - val_accuracy: 0.6104\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 831us/step - loss: 0.6548 - accuracy: 0.6264 - val_loss: 0.6666 - val_accuracy: 0.6120\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 778us/step - loss: 0.6526 - accuracy: 0.6302 - val_loss: 0.6677 - val_accuracy: 0.6077\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.6489 - accuracy: 0.6358 - val_loss: 0.6636 - val_accuracy: 0.6140\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 793us/step - loss: 0.6463 - accuracy: 0.6412 - val_loss: 0.6661 - val_accuracy: 0.6053\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.6439 - accuracy: 0.6442 - val_loss: 0.6610 - val_accuracy: 0.6124\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.6403 - accuracy: 0.6514 - val_loss: 0.6595 - val_accuracy: 0.6130\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 724us/step - loss: 0.6373 - accuracy: 0.6530 - val_loss: 0.6601 - val_accuracy: 0.6084\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 2s 924us/step - loss: 0.6350 - accuracy: 0.6571 - val_loss: 0.6516 - val_accuracy: 0.6215\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 763us/step - loss: 0.6323 - accuracy: 0.6614 - val_loss: 0.6545 - val_accuracy: 0.6116\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.6302 - accuracy: 0.6643 - val_loss: 0.6496 - val_accuracy: 0.6168\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 797us/step - loss: 0.6265 - accuracy: 0.6675 - val_loss: 0.6515 - val_accuracy: 0.6102\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6251 - accuracy: 0.6688 - val_loss: 0.6453 - val_accuracy: 0.6182\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6233 - accuracy: 0.6711 - val_loss: 0.6447 - val_accuracy: 0.6171\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.6209 - accuracy: 0.6732 - val_loss: 0.6441 - val_accuracy: 0.6153\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6179 - accuracy: 0.6768 - val_loss: 0.6421 - val_accuracy: 0.6177\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.6158 - accuracy: 0.6788 - val_loss: 0.6417 - val_accuracy: 0.6168\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6136 - accuracy: 0.6838 - val_loss: 0.6359 - val_accuracy: 0.6256\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6114 - accuracy: 0.6836 - val_loss: 0.6336 - val_accuracy: 0.6282\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.6105 - accuracy: 0.6839 - val_loss: 0.6343 - val_accuracy: 0.6253\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 882us/step - loss: 0.6085 - accuracy: 0.6855 - val_loss: 0.6324 - val_accuracy: 0.6289\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 813us/step - loss: 0.6057 - accuracy: 0.6884 - val_loss: 0.6327 - val_accuracy: 0.6280\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6045 - accuracy: 0.6894 - val_loss: 0.6267 - val_accuracy: 0.6371\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6024 - accuracy: 0.6938 - val_loss: 0.6241 - val_accuracy: 0.6401\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.6012 - accuracy: 0.6911 - val_loss: 0.6297 - val_accuracy: 0.6347\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5988 - accuracy: 0.6937 - val_loss: 0.6262 - val_accuracy: 0.6375\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.5969 - accuracy: 0.6952 - val_loss: 0.6286 - val_accuracy: 0.6360\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.5955 - accuracy: 0.6951 - val_loss: 0.6227 - val_accuracy: 0.6404\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.5943 - accuracy: 0.6947 - val_loss: 0.6231 - val_accuracy: 0.6402\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.5927 - accuracy: 0.6965 - val_loss: 0.6191 - val_accuracy: 0.6439\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.5902 - accuracy: 0.6999 - val_loss: 0.6149 - val_accuracy: 0.6483\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5897 - accuracy: 0.6982 - val_loss: 0.6214 - val_accuracy: 0.6412\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.5877 - accuracy: 0.6985 - val_loss: 0.6127 - val_accuracy: 0.6497\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.5858 - accuracy: 0.7022 - val_loss: 0.6192 - val_accuracy: 0.6457\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.5852 - accuracy: 0.7004 - val_loss: 0.6128 - val_accuracy: 0.6498\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.5818 - accuracy: 0.7053 - val_loss: 0.6141 - val_accuracy: 0.6489\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.5809 - accuracy: 0.7050 - val_loss: 0.6163 - val_accuracy: 0.6462\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5788 - accuracy: 0.7043 - val_loss: 0.6250 - val_accuracy: 0.6404\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.5765 - accuracy: 0.7094 - val_loss: 0.6170 - val_accuracy: 0.6456\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5750 - accuracy: 0.7084 - val_loss: 0.6145 - val_accuracy: 0.6467\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 690us/step - loss: 0.5728 - accuracy: 0.7096 - val_loss: 0.6139 - val_accuracy: 0.6469\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.5721 - accuracy: 0.7102 - val_loss: 0.6128 - val_accuracy: 0.6466\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.5702 - accuracy: 0.7115 - val_loss: 0.6135 - val_accuracy: 0.6461\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 706us/step - loss: 0.7120 - accuracy: 0.4906 - val_loss: 0.7135 - val_accuracy: 0.4017\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6978 - accuracy: 0.5172 - val_loss: 0.7224 - val_accuracy: 0.3382\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6906 - accuracy: 0.5341 - val_loss: 0.7158 - val_accuracy: 0.3763\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6852 - accuracy: 0.5507 - val_loss: 0.7103 - val_accuracy: 0.4205\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6794 - accuracy: 0.5675 - val_loss: 0.7027 - val_accuracy: 0.4641\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 779us/step - loss: 0.6749 - accuracy: 0.5775 - val_loss: 0.7017 - val_accuracy: 0.4715\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6720 - accuracy: 0.5835 - val_loss: 0.6960 - val_accuracy: 0.5022\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6676 - accuracy: 0.5939 - val_loss: 0.6882 - val_accuracy: 0.5287\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.6639 - accuracy: 0.6046 - val_loss: 0.6847 - val_accuracy: 0.5405\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6601 - accuracy: 0.6157 - val_loss: 0.6798 - val_accuracy: 0.5542\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.6570 - accuracy: 0.6179 - val_loss: 0.6781 - val_accuracy: 0.5578\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.6545 - accuracy: 0.6244 - val_loss: 0.6763 - val_accuracy: 0.5605\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.6512 - accuracy: 0.6315 - val_loss: 0.6756 - val_accuracy: 0.5616\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.6493 - accuracy: 0.6334 - val_loss: 0.6722 - val_accuracy: 0.5668\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6474 - accuracy: 0.6360 - val_loss: 0.6668 - val_accuracy: 0.5823\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6441 - accuracy: 0.6398 - val_loss: 0.6663 - val_accuracy: 0.5800\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.6425 - accuracy: 0.6420 - val_loss: 0.6631 - val_accuracy: 0.5865\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.6386 - accuracy: 0.6471 - val_loss: 0.6619 - val_accuracy: 0.5870\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6352 - accuracy: 0.6562 - val_loss: 0.6582 - val_accuracy: 0.5919\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6330 - accuracy: 0.6568 - val_loss: 0.6514 - val_accuracy: 0.6036\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6312 - accuracy: 0.6556 - val_loss: 0.6534 - val_accuracy: 0.5974\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6280 - accuracy: 0.6604 - val_loss: 0.6508 - val_accuracy: 0.5994\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6256 - accuracy: 0.6618 - val_loss: 0.6475 - val_accuracy: 0.6022\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.6240 - accuracy: 0.6626 - val_loss: 0.6481 - val_accuracy: 0.5999\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6218 - accuracy: 0.6653 - val_loss: 0.6419 - val_accuracy: 0.6064\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6184 - accuracy: 0.6694 - val_loss: 0.6413 - val_accuracy: 0.6049\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.6168 - accuracy: 0.6713 - val_loss: 0.6410 - val_accuracy: 0.6038\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.6147 - accuracy: 0.6734 - val_loss: 0.6383 - val_accuracy: 0.6074\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6121 - accuracy: 0.6736 - val_loss: 0.6369 - val_accuracy: 0.6090\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6101 - accuracy: 0.6751 - val_loss: 0.6375 - val_accuracy: 0.6073\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.6088 - accuracy: 0.6772 - val_loss: 0.6332 - val_accuracy: 0.6122\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6069 - accuracy: 0.6775 - val_loss: 0.6334 - val_accuracy: 0.6114\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.6030 - accuracy: 0.6823 - val_loss: 0.6254 - val_accuracy: 0.6226\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6027 - accuracy: 0.6810 - val_loss: 0.6288 - val_accuracy: 0.6177\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5998 - accuracy: 0.6836 - val_loss: 0.6316 - val_accuracy: 0.6140\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.5976 - accuracy: 0.6846 - val_loss: 0.6266 - val_accuracy: 0.6192\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5957 - accuracy: 0.6855 - val_loss: 0.6267 - val_accuracy: 0.6180\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.5950 - accuracy: 0.6858 - val_loss: 0.6234 - val_accuracy: 0.6209\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.5935 - accuracy: 0.6879 - val_loss: 0.6177 - val_accuracy: 0.6251\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.5915 - accuracy: 0.6905 - val_loss: 0.6196 - val_accuracy: 0.6219\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.5893 - accuracy: 0.6916 - val_loss: 0.6215 - val_accuracy: 0.6188\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.5882 - accuracy: 0.6925 - val_loss: 0.6195 - val_accuracy: 0.6204\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5864 - accuracy: 0.6950 - val_loss: 0.6178 - val_accuracy: 0.6221\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.5856 - accuracy: 0.6937 - val_loss: 0.6152 - val_accuracy: 0.6250\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5843 - accuracy: 0.6962 - val_loss: 0.6159 - val_accuracy: 0.6230\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.5824 - accuracy: 0.6964 - val_loss: 0.6241 - val_accuracy: 0.6155\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.5809 - accuracy: 0.6998 - val_loss: 0.6143 - val_accuracy: 0.6258\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.5790 - accuracy: 0.7023 - val_loss: 0.6034 - val_accuracy: 0.6368\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.5777 - accuracy: 0.7024 - val_loss: 0.6207 - val_accuracy: 0.6188\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.5770 - accuracy: 0.7002 - val_loss: 0.6048 - val_accuracy: 0.6361\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 719us/step - loss: 0.7262 - accuracy: 0.4903 - val_loss: 0.7024 - val_accuracy: 0.4715\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 781us/step - loss: 0.7022 - accuracy: 0.5206 - val_loss: 0.7118 - val_accuracy: 0.4563\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6949 - accuracy: 0.5350 - val_loss: 0.6993 - val_accuracy: 0.5107\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 2s 1ms/step - loss: 0.6866 - accuracy: 0.5532 - val_loss: 0.6938 - val_accuracy: 0.5317\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2s 925us/step - loss: 0.6793 - accuracy: 0.5745 - val_loss: 0.6813 - val_accuracy: 0.5673\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 747us/step - loss: 0.6744 - accuracy: 0.5850 - val_loss: 0.6756 - val_accuracy: 0.5856\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 755us/step - loss: 0.6672 - accuracy: 0.6009 - val_loss: 0.6713 - val_accuracy: 0.5943\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.6636 - accuracy: 0.6049 - val_loss: 0.6733 - val_accuracy: 0.5907\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 809us/step - loss: 0.6597 - accuracy: 0.6158 - val_loss: 0.6648 - val_accuracy: 0.6023\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.6549 - accuracy: 0.6258 - val_loss: 0.6643 - val_accuracy: 0.6011\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 894us/step - loss: 0.6507 - accuracy: 0.6332 - val_loss: 0.6606 - val_accuracy: 0.6050\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 753us/step - loss: 0.6478 - accuracy: 0.6397 - val_loss: 0.6593 - val_accuracy: 0.6029\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.6440 - accuracy: 0.6461 - val_loss: 0.6524 - val_accuracy: 0.6095\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 775us/step - loss: 0.6408 - accuracy: 0.6498 - val_loss: 0.6556 - val_accuracy: 0.6058\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 859us/step - loss: 0.6377 - accuracy: 0.6543 - val_loss: 0.6513 - val_accuracy: 0.6122\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 789us/step - loss: 0.6337 - accuracy: 0.6614 - val_loss: 0.6515 - val_accuracy: 0.6123\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 813us/step - loss: 0.6306 - accuracy: 0.6640 - val_loss: 0.6440 - val_accuracy: 0.6198\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 788us/step - loss: 0.6276 - accuracy: 0.6666 - val_loss: 0.6444 - val_accuracy: 0.6197\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 804us/step - loss: 0.6250 - accuracy: 0.6720 - val_loss: 0.6398 - val_accuracy: 0.6242\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 834us/step - loss: 0.6228 - accuracy: 0.6719 - val_loss: 0.6406 - val_accuracy: 0.6217\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 765us/step - loss: 0.6200 - accuracy: 0.6745 - val_loss: 0.6352 - val_accuracy: 0.6281\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 787us/step - loss: 0.6166 - accuracy: 0.6810 - val_loss: 0.6340 - val_accuracy: 0.6294\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 812us/step - loss: 0.6150 - accuracy: 0.6802 - val_loss: 0.6395 - val_accuracy: 0.6227\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 801us/step - loss: 0.6126 - accuracy: 0.6841 - val_loss: 0.6359 - val_accuracy: 0.6263\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 779us/step - loss: 0.6098 - accuracy: 0.6858 - val_loss: 0.6389 - val_accuracy: 0.6234\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 786us/step - loss: 0.6079 - accuracy: 0.6866 - val_loss: 0.6275 - val_accuracy: 0.6337\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 842us/step - loss: 0.6053 - accuracy: 0.6898 - val_loss: 0.6307 - val_accuracy: 0.6319\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 848us/step - loss: 0.6038 - accuracy: 0.6920 - val_loss: 0.6262 - val_accuracy: 0.6351\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 829us/step - loss: 0.6015 - accuracy: 0.6927 - val_loss: 0.6274 - val_accuracy: 0.6339\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 888us/step - loss: 0.5999 - accuracy: 0.6942 - val_loss: 0.6237 - val_accuracy: 0.6382\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 827us/step - loss: 0.5982 - accuracy: 0.6956 - val_loss: 0.6245 - val_accuracy: 0.6373\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 843us/step - loss: 0.5956 - accuracy: 0.6952 - val_loss: 0.6237 - val_accuracy: 0.6383\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 835us/step - loss: 0.5951 - accuracy: 0.6987 - val_loss: 0.6239 - val_accuracy: 0.6384\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 784us/step - loss: 0.5921 - accuracy: 0.6993 - val_loss: 0.6268 - val_accuracy: 0.6357\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 807us/step - loss: 0.5901 - accuracy: 0.7011 - val_loss: 0.6208 - val_accuracy: 0.6431\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 820us/step - loss: 0.5891 - accuracy: 0.7005 - val_loss: 0.6183 - val_accuracy: 0.6465\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 794us/step - loss: 0.5876 - accuracy: 0.7036 - val_loss: 0.6205 - val_accuracy: 0.6437\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.5854 - accuracy: 0.7059 - val_loss: 0.6183 - val_accuracy: 0.6456\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 789us/step - loss: 0.5840 - accuracy: 0.7059 - val_loss: 0.6180 - val_accuracy: 0.6457\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 793us/step - loss: 0.5825 - accuracy: 0.7085 - val_loss: 0.6111 - val_accuracy: 0.6529\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 794us/step - loss: 0.5798 - accuracy: 0.7096 - val_loss: 0.6066 - val_accuracy: 0.6573\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 868us/step - loss: 0.5786 - accuracy: 0.7110 - val_loss: 0.6130 - val_accuracy: 0.6496\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 833us/step - loss: 0.5771 - accuracy: 0.7123 - val_loss: 0.6104 - val_accuracy: 0.6516\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 796us/step - loss: 0.5742 - accuracy: 0.7135 - val_loss: 0.6156 - val_accuracy: 0.6478\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 812us/step - loss: 0.5747 - accuracy: 0.7128 - val_loss: 0.6053 - val_accuracy: 0.6574\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 816us/step - loss: 0.5725 - accuracy: 0.7145 - val_loss: 0.6045 - val_accuracy: 0.6581\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 809us/step - loss: 0.5695 - accuracy: 0.7178 - val_loss: 0.5984 - val_accuracy: 0.6648\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 811us/step - loss: 0.5703 - accuracy: 0.7136 - val_loss: 0.6087 - val_accuracy: 0.6543\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.5692 - accuracy: 0.7154 - val_loss: 0.6051 - val_accuracy: 0.6568\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 884us/step - loss: 0.5667 - accuracy: 0.7188 - val_loss: 0.6093 - val_accuracy: 0.6518\n",
      "Epoch 1/50\n",
      "1646/1672 [============================>.] - ETA: 0s - loss: 0.7319 - accuracy: 0.4817WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 828us/step - loss: 0.7315 - accuracy: 0.4820 - val_loss: 0.6866 - val_accuracy: 0.5422\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 819us/step - loss: 0.7030 - accuracy: 0.5080 - val_loss: 0.7145 - val_accuracy: 0.4045\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2s 919us/step - loss: 0.6970 - accuracy: 0.5220 - val_loss: 0.7112 - val_accuracy: 0.4184\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 779us/step - loss: 0.6910 - accuracy: 0.5342 - val_loss: 0.7062 - val_accuracy: 0.4317\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.6851 - accuracy: 0.5503 - val_loss: 0.6994 - val_accuracy: 0.4735\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 794us/step - loss: 0.6810 - accuracy: 0.5617 - val_loss: 0.6946 - val_accuracy: 0.5055\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 773us/step - loss: 0.6757 - accuracy: 0.5746 - val_loss: 0.6889 - val_accuracy: 0.5412\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 2s 928us/step - loss: 0.6732 - accuracy: 0.5840 - val_loss: 0.6888 - val_accuracy: 0.5427\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 812us/step - loss: 0.6697 - accuracy: 0.5933 - val_loss: 0.6891 - val_accuracy: 0.5422\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 796us/step - loss: 0.6665 - accuracy: 0.6028 - val_loss: 0.6834 - val_accuracy: 0.5653\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.6621 - accuracy: 0.6133 - val_loss: 0.6787 - val_accuracy: 0.5795\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 779us/step - loss: 0.6605 - accuracy: 0.6150 - val_loss: 0.6773 - val_accuracy: 0.5839\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.6558 - accuracy: 0.6269 - val_loss: 0.6739 - val_accuracy: 0.5943\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 781us/step - loss: 0.6542 - accuracy: 0.6297 - val_loss: 0.6714 - val_accuracy: 0.6009\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 769us/step - loss: 0.6502 - accuracy: 0.6380 - val_loss: 0.6709 - val_accuracy: 0.6026\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.6469 - accuracy: 0.6456 - val_loss: 0.6694 - val_accuracy: 0.6042\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 761us/step - loss: 0.6460 - accuracy: 0.6473 - val_loss: 0.6647 - val_accuracy: 0.6125\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.6420 - accuracy: 0.6505 - val_loss: 0.6661 - val_accuracy: 0.6072\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6399 - accuracy: 0.6536 - val_loss: 0.6631 - val_accuracy: 0.6093\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6367 - accuracy: 0.6573 - val_loss: 0.6580 - val_accuracy: 0.6155\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.6350 - accuracy: 0.6606 - val_loss: 0.6567 - val_accuracy: 0.6138\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 781us/step - loss: 0.6318 - accuracy: 0.6636 - val_loss: 0.6511 - val_accuracy: 0.6207\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6297 - accuracy: 0.6692 - val_loss: 0.6531 - val_accuracy: 0.6143\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 778us/step - loss: 0.6269 - accuracy: 0.6719 - val_loss: 0.6493 - val_accuracy: 0.6187\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.6247 - accuracy: 0.6698 - val_loss: 0.6456 - val_accuracy: 0.6225\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.6228 - accuracy: 0.6743 - val_loss: 0.6429 - val_accuracy: 0.6261\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6209 - accuracy: 0.6746 - val_loss: 0.6428 - val_accuracy: 0.6250\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.6189 - accuracy: 0.6778 - val_loss: 0.6405 - val_accuracy: 0.6274\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6166 - accuracy: 0.6796 - val_loss: 0.6447 - val_accuracy: 0.6199\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.6138 - accuracy: 0.6824 - val_loss: 0.6398 - val_accuracy: 0.6251\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6122 - accuracy: 0.6834 - val_loss: 0.6312 - val_accuracy: 0.6366\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.6115 - accuracy: 0.6847 - val_loss: 0.6377 - val_accuracy: 0.6244\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.6087 - accuracy: 0.6871 - val_loss: 0.6353 - val_accuracy: 0.6268\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.6061 - accuracy: 0.6869 - val_loss: 0.6338 - val_accuracy: 0.6274\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6057 - accuracy: 0.6893 - val_loss: 0.6303 - val_accuracy: 0.6324\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6033 - accuracy: 0.6932 - val_loss: 0.6246 - val_accuracy: 0.6408\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6014 - accuracy: 0.6935 - val_loss: 0.6273 - val_accuracy: 0.6353\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 799us/step - loss: 0.5993 - accuracy: 0.6942 - val_loss: 0.6254 - val_accuracy: 0.6374\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.5972 - accuracy: 0.6968 - val_loss: 0.6300 - val_accuracy: 0.6308\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.5964 - accuracy: 0.6958 - val_loss: 0.6300 - val_accuracy: 0.6298\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.5942 - accuracy: 0.6994 - val_loss: 0.6288 - val_accuracy: 0.6307\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 737us/step - loss: 0.5921 - accuracy: 0.7018 - val_loss: 0.6282 - val_accuracy: 0.6301\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5916 - accuracy: 0.6998 - val_loss: 0.6204 - val_accuracy: 0.6407\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5894 - accuracy: 0.7028 - val_loss: 0.6243 - val_accuracy: 0.6341\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.5876 - accuracy: 0.7033 - val_loss: 0.6200 - val_accuracy: 0.6398\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.5857 - accuracy: 0.7042 - val_loss: 0.6181 - val_accuracy: 0.6413\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5849 - accuracy: 0.7057 - val_loss: 0.6194 - val_accuracy: 0.6386\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 752us/step - loss: 0.5833 - accuracy: 0.7058 - val_loss: 0.6143 - val_accuracy: 0.6445\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.5808 - accuracy: 0.7079 - val_loss: 0.6096 - val_accuracy: 0.6498\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.5796 - accuracy: 0.7097 - val_loss: 0.6122 - val_accuracy: 0.6464\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.7425 - accuracy: 0.5162 - val_loss: 0.7399 - val_accuracy: 0.3514\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.7178 - accuracy: 0.5221 - val_loss: 0.7259 - val_accuracy: 0.4044\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 795us/step - loss: 0.7064 - accuracy: 0.5361 - val_loss: 0.7154 - val_accuracy: 0.4664\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6994 - accuracy: 0.5440 - val_loss: 0.7131 - val_accuracy: 0.4754\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6908 - accuracy: 0.5591 - val_loss: 0.7034 - val_accuracy: 0.5014\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.6831 - accuracy: 0.5718 - val_loss: 0.6926 - val_accuracy: 0.5421\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.6775 - accuracy: 0.5805 - val_loss: 0.6864 - val_accuracy: 0.5698\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.6729 - accuracy: 0.5914 - val_loss: 0.6872 - val_accuracy: 0.5696\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6667 - accuracy: 0.5995 - val_loss: 0.6795 - val_accuracy: 0.5834\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6641 - accuracy: 0.6059 - val_loss: 0.6752 - val_accuracy: 0.5911\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.6596 - accuracy: 0.6161 - val_loss: 0.6718 - val_accuracy: 0.5967\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6550 - accuracy: 0.6242 - val_loss: 0.6712 - val_accuracy: 0.5962\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6499 - accuracy: 0.6337 - val_loss: 0.6626 - val_accuracy: 0.6134\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.6472 - accuracy: 0.6372 - val_loss: 0.6596 - val_accuracy: 0.6179\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6433 - accuracy: 0.6405 - val_loss: 0.6595 - val_accuracy: 0.6161\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6384 - accuracy: 0.6480 - val_loss: 0.6541 - val_accuracy: 0.6232\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.6363 - accuracy: 0.6538 - val_loss: 0.6538 - val_accuracy: 0.6210\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.6324 - accuracy: 0.6601 - val_loss: 0.6470 - val_accuracy: 0.6280\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6312 - accuracy: 0.6609 - val_loss: 0.6492 - val_accuracy: 0.6225\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 851us/step - loss: 0.6285 - accuracy: 0.6642 - val_loss: 0.6397 - val_accuracy: 0.6335\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6260 - accuracy: 0.6664 - val_loss: 0.6423 - val_accuracy: 0.6276\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.6237 - accuracy: 0.6700 - val_loss: 0.6376 - val_accuracy: 0.6323\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.6203 - accuracy: 0.6734 - val_loss: 0.6426 - val_accuracy: 0.6255\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 709us/step - loss: 0.6179 - accuracy: 0.6750 - val_loss: 0.6334 - val_accuracy: 0.6365\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6161 - accuracy: 0.6788 - val_loss: 0.6318 - val_accuracy: 0.6376\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 714us/step - loss: 0.6142 - accuracy: 0.6776 - val_loss: 0.6318 - val_accuracy: 0.6367\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6118 - accuracy: 0.6834 - val_loss: 0.6291 - val_accuracy: 0.6409\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.6094 - accuracy: 0.6855 - val_loss: 0.6282 - val_accuracy: 0.6413\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6066 - accuracy: 0.6877 - val_loss: 0.6297 - val_accuracy: 0.6376\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6051 - accuracy: 0.6919 - val_loss: 0.6294 - val_accuracy: 0.6366\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6031 - accuracy: 0.6910 - val_loss: 0.6233 - val_accuracy: 0.6450\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6010 - accuracy: 0.6936 - val_loss: 0.6208 - val_accuracy: 0.6461\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5998 - accuracy: 0.6920 - val_loss: 0.6177 - val_accuracy: 0.6496\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 744us/step - loss: 0.5985 - accuracy: 0.6966 - val_loss: 0.6257 - val_accuracy: 0.6373\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.5954 - accuracy: 0.6986 - val_loss: 0.6192 - val_accuracy: 0.6446\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 794us/step - loss: 0.5944 - accuracy: 0.6977 - val_loss: 0.6203 - val_accuracy: 0.6424\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.5914 - accuracy: 0.7008 - val_loss: 0.6132 - val_accuracy: 0.6500\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5901 - accuracy: 0.7016 - val_loss: 0.6138 - val_accuracy: 0.6486\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5894 - accuracy: 0.7029 - val_loss: 0.6154 - val_accuracy: 0.6460\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.5883 - accuracy: 0.7038 - val_loss: 0.6165 - val_accuracy: 0.6449\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5859 - accuracy: 0.7051 - val_loss: 0.6105 - val_accuracy: 0.6503\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5848 - accuracy: 0.7067 - val_loss: 0.6114 - val_accuracy: 0.6495\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.5835 - accuracy: 0.7068 - val_loss: 0.6139 - val_accuracy: 0.6467\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5821 - accuracy: 0.7069 - val_loss: 0.6072 - val_accuracy: 0.6529\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.5807 - accuracy: 0.7098 - val_loss: 0.6133 - val_accuracy: 0.6474\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.5791 - accuracy: 0.7096 - val_loss: 0.6049 - val_accuracy: 0.6549\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.5782 - accuracy: 0.7115 - val_loss: 0.6109 - val_accuracy: 0.6485\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5755 - accuracy: 0.7127 - val_loss: 0.6072 - val_accuracy: 0.6521\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.5738 - accuracy: 0.7142 - val_loss: 0.6045 - val_accuracy: 0.6534\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 2s 971us/step - loss: 0.5737 - accuracy: 0.7139 - val_loss: 0.6064 - val_accuracy: 0.6517\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 799us/step - loss: 0.6994 - accuracy: 0.5165 - val_loss: 0.7267 - val_accuracy: 0.4094\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 910us/step - loss: 0.6938 - accuracy: 0.5262 - val_loss: 0.7201 - val_accuracy: 0.4184\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 800us/step - loss: 0.6872 - accuracy: 0.5491 - val_loss: 0.7147 - val_accuracy: 0.4129\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 885us/step - loss: 0.6847 - accuracy: 0.5526 - val_loss: 0.7130 - val_accuracy: 0.4225\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 788us/step - loss: 0.6804 - accuracy: 0.5646 - val_loss: 0.7052 - val_accuracy: 0.4593\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.6772 - accuracy: 0.5718 - val_loss: 0.6995 - val_accuracy: 0.4769\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 818us/step - loss: 0.6740 - accuracy: 0.5823 - val_loss: 0.7069 - val_accuracy: 0.4620\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 789us/step - loss: 0.6710 - accuracy: 0.5886 - val_loss: 0.6963 - val_accuracy: 0.4968\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.6693 - accuracy: 0.5930 - val_loss: 0.6975 - val_accuracy: 0.4986\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 792us/step - loss: 0.6663 - accuracy: 0.6003 - val_loss: 0.6913 - val_accuracy: 0.5206\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 835us/step - loss: 0.6637 - accuracy: 0.6021 - val_loss: 0.6918 - val_accuracy: 0.5194\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.6612 - accuracy: 0.6101 - val_loss: 0.6890 - val_accuracy: 0.5273\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 776us/step - loss: 0.6590 - accuracy: 0.6138 - val_loss: 0.6865 - val_accuracy: 0.5344\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 812us/step - loss: 0.6579 - accuracy: 0.6191 - val_loss: 0.6870 - val_accuracy: 0.5359\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 778us/step - loss: 0.6548 - accuracy: 0.6222 - val_loss: 0.6828 - val_accuracy: 0.5469\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.6527 - accuracy: 0.6250 - val_loss: 0.6808 - val_accuracy: 0.5550\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6502 - accuracy: 0.6271 - val_loss: 0.6759 - val_accuracy: 0.5681\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 780us/step - loss: 0.6483 - accuracy: 0.6318 - val_loss: 0.6743 - val_accuracy: 0.5751\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 816us/step - loss: 0.6464 - accuracy: 0.6353 - val_loss: 0.6738 - val_accuracy: 0.5783\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 783us/step - loss: 0.6440 - accuracy: 0.6367 - val_loss: 0.6693 - val_accuracy: 0.5884\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.6424 - accuracy: 0.6383 - val_loss: 0.6717 - val_accuracy: 0.5854\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 2s 898us/step - loss: 0.6401 - accuracy: 0.6420 - val_loss: 0.6679 - val_accuracy: 0.5921\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6380 - accuracy: 0.6432 - val_loss: 0.6649 - val_accuracy: 0.5975\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 883us/step - loss: 0.6373 - accuracy: 0.6460 - val_loss: 0.6664 - val_accuracy: 0.5948\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 793us/step - loss: 0.6358 - accuracy: 0.6481 - val_loss: 0.6611 - val_accuracy: 0.6037\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 785us/step - loss: 0.6323 - accuracy: 0.6514 - val_loss: 0.6614 - val_accuracy: 0.6023\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 759us/step - loss: 0.6312 - accuracy: 0.6519 - val_loss: 0.6568 - val_accuracy: 0.6092\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 807us/step - loss: 0.6293 - accuracy: 0.6535 - val_loss: 0.6585 - val_accuracy: 0.6058\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 792us/step - loss: 0.6291 - accuracy: 0.6555 - val_loss: 0.6503 - val_accuracy: 0.6225\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 810us/step - loss: 0.6262 - accuracy: 0.6589 - val_loss: 0.6530 - val_accuracy: 0.6154\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.6254 - accuracy: 0.6566 - val_loss: 0.6472 - val_accuracy: 0.6278\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 768us/step - loss: 0.6239 - accuracy: 0.6611 - val_loss: 0.6500 - val_accuracy: 0.6201\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 783us/step - loss: 0.6217 - accuracy: 0.6612 - val_loss: 0.6450 - val_accuracy: 0.6298\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 879us/step - loss: 0.6207 - accuracy: 0.6625 - val_loss: 0.6466 - val_accuracy: 0.6246\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 798us/step - loss: 0.6185 - accuracy: 0.6671 - val_loss: 0.6477 - val_accuracy: 0.6207\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 830us/step - loss: 0.6172 - accuracy: 0.6668 - val_loss: 0.6403 - val_accuracy: 0.6355\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 808us/step - loss: 0.6155 - accuracy: 0.6688 - val_loss: 0.6435 - val_accuracy: 0.6298\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 794us/step - loss: 0.6136 - accuracy: 0.6703 - val_loss: 0.6428 - val_accuracy: 0.6293\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 791us/step - loss: 0.6127 - accuracy: 0.6699 - val_loss: 0.6444 - val_accuracy: 0.6221\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.6117 - accuracy: 0.6693 - val_loss: 0.6388 - val_accuracy: 0.6324\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 776us/step - loss: 0.6095 - accuracy: 0.6726 - val_loss: 0.6392 - val_accuracy: 0.6307\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 781us/step - loss: 0.6084 - accuracy: 0.6760 - val_loss: 0.6396 - val_accuracy: 0.6280\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 813us/step - loss: 0.6064 - accuracy: 0.6766 - val_loss: 0.6372 - val_accuracy: 0.6301\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 741us/step - loss: 0.6048 - accuracy: 0.6773 - val_loss: 0.6356 - val_accuracy: 0.6312\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 812us/step - loss: 0.6046 - accuracy: 0.6790 - val_loss: 0.6390 - val_accuracy: 0.6249\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 850us/step - loss: 0.6024 - accuracy: 0.6802 - val_loss: 0.6355 - val_accuracy: 0.6290\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 819us/step - loss: 0.6005 - accuracy: 0.6829 - val_loss: 0.6338 - val_accuracy: 0.6293\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 777us/step - loss: 0.5998 - accuracy: 0.6829 - val_loss: 0.6291 - val_accuracy: 0.6341\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 744us/step - loss: 0.5986 - accuracy: 0.6847 - val_loss: 0.6263 - val_accuracy: 0.6365\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 762us/step - loss: 0.5976 - accuracy: 0.6841 - val_loss: 0.6266 - val_accuracy: 0.6349\n",
      "\n",
      "Training model with batch_size=64, target_eps=0.5...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 5.05 iterated over 41800 steps satisfies differential privacy with eps = 0.245 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.5749999999999997 iterated over 41800 steps satisfies differential privacy with eps = 0.481 and delta = 1e-05.\n",
      "The optimal RDP order is 49.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3375 iterated over 41800 steps satisfies differential privacy with eps = 1.05 and delta = 1e-05.\n",
      "The optimal RDP order is 22.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.9562499999999998 iterated over 41800 steps satisfies differential privacy with eps = 0.655 and delta = 1e-05.\n",
      "The optimal RDP order is 36.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.265625 iterated over 41800 steps satisfies differential privacy with eps = 0.554 and delta = 1e-05.\n",
      "The optimal RDP order is 43.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.4203124999999996 iterated over 41800 steps satisfies differential privacy with eps = 0.515 and delta = 1e-05.\n",
      "The optimal RDP order is 46.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.4976562499999995 iterated over 41800 steps satisfies differential privacy with eps = 0.497 and delta = 1e-05.\n",
      "The optimal RDP order is 48.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 929us/step - loss: 0.7100 - accuracy: 0.5268 - val_loss: 0.7849 - val_accuracy: 0.1689\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6909 - accuracy: 0.5357 - val_loss: 0.7338 - val_accuracy: 0.2928\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 927us/step - loss: 0.6868 - accuracy: 0.5440 - val_loss: 0.7192 - val_accuracy: 0.3633\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6842 - accuracy: 0.5520 - val_loss: 0.7151 - val_accuracy: 0.3878\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 927us/step - loss: 0.6812 - accuracy: 0.5582 - val_loss: 0.7121 - val_accuracy: 0.4105\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.6795 - accuracy: 0.5644 - val_loss: 0.7084 - val_accuracy: 0.4400\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6754 - accuracy: 0.5718 - val_loss: 0.7066 - val_accuracy: 0.4574\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 961us/step - loss: 0.6740 - accuracy: 0.5755 - val_loss: 0.7051 - val_accuracy: 0.4736\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 893us/step - loss: 0.6716 - accuracy: 0.5843 - val_loss: 0.7003 - val_accuracy: 0.5002\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 861us/step - loss: 0.6691 - accuracy: 0.5904 - val_loss: 0.6986 - val_accuracy: 0.5153\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 868us/step - loss: 0.6667 - accuracy: 0.6002 - val_loss: 0.6970 - val_accuracy: 0.5242\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 942us/step - loss: 0.6646 - accuracy: 0.6020 - val_loss: 0.6939 - val_accuracy: 0.5361\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6604 - accuracy: 0.6108 - val_loss: 0.6905 - val_accuracy: 0.5446\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 896us/step - loss: 0.6595 - accuracy: 0.6134 - val_loss: 0.6873 - val_accuracy: 0.5545\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 867us/step - loss: 0.6577 - accuracy: 0.6172 - val_loss: 0.6852 - val_accuracy: 0.5579\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 891us/step - loss: 0.6555 - accuracy: 0.6206 - val_loss: 0.6835 - val_accuracy: 0.5629\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6537 - accuracy: 0.6247 - val_loss: 0.6818 - val_accuracy: 0.5698\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 930us/step - loss: 0.6506 - accuracy: 0.6297 - val_loss: 0.6823 - val_accuracy: 0.5693\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 895us/step - loss: 0.6500 - accuracy: 0.6311 - val_loss: 0.6789 - val_accuracy: 0.5776\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 874us/step - loss: 0.6489 - accuracy: 0.6330 - val_loss: 0.6751 - val_accuracy: 0.5835\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6471 - accuracy: 0.6363 - val_loss: 0.6733 - val_accuracy: 0.5869\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6442 - accuracy: 0.6424 - val_loss: 0.6719 - val_accuracy: 0.5875\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6432 - accuracy: 0.6438 - val_loss: 0.6715 - val_accuracy: 0.5881\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 884us/step - loss: 0.6412 - accuracy: 0.6460 - val_loss: 0.6693 - val_accuracy: 0.5918\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6396 - accuracy: 0.6500 - val_loss: 0.6670 - val_accuracy: 0.5952\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 810us/step - loss: 0.6387 - accuracy: 0.6493 - val_loss: 0.6652 - val_accuracy: 0.5988\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6368 - accuracy: 0.6535 - val_loss: 0.6649 - val_accuracy: 0.5984\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6365 - accuracy: 0.6515 - val_loss: 0.6628 - val_accuracy: 0.6020\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6351 - accuracy: 0.6574 - val_loss: 0.6615 - val_accuracy: 0.6048\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 778us/step - loss: 0.6321 - accuracy: 0.6585 - val_loss: 0.6627 - val_accuracy: 0.6032\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6319 - accuracy: 0.6613 - val_loss: 0.6589 - val_accuracy: 0.6093\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6299 - accuracy: 0.6616 - val_loss: 0.6585 - val_accuracy: 0.6102\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6281 - accuracy: 0.6639 - val_loss: 0.6575 - val_accuracy: 0.6121\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 795us/step - loss: 0.6274 - accuracy: 0.6644 - val_loss: 0.6537 - val_accuracy: 0.6164\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6251 - accuracy: 0.6709 - val_loss: 0.6517 - val_accuracy: 0.6195\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6247 - accuracy: 0.6677 - val_loss: 0.6521 - val_accuracy: 0.6187\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6230 - accuracy: 0.6701 - val_loss: 0.6509 - val_accuracy: 0.6209\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6230 - accuracy: 0.6695 - val_loss: 0.6489 - val_accuracy: 0.6242\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.6211 - accuracy: 0.6715 - val_loss: 0.6494 - val_accuracy: 0.6230\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 794us/step - loss: 0.6181 - accuracy: 0.6759 - val_loss: 0.6470 - val_accuracy: 0.6262\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6185 - accuracy: 0.6733 - val_loss: 0.6457 - val_accuracy: 0.6281\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6167 - accuracy: 0.6768 - val_loss: 0.6427 - val_accuracy: 0.6326\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6160 - accuracy: 0.6779 - val_loss: 0.6450 - val_accuracy: 0.6292\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6146 - accuracy: 0.6782 - val_loss: 0.6435 - val_accuracy: 0.6309\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6135 - accuracy: 0.6784 - val_loss: 0.6414 - val_accuracy: 0.6325\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6114 - accuracy: 0.6813 - val_loss: 0.6414 - val_accuracy: 0.6322\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 824us/step - loss: 0.6112 - accuracy: 0.6794 - val_loss: 0.6382 - val_accuracy: 0.6364\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6101 - accuracy: 0.6812 - val_loss: 0.6400 - val_accuracy: 0.6330\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6080 - accuracy: 0.6855 - val_loss: 0.6369 - val_accuracy: 0.6368\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 931us/step - loss: 0.6073 - accuracy: 0.6856 - val_loss: 0.6364 - val_accuracy: 0.6373\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.7196 - accuracy: 0.4980 - val_loss: 0.7711 - val_accuracy: 0.2045\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.7064 - accuracy: 0.5044 - val_loss: 0.7268 - val_accuracy: 0.3407\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.6997 - accuracy: 0.5159 - val_loss: 0.7085 - val_accuracy: 0.4400\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6966 - accuracy: 0.5241 - val_loss: 0.7004 - val_accuracy: 0.4869\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6927 - accuracy: 0.5366 - val_loss: 0.6961 - val_accuracy: 0.5090\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 795us/step - loss: 0.6883 - accuracy: 0.5458 - val_loss: 0.6937 - val_accuracy: 0.5217\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 736us/step - loss: 0.6869 - accuracy: 0.5524 - val_loss: 0.6916 - val_accuracy: 0.5353\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6840 - accuracy: 0.5596 - val_loss: 0.6887 - val_accuracy: 0.5527\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6810 - accuracy: 0.5678 - val_loss: 0.6865 - val_accuracy: 0.5636\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6788 - accuracy: 0.5738 - val_loss: 0.6849 - val_accuracy: 0.5646\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6762 - accuracy: 0.5839 - val_loss: 0.6830 - val_accuracy: 0.5696\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6750 - accuracy: 0.5824 - val_loss: 0.6807 - val_accuracy: 0.5790\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6723 - accuracy: 0.5933 - val_loss: 0.6808 - val_accuracy: 0.5788\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6704 - accuracy: 0.5961 - val_loss: 0.6790 - val_accuracy: 0.5849\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6683 - accuracy: 0.6032 - val_loss: 0.6790 - val_accuracy: 0.5840\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6666 - accuracy: 0.6024 - val_loss: 0.6765 - val_accuracy: 0.5935\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6650 - accuracy: 0.6074 - val_loss: 0.6750 - val_accuracy: 0.5984\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 881us/step - loss: 0.6628 - accuracy: 0.6123 - val_loss: 0.6745 - val_accuracy: 0.5980\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 984us/step - loss: 0.6616 - accuracy: 0.6178 - val_loss: 0.6742 - val_accuracy: 0.5979\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6596 - accuracy: 0.6209 - val_loss: 0.6730 - val_accuracy: 0.6005\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.6580 - accuracy: 0.6243 - val_loss: 0.6719 - val_accuracy: 0.6046\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6563 - accuracy: 0.6256 - val_loss: 0.6694 - val_accuracy: 0.6111\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6557 - accuracy: 0.6290 - val_loss: 0.6699 - val_accuracy: 0.6072\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6530 - accuracy: 0.6333 - val_loss: 0.6679 - val_accuracy: 0.6115\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6524 - accuracy: 0.6346 - val_loss: 0.6674 - val_accuracy: 0.6094\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.6513 - accuracy: 0.6373 - val_loss: 0.6663 - val_accuracy: 0.6101\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6495 - accuracy: 0.6399 - val_loss: 0.6657 - val_accuracy: 0.6091\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6477 - accuracy: 0.6449 - val_loss: 0.6644 - val_accuracy: 0.6104\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6472 - accuracy: 0.6444 - val_loss: 0.6625 - val_accuracy: 0.6140\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6453 - accuracy: 0.6477 - val_loss: 0.6619 - val_accuracy: 0.6125\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6450 - accuracy: 0.6466 - val_loss: 0.6613 - val_accuracy: 0.6115\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6424 - accuracy: 0.6517 - val_loss: 0.6604 - val_accuracy: 0.6100\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6417 - accuracy: 0.6532 - val_loss: 0.6592 - val_accuracy: 0.6103\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 771us/step - loss: 0.6403 - accuracy: 0.6556 - val_loss: 0.6583 - val_accuracy: 0.6112\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6387 - accuracy: 0.6574 - val_loss: 0.6560 - val_accuracy: 0.6151\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6382 - accuracy: 0.6585 - val_loss: 0.6565 - val_accuracy: 0.6109\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 856us/step - loss: 0.6366 - accuracy: 0.6602 - val_loss: 0.6559 - val_accuracy: 0.6114\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6352 - accuracy: 0.6605 - val_loss: 0.6548 - val_accuracy: 0.6132\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6339 - accuracy: 0.6630 - val_loss: 0.6545 - val_accuracy: 0.6130\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 800us/step - loss: 0.6335 - accuracy: 0.6640 - val_loss: 0.6520 - val_accuracy: 0.6176\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6318 - accuracy: 0.6667 - val_loss: 0.6518 - val_accuracy: 0.6168\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 973us/step - loss: 0.6310 - accuracy: 0.6647 - val_loss: 0.6532 - val_accuracy: 0.6131\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6291 - accuracy: 0.6701 - val_loss: 0.6526 - val_accuracy: 0.6133\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6285 - accuracy: 0.6699 - val_loss: 0.6494 - val_accuracy: 0.6172\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6272 - accuracy: 0.6712 - val_loss: 0.6484 - val_accuracy: 0.6173\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6259 - accuracy: 0.6724 - val_loss: 0.6480 - val_accuracy: 0.6173\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 861us/step - loss: 0.6242 - accuracy: 0.6735 - val_loss: 0.6463 - val_accuracy: 0.6183\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6225 - accuracy: 0.6772 - val_loss: 0.6457 - val_accuracy: 0.6182\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6223 - accuracy: 0.6760 - val_loss: 0.6434 - val_accuracy: 0.6218\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6213 - accuracy: 0.6773 - val_loss: 0.6437 - val_accuracy: 0.6201\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6878 - accuracy: 0.5482 - val_loss: 0.6514 - val_accuracy: 0.6883\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6771 - accuracy: 0.5670 - val_loss: 0.6769 - val_accuracy: 0.5922\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6742 - accuracy: 0.5770 - val_loss: 0.6786 - val_accuracy: 0.5821\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6716 - accuracy: 0.5793 - val_loss: 0.6802 - val_accuracy: 0.5741\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6687 - accuracy: 0.5852 - val_loss: 0.6792 - val_accuracy: 0.5745\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6667 - accuracy: 0.5923 - val_loss: 0.6780 - val_accuracy: 0.5772\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6648 - accuracy: 0.5946 - val_loss: 0.6749 - val_accuracy: 0.5852\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.6621 - accuracy: 0.5995 - val_loss: 0.6756 - val_accuracy: 0.5804\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6599 - accuracy: 0.6046 - val_loss: 0.6726 - val_accuracy: 0.5865\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6584 - accuracy: 0.6084 - val_loss: 0.6702 - val_accuracy: 0.5916\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6547 - accuracy: 0.6169 - val_loss: 0.6685 - val_accuracy: 0.5938\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 867us/step - loss: 0.6533 - accuracy: 0.6192 - val_loss: 0.6653 - val_accuracy: 0.5987\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 708us/step - loss: 0.6511 - accuracy: 0.6229 - val_loss: 0.6645 - val_accuracy: 0.5968\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6500 - accuracy: 0.6220 - val_loss: 0.6637 - val_accuracy: 0.5941\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 784us/step - loss: 0.6471 - accuracy: 0.6295 - val_loss: 0.6617 - val_accuracy: 0.5952\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 736us/step - loss: 0.6449 - accuracy: 0.6327 - val_loss: 0.6593 - val_accuracy: 0.5995\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6411 - accuracy: 0.6388 - val_loss: 0.6566 - val_accuracy: 0.6021\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6409 - accuracy: 0.6391 - val_loss: 0.6536 - val_accuracy: 0.6048\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6386 - accuracy: 0.6399 - val_loss: 0.6508 - val_accuracy: 0.6078\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6367 - accuracy: 0.6454 - val_loss: 0.6507 - val_accuracy: 0.6073\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6348 - accuracy: 0.6467 - val_loss: 0.6490 - val_accuracy: 0.6100\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6338 - accuracy: 0.6479 - val_loss: 0.6468 - val_accuracy: 0.6124\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6311 - accuracy: 0.6534 - val_loss: 0.6430 - val_accuracy: 0.6164\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6289 - accuracy: 0.6549 - val_loss: 0.6428 - val_accuracy: 0.6163\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6280 - accuracy: 0.6560 - val_loss: 0.6416 - val_accuracy: 0.6165\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6265 - accuracy: 0.6584 - val_loss: 0.6413 - val_accuracy: 0.6163\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6245 - accuracy: 0.6605 - val_loss: 0.6383 - val_accuracy: 0.6197\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.6215 - accuracy: 0.6634 - val_loss: 0.6376 - val_accuracy: 0.6203\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.6207 - accuracy: 0.6658 - val_loss: 0.6351 - val_accuracy: 0.6228\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6212 - accuracy: 0.6644 - val_loss: 0.6363 - val_accuracy: 0.6207\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 807us/step - loss: 0.6179 - accuracy: 0.6666 - val_loss: 0.6330 - val_accuracy: 0.6247\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6165 - accuracy: 0.6692 - val_loss: 0.6337 - val_accuracy: 0.6229\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6146 - accuracy: 0.6711 - val_loss: 0.6289 - val_accuracy: 0.6302\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 801us/step - loss: 0.6137 - accuracy: 0.6717 - val_loss: 0.6300 - val_accuracy: 0.6272\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6129 - accuracy: 0.6731 - val_loss: 0.6297 - val_accuracy: 0.6284\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6107 - accuracy: 0.6774 - val_loss: 0.6271 - val_accuracy: 0.6310\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6099 - accuracy: 0.6756 - val_loss: 0.6280 - val_accuracy: 0.6294\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6084 - accuracy: 0.6795 - val_loss: 0.6283 - val_accuracy: 0.6281\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6083 - accuracy: 0.6767 - val_loss: 0.6260 - val_accuracy: 0.6310\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6063 - accuracy: 0.6777 - val_loss: 0.6226 - val_accuracy: 0.6361\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6055 - accuracy: 0.6797 - val_loss: 0.6208 - val_accuracy: 0.6383\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 902us/step - loss: 0.6045 - accuracy: 0.6809 - val_loss: 0.6216 - val_accuracy: 0.6362\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.6025 - accuracy: 0.6846 - val_loss: 0.6225 - val_accuracy: 0.6349\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6009 - accuracy: 0.6856 - val_loss: 0.6200 - val_accuracy: 0.6384\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6009 - accuracy: 0.6841 - val_loss: 0.6197 - val_accuracy: 0.6377\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.5999 - accuracy: 0.6869 - val_loss: 0.6204 - val_accuracy: 0.6366\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 872us/step - loss: 0.5981 - accuracy: 0.6861 - val_loss: 0.6182 - val_accuracy: 0.6395\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.5970 - accuracy: 0.6883 - val_loss: 0.6184 - val_accuracy: 0.6387\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 926us/step - loss: 0.5952 - accuracy: 0.6897 - val_loss: 0.6181 - val_accuracy: 0.6392\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.5952 - accuracy: 0.6881 - val_loss: 0.6178 - val_accuracy: 0.6383\n",
      "Epoch 1/50\n",
      "  1/836 [..............................] - ETA: 0s - loss: 0.6843 - accuracy: 0.5156WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0009s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6858 - accuracy: 0.5537 - val_loss: 0.6526 - val_accuracy: 0.6632\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.6784 - accuracy: 0.5861 - val_loss: 0.6719 - val_accuracy: 0.5741\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6766 - accuracy: 0.5946 - val_loss: 0.6785 - val_accuracy: 0.5504\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6740 - accuracy: 0.6017 - val_loss: 0.6813 - val_accuracy: 0.5398\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6720 - accuracy: 0.6097 - val_loss: 0.6821 - val_accuracy: 0.5343\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6709 - accuracy: 0.6129 - val_loss: 0.6807 - val_accuracy: 0.5377\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6689 - accuracy: 0.6154 - val_loss: 0.6805 - val_accuracy: 0.5400\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 815us/step - loss: 0.6672 - accuracy: 0.6199 - val_loss: 0.6805 - val_accuracy: 0.5389\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6658 - accuracy: 0.6232 - val_loss: 0.6785 - val_accuracy: 0.5447\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6640 - accuracy: 0.6281 - val_loss: 0.6755 - val_accuracy: 0.5545\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 701us/step - loss: 0.6629 - accuracy: 0.6311 - val_loss: 0.6745 - val_accuracy: 0.5580\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 778us/step - loss: 0.6612 - accuracy: 0.6356 - val_loss: 0.6730 - val_accuracy: 0.5618\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 872us/step - loss: 0.6599 - accuracy: 0.6377 - val_loss: 0.6725 - val_accuracy: 0.5632\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6581 - accuracy: 0.6423 - val_loss: 0.6708 - val_accuracy: 0.5684\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6567 - accuracy: 0.6424 - val_loss: 0.6701 - val_accuracy: 0.5697\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6554 - accuracy: 0.6460 - val_loss: 0.6685 - val_accuracy: 0.5741\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 976us/step - loss: 0.6540 - accuracy: 0.6483 - val_loss: 0.6664 - val_accuracy: 0.5841\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 929us/step - loss: 0.6527 - accuracy: 0.6522 - val_loss: 0.6640 - val_accuracy: 0.5938\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.6523 - accuracy: 0.6497 - val_loss: 0.6648 - val_accuracy: 0.5897\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6500 - accuracy: 0.6554 - val_loss: 0.6630 - val_accuracy: 0.5950\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6483 - accuracy: 0.6594 - val_loss: 0.6616 - val_accuracy: 0.5980\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6475 - accuracy: 0.6592 - val_loss: 0.6609 - val_accuracy: 0.5988\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 984us/step - loss: 0.6460 - accuracy: 0.6608 - val_loss: 0.6598 - val_accuracy: 0.6013\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 903us/step - loss: 0.6448 - accuracy: 0.6616 - val_loss: 0.6596 - val_accuracy: 0.5999\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.6432 - accuracy: 0.6645 - val_loss: 0.6584 - val_accuracy: 0.6012\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 914us/step - loss: 0.6416 - accuracy: 0.6651 - val_loss: 0.6573 - val_accuracy: 0.6021\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 893us/step - loss: 0.6409 - accuracy: 0.6686 - val_loss: 0.6552 - val_accuracy: 0.6053\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 934us/step - loss: 0.6401 - accuracy: 0.6678 - val_loss: 0.6548 - val_accuracy: 0.6053\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 937us/step - loss: 0.6389 - accuracy: 0.6708 - val_loss: 0.6523 - val_accuracy: 0.6101\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 932us/step - loss: 0.6375 - accuracy: 0.6711 - val_loss: 0.6526 - val_accuracy: 0.6078\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.6370 - accuracy: 0.6682 - val_loss: 0.6498 - val_accuracy: 0.6131\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 915us/step - loss: 0.6353 - accuracy: 0.6732 - val_loss: 0.6479 - val_accuracy: 0.6163\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 930us/step - loss: 0.6346 - accuracy: 0.6723 - val_loss: 0.6470 - val_accuracy: 0.6163\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6322 - accuracy: 0.6773 - val_loss: 0.6473 - val_accuracy: 0.6137\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 970us/step - loss: 0.6321 - accuracy: 0.6745 - val_loss: 0.6450 - val_accuracy: 0.6192\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 941us/step - loss: 0.6309 - accuracy: 0.6751 - val_loss: 0.6439 - val_accuracy: 0.6207\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 950us/step - loss: 0.6300 - accuracy: 0.6762 - val_loss: 0.6432 - val_accuracy: 0.6221\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 927us/step - loss: 0.6287 - accuracy: 0.6785 - val_loss: 0.6407 - val_accuracy: 0.6282\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 893us/step - loss: 0.6271 - accuracy: 0.6799 - val_loss: 0.6402 - val_accuracy: 0.6283\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6267 - accuracy: 0.6802 - val_loss: 0.6399 - val_accuracy: 0.6287\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.6255 - accuracy: 0.6789 - val_loss: 0.6391 - val_accuracy: 0.6286\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 975us/step - loss: 0.6244 - accuracy: 0.6801 - val_loss: 0.6396 - val_accuracy: 0.6273\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6228 - accuracy: 0.6832 - val_loss: 0.6363 - val_accuracy: 0.6335\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 990us/step - loss: 0.6227 - accuracy: 0.6842 - val_loss: 0.6357 - val_accuracy: 0.6337\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6210 - accuracy: 0.6848 - val_loss: 0.6359 - val_accuracy: 0.6322\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6206 - accuracy: 0.6858 - val_loss: 0.6347 - val_accuracy: 0.6345\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 982us/step - loss: 0.6190 - accuracy: 0.6860 - val_loss: 0.6309 - val_accuracy: 0.6394\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 907us/step - loss: 0.6172 - accuracy: 0.6884 - val_loss: 0.6315 - val_accuracy: 0.6372\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 904us/step - loss: 0.6169 - accuracy: 0.6868 - val_loss: 0.6317 - val_accuracy: 0.6357\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 909us/step - loss: 0.6160 - accuracy: 0.6896 - val_loss: 0.6333 - val_accuracy: 0.6333\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 943us/step - loss: 0.6924 - accuracy: 0.5556 - val_loss: 0.7135 - val_accuracy: 0.4231\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 927us/step - loss: 0.6867 - accuracy: 0.5651 - val_loss: 0.7039 - val_accuracy: 0.4705\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 919us/step - loss: 0.6821 - accuracy: 0.5708 - val_loss: 0.6972 - val_accuracy: 0.5025\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 996us/step - loss: 0.6774 - accuracy: 0.5786 - val_loss: 0.6927 - val_accuracy: 0.5220\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 933us/step - loss: 0.6721 - accuracy: 0.5915 - val_loss: 0.6894 - val_accuracy: 0.5353\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6669 - accuracy: 0.5956 - val_loss: 0.6857 - val_accuracy: 0.5580\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6641 - accuracy: 0.6019 - val_loss: 0.6811 - val_accuracy: 0.5746\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6602 - accuracy: 0.6095 - val_loss: 0.6789 - val_accuracy: 0.5823\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 910us/step - loss: 0.6565 - accuracy: 0.6153 - val_loss: 0.6781 - val_accuracy: 0.5879\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6540 - accuracy: 0.6211 - val_loss: 0.6731 - val_accuracy: 0.5987\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 982us/step - loss: 0.6506 - accuracy: 0.6253 - val_loss: 0.6693 - val_accuracy: 0.6042\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6477 - accuracy: 0.6305 - val_loss: 0.6654 - val_accuracy: 0.6079\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 995us/step - loss: 0.6457 - accuracy: 0.6340 - val_loss: 0.6659 - val_accuracy: 0.6060\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 896us/step - loss: 0.6424 - accuracy: 0.6360 - val_loss: 0.6621 - val_accuracy: 0.6101\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.6407 - accuracy: 0.6399 - val_loss: 0.6628 - val_accuracy: 0.6082\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 995us/step - loss: 0.6386 - accuracy: 0.6449 - val_loss: 0.6608 - val_accuracy: 0.6103\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 976us/step - loss: 0.6359 - accuracy: 0.6473 - val_loss: 0.6601 - val_accuracy: 0.6091\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 932us/step - loss: 0.6339 - accuracy: 0.6492 - val_loss: 0.6612 - val_accuracy: 0.6063\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 939us/step - loss: 0.6317 - accuracy: 0.6522 - val_loss: 0.6547 - val_accuracy: 0.6161\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 947us/step - loss: 0.6311 - accuracy: 0.6528 - val_loss: 0.6542 - val_accuracy: 0.6145\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 973us/step - loss: 0.6295 - accuracy: 0.6546 - val_loss: 0.6543 - val_accuracy: 0.6133\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 915us/step - loss: 0.6268 - accuracy: 0.6579 - val_loss: 0.6512 - val_accuracy: 0.6151\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 999us/step - loss: 0.6250 - accuracy: 0.6571 - val_loss: 0.6494 - val_accuracy: 0.6178\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6238 - accuracy: 0.6594 - val_loss: 0.6492 - val_accuracy: 0.6172\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 979us/step - loss: 0.6221 - accuracy: 0.6635 - val_loss: 0.6492 - val_accuracy: 0.6175\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 875us/step - loss: 0.6192 - accuracy: 0.6677 - val_loss: 0.6467 - val_accuracy: 0.6199\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6186 - accuracy: 0.6673 - val_loss: 0.6470 - val_accuracy: 0.6189\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 966us/step - loss: 0.6170 - accuracy: 0.6693 - val_loss: 0.6414 - val_accuracy: 0.6255\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6161 - accuracy: 0.6677 - val_loss: 0.6402 - val_accuracy: 0.6269\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6130 - accuracy: 0.6729 - val_loss: 0.6397 - val_accuracy: 0.6259\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 966us/step - loss: 0.6118 - accuracy: 0.6729 - val_loss: 0.6381 - val_accuracy: 0.6273\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6113 - accuracy: 0.6727 - val_loss: 0.6370 - val_accuracy: 0.6286\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 929us/step - loss: 0.6096 - accuracy: 0.6743 - val_loss: 0.6368 - val_accuracy: 0.6276\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 903us/step - loss: 0.6083 - accuracy: 0.6759 - val_loss: 0.6350 - val_accuracy: 0.6294\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 972us/step - loss: 0.6070 - accuracy: 0.6773 - val_loss: 0.6343 - val_accuracy: 0.6293\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 985us/step - loss: 0.6055 - accuracy: 0.6805 - val_loss: 0.6375 - val_accuracy: 0.6235\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 906us/step - loss: 0.6031 - accuracy: 0.6808 - val_loss: 0.6309 - val_accuracy: 0.6336\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 925us/step - loss: 0.6025 - accuracy: 0.6829 - val_loss: 0.6318 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.6024 - accuracy: 0.6834 - val_loss: 0.6316 - val_accuracy: 0.6318\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 902us/step - loss: 0.6009 - accuracy: 0.6836 - val_loss: 0.6290 - val_accuracy: 0.6352\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 947us/step - loss: 0.5991 - accuracy: 0.6839 - val_loss: 0.6281 - val_accuracy: 0.6357\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.5978 - accuracy: 0.6862 - val_loss: 0.6278 - val_accuracy: 0.6357\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 934us/step - loss: 0.5964 - accuracy: 0.6850 - val_loss: 0.6266 - val_accuracy: 0.6368\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.5960 - accuracy: 0.6879 - val_loss: 0.6275 - val_accuracy: 0.6346\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.5952 - accuracy: 0.6873 - val_loss: 0.6207 - val_accuracy: 0.6414\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.5942 - accuracy: 0.6879 - val_loss: 0.6253 - val_accuracy: 0.6351\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 989us/step - loss: 0.5927 - accuracy: 0.6905 - val_loss: 0.6252 - val_accuracy: 0.6352\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 907us/step - loss: 0.5914 - accuracy: 0.6935 - val_loss: 0.6202 - val_accuracy: 0.6405\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 982us/step - loss: 0.5909 - accuracy: 0.6904 - val_loss: 0.6238 - val_accuracy: 0.6362\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 900us/step - loss: 0.5907 - accuracy: 0.6905 - val_loss: 0.6240 - val_accuracy: 0.6359\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 970us/step - loss: 0.7140 - accuracy: 0.5045 - val_loss: 0.6688 - val_accuracy: 0.6399\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6973 - accuracy: 0.5302 - val_loss: 0.7035 - val_accuracy: 0.4654\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6913 - accuracy: 0.5428 - val_loss: 0.7102 - val_accuracy: 0.4429\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 944us/step - loss: 0.6879 - accuracy: 0.5520 - val_loss: 0.7075 - val_accuracy: 0.4640\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 804us/step - loss: 0.6850 - accuracy: 0.5583 - val_loss: 0.7045 - val_accuracy: 0.4819\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 983us/step - loss: 0.6808 - accuracy: 0.5690 - val_loss: 0.7010 - val_accuracy: 0.4981\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 801us/step - loss: 0.6781 - accuracy: 0.5704 - val_loss: 0.6956 - val_accuracy: 0.5212\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 962us/step - loss: 0.6736 - accuracy: 0.5807 - val_loss: 0.6928 - val_accuracy: 0.5269\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 892us/step - loss: 0.6709 - accuracy: 0.5908 - val_loss: 0.6889 - val_accuracy: 0.5419\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.6677 - accuracy: 0.5942 - val_loss: 0.6854 - val_accuracy: 0.5559\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 964us/step - loss: 0.6653 - accuracy: 0.6007 - val_loss: 0.6820 - val_accuracy: 0.5694\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.6626 - accuracy: 0.6066 - val_loss: 0.6790 - val_accuracy: 0.5811\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6610 - accuracy: 0.6106 - val_loss: 0.6780 - val_accuracy: 0.5858\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.6587 - accuracy: 0.6129 - val_loss: 0.6754 - val_accuracy: 0.5932\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 914us/step - loss: 0.6563 - accuracy: 0.6180 - val_loss: 0.6730 - val_accuracy: 0.6039\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 806us/step - loss: 0.6542 - accuracy: 0.6249 - val_loss: 0.6713 - val_accuracy: 0.6078\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 892us/step - loss: 0.6525 - accuracy: 0.6284 - val_loss: 0.6708 - val_accuracy: 0.6083\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.6498 - accuracy: 0.6316 - val_loss: 0.6670 - val_accuracy: 0.6124\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6485 - accuracy: 0.6336 - val_loss: 0.6653 - val_accuracy: 0.6120\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6472 - accuracy: 0.6333 - val_loss: 0.6664 - val_accuracy: 0.6084\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 789us/step - loss: 0.6450 - accuracy: 0.6403 - val_loss: 0.6637 - val_accuracy: 0.6093\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6420 - accuracy: 0.6437 - val_loss: 0.6624 - val_accuracy: 0.6099\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 987us/step - loss: 0.6408 - accuracy: 0.6451 - val_loss: 0.6612 - val_accuracy: 0.6107\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.6392 - accuracy: 0.6486 - val_loss: 0.6591 - val_accuracy: 0.6135\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6384 - accuracy: 0.6494 - val_loss: 0.6582 - val_accuracy: 0.6144\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6354 - accuracy: 0.6545 - val_loss: 0.6570 - val_accuracy: 0.6156\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6345 - accuracy: 0.6561 - val_loss: 0.6557 - val_accuracy: 0.6179\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6317 - accuracy: 0.6598 - val_loss: 0.6516 - val_accuracy: 0.6247\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.6314 - accuracy: 0.6598 - val_loss: 0.6516 - val_accuracy: 0.6234\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6287 - accuracy: 0.6616 - val_loss: 0.6485 - val_accuracy: 0.6297\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6273 - accuracy: 0.6650 - val_loss: 0.6495 - val_accuracy: 0.6271\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6271 - accuracy: 0.6615 - val_loss: 0.6466 - val_accuracy: 0.6326\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 868us/step - loss: 0.6250 - accuracy: 0.6649 - val_loss: 0.6464 - val_accuracy: 0.6329\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6239 - accuracy: 0.6658 - val_loss: 0.6438 - val_accuracy: 0.6373\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6222 - accuracy: 0.6676 - val_loss: 0.6431 - val_accuracy: 0.6376\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6209 - accuracy: 0.6700 - val_loss: 0.6439 - val_accuracy: 0.6360\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6199 - accuracy: 0.6707 - val_loss: 0.6410 - val_accuracy: 0.6395\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6181 - accuracy: 0.6731 - val_loss: 0.6403 - val_accuracy: 0.6403\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6162 - accuracy: 0.6746 - val_loss: 0.6402 - val_accuracy: 0.6401\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6159 - accuracy: 0.6751 - val_loss: 0.6406 - val_accuracy: 0.6386\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 794us/step - loss: 0.6147 - accuracy: 0.6765 - val_loss: 0.6372 - val_accuracy: 0.6416\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6127 - accuracy: 0.6781 - val_loss: 0.6358 - val_accuracy: 0.6426\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 802us/step - loss: 0.6111 - accuracy: 0.6771 - val_loss: 0.6343 - val_accuracy: 0.6445\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6109 - accuracy: 0.6760 - val_loss: 0.6336 - val_accuracy: 0.6447\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6095 - accuracy: 0.6785 - val_loss: 0.6349 - val_accuracy: 0.6428\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.6084 - accuracy: 0.6812 - val_loss: 0.6330 - val_accuracy: 0.6453\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 901us/step - loss: 0.6064 - accuracy: 0.6817 - val_loss: 0.6324 - val_accuracy: 0.6465\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6057 - accuracy: 0.6820 - val_loss: 0.6274 - val_accuracy: 0.6538\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 868us/step - loss: 0.6038 - accuracy: 0.6847 - val_loss: 0.6297 - val_accuracy: 0.6504\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6030 - accuracy: 0.6860 - val_loss: 0.6296 - val_accuracy: 0.6496\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.7272 - accuracy: 0.4871 - val_loss: 0.7699 - val_accuracy: 0.2006\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.7182 - accuracy: 0.4927 - val_loss: 0.7490 - val_accuracy: 0.2445\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 824us/step - loss: 0.7122 - accuracy: 0.5005 - val_loss: 0.7391 - val_accuracy: 0.2779\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 826us/step - loss: 0.7062 - accuracy: 0.5155 - val_loss: 0.7300 - val_accuracy: 0.3210\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.7007 - accuracy: 0.5244 - val_loss: 0.7238 - val_accuracy: 0.3424\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6960 - accuracy: 0.5374 - val_loss: 0.7192 - val_accuracy: 0.3598\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6913 - accuracy: 0.5479 - val_loss: 0.7157 - val_accuracy: 0.3960\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6860 - accuracy: 0.5610 - val_loss: 0.7124 - val_accuracy: 0.4366\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6813 - accuracy: 0.5725 - val_loss: 0.7086 - val_accuracy: 0.4669\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6774 - accuracy: 0.5820 - val_loss: 0.7042 - val_accuracy: 0.4898\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 824us/step - loss: 0.6734 - accuracy: 0.5947 - val_loss: 0.7013 - val_accuracy: 0.5142\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.6705 - accuracy: 0.5988 - val_loss: 0.6992 - val_accuracy: 0.5340\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 824us/step - loss: 0.6645 - accuracy: 0.6133 - val_loss: 0.6941 - val_accuracy: 0.5559\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6608 - accuracy: 0.6226 - val_loss: 0.6915 - val_accuracy: 0.5629\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6589 - accuracy: 0.6216 - val_loss: 0.6877 - val_accuracy: 0.5720\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 794us/step - loss: 0.6547 - accuracy: 0.6316 - val_loss: 0.6845 - val_accuracy: 0.5789\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6518 - accuracy: 0.6389 - val_loss: 0.6842 - val_accuracy: 0.5791\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6499 - accuracy: 0.6413 - val_loss: 0.6810 - val_accuracy: 0.5861\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6482 - accuracy: 0.6400 - val_loss: 0.6773 - val_accuracy: 0.5955\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6442 - accuracy: 0.6502 - val_loss: 0.6750 - val_accuracy: 0.6009\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.6428 - accuracy: 0.6528 - val_loss: 0.6737 - val_accuracy: 0.6031\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 861us/step - loss: 0.6402 - accuracy: 0.6558 - val_loss: 0.6700 - val_accuracy: 0.6133\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6368 - accuracy: 0.6625 - val_loss: 0.6698 - val_accuracy: 0.6134\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.6364 - accuracy: 0.6612 - val_loss: 0.6671 - val_accuracy: 0.6182\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 902us/step - loss: 0.6321 - accuracy: 0.6685 - val_loss: 0.6684 - val_accuracy: 0.6137\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6322 - accuracy: 0.6640 - val_loss: 0.6644 - val_accuracy: 0.6218\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6294 - accuracy: 0.6689 - val_loss: 0.6626 - val_accuracy: 0.6237\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6279 - accuracy: 0.6702 - val_loss: 0.6620 - val_accuracy: 0.6235\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 804us/step - loss: 0.6266 - accuracy: 0.6719 - val_loss: 0.6592 - val_accuracy: 0.6260\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 880us/step - loss: 0.6254 - accuracy: 0.6726 - val_loss: 0.6592 - val_accuracy: 0.6252\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6232 - accuracy: 0.6775 - val_loss: 0.6584 - val_accuracy: 0.6250\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.6212 - accuracy: 0.6775 - val_loss: 0.6558 - val_accuracy: 0.6270\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 796us/step - loss: 0.6191 - accuracy: 0.6800 - val_loss: 0.6532 - val_accuracy: 0.6294\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6172 - accuracy: 0.6825 - val_loss: 0.6531 - val_accuracy: 0.6293\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6169 - accuracy: 0.6818 - val_loss: 0.6509 - val_accuracy: 0.6313\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6150 - accuracy: 0.6844 - val_loss: 0.6500 - val_accuracy: 0.6328\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 784us/step - loss: 0.6138 - accuracy: 0.6836 - val_loss: 0.6493 - val_accuracy: 0.6324\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6120 - accuracy: 0.6849 - val_loss: 0.6451 - val_accuracy: 0.6368\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 858us/step - loss: 0.6111 - accuracy: 0.6853 - val_loss: 0.6438 - val_accuracy: 0.6377\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 807us/step - loss: 0.6100 - accuracy: 0.6880 - val_loss: 0.6428 - val_accuracy: 0.6384\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6082 - accuracy: 0.6897 - val_loss: 0.6431 - val_accuracy: 0.6368\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6073 - accuracy: 0.6896 - val_loss: 0.6447 - val_accuracy: 0.6351\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 806us/step - loss: 0.6054 - accuracy: 0.6914 - val_loss: 0.6412 - val_accuracy: 0.6386\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6045 - accuracy: 0.6913 - val_loss: 0.6415 - val_accuracy: 0.6378\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6031 - accuracy: 0.6915 - val_loss: 0.6394 - val_accuracy: 0.6395\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.6029 - accuracy: 0.6927 - val_loss: 0.6413 - val_accuracy: 0.6364\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.5995 - accuracy: 0.6953 - val_loss: 0.6383 - val_accuracy: 0.6397\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 789us/step - loss: 0.5988 - accuracy: 0.6966 - val_loss: 0.6381 - val_accuracy: 0.6394\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.5981 - accuracy: 0.6956 - val_loss: 0.6335 - val_accuracy: 0.6456\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.5960 - accuracy: 0.6972 - val_loss: 0.6354 - val_accuracy: 0.6418\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.8429 - accuracy: 0.4713 - val_loss: 0.5979 - val_accuracy: 0.8395\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.7352 - accuracy: 0.4760 - val_loss: 0.6898 - val_accuracy: 0.5294\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 805us/step - loss: 0.7201 - accuracy: 0.4913 - val_loss: 0.7118 - val_accuracy: 0.3795\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.7137 - accuracy: 0.5045 - val_loss: 0.7146 - val_accuracy: 0.3573\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 892us/step - loss: 0.7045 - accuracy: 0.5219 - val_loss: 0.7132 - val_accuracy: 0.3815\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.7008 - accuracy: 0.5305 - val_loss: 0.7061 - val_accuracy: 0.4413\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6958 - accuracy: 0.5406 - val_loss: 0.7004 - val_accuracy: 0.4846\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6921 - accuracy: 0.5462 - val_loss: 0.6978 - val_accuracy: 0.4994\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6896 - accuracy: 0.5532 - val_loss: 0.6938 - val_accuracy: 0.5173\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6866 - accuracy: 0.5588 - val_loss: 0.6920 - val_accuracy: 0.5244\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6820 - accuracy: 0.5658 - val_loss: 0.6873 - val_accuracy: 0.5452\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6802 - accuracy: 0.5694 - val_loss: 0.6887 - val_accuracy: 0.5403\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 890us/step - loss: 0.6775 - accuracy: 0.5742 - val_loss: 0.6835 - val_accuracy: 0.5611\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6745 - accuracy: 0.5809 - val_loss: 0.6802 - val_accuracy: 0.5714\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 878us/step - loss: 0.6724 - accuracy: 0.5858 - val_loss: 0.6792 - val_accuracy: 0.5746\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6700 - accuracy: 0.5906 - val_loss: 0.6768 - val_accuracy: 0.5812\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.6680 - accuracy: 0.5947 - val_loss: 0.6741 - val_accuracy: 0.5889\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.6649 - accuracy: 0.5980 - val_loss: 0.6713 - val_accuracy: 0.5963\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6633 - accuracy: 0.6013 - val_loss: 0.6712 - val_accuracy: 0.5946\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6602 - accuracy: 0.6086 - val_loss: 0.6695 - val_accuracy: 0.5970\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 795us/step - loss: 0.6584 - accuracy: 0.6105 - val_loss: 0.6657 - val_accuracy: 0.6023\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6568 - accuracy: 0.6106 - val_loss: 0.6652 - val_accuracy: 0.6013\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 797us/step - loss: 0.6556 - accuracy: 0.6135 - val_loss: 0.6623 - val_accuracy: 0.6067\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.6527 - accuracy: 0.6183 - val_loss: 0.6614 - val_accuracy: 0.6078\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 691us/step - loss: 0.6505 - accuracy: 0.6212 - val_loss: 0.6586 - val_accuracy: 0.6119\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 893us/step - loss: 0.6492 - accuracy: 0.6236 - val_loss: 0.6595 - val_accuracy: 0.6089\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6482 - accuracy: 0.6252 - val_loss: 0.6569 - val_accuracy: 0.6138\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6454 - accuracy: 0.6279 - val_loss: 0.6543 - val_accuracy: 0.6177\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6450 - accuracy: 0.6296 - val_loss: 0.6515 - val_accuracy: 0.6209\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.6431 - accuracy: 0.6314 - val_loss: 0.6532 - val_accuracy: 0.6189\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6398 - accuracy: 0.6381 - val_loss: 0.6510 - val_accuracy: 0.6217\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6387 - accuracy: 0.6393 - val_loss: 0.6475 - val_accuracy: 0.6241\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.6377 - accuracy: 0.6396 - val_loss: 0.6474 - val_accuracy: 0.6245\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6352 - accuracy: 0.6432 - val_loss: 0.6462 - val_accuracy: 0.6248\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6354 - accuracy: 0.6411 - val_loss: 0.6447 - val_accuracy: 0.6263\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 771us/step - loss: 0.6331 - accuracy: 0.6424 - val_loss: 0.6419 - val_accuracy: 0.6280\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 993us/step - loss: 0.6309 - accuracy: 0.6491 - val_loss: 0.6411 - val_accuracy: 0.6280\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6301 - accuracy: 0.6475 - val_loss: 0.6400 - val_accuracy: 0.6283\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6278 - accuracy: 0.6523 - val_loss: 0.6399 - val_accuracy: 0.6277\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6275 - accuracy: 0.6541 - val_loss: 0.6393 - val_accuracy: 0.6277\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 878us/step - loss: 0.6260 - accuracy: 0.6526 - val_loss: 0.6379 - val_accuracy: 0.6284\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 875us/step - loss: 0.6258 - accuracy: 0.6549 - val_loss: 0.6362 - val_accuracy: 0.6297\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6225 - accuracy: 0.6559 - val_loss: 0.6341 - val_accuracy: 0.6311\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 923us/step - loss: 0.6214 - accuracy: 0.6590 - val_loss: 0.6356 - val_accuracy: 0.6286\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6216 - accuracy: 0.6574 - val_loss: 0.6347 - val_accuracy: 0.6283\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6196 - accuracy: 0.6579 - val_loss: 0.6334 - val_accuracy: 0.6282\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 934us/step - loss: 0.6194 - accuracy: 0.6594 - val_loss: 0.6307 - val_accuracy: 0.6304\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 733us/step - loss: 0.6167 - accuracy: 0.6631 - val_loss: 0.6313 - val_accuracy: 0.6286\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 771us/step - loss: 0.6161 - accuracy: 0.6637 - val_loss: 0.6297 - val_accuracy: 0.6299\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6162 - accuracy: 0.6636 - val_loss: 0.6296 - val_accuracy: 0.6294\n",
      "Epoch 1/50\n",
      "  1/836 [..............................] - ETA: 0s - loss: 0.7461 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 895us/step - loss: 0.7381 - accuracy: 0.4804 - val_loss: 0.6288 - val_accuracy: 0.8214\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.7083 - accuracy: 0.4983 - val_loss: 0.6786 - val_accuracy: 0.5989\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.7021 - accuracy: 0.5091 - val_loss: 0.6934 - val_accuracy: 0.5306\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6951 - accuracy: 0.5258 - val_loss: 0.6956 - val_accuracy: 0.5256\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 887us/step - loss: 0.6905 - accuracy: 0.5368 - val_loss: 0.6942 - val_accuracy: 0.5365\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 949us/step - loss: 0.6880 - accuracy: 0.5448 - val_loss: 0.6921 - val_accuracy: 0.5516\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6828 - accuracy: 0.5574 - val_loss: 0.6907 - val_accuracy: 0.5584\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6812 - accuracy: 0.5619 - val_loss: 0.6875 - val_accuracy: 0.5660\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6780 - accuracy: 0.5683 - val_loss: 0.6873 - val_accuracy: 0.5629\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 934us/step - loss: 0.6747 - accuracy: 0.5769 - val_loss: 0.6829 - val_accuracy: 0.5681\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.6725 - accuracy: 0.5843 - val_loss: 0.6802 - val_accuracy: 0.5713\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 988us/step - loss: 0.6686 - accuracy: 0.5945 - val_loss: 0.6778 - val_accuracy: 0.5744\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6663 - accuracy: 0.5951 - val_loss: 0.6768 - val_accuracy: 0.5746\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.6627 - accuracy: 0.6035 - val_loss: 0.6728 - val_accuracy: 0.5820\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 903us/step - loss: 0.6611 - accuracy: 0.6097 - val_loss: 0.6692 - val_accuracy: 0.5879\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6575 - accuracy: 0.6163 - val_loss: 0.6667 - val_accuracy: 0.5904\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 984us/step - loss: 0.6572 - accuracy: 0.6151 - val_loss: 0.6648 - val_accuracy: 0.5939\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 986us/step - loss: 0.6532 - accuracy: 0.6236 - val_loss: 0.6637 - val_accuracy: 0.5954\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 900us/step - loss: 0.6521 - accuracy: 0.6286 - val_loss: 0.6630 - val_accuracy: 0.5973\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.6493 - accuracy: 0.6312 - val_loss: 0.6590 - val_accuracy: 0.6030\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 975us/step - loss: 0.6486 - accuracy: 0.6313 - val_loss: 0.6580 - val_accuracy: 0.6051\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 961us/step - loss: 0.6463 - accuracy: 0.6352 - val_loss: 0.6565 - val_accuracy: 0.6077\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 950us/step - loss: 0.6439 - accuracy: 0.6413 - val_loss: 0.6549 - val_accuracy: 0.6092\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 910us/step - loss: 0.6421 - accuracy: 0.6439 - val_loss: 0.6539 - val_accuracy: 0.6104\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 986us/step - loss: 0.6410 - accuracy: 0.6463 - val_loss: 0.6521 - val_accuracy: 0.6126\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 902us/step - loss: 0.6393 - accuracy: 0.6490 - val_loss: 0.6506 - val_accuracy: 0.6135\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6378 - accuracy: 0.6508 - val_loss: 0.6483 - val_accuracy: 0.6174\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 950us/step - loss: 0.6361 - accuracy: 0.6520 - val_loss: 0.6506 - val_accuracy: 0.6124\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 909us/step - loss: 0.6353 - accuracy: 0.6543 - val_loss: 0.6479 - val_accuracy: 0.6163\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 974us/step - loss: 0.6341 - accuracy: 0.6525 - val_loss: 0.6477 - val_accuracy: 0.6153\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 907us/step - loss: 0.6320 - accuracy: 0.6569 - val_loss: 0.6451 - val_accuracy: 0.6188\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6318 - accuracy: 0.6568 - val_loss: 0.6437 - val_accuracy: 0.6200\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6296 - accuracy: 0.6603 - val_loss: 0.6433 - val_accuracy: 0.6185\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.6287 - accuracy: 0.6576 - val_loss: 0.6439 - val_accuracy: 0.6167\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 903us/step - loss: 0.6270 - accuracy: 0.6624 - val_loss: 0.6398 - val_accuracy: 0.6235\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 904us/step - loss: 0.6261 - accuracy: 0.6643 - val_loss: 0.6378 - val_accuracy: 0.6266\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6247 - accuracy: 0.6655 - val_loss: 0.6382 - val_accuracy: 0.6246\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 927us/step - loss: 0.6242 - accuracy: 0.6647 - val_loss: 0.6372 - val_accuracy: 0.6252\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.6227 - accuracy: 0.6669 - val_loss: 0.6359 - val_accuracy: 0.6268\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6225 - accuracy: 0.6682 - val_loss: 0.6367 - val_accuracy: 0.6245\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 877us/step - loss: 0.6222 - accuracy: 0.6668 - val_loss: 0.6348 - val_accuracy: 0.6266\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.6205 - accuracy: 0.6666 - val_loss: 0.6356 - val_accuracy: 0.6255\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.6187 - accuracy: 0.6728 - val_loss: 0.6346 - val_accuracy: 0.6256\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.6182 - accuracy: 0.6722 - val_loss: 0.6347 - val_accuracy: 0.6250\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6166 - accuracy: 0.6737 - val_loss: 0.6319 - val_accuracy: 0.6280\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 904us/step - loss: 0.6153 - accuracy: 0.6754 - val_loss: 0.6299 - val_accuracy: 0.6289\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 984us/step - loss: 0.6155 - accuracy: 0.6747 - val_loss: 0.6319 - val_accuracy: 0.6271\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 984us/step - loss: 0.6138 - accuracy: 0.6763 - val_loss: 0.6324 - val_accuracy: 0.6257\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 982us/step - loss: 0.6119 - accuracy: 0.6813 - val_loss: 0.6310 - val_accuracy: 0.6269\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6121 - accuracy: 0.6791 - val_loss: 0.6306 - val_accuracy: 0.6268\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.7637 - accuracy: 0.5101 - val_loss: 0.8498 - val_accuracy: 0.1466\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.7160 - accuracy: 0.5027 - val_loss: 0.7631 - val_accuracy: 0.2446\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 909us/step - loss: 0.7080 - accuracy: 0.5051 - val_loss: 0.7409 - val_accuracy: 0.2835\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.7043 - accuracy: 0.5123 - val_loss: 0.7305 - val_accuracy: 0.3217\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 933us/step - loss: 0.6984 - accuracy: 0.5193 - val_loss: 0.7260 - val_accuracy: 0.3465\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 867us/step - loss: 0.6956 - accuracy: 0.5250 - val_loss: 0.7214 - val_accuracy: 0.3626\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 931us/step - loss: 0.6908 - accuracy: 0.5323 - val_loss: 0.7173 - val_accuracy: 0.3770\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5421 - val_loss: 0.7140 - val_accuracy: 0.3962\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5504 - val_loss: 0.7100 - val_accuracy: 0.4200\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 918us/step - loss: 0.6822 - accuracy: 0.5533 - val_loss: 0.7082 - val_accuracy: 0.4419\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6784 - accuracy: 0.5626 - val_loss: 0.7036 - val_accuracy: 0.4748\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 977us/step - loss: 0.6746 - accuracy: 0.5698 - val_loss: 0.7021 - val_accuracy: 0.4870\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 995us/step - loss: 0.6730 - accuracy: 0.5715 - val_loss: 0.7000 - val_accuracy: 0.5014\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6693 - accuracy: 0.5802 - val_loss: 0.6981 - val_accuracy: 0.5110\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6674 - accuracy: 0.5846 - val_loss: 0.6940 - val_accuracy: 0.5265\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 888us/step - loss: 0.6662 - accuracy: 0.5856 - val_loss: 0.6929 - val_accuracy: 0.5322\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 923us/step - loss: 0.6631 - accuracy: 0.5939 - val_loss: 0.6890 - val_accuracy: 0.5473\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 983us/step - loss: 0.6613 - accuracy: 0.5954 - val_loss: 0.6854 - val_accuracy: 0.5626\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6595 - accuracy: 0.6009 - val_loss: 0.6871 - val_accuracy: 0.5594\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6567 - accuracy: 0.6023 - val_loss: 0.6822 - val_accuracy: 0.5745\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 938us/step - loss: 0.6537 - accuracy: 0.6118 - val_loss: 0.6789 - val_accuracy: 0.5866\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 900us/step - loss: 0.6521 - accuracy: 0.6126 - val_loss: 0.6801 - val_accuracy: 0.5842\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 903us/step - loss: 0.6496 - accuracy: 0.6183 - val_loss: 0.6788 - val_accuracy: 0.5874\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 999us/step - loss: 0.6481 - accuracy: 0.6176 - val_loss: 0.6765 - val_accuracy: 0.5933\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 891us/step - loss: 0.6453 - accuracy: 0.6220 - val_loss: 0.6721 - val_accuracy: 0.5999\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 934us/step - loss: 0.6437 - accuracy: 0.6255 - val_loss: 0.6717 - val_accuracy: 0.6002\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 887us/step - loss: 0.6423 - accuracy: 0.6269 - val_loss: 0.6697 - val_accuracy: 0.6039\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 972us/step - loss: 0.6420 - accuracy: 0.6280 - val_loss: 0.6679 - val_accuracy: 0.6070\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6400 - accuracy: 0.6283 - val_loss: 0.6664 - val_accuracy: 0.6093\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 974us/step - loss: 0.6370 - accuracy: 0.6365 - val_loss: 0.6659 - val_accuracy: 0.6103\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.6366 - accuracy: 0.6346 - val_loss: 0.6633 - val_accuracy: 0.6151\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 909us/step - loss: 0.6357 - accuracy: 0.6344 - val_loss: 0.6622 - val_accuracy: 0.6171\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 977us/step - loss: 0.6338 - accuracy: 0.6363 - val_loss: 0.6608 - val_accuracy: 0.6185\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 937us/step - loss: 0.6318 - accuracy: 0.6390 - val_loss: 0.6589 - val_accuracy: 0.6215\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 896us/step - loss: 0.6295 - accuracy: 0.6427 - val_loss: 0.6568 - val_accuracy: 0.6229\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6278 - accuracy: 0.6448 - val_loss: 0.6562 - val_accuracy: 0.6241\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6269 - accuracy: 0.6445 - val_loss: 0.6541 - val_accuracy: 0.6265\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6263 - accuracy: 0.6460 - val_loss: 0.6513 - val_accuracy: 0.6294\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 901us/step - loss: 0.6243 - accuracy: 0.6482 - val_loss: 0.6524 - val_accuracy: 0.6284\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 989us/step - loss: 0.6231 - accuracy: 0.6504 - val_loss: 0.6502 - val_accuracy: 0.6295\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6226 - accuracy: 0.6500 - val_loss: 0.6472 - val_accuracy: 0.6316\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 926us/step - loss: 0.6208 - accuracy: 0.6536 - val_loss: 0.6501 - val_accuracy: 0.6294\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 896us/step - loss: 0.6186 - accuracy: 0.6532 - val_loss: 0.6497 - val_accuracy: 0.6302\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 890us/step - loss: 0.6170 - accuracy: 0.6591 - val_loss: 0.6485 - val_accuracy: 0.6314\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 994us/step - loss: 0.6167 - accuracy: 0.6572 - val_loss: 0.6468 - val_accuracy: 0.6323\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6153 - accuracy: 0.6567 - val_loss: 0.6438 - val_accuracy: 0.6342\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 802us/step - loss: 0.6148 - accuracy: 0.6588 - val_loss: 0.6450 - val_accuracy: 0.6331\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 891us/step - loss: 0.6128 - accuracy: 0.6598 - val_loss: 0.6431 - val_accuracy: 0.6345\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 998us/step - loss: 0.6115 - accuracy: 0.6592 - val_loss: 0.6408 - val_accuracy: 0.6360\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6106 - accuracy: 0.6594 - val_loss: 0.6390 - val_accuracy: 0.6378\n",
      "\n",
      "Training model with batch_size=64, target_eps=1.0...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 5.05 iterated over 41800 steps satisfies differential privacy with eps = 0.245 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.5749999999999997 iterated over 41800 steps satisfies differential privacy with eps = 0.481 and delta = 1e-05.\n",
      "The optimal RDP order is 49.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3375 iterated over 41800 steps satisfies differential privacy with eps = 1.05 and delta = 1e-05.\n",
      "The optimal RDP order is 22.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.9562499999999998 iterated over 41800 steps satisfies differential privacy with eps = 0.655 and delta = 1e-05.\n",
      "The optimal RDP order is 36.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.6468749999999999 iterated over 41800 steps satisfies differential privacy with eps = 0.804 and delta = 1e-05.\n",
      "The optimal RDP order is 30.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.4921875 iterated over 41800 steps satisfies differential privacy with eps = 0.91 and delta = 1e-05.\n",
      "The optimal RDP order is 27.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.41484375 iterated over 41800 steps satisfies differential privacy with eps = 0.975 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3761718749999998 iterated over 41800 steps satisfies differential privacy with eps = 1.01 and delta = 1e-05.\n",
      "The optimal RDP order is 24.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3955078125 iterated over 41800 steps satisfies differential privacy with eps = 0.993 and delta = 1e-05.\n",
      "The optimal RDP order is 24.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 975us/step - loss: 0.7558 - accuracy: 0.4909 - val_loss: 0.5487 - val_accuracy: 0.8828\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6835 - accuracy: 0.5538 - val_loss: 0.6302 - val_accuracy: 0.7992\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6728 - accuracy: 0.5785 - val_loss: 0.6639 - val_accuracy: 0.6394\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 956us/step - loss: 0.6683 - accuracy: 0.5888 - val_loss: 0.6740 - val_accuracy: 0.6041\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.6649 - accuracy: 0.5946 - val_loss: 0.6755 - val_accuracy: 0.5933\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 891us/step - loss: 0.6626 - accuracy: 0.5983 - val_loss: 0.6753 - val_accuracy: 0.5913\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 952us/step - loss: 0.6611 - accuracy: 0.6050 - val_loss: 0.6742 - val_accuracy: 0.5907\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.6065 - val_loss: 0.6710 - val_accuracy: 0.5952\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 972us/step - loss: 0.6564 - accuracy: 0.6127 - val_loss: 0.6682 - val_accuracy: 0.6009\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.6557 - accuracy: 0.6140 - val_loss: 0.6669 - val_accuracy: 0.6015\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.6534 - accuracy: 0.6188 - val_loss: 0.6655 - val_accuracy: 0.6022\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6507 - accuracy: 0.6232 - val_loss: 0.6635 - val_accuracy: 0.6060\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6508 - accuracy: 0.6203 - val_loss: 0.6602 - val_accuracy: 0.6117\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6487 - accuracy: 0.6239 - val_loss: 0.6585 - val_accuracy: 0.6135\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 854us/step - loss: 0.6464 - accuracy: 0.6289 - val_loss: 0.6562 - val_accuracy: 0.6159\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6447 - accuracy: 0.6307 - val_loss: 0.6552 - val_accuracy: 0.6167\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6433 - accuracy: 0.6340 - val_loss: 0.6554 - val_accuracy: 0.6144\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6417 - accuracy: 0.6369 - val_loss: 0.6526 - val_accuracy: 0.6175\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 802us/step - loss: 0.6405 - accuracy: 0.6365 - val_loss: 0.6519 - val_accuracy: 0.6173\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6387 - accuracy: 0.6413 - val_loss: 0.6497 - val_accuracy: 0.6209\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6373 - accuracy: 0.6423 - val_loss: 0.6480 - val_accuracy: 0.6235\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 918us/step - loss: 0.6351 - accuracy: 0.6437 - val_loss: 0.6441 - val_accuracy: 0.6304\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6342 - accuracy: 0.6433 - val_loss: 0.6431 - val_accuracy: 0.6302\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6327 - accuracy: 0.6464 - val_loss: 0.6412 - val_accuracy: 0.6330\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6308 - accuracy: 0.6484 - val_loss: 0.6405 - val_accuracy: 0.6319\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 998us/step - loss: 0.6299 - accuracy: 0.6490 - val_loss: 0.6380 - val_accuracy: 0.6362\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 999us/step - loss: 0.6282 - accuracy: 0.6528 - val_loss: 0.6398 - val_accuracy: 0.6291\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 921us/step - loss: 0.6272 - accuracy: 0.6539 - val_loss: 0.6364 - val_accuracy: 0.6362\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 918us/step - loss: 0.6265 - accuracy: 0.6532 - val_loss: 0.6355 - val_accuracy: 0.6365\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 944us/step - loss: 0.6249 - accuracy: 0.6549 - val_loss: 0.6352 - val_accuracy: 0.6347\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6232 - accuracy: 0.6573 - val_loss: 0.6361 - val_accuracy: 0.6305\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 800us/step - loss: 0.6227 - accuracy: 0.6552 - val_loss: 0.6356 - val_accuracy: 0.6300\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6210 - accuracy: 0.6612 - val_loss: 0.6348 - val_accuracy: 0.6304\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6199 - accuracy: 0.6615 - val_loss: 0.6332 - val_accuracy: 0.6339\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6188 - accuracy: 0.6631 - val_loss: 0.6340 - val_accuracy: 0.6307\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6172 - accuracy: 0.6635 - val_loss: 0.6333 - val_accuracy: 0.6311\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 920us/step - loss: 0.6170 - accuracy: 0.6626 - val_loss: 0.6292 - val_accuracy: 0.6416\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 869us/step - loss: 0.6162 - accuracy: 0.6641 - val_loss: 0.6294 - val_accuracy: 0.6404\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.6131 - accuracy: 0.6670 - val_loss: 0.6279 - val_accuracy: 0.6419\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6134 - accuracy: 0.6685 - val_loss: 0.6259 - val_accuracy: 0.6457\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 892us/step - loss: 0.6120 - accuracy: 0.6697 - val_loss: 0.6265 - val_accuracy: 0.6434\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 870us/step - loss: 0.6104 - accuracy: 0.6702 - val_loss: 0.6300 - val_accuracy: 0.6351\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6095 - accuracy: 0.6715 - val_loss: 0.6262 - val_accuracy: 0.6422\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6077 - accuracy: 0.6740 - val_loss: 0.6271 - val_accuracy: 0.6385\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.6077 - accuracy: 0.6707 - val_loss: 0.6262 - val_accuracy: 0.6396\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6064 - accuracy: 0.6744 - val_loss: 0.6249 - val_accuracy: 0.6415\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6055 - accuracy: 0.6740 - val_loss: 0.6218 - val_accuracy: 0.6465\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6037 - accuracy: 0.6758 - val_loss: 0.6221 - val_accuracy: 0.6443\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 892us/step - loss: 0.6027 - accuracy: 0.6782 - val_loss: 0.6222 - val_accuracy: 0.6434\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 824us/step - loss: 0.6027 - accuracy: 0.6768 - val_loss: 0.6234 - val_accuracy: 0.6389\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 877us/step - loss: 0.6848 - accuracy: 0.5717 - val_loss: 0.6734 - val_accuracy: 0.5927\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6794 - accuracy: 0.5823 - val_loss: 0.6859 - val_accuracy: 0.5503\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6772 - accuracy: 0.5873 - val_loss: 0.6866 - val_accuracy: 0.5475\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.6739 - accuracy: 0.5925 - val_loss: 0.6847 - val_accuracy: 0.5505\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 896us/step - loss: 0.6718 - accuracy: 0.5978 - val_loss: 0.6844 - val_accuracy: 0.5486\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 804us/step - loss: 0.6691 - accuracy: 0.6014 - val_loss: 0.6821 - val_accuracy: 0.5526\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6665 - accuracy: 0.6085 - val_loss: 0.6794 - val_accuracy: 0.5602\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6637 - accuracy: 0.6134 - val_loss: 0.6796 - val_accuracy: 0.5621\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6613 - accuracy: 0.6190 - val_loss: 0.6779 - val_accuracy: 0.5701\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6596 - accuracy: 0.6228 - val_loss: 0.6787 - val_accuracy: 0.5678\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 992us/step - loss: 0.6569 - accuracy: 0.6280 - val_loss: 0.6766 - val_accuracy: 0.5747\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6557 - accuracy: 0.6269 - val_loss: 0.6733 - val_accuracy: 0.5830\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6529 - accuracy: 0.6338 - val_loss: 0.6725 - val_accuracy: 0.5837\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6506 - accuracy: 0.6369 - val_loss: 0.6711 - val_accuracy: 0.5864\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6500 - accuracy: 0.6398 - val_loss: 0.6693 - val_accuracy: 0.5921\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 866us/step - loss: 0.6473 - accuracy: 0.6455 - val_loss: 0.6695 - val_accuracy: 0.5905\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 868us/step - loss: 0.6461 - accuracy: 0.6459 - val_loss: 0.6676 - val_accuracy: 0.5927\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 854us/step - loss: 0.6438 - accuracy: 0.6497 - val_loss: 0.6638 - val_accuracy: 0.5994\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 780us/step - loss: 0.6429 - accuracy: 0.6507 - val_loss: 0.6638 - val_accuracy: 0.5987\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.6419 - accuracy: 0.6519 - val_loss: 0.6634 - val_accuracy: 0.5992\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6403 - accuracy: 0.6538 - val_loss: 0.6622 - val_accuracy: 0.6006\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6382 - accuracy: 0.6576 - val_loss: 0.6604 - val_accuracy: 0.6029\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 862us/step - loss: 0.6367 - accuracy: 0.6601 - val_loss: 0.6582 - val_accuracy: 0.6060\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6354 - accuracy: 0.6634 - val_loss: 0.6560 - val_accuracy: 0.6085\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 996us/step - loss: 0.6348 - accuracy: 0.6636 - val_loss: 0.6574 - val_accuracy: 0.6057\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 969us/step - loss: 0.6340 - accuracy: 0.6654 - val_loss: 0.6543 - val_accuracy: 0.6098\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 824us/step - loss: 0.6317 - accuracy: 0.6669 - val_loss: 0.6556 - val_accuracy: 0.6067\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6314 - accuracy: 0.6665 - val_loss: 0.6540 - val_accuracy: 0.6095\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6294 - accuracy: 0.6680 - val_loss: 0.6523 - val_accuracy: 0.6120\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6281 - accuracy: 0.6707 - val_loss: 0.6508 - val_accuracy: 0.6141\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 733us/step - loss: 0.6278 - accuracy: 0.6688 - val_loss: 0.6491 - val_accuracy: 0.6166\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 848us/step - loss: 0.6251 - accuracy: 0.6756 - val_loss: 0.6494 - val_accuracy: 0.6151\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.6259 - accuracy: 0.6718 - val_loss: 0.6476 - val_accuracy: 0.6185\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6235 - accuracy: 0.6774 - val_loss: 0.6469 - val_accuracy: 0.6195\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 790us/step - loss: 0.6228 - accuracy: 0.6739 - val_loss: 0.6460 - val_accuracy: 0.6197\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6231 - accuracy: 0.6756 - val_loss: 0.6461 - val_accuracy: 0.6192\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6216 - accuracy: 0.6775 - val_loss: 0.6457 - val_accuracy: 0.6193\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 826us/step - loss: 0.6194 - accuracy: 0.6816 - val_loss: 0.6448 - val_accuracy: 0.6199\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 804us/step - loss: 0.6190 - accuracy: 0.6802 - val_loss: 0.6428 - val_accuracy: 0.6229\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6191 - accuracy: 0.6786 - val_loss: 0.6418 - val_accuracy: 0.6238\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6168 - accuracy: 0.6820 - val_loss: 0.6412 - val_accuracy: 0.6249\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6167 - accuracy: 0.6830 - val_loss: 0.6410 - val_accuracy: 0.6242\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6156 - accuracy: 0.6835 - val_loss: 0.6391 - val_accuracy: 0.6270\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6154 - accuracy: 0.6835 - val_loss: 0.6402 - val_accuracy: 0.6247\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 805us/step - loss: 0.6134 - accuracy: 0.6871 - val_loss: 0.6398 - val_accuracy: 0.6236\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6133 - accuracy: 0.6848 - val_loss: 0.6384 - val_accuracy: 0.6253\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 719us/step - loss: 0.6117 - accuracy: 0.6878 - val_loss: 0.6384 - val_accuracy: 0.6246\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6106 - accuracy: 0.6892 - val_loss: 0.6389 - val_accuracy: 0.6238\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6112 - accuracy: 0.6877 - val_loss: 0.6364 - val_accuracy: 0.6266\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6097 - accuracy: 0.6896 - val_loss: 0.6360 - val_accuracy: 0.6261\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 945us/step - loss: 0.7170 - accuracy: 0.5102 - val_loss: 0.7324 - val_accuracy: 0.2462\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.7110 - accuracy: 0.5187 - val_loss: 0.7220 - val_accuracy: 0.3141\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.7065 - accuracy: 0.5232 - val_loss: 0.7140 - val_accuracy: 0.3748\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.7020 - accuracy: 0.5312 - val_loss: 0.7124 - val_accuracy: 0.3951\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6995 - accuracy: 0.5358 - val_loss: 0.7099 - val_accuracy: 0.4202\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6954 - accuracy: 0.5387 - val_loss: 0.7074 - val_accuracy: 0.4428\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 858us/step - loss: 0.6913 - accuracy: 0.5446 - val_loss: 0.7056 - val_accuracy: 0.4539\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6882 - accuracy: 0.5534 - val_loss: 0.7019 - val_accuracy: 0.4771\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 926us/step - loss: 0.6851 - accuracy: 0.5566 - val_loss: 0.6973 - val_accuracy: 0.5004\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6832 - accuracy: 0.5622 - val_loss: 0.6960 - val_accuracy: 0.5058\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6815 - accuracy: 0.5626 - val_loss: 0.6958 - val_accuracy: 0.5068\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 907us/step - loss: 0.6769 - accuracy: 0.5743 - val_loss: 0.6953 - val_accuracy: 0.5105\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6756 - accuracy: 0.5761 - val_loss: 0.6921 - val_accuracy: 0.5289\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 869us/step - loss: 0.6735 - accuracy: 0.5781 - val_loss: 0.6895 - val_accuracy: 0.5433\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6706 - accuracy: 0.5882 - val_loss: 0.6893 - val_accuracy: 0.5447\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 895us/step - loss: 0.6684 - accuracy: 0.5920 - val_loss: 0.6860 - val_accuracy: 0.5583\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 802us/step - loss: 0.6660 - accuracy: 0.5966 - val_loss: 0.6855 - val_accuracy: 0.5607\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 745us/step - loss: 0.6645 - accuracy: 0.5987 - val_loss: 0.6844 - val_accuracy: 0.5651\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 883us/step - loss: 0.6631 - accuracy: 0.6005 - val_loss: 0.6804 - val_accuracy: 0.5775\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.6597 - accuracy: 0.6094 - val_loss: 0.6780 - val_accuracy: 0.5840\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 869us/step - loss: 0.6589 - accuracy: 0.6123 - val_loss: 0.6775 - val_accuracy: 0.5839\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 753us/step - loss: 0.6566 - accuracy: 0.6159 - val_loss: 0.6752 - val_accuracy: 0.5904\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 717us/step - loss: 0.6562 - accuracy: 0.6163 - val_loss: 0.6761 - val_accuracy: 0.5856\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6529 - accuracy: 0.6228 - val_loss: 0.6724 - val_accuracy: 0.5950\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6515 - accuracy: 0.6241 - val_loss: 0.6697 - val_accuracy: 0.6013\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 894us/step - loss: 0.6501 - accuracy: 0.6284 - val_loss: 0.6718 - val_accuracy: 0.5954\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6479 - accuracy: 0.6315 - val_loss: 0.6688 - val_accuracy: 0.6010\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6460 - accuracy: 0.6350 - val_loss: 0.6676 - val_accuracy: 0.6020\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6444 - accuracy: 0.6382 - val_loss: 0.6664 - val_accuracy: 0.6025\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6437 - accuracy: 0.6374 - val_loss: 0.6637 - val_accuracy: 0.6070\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6423 - accuracy: 0.6405 - val_loss: 0.6618 - val_accuracy: 0.6090\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 893us/step - loss: 0.6400 - accuracy: 0.6425 - val_loss: 0.6594 - val_accuracy: 0.6133\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6387 - accuracy: 0.6445 - val_loss: 0.6585 - val_accuracy: 0.6146\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 890us/step - loss: 0.6381 - accuracy: 0.6449 - val_loss: 0.6570 - val_accuracy: 0.6169\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 918us/step - loss: 0.6366 - accuracy: 0.6507 - val_loss: 0.6558 - val_accuracy: 0.6180\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 895us/step - loss: 0.6353 - accuracy: 0.6508 - val_loss: 0.6556 - val_accuracy: 0.6176\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.6326 - accuracy: 0.6568 - val_loss: 0.6534 - val_accuracy: 0.6203\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6314 - accuracy: 0.6557 - val_loss: 0.6528 - val_accuracy: 0.6201\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6306 - accuracy: 0.6562 - val_loss: 0.6508 - val_accuracy: 0.6229\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6296 - accuracy: 0.6576 - val_loss: 0.6512 - val_accuracy: 0.6208\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6280 - accuracy: 0.6594 - val_loss: 0.6494 - val_accuracy: 0.6228\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 796us/step - loss: 0.6276 - accuracy: 0.6605 - val_loss: 0.6471 - val_accuracy: 0.6259\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6259 - accuracy: 0.6612 - val_loss: 0.6447 - val_accuracy: 0.6293\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 944us/step - loss: 0.6250 - accuracy: 0.6613 - val_loss: 0.6437 - val_accuracy: 0.6300\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6236 - accuracy: 0.6646 - val_loss: 0.6451 - val_accuracy: 0.6272\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6226 - accuracy: 0.6643 - val_loss: 0.6444 - val_accuracy: 0.6272\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6217 - accuracy: 0.6649 - val_loss: 0.6421 - val_accuracy: 0.6299\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6203 - accuracy: 0.6646 - val_loss: 0.6408 - val_accuracy: 0.6316\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6187 - accuracy: 0.6664 - val_loss: 0.6398 - val_accuracy: 0.6326\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 946us/step - loss: 0.6178 - accuracy: 0.6678 - val_loss: 0.6366 - val_accuracy: 0.6384\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 945us/step - loss: 0.7097 - accuracy: 0.5011 - val_loss: 0.6737 - val_accuracy: 0.6583\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6957 - accuracy: 0.5273 - val_loss: 0.7026 - val_accuracy: 0.4740\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6909 - accuracy: 0.5386 - val_loss: 0.7064 - val_accuracy: 0.4623\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6860 - accuracy: 0.5538 - val_loss: 0.7061 - val_accuracy: 0.4754\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 930us/step - loss: 0.6838 - accuracy: 0.5614 - val_loss: 0.7029 - val_accuracy: 0.4980\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 901us/step - loss: 0.6802 - accuracy: 0.5711 - val_loss: 0.7002 - val_accuracy: 0.5088\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6764 - accuracy: 0.5799 - val_loss: 0.6975 - val_accuracy: 0.5253\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.6747 - accuracy: 0.5839 - val_loss: 0.6954 - val_accuracy: 0.5368\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6717 - accuracy: 0.5898 - val_loss: 0.6925 - val_accuracy: 0.5464\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 968us/step - loss: 0.6689 - accuracy: 0.5962 - val_loss: 0.6925 - val_accuracy: 0.5515\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6665 - accuracy: 0.6004 - val_loss: 0.6906 - val_accuracy: 0.5628\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 926us/step - loss: 0.6651 - accuracy: 0.6068 - val_loss: 0.6897 - val_accuracy: 0.5653\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.6615 - accuracy: 0.6146 - val_loss: 0.6871 - val_accuracy: 0.5699\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 867us/step - loss: 0.6595 - accuracy: 0.6187 - val_loss: 0.6852 - val_accuracy: 0.5715\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6574 - accuracy: 0.6203 - val_loss: 0.6837 - val_accuracy: 0.5739\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 978us/step - loss: 0.6573 - accuracy: 0.6229 - val_loss: 0.6811 - val_accuracy: 0.5796\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6546 - accuracy: 0.6274 - val_loss: 0.6782 - val_accuracy: 0.5856\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6529 - accuracy: 0.6302 - val_loss: 0.6774 - val_accuracy: 0.5871\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6509 - accuracy: 0.6332 - val_loss: 0.6780 - val_accuracy: 0.5845\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 911us/step - loss: 0.6490 - accuracy: 0.6375 - val_loss: 0.6767 - val_accuracy: 0.5864\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 998us/step - loss: 0.6482 - accuracy: 0.6375 - val_loss: 0.6747 - val_accuracy: 0.5906\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 925us/step - loss: 0.6465 - accuracy: 0.6395 - val_loss: 0.6731 - val_accuracy: 0.5929\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 962us/step - loss: 0.6435 - accuracy: 0.6447 - val_loss: 0.6711 - val_accuracy: 0.5977\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6430 - accuracy: 0.6458 - val_loss: 0.6697 - val_accuracy: 0.6008\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 929us/step - loss: 0.6417 - accuracy: 0.6451 - val_loss: 0.6699 - val_accuracy: 0.6000\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 901us/step - loss: 0.6400 - accuracy: 0.6490 - val_loss: 0.6669 - val_accuracy: 0.6065\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 939us/step - loss: 0.6380 - accuracy: 0.6536 - val_loss: 0.6632 - val_accuracy: 0.6140\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 979us/step - loss: 0.6358 - accuracy: 0.6539 - val_loss: 0.6614 - val_accuracy: 0.6157\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6348 - accuracy: 0.6556 - val_loss: 0.6599 - val_accuracy: 0.6175\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 909us/step - loss: 0.6343 - accuracy: 0.6571 - val_loss: 0.6614 - val_accuracy: 0.6126\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 986us/step - loss: 0.6326 - accuracy: 0.6598 - val_loss: 0.6591 - val_accuracy: 0.6153\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 970us/step - loss: 0.6307 - accuracy: 0.6598 - val_loss: 0.6576 - val_accuracy: 0.6182\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 946us/step - loss: 0.6296 - accuracy: 0.6606 - val_loss: 0.6553 - val_accuracy: 0.6215\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 936us/step - loss: 0.6285 - accuracy: 0.6627 - val_loss: 0.6530 - val_accuracy: 0.6245\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6274 - accuracy: 0.6631 - val_loss: 0.6534 - val_accuracy: 0.6232\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6259 - accuracy: 0.6641 - val_loss: 0.6501 - val_accuracy: 0.6276\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6236 - accuracy: 0.6668 - val_loss: 0.6485 - val_accuracy: 0.6286\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6233 - accuracy: 0.6666 - val_loss: 0.6489 - val_accuracy: 0.6277\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6215 - accuracy: 0.6710 - val_loss: 0.6486 - val_accuracy: 0.6272\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6200 - accuracy: 0.6714 - val_loss: 0.6473 - val_accuracy: 0.6286\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6196 - accuracy: 0.6702 - val_loss: 0.6432 - val_accuracy: 0.6344\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 992us/step - loss: 0.6168 - accuracy: 0.6727 - val_loss: 0.6431 - val_accuracy: 0.6332\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6176 - accuracy: 0.6704 - val_loss: 0.6419 - val_accuracy: 0.6341\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6163 - accuracy: 0.6725 - val_loss: 0.6392 - val_accuracy: 0.6374\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 997us/step - loss: 0.6147 - accuracy: 0.6761 - val_loss: 0.6388 - val_accuracy: 0.6366\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.6129 - accuracy: 0.6778 - val_loss: 0.6362 - val_accuracy: 0.6393\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6127 - accuracy: 0.6782 - val_loss: 0.6353 - val_accuracy: 0.6392\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6107 - accuracy: 0.6800 - val_loss: 0.6368 - val_accuracy: 0.6363\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6084 - accuracy: 0.6810 - val_loss: 0.6360 - val_accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6089 - accuracy: 0.6792 - val_loss: 0.6345 - val_accuracy: 0.6371\n",
      "Epoch 1/50\n",
      "  1/836 [..............................] - ETA: 0s - loss: 0.7326 - accuracy: 0.5156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7222 - accuracy: 0.5221 - val_loss: 0.7596 - val_accuracy: 0.3316\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 919us/step - loss: 0.7063 - accuracy: 0.5242 - val_loss: 0.7286 - val_accuracy: 0.4280\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.7021 - accuracy: 0.5328 - val_loss: 0.7192 - val_accuracy: 0.4521\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6975 - accuracy: 0.5403 - val_loss: 0.7162 - val_accuracy: 0.4606\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 924us/step - loss: 0.6937 - accuracy: 0.5493 - val_loss: 0.7137 - val_accuracy: 0.4688\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 969us/step - loss: 0.6897 - accuracy: 0.5568 - val_loss: 0.7116 - val_accuracy: 0.4773\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5642 - val_loss: 0.7066 - val_accuracy: 0.4876\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 979us/step - loss: 0.6833 - accuracy: 0.5706 - val_loss: 0.7045 - val_accuracy: 0.4944\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.6795 - accuracy: 0.5771 - val_loss: 0.7005 - val_accuracy: 0.5050\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 910us/step - loss: 0.6765 - accuracy: 0.5847 - val_loss: 0.6952 - val_accuracy: 0.5184\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 941us/step - loss: 0.6738 - accuracy: 0.5898 - val_loss: 0.6920 - val_accuracy: 0.5274\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 924us/step - loss: 0.6718 - accuracy: 0.5933 - val_loss: 0.6931 - val_accuracy: 0.5250\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 907us/step - loss: 0.6692 - accuracy: 0.6014 - val_loss: 0.6873 - val_accuracy: 0.5385\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 947us/step - loss: 0.6672 - accuracy: 0.6010 - val_loss: 0.6856 - val_accuracy: 0.5399\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 963us/step - loss: 0.6651 - accuracy: 0.6039 - val_loss: 0.6858 - val_accuracy: 0.5375\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 984us/step - loss: 0.6616 - accuracy: 0.6143 - val_loss: 0.6818 - val_accuracy: 0.5454\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 1000us/step - loss: 0.6613 - accuracy: 0.6122 - val_loss: 0.6807 - val_accuracy: 0.5482\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6589 - accuracy: 0.6176 - val_loss: 0.6790 - val_accuracy: 0.5517\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 914us/step - loss: 0.6567 - accuracy: 0.6223 - val_loss: 0.6754 - val_accuracy: 0.5582\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 960us/step - loss: 0.6553 - accuracy: 0.6231 - val_loss: 0.6743 - val_accuracy: 0.5607\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6537 - accuracy: 0.6260 - val_loss: 0.6778 - val_accuracy: 0.5542\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 966us/step - loss: 0.6511 - accuracy: 0.6305 - val_loss: 0.6736 - val_accuracy: 0.5604\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 984us/step - loss: 0.6504 - accuracy: 0.6304 - val_loss: 0.6741 - val_accuracy: 0.5576\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 928us/step - loss: 0.6489 - accuracy: 0.6335 - val_loss: 0.6741 - val_accuracy: 0.5561\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 939us/step - loss: 0.6472 - accuracy: 0.6368 - val_loss: 0.6737 - val_accuracy: 0.5556\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 974us/step - loss: 0.6471 - accuracy: 0.6361 - val_loss: 0.6700 - val_accuracy: 0.5613\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6459 - accuracy: 0.6368 - val_loss: 0.6699 - val_accuracy: 0.5600\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 997us/step - loss: 0.6435 - accuracy: 0.6411 - val_loss: 0.6687 - val_accuracy: 0.5618\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 928us/step - loss: 0.6425 - accuracy: 0.6425 - val_loss: 0.6694 - val_accuracy: 0.5604\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 906us/step - loss: 0.6419 - accuracy: 0.6438 - val_loss: 0.6669 - val_accuracy: 0.5649\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 931us/step - loss: 0.6401 - accuracy: 0.6445 - val_loss: 0.6678 - val_accuracy: 0.5632\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 909us/step - loss: 0.6377 - accuracy: 0.6483 - val_loss: 0.6694 - val_accuracy: 0.5618\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 946us/step - loss: 0.6372 - accuracy: 0.6477 - val_loss: 0.6677 - val_accuracy: 0.5630\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 989us/step - loss: 0.6364 - accuracy: 0.6498 - val_loss: 0.6650 - val_accuracy: 0.5662\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.6358 - accuracy: 0.6500 - val_loss: 0.6627 - val_accuracy: 0.5698\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 921us/step - loss: 0.6341 - accuracy: 0.6528 - val_loss: 0.6611 - val_accuracy: 0.5727\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6332 - accuracy: 0.6540 - val_loss: 0.6591 - val_accuracy: 0.5741\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6321 - accuracy: 0.6554 - val_loss: 0.6596 - val_accuracy: 0.5744\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6297 - accuracy: 0.6552 - val_loss: 0.6576 - val_accuracy: 0.5762\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6292 - accuracy: 0.6583 - val_loss: 0.6589 - val_accuracy: 0.5748\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6293 - accuracy: 0.6583 - val_loss: 0.6543 - val_accuracy: 0.5798\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6281 - accuracy: 0.6611 - val_loss: 0.6551 - val_accuracy: 0.5783\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 932us/step - loss: 0.6273 - accuracy: 0.6613 - val_loss: 0.6548 - val_accuracy: 0.5783\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 929us/step - loss: 0.6264 - accuracy: 0.6601 - val_loss: 0.6561 - val_accuracy: 0.5753\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 972us/step - loss: 0.6247 - accuracy: 0.6603 - val_loss: 0.6523 - val_accuracy: 0.5816\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6241 - accuracy: 0.6618 - val_loss: 0.6522 - val_accuracy: 0.5820\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6236 - accuracy: 0.6621 - val_loss: 0.6511 - val_accuracy: 0.5839\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 944us/step - loss: 0.6213 - accuracy: 0.6643 - val_loss: 0.6526 - val_accuracy: 0.5809\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 826us/step - loss: 0.6216 - accuracy: 0.6646 - val_loss: 0.6521 - val_accuracy: 0.5809\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6204 - accuracy: 0.6651 - val_loss: 0.6486 - val_accuracy: 0.5860\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6919 - accuracy: 0.5393 - val_loss: 0.7008 - val_accuracy: 0.4926\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6869 - accuracy: 0.5520 - val_loss: 0.6994 - val_accuracy: 0.5043\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6844 - accuracy: 0.5596 - val_loss: 0.6959 - val_accuracy: 0.5201\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 963us/step - loss: 0.6826 - accuracy: 0.5617 - val_loss: 0.6938 - val_accuracy: 0.5299\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6800 - accuracy: 0.5706 - val_loss: 0.6904 - val_accuracy: 0.5471\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6768 - accuracy: 0.5775 - val_loss: 0.6889 - val_accuracy: 0.5579\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6745 - accuracy: 0.5813 - val_loss: 0.6863 - val_accuracy: 0.5726\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 910us/step - loss: 0.6722 - accuracy: 0.5854 - val_loss: 0.6839 - val_accuracy: 0.5816\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 924us/step - loss: 0.6698 - accuracy: 0.5931 - val_loss: 0.6830 - val_accuracy: 0.5834\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 862us/step - loss: 0.6665 - accuracy: 0.5986 - val_loss: 0.6813 - val_accuracy: 0.5897\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6665 - accuracy: 0.5977 - val_loss: 0.6801 - val_accuracy: 0.5923\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6646 - accuracy: 0.6031 - val_loss: 0.6778 - val_accuracy: 0.5988\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 901us/step - loss: 0.6635 - accuracy: 0.6074 - val_loss: 0.6762 - val_accuracy: 0.6031\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.6610 - accuracy: 0.6119 - val_loss: 0.6745 - val_accuracy: 0.6068\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.6591 - accuracy: 0.6164 - val_loss: 0.6741 - val_accuracy: 0.6062\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 895us/step - loss: 0.6584 - accuracy: 0.6181 - val_loss: 0.6737 - val_accuracy: 0.6052\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 900us/step - loss: 0.6562 - accuracy: 0.6242 - val_loss: 0.6719 - val_accuracy: 0.6103\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6560 - accuracy: 0.6226 - val_loss: 0.6708 - val_accuracy: 0.6111\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 708us/step - loss: 0.6527 - accuracy: 0.6317 - val_loss: 0.6688 - val_accuracy: 0.6147\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 936us/step - loss: 0.6520 - accuracy: 0.6336 - val_loss: 0.6683 - val_accuracy: 0.6159\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 807us/step - loss: 0.6510 - accuracy: 0.6348 - val_loss: 0.6687 - val_accuracy: 0.6131\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6496 - accuracy: 0.6351 - val_loss: 0.6671 - val_accuracy: 0.6167\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 923us/step - loss: 0.6472 - accuracy: 0.6404 - val_loss: 0.6638 - val_accuracy: 0.6240\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 886us/step - loss: 0.6467 - accuracy: 0.6406 - val_loss: 0.6639 - val_accuracy: 0.6225\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6462 - accuracy: 0.6400 - val_loss: 0.6627 - val_accuracy: 0.6242\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6434 - accuracy: 0.6471 - val_loss: 0.6603 - val_accuracy: 0.6298\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6429 - accuracy: 0.6450 - val_loss: 0.6587 - val_accuracy: 0.6333\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6411 - accuracy: 0.6484 - val_loss: 0.6576 - val_accuracy: 0.6343\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6403 - accuracy: 0.6486 - val_loss: 0.6560 - val_accuracy: 0.6360\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6380 - accuracy: 0.6550 - val_loss: 0.6563 - val_accuracy: 0.6346\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 958us/step - loss: 0.6371 - accuracy: 0.6549 - val_loss: 0.6552 - val_accuracy: 0.6355\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6357 - accuracy: 0.6584 - val_loss: 0.6545 - val_accuracy: 0.6357\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6346 - accuracy: 0.6581 - val_loss: 0.6541 - val_accuracy: 0.6346\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6336 - accuracy: 0.6614 - val_loss: 0.6523 - val_accuracy: 0.6363\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6322 - accuracy: 0.6621 - val_loss: 0.6514 - val_accuracy: 0.6366\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 890us/step - loss: 0.6309 - accuracy: 0.6634 - val_loss: 0.6493 - val_accuracy: 0.6392\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6305 - accuracy: 0.6628 - val_loss: 0.6496 - val_accuracy: 0.6367\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 875us/step - loss: 0.6270 - accuracy: 0.6701 - val_loss: 0.6470 - val_accuracy: 0.6404\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6267 - accuracy: 0.6677 - val_loss: 0.6456 - val_accuracy: 0.6419\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 987us/step - loss: 0.6250 - accuracy: 0.6696 - val_loss: 0.6456 - val_accuracy: 0.6403\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 941us/step - loss: 0.6250 - accuracy: 0.6682 - val_loss: 0.6437 - val_accuracy: 0.6424\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6224 - accuracy: 0.6735 - val_loss: 0.6443 - val_accuracy: 0.6404\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6212 - accuracy: 0.6730 - val_loss: 0.6415 - val_accuracy: 0.6439\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6203 - accuracy: 0.6747 - val_loss: 0.6424 - val_accuracy: 0.6417\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6184 - accuracy: 0.6762 - val_loss: 0.6400 - val_accuracy: 0.6450\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6175 - accuracy: 0.6768 - val_loss: 0.6373 - val_accuracy: 0.6496\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6154 - accuracy: 0.6784 - val_loss: 0.6364 - val_accuracy: 0.6512\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 923us/step - loss: 0.6148 - accuracy: 0.6794 - val_loss: 0.6337 - val_accuracy: 0.6560\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 949us/step - loss: 0.6146 - accuracy: 0.6784 - val_loss: 0.6342 - val_accuracy: 0.6547\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6127 - accuracy: 0.6807 - val_loss: 0.6374 - val_accuracy: 0.6457\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.7183 - accuracy: 0.5356 - val_loss: 0.7739 - val_accuracy: 0.2005\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 930us/step - loss: 0.6986 - accuracy: 0.5461 - val_loss: 0.7227 - val_accuracy: 0.3908\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6892 - accuracy: 0.5577 - val_loss: 0.7095 - val_accuracy: 0.4428\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6852 - accuracy: 0.5659 - val_loss: 0.6992 - val_accuracy: 0.4693\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 856us/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6972 - val_accuracy: 0.4797\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6754 - accuracy: 0.5891 - val_loss: 0.6900 - val_accuracy: 0.5137\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6713 - accuracy: 0.5926 - val_loss: 0.6894 - val_accuracy: 0.5195\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 894us/step - loss: 0.6686 - accuracy: 0.5996 - val_loss: 0.6866 - val_accuracy: 0.5307\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6650 - accuracy: 0.6081 - val_loss: 0.6838 - val_accuracy: 0.5413\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 921us/step - loss: 0.6612 - accuracy: 0.6156 - val_loss: 0.6804 - val_accuracy: 0.5525\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6585 - accuracy: 0.6194 - val_loss: 0.6774 - val_accuracy: 0.5608\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 808us/step - loss: 0.6550 - accuracy: 0.6267 - val_loss: 0.6770 - val_accuracy: 0.5632\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6529 - accuracy: 0.6305 - val_loss: 0.6723 - val_accuracy: 0.5778\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6495 - accuracy: 0.6377 - val_loss: 0.6671 - val_accuracy: 0.5925\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6456 - accuracy: 0.6423 - val_loss: 0.6642 - val_accuracy: 0.6018\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 962us/step - loss: 0.6442 - accuracy: 0.6412 - val_loss: 0.6629 - val_accuracy: 0.6025\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 848us/step - loss: 0.6414 - accuracy: 0.6493 - val_loss: 0.6634 - val_accuracy: 0.6006\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6415 - accuracy: 0.6487 - val_loss: 0.6608 - val_accuracy: 0.6060\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 888us/step - loss: 0.6379 - accuracy: 0.6543 - val_loss: 0.6593 - val_accuracy: 0.6085\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.6339 - accuracy: 0.6592 - val_loss: 0.6589 - val_accuracy: 0.6089\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6326 - accuracy: 0.6625 - val_loss: 0.6555 - val_accuracy: 0.6158\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 904us/step - loss: 0.6314 - accuracy: 0.6631 - val_loss: 0.6524 - val_accuracy: 0.6215\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6284 - accuracy: 0.6666 - val_loss: 0.6517 - val_accuracy: 0.6211\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 940us/step - loss: 0.6260 - accuracy: 0.6707 - val_loss: 0.6499 - val_accuracy: 0.6229\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6251 - accuracy: 0.6704 - val_loss: 0.6486 - val_accuracy: 0.6250\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6219 - accuracy: 0.6741 - val_loss: 0.6438 - val_accuracy: 0.6310\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 930us/step - loss: 0.6206 - accuracy: 0.6746 - val_loss: 0.6456 - val_accuracy: 0.6268\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6189 - accuracy: 0.6756 - val_loss: 0.6437 - val_accuracy: 0.6287\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 869us/step - loss: 0.6182 - accuracy: 0.6763 - val_loss: 0.6413 - val_accuracy: 0.6310\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.6158 - accuracy: 0.6782 - val_loss: 0.6446 - val_accuracy: 0.6247\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6154 - accuracy: 0.6803 - val_loss: 0.6382 - val_accuracy: 0.6336\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6129 - accuracy: 0.6814 - val_loss: 0.6372 - val_accuracy: 0.6357\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6109 - accuracy: 0.6825 - val_loss: 0.6331 - val_accuracy: 0.6413\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 848us/step - loss: 0.6094 - accuracy: 0.6853 - val_loss: 0.6333 - val_accuracy: 0.6402\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6090 - accuracy: 0.6834 - val_loss: 0.6325 - val_accuracy: 0.6407\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6069 - accuracy: 0.6857 - val_loss: 0.6314 - val_accuracy: 0.6424\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 813us/step - loss: 0.6057 - accuracy: 0.6866 - val_loss: 0.6286 - val_accuracy: 0.6460\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6043 - accuracy: 0.6881 - val_loss: 0.6318 - val_accuracy: 0.6399\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6020 - accuracy: 0.6896 - val_loss: 0.6286 - val_accuracy: 0.6434\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.6001 - accuracy: 0.6916 - val_loss: 0.6292 - val_accuracy: 0.6422\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.5998 - accuracy: 0.6924 - val_loss: 0.6292 - val_accuracy: 0.6410\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.5986 - accuracy: 0.6922 - val_loss: 0.6231 - val_accuracy: 0.6478\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.5981 - accuracy: 0.6922 - val_loss: 0.6241 - val_accuracy: 0.6465\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.5953 - accuracy: 0.6924 - val_loss: 0.6192 - val_accuracy: 0.6510\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 797us/step - loss: 0.5945 - accuracy: 0.6952 - val_loss: 0.6248 - val_accuracy: 0.6441\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.5933 - accuracy: 0.6964 - val_loss: 0.6204 - val_accuracy: 0.6487\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.5923 - accuracy: 0.6965 - val_loss: 0.6170 - val_accuracy: 0.6514\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.5903 - accuracy: 0.6991 - val_loss: 0.6192 - val_accuracy: 0.6477\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.5905 - accuracy: 0.6983 - val_loss: 0.6164 - val_accuracy: 0.6504\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.5892 - accuracy: 0.6995 - val_loss: 0.6185 - val_accuracy: 0.6472\n",
      "Epoch 1/50\n",
      "  1/836 [..............................] - ETA: 0s - loss: 0.6971 - accuracy: 0.6094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 987us/step - loss: 0.7240 - accuracy: 0.5070 - val_loss: 0.8079 - val_accuracy: 0.1574\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 868us/step - loss: 0.7108 - accuracy: 0.4990 - val_loss: 0.7585 - val_accuracy: 0.1817\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.7063 - accuracy: 0.4993 - val_loss: 0.7378 - val_accuracy: 0.2153\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 880us/step - loss: 0.7038 - accuracy: 0.5024 - val_loss: 0.7282 - val_accuracy: 0.2612\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 810us/step - loss: 0.7020 - accuracy: 0.5076 - val_loss: 0.7238 - val_accuracy: 0.3065\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6988 - accuracy: 0.5151 - val_loss: 0.7190 - val_accuracy: 0.3556\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6954 - accuracy: 0.5229 - val_loss: 0.7165 - val_accuracy: 0.3754\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6928 - accuracy: 0.5293 - val_loss: 0.7134 - val_accuracy: 0.4004\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6910 - accuracy: 0.5338 - val_loss: 0.7111 - val_accuracy: 0.4189\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6881 - accuracy: 0.5385 - val_loss: 0.7059 - val_accuracy: 0.4430\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.6866 - accuracy: 0.5461 - val_loss: 0.7054 - val_accuracy: 0.4466\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.6850 - accuracy: 0.5492 - val_loss: 0.7038 - val_accuracy: 0.4542\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 790us/step - loss: 0.6819 - accuracy: 0.5547 - val_loss: 0.7013 - val_accuracy: 0.4649\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 866us/step - loss: 0.6801 - accuracy: 0.5614 - val_loss: 0.6980 - val_accuracy: 0.4794\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 948us/step - loss: 0.6779 - accuracy: 0.5648 - val_loss: 0.6976 - val_accuracy: 0.4865\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 979us/step - loss: 0.6757 - accuracy: 0.5738 - val_loss: 0.6941 - val_accuracy: 0.5065\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6744 - accuracy: 0.5729 - val_loss: 0.6911 - val_accuracy: 0.5175\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 943us/step - loss: 0.6721 - accuracy: 0.5789 - val_loss: 0.6896 - val_accuracy: 0.5237\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6715 - accuracy: 0.5820 - val_loss: 0.6886 - val_accuracy: 0.5265\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 896us/step - loss: 0.6695 - accuracy: 0.5870 - val_loss: 0.6880 - val_accuracy: 0.5299\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 900us/step - loss: 0.6677 - accuracy: 0.5903 - val_loss: 0.6871 - val_accuracy: 0.5333\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 910us/step - loss: 0.6659 - accuracy: 0.5919 - val_loss: 0.6840 - val_accuracy: 0.5421\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6644 - accuracy: 0.5970 - val_loss: 0.6823 - val_accuracy: 0.5466\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6620 - accuracy: 0.6025 - val_loss: 0.6807 - val_accuracy: 0.5508\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6611 - accuracy: 0.6034 - val_loss: 0.6797 - val_accuracy: 0.5525\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.6598 - accuracy: 0.6056 - val_loss: 0.6785 - val_accuracy: 0.5562\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.6580 - accuracy: 0.6112 - val_loss: 0.6771 - val_accuracy: 0.5607\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6573 - accuracy: 0.6103 - val_loss: 0.6766 - val_accuracy: 0.5626\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6553 - accuracy: 0.6153 - val_loss: 0.6744 - val_accuracy: 0.5659\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6533 - accuracy: 0.6189 - val_loss: 0.6722 - val_accuracy: 0.5716\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 921us/step - loss: 0.6520 - accuracy: 0.6186 - val_loss: 0.6703 - val_accuracy: 0.5757\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 998us/step - loss: 0.6512 - accuracy: 0.6211 - val_loss: 0.6686 - val_accuracy: 0.5802\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6492 - accuracy: 0.6232 - val_loss: 0.6669 - val_accuracy: 0.5855\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6480 - accuracy: 0.6273 - val_loss: 0.6659 - val_accuracy: 0.5882\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 988us/step - loss: 0.6470 - accuracy: 0.6277 - val_loss: 0.6644 - val_accuracy: 0.5905\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6454 - accuracy: 0.6297 - val_loss: 0.6632 - val_accuracy: 0.5927\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6448 - accuracy: 0.6313 - val_loss: 0.6620 - val_accuracy: 0.5941\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6422 - accuracy: 0.6355 - val_loss: 0.6623 - val_accuracy: 0.5922\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 993us/step - loss: 0.6416 - accuracy: 0.6357 - val_loss: 0.6598 - val_accuracy: 0.5983\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6403 - accuracy: 0.6355 - val_loss: 0.6585 - val_accuracy: 0.6004\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.6390 - accuracy: 0.6381 - val_loss: 0.6581 - val_accuracy: 0.6018\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6376 - accuracy: 0.6400 - val_loss: 0.6565 - val_accuracy: 0.6072\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6366 - accuracy: 0.6401 - val_loss: 0.6566 - val_accuracy: 0.6060\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 994us/step - loss: 0.6355 - accuracy: 0.6443 - val_loss: 0.6561 - val_accuracy: 0.6060\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.6345 - accuracy: 0.6434 - val_loss: 0.6541 - val_accuracy: 0.6099\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 963us/step - loss: 0.6332 - accuracy: 0.6471 - val_loss: 0.6533 - val_accuracy: 0.6119\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 940us/step - loss: 0.6311 - accuracy: 0.6478 - val_loss: 0.6507 - val_accuracy: 0.6164\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.6308 - accuracy: 0.6465 - val_loss: 0.6508 - val_accuracy: 0.6152\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.6299 - accuracy: 0.6473 - val_loss: 0.6485 - val_accuracy: 0.6198\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6279 - accuracy: 0.6502 - val_loss: 0.6465 - val_accuracy: 0.6228\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 980us/step - loss: 0.6924 - accuracy: 0.5439 - val_loss: 0.6813 - val_accuracy: 0.5636\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6829 - accuracy: 0.5656 - val_loss: 0.6995 - val_accuracy: 0.4625\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 967us/step - loss: 0.6787 - accuracy: 0.5786 - val_loss: 0.7014 - val_accuracy: 0.4632\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 968us/step - loss: 0.6728 - accuracy: 0.5924 - val_loss: 0.6991 - val_accuracy: 0.4811\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 954us/step - loss: 0.6695 - accuracy: 0.5988 - val_loss: 0.6954 - val_accuracy: 0.5053\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6669 - accuracy: 0.6051 - val_loss: 0.6931 - val_accuracy: 0.5163\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6628 - accuracy: 0.6168 - val_loss: 0.6865 - val_accuracy: 0.5405\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6598 - accuracy: 0.6220 - val_loss: 0.6847 - val_accuracy: 0.5458\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 958us/step - loss: 0.6580 - accuracy: 0.6262 - val_loss: 0.6845 - val_accuracy: 0.5453\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 986us/step - loss: 0.6554 - accuracy: 0.6299 - val_loss: 0.6817 - val_accuracy: 0.5520\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.6529 - accuracy: 0.6357 - val_loss: 0.6786 - val_accuracy: 0.5604\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 950us/step - loss: 0.6509 - accuracy: 0.6383 - val_loss: 0.6753 - val_accuracy: 0.5693\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6489 - accuracy: 0.6416 - val_loss: 0.6737 - val_accuracy: 0.5720\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6462 - accuracy: 0.6479 - val_loss: 0.6723 - val_accuracy: 0.5740\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 941us/step - loss: 0.6458 - accuracy: 0.6482 - val_loss: 0.6705 - val_accuracy: 0.5788\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 907us/step - loss: 0.6434 - accuracy: 0.6527 - val_loss: 0.6681 - val_accuracy: 0.5835\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 961us/step - loss: 0.6410 - accuracy: 0.6561 - val_loss: 0.6660 - val_accuracy: 0.5886\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6398 - accuracy: 0.6546 - val_loss: 0.6641 - val_accuracy: 0.5922\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6364 - accuracy: 0.6615 - val_loss: 0.6617 - val_accuracy: 0.5977\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6358 - accuracy: 0.6633 - val_loss: 0.6603 - val_accuracy: 0.6009\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 954us/step - loss: 0.6336 - accuracy: 0.6658 - val_loss: 0.6595 - val_accuracy: 0.6021\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 990us/step - loss: 0.6323 - accuracy: 0.6690 - val_loss: 0.6549 - val_accuracy: 0.6114\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 874us/step - loss: 0.6312 - accuracy: 0.6681 - val_loss: 0.6556 - val_accuracy: 0.6096\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 921us/step - loss: 0.6288 - accuracy: 0.6715 - val_loss: 0.6543 - val_accuracy: 0.6121\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6277 - accuracy: 0.6725 - val_loss: 0.6541 - val_accuracy: 0.6125\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6265 - accuracy: 0.6735 - val_loss: 0.6527 - val_accuracy: 0.6147\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6247 - accuracy: 0.6774 - val_loss: 0.6535 - val_accuracy: 0.6123\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6237 - accuracy: 0.6778 - val_loss: 0.6522 - val_accuracy: 0.6144\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6223 - accuracy: 0.6793 - val_loss: 0.6505 - val_accuracy: 0.6158\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6209 - accuracy: 0.6771 - val_loss: 0.6483 - val_accuracy: 0.6185\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 974us/step - loss: 0.6196 - accuracy: 0.6827 - val_loss: 0.6463 - val_accuracy: 0.6203\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6180 - accuracy: 0.6821 - val_loss: 0.6449 - val_accuracy: 0.6220\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 961us/step - loss: 0.6162 - accuracy: 0.6833 - val_loss: 0.6457 - val_accuracy: 0.6195\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 974us/step - loss: 0.6157 - accuracy: 0.6839 - val_loss: 0.6454 - val_accuracy: 0.6192\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6146 - accuracy: 0.6843 - val_loss: 0.6416 - val_accuracy: 0.6248\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 968us/step - loss: 0.6139 - accuracy: 0.6856 - val_loss: 0.6423 - val_accuracy: 0.6219\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 964us/step - loss: 0.6121 - accuracy: 0.6873 - val_loss: 0.6416 - val_accuracy: 0.6234\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 966us/step - loss: 0.6101 - accuracy: 0.6907 - val_loss: 0.6399 - val_accuracy: 0.6256\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 961us/step - loss: 0.6093 - accuracy: 0.6912 - val_loss: 0.6399 - val_accuracy: 0.6252\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6091 - accuracy: 0.6889 - val_loss: 0.6398 - val_accuracy: 0.6249\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 948us/step - loss: 0.6076 - accuracy: 0.6914 - val_loss: 0.6383 - val_accuracy: 0.6269\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 977us/step - loss: 0.6054 - accuracy: 0.6936 - val_loss: 0.6392 - val_accuracy: 0.6256\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 900us/step - loss: 0.6059 - accuracy: 0.6906 - val_loss: 0.6356 - val_accuracy: 0.6311\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6057 - accuracy: 0.6932 - val_loss: 0.6326 - val_accuracy: 0.6376\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 971us/step - loss: 0.6038 - accuracy: 0.6950 - val_loss: 0.6366 - val_accuracy: 0.6288\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 896us/step - loss: 0.6027 - accuracy: 0.6947 - val_loss: 0.6317 - val_accuracy: 0.6394\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6018 - accuracy: 0.6939 - val_loss: 0.6314 - val_accuracy: 0.6397\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 982us/step - loss: 0.6017 - accuracy: 0.6955 - val_loss: 0.6285 - val_accuracy: 0.6429\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.5999 - accuracy: 0.6975 - val_loss: 0.6322 - val_accuracy: 0.6377\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 957us/step - loss: 0.5996 - accuracy: 0.6955 - val_loss: 0.6294 - val_accuracy: 0.6412\n",
      "Epoch 1/50\n",
      "777/836 [==========================>...] - ETA: 0s - loss: 0.7255 - accuracy: 0.5118WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7234 - accuracy: 0.5145 - val_loss: 0.6607 - val_accuracy: 0.6784\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6977 - accuracy: 0.5441 - val_loss: 0.6977 - val_accuracy: 0.4949\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 988us/step - loss: 0.6959 - accuracy: 0.5492 - val_loss: 0.7042 - val_accuracy: 0.4622\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 875us/step - loss: 0.6893 - accuracy: 0.5632 - val_loss: 0.7031 - val_accuracy: 0.4729\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.6852 - accuracy: 0.5704 - val_loss: 0.6989 - val_accuracy: 0.4978\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6810 - accuracy: 0.5797 - val_loss: 0.6934 - val_accuracy: 0.5257\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 965us/step - loss: 0.6766 - accuracy: 0.5850 - val_loss: 0.6891 - val_accuracy: 0.5440\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 980us/step - loss: 0.6751 - accuracy: 0.5884 - val_loss: 0.6910 - val_accuracy: 0.5391\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6704 - accuracy: 0.5963 - val_loss: 0.6876 - val_accuracy: 0.5494\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6677 - accuracy: 0.6021 - val_loss: 0.6854 - val_accuracy: 0.5551\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.6075 - val_loss: 0.6828 - val_accuracy: 0.5620\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6608 - accuracy: 0.6179 - val_loss: 0.6807 - val_accuracy: 0.5675\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.6206 - val_loss: 0.6775 - val_accuracy: 0.5759\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 985us/step - loss: 0.6554 - accuracy: 0.6262 - val_loss: 0.6763 - val_accuracy: 0.5791\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 970us/step - loss: 0.6529 - accuracy: 0.6302 - val_loss: 0.6728 - val_accuracy: 0.5877\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6496 - accuracy: 0.6348 - val_loss: 0.6702 - val_accuracy: 0.5927\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 923us/step - loss: 0.6475 - accuracy: 0.6394 - val_loss: 0.6670 - val_accuracy: 0.5994\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 972us/step - loss: 0.6444 - accuracy: 0.6455 - val_loss: 0.6638 - val_accuracy: 0.6044\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 952us/step - loss: 0.6425 - accuracy: 0.6465 - val_loss: 0.6613 - val_accuracy: 0.6083\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 874us/step - loss: 0.6400 - accuracy: 0.6511 - val_loss: 0.6599 - val_accuracy: 0.6114\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 914us/step - loss: 0.6386 - accuracy: 0.6524 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 923us/step - loss: 0.6364 - accuracy: 0.6542 - val_loss: 0.6562 - val_accuracy: 0.6185\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 956us/step - loss: 0.6345 - accuracy: 0.6552 - val_loss: 0.6547 - val_accuracy: 0.6214\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 965us/step - loss: 0.6328 - accuracy: 0.6614 - val_loss: 0.6518 - val_accuracy: 0.6262\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 959us/step - loss: 0.6294 - accuracy: 0.6656 - val_loss: 0.6522 - val_accuracy: 0.6259\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6275 - accuracy: 0.6668 - val_loss: 0.6490 - val_accuracy: 0.6322\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6260 - accuracy: 0.6720 - val_loss: 0.6473 - val_accuracy: 0.6349\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 928us/step - loss: 0.6242 - accuracy: 0.6706 - val_loss: 0.6477 - val_accuracy: 0.6335\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 980us/step - loss: 0.6235 - accuracy: 0.6718 - val_loss: 0.6465 - val_accuracy: 0.6354\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6211 - accuracy: 0.6724 - val_loss: 0.6418 - val_accuracy: 0.6428\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6203 - accuracy: 0.6755 - val_loss: 0.6436 - val_accuracy: 0.6403\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 938us/step - loss: 0.6197 - accuracy: 0.6764 - val_loss: 0.6439 - val_accuracy: 0.6385\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 993us/step - loss: 0.6173 - accuracy: 0.6799 - val_loss: 0.6450 - val_accuracy: 0.6344\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 911us/step - loss: 0.6161 - accuracy: 0.6793 - val_loss: 0.6393 - val_accuracy: 0.6446\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6153 - accuracy: 0.6783 - val_loss: 0.6385 - val_accuracy: 0.6448\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 925us/step - loss: 0.6141 - accuracy: 0.6819 - val_loss: 0.6379 - val_accuracy: 0.6446\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6135 - accuracy: 0.6815 - val_loss: 0.6369 - val_accuracy: 0.6451\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 868us/step - loss: 0.6112 - accuracy: 0.6850 - val_loss: 0.6362 - val_accuracy: 0.6457\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6097 - accuracy: 0.6856 - val_loss: 0.6376 - val_accuracy: 0.6420\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 936us/step - loss: 0.6086 - accuracy: 0.6848 - val_loss: 0.6330 - val_accuracy: 0.6480\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 893us/step - loss: 0.6078 - accuracy: 0.6860 - val_loss: 0.6337 - val_accuracy: 0.6466\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 848us/step - loss: 0.6072 - accuracy: 0.6863 - val_loss: 0.6349 - val_accuracy: 0.6447\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.6052 - accuracy: 0.6891 - val_loss: 0.6341 - val_accuracy: 0.6454\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 980us/step - loss: 0.6046 - accuracy: 0.6877 - val_loss: 0.6315 - val_accuracy: 0.6491\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6029 - accuracy: 0.6896 - val_loss: 0.6290 - val_accuracy: 0.6511\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6021 - accuracy: 0.6897 - val_loss: 0.6303 - val_accuracy: 0.6497\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6010 - accuracy: 0.6904 - val_loss: 0.6298 - val_accuracy: 0.6499\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6003 - accuracy: 0.6918 - val_loss: 0.6267 - val_accuracy: 0.6524\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 959us/step - loss: 0.5989 - accuracy: 0.6951 - val_loss: 0.6287 - val_accuracy: 0.6499\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.5972 - accuracy: 0.6934 - val_loss: 0.6298 - val_accuracy: 0.6475\n",
      "\n",
      "Training model with batch_size=64, target_eps=2.0...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 5.05 iterated over 41800 steps satisfies differential privacy with eps = 0.245 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.5749999999999997 iterated over 41800 steps satisfies differential privacy with eps = 0.481 and delta = 1e-05.\n",
      "The optimal RDP order is 49.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3375 iterated over 41800 steps satisfies differential privacy with eps = 1.05 and delta = 1e-05.\n",
      "The optimal RDP order is 22.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.71875 iterated over 41800 steps satisfies differential privacy with eps = 3.62 and delta = 1e-05.\n",
      "The optimal RDP order is 6.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.028125 iterated over 41800 steps satisfies differential privacy with eps = 1.6 and delta = 1e-05.\n",
      "The optimal RDP order is 13.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.8734375 iterated over 41800 steps satisfies differential privacy with eps = 2.21 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.9507812499999999 iterated over 41800 steps satisfies differential privacy with eps = 1.85 and delta = 1e-05.\n",
      "The optimal RDP order is 11.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.912109375 iterated over 41800 steps satisfies differential privacy with eps = 2.02 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.9314453125 iterated over 41800 steps satisfies differential privacy with eps = 1.95 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.92177734375 iterated over 41800 steps satisfies differential privacy with eps = 1.98 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.916943359375 iterated over 41800 steps satisfies differential privacy with eps = 2 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7020 - accuracy: 0.4989 - val_loss: 0.7404 - val_accuracy: 0.1973\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 881us/step - loss: 0.6966 - accuracy: 0.5137 - val_loss: 0.7369 - val_accuracy: 0.2057\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6920 - accuracy: 0.5267 - val_loss: 0.7323 - val_accuracy: 0.2268\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6876 - accuracy: 0.5375 - val_loss: 0.7264 - val_accuracy: 0.2589\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6851 - accuracy: 0.5471 - val_loss: 0.7208 - val_accuracy: 0.3055\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6814 - accuracy: 0.5599 - val_loss: 0.7145 - val_accuracy: 0.3793\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 989us/step - loss: 0.6782 - accuracy: 0.5723 - val_loss: 0.7104 - val_accuracy: 0.4280\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6755 - accuracy: 0.5812 - val_loss: 0.7063 - val_accuracy: 0.4673\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6726 - accuracy: 0.5894 - val_loss: 0.7032 - val_accuracy: 0.4857\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6702 - accuracy: 0.5962 - val_loss: 0.7002 - val_accuracy: 0.5034\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 848us/step - loss: 0.6684 - accuracy: 0.6011 - val_loss: 0.6958 - val_accuracy: 0.5320\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6665 - accuracy: 0.6088 - val_loss: 0.6939 - val_accuracy: 0.5423\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6643 - accuracy: 0.6167 - val_loss: 0.6929 - val_accuracy: 0.5467\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 887us/step - loss: 0.6620 - accuracy: 0.6211 - val_loss: 0.6898 - val_accuracy: 0.5603\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6610 - accuracy: 0.6215 - val_loss: 0.6900 - val_accuracy: 0.5562\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 884us/step - loss: 0.6586 - accuracy: 0.6294 - val_loss: 0.6881 - val_accuracy: 0.5626\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6573 - accuracy: 0.6288 - val_loss: 0.6854 - val_accuracy: 0.5729\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6554 - accuracy: 0.6325 - val_loss: 0.6827 - val_accuracy: 0.5821\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6540 - accuracy: 0.6354 - val_loss: 0.6809 - val_accuracy: 0.5873\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6527 - accuracy: 0.6380 - val_loss: 0.6810 - val_accuracy: 0.5856\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 866us/step - loss: 0.6508 - accuracy: 0.6399 - val_loss: 0.6794 - val_accuracy: 0.5895\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 879us/step - loss: 0.6489 - accuracy: 0.6446 - val_loss: 0.6787 - val_accuracy: 0.5901\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.6475 - accuracy: 0.6468 - val_loss: 0.6769 - val_accuracy: 0.5926\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 920us/step - loss: 0.6463 - accuracy: 0.6458 - val_loss: 0.6750 - val_accuracy: 0.5953\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6442 - accuracy: 0.6498 - val_loss: 0.6736 - val_accuracy: 0.5983\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 883us/step - loss: 0.6423 - accuracy: 0.6536 - val_loss: 0.6739 - val_accuracy: 0.5965\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.6404 - accuracy: 0.6559 - val_loss: 0.6717 - val_accuracy: 0.6013\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6386 - accuracy: 0.6567 - val_loss: 0.6710 - val_accuracy: 0.6005\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.6377 - accuracy: 0.6562 - val_loss: 0.6690 - val_accuracy: 0.6029\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6350 - accuracy: 0.6618 - val_loss: 0.6665 - val_accuracy: 0.6068\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6334 - accuracy: 0.6603 - val_loss: 0.6661 - val_accuracy: 0.6060\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 914us/step - loss: 0.6315 - accuracy: 0.6659 - val_loss: 0.6627 - val_accuracy: 0.6091\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6303 - accuracy: 0.6679 - val_loss: 0.6613 - val_accuracy: 0.6098\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6281 - accuracy: 0.6684 - val_loss: 0.6604 - val_accuracy: 0.6107\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6265 - accuracy: 0.6672 - val_loss: 0.6572 - val_accuracy: 0.6157\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6240 - accuracy: 0.6728 - val_loss: 0.6572 - val_accuracy: 0.6150\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6222 - accuracy: 0.6733 - val_loss: 0.6544 - val_accuracy: 0.6198\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 858us/step - loss: 0.6200 - accuracy: 0.6768 - val_loss: 0.6516 - val_accuracy: 0.6251\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.6180 - accuracy: 0.6780 - val_loss: 0.6489 - val_accuracy: 0.6295\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6156 - accuracy: 0.6824 - val_loss: 0.6461 - val_accuracy: 0.6362\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6141 - accuracy: 0.6829 - val_loss: 0.6446 - val_accuracy: 0.6372\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6125 - accuracy: 0.6840 - val_loss: 0.6459 - val_accuracy: 0.6343\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6098 - accuracy: 0.6884 - val_loss: 0.6446 - val_accuracy: 0.6356\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 862us/step - loss: 0.6083 - accuracy: 0.6859 - val_loss: 0.6419 - val_accuracy: 0.6403\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 920us/step - loss: 0.6070 - accuracy: 0.6886 - val_loss: 0.6409 - val_accuracy: 0.6399\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6069 - accuracy: 0.6873 - val_loss: 0.6387 - val_accuracy: 0.6431\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6054 - accuracy: 0.6883 - val_loss: 0.6379 - val_accuracy: 0.6430\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 865us/step - loss: 0.6030 - accuracy: 0.6914 - val_loss: 0.6366 - val_accuracy: 0.6446\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6017 - accuracy: 0.6903 - val_loss: 0.6362 - val_accuracy: 0.6443\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6009 - accuracy: 0.6936 - val_loss: 0.6363 - val_accuracy: 0.6425\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.6899 - accuracy: 0.5447 - val_loss: 0.6929 - val_accuracy: 0.5442\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 865us/step - loss: 0.6869 - accuracy: 0.5508 - val_loss: 0.7051 - val_accuracy: 0.4726\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 892us/step - loss: 0.6836 - accuracy: 0.5610 - val_loss: 0.7057 - val_accuracy: 0.4701\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 962us/step - loss: 0.6810 - accuracy: 0.5650 - val_loss: 0.7044 - val_accuracy: 0.4789\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6784 - accuracy: 0.5705 - val_loss: 0.7038 - val_accuracy: 0.4846\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6768 - accuracy: 0.5777 - val_loss: 0.6994 - val_accuracy: 0.5087\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.6765 - accuracy: 0.5761 - val_loss: 0.6976 - val_accuracy: 0.5187\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6712 - accuracy: 0.5871 - val_loss: 0.6962 - val_accuracy: 0.5258\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 865us/step - loss: 0.6707 - accuracy: 0.5870 - val_loss: 0.6953 - val_accuracy: 0.5283\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6682 - accuracy: 0.5959 - val_loss: 0.6930 - val_accuracy: 0.5396\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 880us/step - loss: 0.6666 - accuracy: 0.5982 - val_loss: 0.6903 - val_accuracy: 0.5503\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6646 - accuracy: 0.6044 - val_loss: 0.6884 - val_accuracy: 0.5580\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 856us/step - loss: 0.6609 - accuracy: 0.6096 - val_loss: 0.6867 - val_accuracy: 0.5661\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 950us/step - loss: 0.6605 - accuracy: 0.6100 - val_loss: 0.6849 - val_accuracy: 0.5735\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 809us/step - loss: 0.6591 - accuracy: 0.6145 - val_loss: 0.6826 - val_accuracy: 0.5826\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6562 - accuracy: 0.6194 - val_loss: 0.6799 - val_accuracy: 0.5900\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 848us/step - loss: 0.6555 - accuracy: 0.6224 - val_loss: 0.6782 - val_accuracy: 0.5958\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 915us/step - loss: 0.6536 - accuracy: 0.6252 - val_loss: 0.6759 - val_accuracy: 0.6047\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6525 - accuracy: 0.6262 - val_loss: 0.6755 - val_accuracy: 0.6051\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 896us/step - loss: 0.6505 - accuracy: 0.6315 - val_loss: 0.6721 - val_accuracy: 0.6171\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6490 - accuracy: 0.6348 - val_loss: 0.6715 - val_accuracy: 0.6179\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6472 - accuracy: 0.6368 - val_loss: 0.6711 - val_accuracy: 0.6176\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6440 - accuracy: 0.6422 - val_loss: 0.6679 - val_accuracy: 0.6248\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6438 - accuracy: 0.6404 - val_loss: 0.6674 - val_accuracy: 0.6241\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6424 - accuracy: 0.6451 - val_loss: 0.6665 - val_accuracy: 0.6251\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 913us/step - loss: 0.6412 - accuracy: 0.6448 - val_loss: 0.6667 - val_accuracy: 0.6231\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6395 - accuracy: 0.6510 - val_loss: 0.6649 - val_accuracy: 0.6267\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6386 - accuracy: 0.6502 - val_loss: 0.6647 - val_accuracy: 0.6252\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6370 - accuracy: 0.6537 - val_loss: 0.6623 - val_accuracy: 0.6299\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6354 - accuracy: 0.6555 - val_loss: 0.6610 - val_accuracy: 0.6310\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.6348 - accuracy: 0.6546 - val_loss: 0.6571 - val_accuracy: 0.6380\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6330 - accuracy: 0.6564 - val_loss: 0.6559 - val_accuracy: 0.6381\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.6307 - accuracy: 0.6603 - val_loss: 0.6554 - val_accuracy: 0.6375\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 861us/step - loss: 0.6298 - accuracy: 0.6620 - val_loss: 0.6534 - val_accuracy: 0.6396\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 933us/step - loss: 0.6288 - accuracy: 0.6625 - val_loss: 0.6511 - val_accuracy: 0.6447\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6279 - accuracy: 0.6623 - val_loss: 0.6512 - val_accuracy: 0.6427\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6264 - accuracy: 0.6640 - val_loss: 0.6493 - val_accuracy: 0.6450\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 955us/step - loss: 0.6264 - accuracy: 0.6633 - val_loss: 0.6489 - val_accuracy: 0.6438\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6234 - accuracy: 0.6692 - val_loss: 0.6490 - val_accuracy: 0.6420\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6228 - accuracy: 0.6672 - val_loss: 0.6467 - val_accuracy: 0.6455\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 957us/step - loss: 0.6212 - accuracy: 0.6697 - val_loss: 0.6444 - val_accuracy: 0.6490\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6202 - accuracy: 0.6695 - val_loss: 0.6437 - val_accuracy: 0.6497\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 888us/step - loss: 0.6189 - accuracy: 0.6718 - val_loss: 0.6407 - val_accuracy: 0.6570\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 881us/step - loss: 0.6173 - accuracy: 0.6737 - val_loss: 0.6412 - val_accuracy: 0.6535\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6165 - accuracy: 0.6733 - val_loss: 0.6430 - val_accuracy: 0.6467\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6156 - accuracy: 0.6723 - val_loss: 0.6401 - val_accuracy: 0.6522\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 939us/step - loss: 0.6141 - accuracy: 0.6751 - val_loss: 0.6375 - val_accuracy: 0.6569\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 872us/step - loss: 0.6135 - accuracy: 0.6760 - val_loss: 0.6403 - val_accuracy: 0.6477\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.6130 - accuracy: 0.6761 - val_loss: 0.6388 - val_accuracy: 0.6500\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.6113 - accuracy: 0.6782 - val_loss: 0.6344 - val_accuracy: 0.6575\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 890us/step - loss: 0.7347 - accuracy: 0.5078 - val_loss: 0.8044 - val_accuracy: 0.1755\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7121 - accuracy: 0.5002 - val_loss: 0.7507 - val_accuracy: 0.2885\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.7064 - accuracy: 0.5013 - val_loss: 0.7360 - val_accuracy: 0.3256\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.7023 - accuracy: 0.5099 - val_loss: 0.7293 - val_accuracy: 0.3347\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 854us/step - loss: 0.6989 - accuracy: 0.5142 - val_loss: 0.7236 - val_accuracy: 0.3434\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 862us/step - loss: 0.6933 - accuracy: 0.5301 - val_loss: 0.7184 - val_accuracy: 0.3559\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6903 - accuracy: 0.5355 - val_loss: 0.7150 - val_accuracy: 0.3691\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6851 - accuracy: 0.5448 - val_loss: 0.7076 - val_accuracy: 0.4126\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6818 - accuracy: 0.5531 - val_loss: 0.7015 - val_accuracy: 0.4545\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.6764 - accuracy: 0.5646 - val_loss: 0.6959 - val_accuracy: 0.5121\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6719 - accuracy: 0.5744 - val_loss: 0.6934 - val_accuracy: 0.5399\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6678 - accuracy: 0.5865 - val_loss: 0.6904 - val_accuracy: 0.5528\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6655 - accuracy: 0.5922 - val_loss: 0.6854 - val_accuracy: 0.5653\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 950us/step - loss: 0.6620 - accuracy: 0.5996 - val_loss: 0.6844 - val_accuracy: 0.5631\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6029 - val_loss: 0.6817 - val_accuracy: 0.5671\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 954us/step - loss: 0.6575 - accuracy: 0.6115 - val_loss: 0.6787 - val_accuracy: 0.5725\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6554 - accuracy: 0.6115 - val_loss: 0.6761 - val_accuracy: 0.5793\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6533 - accuracy: 0.6161 - val_loss: 0.6758 - val_accuracy: 0.5806\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6504 - accuracy: 0.6219 - val_loss: 0.6748 - val_accuracy: 0.5848\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6483 - accuracy: 0.6248 - val_loss: 0.6707 - val_accuracy: 0.5980\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6466 - accuracy: 0.6283 - val_loss: 0.6693 - val_accuracy: 0.6057\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6444 - accuracy: 0.6325 - val_loss: 0.6694 - val_accuracy: 0.6027\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 991us/step - loss: 0.6428 - accuracy: 0.6355 - val_loss: 0.6667 - val_accuracy: 0.6102\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 958us/step - loss: 0.6408 - accuracy: 0.6366 - val_loss: 0.6623 - val_accuracy: 0.6215\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.6394 - accuracy: 0.6382 - val_loss: 0.6622 - val_accuracy: 0.6195\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6376 - accuracy: 0.6419 - val_loss: 0.6606 - val_accuracy: 0.6220\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.6366 - accuracy: 0.6420 - val_loss: 0.6574 - val_accuracy: 0.6282\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6343 - accuracy: 0.6478 - val_loss: 0.6572 - val_accuracy: 0.6252\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6324 - accuracy: 0.6490 - val_loss: 0.6558 - val_accuracy: 0.6265\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 898us/step - loss: 0.6319 - accuracy: 0.6507 - val_loss: 0.6537 - val_accuracy: 0.6288\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.6291 - accuracy: 0.6537 - val_loss: 0.6528 - val_accuracy: 0.6299\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 956us/step - loss: 0.6282 - accuracy: 0.6540 - val_loss: 0.6529 - val_accuracy: 0.6272\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6281 - accuracy: 0.6542 - val_loss: 0.6492 - val_accuracy: 0.6334\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 974us/step - loss: 0.6264 - accuracy: 0.6557 - val_loss: 0.6480 - val_accuracy: 0.6337\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6242 - accuracy: 0.6599 - val_loss: 0.6518 - val_accuracy: 0.6268\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 980us/step - loss: 0.6232 - accuracy: 0.6584 - val_loss: 0.6468 - val_accuracy: 0.6350\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6215 - accuracy: 0.6614 - val_loss: 0.6458 - val_accuracy: 0.6365\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 970us/step - loss: 0.6209 - accuracy: 0.6617 - val_loss: 0.6422 - val_accuracy: 0.6410\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6193 - accuracy: 0.6643 - val_loss: 0.6421 - val_accuracy: 0.6403\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 947us/step - loss: 0.6180 - accuracy: 0.6636 - val_loss: 0.6429 - val_accuracy: 0.6384\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 947us/step - loss: 0.6182 - accuracy: 0.6606 - val_loss: 0.6426 - val_accuracy: 0.6382\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 985us/step - loss: 0.6149 - accuracy: 0.6651 - val_loss: 0.6391 - val_accuracy: 0.6420\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 945us/step - loss: 0.6134 - accuracy: 0.6682 - val_loss: 0.6396 - val_accuracy: 0.6405\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6135 - accuracy: 0.6669 - val_loss: 0.6364 - val_accuracy: 0.6448\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.6110 - accuracy: 0.6701 - val_loss: 0.6386 - val_accuracy: 0.6405\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 988us/step - loss: 0.6109 - accuracy: 0.6712 - val_loss: 0.6363 - val_accuracy: 0.6429\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6098 - accuracy: 0.6712 - val_loss: 0.6344 - val_accuracy: 0.6458\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6079 - accuracy: 0.6725 - val_loss: 0.6344 - val_accuracy: 0.6457\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6081 - accuracy: 0.6736 - val_loss: 0.6334 - val_accuracy: 0.6459\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 980us/step - loss: 0.6054 - accuracy: 0.6772 - val_loss: 0.6315 - val_accuracy: 0.6477\n",
      "Epoch 1/50\n",
      "  1/836 [..............................] - ETA: 0s - loss: 0.7453 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0011s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 992us/step - loss: 0.7251 - accuracy: 0.4894 - val_loss: 0.7608 - val_accuracy: 0.2577\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 924us/step - loss: 0.7168 - accuracy: 0.4917 - val_loss: 0.7322 - val_accuracy: 0.3614\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 975us/step - loss: 0.7095 - accuracy: 0.5053 - val_loss: 0.7212 - val_accuracy: 0.4160\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7054 - accuracy: 0.5127 - val_loss: 0.7166 - val_accuracy: 0.4421\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 928us/step - loss: 0.7010 - accuracy: 0.5224 - val_loss: 0.7117 - val_accuracy: 0.4622\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6973 - accuracy: 0.5306 - val_loss: 0.7074 - val_accuracy: 0.4793\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 926us/step - loss: 0.6924 - accuracy: 0.5387 - val_loss: 0.7036 - val_accuracy: 0.4983\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 967us/step - loss: 0.6892 - accuracy: 0.5458 - val_loss: 0.6993 - val_accuracy: 0.5180\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 907us/step - loss: 0.6856 - accuracy: 0.5536 - val_loss: 0.6968 - val_accuracy: 0.5269\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 984us/step - loss: 0.6828 - accuracy: 0.5615 - val_loss: 0.6925 - val_accuracy: 0.5386\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6804 - accuracy: 0.5670 - val_loss: 0.6917 - val_accuracy: 0.5409\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6762 - accuracy: 0.5732 - val_loss: 0.6885 - val_accuracy: 0.5513\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 939us/step - loss: 0.6733 - accuracy: 0.5815 - val_loss: 0.6862 - val_accuracy: 0.5576\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 993us/step - loss: 0.6716 - accuracy: 0.5845 - val_loss: 0.6845 - val_accuracy: 0.5633\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6700 - accuracy: 0.5903 - val_loss: 0.6830 - val_accuracy: 0.5660\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6689 - accuracy: 0.5935 - val_loss: 0.6799 - val_accuracy: 0.5733\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 929us/step - loss: 0.6651 - accuracy: 0.5991 - val_loss: 0.6777 - val_accuracy: 0.5775\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 990us/step - loss: 0.6636 - accuracy: 0.6000 - val_loss: 0.6777 - val_accuracy: 0.5776\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 978us/step - loss: 0.6625 - accuracy: 0.6022 - val_loss: 0.6781 - val_accuracy: 0.5753\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6602 - accuracy: 0.6089 - val_loss: 0.6745 - val_accuracy: 0.5827\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 978us/step - loss: 0.6581 - accuracy: 0.6115 - val_loss: 0.6722 - val_accuracy: 0.5864\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6569 - accuracy: 0.6162 - val_loss: 0.6708 - val_accuracy: 0.5886\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.6550 - accuracy: 0.6184 - val_loss: 0.6698 - val_accuracy: 0.5896\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6532 - accuracy: 0.6221 - val_loss: 0.6700 - val_accuracy: 0.5874\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 974us/step - loss: 0.6521 - accuracy: 0.6249 - val_loss: 0.6674 - val_accuracy: 0.5919\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6492 - accuracy: 0.6311 - val_loss: 0.6664 - val_accuracy: 0.5934\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6480 - accuracy: 0.6294 - val_loss: 0.6657 - val_accuracy: 0.5929\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6459 - accuracy: 0.6337 - val_loss: 0.6635 - val_accuracy: 0.5948\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6436 - accuracy: 0.6386 - val_loss: 0.6609 - val_accuracy: 0.5981\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.6431 - accuracy: 0.6383 - val_loss: 0.6608 - val_accuracy: 0.5975\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6410 - accuracy: 0.6423 - val_loss: 0.6579 - val_accuracy: 0.6025\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 868us/step - loss: 0.6398 - accuracy: 0.6425 - val_loss: 0.6573 - val_accuracy: 0.6036\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6383 - accuracy: 0.6455 - val_loss: 0.6581 - val_accuracy: 0.6027\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6370 - accuracy: 0.6494 - val_loss: 0.6541 - val_accuracy: 0.6074\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 946us/step - loss: 0.6350 - accuracy: 0.6508 - val_loss: 0.6528 - val_accuracy: 0.6089\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 956us/step - loss: 0.6346 - accuracy: 0.6501 - val_loss: 0.6521 - val_accuracy: 0.6093\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 924us/step - loss: 0.6323 - accuracy: 0.6554 - val_loss: 0.6499 - val_accuracy: 0.6125\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 963us/step - loss: 0.6316 - accuracy: 0.6549 - val_loss: 0.6487 - val_accuracy: 0.6133\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6307 - accuracy: 0.6530 - val_loss: 0.6496 - val_accuracy: 0.6120\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6297 - accuracy: 0.6581 - val_loss: 0.6509 - val_accuracy: 0.6088\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 964us/step - loss: 0.6274 - accuracy: 0.6612 - val_loss: 0.6487 - val_accuracy: 0.6116\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6262 - accuracy: 0.6633 - val_loss: 0.6460 - val_accuracy: 0.6143\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6246 - accuracy: 0.6662 - val_loss: 0.6455 - val_accuracy: 0.6144\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6233 - accuracy: 0.6653 - val_loss: 0.6472 - val_accuracy: 0.6099\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6210 - accuracy: 0.6669 - val_loss: 0.6462 - val_accuracy: 0.6113\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6193 - accuracy: 0.6708 - val_loss: 0.6454 - val_accuracy: 0.6132\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 972us/step - loss: 0.6191 - accuracy: 0.6687 - val_loss: 0.6434 - val_accuracy: 0.6156\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 960us/step - loss: 0.6175 - accuracy: 0.6705 - val_loss: 0.6423 - val_accuracy: 0.6173\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 950us/step - loss: 0.6160 - accuracy: 0.6734 - val_loss: 0.6416 - val_accuracy: 0.6177\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 952us/step - loss: 0.6153 - accuracy: 0.6732 - val_loss: 0.6434 - val_accuracy: 0.6141\n",
      "Epoch 1/50\n",
      "  1/836 [..............................] - ETA: 0s - loss: 0.7488 - accuracy: 0.6094WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7388 - accuracy: 0.5248 - val_loss: 0.8442 - val_accuracy: 0.1173\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 978us/step - loss: 0.6993 - accuracy: 0.5336 - val_loss: 0.7564 - val_accuracy: 0.1515\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 925us/step - loss: 0.6896 - accuracy: 0.5467 - val_loss: 0.7299 - val_accuracy: 0.2713\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 894us/step - loss: 0.6866 - accuracy: 0.5550 - val_loss: 0.7201 - val_accuracy: 0.3735\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6835 - accuracy: 0.5615 - val_loss: 0.7139 - val_accuracy: 0.4447\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6786 - accuracy: 0.5769 - val_loss: 0.7086 - val_accuracy: 0.4860\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.6764 - accuracy: 0.5856 - val_loss: 0.7069 - val_accuracy: 0.4978\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 868us/step - loss: 0.6736 - accuracy: 0.5923 - val_loss: 0.7059 - val_accuracy: 0.5033\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.6700 - accuracy: 0.6039 - val_loss: 0.7008 - val_accuracy: 0.5229\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 931us/step - loss: 0.6682 - accuracy: 0.6075 - val_loss: 0.6995 - val_accuracy: 0.5297\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 856us/step - loss: 0.6655 - accuracy: 0.6138 - val_loss: 0.6963 - val_accuracy: 0.5382\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6635 - accuracy: 0.6172 - val_loss: 0.6937 - val_accuracy: 0.5461\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6615 - accuracy: 0.6253 - val_loss: 0.6931 - val_accuracy: 0.5484\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 904us/step - loss: 0.6593 - accuracy: 0.6280 - val_loss: 0.6921 - val_accuracy: 0.5497\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 891us/step - loss: 0.6574 - accuracy: 0.6338 - val_loss: 0.6893 - val_accuracy: 0.5548\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 932us/step - loss: 0.6563 - accuracy: 0.6347 - val_loss: 0.6866 - val_accuracy: 0.5605\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 969us/step - loss: 0.6547 - accuracy: 0.6382 - val_loss: 0.6843 - val_accuracy: 0.5639\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6530 - accuracy: 0.6437 - val_loss: 0.6844 - val_accuracy: 0.5635\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 884us/step - loss: 0.6517 - accuracy: 0.6445 - val_loss: 0.6839 - val_accuracy: 0.5638\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6494 - accuracy: 0.6487 - val_loss: 0.6802 - val_accuracy: 0.5728\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 901us/step - loss: 0.6490 - accuracy: 0.6489 - val_loss: 0.6803 - val_accuracy: 0.5717\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6462 - accuracy: 0.6548 - val_loss: 0.6780 - val_accuracy: 0.5783\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6455 - accuracy: 0.6544 - val_loss: 0.6772 - val_accuracy: 0.5796\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6444 - accuracy: 0.6537 - val_loss: 0.6765 - val_accuracy: 0.5802\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 909us/step - loss: 0.6415 - accuracy: 0.6607 - val_loss: 0.6754 - val_accuracy: 0.5827\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 966us/step - loss: 0.6414 - accuracy: 0.6605 - val_loss: 0.6731 - val_accuracy: 0.5873\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 892us/step - loss: 0.6401 - accuracy: 0.6620 - val_loss: 0.6697 - val_accuracy: 0.5956\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.6387 - accuracy: 0.6645 - val_loss: 0.6710 - val_accuracy: 0.5908\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6371 - accuracy: 0.6656 - val_loss: 0.6694 - val_accuracy: 0.5941\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 988us/step - loss: 0.6359 - accuracy: 0.6665 - val_loss: 0.6670 - val_accuracy: 0.6010\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.6343 - accuracy: 0.6688 - val_loss: 0.6671 - val_accuracy: 0.5997\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6324 - accuracy: 0.6718 - val_loss: 0.6672 - val_accuracy: 0.5989\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6326 - accuracy: 0.6698 - val_loss: 0.6656 - val_accuracy: 0.6029\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.6298 - accuracy: 0.6756 - val_loss: 0.6663 - val_accuracy: 0.5999\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 826us/step - loss: 0.6288 - accuracy: 0.6764 - val_loss: 0.6623 - val_accuracy: 0.6093\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 861us/step - loss: 0.6287 - accuracy: 0.6745 - val_loss: 0.6609 - val_accuracy: 0.6119\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6270 - accuracy: 0.6771 - val_loss: 0.6602 - val_accuracy: 0.6123\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6256 - accuracy: 0.6772 - val_loss: 0.6599 - val_accuracy: 0.6120\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 915us/step - loss: 0.6248 - accuracy: 0.6784 - val_loss: 0.6585 - val_accuracy: 0.6141\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6231 - accuracy: 0.6810 - val_loss: 0.6572 - val_accuracy: 0.6147\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 854us/step - loss: 0.6213 - accuracy: 0.6829 - val_loss: 0.6545 - val_accuracy: 0.6187\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 974us/step - loss: 0.6213 - accuracy: 0.6819 - val_loss: 0.6543 - val_accuracy: 0.6193\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 856us/step - loss: 0.6197 - accuracy: 0.6829 - val_loss: 0.6556 - val_accuracy: 0.6168\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6185 - accuracy: 0.6866 - val_loss: 0.6544 - val_accuracy: 0.6186\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.6166 - accuracy: 0.6862 - val_loss: 0.6534 - val_accuracy: 0.6195\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6162 - accuracy: 0.6862 - val_loss: 0.6506 - val_accuracy: 0.6222\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6157 - accuracy: 0.6876 - val_loss: 0.6501 - val_accuracy: 0.6227\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6135 - accuracy: 0.6876 - val_loss: 0.6511 - val_accuracy: 0.6211\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 802us/step - loss: 0.6125 - accuracy: 0.6903 - val_loss: 0.6490 - val_accuracy: 0.6241\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6118 - accuracy: 0.6894 - val_loss: 0.6475 - val_accuracy: 0.6260\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 902us/step - loss: 0.7366 - accuracy: 0.5123 - val_loss: 0.7739 - val_accuracy: 0.2292\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 909us/step - loss: 0.7166 - accuracy: 0.5188 - val_loss: 0.7371 - val_accuracy: 0.2999\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.7088 - accuracy: 0.5238 - val_loss: 0.7257 - val_accuracy: 0.3462\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.7042 - accuracy: 0.5304 - val_loss: 0.7204 - val_accuracy: 0.3698\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6965 - accuracy: 0.5447 - val_loss: 0.7155 - val_accuracy: 0.3956\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6930 - accuracy: 0.5517 - val_loss: 0.7107 - val_accuracy: 0.4153\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6887 - accuracy: 0.5604 - val_loss: 0.7065 - val_accuracy: 0.4330\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6831 - accuracy: 0.5703 - val_loss: 0.7034 - val_accuracy: 0.4635\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6786 - accuracy: 0.5774 - val_loss: 0.6999 - val_accuracy: 0.4751\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 944us/step - loss: 0.6769 - accuracy: 0.5826 - val_loss: 0.6977 - val_accuracy: 0.4837\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 854us/step - loss: 0.6718 - accuracy: 0.5906 - val_loss: 0.6931 - val_accuracy: 0.4988\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6696 - accuracy: 0.5955 - val_loss: 0.6918 - val_accuracy: 0.5072\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 891us/step - loss: 0.6659 - accuracy: 0.6017 - val_loss: 0.6875 - val_accuracy: 0.5284\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6634 - accuracy: 0.6060 - val_loss: 0.6854 - val_accuracy: 0.5429\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6604 - accuracy: 0.6141 - val_loss: 0.6851 - val_accuracy: 0.5489\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.6575 - accuracy: 0.6189 - val_loss: 0.6802 - val_accuracy: 0.5643\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 865us/step - loss: 0.6541 - accuracy: 0.6260 - val_loss: 0.6780 - val_accuracy: 0.5695\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6511 - accuracy: 0.6294 - val_loss: 0.6769 - val_accuracy: 0.5710\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6485 - accuracy: 0.6335 - val_loss: 0.6709 - val_accuracy: 0.5818\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6472 - accuracy: 0.6353 - val_loss: 0.6707 - val_accuracy: 0.5830\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6444 - accuracy: 0.6394 - val_loss: 0.6725 - val_accuracy: 0.5802\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 824us/step - loss: 0.6422 - accuracy: 0.6425 - val_loss: 0.6666 - val_accuracy: 0.5883\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6395 - accuracy: 0.6464 - val_loss: 0.6681 - val_accuracy: 0.5843\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 865us/step - loss: 0.6385 - accuracy: 0.6475 - val_loss: 0.6646 - val_accuracy: 0.5904\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6346 - accuracy: 0.6522 - val_loss: 0.6608 - val_accuracy: 0.5957\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6328 - accuracy: 0.6555 - val_loss: 0.6583 - val_accuracy: 0.5978\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6309 - accuracy: 0.6592 - val_loss: 0.6581 - val_accuracy: 0.5983\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 865us/step - loss: 0.6286 - accuracy: 0.6613 - val_loss: 0.6561 - val_accuracy: 0.6005\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6273 - accuracy: 0.6634 - val_loss: 0.6548 - val_accuracy: 0.6011\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 992us/step - loss: 0.6251 - accuracy: 0.6644 - val_loss: 0.6594 - val_accuracy: 0.5966\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 978us/step - loss: 0.6242 - accuracy: 0.6650 - val_loss: 0.6539 - val_accuracy: 0.6029\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 877us/step - loss: 0.6224 - accuracy: 0.6658 - val_loss: 0.6528 - val_accuracy: 0.6050\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 888us/step - loss: 0.6207 - accuracy: 0.6691 - val_loss: 0.6522 - val_accuracy: 0.6063\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 932us/step - loss: 0.6192 - accuracy: 0.6731 - val_loss: 0.6486 - val_accuracy: 0.6106\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6185 - accuracy: 0.6680 - val_loss: 0.6469 - val_accuracy: 0.6115\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 931us/step - loss: 0.6169 - accuracy: 0.6689 - val_loss: 0.6474 - val_accuracy: 0.6107\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6156 - accuracy: 0.6727 - val_loss: 0.6431 - val_accuracy: 0.6151\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6138 - accuracy: 0.6750 - val_loss: 0.6421 - val_accuracy: 0.6165\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 921us/step - loss: 0.6114 - accuracy: 0.6785 - val_loss: 0.6441 - val_accuracy: 0.6133\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6109 - accuracy: 0.6775 - val_loss: 0.6421 - val_accuracy: 0.6168\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6096 - accuracy: 0.6790 - val_loss: 0.6404 - val_accuracy: 0.6189\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6069 - accuracy: 0.6824 - val_loss: 0.6396 - val_accuracy: 0.6190\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 858us/step - loss: 0.6069 - accuracy: 0.6799 - val_loss: 0.6368 - val_accuracy: 0.6213\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6062 - accuracy: 0.6809 - val_loss: 0.6371 - val_accuracy: 0.6204\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6042 - accuracy: 0.6840 - val_loss: 0.6367 - val_accuracy: 0.6217\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6034 - accuracy: 0.6826 - val_loss: 0.6350 - val_accuracy: 0.6252\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6021 - accuracy: 0.6853 - val_loss: 0.6345 - val_accuracy: 0.6263\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 912us/step - loss: 0.6008 - accuracy: 0.6859 - val_loss: 0.6325 - val_accuracy: 0.6283\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 973us/step - loss: 0.6007 - accuracy: 0.6851 - val_loss: 0.6307 - val_accuracy: 0.6291\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.5986 - accuracy: 0.6893 - val_loss: 0.6303 - val_accuracy: 0.6293\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 887us/step - loss: 0.7195 - accuracy: 0.5002 - val_loss: 0.7613 - val_accuracy: 0.2114\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.7128 - accuracy: 0.5038 - val_loss: 0.7441 - val_accuracy: 0.2903\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 866us/step - loss: 0.7089 - accuracy: 0.5124 - val_loss: 0.7368 - val_accuracy: 0.3069\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 866us/step - loss: 0.7040 - accuracy: 0.5212 - val_loss: 0.7329 - val_accuracy: 0.3363\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 878us/step - loss: 0.6996 - accuracy: 0.5291 - val_loss: 0.7287 - val_accuracy: 0.3744\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 934us/step - loss: 0.6962 - accuracy: 0.5384 - val_loss: 0.7252 - val_accuracy: 0.3919\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 870us/step - loss: 0.6924 - accuracy: 0.5464 - val_loss: 0.7212 - val_accuracy: 0.4160\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 874us/step - loss: 0.6894 - accuracy: 0.5535 - val_loss: 0.7208 - val_accuracy: 0.4214\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 807us/step - loss: 0.6859 - accuracy: 0.5617 - val_loss: 0.7194 - val_accuracy: 0.4297\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 949us/step - loss: 0.6838 - accuracy: 0.5678 - val_loss: 0.7165 - val_accuracy: 0.4471\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 958us/step - loss: 0.6812 - accuracy: 0.5739 - val_loss: 0.7142 - val_accuracy: 0.4625\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 969us/step - loss: 0.6801 - accuracy: 0.5771 - val_loss: 0.7128 - val_accuracy: 0.4723\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6780 - accuracy: 0.5837 - val_loss: 0.7087 - val_accuracy: 0.4876\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 944us/step - loss: 0.6756 - accuracy: 0.5897 - val_loss: 0.7070 - val_accuracy: 0.4931\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 915us/step - loss: 0.6730 - accuracy: 0.5973 - val_loss: 0.7055 - val_accuracy: 0.4982\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 886us/step - loss: 0.6722 - accuracy: 0.6005 - val_loss: 0.7034 - val_accuracy: 0.5038\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 958us/step - loss: 0.6705 - accuracy: 0.6057 - val_loss: 0.7006 - val_accuracy: 0.5093\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 962us/step - loss: 0.6678 - accuracy: 0.6095 - val_loss: 0.7003 - val_accuracy: 0.5120\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 972us/step - loss: 0.6660 - accuracy: 0.6159 - val_loss: 0.6986 - val_accuracy: 0.5158\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 921us/step - loss: 0.6650 - accuracy: 0.6175 - val_loss: 0.6973 - val_accuracy: 0.5192\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6635 - accuracy: 0.6231 - val_loss: 0.6974 - val_accuracy: 0.5203\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 789us/step - loss: 0.6628 - accuracy: 0.6231 - val_loss: 0.6967 - val_accuracy: 0.5235\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 878us/step - loss: 0.6611 - accuracy: 0.6282 - val_loss: 0.6929 - val_accuracy: 0.5332\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 866us/step - loss: 0.6590 - accuracy: 0.6321 - val_loss: 0.6912 - val_accuracy: 0.5364\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6571 - accuracy: 0.6353 - val_loss: 0.6902 - val_accuracy: 0.5389\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 970us/step - loss: 0.6566 - accuracy: 0.6357 - val_loss: 0.6895 - val_accuracy: 0.5393\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6544 - accuracy: 0.6409 - val_loss: 0.6894 - val_accuracy: 0.5392\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6537 - accuracy: 0.6421 - val_loss: 0.6845 - val_accuracy: 0.5501\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 900us/step - loss: 0.6523 - accuracy: 0.6429 - val_loss: 0.6845 - val_accuracy: 0.5496\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 886us/step - loss: 0.6506 - accuracy: 0.6479 - val_loss: 0.6819 - val_accuracy: 0.5558\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 865us/step - loss: 0.6489 - accuracy: 0.6486 - val_loss: 0.6830 - val_accuracy: 0.5525\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6472 - accuracy: 0.6528 - val_loss: 0.6806 - val_accuracy: 0.5572\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 807us/step - loss: 0.6459 - accuracy: 0.6530 - val_loss: 0.6782 - val_accuracy: 0.5624\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 886us/step - loss: 0.6452 - accuracy: 0.6554 - val_loss: 0.6765 - val_accuracy: 0.5660\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.6428 - accuracy: 0.6598 - val_loss: 0.6763 - val_accuracy: 0.5660\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 980us/step - loss: 0.6426 - accuracy: 0.6592 - val_loss: 0.6769 - val_accuracy: 0.5645\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6403 - accuracy: 0.6620 - val_loss: 0.6758 - val_accuracy: 0.5655\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6393 - accuracy: 0.6622 - val_loss: 0.6721 - val_accuracy: 0.5708\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 884us/step - loss: 0.6383 - accuracy: 0.6659 - val_loss: 0.6705 - val_accuracy: 0.5722\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6370 - accuracy: 0.6647 - val_loss: 0.6686 - val_accuracy: 0.5744\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6365 - accuracy: 0.6662 - val_loss: 0.6672 - val_accuracy: 0.5765\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6343 - accuracy: 0.6693 - val_loss: 0.6680 - val_accuracy: 0.5739\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6336 - accuracy: 0.6690 - val_loss: 0.6680 - val_accuracy: 0.5737\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6322 - accuracy: 0.6699 - val_loss: 0.6661 - val_accuracy: 0.5770\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 979us/step - loss: 0.6312 - accuracy: 0.6727 - val_loss: 0.6643 - val_accuracy: 0.5817\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6306 - accuracy: 0.6732 - val_loss: 0.6649 - val_accuracy: 0.5796\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6285 - accuracy: 0.6721 - val_loss: 0.6627 - val_accuracy: 0.5842\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6273 - accuracy: 0.6760 - val_loss: 0.6611 - val_accuracy: 0.5864\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6265 - accuracy: 0.6747 - val_loss: 0.6608 - val_accuracy: 0.5862\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 923us/step - loss: 0.6253 - accuracy: 0.6773 - val_loss: 0.6596 - val_accuracy: 0.5882\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6904 - accuracy: 0.5406 - val_loss: 0.7392 - val_accuracy: 0.2148\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6871 - accuracy: 0.5480 - val_loss: 0.7238 - val_accuracy: 0.2887\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5557 - val_loss: 0.7168 - val_accuracy: 0.3428\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6813 - accuracy: 0.5615 - val_loss: 0.7131 - val_accuracy: 0.3740\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6795 - accuracy: 0.5671 - val_loss: 0.7103 - val_accuracy: 0.4057\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6754 - accuracy: 0.5777 - val_loss: 0.7068 - val_accuracy: 0.4399\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6750 - accuracy: 0.5786 - val_loss: 0.7043 - val_accuracy: 0.4602\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6725 - accuracy: 0.5833 - val_loss: 0.7022 - val_accuracy: 0.4752\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 971us/step - loss: 0.6702 - accuracy: 0.5898 - val_loss: 0.6992 - val_accuracy: 0.4914\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 983us/step - loss: 0.6686 - accuracy: 0.5931 - val_loss: 0.6979 - val_accuracy: 0.4987\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6655 - accuracy: 0.6028 - val_loss: 0.6960 - val_accuracy: 0.5067\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.6041 - val_loss: 0.6948 - val_accuracy: 0.5123\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 965us/step - loss: 0.6629 - accuracy: 0.6101 - val_loss: 0.6911 - val_accuracy: 0.5256\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6610 - accuracy: 0.6137 - val_loss: 0.6891 - val_accuracy: 0.5340\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6591 - accuracy: 0.6162 - val_loss: 0.6881 - val_accuracy: 0.5381\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6576 - accuracy: 0.6213 - val_loss: 0.6862 - val_accuracy: 0.5448\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 993us/step - loss: 0.6553 - accuracy: 0.6249 - val_loss: 0.6845 - val_accuracy: 0.5506\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 964us/step - loss: 0.6541 - accuracy: 0.6247 - val_loss: 0.6839 - val_accuracy: 0.5519\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6526 - accuracy: 0.6304 - val_loss: 0.6810 - val_accuracy: 0.5624\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6514 - accuracy: 0.6339 - val_loss: 0.6776 - val_accuracy: 0.5727\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6502 - accuracy: 0.6352 - val_loss: 0.6783 - val_accuracy: 0.5710\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6482 - accuracy: 0.6371 - val_loss: 0.6759 - val_accuracy: 0.5767\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6467 - accuracy: 0.6386 - val_loss: 0.6740 - val_accuracy: 0.5808\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 969us/step - loss: 0.6454 - accuracy: 0.6402 - val_loss: 0.6722 - val_accuracy: 0.5843\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 997us/step - loss: 0.6442 - accuracy: 0.6403 - val_loss: 0.6713 - val_accuracy: 0.5858\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 938us/step - loss: 0.6424 - accuracy: 0.6437 - val_loss: 0.6701 - val_accuracy: 0.5880\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 929us/step - loss: 0.6412 - accuracy: 0.6460 - val_loss: 0.6691 - val_accuracy: 0.5901\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 970us/step - loss: 0.6400 - accuracy: 0.6471 - val_loss: 0.6677 - val_accuracy: 0.5929\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6388 - accuracy: 0.6487 - val_loss: 0.6637 - val_accuracy: 0.6021\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.6370 - accuracy: 0.6536 - val_loss: 0.6631 - val_accuracy: 0.6027\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6358 - accuracy: 0.6514 - val_loss: 0.6622 - val_accuracy: 0.6035\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6341 - accuracy: 0.6571 - val_loss: 0.6607 - val_accuracy: 0.6062\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6328 - accuracy: 0.6555 - val_loss: 0.6592 - val_accuracy: 0.6083\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 965us/step - loss: 0.6307 - accuracy: 0.6597 - val_loss: 0.6590 - val_accuracy: 0.6082\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6310 - accuracy: 0.6565 - val_loss: 0.6574 - val_accuracy: 0.6101\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 988us/step - loss: 0.6295 - accuracy: 0.6597 - val_loss: 0.6563 - val_accuracy: 0.6113\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6269 - accuracy: 0.6619 - val_loss: 0.6544 - val_accuracy: 0.6134\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6264 - accuracy: 0.6617 - val_loss: 0.6533 - val_accuracy: 0.6137\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6254 - accuracy: 0.6617 - val_loss: 0.6523 - val_accuracy: 0.6142\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 958us/step - loss: 0.6240 - accuracy: 0.6633 - val_loss: 0.6501 - val_accuracy: 0.6161\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6231 - accuracy: 0.6653 - val_loss: 0.6497 - val_accuracy: 0.6166\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 919us/step - loss: 0.6218 - accuracy: 0.6666 - val_loss: 0.6486 - val_accuracy: 0.6172\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6197 - accuracy: 0.6703 - val_loss: 0.6493 - val_accuracy: 0.6166\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 987us/step - loss: 0.6200 - accuracy: 0.6686 - val_loss: 0.6472 - val_accuracy: 0.6182\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 965us/step - loss: 0.6185 - accuracy: 0.6695 - val_loss: 0.6439 - val_accuracy: 0.6245\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6167 - accuracy: 0.6719 - val_loss: 0.6443 - val_accuracy: 0.6236\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6162 - accuracy: 0.6731 - val_loss: 0.6432 - val_accuracy: 0.6256\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 979us/step - loss: 0.6152 - accuracy: 0.6725 - val_loss: 0.6408 - val_accuracy: 0.6290\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 982us/step - loss: 0.6153 - accuracy: 0.6712 - val_loss: 0.6400 - val_accuracy: 0.6301\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 967us/step - loss: 0.6123 - accuracy: 0.6750 - val_loss: 0.6384 - val_accuracy: 0.6324\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7096 - accuracy: 0.4924 - val_loss: 0.7144 - val_accuracy: 0.3822\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7017 - accuracy: 0.5080 - val_loss: 0.7225 - val_accuracy: 0.3699\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6955 - accuracy: 0.5261 - val_loss: 0.7172 - val_accuracy: 0.4078\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6912 - accuracy: 0.5346 - val_loss: 0.7120 - val_accuracy: 0.4430\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6871 - accuracy: 0.5428 - val_loss: 0.7088 - val_accuracy: 0.4646\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6824 - accuracy: 0.5557 - val_loss: 0.7056 - val_accuracy: 0.4838\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6788 - accuracy: 0.5625 - val_loss: 0.7027 - val_accuracy: 0.5019\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 944us/step - loss: 0.6759 - accuracy: 0.5695 - val_loss: 0.6983 - val_accuracy: 0.5223\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 998us/step - loss: 0.6735 - accuracy: 0.5763 - val_loss: 0.6961 - val_accuracy: 0.5335\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 925us/step - loss: 0.6706 - accuracy: 0.5841 - val_loss: 0.6938 - val_accuracy: 0.5445\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6683 - accuracy: 0.5873 - val_loss: 0.6915 - val_accuracy: 0.5531\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6645 - accuracy: 0.5979 - val_loss: 0.6890 - val_accuracy: 0.5611\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6635 - accuracy: 0.6000 - val_loss: 0.6842 - val_accuracy: 0.5755\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6603 - accuracy: 0.6089 - val_loss: 0.6818 - val_accuracy: 0.5829\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 950us/step - loss: 0.6581 - accuracy: 0.6133 - val_loss: 0.6793 - val_accuracy: 0.5896\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6563 - accuracy: 0.6157 - val_loss: 0.6796 - val_accuracy: 0.5882\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6538 - accuracy: 0.6183 - val_loss: 0.6761 - val_accuracy: 0.5967\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 956us/step - loss: 0.6515 - accuracy: 0.6253 - val_loss: 0.6751 - val_accuracy: 0.5979\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6501 - accuracy: 0.6285 - val_loss: 0.6723 - val_accuracy: 0.6029\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6476 - accuracy: 0.6340 - val_loss: 0.6704 - val_accuracy: 0.6060\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 996us/step - loss: 0.6464 - accuracy: 0.6349 - val_loss: 0.6698 - val_accuracy: 0.6067\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6448 - accuracy: 0.6357 - val_loss: 0.6679 - val_accuracy: 0.6085\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6433 - accuracy: 0.6392 - val_loss: 0.6645 - val_accuracy: 0.6141\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 976us/step - loss: 0.6413 - accuracy: 0.6424 - val_loss: 0.6620 - val_accuracy: 0.6185\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 992us/step - loss: 0.6397 - accuracy: 0.6460 - val_loss: 0.6598 - val_accuracy: 0.6213\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6379 - accuracy: 0.6496 - val_loss: 0.6582 - val_accuracy: 0.6234\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6356 - accuracy: 0.6521 - val_loss: 0.6572 - val_accuracy: 0.6235\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6361 - accuracy: 0.6539 - val_loss: 0.6552 - val_accuracy: 0.6251\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 994us/step - loss: 0.6333 - accuracy: 0.6549 - val_loss: 0.6530 - val_accuracy: 0.6278\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6314 - accuracy: 0.6599 - val_loss: 0.6517 - val_accuracy: 0.6292\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6305 - accuracy: 0.6588 - val_loss: 0.6514 - val_accuracy: 0.6283\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6286 - accuracy: 0.6629 - val_loss: 0.6492 - val_accuracy: 0.6315\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6273 - accuracy: 0.6619 - val_loss: 0.6485 - val_accuracy: 0.6314\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 970us/step - loss: 0.6258 - accuracy: 0.6649 - val_loss: 0.6447 - val_accuracy: 0.6359\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6240 - accuracy: 0.6688 - val_loss: 0.6443 - val_accuracy: 0.6352\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 980us/step - loss: 0.6237 - accuracy: 0.6679 - val_loss: 0.6452 - val_accuracy: 0.6334\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 981us/step - loss: 0.6222 - accuracy: 0.6709 - val_loss: 0.6430 - val_accuracy: 0.6354\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6208 - accuracy: 0.6718 - val_loss: 0.6426 - val_accuracy: 0.6349\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6197 - accuracy: 0.6720 - val_loss: 0.6392 - val_accuracy: 0.6388\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.6184 - accuracy: 0.6734 - val_loss: 0.6392 - val_accuracy: 0.6384\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.6176 - accuracy: 0.6759 - val_loss: 0.6398 - val_accuracy: 0.6364\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6158 - accuracy: 0.6761 - val_loss: 0.6365 - val_accuracy: 0.6414\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6153 - accuracy: 0.6775 - val_loss: 0.6326 - val_accuracy: 0.6479\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 974us/step - loss: 0.6140 - accuracy: 0.6794 - val_loss: 0.6361 - val_accuracy: 0.6396\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 878us/step - loss: 0.6124 - accuracy: 0.6805 - val_loss: 0.6343 - val_accuracy: 0.6424\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 790us/step - loss: 0.6110 - accuracy: 0.6833 - val_loss: 0.6345 - val_accuracy: 0.6405\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6111 - accuracy: 0.6831 - val_loss: 0.6349 - val_accuracy: 0.6402\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6088 - accuracy: 0.6834 - val_loss: 0.6317 - val_accuracy: 0.6445\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 932us/step - loss: 0.6087 - accuracy: 0.6834 - val_loss: 0.6306 - val_accuracy: 0.6456\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.6078 - accuracy: 0.6855 - val_loss: 0.6312 - val_accuracy: 0.6435\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 948us/step - loss: 0.7399 - accuracy: 0.4920 - val_loss: 0.5977 - val_accuracy: 0.8541\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 888us/step - loss: 0.7065 - accuracy: 0.5199 - val_loss: 0.6523 - val_accuracy: 0.7721\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6957 - accuracy: 0.5407 - val_loss: 0.6817 - val_accuracy: 0.5971\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.6905 - accuracy: 0.5534 - val_loss: 0.6963 - val_accuracy: 0.5008\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 898us/step - loss: 0.6863 - accuracy: 0.5646 - val_loss: 0.7029 - val_accuracy: 0.4692\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 867us/step - loss: 0.6843 - accuracy: 0.5698 - val_loss: 0.7047 - val_accuracy: 0.4650\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6826 - accuracy: 0.5741 - val_loss: 0.7045 - val_accuracy: 0.4743\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6805 - accuracy: 0.5793 - val_loss: 0.7043 - val_accuracy: 0.4809\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6787 - accuracy: 0.5852 - val_loss: 0.7024 - val_accuracy: 0.4999\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 977us/step - loss: 0.6766 - accuracy: 0.5883 - val_loss: 0.7024 - val_accuracy: 0.5036\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.6743 - accuracy: 0.5932 - val_loss: 0.7007 - val_accuracy: 0.5172\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6731 - accuracy: 0.5991 - val_loss: 0.6997 - val_accuracy: 0.5269\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 874us/step - loss: 0.6703 - accuracy: 0.6053 - val_loss: 0.6972 - val_accuracy: 0.5409\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 861us/step - loss: 0.6705 - accuracy: 0.6032 - val_loss: 0.6963 - val_accuracy: 0.5472\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 800us/step - loss: 0.6687 - accuracy: 0.6081 - val_loss: 0.6953 - val_accuracy: 0.5514\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6668 - accuracy: 0.6130 - val_loss: 0.6946 - val_accuracy: 0.5542\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6655 - accuracy: 0.6198 - val_loss: 0.6932 - val_accuracy: 0.5562\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6640 - accuracy: 0.6194 - val_loss: 0.6920 - val_accuracy: 0.5590\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6620 - accuracy: 0.6254 - val_loss: 0.6908 - val_accuracy: 0.5629\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 872us/step - loss: 0.6612 - accuracy: 0.6253 - val_loss: 0.6892 - val_accuracy: 0.5667\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 880us/step - loss: 0.6590 - accuracy: 0.6322 - val_loss: 0.6891 - val_accuracy: 0.5677\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 994us/step - loss: 0.6576 - accuracy: 0.6316 - val_loss: 0.6882 - val_accuracy: 0.5715\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 962us/step - loss: 0.6566 - accuracy: 0.6377 - val_loss: 0.6859 - val_accuracy: 0.5769\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6551 - accuracy: 0.6383 - val_loss: 0.6850 - val_accuracy: 0.5795\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6540 - accuracy: 0.6393 - val_loss: 0.6833 - val_accuracy: 0.5829\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 976us/step - loss: 0.6522 - accuracy: 0.6430 - val_loss: 0.6824 - val_accuracy: 0.5838\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 896us/step - loss: 0.6504 - accuracy: 0.6475 - val_loss: 0.6807 - val_accuracy: 0.5851\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6495 - accuracy: 0.6496 - val_loss: 0.6800 - val_accuracy: 0.5872\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6474 - accuracy: 0.6532 - val_loss: 0.6775 - val_accuracy: 0.5912\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6468 - accuracy: 0.6531 - val_loss: 0.6771 - val_accuracy: 0.5918\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 826us/step - loss: 0.6447 - accuracy: 0.6556 - val_loss: 0.6763 - val_accuracy: 0.5923\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 867us/step - loss: 0.6439 - accuracy: 0.6553 - val_loss: 0.6756 - val_accuracy: 0.5934\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6417 - accuracy: 0.6589 - val_loss: 0.6743 - val_accuracy: 0.5950\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6405 - accuracy: 0.6591 - val_loss: 0.6729 - val_accuracy: 0.5963\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 978us/step - loss: 0.6383 - accuracy: 0.6641 - val_loss: 0.6706 - val_accuracy: 0.5996\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 881us/step - loss: 0.6365 - accuracy: 0.6645 - val_loss: 0.6688 - val_accuracy: 0.6019\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6348 - accuracy: 0.6696 - val_loss: 0.6674 - val_accuracy: 0.6040\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 988us/step - loss: 0.6343 - accuracy: 0.6678 - val_loss: 0.6645 - val_accuracy: 0.6093\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 915us/step - loss: 0.6324 - accuracy: 0.6685 - val_loss: 0.6644 - val_accuracy: 0.6080\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6305 - accuracy: 0.6737 - val_loss: 0.6637 - val_accuracy: 0.6088\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6299 - accuracy: 0.6732 - val_loss: 0.6624 - val_accuracy: 0.6102\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6294 - accuracy: 0.6736 - val_loss: 0.6601 - val_accuracy: 0.6154\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 935us/step - loss: 0.6265 - accuracy: 0.6762 - val_loss: 0.6581 - val_accuracy: 0.6176\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6269 - accuracy: 0.6751 - val_loss: 0.6595 - val_accuracy: 0.6137\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6252 - accuracy: 0.6767 - val_loss: 0.6582 - val_accuracy: 0.6165\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6240 - accuracy: 0.6799 - val_loss: 0.6583 - val_accuracy: 0.6142\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 910us/step - loss: 0.6227 - accuracy: 0.6799 - val_loss: 0.6566 - val_accuracy: 0.6179\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 854us/step - loss: 0.6224 - accuracy: 0.6806 - val_loss: 0.6546 - val_accuracy: 0.6217\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 938us/step - loss: 0.6208 - accuracy: 0.6831 - val_loss: 0.6528 - val_accuracy: 0.6240\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6199 - accuracy: 0.6808 - val_loss: 0.6513 - val_accuracy: 0.6253\n",
      "\n",
      "Training model with batch_size=128, target_eps=0.5...\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 5.05 iterated over 20900 steps satisfies differential privacy with eps = 0.337 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 2.5749999999999997 iterated over 20900 steps satisfies differential privacy with eps = 0.684 and delta = 1e-05.\n",
      "The optimal RDP order is 35.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 3.8125 iterated over 20900 steps satisfies differential privacy with eps = 0.449 and delta = 1e-05.\n",
      "The optimal RDP order is 53.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 3.1937499999999996 iterated over 20900 steps satisfies differential privacy with eps = 0.542 and delta = 1e-05.\n",
      "The optimal RDP order is 44.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 3.503125 iterated over 20900 steps satisfies differential privacy with eps = 0.491 and delta = 1e-05.\n",
      "The optimal RDP order is 48.0.\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7390 - accuracy: 0.4809 - val_loss: 0.5450 - val_accuracy: 0.8830\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.4863 - val_loss: 0.5803 - val_accuracy: 0.8830\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.5006 - val_loss: 0.6080 - val_accuracy: 0.8831\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.5114 - val_loss: 0.6292 - val_accuracy: 0.8516\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6918 - accuracy: 0.5249 - val_loss: 0.6451 - val_accuracy: 0.8131\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5365 - val_loss: 0.6569 - val_accuracy: 0.7536\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5381 - val_loss: 0.6654 - val_accuracy: 0.6875\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5435 - val_loss: 0.6714 - val_accuracy: 0.6326\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5485 - val_loss: 0.6757 - val_accuracy: 0.6103\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5551 - val_loss: 0.6788 - val_accuracy: 0.5971\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5555 - val_loss: 0.6807 - val_accuracy: 0.5917\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5567 - val_loss: 0.6819 - val_accuracy: 0.5873\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5600 - val_loss: 0.6824 - val_accuracy: 0.5863\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6789 - accuracy: 0.5657 - val_loss: 0.6826 - val_accuracy: 0.5855\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5685 - val_loss: 0.6823 - val_accuracy: 0.5872\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6774 - accuracy: 0.5715 - val_loss: 0.6823 - val_accuracy: 0.5883\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.5740 - val_loss: 0.6822 - val_accuracy: 0.5900\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.5804 - val_loss: 0.6818 - val_accuracy: 0.5913\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6746 - accuracy: 0.5773 - val_loss: 0.6813 - val_accuracy: 0.5928\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.5827 - val_loss: 0.6810 - val_accuracy: 0.5952\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6723 - accuracy: 0.5846 - val_loss: 0.6804 - val_accuracy: 0.5979\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 996us/step - loss: 0.6721 - accuracy: 0.5852 - val_loss: 0.6799 - val_accuracy: 0.6007\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6712 - accuracy: 0.5854 - val_loss: 0.6794 - val_accuracy: 0.6031\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6701 - accuracy: 0.5920 - val_loss: 0.6793 - val_accuracy: 0.6044\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.5905 - val_loss: 0.6788 - val_accuracy: 0.6077\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6691 - accuracy: 0.5927 - val_loss: 0.6781 - val_accuracy: 0.6096\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.5963 - val_loss: 0.6777 - val_accuracy: 0.6106\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.5964 - val_loss: 0.6775 - val_accuracy: 0.6107\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6677 - accuracy: 0.5960 - val_loss: 0.6772 - val_accuracy: 0.6122\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6660 - accuracy: 0.6047 - val_loss: 0.6771 - val_accuracy: 0.6119\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6654 - accuracy: 0.6039 - val_loss: 0.6765 - val_accuracy: 0.6125\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6654 - accuracy: 0.6044 - val_loss: 0.6765 - val_accuracy: 0.6117\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.6027 - val_loss: 0.6760 - val_accuracy: 0.6131\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.6043 - val_loss: 0.6753 - val_accuracy: 0.6147\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6070 - val_loss: 0.6752 - val_accuracy: 0.6143\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.6093 - val_loss: 0.6748 - val_accuracy: 0.6154\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6122 - val_loss: 0.6746 - val_accuracy: 0.6156\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 981us/step - loss: 0.6628 - accuracy: 0.6104 - val_loss: 0.6742 - val_accuracy: 0.6168\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6139 - val_loss: 0.6739 - val_accuracy: 0.6167\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6113 - val_loss: 0.6734 - val_accuracy: 0.6171\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6140 - val_loss: 0.6729 - val_accuracy: 0.6173\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.6156 - val_loss: 0.6726 - val_accuracy: 0.6163\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6205 - val_loss: 0.6721 - val_accuracy: 0.6159\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6201 - val_loss: 0.6714 - val_accuracy: 0.6161\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6214 - val_loss: 0.6710 - val_accuracy: 0.6162\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6214 - val_loss: 0.6707 - val_accuracy: 0.6154\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6227 - val_loss: 0.6705 - val_accuracy: 0.6147\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 982us/step - loss: 0.6569 - accuracy: 0.6221 - val_loss: 0.6701 - val_accuracy: 0.6150\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6248 - val_loss: 0.6697 - val_accuracy: 0.6150\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6244 - val_loss: 0.6689 - val_accuracy: 0.6157\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7340 - accuracy: 0.5028 - val_loss: 0.7678 - val_accuracy: 0.1734\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7237 - accuracy: 0.5096 - val_loss: 0.7399 - val_accuracy: 0.2802\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.5082 - val_loss: 0.7261 - val_accuracy: 0.3712\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.5138 - val_loss: 0.7186 - val_accuracy: 0.4221\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7131 - accuracy: 0.5210 - val_loss: 0.7140 - val_accuracy: 0.4599\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 927us/step - loss: 0.7121 - accuracy: 0.5201 - val_loss: 0.7081 - val_accuracy: 0.4972\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.5275 - val_loss: 0.7047 - val_accuracy: 0.5264\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7049 - accuracy: 0.5303 - val_loss: 0.7021 - val_accuracy: 0.5400\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.5357 - val_loss: 0.6983 - val_accuracy: 0.5555\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.5415 - val_loss: 0.6949 - val_accuracy: 0.5681\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.5410 - val_loss: 0.6934 - val_accuracy: 0.5746\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5500 - val_loss: 0.6923 - val_accuracy: 0.5768\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5521 - val_loss: 0.6904 - val_accuracy: 0.5821\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6898 - accuracy: 0.5541 - val_loss: 0.6893 - val_accuracy: 0.5832\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5587 - val_loss: 0.6875 - val_accuracy: 0.5863\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5598 - val_loss: 0.6875 - val_accuracy: 0.5834\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6826 - accuracy: 0.5639 - val_loss: 0.6860 - val_accuracy: 0.5859\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6811 - accuracy: 0.5652 - val_loss: 0.6850 - val_accuracy: 0.5875\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6803 - accuracy: 0.5684 - val_loss: 0.6829 - val_accuracy: 0.5933\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6800 - accuracy: 0.5659 - val_loss: 0.6812 - val_accuracy: 0.5977\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6763 - accuracy: 0.5738 - val_loss: 0.6797 - val_accuracy: 0.5983\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.5738 - val_loss: 0.6786 - val_accuracy: 0.6007\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5789 - val_loss: 0.6776 - val_accuracy: 0.6013\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5818 - val_loss: 0.6761 - val_accuracy: 0.6038\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6701 - accuracy: 0.5847 - val_loss: 0.6740 - val_accuracy: 0.6098\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6703 - accuracy: 0.5836 - val_loss: 0.6719 - val_accuracy: 0.6151\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6686 - accuracy: 0.5892 - val_loss: 0.6725 - val_accuracy: 0.6109\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 998us/step - loss: 0.6661 - accuracy: 0.5914 - val_loss: 0.6712 - val_accuracy: 0.6127\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6653 - accuracy: 0.5930 - val_loss: 0.6698 - val_accuracy: 0.6156\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 996us/step - loss: 0.6643 - accuracy: 0.5957 - val_loss: 0.6692 - val_accuracy: 0.6145\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.5987 - val_loss: 0.6685 - val_accuracy: 0.6133\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.6001 - val_loss: 0.6667 - val_accuracy: 0.6164\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6011 - val_loss: 0.6651 - val_accuracy: 0.6192\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.6043 - val_loss: 0.6638 - val_accuracy: 0.6204\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6066 - val_loss: 0.6631 - val_accuracy: 0.6197\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6070 - val_loss: 0.6639 - val_accuracy: 0.6164\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6553 - accuracy: 0.6134 - val_loss: 0.6635 - val_accuracy: 0.6155\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6086 - val_loss: 0.6629 - val_accuracy: 0.6154\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6538 - accuracy: 0.6146 - val_loss: 0.6622 - val_accuracy: 0.6157\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6140 - val_loss: 0.6612 - val_accuracy: 0.6167\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6181 - val_loss: 0.6607 - val_accuracy: 0.6157\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6134 - val_loss: 0.6601 - val_accuracy: 0.6163\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6210 - val_loss: 0.6597 - val_accuracy: 0.6154\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6211 - val_loss: 0.6580 - val_accuracy: 0.6184\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6215 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6474 - accuracy: 0.6249 - val_loss: 0.6570 - val_accuracy: 0.6173\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6475 - accuracy: 0.6246 - val_loss: 0.6570 - val_accuracy: 0.6150\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6456 - accuracy: 0.6264 - val_loss: 0.6571 - val_accuracy: 0.6133\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6455 - accuracy: 0.6252 - val_loss: 0.6573 - val_accuracy: 0.6114\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6441 - accuracy: 0.6315 - val_loss: 0.6556 - val_accuracy: 0.6134\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6725 - accuracy: 0.5759 - val_loss: 0.6471 - val_accuracy: 0.6834\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6682 - accuracy: 0.5822 - val_loss: 0.6597 - val_accuracy: 0.6466\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6669 - accuracy: 0.5825 - val_loss: 0.6657 - val_accuracy: 0.6342\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6651 - accuracy: 0.5857 - val_loss: 0.6678 - val_accuracy: 0.6279\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6645 - accuracy: 0.5885 - val_loss: 0.6678 - val_accuracy: 0.6274\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.5890 - val_loss: 0.6678 - val_accuracy: 0.6283\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6609 - accuracy: 0.5927 - val_loss: 0.6677 - val_accuracy: 0.6283\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6601 - accuracy: 0.5939 - val_loss: 0.6656 - val_accuracy: 0.6325\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6576 - accuracy: 0.5996 - val_loss: 0.6651 - val_accuracy: 0.6331\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6571 - accuracy: 0.5995 - val_loss: 0.6637 - val_accuracy: 0.6361\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6011 - val_loss: 0.6613 - val_accuracy: 0.6397\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6556 - accuracy: 0.6001 - val_loss: 0.6595 - val_accuracy: 0.6423\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6529 - accuracy: 0.6063 - val_loss: 0.6584 - val_accuracy: 0.6440\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6096 - val_loss: 0.6577 - val_accuracy: 0.6453\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6504 - accuracy: 0.6114 - val_loss: 0.6570 - val_accuracy: 0.6460\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6505 - accuracy: 0.6094 - val_loss: 0.6562 - val_accuracy: 0.6475\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6478 - accuracy: 0.6164 - val_loss: 0.6563 - val_accuracy: 0.6464\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6481 - accuracy: 0.6132 - val_loss: 0.6554 - val_accuracy: 0.6461\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6449 - accuracy: 0.6176 - val_loss: 0.6529 - val_accuracy: 0.6496\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6455 - accuracy: 0.6181 - val_loss: 0.6516 - val_accuracy: 0.6504\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6445 - accuracy: 0.6183 - val_loss: 0.6508 - val_accuracy: 0.6509\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6225 - val_loss: 0.6497 - val_accuracy: 0.6527\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6418 - accuracy: 0.6229 - val_loss: 0.6493 - val_accuracy: 0.6529\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6415 - accuracy: 0.6249 - val_loss: 0.6481 - val_accuracy: 0.6550\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6405 - accuracy: 0.6258 - val_loss: 0.6472 - val_accuracy: 0.6561\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6396 - accuracy: 0.6290 - val_loss: 0.6454 - val_accuracy: 0.6582\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6395 - accuracy: 0.6260 - val_loss: 0.6450 - val_accuracy: 0.6584\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6294 - val_loss: 0.6451 - val_accuracy: 0.6568\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6370 - accuracy: 0.6303 - val_loss: 0.6451 - val_accuracy: 0.6551\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6358 - accuracy: 0.6328 - val_loss: 0.6439 - val_accuracy: 0.6560\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6356 - accuracy: 0.6315 - val_loss: 0.6425 - val_accuracy: 0.6566\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6340 - accuracy: 0.6349 - val_loss: 0.6430 - val_accuracy: 0.6553\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6348 - accuracy: 0.6333 - val_loss: 0.6427 - val_accuracy: 0.6543\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6330 - accuracy: 0.6351 - val_loss: 0.6420 - val_accuracy: 0.6542\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6309 - accuracy: 0.6360 - val_loss: 0.6406 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6381 - val_loss: 0.6396 - val_accuracy: 0.6564\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6299 - accuracy: 0.6389 - val_loss: 0.6390 - val_accuracy: 0.6561\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6293 - accuracy: 0.6392 - val_loss: 0.6381 - val_accuracy: 0.6576\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6292 - accuracy: 0.6418 - val_loss: 0.6375 - val_accuracy: 0.6575\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6284 - accuracy: 0.6428 - val_loss: 0.6368 - val_accuracy: 0.6572\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6284 - accuracy: 0.6419 - val_loss: 0.6364 - val_accuracy: 0.6573\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6262 - accuracy: 0.6433 - val_loss: 0.6365 - val_accuracy: 0.6564\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.6442 - val_loss: 0.6358 - val_accuracy: 0.6564\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6259 - accuracy: 0.6448 - val_loss: 0.6349 - val_accuracy: 0.6579\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.6466 - val_loss: 0.6343 - val_accuracy: 0.6582\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6242 - accuracy: 0.6449 - val_loss: 0.6338 - val_accuracy: 0.6580\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6230 - accuracy: 0.6484 - val_loss: 0.6339 - val_accuracy: 0.6569\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6217 - accuracy: 0.6469 - val_loss: 0.6311 - val_accuracy: 0.6598\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6218 - accuracy: 0.6478 - val_loss: 0.6317 - val_accuracy: 0.6579\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6212 - accuracy: 0.6502 - val_loss: 0.6314 - val_accuracy: 0.6580\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7041 - accuracy: 0.5140 - val_loss: 0.6620 - val_accuracy: 0.6884\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.5285 - val_loss: 0.6842 - val_accuracy: 0.5642\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6952 - accuracy: 0.5330 - val_loss: 0.6968 - val_accuracy: 0.4925\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5416 - val_loss: 0.7037 - val_accuracy: 0.4558\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5441 - val_loss: 0.7069 - val_accuracy: 0.4409\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5517 - val_loss: 0.7081 - val_accuracy: 0.4380\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5535 - val_loss: 0.7072 - val_accuracy: 0.4475\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5575 - val_loss: 0.7058 - val_accuracy: 0.4600\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5667 - val_loss: 0.7040 - val_accuracy: 0.4674\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6804 - accuracy: 0.5707 - val_loss: 0.7014 - val_accuracy: 0.4755\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.5734 - val_loss: 0.6984 - val_accuracy: 0.4874\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6760 - accuracy: 0.5817 - val_loss: 0.6959 - val_accuracy: 0.5020\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.5878 - val_loss: 0.6936 - val_accuracy: 0.5134\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6728 - accuracy: 0.5864 - val_loss: 0.6911 - val_accuracy: 0.5206\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6708 - accuracy: 0.5944 - val_loss: 0.6891 - val_accuracy: 0.5337\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6697 - accuracy: 0.5969 - val_loss: 0.6874 - val_accuracy: 0.5422\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.5985 - val_loss: 0.6861 - val_accuracy: 0.5505\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6667 - accuracy: 0.6003 - val_loss: 0.6854 - val_accuracy: 0.5549\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.6058 - val_loss: 0.6843 - val_accuracy: 0.5614\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6646 - accuracy: 0.6065 - val_loss: 0.6832 - val_accuracy: 0.5673\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6622 - accuracy: 0.6103 - val_loss: 0.6821 - val_accuracy: 0.5715\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.6152 - val_loss: 0.6811 - val_accuracy: 0.5749\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6601 - accuracy: 0.6163 - val_loss: 0.6801 - val_accuracy: 0.5803\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6590 - accuracy: 0.6177 - val_loss: 0.6786 - val_accuracy: 0.5854\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6569 - accuracy: 0.6204 - val_loss: 0.6777 - val_accuracy: 0.5894\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6209 - val_loss: 0.6771 - val_accuracy: 0.5903\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6566 - accuracy: 0.6228 - val_loss: 0.6760 - val_accuracy: 0.5932\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.6241 - val_loss: 0.6749 - val_accuracy: 0.5952\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6541 - accuracy: 0.6263 - val_loss: 0.6740 - val_accuracy: 0.5966\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6533 - accuracy: 0.6292 - val_loss: 0.6729 - val_accuracy: 0.5994\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6525 - accuracy: 0.6306 - val_loss: 0.6713 - val_accuracy: 0.6044\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6309 - val_loss: 0.6703 - val_accuracy: 0.6071\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6505 - accuracy: 0.6335 - val_loss: 0.6693 - val_accuracy: 0.6107\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6498 - accuracy: 0.6367 - val_loss: 0.6688 - val_accuracy: 0.6127\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6490 - accuracy: 0.6367 - val_loss: 0.6681 - val_accuracy: 0.6147\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6478 - accuracy: 0.6400 - val_loss: 0.6675 - val_accuracy: 0.6168\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6475 - accuracy: 0.6390 - val_loss: 0.6664 - val_accuracy: 0.6200\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6467 - accuracy: 0.6403 - val_loss: 0.6649 - val_accuracy: 0.6238\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6463 - accuracy: 0.6411 - val_loss: 0.6639 - val_accuracy: 0.6261\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6459 - val_loss: 0.6636 - val_accuracy: 0.6259\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6434 - accuracy: 0.6469 - val_loss: 0.6626 - val_accuracy: 0.6282\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6417 - accuracy: 0.6498 - val_loss: 0.6610 - val_accuracy: 0.6309\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6414 - accuracy: 0.6523 - val_loss: 0.6601 - val_accuracy: 0.6321\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6399 - accuracy: 0.6545 - val_loss: 0.6585 - val_accuracy: 0.6336\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6499 - val_loss: 0.6577 - val_accuracy: 0.6325\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6384 - accuracy: 0.6527 - val_loss: 0.6566 - val_accuracy: 0.6321\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.6533 - val_loss: 0.6559 - val_accuracy: 0.6305\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6365 - accuracy: 0.6587 - val_loss: 0.6546 - val_accuracy: 0.6324\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6349 - accuracy: 0.6588 - val_loss: 0.6527 - val_accuracy: 0.6371\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6349 - accuracy: 0.6592 - val_loss: 0.6523 - val_accuracy: 0.6380\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7590 - accuracy: 0.5221 - val_loss: 0.8670 - val_accuracy: 0.1606\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7183 - accuracy: 0.5211 - val_loss: 0.7652 - val_accuracy: 0.3279\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7068 - accuracy: 0.5202 - val_loss: 0.7256 - val_accuracy: 0.4328\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7055 - accuracy: 0.5226 - val_loss: 0.7088 - val_accuracy: 0.4942\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7019 - accuracy: 0.5257 - val_loss: 0.7034 - val_accuracy: 0.5156\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7019 - accuracy: 0.5248 - val_loss: 0.6994 - val_accuracy: 0.5292\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7012 - accuracy: 0.5238 - val_loss: 0.6983 - val_accuracy: 0.5338\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6993 - accuracy: 0.5300 - val_loss: 0.6955 - val_accuracy: 0.5448\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6964 - accuracy: 0.5338 - val_loss: 0.6950 - val_accuracy: 0.5466\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6962 - accuracy: 0.5329 - val_loss: 0.6951 - val_accuracy: 0.5478\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5389 - val_loss: 0.6939 - val_accuracy: 0.5524\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5402 - val_loss: 0.6944 - val_accuracy: 0.5514\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6941 - accuracy: 0.5364 - val_loss: 0.6931 - val_accuracy: 0.5552\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6892 - accuracy: 0.5435 - val_loss: 0.6911 - val_accuracy: 0.5619\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5513 - val_loss: 0.6910 - val_accuracy: 0.5630\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5527 - val_loss: 0.6894 - val_accuracy: 0.5678\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5540 - val_loss: 0.6887 - val_accuracy: 0.5694\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5544 - val_loss: 0.6896 - val_accuracy: 0.5682\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5583 - val_loss: 0.6886 - val_accuracy: 0.5713\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6809 - accuracy: 0.5653 - val_loss: 0.6864 - val_accuracy: 0.5753\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6806 - accuracy: 0.5609 - val_loss: 0.6864 - val_accuracy: 0.5757\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6781 - accuracy: 0.5670 - val_loss: 0.6838 - val_accuracy: 0.5807\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6796 - accuracy: 0.5652 - val_loss: 0.6845 - val_accuracy: 0.5793\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6771 - accuracy: 0.5700 - val_loss: 0.6838 - val_accuracy: 0.5809\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.5696 - val_loss: 0.6831 - val_accuracy: 0.5824\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6744 - accuracy: 0.5757 - val_loss: 0.6825 - val_accuracy: 0.5839\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6742 - accuracy: 0.5741 - val_loss: 0.6819 - val_accuracy: 0.5853\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6720 - accuracy: 0.5786 - val_loss: 0.6807 - val_accuracy: 0.5879\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.5803 - val_loss: 0.6805 - val_accuracy: 0.5876\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.5815 - val_loss: 0.6786 - val_accuracy: 0.5916\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6704 - accuracy: 0.5830 - val_loss: 0.6792 - val_accuracy: 0.5902\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5840 - val_loss: 0.6772 - val_accuracy: 0.5943\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.5873 - val_loss: 0.6778 - val_accuracy: 0.5935\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.5904 - val_loss: 0.6771 - val_accuracy: 0.5947\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6672 - accuracy: 0.5891 - val_loss: 0.6738 - val_accuracy: 0.6006\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.5945 - val_loss: 0.6732 - val_accuracy: 0.6017\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6651 - accuracy: 0.5965 - val_loss: 0.6732 - val_accuracy: 0.6025\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6637 - accuracy: 0.5992 - val_loss: 0.6727 - val_accuracy: 0.6039\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6633 - accuracy: 0.5965 - val_loss: 0.6722 - val_accuracy: 0.6048\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6619 - accuracy: 0.5974 - val_loss: 0.6713 - val_accuracy: 0.6061\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6037 - val_loss: 0.6699 - val_accuracy: 0.6102\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.6062 - val_loss: 0.6695 - val_accuracy: 0.6113\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6587 - accuracy: 0.6069 - val_loss: 0.6690 - val_accuracy: 0.6117\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6582 - accuracy: 0.6119 - val_loss: 0.6675 - val_accuracy: 0.6141\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6579 - accuracy: 0.6086 - val_loss: 0.6679 - val_accuracy: 0.6131\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6576 - accuracy: 0.6108 - val_loss: 0.6689 - val_accuracy: 0.6107\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6552 - accuracy: 0.6140 - val_loss: 0.6666 - val_accuracy: 0.6156\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6116 - val_loss: 0.6652 - val_accuracy: 0.6174\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6549 - accuracy: 0.6158 - val_loss: 0.6638 - val_accuracy: 0.6195\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6551 - accuracy: 0.6166 - val_loss: 0.6634 - val_accuracy: 0.6201\n",
      "Epoch 1/50\n",
      "  1/418 [..............................] - ETA: 0s - loss: 0.7602 - accuracy: 0.4688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7370 - accuracy: 0.4993 - val_loss: 0.6280 - val_accuracy: 0.7202\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7163 - accuracy: 0.5064 - val_loss: 0.6707 - val_accuracy: 0.5667\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7082 - accuracy: 0.5135 - val_loss: 0.6962 - val_accuracy: 0.4946\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7055 - accuracy: 0.5120 - val_loss: 0.7113 - val_accuracy: 0.4610\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7025 - accuracy: 0.5191 - val_loss: 0.7194 - val_accuracy: 0.4462\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5253 - val_loss: 0.7228 - val_accuracy: 0.4424\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.5265 - val_loss: 0.7248 - val_accuracy: 0.4398\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.5328 - val_loss: 0.7259 - val_accuracy: 0.4396\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5375 - val_loss: 0.7254 - val_accuracy: 0.4435\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6920 - accuracy: 0.5407 - val_loss: 0.7241 - val_accuracy: 0.4493\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5416 - val_loss: 0.7228 - val_accuracy: 0.4555\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5484 - val_loss: 0.7222 - val_accuracy: 0.4576\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5538 - val_loss: 0.7205 - val_accuracy: 0.4667\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5533 - val_loss: 0.7196 - val_accuracy: 0.4748\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5604 - val_loss: 0.7177 - val_accuracy: 0.4797\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5612 - val_loss: 0.7161 - val_accuracy: 0.4840\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6804 - accuracy: 0.5658 - val_loss: 0.7146 - val_accuracy: 0.4870\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5727 - val_loss: 0.7126 - val_accuracy: 0.4904\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6776 - accuracy: 0.5749 - val_loss: 0.7119 - val_accuracy: 0.4913\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.5788 - val_loss: 0.7105 - val_accuracy: 0.4965\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6741 - accuracy: 0.5834 - val_loss: 0.7092 - val_accuracy: 0.5012\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6740 - accuracy: 0.5837 - val_loss: 0.7076 - val_accuracy: 0.5076\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.5872 - val_loss: 0.7064 - val_accuracy: 0.5119\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.5907 - val_loss: 0.7044 - val_accuracy: 0.5182\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.5965 - val_loss: 0.7032 - val_accuracy: 0.5291\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 963us/step - loss: 0.6688 - accuracy: 0.5969 - val_loss: 0.7024 - val_accuracy: 0.5328\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6681 - accuracy: 0.5954 - val_loss: 0.7013 - val_accuracy: 0.5358\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6656 - accuracy: 0.6035 - val_loss: 0.7004 - val_accuracy: 0.5360\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.6046 - val_loss: 0.6990 - val_accuracy: 0.5378\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6646 - accuracy: 0.6051 - val_loss: 0.6977 - val_accuracy: 0.5402\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6087 - val_loss: 0.6960 - val_accuracy: 0.5485\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6620 - accuracy: 0.6108 - val_loss: 0.6951 - val_accuracy: 0.5517\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 995us/step - loss: 0.6612 - accuracy: 0.6142 - val_loss: 0.6939 - val_accuracy: 0.5558\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.6138 - val_loss: 0.6933 - val_accuracy: 0.5579\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6181 - val_loss: 0.6921 - val_accuracy: 0.5611\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6580 - accuracy: 0.6218 - val_loss: 0.6906 - val_accuracy: 0.5660\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.6574 - accuracy: 0.6233 - val_loss: 0.6894 - val_accuracy: 0.5668\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6255 - val_loss: 0.6882 - val_accuracy: 0.5674\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6554 - accuracy: 0.6239 - val_loss: 0.6872 - val_accuracy: 0.5688\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6292 - val_loss: 0.6866 - val_accuracy: 0.5689\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6300 - val_loss: 0.6860 - val_accuracy: 0.5724\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6280 - val_loss: 0.6847 - val_accuracy: 0.5776\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.6509 - accuracy: 0.6327 - val_loss: 0.6833 - val_accuracy: 0.5827\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6511 - accuracy: 0.6339 - val_loss: 0.6822 - val_accuracy: 0.5853\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 989us/step - loss: 0.6510 - accuracy: 0.6333 - val_loss: 0.6812 - val_accuracy: 0.5876\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6398 - val_loss: 0.6803 - val_accuracy: 0.5898\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 942us/step - loss: 0.6471 - accuracy: 0.6403 - val_loss: 0.6799 - val_accuracy: 0.5904\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6386 - val_loss: 0.6787 - val_accuracy: 0.5928\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6454 - accuracy: 0.6418 - val_loss: 0.6774 - val_accuracy: 0.5936\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6439 - accuracy: 0.6455 - val_loss: 0.6766 - val_accuracy: 0.5948\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5417 - val_loss: 0.7302 - val_accuracy: 0.4681\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6923 - accuracy: 0.5417 - val_loss: 0.7213 - val_accuracy: 0.5043\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5476 - val_loss: 0.7156 - val_accuracy: 0.5270\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5519 - val_loss: 0.7125 - val_accuracy: 0.5350\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 963us/step - loss: 0.6856 - accuracy: 0.5549 - val_loss: 0.7102 - val_accuracy: 0.5410\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5581 - val_loss: 0.7078 - val_accuracy: 0.5442\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 992us/step - loss: 0.6825 - accuracy: 0.5657 - val_loss: 0.7052 - val_accuracy: 0.5485\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5619 - val_loss: 0.7039 - val_accuracy: 0.5497\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5689 - val_loss: 0.7019 - val_accuracy: 0.5530\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5701 - val_loss: 0.7004 - val_accuracy: 0.5550\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5732 - val_loss: 0.7002 - val_accuracy: 0.5525\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6767 - accuracy: 0.5775 - val_loss: 0.6989 - val_accuracy: 0.5539\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5785 - val_loss: 0.6979 - val_accuracy: 0.5549\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6747 - accuracy: 0.5809 - val_loss: 0.6964 - val_accuracy: 0.5573\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.5833 - val_loss: 0.6950 - val_accuracy: 0.5599\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5884 - val_loss: 0.6934 - val_accuracy: 0.5614\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6700 - accuracy: 0.5893 - val_loss: 0.6924 - val_accuracy: 0.5622\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.5919 - val_loss: 0.6919 - val_accuracy: 0.5630\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 925us/step - loss: 0.6689 - accuracy: 0.5913 - val_loss: 0.6910 - val_accuracy: 0.5642\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6675 - accuracy: 0.5946 - val_loss: 0.6905 - val_accuracy: 0.5647\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6654 - accuracy: 0.5994 - val_loss: 0.6893 - val_accuracy: 0.5662\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6034 - val_loss: 0.6891 - val_accuracy: 0.5653\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.6038 - val_loss: 0.6869 - val_accuracy: 0.5688\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 990us/step - loss: 0.6623 - accuracy: 0.6080 - val_loss: 0.6865 - val_accuracy: 0.5688\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6075 - val_loss: 0.6855 - val_accuracy: 0.5701\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 977us/step - loss: 0.6611 - accuracy: 0.6120 - val_loss: 0.6842 - val_accuracy: 0.5726\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6130 - val_loss: 0.6833 - val_accuracy: 0.5747\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.6597 - accuracy: 0.6115 - val_loss: 0.6824 - val_accuracy: 0.5755\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6151 - val_loss: 0.6814 - val_accuracy: 0.5767\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6156 - val_loss: 0.6801 - val_accuracy: 0.5802\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 943us/step - loss: 0.6570 - accuracy: 0.6177 - val_loss: 0.6801 - val_accuracy: 0.5790\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6220 - val_loss: 0.6792 - val_accuracy: 0.5824\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6216 - val_loss: 0.6784 - val_accuracy: 0.5855\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6254 - val_loss: 0.6780 - val_accuracy: 0.5866\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6260 - val_loss: 0.6770 - val_accuracy: 0.5891\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6261 - val_loss: 0.6767 - val_accuracy: 0.5887\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6324 - val_loss: 0.6759 - val_accuracy: 0.5892\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 988us/step - loss: 0.6503 - accuracy: 0.6301 - val_loss: 0.6756 - val_accuracy: 0.5891\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6327 - val_loss: 0.6750 - val_accuracy: 0.5884\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6340 - val_loss: 0.6744 - val_accuracy: 0.5902\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6356 - val_loss: 0.6734 - val_accuracy: 0.5924\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 993us/step - loss: 0.6464 - accuracy: 0.6387 - val_loss: 0.6729 - val_accuracy: 0.5933\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.6406 - val_loss: 0.6717 - val_accuracy: 0.5958\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6449 - accuracy: 0.6398 - val_loss: 0.6706 - val_accuracy: 0.5987\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6415 - val_loss: 0.6701 - val_accuracy: 0.5987\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.6426 - val_loss: 0.6703 - val_accuracy: 0.5980\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6425 - accuracy: 0.6435 - val_loss: 0.6695 - val_accuracy: 0.5998\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6435 - val_loss: 0.6687 - val_accuracy: 0.6007\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6474 - val_loss: 0.6676 - val_accuracy: 0.6022\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6481 - val_loss: 0.6668 - val_accuracy: 0.6031\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7373 - accuracy: 0.5050 - val_loss: 0.8688 - val_accuracy: 0.1172\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7203 - accuracy: 0.4933 - val_loss: 0.8101 - val_accuracy: 0.1174\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.4933 - val_loss: 0.7790 - val_accuracy: 0.1360\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.4975 - val_loss: 0.7623 - val_accuracy: 0.1587\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 936us/step - loss: 0.7056 - accuracy: 0.5009 - val_loss: 0.7515 - val_accuracy: 0.1807\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.5109 - val_loss: 0.7450 - val_accuracy: 0.1962\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.5217 - val_loss: 0.7404 - val_accuracy: 0.2097\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.5259 - val_loss: 0.7367 - val_accuracy: 0.2277\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5363 - val_loss: 0.7341 - val_accuracy: 0.2493\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5439 - val_loss: 0.7310 - val_accuracy: 0.2786\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.6884 - accuracy: 0.5514 - val_loss: 0.7285 - val_accuracy: 0.3123\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5540 - val_loss: 0.7262 - val_accuracy: 0.3352\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5651 - val_loss: 0.7245 - val_accuracy: 0.3546\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5707 - val_loss: 0.7214 - val_accuracy: 0.3770\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5779 - val_loss: 0.7185 - val_accuracy: 0.3943\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6775 - accuracy: 0.5836 - val_loss: 0.7160 - val_accuracy: 0.4132\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.5879 - val_loss: 0.7140 - val_accuracy: 0.4278\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6740 - accuracy: 0.5986 - val_loss: 0.7121 - val_accuracy: 0.4417\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.5994 - val_loss: 0.7100 - val_accuracy: 0.4531\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.6009 - val_loss: 0.7079 - val_accuracy: 0.4654\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.6096 - val_loss: 0.7060 - val_accuracy: 0.4776\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.6129 - val_loss: 0.7049 - val_accuracy: 0.4856\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6199 - val_loss: 0.7027 - val_accuracy: 0.4968\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.6198 - val_loss: 0.7007 - val_accuracy: 0.5093\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6630 - accuracy: 0.6248 - val_loss: 0.6994 - val_accuracy: 0.5171\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6254 - val_loss: 0.6975 - val_accuracy: 0.5252\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 995us/step - loss: 0.6601 - accuracy: 0.6321 - val_loss: 0.6952 - val_accuracy: 0.5354\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6316 - val_loss: 0.6941 - val_accuracy: 0.5427\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.6342 - val_loss: 0.6932 - val_accuracy: 0.5446\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6363 - val_loss: 0.6917 - val_accuracy: 0.5489\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6405 - val_loss: 0.6905 - val_accuracy: 0.5540\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6552 - accuracy: 0.6424 - val_loss: 0.6898 - val_accuracy: 0.5567\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6464 - val_loss: 0.6884 - val_accuracy: 0.5607\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6453 - val_loss: 0.6872 - val_accuracy: 0.5634\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6471 - val_loss: 0.6868 - val_accuracy: 0.5638\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6497 - val_loss: 0.6858 - val_accuracy: 0.5663\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6531 - val_loss: 0.6841 - val_accuracy: 0.5702\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6492 - accuracy: 0.6550 - val_loss: 0.6833 - val_accuracy: 0.5718\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6483 - accuracy: 0.6572 - val_loss: 0.6826 - val_accuracy: 0.5730\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6546 - val_loss: 0.6820 - val_accuracy: 0.5740\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6473 - accuracy: 0.6570 - val_loss: 0.6810 - val_accuracy: 0.5762\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6462 - accuracy: 0.6553 - val_loss: 0.6804 - val_accuracy: 0.5772\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6583 - val_loss: 0.6789 - val_accuracy: 0.5804\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.6633 - val_loss: 0.6775 - val_accuracy: 0.5833\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6605 - val_loss: 0.6768 - val_accuracy: 0.5841\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6427 - accuracy: 0.6630 - val_loss: 0.6764 - val_accuracy: 0.5842\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6629 - val_loss: 0.6761 - val_accuracy: 0.5841\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.6609 - val_loss: 0.6751 - val_accuracy: 0.5860\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.6616 - val_loss: 0.6745 - val_accuracy: 0.5866\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6394 - accuracy: 0.6666 - val_loss: 0.6735 - val_accuracy: 0.5886\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7120 - accuracy: 0.4978 - val_loss: 0.6305 - val_accuracy: 0.8060\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.5091 - val_loss: 0.6602 - val_accuracy: 0.6788\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.5269 - val_loss: 0.6752 - val_accuracy: 0.6015\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5362 - val_loss: 0.6833 - val_accuracy: 0.5573\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5420 - val_loss: 0.6870 - val_accuracy: 0.5362\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5478 - val_loss: 0.6872 - val_accuracy: 0.5315\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5512 - val_loss: 0.6870 - val_accuracy: 0.5281\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5547 - val_loss: 0.6876 - val_accuracy: 0.5236\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5590 - val_loss: 0.6865 - val_accuracy: 0.5252\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5631 - val_loss: 0.6854 - val_accuracy: 0.5285\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5685 - val_loss: 0.6848 - val_accuracy: 0.5299\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.5723 - val_loss: 0.6834 - val_accuracy: 0.5353\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.5724 - val_loss: 0.6820 - val_accuracy: 0.5381\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6737 - accuracy: 0.5771 - val_loss: 0.6810 - val_accuracy: 0.5399\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.5808 - val_loss: 0.6799 - val_accuracy: 0.5438\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.5789 - val_loss: 0.6788 - val_accuracy: 0.5469\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6692 - accuracy: 0.5857 - val_loss: 0.6770 - val_accuracy: 0.5520\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.5867 - val_loss: 0.6767 - val_accuracy: 0.5550\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6662 - accuracy: 0.5923 - val_loss: 0.6758 - val_accuracy: 0.5572\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6650 - accuracy: 0.5939 - val_loss: 0.6753 - val_accuracy: 0.5577\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.5968 - val_loss: 0.6739 - val_accuracy: 0.5608\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6630 - accuracy: 0.5990 - val_loss: 0.6728 - val_accuracy: 0.5631\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6627 - accuracy: 0.5993 - val_loss: 0.6717 - val_accuracy: 0.5680\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6013 - val_loss: 0.6702 - val_accuracy: 0.5725\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6058 - val_loss: 0.6692 - val_accuracy: 0.5753\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6055 - val_loss: 0.6679 - val_accuracy: 0.5786\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6584 - accuracy: 0.6058 - val_loss: 0.6670 - val_accuracy: 0.5807\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6104 - val_loss: 0.6660 - val_accuracy: 0.5827\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6103 - val_loss: 0.6655 - val_accuracy: 0.5840\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6546 - accuracy: 0.6117 - val_loss: 0.6647 - val_accuracy: 0.5858\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6131 - val_loss: 0.6639 - val_accuracy: 0.5870\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6162 - val_loss: 0.6621 - val_accuracy: 0.5918\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6174 - val_loss: 0.6619 - val_accuracy: 0.5921\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6187 - val_loss: 0.6609 - val_accuracy: 0.5929\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6496 - accuracy: 0.6173 - val_loss: 0.6601 - val_accuracy: 0.5944\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6204 - val_loss: 0.6600 - val_accuracy: 0.5941\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6231 - val_loss: 0.6594 - val_accuracy: 0.5947\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6232 - val_loss: 0.6580 - val_accuracy: 0.5969\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6473 - accuracy: 0.6238 - val_loss: 0.6571 - val_accuracy: 0.5981\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.6243 - val_loss: 0.6575 - val_accuracy: 0.5967\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.6273 - val_loss: 0.6557 - val_accuracy: 0.5988\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6271 - val_loss: 0.6550 - val_accuracy: 0.6000\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 980us/step - loss: 0.6442 - accuracy: 0.6255 - val_loss: 0.6559 - val_accuracy: 0.5980\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.6270 - val_loss: 0.6555 - val_accuracy: 0.5987\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6306 - val_loss: 0.6547 - val_accuracy: 0.6001\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6420 - accuracy: 0.6308 - val_loss: 0.6532 - val_accuracy: 0.6031\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6315 - val_loss: 0.6523 - val_accuracy: 0.6048\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6405 - accuracy: 0.6326 - val_loss: 0.6515 - val_accuracy: 0.6063\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6397 - accuracy: 0.6315 - val_loss: 0.6523 - val_accuracy: 0.6039\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6390 - accuracy: 0.6336 - val_loss: 0.6517 - val_accuracy: 0.6039\n",
      "Epoch 1/50\n",
      "403/418 [===========================>..] - ETA: 0s - loss: 0.8704 - accuracy: 0.5216WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0012s). Check your callbacks.\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.8685 - accuracy: 0.5213 - val_loss: 1.1492 - val_accuracy: 0.1172\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7696 - accuracy: 0.5171 - val_loss: 0.9507 - val_accuracy: 0.1205\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7293 - accuracy: 0.5154 - val_loss: 0.8459 - val_accuracy: 0.1278\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7122 - accuracy: 0.5113 - val_loss: 0.7869 - val_accuracy: 0.1751\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7040 - accuracy: 0.5139 - val_loss: 0.7524 - val_accuracy: 0.3091\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7006 - accuracy: 0.5177 - val_loss: 0.7318 - val_accuracy: 0.3791\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6978 - accuracy: 0.5202 - val_loss: 0.7192 - val_accuracy: 0.4150\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6951 - accuracy: 0.5282 - val_loss: 0.7110 - val_accuracy: 0.4412\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6920 - accuracy: 0.5355 - val_loss: 0.7053 - val_accuracy: 0.4623\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6891 - accuracy: 0.5415 - val_loss: 0.7013 - val_accuracy: 0.4800\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5411 - val_loss: 0.6980 - val_accuracy: 0.4955\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5501 - val_loss: 0.6959 - val_accuracy: 0.5061\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6835 - accuracy: 0.5551 - val_loss: 0.6942 - val_accuracy: 0.5159\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6833 - accuracy: 0.5570 - val_loss: 0.6925 - val_accuracy: 0.5256\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5601 - val_loss: 0.6913 - val_accuracy: 0.5346\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6788 - accuracy: 0.5636 - val_loss: 0.6900 - val_accuracy: 0.5380\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6782 - accuracy: 0.5637 - val_loss: 0.6887 - val_accuracy: 0.5451\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6743 - accuracy: 0.5759 - val_loss: 0.6879 - val_accuracy: 0.5496\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6743 - accuracy: 0.5785 - val_loss: 0.6865 - val_accuracy: 0.5557\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6729 - accuracy: 0.5784 - val_loss: 0.6852 - val_accuracy: 0.5623\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6726 - accuracy: 0.5801 - val_loss: 0.6846 - val_accuracy: 0.5643\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5828 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6692 - accuracy: 0.5849 - val_loss: 0.6817 - val_accuracy: 0.5727\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6670 - accuracy: 0.5921 - val_loss: 0.6806 - val_accuracy: 0.5768\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6652 - accuracy: 0.5957 - val_loss: 0.6792 - val_accuracy: 0.5803\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.5965 - val_loss: 0.6777 - val_accuracy: 0.5839\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.5979 - val_loss: 0.6760 - val_accuracy: 0.5879\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6627 - accuracy: 0.6003 - val_loss: 0.6756 - val_accuracy: 0.5894\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6608 - accuracy: 0.6035 - val_loss: 0.6740 - val_accuracy: 0.5935\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6601 - accuracy: 0.6045 - val_loss: 0.6725 - val_accuracy: 0.5974\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6597 - accuracy: 0.6062 - val_loss: 0.6718 - val_accuracy: 0.5978\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6567 - accuracy: 0.6098 - val_loss: 0.6711 - val_accuracy: 0.5996\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6555 - accuracy: 0.6127 - val_loss: 0.6697 - val_accuracy: 0.6036\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6553 - accuracy: 0.6108 - val_loss: 0.6689 - val_accuracy: 0.6049\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6537 - accuracy: 0.6160 - val_loss: 0.6681 - val_accuracy: 0.6068\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6532 - accuracy: 0.6184 - val_loss: 0.6663 - val_accuracy: 0.6105\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6527 - accuracy: 0.6178 - val_loss: 0.6656 - val_accuracy: 0.6116\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6510 - accuracy: 0.6201 - val_loss: 0.6649 - val_accuracy: 0.6123\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6522 - accuracy: 0.6187 - val_loss: 0.6636 - val_accuracy: 0.6143\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6492 - accuracy: 0.6220 - val_loss: 0.6631 - val_accuracy: 0.6144\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6258 - val_loss: 0.6627 - val_accuracy: 0.6150\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6473 - accuracy: 0.6259 - val_loss: 0.6621 - val_accuracy: 0.6154\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6470 - accuracy: 0.6270 - val_loss: 0.6610 - val_accuracy: 0.6179\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6457 - accuracy: 0.6269 - val_loss: 0.6604 - val_accuracy: 0.6187\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6436 - accuracy: 0.6324 - val_loss: 0.6594 - val_accuracy: 0.6206\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6442 - accuracy: 0.6312 - val_loss: 0.6589 - val_accuracy: 0.6214\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6431 - accuracy: 0.6300 - val_loss: 0.6580 - val_accuracy: 0.6230\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6424 - accuracy: 0.6323 - val_loss: 0.6569 - val_accuracy: 0.6242\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6417 - accuracy: 0.6335 - val_loss: 0.6559 - val_accuracy: 0.6263\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6415 - accuracy: 0.6351 - val_loss: 0.6540 - val_accuracy: 0.6293\n",
      "\n",
      "Training model with batch_size=128, target_eps=1.0...\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 5.05 iterated over 20900 steps satisfies differential privacy with eps = 0.337 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 2.5749999999999997 iterated over 20900 steps satisfies differential privacy with eps = 0.684 and delta = 1e-05.\n",
      "The optimal RDP order is 35.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.3375 iterated over 20900 steps satisfies differential privacy with eps = 1.51 and delta = 1e-05.\n",
      "The optimal RDP order is 16.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.9562499999999998 iterated over 20900 steps satisfies differential privacy with eps = 0.934 and delta = 1e-05.\n",
      "The optimal RDP order is 26.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.6468749999999999 iterated over 20900 steps satisfies differential privacy with eps = 1.15 and delta = 1e-05.\n",
      "The optimal RDP order is 21.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.8015624999999997 iterated over 20900 steps satisfies differential privacy with eps = 1.03 and delta = 1e-05.\n",
      "The optimal RDP order is 24.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.8789062499999998 iterated over 20900 steps satisfies differential privacy with eps = 0.979 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.8402343749999996 iterated over 20900 steps satisfies differential privacy with eps = 1 and delta = 1e-05.\n",
      "The optimal RDP order is 24.0.\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7270 - accuracy: 0.5083 - val_loss: 0.7673 - val_accuracy: 0.2128\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7217 - accuracy: 0.5110 - val_loss: 0.7473 - val_accuracy: 0.2589\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7188 - accuracy: 0.5171 - val_loss: 0.7378 - val_accuracy: 0.2772\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7132 - accuracy: 0.5227 - val_loss: 0.7335 - val_accuracy: 0.2913\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7103 - accuracy: 0.5266 - val_loss: 0.7298 - val_accuracy: 0.3078\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7085 - accuracy: 0.5287 - val_loss: 0.7271 - val_accuracy: 0.3212\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7047 - accuracy: 0.5345 - val_loss: 0.7250 - val_accuracy: 0.3405\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.5344 - val_loss: 0.7224 - val_accuracy: 0.3586\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7005 - accuracy: 0.5420 - val_loss: 0.7208 - val_accuracy: 0.3713\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5446 - val_loss: 0.7181 - val_accuracy: 0.3865\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6969 - accuracy: 0.5494 - val_loss: 0.7164 - val_accuracy: 0.4030\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6954 - accuracy: 0.5490 - val_loss: 0.7147 - val_accuracy: 0.4184\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6937 - accuracy: 0.5521 - val_loss: 0.7130 - val_accuracy: 0.4308\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6914 - accuracy: 0.5617 - val_loss: 0.7110 - val_accuracy: 0.4472\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5630 - val_loss: 0.7097 - val_accuracy: 0.4580\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6881 - accuracy: 0.5628 - val_loss: 0.7082 - val_accuracy: 0.4660\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5723 - val_loss: 0.7064 - val_accuracy: 0.4757\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6820 - accuracy: 0.5749 - val_loss: 0.7046 - val_accuracy: 0.4829\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6828 - accuracy: 0.5723 - val_loss: 0.7033 - val_accuracy: 0.4882\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6808 - accuracy: 0.5766 - val_loss: 0.7032 - val_accuracy: 0.4921\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6778 - accuracy: 0.5826 - val_loss: 0.7025 - val_accuracy: 0.4974\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5867 - val_loss: 0.6992 - val_accuracy: 0.5099\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6738 - accuracy: 0.5912 - val_loss: 0.6984 - val_accuracy: 0.5142\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6729 - accuracy: 0.5935 - val_loss: 0.6968 - val_accuracy: 0.5193\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6722 - accuracy: 0.5959 - val_loss: 0.6961 - val_accuracy: 0.5213\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6715 - accuracy: 0.5946 - val_loss: 0.6939 - val_accuracy: 0.5274\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.6015 - val_loss: 0.6918 - val_accuracy: 0.5331\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.6053 - val_loss: 0.6910 - val_accuracy: 0.5354\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6669 - accuracy: 0.6051 - val_loss: 0.6897 - val_accuracy: 0.5381\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6656 - accuracy: 0.6075 - val_loss: 0.6891 - val_accuracy: 0.5395\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.6109 - val_loss: 0.6876 - val_accuracy: 0.5426\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6624 - accuracy: 0.6152 - val_loss: 0.6878 - val_accuracy: 0.5437\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6609 - accuracy: 0.6184 - val_loss: 0.6859 - val_accuracy: 0.5486\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.6171 - val_loss: 0.6843 - val_accuracy: 0.5538\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6608 - accuracy: 0.6174 - val_loss: 0.6845 - val_accuracy: 0.5545\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6587 - accuracy: 0.6247 - val_loss: 0.6834 - val_accuracy: 0.5582\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6577 - accuracy: 0.6258 - val_loss: 0.6818 - val_accuracy: 0.5611\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6279 - val_loss: 0.6806 - val_accuracy: 0.5641\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6557 - accuracy: 0.6288 - val_loss: 0.6806 - val_accuracy: 0.5643\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6539 - accuracy: 0.6323 - val_loss: 0.6795 - val_accuracy: 0.5667\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6527 - accuracy: 0.6348 - val_loss: 0.6783 - val_accuracy: 0.5695\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6513 - accuracy: 0.6366 - val_loss: 0.6791 - val_accuracy: 0.5683\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6507 - accuracy: 0.6391 - val_loss: 0.6772 - val_accuracy: 0.5723\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6508 - accuracy: 0.6391 - val_loss: 0.6767 - val_accuracy: 0.5738\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6493 - accuracy: 0.6405 - val_loss: 0.6755 - val_accuracy: 0.5762\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6489 - accuracy: 0.6417 - val_loss: 0.6748 - val_accuracy: 0.5776\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6469 - accuracy: 0.6463 - val_loss: 0.6734 - val_accuracy: 0.5800\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6468 - accuracy: 0.6466 - val_loss: 0.6725 - val_accuracy: 0.5828\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6462 - accuracy: 0.6438 - val_loss: 0.6720 - val_accuracy: 0.5832\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6445 - accuracy: 0.6485 - val_loss: 0.6721 - val_accuracy: 0.5842\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7403 - accuracy: 0.4924 - val_loss: 0.5870 - val_accuracy: 0.8773\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7150 - accuracy: 0.5058 - val_loss: 0.6340 - val_accuracy: 0.8620\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7046 - accuracy: 0.5176 - val_loss: 0.6626 - val_accuracy: 0.7810\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7015 - accuracy: 0.5204 - val_loss: 0.6792 - val_accuracy: 0.6150\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6992 - accuracy: 0.5218 - val_loss: 0.6893 - val_accuracy: 0.5020\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6978 - accuracy: 0.5249 - val_loss: 0.6947 - val_accuracy: 0.4555\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6960 - accuracy: 0.5287 - val_loss: 0.6979 - val_accuracy: 0.4170\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.5291 - val_loss: 0.6990 - val_accuracy: 0.4107\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6935 - accuracy: 0.5338 - val_loss: 0.6997 - val_accuracy: 0.4103\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6920 - accuracy: 0.5357 - val_loss: 0.7004 - val_accuracy: 0.4107\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5366 - val_loss: 0.6995 - val_accuracy: 0.4253\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6902 - accuracy: 0.5383 - val_loss: 0.6990 - val_accuracy: 0.4353\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5449 - val_loss: 0.6985 - val_accuracy: 0.4442\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6885 - accuracy: 0.5441 - val_loss: 0.6978 - val_accuracy: 0.4528\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5494 - val_loss: 0.6966 - val_accuracy: 0.4650\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6831 - accuracy: 0.5525 - val_loss: 0.6960 - val_accuracy: 0.4731\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5501 - val_loss: 0.6955 - val_accuracy: 0.4808\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6835 - accuracy: 0.5555 - val_loss: 0.6942 - val_accuracy: 0.4929\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6833 - accuracy: 0.5550 - val_loss: 0.6938 - val_accuracy: 0.4986\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6817 - accuracy: 0.5581 - val_loss: 0.6933 - val_accuracy: 0.5046\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6817 - accuracy: 0.5572 - val_loss: 0.6929 - val_accuracy: 0.5077\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6800 - accuracy: 0.5643 - val_loss: 0.6914 - val_accuracy: 0.5159\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6794 - accuracy: 0.5666 - val_loss: 0.6917 - val_accuracy: 0.5164\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6783 - accuracy: 0.5684 - val_loss: 0.6907 - val_accuracy: 0.5236\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5739 - val_loss: 0.6899 - val_accuracy: 0.5298\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6775 - accuracy: 0.5738 - val_loss: 0.6893 - val_accuracy: 0.5330\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6744 - accuracy: 0.5800 - val_loss: 0.6890 - val_accuracy: 0.5362\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6746 - accuracy: 0.5787 - val_loss: 0.6883 - val_accuracy: 0.5406\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.5837 - val_loss: 0.6878 - val_accuracy: 0.5438\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6731 - accuracy: 0.5842 - val_loss: 0.6870 - val_accuracy: 0.5487\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6727 - accuracy: 0.5856 - val_loss: 0.6862 - val_accuracy: 0.5521\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6717 - accuracy: 0.5863 - val_loss: 0.6853 - val_accuracy: 0.5578\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6717 - accuracy: 0.5894 - val_loss: 0.6846 - val_accuracy: 0.5613\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6706 - accuracy: 0.5912 - val_loss: 0.6841 - val_accuracy: 0.5635\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6696 - accuracy: 0.5939 - val_loss: 0.6834 - val_accuracy: 0.5659\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.5978 - val_loss: 0.6820 - val_accuracy: 0.5716\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6674 - accuracy: 0.5988 - val_loss: 0.6816 - val_accuracy: 0.5722\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6663 - accuracy: 0.6034 - val_loss: 0.6812 - val_accuracy: 0.5733\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6672 - accuracy: 0.5998 - val_loss: 0.6805 - val_accuracy: 0.5770\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6650 - accuracy: 0.6065 - val_loss: 0.6794 - val_accuracy: 0.5809\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6652 - accuracy: 0.6061 - val_loss: 0.6787 - val_accuracy: 0.5837\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.6106 - val_loss: 0.6776 - val_accuracy: 0.5870\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6628 - accuracy: 0.6100 - val_loss: 0.6765 - val_accuracy: 0.5914\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6620 - accuracy: 0.6116 - val_loss: 0.6757 - val_accuracy: 0.5936\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6616 - accuracy: 0.6135 - val_loss: 0.6749 - val_accuracy: 0.5962\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6601 - accuracy: 0.6170 - val_loss: 0.6744 - val_accuracy: 0.5969\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6186 - val_loss: 0.6733 - val_accuracy: 0.5998\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6585 - accuracy: 0.6198 - val_loss: 0.6717 - val_accuracy: 0.6046\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6238 - val_loss: 0.6709 - val_accuracy: 0.6063\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6278 - val_loss: 0.6702 - val_accuracy: 0.6069\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7528 - accuracy: 0.4729 - val_loss: 0.6166 - val_accuracy: 0.7711\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7276 - accuracy: 0.4765 - val_loss: 0.6663 - val_accuracy: 0.6337\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7184 - accuracy: 0.4865 - val_loss: 0.6908 - val_accuracy: 0.5474\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7146 - accuracy: 0.4945 - val_loss: 0.7023 - val_accuracy: 0.5197\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.4980 - val_loss: 0.7065 - val_accuracy: 0.4996\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7095 - accuracy: 0.5011 - val_loss: 0.7080 - val_accuracy: 0.4814\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7061 - accuracy: 0.5075 - val_loss: 0.7072 - val_accuracy: 0.4769\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5135 - val_loss: 0.7062 - val_accuracy: 0.4748\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.5166 - val_loss: 0.7061 - val_accuracy: 0.4672\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7006 - accuracy: 0.5183 - val_loss: 0.7045 - val_accuracy: 0.4677\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.5190 - val_loss: 0.7035 - val_accuracy: 0.4673\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.5202 - val_loss: 0.7019 - val_accuracy: 0.4736\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6954 - accuracy: 0.5295 - val_loss: 0.7008 - val_accuracy: 0.4769\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6944 - accuracy: 0.5303 - val_loss: 0.7007 - val_accuracy: 0.4733\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6920 - accuracy: 0.5372 - val_loss: 0.6994 - val_accuracy: 0.4744\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5354 - val_loss: 0.6983 - val_accuracy: 0.4767\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6904 - accuracy: 0.5405 - val_loss: 0.6972 - val_accuracy: 0.4793\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5407 - val_loss: 0.6963 - val_accuracy: 0.4798\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5432 - val_loss: 0.6948 - val_accuracy: 0.4825\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5479 - val_loss: 0.6933 - val_accuracy: 0.4863\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5480 - val_loss: 0.6926 - val_accuracy: 0.4876\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5555 - val_loss: 0.6920 - val_accuracy: 0.4893\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5592 - val_loss: 0.6912 - val_accuracy: 0.4914\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5631 - val_loss: 0.6906 - val_accuracy: 0.4952\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5593 - val_loss: 0.6900 - val_accuracy: 0.4995\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5661 - val_loss: 0.6888 - val_accuracy: 0.5059\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5678 - val_loss: 0.6883 - val_accuracy: 0.5090\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6787 - accuracy: 0.5670 - val_loss: 0.6874 - val_accuracy: 0.5137\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6777 - accuracy: 0.5716 - val_loss: 0.6856 - val_accuracy: 0.5243\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6771 - accuracy: 0.5737 - val_loss: 0.6847 - val_accuracy: 0.5266\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.5777 - val_loss: 0.6844 - val_accuracy: 0.5273\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6750 - accuracy: 0.5778 - val_loss: 0.6837 - val_accuracy: 0.5291\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.5847 - val_loss: 0.6836 - val_accuracy: 0.5301\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6723 - accuracy: 0.5847 - val_loss: 0.6825 - val_accuracy: 0.5339\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.5894 - val_loss: 0.6815 - val_accuracy: 0.5371\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6702 - accuracy: 0.5903 - val_loss: 0.6809 - val_accuracy: 0.5390\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.5919 - val_loss: 0.6803 - val_accuracy: 0.5405\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.5931 - val_loss: 0.6793 - val_accuracy: 0.5432\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.5964 - val_loss: 0.6785 - val_accuracy: 0.5452\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5975 - val_loss: 0.6774 - val_accuracy: 0.5476\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6016 - val_loss: 0.6768 - val_accuracy: 0.5479\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.6043 - val_loss: 0.6758 - val_accuracy: 0.5504\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.6053 - val_loss: 0.6755 - val_accuracy: 0.5507\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.6045 - val_loss: 0.6748 - val_accuracy: 0.5508\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.6102 - val_loss: 0.6738 - val_accuracy: 0.5529\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6625 - accuracy: 0.6104 - val_loss: 0.6732 - val_accuracy: 0.5550\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6612 - accuracy: 0.6128 - val_loss: 0.6726 - val_accuracy: 0.5570\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6605 - accuracy: 0.6134 - val_loss: 0.6723 - val_accuracy: 0.5583\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6136 - val_loss: 0.6715 - val_accuracy: 0.5603\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6211 - val_loss: 0.6711 - val_accuracy: 0.5616\n",
      "Epoch 1/50\n",
      "  1/418 [..............................] - ETA: 0s - loss: 0.7179 - accuracy: 0.4688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0011s). Check your callbacks.\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.5165 - val_loss: 0.7723 - val_accuracy: 0.2341\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5201 - val_loss: 0.7411 - val_accuracy: 0.2988\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.5258 - val_loss: 0.7252 - val_accuracy: 0.3591\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6940 - accuracy: 0.5292 - val_loss: 0.7171 - val_accuracy: 0.3975\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6904 - accuracy: 0.5385 - val_loss: 0.7120 - val_accuracy: 0.4284\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5358 - val_loss: 0.7087 - val_accuracy: 0.4497\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5391 - val_loss: 0.7073 - val_accuracy: 0.4600\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5431 - val_loss: 0.7059 - val_accuracy: 0.4698\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5481 - val_loss: 0.7036 - val_accuracy: 0.4789\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5528 - val_loss: 0.7021 - val_accuracy: 0.4848\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5581 - val_loss: 0.7016 - val_accuracy: 0.4901\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5613 - val_loss: 0.7002 - val_accuracy: 0.4984\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5630 - val_loss: 0.6980 - val_accuracy: 0.5069\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5646 - val_loss: 0.6975 - val_accuracy: 0.5081\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5689 - val_loss: 0.6957 - val_accuracy: 0.5141\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6764 - accuracy: 0.5758 - val_loss: 0.6952 - val_accuracy: 0.5165\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.5748 - val_loss: 0.6935 - val_accuracy: 0.5208\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5769 - val_loss: 0.6930 - val_accuracy: 0.5248\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.5841 - val_loss: 0.6923 - val_accuracy: 0.5317\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.5833 - val_loss: 0.6904 - val_accuracy: 0.5437\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.5895 - val_loss: 0.6891 - val_accuracy: 0.5513\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 997us/step - loss: 0.6699 - accuracy: 0.5907 - val_loss: 0.6877 - val_accuracy: 0.5587\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.5952 - val_loss: 0.6874 - val_accuracy: 0.5610\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5991 - val_loss: 0.6857 - val_accuracy: 0.5661\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.6038 - val_loss: 0.6845 - val_accuracy: 0.5699\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.6008 - val_loss: 0.6828 - val_accuracy: 0.5766\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.6063 - val_loss: 0.6820 - val_accuracy: 0.5802\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6100 - val_loss: 0.6802 - val_accuracy: 0.5862\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6102 - val_loss: 0.6800 - val_accuracy: 0.5872\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.6146 - val_loss: 0.6782 - val_accuracy: 0.5938\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6183 - val_loss: 0.6766 - val_accuracy: 0.5973\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6575 - accuracy: 0.6189 - val_loss: 0.6757 - val_accuracy: 0.5992\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6565 - accuracy: 0.6202 - val_loss: 0.6743 - val_accuracy: 0.6010\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6264 - val_loss: 0.6731 - val_accuracy: 0.6017\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6540 - accuracy: 0.6271 - val_loss: 0.6725 - val_accuracy: 0.6029\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6286 - val_loss: 0.6718 - val_accuracy: 0.6033\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6511 - accuracy: 0.6331 - val_loss: 0.6707 - val_accuracy: 0.6048\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6324 - val_loss: 0.6698 - val_accuracy: 0.6059\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6362 - val_loss: 0.6680 - val_accuracy: 0.6069\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6480 - accuracy: 0.6396 - val_loss: 0.6669 - val_accuracy: 0.6080\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6397 - val_loss: 0.6666 - val_accuracy: 0.6078\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6375 - val_loss: 0.6659 - val_accuracy: 0.6083\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6447 - accuracy: 0.6424 - val_loss: 0.6647 - val_accuracy: 0.6092\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6447 - accuracy: 0.6436 - val_loss: 0.6636 - val_accuracy: 0.6107\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6482 - val_loss: 0.6632 - val_accuracy: 0.6111\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.6432 - accuracy: 0.6442 - val_loss: 0.6614 - val_accuracy: 0.6133\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6418 - accuracy: 0.6476 - val_loss: 0.6610 - val_accuracy: 0.6134\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6415 - accuracy: 0.6481 - val_loss: 0.6595 - val_accuracy: 0.6147\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6538 - val_loss: 0.6586 - val_accuracy: 0.6156\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6562 - val_loss: 0.6579 - val_accuracy: 0.6156\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6951 - accuracy: 0.5554 - val_loss: 0.7295 - val_accuracy: 0.3438\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5618 - val_loss: 0.7180 - val_accuracy: 0.4095\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6907 - accuracy: 0.5604 - val_loss: 0.7116 - val_accuracy: 0.4477\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5717 - val_loss: 0.7073 - val_accuracy: 0.4731\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5715 - val_loss: 0.7053 - val_accuracy: 0.4845\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5736 - val_loss: 0.7034 - val_accuracy: 0.4940\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5781 - val_loss: 0.7011 - val_accuracy: 0.5014\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6803 - accuracy: 0.5803 - val_loss: 0.7000 - val_accuracy: 0.5055\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5863 - val_loss: 0.6989 - val_accuracy: 0.5075\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.5882 - val_loss: 0.6970 - val_accuracy: 0.5103\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.5886 - val_loss: 0.6964 - val_accuracy: 0.5112\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.5953 - val_loss: 0.6959 - val_accuracy: 0.5137\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5929 - val_loss: 0.6943 - val_accuracy: 0.5181\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.5963 - val_loss: 0.6936 - val_accuracy: 0.5193\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5988 - val_loss: 0.6931 - val_accuracy: 0.5201\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.6025 - val_loss: 0.6910 - val_accuracy: 0.5248\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.6026 - val_loss: 0.6904 - val_accuracy: 0.5258\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.6061 - val_loss: 0.6899 - val_accuracy: 0.5270\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.6109 - val_loss: 0.6876 - val_accuracy: 0.5318\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6655 - accuracy: 0.6084 - val_loss: 0.6872 - val_accuracy: 0.5321\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.6106 - val_loss: 0.6870 - val_accuracy: 0.5323\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6634 - accuracy: 0.6114 - val_loss: 0.6863 - val_accuracy: 0.5331\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.6158 - val_loss: 0.6849 - val_accuracy: 0.5350\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6163 - val_loss: 0.6844 - val_accuracy: 0.5359\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6187 - val_loss: 0.6838 - val_accuracy: 0.5369\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6203 - val_loss: 0.6835 - val_accuracy: 0.5370\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6588 - accuracy: 0.6209 - val_loss: 0.6823 - val_accuracy: 0.5386\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6193 - val_loss: 0.6816 - val_accuracy: 0.5395\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6567 - accuracy: 0.6245 - val_loss: 0.6801 - val_accuracy: 0.5422\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6265 - val_loss: 0.6804 - val_accuracy: 0.5415\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6265 - val_loss: 0.6801 - val_accuracy: 0.5416\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6288 - val_loss: 0.6790 - val_accuracy: 0.5447\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6291 - val_loss: 0.6784 - val_accuracy: 0.5465\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6523 - accuracy: 0.6338 - val_loss: 0.6774 - val_accuracy: 0.5486\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6324 - val_loss: 0.6768 - val_accuracy: 0.5490\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6362 - val_loss: 0.6756 - val_accuracy: 0.5514\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6383 - val_loss: 0.6751 - val_accuracy: 0.5526\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6384 - val_loss: 0.6743 - val_accuracy: 0.5539\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6386 - val_loss: 0.6736 - val_accuracy: 0.5549\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6477 - accuracy: 0.6399 - val_loss: 0.6732 - val_accuracy: 0.5563\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6428 - val_loss: 0.6727 - val_accuracy: 0.5570\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.6422 - val_loss: 0.6716 - val_accuracy: 0.5592\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6450 - val_loss: 0.6699 - val_accuracy: 0.5623\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6444 - accuracy: 0.6461 - val_loss: 0.6697 - val_accuracy: 0.5631\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6468 - val_loss: 0.6707 - val_accuracy: 0.5615\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6434 - accuracy: 0.6468 - val_loss: 0.6695 - val_accuracy: 0.5631\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.6438 - val_loss: 0.6689 - val_accuracy: 0.5641\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6491 - val_loss: 0.6683 - val_accuracy: 0.5652\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.6480 - val_loss: 0.6686 - val_accuracy: 0.5644\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6493 - val_loss: 0.6673 - val_accuracy: 0.5665\n",
      "Epoch 1/50\n",
      "  1/418 [..............................] - ETA: 0s - loss: 0.7013 - accuracy: 0.4766WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.5105 - val_loss: 0.6957 - val_accuracy: 0.5198\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 980us/step - loss: 0.6985 - accuracy: 0.5158 - val_loss: 0.6970 - val_accuracy: 0.5175\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6987 - accuracy: 0.5204 - val_loss: 0.6983 - val_accuracy: 0.5085\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.5222 - val_loss: 0.6973 - val_accuracy: 0.5097\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6960 - accuracy: 0.5247 - val_loss: 0.6968 - val_accuracy: 0.5085\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6920 - accuracy: 0.5316 - val_loss: 0.6963 - val_accuracy: 0.5051\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5317 - val_loss: 0.6951 - val_accuracy: 0.5112\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6896 - accuracy: 0.5391 - val_loss: 0.6945 - val_accuracy: 0.5089\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6883 - accuracy: 0.5412 - val_loss: 0.6935 - val_accuracy: 0.5089\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5476 - val_loss: 0.6924 - val_accuracy: 0.5086\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5479 - val_loss: 0.6911 - val_accuracy: 0.5093\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5508 - val_loss: 0.6895 - val_accuracy: 0.5159\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5580 - val_loss: 0.6887 - val_accuracy: 0.5164\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5590 - val_loss: 0.6873 - val_accuracy: 0.5231\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6808 - accuracy: 0.5649 - val_loss: 0.6869 - val_accuracy: 0.5212\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6797 - accuracy: 0.5647 - val_loss: 0.6858 - val_accuracy: 0.5237\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5653 - val_loss: 0.6852 - val_accuracy: 0.5235\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5699 - val_loss: 0.6844 - val_accuracy: 0.5253\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.5703 - val_loss: 0.6838 - val_accuracy: 0.5257\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 982us/step - loss: 0.6759 - accuracy: 0.5719 - val_loss: 0.6824 - val_accuracy: 0.5311\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.5797 - val_loss: 0.6817 - val_accuracy: 0.5336\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.5806 - val_loss: 0.6808 - val_accuracy: 0.5369\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 985us/step - loss: 0.6722 - accuracy: 0.5854 - val_loss: 0.6798 - val_accuracy: 0.5414\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5858 - val_loss: 0.6793 - val_accuracy: 0.5427\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6697 - accuracy: 0.5868 - val_loss: 0.6783 - val_accuracy: 0.5469\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6698 - accuracy: 0.5884 - val_loss: 0.6779 - val_accuracy: 0.5476\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5917 - val_loss: 0.6764 - val_accuracy: 0.5534\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6675 - accuracy: 0.5950 - val_loss: 0.6756 - val_accuracy: 0.5557\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.5949 - val_loss: 0.6750 - val_accuracy: 0.5569\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.5998 - val_loss: 0.6740 - val_accuracy: 0.5594\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6642 - accuracy: 0.6010 - val_loss: 0.6733 - val_accuracy: 0.5604\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.6044 - val_loss: 0.6732 - val_accuracy: 0.5590\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.6043 - val_loss: 0.6722 - val_accuracy: 0.5636\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6040 - val_loss: 0.6709 - val_accuracy: 0.5683\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6066 - val_loss: 0.6703 - val_accuracy: 0.5698\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6115 - val_loss: 0.6699 - val_accuracy: 0.5702\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6591 - accuracy: 0.6125 - val_loss: 0.6688 - val_accuracy: 0.5726\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 979us/step - loss: 0.6583 - accuracy: 0.6134 - val_loss: 0.6678 - val_accuracy: 0.5750\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6172 - val_loss: 0.6675 - val_accuracy: 0.5750\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6571 - accuracy: 0.6157 - val_loss: 0.6665 - val_accuracy: 0.5774\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6550 - accuracy: 0.6209 - val_loss: 0.6654 - val_accuracy: 0.5799\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6552 - accuracy: 0.6192 - val_loss: 0.6646 - val_accuracy: 0.5808\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6534 - accuracy: 0.6244 - val_loss: 0.6643 - val_accuracy: 0.5808\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6522 - accuracy: 0.6253 - val_loss: 0.6639 - val_accuracy: 0.5810\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6520 - accuracy: 0.6226 - val_loss: 0.6637 - val_accuracy: 0.5808\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6512 - accuracy: 0.6269 - val_loss: 0.6627 - val_accuracy: 0.5827\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6509 - accuracy: 0.6261 - val_loss: 0.6621 - val_accuracy: 0.5834\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6500 - accuracy: 0.6264 - val_loss: 0.6611 - val_accuracy: 0.5856\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6336 - val_loss: 0.6605 - val_accuracy: 0.5872\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6469 - accuracy: 0.6349 - val_loss: 0.6596 - val_accuracy: 0.5891\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7419 - accuracy: 0.5198 - val_loss: 0.9325 - val_accuracy: 0.1439\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.5256 - val_loss: 0.8478 - val_accuracy: 0.1856\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6998 - accuracy: 0.5340 - val_loss: 0.7939 - val_accuracy: 0.2700\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6924 - accuracy: 0.5398 - val_loss: 0.7600 - val_accuracy: 0.3363\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5434 - val_loss: 0.7377 - val_accuracy: 0.4085\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5524 - val_loss: 0.7231 - val_accuracy: 0.4452\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5547 - val_loss: 0.7132 - val_accuracy: 0.4759\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5584 - val_loss: 0.7058 - val_accuracy: 0.5061\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6791 - accuracy: 0.5617 - val_loss: 0.7006 - val_accuracy: 0.5186\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6779 - accuracy: 0.5678 - val_loss: 0.6973 - val_accuracy: 0.5270\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6763 - accuracy: 0.5679 - val_loss: 0.6944 - val_accuracy: 0.5326\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6754 - accuracy: 0.5735 - val_loss: 0.6920 - val_accuracy: 0.5383\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6731 - accuracy: 0.5775 - val_loss: 0.6900 - val_accuracy: 0.5442\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6708 - accuracy: 0.5815 - val_loss: 0.6881 - val_accuracy: 0.5495\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.5840 - val_loss: 0.6870 - val_accuracy: 0.5534\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6692 - accuracy: 0.5867 - val_loss: 0.6860 - val_accuracy: 0.5563\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6677 - accuracy: 0.5889 - val_loss: 0.6848 - val_accuracy: 0.5600\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.5925 - val_loss: 0.6837 - val_accuracy: 0.5629\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6656 - accuracy: 0.5922 - val_loss: 0.6828 - val_accuracy: 0.5663\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.5956 - val_loss: 0.6815 - val_accuracy: 0.5685\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6631 - accuracy: 0.5971 - val_loss: 0.6801 - val_accuracy: 0.5712\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6622 - accuracy: 0.5972 - val_loss: 0.6784 - val_accuracy: 0.5748\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6036 - val_loss: 0.6774 - val_accuracy: 0.5757\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6589 - accuracy: 0.6051 - val_loss: 0.6765 - val_accuracy: 0.5780\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6584 - accuracy: 0.6060 - val_loss: 0.6749 - val_accuracy: 0.5807\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6565 - accuracy: 0.6077 - val_loss: 0.6737 - val_accuracy: 0.5831\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6556 - accuracy: 0.6092 - val_loss: 0.6727 - val_accuracy: 0.5852\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6136 - val_loss: 0.6717 - val_accuracy: 0.5868\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6532 - accuracy: 0.6154 - val_loss: 0.6708 - val_accuracy: 0.5874\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6529 - accuracy: 0.6155 - val_loss: 0.6699 - val_accuracy: 0.5891\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6518 - accuracy: 0.6164 - val_loss: 0.6691 - val_accuracy: 0.5903\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6197 - val_loss: 0.6688 - val_accuracy: 0.5906\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6173 - val_loss: 0.6675 - val_accuracy: 0.5922\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6480 - accuracy: 0.6242 - val_loss: 0.6667 - val_accuracy: 0.5932\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6213 - val_loss: 0.6658 - val_accuracy: 0.5934\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6465 - accuracy: 0.6253 - val_loss: 0.6653 - val_accuracy: 0.5943\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6445 - accuracy: 0.6276 - val_loss: 0.6642 - val_accuracy: 0.5949\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6449 - accuracy: 0.6276 - val_loss: 0.6634 - val_accuracy: 0.5956\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6438 - accuracy: 0.6292 - val_loss: 0.6631 - val_accuracy: 0.5948\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6433 - accuracy: 0.6292 - val_loss: 0.6624 - val_accuracy: 0.5953\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6431 - accuracy: 0.6295 - val_loss: 0.6618 - val_accuracy: 0.5957\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6318 - val_loss: 0.6613 - val_accuracy: 0.5962\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6399 - accuracy: 0.6352 - val_loss: 0.6604 - val_accuracy: 0.5965\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.6345 - val_loss: 0.6593 - val_accuracy: 0.5984\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6392 - accuracy: 0.6353 - val_loss: 0.6592 - val_accuracy: 0.5986\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6379 - accuracy: 0.6385 - val_loss: 0.6581 - val_accuracy: 0.5998\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6368 - accuracy: 0.6378 - val_loss: 0.6569 - val_accuracy: 0.6017\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6357 - accuracy: 0.6411 - val_loss: 0.6568 - val_accuracy: 0.6011\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6355 - accuracy: 0.6400 - val_loss: 0.6567 - val_accuracy: 0.6013\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6350 - accuracy: 0.6393 - val_loss: 0.6559 - val_accuracy: 0.6018\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5484 - val_loss: 0.7646 - val_accuracy: 0.1821\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5512 - val_loss: 0.7352 - val_accuracy: 0.2933\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6836 - accuracy: 0.5623 - val_loss: 0.7203 - val_accuracy: 0.3751\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6837 - accuracy: 0.5651 - val_loss: 0.7102 - val_accuracy: 0.4317\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6825 - accuracy: 0.5661 - val_loss: 0.7036 - val_accuracy: 0.4763\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5699 - val_loss: 0.7005 - val_accuracy: 0.4943\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6805 - accuracy: 0.5722 - val_loss: 0.6981 - val_accuracy: 0.5070\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6789 - accuracy: 0.5745 - val_loss: 0.6970 - val_accuracy: 0.5128\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5804 - val_loss: 0.6948 - val_accuracy: 0.5264\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5812 - val_loss: 0.6943 - val_accuracy: 0.5309\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6762 - accuracy: 0.5834 - val_loss: 0.6929 - val_accuracy: 0.5383\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6756 - accuracy: 0.5850 - val_loss: 0.6922 - val_accuracy: 0.5426\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6751 - accuracy: 0.5855 - val_loss: 0.6911 - val_accuracy: 0.5483\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.5912 - val_loss: 0.6906 - val_accuracy: 0.5508\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.5928 - val_loss: 0.6899 - val_accuracy: 0.5545\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6710 - accuracy: 0.5953 - val_loss: 0.6892 - val_accuracy: 0.5588\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6717 - accuracy: 0.5947 - val_loss: 0.6888 - val_accuracy: 0.5612\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6703 - accuracy: 0.5986 - val_loss: 0.6876 - val_accuracy: 0.5672\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.6039 - val_loss: 0.6869 - val_accuracy: 0.5702\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6689 - accuracy: 0.6015 - val_loss: 0.6864 - val_accuracy: 0.5733\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6682 - accuracy: 0.6049 - val_loss: 0.6854 - val_accuracy: 0.5776\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6672 - accuracy: 0.6071 - val_loss: 0.6851 - val_accuracy: 0.5788\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.6106 - val_loss: 0.6851 - val_accuracy: 0.5782\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6659 - accuracy: 0.6083 - val_loss: 0.6845 - val_accuracy: 0.5811\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6651 - accuracy: 0.6129 - val_loss: 0.6825 - val_accuracy: 0.5886\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6152 - val_loss: 0.6815 - val_accuracy: 0.5921\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6624 - accuracy: 0.6196 - val_loss: 0.6814 - val_accuracy: 0.5922\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6624 - accuracy: 0.6171 - val_loss: 0.6809 - val_accuracy: 0.5931\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6190 - val_loss: 0.6807 - val_accuracy: 0.5935\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6615 - accuracy: 0.6194 - val_loss: 0.6796 - val_accuracy: 0.5958\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6614 - accuracy: 0.6229 - val_loss: 0.6789 - val_accuracy: 0.5977\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6591 - accuracy: 0.6266 - val_loss: 0.6778 - val_accuracy: 0.5998\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6583 - accuracy: 0.6269 - val_loss: 0.6775 - val_accuracy: 0.6001\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6585 - accuracy: 0.6290 - val_loss: 0.6771 - val_accuracy: 0.6006\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6573 - accuracy: 0.6289 - val_loss: 0.6764 - val_accuracy: 0.6016\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6329 - val_loss: 0.6763 - val_accuracy: 0.6010\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6565 - accuracy: 0.6314 - val_loss: 0.6765 - val_accuracy: 0.6002\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6339 - val_loss: 0.6759 - val_accuracy: 0.6022\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6331 - val_loss: 0.6745 - val_accuracy: 0.6047\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6536 - accuracy: 0.6379 - val_loss: 0.6738 - val_accuracy: 0.6056\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6535 - accuracy: 0.6368 - val_loss: 0.6732 - val_accuracy: 0.6070\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6524 - accuracy: 0.6388 - val_loss: 0.6730 - val_accuracy: 0.6071\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6393 - val_loss: 0.6726 - val_accuracy: 0.6070\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6506 - accuracy: 0.6425 - val_loss: 0.6718 - val_accuracy: 0.6084\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6492 - accuracy: 0.6442 - val_loss: 0.6703 - val_accuracy: 0.6121\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6427 - val_loss: 0.6691 - val_accuracy: 0.6151\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6491 - accuracy: 0.6424 - val_loss: 0.6689 - val_accuracy: 0.6150\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6495 - accuracy: 0.6432 - val_loss: 0.6684 - val_accuracy: 0.6166\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6463 - val_loss: 0.6680 - val_accuracy: 0.6174\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6475 - accuracy: 0.6467 - val_loss: 0.6678 - val_accuracy: 0.6175\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7037 - accuracy: 0.5171 - val_loss: 0.6919 - val_accuracy: 0.4918\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6996 - accuracy: 0.5229 - val_loss: 0.7020 - val_accuracy: 0.4492\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6966 - accuracy: 0.5319 - val_loss: 0.7059 - val_accuracy: 0.4423\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6928 - accuracy: 0.5428 - val_loss: 0.7077 - val_accuracy: 0.4401\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6902 - accuracy: 0.5463 - val_loss: 0.7071 - val_accuracy: 0.4434\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6878 - accuracy: 0.5532 - val_loss: 0.7048 - val_accuracy: 0.4489\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5583 - val_loss: 0.7031 - val_accuracy: 0.4512\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5622 - val_loss: 0.7009 - val_accuracy: 0.4547\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6834 - accuracy: 0.5641 - val_loss: 0.6986 - val_accuracy: 0.4586\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5703 - val_loss: 0.6974 - val_accuracy: 0.4608\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6781 - accuracy: 0.5735 - val_loss: 0.6953 - val_accuracy: 0.4639\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6779 - accuracy: 0.5731 - val_loss: 0.6938 - val_accuracy: 0.4661\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.5812 - val_loss: 0.6919 - val_accuracy: 0.4698\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6739 - accuracy: 0.5832 - val_loss: 0.6901 - val_accuracy: 0.4732\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6722 - accuracy: 0.5909 - val_loss: 0.6885 - val_accuracy: 0.4790\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6701 - accuracy: 0.5923 - val_loss: 0.6872 - val_accuracy: 0.4841\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6695 - accuracy: 0.5911 - val_loss: 0.6858 - val_accuracy: 0.4903\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6677 - accuracy: 0.5979 - val_loss: 0.6839 - val_accuracy: 0.4954\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6663 - accuracy: 0.5995 - val_loss: 0.6828 - val_accuracy: 0.4995\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6646 - accuracy: 0.6019 - val_loss: 0.6815 - val_accuracy: 0.5032\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6054 - val_loss: 0.6801 - val_accuracy: 0.5068\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6624 - accuracy: 0.6072 - val_loss: 0.6786 - val_accuracy: 0.5110\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6617 - accuracy: 0.6074 - val_loss: 0.6764 - val_accuracy: 0.5166\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6591 - accuracy: 0.6106 - val_loss: 0.6748 - val_accuracy: 0.5223\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6585 - accuracy: 0.6144 - val_loss: 0.6735 - val_accuracy: 0.5265\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6564 - accuracy: 0.6161 - val_loss: 0.6709 - val_accuracy: 0.5339\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6551 - accuracy: 0.6200 - val_loss: 0.6685 - val_accuracy: 0.5393\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6535 - accuracy: 0.6215 - val_loss: 0.6668 - val_accuracy: 0.5453\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6517 - accuracy: 0.6254 - val_loss: 0.6657 - val_accuracy: 0.5480\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6511 - accuracy: 0.6266 - val_loss: 0.6647 - val_accuracy: 0.5513\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6264 - val_loss: 0.6635 - val_accuracy: 0.5546\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6488 - accuracy: 0.6281 - val_loss: 0.6625 - val_accuracy: 0.5580\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6473 - accuracy: 0.6309 - val_loss: 0.6618 - val_accuracy: 0.5595\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6462 - accuracy: 0.6359 - val_loss: 0.6612 - val_accuracy: 0.5614\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6450 - accuracy: 0.6352 - val_loss: 0.6599 - val_accuracy: 0.5647\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6429 - accuracy: 0.6402 - val_loss: 0.6584 - val_accuracy: 0.5684\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6435 - accuracy: 0.6372 - val_loss: 0.6574 - val_accuracy: 0.5697\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6413 - accuracy: 0.6411 - val_loss: 0.6567 - val_accuracy: 0.5703\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6423 - accuracy: 0.6373 - val_loss: 0.6550 - val_accuracy: 0.5745\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6391 - accuracy: 0.6426 - val_loss: 0.6536 - val_accuracy: 0.5761\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6422 - val_loss: 0.6524 - val_accuracy: 0.5787\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6368 - accuracy: 0.6497 - val_loss: 0.6518 - val_accuracy: 0.5796\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6369 - accuracy: 0.6464 - val_loss: 0.6512 - val_accuracy: 0.5808\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6352 - accuracy: 0.6501 - val_loss: 0.6506 - val_accuracy: 0.5826\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6347 - accuracy: 0.6491 - val_loss: 0.6500 - val_accuracy: 0.5847\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.6496 - val_loss: 0.6496 - val_accuracy: 0.5859\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6325 - accuracy: 0.6504 - val_loss: 0.6485 - val_accuracy: 0.5876\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6320 - accuracy: 0.6525 - val_loss: 0.6482 - val_accuracy: 0.5891\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.6562 - val_loss: 0.6469 - val_accuracy: 0.5910\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.6557 - val_loss: 0.6457 - val_accuracy: 0.5933\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.9175 - accuracy: 0.4866 - val_loss: 0.4461 - val_accuracy: 0.8815\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7530 - accuracy: 0.5127 - val_loss: 0.5346 - val_accuracy: 0.8716\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7014 - accuracy: 0.5496 - val_loss: 0.5995 - val_accuracy: 0.8373\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5698 - val_loss: 0.6384 - val_accuracy: 0.7075\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5748 - val_loss: 0.6592 - val_accuracy: 0.6401\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.5820 - val_loss: 0.6696 - val_accuracy: 0.6074\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.5872 - val_loss: 0.6740 - val_accuracy: 0.5913\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6720 - accuracy: 0.5906 - val_loss: 0.6754 - val_accuracy: 0.5873\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6710 - accuracy: 0.5933 - val_loss: 0.6755 - val_accuracy: 0.5872\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.5952 - val_loss: 0.6762 - val_accuracy: 0.5861\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.5993 - val_loss: 0.6768 - val_accuracy: 0.5848\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.6014 - val_loss: 0.6755 - val_accuracy: 0.5882\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6021 - val_loss: 0.6738 - val_accuracy: 0.5932\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.6025 - val_loss: 0.6739 - val_accuracy: 0.5935\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6081 - val_loss: 0.6745 - val_accuracy: 0.5926\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6094 - val_loss: 0.6736 - val_accuracy: 0.5950\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6611 - accuracy: 0.6108 - val_loss: 0.6723 - val_accuracy: 0.5989\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.6122 - val_loss: 0.6713 - val_accuracy: 0.6001\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6563 - accuracy: 0.6154 - val_loss: 0.6700 - val_accuracy: 0.6022\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6186 - val_loss: 0.6697 - val_accuracy: 0.6017\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6549 - accuracy: 0.6189 - val_loss: 0.6691 - val_accuracy: 0.6029\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6221 - val_loss: 0.6687 - val_accuracy: 0.6036\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6533 - accuracy: 0.6210 - val_loss: 0.6678 - val_accuracy: 0.6048\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6517 - accuracy: 0.6244 - val_loss: 0.6683 - val_accuracy: 0.6039\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6245 - val_loss: 0.6669 - val_accuracy: 0.6070\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6227 - val_loss: 0.6658 - val_accuracy: 0.6083\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6494 - accuracy: 0.6280 - val_loss: 0.6659 - val_accuracy: 0.6084\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6314 - val_loss: 0.6652 - val_accuracy: 0.6102\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6310 - val_loss: 0.6642 - val_accuracy: 0.6112\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6319 - val_loss: 0.6633 - val_accuracy: 0.6123\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6347 - val_loss: 0.6633 - val_accuracy: 0.6116\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6434 - accuracy: 0.6346 - val_loss: 0.6628 - val_accuracy: 0.6127\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6379 - val_loss: 0.6620 - val_accuracy: 0.6136\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.6394 - val_loss: 0.6620 - val_accuracy: 0.6132\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6394 - val_loss: 0.6613 - val_accuracy: 0.6143\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6401 - accuracy: 0.6417 - val_loss: 0.6612 - val_accuracy: 0.6140\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6375 - accuracy: 0.6451 - val_loss: 0.6613 - val_accuracy: 0.6136\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6375 - accuracy: 0.6440 - val_loss: 0.6609 - val_accuracy: 0.6145\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6362 - accuracy: 0.6477 - val_loss: 0.6602 - val_accuracy: 0.6155\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.6483 - val_loss: 0.6583 - val_accuracy: 0.6186\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6352 - accuracy: 0.6438 - val_loss: 0.6579 - val_accuracy: 0.6193\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6490 - val_loss: 0.6568 - val_accuracy: 0.6209\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6527 - val_loss: 0.6556 - val_accuracy: 0.6230\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6302 - accuracy: 0.6551 - val_loss: 0.6552 - val_accuracy: 0.6237\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.6538 - val_loss: 0.6554 - val_accuracy: 0.6229\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.6514 - val_loss: 0.6544 - val_accuracy: 0.6238\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6569 - val_loss: 0.6527 - val_accuracy: 0.6266\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6588 - val_loss: 0.6533 - val_accuracy: 0.6250\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6271 - accuracy: 0.6574 - val_loss: 0.6528 - val_accuracy: 0.6258\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6263 - accuracy: 0.6598 - val_loss: 0.6519 - val_accuracy: 0.6267\n",
      "\n",
      "Training model with batch_size=128, target_eps=2.0...\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 5.05 iterated over 20900 steps satisfies differential privacy with eps = 0.337 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 2.5749999999999997 iterated over 20900 steps satisfies differential privacy with eps = 0.684 and delta = 1e-05.\n",
      "The optimal RDP order is 35.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.3375 iterated over 20900 steps satisfies differential privacy with eps = 1.51 and delta = 1e-05.\n",
      "The optimal RDP order is 16.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 0.71875 iterated over 20900 steps satisfies differential privacy with eps = 5.07 and delta = 1e-05.\n",
      "The optimal RDP order is 5.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.028125 iterated over 20900 steps satisfies differential privacy with eps = 2.25 and delta = 1e-05.\n",
      "The optimal RDP order is 11.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.1828124999999998 iterated over 20900 steps satisfies differential privacy with eps = 1.8 and delta = 1e-05.\n",
      "The optimal RDP order is 14.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.10546875 iterated over 20900 steps satisfies differential privacy with eps = 2 and delta = 1e-05.\n",
      "The optimal RDP order is 13.0.\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6912 - accuracy: 0.5330 - val_loss: 0.7411 - val_accuracy: 0.3068\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5415 - val_loss: 0.7256 - val_accuracy: 0.3717\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5454 - val_loss: 0.7169 - val_accuracy: 0.4200\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5507 - val_loss: 0.7123 - val_accuracy: 0.4473\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5510 - val_loss: 0.7092 - val_accuracy: 0.4658\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5567 - val_loss: 0.7065 - val_accuracy: 0.4817\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5661 - val_loss: 0.7051 - val_accuracy: 0.4898\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.5689 - val_loss: 0.7038 - val_accuracy: 0.4961\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6792 - accuracy: 0.5659 - val_loss: 0.7024 - val_accuracy: 0.5004\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6778 - accuracy: 0.5716 - val_loss: 0.7013 - val_accuracy: 0.5055\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5759 - val_loss: 0.7001 - val_accuracy: 0.5111\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.5776 - val_loss: 0.6992 - val_accuracy: 0.5141\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6743 - accuracy: 0.5812 - val_loss: 0.6980 - val_accuracy: 0.5180\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.5849 - val_loss: 0.6975 - val_accuracy: 0.5187\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.5899 - val_loss: 0.6971 - val_accuracy: 0.5183\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6712 - accuracy: 0.5882 - val_loss: 0.6963 - val_accuracy: 0.5196\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5949 - val_loss: 0.6958 - val_accuracy: 0.5200\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5954 - val_loss: 0.6949 - val_accuracy: 0.5226\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6674 - accuracy: 0.5979 - val_loss: 0.6931 - val_accuracy: 0.5294\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6678 - accuracy: 0.5992 - val_loss: 0.6929 - val_accuracy: 0.5280\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6665 - accuracy: 0.5997 - val_loss: 0.6919 - val_accuracy: 0.5302\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6018 - val_loss: 0.6906 - val_accuracy: 0.5347\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6640 - accuracy: 0.6063 - val_loss: 0.6891 - val_accuracy: 0.5379\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.6041 - val_loss: 0.6874 - val_accuracy: 0.5421\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6092 - val_loss: 0.6885 - val_accuracy: 0.5363\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6625 - accuracy: 0.6085 - val_loss: 0.6871 - val_accuracy: 0.5385\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6101 - val_loss: 0.6867 - val_accuracy: 0.5393\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6600 - accuracy: 0.6144 - val_loss: 0.6860 - val_accuracy: 0.5404\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6159 - val_loss: 0.6843 - val_accuracy: 0.5464\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6155 - val_loss: 0.6827 - val_accuracy: 0.5505\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6162 - val_loss: 0.6817 - val_accuracy: 0.5525\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6563 - accuracy: 0.6197 - val_loss: 0.6817 - val_accuracy: 0.5521\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6204 - val_loss: 0.6811 - val_accuracy: 0.5525\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6197 - val_loss: 0.6795 - val_accuracy: 0.5565\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6543 - accuracy: 0.6222 - val_loss: 0.6784 - val_accuracy: 0.5584\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6539 - accuracy: 0.6257 - val_loss: 0.6778 - val_accuracy: 0.5587\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6526 - accuracy: 0.6252 - val_loss: 0.6777 - val_accuracy: 0.5586\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6524 - accuracy: 0.6248 - val_loss: 0.6768 - val_accuracy: 0.5600\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6289 - val_loss: 0.6748 - val_accuracy: 0.5644\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6501 - accuracy: 0.6289 - val_loss: 0.6745 - val_accuracy: 0.5652\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6489 - accuracy: 0.6298 - val_loss: 0.6725 - val_accuracy: 0.5705\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6479 - accuracy: 0.6346 - val_loss: 0.6719 - val_accuracy: 0.5725\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6321 - val_loss: 0.6720 - val_accuracy: 0.5717\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6462 - accuracy: 0.6356 - val_loss: 0.6707 - val_accuracy: 0.5755\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6458 - accuracy: 0.6363 - val_loss: 0.6693 - val_accuracy: 0.5793\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6456 - accuracy: 0.6357 - val_loss: 0.6693 - val_accuracy: 0.5792\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6360 - val_loss: 0.6686 - val_accuracy: 0.5811\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6450 - accuracy: 0.6372 - val_loss: 0.6676 - val_accuracy: 0.5829\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6429 - accuracy: 0.6414 - val_loss: 0.6670 - val_accuracy: 0.5839\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6425 - accuracy: 0.6396 - val_loss: 0.6652 - val_accuracy: 0.5900\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7619 - accuracy: 0.5050 - val_loss: 0.8751 - val_accuracy: 0.1265\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7396 - accuracy: 0.5000 - val_loss: 0.8080 - val_accuracy: 0.1605\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7317 - accuracy: 0.5007 - val_loss: 0.7739 - val_accuracy: 0.2182\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.4997 - val_loss: 0.7577 - val_accuracy: 0.2621\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7223 - accuracy: 0.5045 - val_loss: 0.7476 - val_accuracy: 0.2969\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7209 - accuracy: 0.5053 - val_loss: 0.7416 - val_accuracy: 0.3162\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.5106 - val_loss: 0.7374 - val_accuracy: 0.3385\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7162 - accuracy: 0.5100 - val_loss: 0.7347 - val_accuracy: 0.3504\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.5161 - val_loss: 0.7313 - val_accuracy: 0.3663\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.5167 - val_loss: 0.7285 - val_accuracy: 0.3813\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7092 - accuracy: 0.5228 - val_loss: 0.7270 - val_accuracy: 0.3916\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.5213 - val_loss: 0.7254 - val_accuracy: 0.4029\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7056 - accuracy: 0.5275 - val_loss: 0.7228 - val_accuracy: 0.4147\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7049 - accuracy: 0.5283 - val_loss: 0.7227 - val_accuracy: 0.4192\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7021 - accuracy: 0.5306 - val_loss: 0.7213 - val_accuracy: 0.4275\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7004 - accuracy: 0.5334 - val_loss: 0.7197 - val_accuracy: 0.4358\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.5350 - val_loss: 0.7185 - val_accuracy: 0.4401\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.5410 - val_loss: 0.7166 - val_accuracy: 0.4503\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5420 - val_loss: 0.7164 - val_accuracy: 0.4507\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5461 - val_loss: 0.7152 - val_accuracy: 0.4554\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5458 - val_loss: 0.7148 - val_accuracy: 0.4579\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5506 - val_loss: 0.7139 - val_accuracy: 0.4617\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6900 - accuracy: 0.5538 - val_loss: 0.7120 - val_accuracy: 0.4650\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5532 - val_loss: 0.7097 - val_accuracy: 0.4699\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5555 - val_loss: 0.7088 - val_accuracy: 0.4712\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5575 - val_loss: 0.7081 - val_accuracy: 0.4725\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5561 - val_loss: 0.7077 - val_accuracy: 0.4715\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5615 - val_loss: 0.7066 - val_accuracy: 0.4743\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5615 - val_loss: 0.7053 - val_accuracy: 0.4779\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6830 - accuracy: 0.5650 - val_loss: 0.7041 - val_accuracy: 0.4813\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5644 - val_loss: 0.7038 - val_accuracy: 0.4816\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5734 - val_loss: 0.7027 - val_accuracy: 0.4861\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5698 - val_loss: 0.7017 - val_accuracy: 0.4901\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5737 - val_loss: 0.7012 - val_accuracy: 0.4918\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5774 - val_loss: 0.7002 - val_accuracy: 0.4947\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.5808 - val_loss: 0.6988 - val_accuracy: 0.4997\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5816 - val_loss: 0.6982 - val_accuracy: 0.5029\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6755 - accuracy: 0.5803 - val_loss: 0.6978 - val_accuracy: 0.5033\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6744 - accuracy: 0.5838 - val_loss: 0.6966 - val_accuracy: 0.5074\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6736 - accuracy: 0.5856 - val_loss: 0.6957 - val_accuracy: 0.5111\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.5872 - val_loss: 0.6946 - val_accuracy: 0.5152\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6723 - accuracy: 0.5895 - val_loss: 0.6936 - val_accuracy: 0.5189\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.5911 - val_loss: 0.6922 - val_accuracy: 0.5229\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.5943 - val_loss: 0.6925 - val_accuracy: 0.5233\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.5953 - val_loss: 0.6917 - val_accuracy: 0.5271\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6691 - accuracy: 0.5946 - val_loss: 0.6912 - val_accuracy: 0.5294\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6679 - accuracy: 0.5961 - val_loss: 0.6901 - val_accuracy: 0.5340\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6667 - accuracy: 0.5992 - val_loss: 0.6900 - val_accuracy: 0.5351\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.6007 - val_loss: 0.6883 - val_accuracy: 0.5400\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6658 - accuracy: 0.6020 - val_loss: 0.6867 - val_accuracy: 0.5448\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5207 - val_loss: 0.6791 - val_accuracy: 0.5876\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.5293 - val_loss: 0.7020 - val_accuracy: 0.4612\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.5379 - val_loss: 0.7108 - val_accuracy: 0.4378\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7095 - accuracy: 0.5411 - val_loss: 0.7103 - val_accuracy: 0.4456\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7032 - accuracy: 0.5495 - val_loss: 0.7076 - val_accuracy: 0.4620\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7013 - accuracy: 0.5526 - val_loss: 0.7049 - val_accuracy: 0.4724\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6978 - accuracy: 0.5576 - val_loss: 0.7036 - val_accuracy: 0.4787\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5640 - val_loss: 0.7002 - val_accuracy: 0.4872\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5673 - val_loss: 0.6985 - val_accuracy: 0.4950\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5712 - val_loss: 0.6962 - val_accuracy: 0.5056\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5772 - val_loss: 0.6944 - val_accuracy: 0.5126\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6819 - accuracy: 0.5805 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6793 - accuracy: 0.5818 - val_loss: 0.6911 - val_accuracy: 0.5225\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5850 - val_loss: 0.6919 - val_accuracy: 0.5216\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.5900 - val_loss: 0.6882 - val_accuracy: 0.5298\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.5938 - val_loss: 0.6871 - val_accuracy: 0.5342\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5966 - val_loss: 0.6863 - val_accuracy: 0.5368\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5981 - val_loss: 0.6843 - val_accuracy: 0.5400\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6675 - accuracy: 0.5995 - val_loss: 0.6821 - val_accuracy: 0.5448\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.6040 - val_loss: 0.6810 - val_accuracy: 0.5483\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6633 - accuracy: 0.6063 - val_loss: 0.6795 - val_accuracy: 0.5506\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6647 - accuracy: 0.6018 - val_loss: 0.6793 - val_accuracy: 0.5509\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.6080 - val_loss: 0.6790 - val_accuracy: 0.5508\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6599 - accuracy: 0.6132 - val_loss: 0.6772 - val_accuracy: 0.5544\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6188 - val_loss: 0.6764 - val_accuracy: 0.5557\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6570 - accuracy: 0.6173 - val_loss: 0.6764 - val_accuracy: 0.5555\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6183 - val_loss: 0.6750 - val_accuracy: 0.5574\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6554 - accuracy: 0.6208 - val_loss: 0.6746 - val_accuracy: 0.5590\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6536 - accuracy: 0.6238 - val_loss: 0.6725 - val_accuracy: 0.5631\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6515 - accuracy: 0.6224 - val_loss: 0.6710 - val_accuracy: 0.5655\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6516 - accuracy: 0.6258 - val_loss: 0.6701 - val_accuracy: 0.5667\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6504 - accuracy: 0.6256 - val_loss: 0.6692 - val_accuracy: 0.5681\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6495 - accuracy: 0.6278 - val_loss: 0.6681 - val_accuracy: 0.5693\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6474 - accuracy: 0.6323 - val_loss: 0.6672 - val_accuracy: 0.5709\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6468 - accuracy: 0.6324 - val_loss: 0.6682 - val_accuracy: 0.5692\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6461 - accuracy: 0.6332 - val_loss: 0.6663 - val_accuracy: 0.5720\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6458 - accuracy: 0.6320 - val_loss: 0.6664 - val_accuracy: 0.5718\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6445 - accuracy: 0.6345 - val_loss: 0.6656 - val_accuracy: 0.5733\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6443 - accuracy: 0.6353 - val_loss: 0.6639 - val_accuracy: 0.5756\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6428 - accuracy: 0.6356 - val_loss: 0.6639 - val_accuracy: 0.5756\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6413 - accuracy: 0.6355 - val_loss: 0.6639 - val_accuracy: 0.5754\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6401 - accuracy: 0.6400 - val_loss: 0.6627 - val_accuracy: 0.5765\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6399 - accuracy: 0.6400 - val_loss: 0.6609 - val_accuracy: 0.5781\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6392 - accuracy: 0.6396 - val_loss: 0.6614 - val_accuracy: 0.5779\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6374 - accuracy: 0.6434 - val_loss: 0.6612 - val_accuracy: 0.5780\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6363 - accuracy: 0.6462 - val_loss: 0.6596 - val_accuracy: 0.5795\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6357 - accuracy: 0.6468 - val_loss: 0.6600 - val_accuracy: 0.5787\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6374 - accuracy: 0.6427 - val_loss: 0.6589 - val_accuracy: 0.5801\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6346 - accuracy: 0.6457 - val_loss: 0.6575 - val_accuracy: 0.5819\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6328 - accuracy: 0.6491 - val_loss: 0.6566 - val_accuracy: 0.5837\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7744 - accuracy: 0.4791 - val_loss: 0.5528 - val_accuracy: 0.8733\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7286 - accuracy: 0.4820 - val_loss: 0.6119 - val_accuracy: 0.8184\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7087 - accuracy: 0.4912 - val_loss: 0.6514 - val_accuracy: 0.7467\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7031 - accuracy: 0.5000 - val_loss: 0.6764 - val_accuracy: 0.5996\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6985 - accuracy: 0.5146 - val_loss: 0.6916 - val_accuracy: 0.5299\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6966 - accuracy: 0.5167 - val_loss: 0.7006 - val_accuracy: 0.4910\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6955 - accuracy: 0.5219 - val_loss: 0.7058 - val_accuracy: 0.4644\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6951 - accuracy: 0.5240 - val_loss: 0.7086 - val_accuracy: 0.4581\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5328 - val_loss: 0.7099 - val_accuracy: 0.4615\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6918 - accuracy: 0.5335 - val_loss: 0.7099 - val_accuracy: 0.4691\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6900 - accuracy: 0.5385 - val_loss: 0.7094 - val_accuracy: 0.4731\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6888 - accuracy: 0.5464 - val_loss: 0.7089 - val_accuracy: 0.4753\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5476 - val_loss: 0.7079 - val_accuracy: 0.4802\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5496 - val_loss: 0.7069 - val_accuracy: 0.4826\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5535 - val_loss: 0.7063 - val_accuracy: 0.4837\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6848 - accuracy: 0.5559 - val_loss: 0.7054 - val_accuracy: 0.4876\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6826 - accuracy: 0.5642 - val_loss: 0.7048 - val_accuracy: 0.4955\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5609 - val_loss: 0.7035 - val_accuracy: 0.5061\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6831 - accuracy: 0.5599 - val_loss: 0.7030 - val_accuracy: 0.5077\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6809 - accuracy: 0.5669 - val_loss: 0.7019 - val_accuracy: 0.5091\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6801 - accuracy: 0.5682 - val_loss: 0.7014 - val_accuracy: 0.5097\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6798 - accuracy: 0.5703 - val_loss: 0.7012 - val_accuracy: 0.5106\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6781 - accuracy: 0.5741 - val_loss: 0.7004 - val_accuracy: 0.5117\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6776 - accuracy: 0.5794 - val_loss: 0.7000 - val_accuracy: 0.5130\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6778 - accuracy: 0.5775 - val_loss: 0.6984 - val_accuracy: 0.5172\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6764 - accuracy: 0.5801 - val_loss: 0.6978 - val_accuracy: 0.5182\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6746 - accuracy: 0.5869 - val_loss: 0.6964 - val_accuracy: 0.5222\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6754 - accuracy: 0.5844 - val_loss: 0.6957 - val_accuracy: 0.5248\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5903 - val_loss: 0.6944 - val_accuracy: 0.5273\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6724 - accuracy: 0.5941 - val_loss: 0.6938 - val_accuracy: 0.5290\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6731 - accuracy: 0.5896 - val_loss: 0.6933 - val_accuracy: 0.5304\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6710 - accuracy: 0.5955 - val_loss: 0.6921 - val_accuracy: 0.5321\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6710 - accuracy: 0.5976 - val_loss: 0.6915 - val_accuracy: 0.5320\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6703 - accuracy: 0.5989 - val_loss: 0.6910 - val_accuracy: 0.5326\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6696 - accuracy: 0.5996 - val_loss: 0.6902 - val_accuracy: 0.5358\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.6041 - val_loss: 0.6895 - val_accuracy: 0.5386\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6675 - accuracy: 0.6074 - val_loss: 0.6889 - val_accuracy: 0.5394\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6664 - accuracy: 0.6105 - val_loss: 0.6883 - val_accuracy: 0.5398\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6663 - accuracy: 0.6090 - val_loss: 0.6868 - val_accuracy: 0.5425\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6653 - accuracy: 0.6102 - val_loss: 0.6865 - val_accuracy: 0.5434\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6648 - accuracy: 0.6156 - val_loss: 0.6858 - val_accuracy: 0.5436\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6651 - accuracy: 0.6119 - val_loss: 0.6849 - val_accuracy: 0.5459\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6632 - accuracy: 0.6159 - val_loss: 0.6844 - val_accuracy: 0.5465\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6633 - accuracy: 0.6154 - val_loss: 0.6833 - val_accuracy: 0.5511\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6620 - accuracy: 0.6204 - val_loss: 0.6826 - val_accuracy: 0.5535\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6613 - accuracy: 0.6228 - val_loss: 0.6815 - val_accuracy: 0.5567\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.6211 - val_loss: 0.6811 - val_accuracy: 0.5576\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6613 - accuracy: 0.6204 - val_loss: 0.6807 - val_accuracy: 0.5577\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6590 - accuracy: 0.6243 - val_loss: 0.6803 - val_accuracy: 0.5590\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6244 - val_loss: 0.6797 - val_accuracy: 0.5602\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7186 - accuracy: 0.5047 - val_loss: 0.8022 - val_accuracy: 0.1581\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7128 - accuracy: 0.4960 - val_loss: 0.7685 - val_accuracy: 0.1903\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7070 - accuracy: 0.5035 - val_loss: 0.7519 - val_accuracy: 0.2209\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7061 - accuracy: 0.5009 - val_loss: 0.7428 - val_accuracy: 0.2441\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7029 - accuracy: 0.5086 - val_loss: 0.7382 - val_accuracy: 0.2575\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7005 - accuracy: 0.5135 - val_loss: 0.7341 - val_accuracy: 0.2710\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6987 - accuracy: 0.5179 - val_loss: 0.7324 - val_accuracy: 0.2760\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6963 - accuracy: 0.5205 - val_loss: 0.7297 - val_accuracy: 0.2840\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6958 - accuracy: 0.5239 - val_loss: 0.7282 - val_accuracy: 0.2912\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5295 - val_loss: 0.7272 - val_accuracy: 0.2975\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6913 - accuracy: 0.5336 - val_loss: 0.7253 - val_accuracy: 0.3090\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6910 - accuracy: 0.5339 - val_loss: 0.7236 - val_accuracy: 0.3214\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5372 - val_loss: 0.7215 - val_accuracy: 0.3341\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5447 - val_loss: 0.7201 - val_accuracy: 0.3413\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5487 - val_loss: 0.7186 - val_accuracy: 0.3529\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5490 - val_loss: 0.7170 - val_accuracy: 0.3659\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6826 - accuracy: 0.5573 - val_loss: 0.7152 - val_accuracy: 0.3811\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6804 - accuracy: 0.5607 - val_loss: 0.7137 - val_accuracy: 0.3974\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6799 - accuracy: 0.5629 - val_loss: 0.7128 - val_accuracy: 0.4116\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6785 - accuracy: 0.5629 - val_loss: 0.7108 - val_accuracy: 0.4302\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6781 - accuracy: 0.5686 - val_loss: 0.7099 - val_accuracy: 0.4424\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6763 - accuracy: 0.5686 - val_loss: 0.7084 - val_accuracy: 0.4567\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6748 - accuracy: 0.5731 - val_loss: 0.7070 - val_accuracy: 0.4695\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6737 - accuracy: 0.5769 - val_loss: 0.7057 - val_accuracy: 0.4815\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6724 - accuracy: 0.5798 - val_loss: 0.7041 - val_accuracy: 0.4936\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6710 - accuracy: 0.5828 - val_loss: 0.7026 - val_accuracy: 0.5046\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6699 - accuracy: 0.5857 - val_loss: 0.7009 - val_accuracy: 0.5144\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6685 - accuracy: 0.5902 - val_loss: 0.7002 - val_accuracy: 0.5198\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6681 - accuracy: 0.5916 - val_loss: 0.6993 - val_accuracy: 0.5247\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6666 - accuracy: 0.5952 - val_loss: 0.6990 - val_accuracy: 0.5287\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6651 - accuracy: 0.5971 - val_loss: 0.6981 - val_accuracy: 0.5343\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.6010 - val_loss: 0.6964 - val_accuracy: 0.5396\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.5998 - val_loss: 0.6959 - val_accuracy: 0.5411\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6624 - accuracy: 0.6027 - val_loss: 0.6944 - val_accuracy: 0.5476\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6598 - accuracy: 0.6080 - val_loss: 0.6939 - val_accuracy: 0.5482\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6599 - accuracy: 0.6097 - val_loss: 0.6927 - val_accuracy: 0.5506\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6604 - accuracy: 0.6086 - val_loss: 0.6920 - val_accuracy: 0.5517\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6571 - accuracy: 0.6140 - val_loss: 0.6911 - val_accuracy: 0.5535\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6147 - val_loss: 0.6907 - val_accuracy: 0.5538\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6183 - val_loss: 0.6887 - val_accuracy: 0.5601\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6550 - accuracy: 0.6217 - val_loss: 0.6880 - val_accuracy: 0.5609\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6550 - accuracy: 0.6186 - val_loss: 0.6869 - val_accuracy: 0.5625\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6232 - val_loss: 0.6857 - val_accuracy: 0.5664\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6522 - accuracy: 0.6230 - val_loss: 0.6837 - val_accuracy: 0.5710\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6516 - accuracy: 0.6230 - val_loss: 0.6839 - val_accuracy: 0.5701\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6511 - accuracy: 0.6257 - val_loss: 0.6829 - val_accuracy: 0.5718\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6501 - accuracy: 0.6246 - val_loss: 0.6816 - val_accuracy: 0.5755\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6490 - accuracy: 0.6301 - val_loss: 0.6805 - val_accuracy: 0.5788\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6481 - accuracy: 0.6314 - val_loss: 0.6795 - val_accuracy: 0.5810\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6470 - accuracy: 0.6345 - val_loss: 0.6785 - val_accuracy: 0.5837\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7313 - accuracy: 0.4841 - val_loss: 0.6728 - val_accuracy: 0.5812\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7202 - accuracy: 0.4964 - val_loss: 0.7016 - val_accuracy: 0.4595\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7146 - accuracy: 0.5069 - val_loss: 0.7170 - val_accuracy: 0.4031\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.5094 - val_loss: 0.7217 - val_accuracy: 0.3749\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7093 - accuracy: 0.5156 - val_loss: 0.7218 - val_accuracy: 0.3646\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7058 - accuracy: 0.5203 - val_loss: 0.7222 - val_accuracy: 0.3596\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7035 - accuracy: 0.5265 - val_loss: 0.7208 - val_accuracy: 0.3678\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7012 - accuracy: 0.5313 - val_loss: 0.7189 - val_accuracy: 0.3780\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7000 - accuracy: 0.5345 - val_loss: 0.7167 - val_accuracy: 0.3916\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6967 - accuracy: 0.5383 - val_loss: 0.7147 - val_accuracy: 0.4061\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6953 - accuracy: 0.5418 - val_loss: 0.7121 - val_accuracy: 0.4224\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5477 - val_loss: 0.7103 - val_accuracy: 0.4370\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6909 - accuracy: 0.5500 - val_loss: 0.7091 - val_accuracy: 0.4482\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6883 - accuracy: 0.5562 - val_loss: 0.7074 - val_accuracy: 0.4614\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6871 - accuracy: 0.5572 - val_loss: 0.7043 - val_accuracy: 0.4762\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5627 - val_loss: 0.7024 - val_accuracy: 0.4865\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6820 - accuracy: 0.5681 - val_loss: 0.7009 - val_accuracy: 0.4924\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6822 - accuracy: 0.5686 - val_loss: 0.6989 - val_accuracy: 0.4995\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6794 - accuracy: 0.5736 - val_loss: 0.6962 - val_accuracy: 0.5076\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6784 - accuracy: 0.5792 - val_loss: 0.6950 - val_accuracy: 0.5109\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6762 - accuracy: 0.5825 - val_loss: 0.6936 - val_accuracy: 0.5126\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6732 - accuracy: 0.5880 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6733 - accuracy: 0.5868 - val_loss: 0.6901 - val_accuracy: 0.5213\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6704 - accuracy: 0.5922 - val_loss: 0.6888 - val_accuracy: 0.5229\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6696 - accuracy: 0.5944 - val_loss: 0.6876 - val_accuracy: 0.5243\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6681 - accuracy: 0.5989 - val_loss: 0.6863 - val_accuracy: 0.5266\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6662 - accuracy: 0.6011 - val_loss: 0.6841 - val_accuracy: 0.5325\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6657 - accuracy: 0.6045 - val_loss: 0.6824 - val_accuracy: 0.5384\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6634 - accuracy: 0.6104 - val_loss: 0.6809 - val_accuracy: 0.5416\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6616 - accuracy: 0.6108 - val_loss: 0.6797 - val_accuracy: 0.5445\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6605 - accuracy: 0.6160 - val_loss: 0.6775 - val_accuracy: 0.5496\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6598 - accuracy: 0.6156 - val_loss: 0.6771 - val_accuracy: 0.5514\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6567 - accuracy: 0.6209 - val_loss: 0.6749 - val_accuracy: 0.5566\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6563 - accuracy: 0.6228 - val_loss: 0.6737 - val_accuracy: 0.5609\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6210 - val_loss: 0.6726 - val_accuracy: 0.5620\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6221 - val_loss: 0.6712 - val_accuracy: 0.5652\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6223 - val_loss: 0.6716 - val_accuracy: 0.5646\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6296 - val_loss: 0.6701 - val_accuracy: 0.5683\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6259 - val_loss: 0.6695 - val_accuracy: 0.5707\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6321 - val_loss: 0.6673 - val_accuracy: 0.5761\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6297 - val_loss: 0.6657 - val_accuracy: 0.5788\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6326 - val_loss: 0.6657 - val_accuracy: 0.5788\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6465 - accuracy: 0.6366 - val_loss: 0.6642 - val_accuracy: 0.5818\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6461 - accuracy: 0.6363 - val_loss: 0.6641 - val_accuracy: 0.5807\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6410 - val_loss: 0.6636 - val_accuracy: 0.5813\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.6384 - val_loss: 0.6626 - val_accuracy: 0.5829\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.6388 - val_loss: 0.6618 - val_accuracy: 0.5833\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6461 - val_loss: 0.6608 - val_accuracy: 0.5848\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6421 - val_loss: 0.6601 - val_accuracy: 0.5854\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.6419 - val_loss: 0.6587 - val_accuracy: 0.5880\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7580 - accuracy: 0.5052 - val_loss: 0.5900 - val_accuracy: 0.8405\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.5230 - val_loss: 0.6592 - val_accuracy: 0.7340\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7021 - accuracy: 0.5333 - val_loss: 0.6903 - val_accuracy: 0.5494\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.5394 - val_loss: 0.7027 - val_accuracy: 0.4605\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.5406 - val_loss: 0.7068 - val_accuracy: 0.4418\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5498 - val_loss: 0.7075 - val_accuracy: 0.4453\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5489 - val_loss: 0.7066 - val_accuracy: 0.4518\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5567 - val_loss: 0.7048 - val_accuracy: 0.4654\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5588 - val_loss: 0.7028 - val_accuracy: 0.4777\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5663 - val_loss: 0.7020 - val_accuracy: 0.4826\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5656 - val_loss: 0.7008 - val_accuracy: 0.4889\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5755 - val_loss: 0.6986 - val_accuracy: 0.5023\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5745 - val_loss: 0.6977 - val_accuracy: 0.5061\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6776 - accuracy: 0.5776 - val_loss: 0.6961 - val_accuracy: 0.5117\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6748 - accuracy: 0.5838 - val_loss: 0.6956 - val_accuracy: 0.5138\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6731 - accuracy: 0.5858 - val_loss: 0.6930 - val_accuracy: 0.5253\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5935 - val_loss: 0.6916 - val_accuracy: 0.5294\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6712 - accuracy: 0.5917 - val_loss: 0.6909 - val_accuracy: 0.5327\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5937 - val_loss: 0.6914 - val_accuracy: 0.5288\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.5989 - val_loss: 0.6893 - val_accuracy: 0.5371\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6667 - accuracy: 0.5992 - val_loss: 0.6881 - val_accuracy: 0.5427\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.6062 - val_loss: 0.6858 - val_accuracy: 0.5499\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6642 - accuracy: 0.6075 - val_loss: 0.6858 - val_accuracy: 0.5490\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.6097 - val_loss: 0.6857 - val_accuracy: 0.5490\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.6093 - val_loss: 0.6850 - val_accuracy: 0.5490\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.6162 - val_loss: 0.6839 - val_accuracy: 0.5530\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.6150 - val_loss: 0.6824 - val_accuracy: 0.5566\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6577 - accuracy: 0.6150 - val_loss: 0.6819 - val_accuracy: 0.5571\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6562 - accuracy: 0.6190 - val_loss: 0.6805 - val_accuracy: 0.5613\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6226 - val_loss: 0.6799 - val_accuracy: 0.5624\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6550 - accuracy: 0.6234 - val_loss: 0.6798 - val_accuracy: 0.5619\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6544 - accuracy: 0.6236 - val_loss: 0.6785 - val_accuracy: 0.5640\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6270 - val_loss: 0.6779 - val_accuracy: 0.5649\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6519 - accuracy: 0.6296 - val_loss: 0.6778 - val_accuracy: 0.5647\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6277 - val_loss: 0.6779 - val_accuracy: 0.5643\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6311 - val_loss: 0.6758 - val_accuracy: 0.5693\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6330 - val_loss: 0.6749 - val_accuracy: 0.5708\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6495 - accuracy: 0.6332 - val_loss: 0.6741 - val_accuracy: 0.5716\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6489 - accuracy: 0.6314 - val_loss: 0.6735 - val_accuracy: 0.5729\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6376 - val_loss: 0.6728 - val_accuracy: 0.5738\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6399 - val_loss: 0.6726 - val_accuracy: 0.5729\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6428 - val_loss: 0.6718 - val_accuracy: 0.5745\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.6403 - val_loss: 0.6701 - val_accuracy: 0.5777\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.6424 - val_loss: 0.6691 - val_accuracy: 0.5802\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6483 - val_loss: 0.6693 - val_accuracy: 0.5796\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.6446 - val_loss: 0.6680 - val_accuracy: 0.5818\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6482 - val_loss: 0.6673 - val_accuracy: 0.5827\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6496 - val_loss: 0.6662 - val_accuracy: 0.5842\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6385 - accuracy: 0.6478 - val_loss: 0.6656 - val_accuracy: 0.5850\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6496 - val_loss: 0.6642 - val_accuracy: 0.5875\n",
      "Epoch 1/50\n",
      "  1/418 [..............................] - ETA: 0s - loss: 0.7641 - accuracy: 0.5859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7602 - accuracy: 0.5215 - val_loss: 0.9366 - val_accuracy: 0.1230\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.5234 - val_loss: 0.8293 - val_accuracy: 0.1342\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.5203 - val_loss: 0.7741 - val_accuracy: 0.1819\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6988 - accuracy: 0.5204 - val_loss: 0.7445 - val_accuracy: 0.2574\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5228 - val_loss: 0.7286 - val_accuracy: 0.3132\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5273 - val_loss: 0.7198 - val_accuracy: 0.3602\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6949 - accuracy: 0.5259 - val_loss: 0.7147 - val_accuracy: 0.3904\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5379 - val_loss: 0.7116 - val_accuracy: 0.4123\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5424 - val_loss: 0.7090 - val_accuracy: 0.4333\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5431 - val_loss: 0.7078 - val_accuracy: 0.4481\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5479 - val_loss: 0.7064 - val_accuracy: 0.4598\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5545 - val_loss: 0.7048 - val_accuracy: 0.4720\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5535 - val_loss: 0.7034 - val_accuracy: 0.4828\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5610 - val_loss: 0.7030 - val_accuracy: 0.4878\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5648 - val_loss: 0.7017 - val_accuracy: 0.4974\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6797 - accuracy: 0.5682 - val_loss: 0.7001 - val_accuracy: 0.5076\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5684 - val_loss: 0.6989 - val_accuracy: 0.5156\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6769 - accuracy: 0.5755 - val_loss: 0.6973 - val_accuracy: 0.5247\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.5787 - val_loss: 0.6957 - val_accuracy: 0.5314\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5800 - val_loss: 0.6943 - val_accuracy: 0.5372\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6739 - accuracy: 0.5813 - val_loss: 0.6937 - val_accuracy: 0.5409\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6725 - accuracy: 0.5877 - val_loss: 0.6923 - val_accuracy: 0.5461\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6720 - accuracy: 0.5884 - val_loss: 0.6917 - val_accuracy: 0.5488\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6727 - accuracy: 0.5862 - val_loss: 0.6910 - val_accuracy: 0.5509\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6711 - accuracy: 0.5917 - val_loss: 0.6895 - val_accuracy: 0.5563\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.5907 - val_loss: 0.6883 - val_accuracy: 0.5602\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5954 - val_loss: 0.6872 - val_accuracy: 0.5643\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6684 - accuracy: 0.5999 - val_loss: 0.6858 - val_accuracy: 0.5701\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6669 - accuracy: 0.6012 - val_loss: 0.6852 - val_accuracy: 0.5727\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.6012 - val_loss: 0.6842 - val_accuracy: 0.5754\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6660 - accuracy: 0.6059 - val_loss: 0.6835 - val_accuracy: 0.5768\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6655 - accuracy: 0.6067 - val_loss: 0.6826 - val_accuracy: 0.5793\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6644 - accuracy: 0.6055 - val_loss: 0.6817 - val_accuracy: 0.5816\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6126 - val_loss: 0.6820 - val_accuracy: 0.5804\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6632 - accuracy: 0.6116 - val_loss: 0.6811 - val_accuracy: 0.5835\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6620 - accuracy: 0.6134 - val_loss: 0.6794 - val_accuracy: 0.5865\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.6162 - val_loss: 0.6789 - val_accuracy: 0.5879\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6163 - val_loss: 0.6783 - val_accuracy: 0.5895\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6208 - val_loss: 0.6773 - val_accuracy: 0.5925\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6584 - accuracy: 0.6216 - val_loss: 0.6771 - val_accuracy: 0.5932\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.6236 - val_loss: 0.6762 - val_accuracy: 0.5948\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6240 - val_loss: 0.6756 - val_accuracy: 0.5957\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6568 - accuracy: 0.6255 - val_loss: 0.6752 - val_accuracy: 0.5960\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6292 - val_loss: 0.6746 - val_accuracy: 0.5976\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.6293 - val_loss: 0.6739 - val_accuracy: 0.5994\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6328 - val_loss: 0.6730 - val_accuracy: 0.6016\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6295 - val_loss: 0.6716 - val_accuracy: 0.6052\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6322 - val_loss: 0.6711 - val_accuracy: 0.6053\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6353 - val_loss: 0.6698 - val_accuracy: 0.6082\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6368 - val_loss: 0.6704 - val_accuracy: 0.6068\n",
      "Epoch 1/50\n",
      "  1/418 [..............................] - ETA: 0s - loss: 0.7302 - accuracy: 0.3750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7212 - accuracy: 0.4595 - val_loss: 0.7138 - val_accuracy: 0.4137\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.4654 - val_loss: 0.7268 - val_accuracy: 0.3496\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.4715 - val_loss: 0.7321 - val_accuracy: 0.3188\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.4832 - val_loss: 0.7329 - val_accuracy: 0.3059\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.4840 - val_loss: 0.7329 - val_accuracy: 0.2936\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.4912 - val_loss: 0.7316 - val_accuracy: 0.2906\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.4959 - val_loss: 0.7298 - val_accuracy: 0.3064\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.4980 - val_loss: 0.7277 - val_accuracy: 0.3225\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6996 - accuracy: 0.5066 - val_loss: 0.7254 - val_accuracy: 0.3317\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6991 - accuracy: 0.5084 - val_loss: 0.7229 - val_accuracy: 0.3397\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.5137 - val_loss: 0.7209 - val_accuracy: 0.3458\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5173 - val_loss: 0.7184 - val_accuracy: 0.3539\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5224 - val_loss: 0.7166 - val_accuracy: 0.3707\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5287 - val_loss: 0.7146 - val_accuracy: 0.3899\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5262 - val_loss: 0.7120 - val_accuracy: 0.4083\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5371 - val_loss: 0.7100 - val_accuracy: 0.4220\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5390 - val_loss: 0.7085 - val_accuracy: 0.4353\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5409 - val_loss: 0.7076 - val_accuracy: 0.4456\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5417 - val_loss: 0.7066 - val_accuracy: 0.4524\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5492 - val_loss: 0.7051 - val_accuracy: 0.4611\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5540 - val_loss: 0.7040 - val_accuracy: 0.4663\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6814 - accuracy: 0.5571 - val_loss: 0.7036 - val_accuracy: 0.4683\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5613 - val_loss: 0.7021 - val_accuracy: 0.4786\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5638 - val_loss: 0.7006 - val_accuracy: 0.4865\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.5650 - val_loss: 0.7000 - val_accuracy: 0.4898\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.5656 - val_loss: 0.6996 - val_accuracy: 0.4935\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.5740 - val_loss: 0.6991 - val_accuracy: 0.4986\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.5711 - val_loss: 0.6979 - val_accuracy: 0.5062\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.5755 - val_loss: 0.6977 - val_accuracy: 0.5101\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.5775 - val_loss: 0.6964 - val_accuracy: 0.5151\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.5809 - val_loss: 0.6964 - val_accuracy: 0.5174\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.5854 - val_loss: 0.6958 - val_accuracy: 0.5212\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.5887 - val_loss: 0.6948 - val_accuracy: 0.5262\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6705 - accuracy: 0.5876 - val_loss: 0.6941 - val_accuracy: 0.5295\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6697 - accuracy: 0.5908 - val_loss: 0.6935 - val_accuracy: 0.5305\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.5917 - val_loss: 0.6922 - val_accuracy: 0.5331\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5959 - val_loss: 0.6916 - val_accuracy: 0.5363\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.5984 - val_loss: 0.6912 - val_accuracy: 0.5380\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6665 - accuracy: 0.5982 - val_loss: 0.6908 - val_accuracy: 0.5406\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.6027 - val_loss: 0.6894 - val_accuracy: 0.5458\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.6000 - val_loss: 0.6889 - val_accuracy: 0.5478\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6062 - val_loss: 0.6885 - val_accuracy: 0.5489\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.6066 - val_loss: 0.6876 - val_accuracy: 0.5513\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6059 - val_loss: 0.6869 - val_accuracy: 0.5550\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.6082 - val_loss: 0.6867 - val_accuracy: 0.5560\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6118 - val_loss: 0.6858 - val_accuracy: 0.5590\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6607 - accuracy: 0.6127 - val_loss: 0.6845 - val_accuracy: 0.5636\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.6123 - val_loss: 0.6844 - val_accuracy: 0.5628\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.6124 - val_loss: 0.6841 - val_accuracy: 0.5630\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6170 - val_loss: 0.6832 - val_accuracy: 0.5653\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.7127 - accuracy: 0.5032 - val_loss: 0.8042 - val_accuracy: 0.1422\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7084 - accuracy: 0.5000 - val_loss: 0.7790 - val_accuracy: 0.1624\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.5050 - val_loss: 0.7625 - val_accuracy: 0.1912\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.5044 - val_loss: 0.7507 - val_accuracy: 0.2333\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.5099 - val_loss: 0.7425 - val_accuracy: 0.2745\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.5127 - val_loss: 0.7368 - val_accuracy: 0.3097\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.5172 - val_loss: 0.7323 - val_accuracy: 0.3356\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 985us/step - loss: 0.6944 - accuracy: 0.5259 - val_loss: 0.7287 - val_accuracy: 0.3585\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5300 - val_loss: 0.7263 - val_accuracy: 0.3751\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5336 - val_loss: 0.7247 - val_accuracy: 0.3893\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5384 - val_loss: 0.7225 - val_accuracy: 0.4045\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5416 - val_loss: 0.7205 - val_accuracy: 0.4169\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5499 - val_loss: 0.7191 - val_accuracy: 0.4282\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5535 - val_loss: 0.7175 - val_accuracy: 0.4393\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5556 - val_loss: 0.7166 - val_accuracy: 0.4485\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6822 - accuracy: 0.5629 - val_loss: 0.7153 - val_accuracy: 0.4591\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6813 - accuracy: 0.5646 - val_loss: 0.7142 - val_accuracy: 0.4654\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6801 - accuracy: 0.5648 - val_loss: 0.7130 - val_accuracy: 0.4725\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6792 - accuracy: 0.5698 - val_loss: 0.7117 - val_accuracy: 0.4800\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6786 - accuracy: 0.5727 - val_loss: 0.7111 - val_accuracy: 0.4829\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6762 - accuracy: 0.5783 - val_loss: 0.7097 - val_accuracy: 0.4884\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6757 - accuracy: 0.5797 - val_loss: 0.7088 - val_accuracy: 0.4925\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6742 - accuracy: 0.5840 - val_loss: 0.7075 - val_accuracy: 0.4972\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6738 - accuracy: 0.5861 - val_loss: 0.7068 - val_accuracy: 0.5015\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6728 - accuracy: 0.5856 - val_loss: 0.7056 - val_accuracy: 0.5057\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6717 - accuracy: 0.5902 - val_loss: 0.7038 - val_accuracy: 0.5126\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6704 - accuracy: 0.5929 - val_loss: 0.7032 - val_accuracy: 0.5149\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6693 - accuracy: 0.5956 - val_loss: 0.7025 - val_accuracy: 0.5172\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6687 - accuracy: 0.5973 - val_loss: 0.7015 - val_accuracy: 0.5210\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6681 - accuracy: 0.6000 - val_loss: 0.7005 - val_accuracy: 0.5236\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6667 - accuracy: 0.6015 - val_loss: 0.6991 - val_accuracy: 0.5270\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6656 - accuracy: 0.6057 - val_loss: 0.6985 - val_accuracy: 0.5295\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6656 - accuracy: 0.6035 - val_loss: 0.6978 - val_accuracy: 0.5319\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6638 - accuracy: 0.6103 - val_loss: 0.6964 - val_accuracy: 0.5373\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6626 - accuracy: 0.6109 - val_loss: 0.6957 - val_accuracy: 0.5388\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6617 - accuracy: 0.6101 - val_loss: 0.6941 - val_accuracy: 0.5436\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6611 - accuracy: 0.6120 - val_loss: 0.6927 - val_accuracy: 0.5471\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6597 - accuracy: 0.6175 - val_loss: 0.6916 - val_accuracy: 0.5494\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6147 - val_loss: 0.6900 - val_accuracy: 0.5530\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6579 - accuracy: 0.6196 - val_loss: 0.6885 - val_accuracy: 0.5571\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6564 - accuracy: 0.6223 - val_loss: 0.6871 - val_accuracy: 0.5612\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6229 - val_loss: 0.6857 - val_accuracy: 0.5656\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6240 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6529 - accuracy: 0.6278 - val_loss: 0.6817 - val_accuracy: 0.5783\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6531 - accuracy: 0.6257 - val_loss: 0.6816 - val_accuracy: 0.5783\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6517 - accuracy: 0.6282 - val_loss: 0.6798 - val_accuracy: 0.5830\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6504 - accuracy: 0.6306 - val_loss: 0.6794 - val_accuracy: 0.5841\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6499 - accuracy: 0.6315 - val_loss: 0.6783 - val_accuracy: 0.5852\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6496 - accuracy: 0.6328 - val_loss: 0.6784 - val_accuracy: 0.5850\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6486 - accuracy: 0.6329 - val_loss: 0.6770 - val_accuracy: 0.5874\n"
     ]
    }
   ],
   "source": [
    "# Run experiments targeting specific epsilon values\n",
    "delta = 1e-5\n",
    "\n",
    "# 1. Vary batch_size with target epsilon\n",
    "results_batch_size = {}\n",
    "eps_batch_size = {}\n",
    "noise_batch_size = {}\n",
    "for bs in batch_size_values:\n",
    "    for target_eps in target_eps_values:\n",
    "        print(f\"\\nTraining model with batch_size={bs}, target_eps={target_eps}...\")\n",
    "        n = len(X_train_filtered)\n",
    "        num_microbatches = min(bs // 4, bs)  # Ensure num_microbatches is reasonable\n",
    "        noise_multiplier, eps = adjust_noise_multiplier(n, bs, epochs, target_eps, delta)\n",
    "        results = run_iterations(\n",
    "            X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered,\n",
    "            batch_size=bs, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "            num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier\n",
    "        )\n",
    "        key = (bs, target_eps)\n",
    "        results_batch_size[key] = compute_statistics(results)\n",
    "        eps_batch_size[key] = eps\n",
    "        noise_batch_size[key] = noise_multiplier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247c81e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with sample_size_ratio=1, target_eps=0.5...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 5.05 iterated over 83600 steps satisfies differential privacy with eps = 0.167 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.5749999999999997 iterated over 83600 steps satisfies differential privacy with eps = 0.34 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.3375 iterated over 83600 steps satisfies differential privacy with eps = 0.763 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.9562499999999998 iterated over 83600 steps satisfies differential privacy with eps = 0.46 and delta = 1e-05.\n",
      "The optimal RDP order is 51.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.6468749999999999 iterated over 83600 steps satisfies differential privacy with eps = 0.566 and delta = 1e-05.\n",
      "The optimal RDP order is 39.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.8015624999999997 iterated over 83600 steps satisfies differential privacy with eps = 0.507 and delta = 1e-05.\n",
      "The optimal RDP order is 46.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6872 - accuracy: 0.5529 - val_loss: 0.6966 - val_accuracy: 0.5311\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.6771 - accuracy: 0.5722 - val_loss: 0.6872 - val_accuracy: 0.5587\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6716 - accuracy: 0.5835 - val_loss: 0.6817 - val_accuracy: 0.5737\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6656 - accuracy: 0.5978 - val_loss: 0.6772 - val_accuracy: 0.5843\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6606 - accuracy: 0.6092 - val_loss: 0.6763 - val_accuracy: 0.5826\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6568 - accuracy: 0.6157 - val_loss: 0.6692 - val_accuracy: 0.5988\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6506 - accuracy: 0.6246 - val_loss: 0.6717 - val_accuracy: 0.5900\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.6477 - accuracy: 0.6328 - val_loss: 0.6596 - val_accuracy: 0.6156\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6439 - accuracy: 0.6381 - val_loss: 0.6600 - val_accuracy: 0.6094\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6403 - accuracy: 0.6444 - val_loss: 0.6582 - val_accuracy: 0.6111\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6374 - accuracy: 0.6488 - val_loss: 0.6547 - val_accuracy: 0.6175\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6345 - accuracy: 0.6487 - val_loss: 0.6558 - val_accuracy: 0.6134\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6311 - accuracy: 0.6574 - val_loss: 0.6451 - val_accuracy: 0.6280\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6288 - accuracy: 0.6604 - val_loss: 0.6443 - val_accuracy: 0.6277\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6251 - accuracy: 0.6654 - val_loss: 0.6427 - val_accuracy: 0.6290\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6236 - accuracy: 0.6660 - val_loss: 0.6414 - val_accuracy: 0.6301\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6209 - accuracy: 0.6697 - val_loss: 0.6412 - val_accuracy: 0.6299\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6181 - accuracy: 0.6715 - val_loss: 0.6358 - val_accuracy: 0.6354\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6148 - accuracy: 0.6758 - val_loss: 0.6391 - val_accuracy: 0.6298\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6146 - accuracy: 0.6754 - val_loss: 0.6400 - val_accuracy: 0.6256\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6120 - accuracy: 0.6770 - val_loss: 0.6293 - val_accuracy: 0.6424\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6094 - accuracy: 0.6839 - val_loss: 0.6365 - val_accuracy: 0.6280\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6075 - accuracy: 0.6834 - val_loss: 0.6235 - val_accuracy: 0.6448\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6047 - accuracy: 0.6885 - val_loss: 0.6307 - val_accuracy: 0.6350\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6029 - accuracy: 0.6883 - val_loss: 0.6235 - val_accuracy: 0.6403\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6011 - accuracy: 0.6903 - val_loss: 0.6315 - val_accuracy: 0.6287\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5982 - accuracy: 0.6929 - val_loss: 0.6240 - val_accuracy: 0.6361\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5963 - accuracy: 0.6952 - val_loss: 0.6299 - val_accuracy: 0.6267\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5960 - accuracy: 0.6942 - val_loss: 0.6232 - val_accuracy: 0.6342\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5940 - accuracy: 0.6953 - val_loss: 0.6240 - val_accuracy: 0.6318\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.5911 - accuracy: 0.6992 - val_loss: 0.6207 - val_accuracy: 0.6335\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5903 - accuracy: 0.6996 - val_loss: 0.6240 - val_accuracy: 0.6277\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5886 - accuracy: 0.7002 - val_loss: 0.6154 - val_accuracy: 0.6356\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5871 - accuracy: 0.7034 - val_loss: 0.6208 - val_accuracy: 0.6292\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5851 - accuracy: 0.7023 - val_loss: 0.6179 - val_accuracy: 0.6295\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5830 - accuracy: 0.7066 - val_loss: 0.6139 - val_accuracy: 0.6350\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5827 - accuracy: 0.7055 - val_loss: 0.6078 - val_accuracy: 0.6434\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5801 - accuracy: 0.7064 - val_loss: 0.6101 - val_accuracy: 0.6409\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5786 - accuracy: 0.7083 - val_loss: 0.6134 - val_accuracy: 0.6365\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.5769 - accuracy: 0.7098 - val_loss: 0.6181 - val_accuracy: 0.6302\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5766 - accuracy: 0.7094 - val_loss: 0.6138 - val_accuracy: 0.6371\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5740 - accuracy: 0.7141 - val_loss: 0.6149 - val_accuracy: 0.6365\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5718 - accuracy: 0.7139 - val_loss: 0.6078 - val_accuracy: 0.6447\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.5705 - accuracy: 0.7134 - val_loss: 0.6116 - val_accuracy: 0.6406\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5703 - accuracy: 0.7155 - val_loss: 0.6143 - val_accuracy: 0.6372\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5691 - accuracy: 0.7151 - val_loss: 0.6089 - val_accuracy: 0.6428\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5674 - accuracy: 0.7149 - val_loss: 0.6051 - val_accuracy: 0.6462\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5661 - accuracy: 0.7165 - val_loss: 0.6111 - val_accuracy: 0.6402\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5644 - accuracy: 0.7185 - val_loss: 0.6072 - val_accuracy: 0.6438\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5629 - accuracy: 0.7194 - val_loss: 0.6112 - val_accuracy: 0.6404\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.7218 - accuracy: 0.4978 - val_loss: 0.6677 - val_accuracy: 0.6769\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6927 - accuracy: 0.5279 - val_loss: 0.7038 - val_accuracy: 0.4623\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6877 - accuracy: 0.5464 - val_loss: 0.7047 - val_accuracy: 0.4695\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6821 - accuracy: 0.5602 - val_loss: 0.7012 - val_accuracy: 0.4963\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6758 - accuracy: 0.5765 - val_loss: 0.6966 - val_accuracy: 0.5246\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6711 - accuracy: 0.5905 - val_loss: 0.6952 - val_accuracy: 0.5360\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6668 - accuracy: 0.6003 - val_loss: 0.6891 - val_accuracy: 0.5625\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6625 - accuracy: 0.6092 - val_loss: 0.6873 - val_accuracy: 0.5706\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6588 - accuracy: 0.6188 - val_loss: 0.6845 - val_accuracy: 0.5760\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.6556 - accuracy: 0.6250 - val_loss: 0.6797 - val_accuracy: 0.5882\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6520 - accuracy: 0.6278 - val_loss: 0.6757 - val_accuracy: 0.5958\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6487 - accuracy: 0.6361 - val_loss: 0.6765 - val_accuracy: 0.5943\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6460 - accuracy: 0.6423 - val_loss: 0.6739 - val_accuracy: 0.5975\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6431 - accuracy: 0.6476 - val_loss: 0.6688 - val_accuracy: 0.6018\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6401 - accuracy: 0.6502 - val_loss: 0.6664 - val_accuracy: 0.6046\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6374 - accuracy: 0.6562 - val_loss: 0.6624 - val_accuracy: 0.6126\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6345 - accuracy: 0.6612 - val_loss: 0.6599 - val_accuracy: 0.6151\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6319 - accuracy: 0.6647 - val_loss: 0.6579 - val_accuracy: 0.6162\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6294 - accuracy: 0.6672 - val_loss: 0.6598 - val_accuracy: 0.6141\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6268 - accuracy: 0.6701 - val_loss: 0.6529 - val_accuracy: 0.6208\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6243 - accuracy: 0.6744 - val_loss: 0.6496 - val_accuracy: 0.6222\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6217 - accuracy: 0.6772 - val_loss: 0.6532 - val_accuracy: 0.6183\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6198 - accuracy: 0.6779 - val_loss: 0.6491 - val_accuracy: 0.6209\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6166 - accuracy: 0.6812 - val_loss: 0.6434 - val_accuracy: 0.6240\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6156 - accuracy: 0.6825 - val_loss: 0.6416 - val_accuracy: 0.6250\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 487us/step - loss: 0.6119 - accuracy: 0.6848 - val_loss: 0.6419 - val_accuracy: 0.6244\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6114 - accuracy: 0.6882 - val_loss: 0.6445 - val_accuracy: 0.6220\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6077 - accuracy: 0.6893 - val_loss: 0.6433 - val_accuracy: 0.6215\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6066 - accuracy: 0.6897 - val_loss: 0.6396 - val_accuracy: 0.6256\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6044 - accuracy: 0.6923 - val_loss: 0.6389 - val_accuracy: 0.6270\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6024 - accuracy: 0.6954 - val_loss: 0.6372 - val_accuracy: 0.6290\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6009 - accuracy: 0.6932 - val_loss: 0.6332 - val_accuracy: 0.6330\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5977 - accuracy: 0.6987 - val_loss: 0.6312 - val_accuracy: 0.6347\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5961 - accuracy: 0.7001 - val_loss: 0.6324 - val_accuracy: 0.6331\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5954 - accuracy: 0.7012 - val_loss: 0.6295 - val_accuracy: 0.6357\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5922 - accuracy: 0.7016 - val_loss: 0.6289 - val_accuracy: 0.6360\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5904 - accuracy: 0.7041 - val_loss: 0.6303 - val_accuracy: 0.6349\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5894 - accuracy: 0.7035 - val_loss: 0.6227 - val_accuracy: 0.6401\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.5881 - accuracy: 0.7060 - val_loss: 0.6210 - val_accuracy: 0.6429\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5854 - accuracy: 0.7082 - val_loss: 0.6229 - val_accuracy: 0.6414\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5842 - accuracy: 0.7083 - val_loss: 0.6241 - val_accuracy: 0.6401\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5827 - accuracy: 0.7087 - val_loss: 0.6169 - val_accuracy: 0.6449\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.5810 - accuracy: 0.7093 - val_loss: 0.6200 - val_accuracy: 0.6433\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5794 - accuracy: 0.7116 - val_loss: 0.6158 - val_accuracy: 0.6447\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5780 - accuracy: 0.7117 - val_loss: 0.6138 - val_accuracy: 0.6448\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 474us/step - loss: 0.5749 - accuracy: 0.7144 - val_loss: 0.6192 - val_accuracy: 0.6417\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 484us/step - loss: 0.5747 - accuracy: 0.7142 - val_loss: 0.6185 - val_accuracy: 0.6419\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.5720 - accuracy: 0.7170 - val_loss: 0.6145 - val_accuracy: 0.6446\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5704 - accuracy: 0.7153 - val_loss: 0.6182 - val_accuracy: 0.6425\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5695 - accuracy: 0.7173 - val_loss: 0.6149 - val_accuracy: 0.6445\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6890 - accuracy: 0.5547 - val_loss: 0.7109 - val_accuracy: 0.4766\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2s 983us/step - loss: 0.6805 - accuracy: 0.5673 - val_loss: 0.6985 - val_accuracy: 0.5175\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 787us/step - loss: 0.6757 - accuracy: 0.5822 - val_loss: 0.6890 - val_accuracy: 0.5422\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6712 - accuracy: 0.5895 - val_loss: 0.6872 - val_accuracy: 0.5459\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6663 - accuracy: 0.5993 - val_loss: 0.6854 - val_accuracy: 0.5469\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 510us/step - loss: 0.6620 - accuracy: 0.6103 - val_loss: 0.6750 - val_accuracy: 0.5693\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6578 - accuracy: 0.6177 - val_loss: 0.6767 - val_accuracy: 0.5659\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6547 - accuracy: 0.6253 - val_loss: 0.6714 - val_accuracy: 0.5733\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6494 - accuracy: 0.6318 - val_loss: 0.6601 - val_accuracy: 0.5944\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6458 - accuracy: 0.6378 - val_loss: 0.6630 - val_accuracy: 0.5851\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6432 - accuracy: 0.6408 - val_loss: 0.6652 - val_accuracy: 0.5802\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 488us/step - loss: 0.6399 - accuracy: 0.6468 - val_loss: 0.6583 - val_accuracy: 0.5913\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6365 - accuracy: 0.6518 - val_loss: 0.6559 - val_accuracy: 0.5937\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6326 - accuracy: 0.6567 - val_loss: 0.6560 - val_accuracy: 0.5922\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6305 - accuracy: 0.6585 - val_loss: 0.6510 - val_accuracy: 0.6026\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.6269 - accuracy: 0.6609 - val_loss: 0.6516 - val_accuracy: 0.6002\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6249 - accuracy: 0.6640 - val_loss: 0.6429 - val_accuracy: 0.6147\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6225 - accuracy: 0.6661 - val_loss: 0.6449 - val_accuracy: 0.6089\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6194 - accuracy: 0.6669 - val_loss: 0.6427 - val_accuracy: 0.6127\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6166 - accuracy: 0.6707 - val_loss: 0.6419 - val_accuracy: 0.6131\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.6138 - accuracy: 0.6726 - val_loss: 0.6363 - val_accuracy: 0.6216\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6125 - accuracy: 0.6725 - val_loss: 0.6399 - val_accuracy: 0.6135\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6103 - accuracy: 0.6743 - val_loss: 0.6317 - val_accuracy: 0.6239\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6076 - accuracy: 0.6788 - val_loss: 0.6319 - val_accuracy: 0.6234\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6058 - accuracy: 0.6785 - val_loss: 0.6277 - val_accuracy: 0.6273\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6026 - accuracy: 0.6808 - val_loss: 0.6231 - val_accuracy: 0.6362\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6010 - accuracy: 0.6850 - val_loss: 0.6241 - val_accuracy: 0.6329\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5981 - accuracy: 0.6849 - val_loss: 0.6263 - val_accuracy: 0.6271\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5963 - accuracy: 0.6869 - val_loss: 0.6207 - val_accuracy: 0.6345\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5953 - accuracy: 0.6876 - val_loss: 0.6287 - val_accuracy: 0.6224\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5925 - accuracy: 0.6913 - val_loss: 0.6228 - val_accuracy: 0.6284\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5907 - accuracy: 0.6907 - val_loss: 0.6205 - val_accuracy: 0.6303\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 490us/step - loss: 0.5882 - accuracy: 0.6922 - val_loss: 0.6229 - val_accuracy: 0.6257\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5873 - accuracy: 0.6931 - val_loss: 0.6181 - val_accuracy: 0.6347\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5854 - accuracy: 0.6957 - val_loss: 0.6240 - val_accuracy: 0.6263\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.5841 - accuracy: 0.6982 - val_loss: 0.6243 - val_accuracy: 0.6255\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5807 - accuracy: 0.7014 - val_loss: 0.6108 - val_accuracy: 0.6458\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5805 - accuracy: 0.7002 - val_loss: 0.6228 - val_accuracy: 0.6279\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5794 - accuracy: 0.7018 - val_loss: 0.6107 - val_accuracy: 0.6445\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 486us/step - loss: 0.5776 - accuracy: 0.7013 - val_loss: 0.6226 - val_accuracy: 0.6293\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5755 - accuracy: 0.7042 - val_loss: 0.6106 - val_accuracy: 0.6440\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5746 - accuracy: 0.7038 - val_loss: 0.6117 - val_accuracy: 0.6428\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5730 - accuracy: 0.7065 - val_loss: 0.6188 - val_accuracy: 0.6346\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5704 - accuracy: 0.7089 - val_loss: 0.6182 - val_accuracy: 0.6349\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.5697 - accuracy: 0.7090 - val_loss: 0.6138 - val_accuracy: 0.6405\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5679 - accuracy: 0.7121 - val_loss: 0.6098 - val_accuracy: 0.6446\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5674 - accuracy: 0.7120 - val_loss: 0.6186 - val_accuracy: 0.6313\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5652 - accuracy: 0.7145 - val_loss: 0.6132 - val_accuracy: 0.6375\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5639 - accuracy: 0.7139 - val_loss: 0.6085 - val_accuracy: 0.6427\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5622 - accuracy: 0.7161 - val_loss: 0.6134 - val_accuracy: 0.6345\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.7281 - accuracy: 0.4650 - val_loss: 0.7239 - val_accuracy: 0.3083\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.7197 - accuracy: 0.4759 - val_loss: 0.7299 - val_accuracy: 0.2791\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.7135 - accuracy: 0.4875 - val_loss: 0.7314 - val_accuracy: 0.2741\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.7064 - accuracy: 0.5047 - val_loss: 0.7231 - val_accuracy: 0.3644\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.7008 - accuracy: 0.5148 - val_loss: 0.7165 - val_accuracy: 0.4059\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.6973 - accuracy: 0.5237 - val_loss: 0.7134 - val_accuracy: 0.4395\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6935 - accuracy: 0.5324 - val_loss: 0.7142 - val_accuracy: 0.4423\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.6888 - accuracy: 0.5471 - val_loss: 0.7084 - val_accuracy: 0.4595\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6850 - accuracy: 0.5578 - val_loss: 0.7040 - val_accuracy: 0.4758\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6821 - accuracy: 0.5658 - val_loss: 0.7034 - val_accuracy: 0.4926\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 500us/step - loss: 0.6790 - accuracy: 0.5749 - val_loss: 0.7008 - val_accuracy: 0.5068\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6761 - accuracy: 0.5808 - val_loss: 0.6968 - val_accuracy: 0.5277\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6734 - accuracy: 0.5925 - val_loss: 0.6957 - val_accuracy: 0.5370\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6708 - accuracy: 0.5970 - val_loss: 0.6890 - val_accuracy: 0.5614\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6677 - accuracy: 0.6066 - val_loss: 0.6895 - val_accuracy: 0.5635\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.6646 - accuracy: 0.6160 - val_loss: 0.6871 - val_accuracy: 0.5702\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.6616 - accuracy: 0.6211 - val_loss: 0.6825 - val_accuracy: 0.5843\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6598 - accuracy: 0.6251 - val_loss: 0.6805 - val_accuracy: 0.5870\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.6558 - accuracy: 0.6340 - val_loss: 0.6788 - val_accuracy: 0.5896\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6537 - accuracy: 0.6379 - val_loss: 0.6763 - val_accuracy: 0.5918\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6499 - accuracy: 0.6446 - val_loss: 0.6781 - val_accuracy: 0.5880\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 506us/step - loss: 0.6474 - accuracy: 0.6490 - val_loss: 0.6719 - val_accuracy: 0.5983\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6446 - accuracy: 0.6537 - val_loss: 0.6673 - val_accuracy: 0.6073\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.6405 - accuracy: 0.6604 - val_loss: 0.6645 - val_accuracy: 0.6111\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6388 - accuracy: 0.6617 - val_loss: 0.6652 - val_accuracy: 0.6077\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6362 - accuracy: 0.6651 - val_loss: 0.6616 - val_accuracy: 0.6124\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.6331 - accuracy: 0.6692 - val_loss: 0.6595 - val_accuracy: 0.6159\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6309 - accuracy: 0.6705 - val_loss: 0.6585 - val_accuracy: 0.6163\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.6291 - accuracy: 0.6732 - val_loss: 0.6573 - val_accuracy: 0.6163\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6256 - accuracy: 0.6774 - val_loss: 0.6530 - val_accuracy: 0.6214\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6239 - accuracy: 0.6786 - val_loss: 0.6526 - val_accuracy: 0.6204\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6216 - accuracy: 0.6805 - val_loss: 0.6492 - val_accuracy: 0.6245\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6184 - accuracy: 0.6842 - val_loss: 0.6468 - val_accuracy: 0.6268\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6165 - accuracy: 0.6858 - val_loss: 0.6454 - val_accuracy: 0.6268\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6146 - accuracy: 0.6862 - val_loss: 0.6451 - val_accuracy: 0.6263\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6118 - accuracy: 0.6890 - val_loss: 0.6383 - val_accuracy: 0.6331\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6092 - accuracy: 0.6928 - val_loss: 0.6379 - val_accuracy: 0.6320\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6075 - accuracy: 0.6920 - val_loss: 0.6363 - val_accuracy: 0.6321\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6054 - accuracy: 0.6914 - val_loss: 0.6358 - val_accuracy: 0.6314\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6032 - accuracy: 0.6946 - val_loss: 0.6375 - val_accuracy: 0.6281\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6007 - accuracy: 0.6967 - val_loss: 0.6369 - val_accuracy: 0.6274\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5995 - accuracy: 0.6968 - val_loss: 0.6353 - val_accuracy: 0.6290\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.5972 - accuracy: 0.6990 - val_loss: 0.6315 - val_accuracy: 0.6344\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5952 - accuracy: 0.6994 - val_loss: 0.6293 - val_accuracy: 0.6376\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5943 - accuracy: 0.6986 - val_loss: 0.6293 - val_accuracy: 0.6375\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5926 - accuracy: 0.6997 - val_loss: 0.6267 - val_accuracy: 0.6413\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.5902 - accuracy: 0.7035 - val_loss: 0.6227 - val_accuracy: 0.6459\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5881 - accuracy: 0.7033 - val_loss: 0.6199 - val_accuracy: 0.6497\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5867 - accuracy: 0.7075 - val_loss: 0.6198 - val_accuracy: 0.6488\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5854 - accuracy: 0.7042 - val_loss: 0.6256 - val_accuracy: 0.6392\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6835 - accuracy: 0.5607 - val_loss: 0.6822 - val_accuracy: 0.6051\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6721 - accuracy: 0.5858 - val_loss: 0.6851 - val_accuracy: 0.5892\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6659 - accuracy: 0.5984 - val_loss: 0.6809 - val_accuracy: 0.5912\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6591 - accuracy: 0.6114 - val_loss: 0.6752 - val_accuracy: 0.5950\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6527 - accuracy: 0.6235 - val_loss: 0.6694 - val_accuracy: 0.6054\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6473 - accuracy: 0.6328 - val_loss: 0.6597 - val_accuracy: 0.6204\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6429 - accuracy: 0.6398 - val_loss: 0.6601 - val_accuracy: 0.6138\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6387 - accuracy: 0.6433 - val_loss: 0.6585 - val_accuracy: 0.6173\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6341 - accuracy: 0.6523 - val_loss: 0.6516 - val_accuracy: 0.6307\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6329 - accuracy: 0.6523 - val_loss: 0.6492 - val_accuracy: 0.6343\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6281 - accuracy: 0.6583 - val_loss: 0.6490 - val_accuracy: 0.6320\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6251 - accuracy: 0.6623 - val_loss: 0.6430 - val_accuracy: 0.6410\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6229 - accuracy: 0.6641 - val_loss: 0.6393 - val_accuracy: 0.6447\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6209 - accuracy: 0.6633 - val_loss: 0.6371 - val_accuracy: 0.6435\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6175 - accuracy: 0.6671 - val_loss: 0.6332 - val_accuracy: 0.6462\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6137 - accuracy: 0.6720 - val_loss: 0.6320 - val_accuracy: 0.6445\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6120 - accuracy: 0.6725 - val_loss: 0.6384 - val_accuracy: 0.6329\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6103 - accuracy: 0.6746 - val_loss: 0.6363 - val_accuracy: 0.6326\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.6079 - accuracy: 0.6786 - val_loss: 0.6327 - val_accuracy: 0.6359\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.6053 - accuracy: 0.6773 - val_loss: 0.6284 - val_accuracy: 0.6407\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6032 - accuracy: 0.6810 - val_loss: 0.6270 - val_accuracy: 0.6422\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6009 - accuracy: 0.6836 - val_loss: 0.6197 - val_accuracy: 0.6517\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5997 - accuracy: 0.6836 - val_loss: 0.6295 - val_accuracy: 0.6359\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5985 - accuracy: 0.6857 - val_loss: 0.6331 - val_accuracy: 0.6294\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5952 - accuracy: 0.6892 - val_loss: 0.6238 - val_accuracy: 0.6420\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5941 - accuracy: 0.6885 - val_loss: 0.6213 - val_accuracy: 0.6439\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5914 - accuracy: 0.6900 - val_loss: 0.6235 - val_accuracy: 0.6388\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5906 - accuracy: 0.6911 - val_loss: 0.6215 - val_accuracy: 0.6408\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5896 - accuracy: 0.6920 - val_loss: 0.6202 - val_accuracy: 0.6426\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5876 - accuracy: 0.6925 - val_loss: 0.6205 - val_accuracy: 0.6419\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.5851 - accuracy: 0.6940 - val_loss: 0.6222 - val_accuracy: 0.6385\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5846 - accuracy: 0.6951 - val_loss: 0.6166 - val_accuracy: 0.6453\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5824 - accuracy: 0.6968 - val_loss: 0.6163 - val_accuracy: 0.6446\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5815 - accuracy: 0.6985 - val_loss: 0.6145 - val_accuracy: 0.6458\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5805 - accuracy: 0.6984 - val_loss: 0.6187 - val_accuracy: 0.6402\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5801 - accuracy: 0.6996 - val_loss: 0.6151 - val_accuracy: 0.6450\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.5776 - accuracy: 0.7006 - val_loss: 0.6194 - val_accuracy: 0.6399\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5750 - accuracy: 0.7027 - val_loss: 0.6177 - val_accuracy: 0.6417\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.5744 - accuracy: 0.7027 - val_loss: 0.6212 - val_accuracy: 0.6370\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5735 - accuracy: 0.7038 - val_loss: 0.6144 - val_accuracy: 0.6445\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5725 - accuracy: 0.7050 - val_loss: 0.6108 - val_accuracy: 0.6461\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5706 - accuracy: 0.7071 - val_loss: 0.6150 - val_accuracy: 0.6417\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5700 - accuracy: 0.7048 - val_loss: 0.6161 - val_accuracy: 0.6402\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5682 - accuracy: 0.7081 - val_loss: 0.6127 - val_accuracy: 0.6426\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5687 - accuracy: 0.7079 - val_loss: 0.6166 - val_accuracy: 0.6386\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.5667 - accuracy: 0.7091 - val_loss: 0.6127 - val_accuracy: 0.6423\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5656 - accuracy: 0.7097 - val_loss: 0.6086 - val_accuracy: 0.6449\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.5643 - accuracy: 0.7118 - val_loss: 0.6084 - val_accuracy: 0.6454\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.5630 - accuracy: 0.7125 - val_loss: 0.6087 - val_accuracy: 0.6459\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5612 - accuracy: 0.7134 - val_loss: 0.6089 - val_accuracy: 0.6462\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6909 - accuracy: 0.5390 - val_loss: 0.6901 - val_accuracy: 0.5227\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6826 - accuracy: 0.5535 - val_loss: 0.6814 - val_accuracy: 0.5456\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6768 - accuracy: 0.5700 - val_loss: 0.6794 - val_accuracy: 0.5445\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6714 - accuracy: 0.5814 - val_loss: 0.6735 - val_accuracy: 0.5587\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6662 - accuracy: 0.5909 - val_loss: 0.6701 - val_accuracy: 0.5660\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6609 - accuracy: 0.6026 - val_loss: 0.6679 - val_accuracy: 0.5713\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6566 - accuracy: 0.6093 - val_loss: 0.6634 - val_accuracy: 0.5804\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6531 - accuracy: 0.6179 - val_loss: 0.6602 - val_accuracy: 0.5892\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6481 - accuracy: 0.6253 - val_loss: 0.6582 - val_accuracy: 0.5928\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6442 - accuracy: 0.6326 - val_loss: 0.6551 - val_accuracy: 0.5983\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.6412 - accuracy: 0.6357 - val_loss: 0.6544 - val_accuracy: 0.5981\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6388 - accuracy: 0.6394 - val_loss: 0.6502 - val_accuracy: 0.6067\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6353 - accuracy: 0.6442 - val_loss: 0.6494 - val_accuracy: 0.6075\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6319 - accuracy: 0.6510 - val_loss: 0.6458 - val_accuracy: 0.6137\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6283 - accuracy: 0.6553 - val_loss: 0.6443 - val_accuracy: 0.6147\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6260 - accuracy: 0.6547 - val_loss: 0.6366 - val_accuracy: 0.6240\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6221 - accuracy: 0.6618 - val_loss: 0.6367 - val_accuracy: 0.6232\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6194 - accuracy: 0.6635 - val_loss: 0.6336 - val_accuracy: 0.6268\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6157 - accuracy: 0.6690 - val_loss: 0.6330 - val_accuracy: 0.6274\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6140 - accuracy: 0.6695 - val_loss: 0.6346 - val_accuracy: 0.6263\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6095 - accuracy: 0.6743 - val_loss: 0.6332 - val_accuracy: 0.6287\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.6070 - accuracy: 0.6764 - val_loss: 0.6253 - val_accuracy: 0.6355\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6042 - accuracy: 0.6784 - val_loss: 0.6246 - val_accuracy: 0.6353\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.6016 - accuracy: 0.6824 - val_loss: 0.6271 - val_accuracy: 0.6318\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5999 - accuracy: 0.6839 - val_loss: 0.6226 - val_accuracy: 0.6351\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5972 - accuracy: 0.6861 - val_loss: 0.6161 - val_accuracy: 0.6423\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5958 - accuracy: 0.6867 - val_loss: 0.6232 - val_accuracy: 0.6334\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5944 - accuracy: 0.6879 - val_loss: 0.6225 - val_accuracy: 0.6339\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5914 - accuracy: 0.6890 - val_loss: 0.6138 - val_accuracy: 0.6410\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5900 - accuracy: 0.6889 - val_loss: 0.6158 - val_accuracy: 0.6398\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.5889 - accuracy: 0.6929 - val_loss: 0.6128 - val_accuracy: 0.6402\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.5863 - accuracy: 0.6927 - val_loss: 0.6229 - val_accuracy: 0.6299\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5851 - accuracy: 0.6960 - val_loss: 0.6171 - val_accuracy: 0.6337\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5837 - accuracy: 0.6974 - val_loss: 0.6108 - val_accuracy: 0.6388\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5816 - accuracy: 0.6973 - val_loss: 0.6148 - val_accuracy: 0.6355\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5802 - accuracy: 0.7002 - val_loss: 0.6103 - val_accuracy: 0.6370\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5792 - accuracy: 0.7002 - val_loss: 0.6031 - val_accuracy: 0.6472\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 504us/step - loss: 0.5784 - accuracy: 0.7015 - val_loss: 0.6077 - val_accuracy: 0.6410\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5767 - accuracy: 0.7014 - val_loss: 0.6074 - val_accuracy: 0.6419\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.5754 - accuracy: 0.7032 - val_loss: 0.6044 - val_accuracy: 0.6435\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5736 - accuracy: 0.7064 - val_loss: 0.6016 - val_accuracy: 0.6476\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5723 - accuracy: 0.7059 - val_loss: 0.6100 - val_accuracy: 0.6361\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.5723 - accuracy: 0.7073 - val_loss: 0.6036 - val_accuracy: 0.6435\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5707 - accuracy: 0.7064 - val_loss: 0.6066 - val_accuracy: 0.6392\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5701 - accuracy: 0.7100 - val_loss: 0.6097 - val_accuracy: 0.6354\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5683 - accuracy: 0.7092 - val_loss: 0.6018 - val_accuracy: 0.6429\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5671 - accuracy: 0.7116 - val_loss: 0.6058 - val_accuracy: 0.6383\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5659 - accuracy: 0.7141 - val_loss: 0.6089 - val_accuracy: 0.6330\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5639 - accuracy: 0.7161 - val_loss: 0.6070 - val_accuracy: 0.6354\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.5632 - accuracy: 0.7133 - val_loss: 0.6006 - val_accuracy: 0.6407\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.7036 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6958 - accuracy: 0.5372 - val_loss: 0.7151 - val_accuracy: 0.4183\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6793 - accuracy: 0.5730 - val_loss: 0.6978 - val_accuracy: 0.5092\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6684 - accuracy: 0.5971 - val_loss: 0.6848 - val_accuracy: 0.5530\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6608 - accuracy: 0.6118 - val_loss: 0.6823 - val_accuracy: 0.5649\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6532 - accuracy: 0.6258 - val_loss: 0.6770 - val_accuracy: 0.5776\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.6462 - accuracy: 0.6410 - val_loss: 0.6695 - val_accuracy: 0.5900\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6408 - accuracy: 0.6469 - val_loss: 0.6690 - val_accuracy: 0.5932\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6371 - accuracy: 0.6551 - val_loss: 0.6611 - val_accuracy: 0.6079\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6308 - accuracy: 0.6607 - val_loss: 0.6559 - val_accuracy: 0.6171\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6279 - accuracy: 0.6644 - val_loss: 0.6536 - val_accuracy: 0.6185\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6240 - accuracy: 0.6694 - val_loss: 0.6569 - val_accuracy: 0.6159\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.6208 - accuracy: 0.6731 - val_loss: 0.6504 - val_accuracy: 0.6252\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 499us/step - loss: 0.6190 - accuracy: 0.6748 - val_loss: 0.6518 - val_accuracy: 0.6204\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6148 - accuracy: 0.6796 - val_loss: 0.6432 - val_accuracy: 0.6312\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6129 - accuracy: 0.6823 - val_loss: 0.6464 - val_accuracy: 0.6269\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6093 - accuracy: 0.6828 - val_loss: 0.6390 - val_accuracy: 0.6328\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 513us/step - loss: 0.6074 - accuracy: 0.6866 - val_loss: 0.6402 - val_accuracy: 0.6316\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6051 - accuracy: 0.6867 - val_loss: 0.6361 - val_accuracy: 0.6337\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6028 - accuracy: 0.6900 - val_loss: 0.6407 - val_accuracy: 0.6316\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6011 - accuracy: 0.6883 - val_loss: 0.6356 - val_accuracy: 0.6329\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.5991 - accuracy: 0.6935 - val_loss: 0.6352 - val_accuracy: 0.6326\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5970 - accuracy: 0.6910 - val_loss: 0.6236 - val_accuracy: 0.6402\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5945 - accuracy: 0.6961 - val_loss: 0.6296 - val_accuracy: 0.6346\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5928 - accuracy: 0.6968 - val_loss: 0.6254 - val_accuracy: 0.6362\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 496us/step - loss: 0.5905 - accuracy: 0.6990 - val_loss: 0.6247 - val_accuracy: 0.6367\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 516us/step - loss: 0.5885 - accuracy: 0.6991 - val_loss: 0.6260 - val_accuracy: 0.6359\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5878 - accuracy: 0.6999 - val_loss: 0.6282 - val_accuracy: 0.6352\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 512us/step - loss: 0.5862 - accuracy: 0.6995 - val_loss: 0.6234 - val_accuracy: 0.6380\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.5847 - accuracy: 0.7022 - val_loss: 0.6203 - val_accuracy: 0.6393\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5814 - accuracy: 0.7054 - val_loss: 0.6180 - val_accuracy: 0.6403\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.5807 - accuracy: 0.7033 - val_loss: 0.6215 - val_accuracy: 0.6378\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5791 - accuracy: 0.7054 - val_loss: 0.6222 - val_accuracy: 0.6360\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5777 - accuracy: 0.7057 - val_loss: 0.6161 - val_accuracy: 0.6409\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.5762 - accuracy: 0.7082 - val_loss: 0.6132 - val_accuracy: 0.6426\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5747 - accuracy: 0.7081 - val_loss: 0.6177 - val_accuracy: 0.6387\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5740 - accuracy: 0.7094 - val_loss: 0.6089 - val_accuracy: 0.6489\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 491us/step - loss: 0.5718 - accuracy: 0.7099 - val_loss: 0.6094 - val_accuracy: 0.6485\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.5707 - accuracy: 0.7105 - val_loss: 0.6092 - val_accuracy: 0.6498\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5691 - accuracy: 0.7108 - val_loss: 0.6195 - val_accuracy: 0.6378\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5680 - accuracy: 0.7112 - val_loss: 0.6163 - val_accuracy: 0.6422\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 505us/step - loss: 0.5671 - accuracy: 0.7128 - val_loss: 0.6159 - val_accuracy: 0.6443\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5647 - accuracy: 0.7145 - val_loss: 0.6197 - val_accuracy: 0.6395\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5641 - accuracy: 0.7158 - val_loss: 0.6087 - val_accuracy: 0.6489\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5624 - accuracy: 0.7165 - val_loss: 0.6067 - val_accuracy: 0.6507\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.5617 - accuracy: 0.7175 - val_loss: 0.6108 - val_accuracy: 0.6471\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 485us/step - loss: 0.5601 - accuracy: 0.7187 - val_loss: 0.6039 - val_accuracy: 0.6517\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 542us/step - loss: 0.5597 - accuracy: 0.7176 - val_loss: 0.6039 - val_accuracy: 0.6512\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 492us/step - loss: 0.5588 - accuracy: 0.7178 - val_loss: 0.6102 - val_accuracy: 0.6467\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5574 - accuracy: 0.7212 - val_loss: 0.6098 - val_accuracy: 0.6453\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5565 - accuracy: 0.7197 - val_loss: 0.6112 - val_accuracy: 0.6414\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.7267 - accuracy: 0.5167 - val_loss: 0.7324 - val_accuracy: 0.3982\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 503us/step - loss: 0.7040 - accuracy: 0.5433 - val_loss: 0.7185 - val_accuracy: 0.4082\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6913 - accuracy: 0.5637 - val_loss: 0.7097 - val_accuracy: 0.4120\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 489us/step - loss: 0.6791 - accuracy: 0.5843 - val_loss: 0.7041 - val_accuracy: 0.4243\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6702 - accuracy: 0.5998 - val_loss: 0.6905 - val_accuracy: 0.4727\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6610 - accuracy: 0.6160 - val_loss: 0.6831 - val_accuracy: 0.5053\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.6549 - accuracy: 0.6267 - val_loss: 0.6770 - val_accuracy: 0.5242\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6494 - accuracy: 0.6315 - val_loss: 0.6669 - val_accuracy: 0.5484\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.6447 - accuracy: 0.6426 - val_loss: 0.6647 - val_accuracy: 0.5599\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 497us/step - loss: 0.6399 - accuracy: 0.6452 - val_loss: 0.6617 - val_accuracy: 0.5675\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6355 - accuracy: 0.6521 - val_loss: 0.6588 - val_accuracy: 0.5739\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.6303 - accuracy: 0.6600 - val_loss: 0.6565 - val_accuracy: 0.5767\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6274 - accuracy: 0.6614 - val_loss: 0.6565 - val_accuracy: 0.5783\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 493us/step - loss: 0.6245 - accuracy: 0.6654 - val_loss: 0.6426 - val_accuracy: 0.5995\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6205 - accuracy: 0.6701 - val_loss: 0.6524 - val_accuracy: 0.5856\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 494us/step - loss: 0.6165 - accuracy: 0.6747 - val_loss: 0.6513 - val_accuracy: 0.5875\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6147 - accuracy: 0.6748 - val_loss: 0.6370 - val_accuracy: 0.6018\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6116 - accuracy: 0.6774 - val_loss: 0.6412 - val_accuracy: 0.5980\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6090 - accuracy: 0.6796 - val_loss: 0.6371 - val_accuracy: 0.6013\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 740us/step - loss: 0.6080 - accuracy: 0.6807 - val_loss: 0.6327 - val_accuracy: 0.6057\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6042 - accuracy: 0.6839 - val_loss: 0.6381 - val_accuracy: 0.6000\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 684us/step - loss: 0.6011 - accuracy: 0.6878 - val_loss: 0.6315 - val_accuracy: 0.6063\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5997 - accuracy: 0.6886 - val_loss: 0.6262 - val_accuracy: 0.6146\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5971 - accuracy: 0.6916 - val_loss: 0.6251 - val_accuracy: 0.6173\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.5954 - accuracy: 0.6923 - val_loss: 0.6237 - val_accuracy: 0.6201\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5926 - accuracy: 0.6941 - val_loss: 0.6303 - val_accuracy: 0.6107\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5924 - accuracy: 0.6923 - val_loss: 0.6205 - val_accuracy: 0.6273\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5901 - accuracy: 0.6948 - val_loss: 0.6207 - val_accuracy: 0.6276\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5882 - accuracy: 0.6983 - val_loss: 0.6282 - val_accuracy: 0.6167\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5857 - accuracy: 0.6991 - val_loss: 0.6202 - val_accuracy: 0.6304\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5839 - accuracy: 0.7017 - val_loss: 0.6160 - val_accuracy: 0.6371\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5816 - accuracy: 0.7036 - val_loss: 0.6194 - val_accuracy: 0.6329\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5816 - accuracy: 0.7021 - val_loss: 0.6187 - val_accuracy: 0.6341\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.5802 - accuracy: 0.7046 - val_loss: 0.6115 - val_accuracy: 0.6423\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5785 - accuracy: 0.7046 - val_loss: 0.6206 - val_accuracy: 0.6314\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5762 - accuracy: 0.7062 - val_loss: 0.6140 - val_accuracy: 0.6385\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5760 - accuracy: 0.7067 - val_loss: 0.6148 - val_accuracy: 0.6375\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5747 - accuracy: 0.7070 - val_loss: 0.6209 - val_accuracy: 0.6312\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.5723 - accuracy: 0.7089 - val_loss: 0.6121 - val_accuracy: 0.6416\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5708 - accuracy: 0.7108 - val_loss: 0.6161 - val_accuracy: 0.6368\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5690 - accuracy: 0.7113 - val_loss: 0.6089 - val_accuracy: 0.6428\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5684 - accuracy: 0.7116 - val_loss: 0.6059 - val_accuracy: 0.6450\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.5662 - accuracy: 0.7143 - val_loss: 0.6064 - val_accuracy: 0.6444\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.5659 - accuracy: 0.7146 - val_loss: 0.6052 - val_accuracy: 0.6460\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5633 - accuracy: 0.7156 - val_loss: 0.6074 - val_accuracy: 0.6429\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.5626 - accuracy: 0.7160 - val_loss: 0.6175 - val_accuracy: 0.6328\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5617 - accuracy: 0.7164 - val_loss: 0.6080 - val_accuracy: 0.6423\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.5600 - accuracy: 0.7165 - val_loss: 0.6069 - val_accuracy: 0.6428\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5593 - accuracy: 0.7182 - val_loss: 0.6060 - val_accuracy: 0.6429\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.5583 - accuracy: 0.7176 - val_loss: 0.6112 - val_accuracy: 0.6367\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6600 - accuracy: 0.6156 - val_loss: 0.6686 - val_accuracy: 0.5782\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6488 - accuracy: 0.6419 - val_loss: 0.6718 - val_accuracy: 0.5698\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6434 - accuracy: 0.6533 - val_loss: 0.6653 - val_accuracy: 0.5813\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6376 - accuracy: 0.6628 - val_loss: 0.6641 - val_accuracy: 0.5833\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6324 - accuracy: 0.6710 - val_loss: 0.6561 - val_accuracy: 0.5987\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6295 - accuracy: 0.6734 - val_loss: 0.6544 - val_accuracy: 0.6038\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6247 - accuracy: 0.6812 - val_loss: 0.6528 - val_accuracy: 0.6059\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6200 - accuracy: 0.6847 - val_loss: 0.6483 - val_accuracy: 0.6094\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6165 - accuracy: 0.6900 - val_loss: 0.6494 - val_accuracy: 0.6027\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6130 - accuracy: 0.6888 - val_loss: 0.6439 - val_accuracy: 0.6143\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6095 - accuracy: 0.6956 - val_loss: 0.6399 - val_accuracy: 0.6179\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.6062 - accuracy: 0.6967 - val_loss: 0.6360 - val_accuracy: 0.6213\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6029 - accuracy: 0.6974 - val_loss: 0.6306 - val_accuracy: 0.6295\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6018 - accuracy: 0.6990 - val_loss: 0.6375 - val_accuracy: 0.6155\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5976 - accuracy: 0.7016 - val_loss: 0.6280 - val_accuracy: 0.6305\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5962 - accuracy: 0.7017 - val_loss: 0.6320 - val_accuracy: 0.6238\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5938 - accuracy: 0.7045 - val_loss: 0.6282 - val_accuracy: 0.6293\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5918 - accuracy: 0.7063 - val_loss: 0.6171 - val_accuracy: 0.6441\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5899 - accuracy: 0.7056 - val_loss: 0.6281 - val_accuracy: 0.6286\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5887 - accuracy: 0.7065 - val_loss: 0.6221 - val_accuracy: 0.6370\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5851 - accuracy: 0.7092 - val_loss: 0.6203 - val_accuracy: 0.6383\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5838 - accuracy: 0.7095 - val_loss: 0.6180 - val_accuracy: 0.6399\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5823 - accuracy: 0.7118 - val_loss: 0.6235 - val_accuracy: 0.6344\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5811 - accuracy: 0.7131 - val_loss: 0.6081 - val_accuracy: 0.6479\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.5793 - accuracy: 0.7113 - val_loss: 0.6160 - val_accuracy: 0.6383\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5774 - accuracy: 0.7150 - val_loss: 0.6174 - val_accuracy: 0.6364\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.5759 - accuracy: 0.7147 - val_loss: 0.6144 - val_accuracy: 0.6381\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5747 - accuracy: 0.7149 - val_loss: 0.6086 - val_accuracy: 0.6469\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5737 - accuracy: 0.7147 - val_loss: 0.6181 - val_accuracy: 0.6351\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5710 - accuracy: 0.7167 - val_loss: 0.6142 - val_accuracy: 0.6405\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5701 - accuracy: 0.7169 - val_loss: 0.6176 - val_accuracy: 0.6365\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5691 - accuracy: 0.7180 - val_loss: 0.6150 - val_accuracy: 0.6394\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5688 - accuracy: 0.7180 - val_loss: 0.6172 - val_accuracy: 0.6368\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5664 - accuracy: 0.7179 - val_loss: 0.6124 - val_accuracy: 0.6434\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5657 - accuracy: 0.7186 - val_loss: 0.6138 - val_accuracy: 0.6419\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5644 - accuracy: 0.7204 - val_loss: 0.6139 - val_accuracy: 0.6419\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5623 - accuracy: 0.7198 - val_loss: 0.6073 - val_accuracy: 0.6501\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5619 - accuracy: 0.7220 - val_loss: 0.6094 - val_accuracy: 0.6469\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.5609 - accuracy: 0.7200 - val_loss: 0.6092 - val_accuracy: 0.6472\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.5592 - accuracy: 0.7222 - val_loss: 0.6039 - val_accuracy: 0.6528\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.5587 - accuracy: 0.7231 - val_loss: 0.6131 - val_accuracy: 0.6436\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5575 - accuracy: 0.7208 - val_loss: 0.6090 - val_accuracy: 0.6476\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5567 - accuracy: 0.7238 - val_loss: 0.6087 - val_accuracy: 0.6479\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.5557 - accuracy: 0.7260 - val_loss: 0.5997 - val_accuracy: 0.6553\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5537 - accuracy: 0.7257 - val_loss: 0.6057 - val_accuracy: 0.6502\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5535 - accuracy: 0.7242 - val_loss: 0.6026 - val_accuracy: 0.6527\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5529 - accuracy: 0.7254 - val_loss: 0.5996 - val_accuracy: 0.6547\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5520 - accuracy: 0.7247 - val_loss: 0.6149 - val_accuracy: 0.6393\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5508 - accuracy: 0.7258 - val_loss: 0.6108 - val_accuracy: 0.6443\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5486 - accuracy: 0.7267 - val_loss: 0.5990 - val_accuracy: 0.6542\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.7254 - accuracy: 0.5171 - val_loss: 0.7359 - val_accuracy: 0.2746\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.7022 - accuracy: 0.5227 - val_loss: 0.7023 - val_accuracy: 0.4858\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 538us/step - loss: 0.6942 - accuracy: 0.5397 - val_loss: 0.6941 - val_accuracy: 0.5550\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6880 - accuracy: 0.5482 - val_loss: 0.6914 - val_accuracy: 0.5717\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 518us/step - loss: 0.6813 - accuracy: 0.5643 - val_loss: 0.6870 - val_accuracy: 0.5894\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6760 - accuracy: 0.5787 - val_loss: 0.6846 - val_accuracy: 0.6020\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6682 - accuracy: 0.5926 - val_loss: 0.6807 - val_accuracy: 0.6105\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6605 - accuracy: 0.6106 - val_loss: 0.6732 - val_accuracy: 0.6284\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6573 - accuracy: 0.6171 - val_loss: 0.6697 - val_accuracy: 0.6324\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6526 - accuracy: 0.6264 - val_loss: 0.6675 - val_accuracy: 0.6347\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6468 - accuracy: 0.6330 - val_loss: 0.6622 - val_accuracy: 0.6451\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6415 - accuracy: 0.6448 - val_loss: 0.6568 - val_accuracy: 0.6524\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6370 - accuracy: 0.6521 - val_loss: 0.6532 - val_accuracy: 0.6549\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6334 - accuracy: 0.6562 - val_loss: 0.6532 - val_accuracy: 0.6493\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6297 - accuracy: 0.6630 - val_loss: 0.6501 - val_accuracy: 0.6513\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6267 - accuracy: 0.6662 - val_loss: 0.6434 - val_accuracy: 0.6591\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6230 - accuracy: 0.6716 - val_loss: 0.6407 - val_accuracy: 0.6612\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.6192 - accuracy: 0.6759 - val_loss: 0.6348 - val_accuracy: 0.6664\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6162 - accuracy: 0.6785 - val_loss: 0.6375 - val_accuracy: 0.6605\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6127 - accuracy: 0.6816 - val_loss: 0.6323 - val_accuracy: 0.6636\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6113 - accuracy: 0.6791 - val_loss: 0.6273 - val_accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6068 - accuracy: 0.6878 - val_loss: 0.6271 - val_accuracy: 0.6639\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6044 - accuracy: 0.6890 - val_loss: 0.6302 - val_accuracy: 0.6581\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6015 - accuracy: 0.6926 - val_loss: 0.6248 - val_accuracy: 0.6618\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5988 - accuracy: 0.6941 - val_loss: 0.6183 - val_accuracy: 0.6691\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5971 - accuracy: 0.6969 - val_loss: 0.6188 - val_accuracy: 0.6645\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.5938 - accuracy: 0.6996 - val_loss: 0.6108 - val_accuracy: 0.6721\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.5917 - accuracy: 0.7001 - val_loss: 0.6149 - val_accuracy: 0.6668\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5897 - accuracy: 0.7023 - val_loss: 0.6165 - val_accuracy: 0.6622\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5870 - accuracy: 0.7036 - val_loss: 0.6096 - val_accuracy: 0.6670\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5836 - accuracy: 0.7092 - val_loss: 0.6102 - val_accuracy: 0.6643\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 511us/step - loss: 0.5821 - accuracy: 0.7086 - val_loss: 0.6031 - val_accuracy: 0.6684\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5806 - accuracy: 0.7090 - val_loss: 0.6061 - val_accuracy: 0.6657\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5787 - accuracy: 0.7104 - val_loss: 0.6057 - val_accuracy: 0.6644\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.5756 - accuracy: 0.7129 - val_loss: 0.6015 - val_accuracy: 0.6655\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5734 - accuracy: 0.7137 - val_loss: 0.6054 - val_accuracy: 0.6617\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5725 - accuracy: 0.7146 - val_loss: 0.6068 - val_accuracy: 0.6600\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.5700 - accuracy: 0.7178 - val_loss: 0.6004 - val_accuracy: 0.6643\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5698 - accuracy: 0.7166 - val_loss: 0.6019 - val_accuracy: 0.6615\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5679 - accuracy: 0.7188 - val_loss: 0.5950 - val_accuracy: 0.6673\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5651 - accuracy: 0.7210 - val_loss: 0.6027 - val_accuracy: 0.6570\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5640 - accuracy: 0.7213 - val_loss: 0.5977 - val_accuracy: 0.6611\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5630 - accuracy: 0.7214 - val_loss: 0.5939 - val_accuracy: 0.6634\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5613 - accuracy: 0.7225 - val_loss: 0.6009 - val_accuracy: 0.6550\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.5594 - accuracy: 0.7238 - val_loss: 0.5968 - val_accuracy: 0.6589\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5583 - accuracy: 0.7244 - val_loss: 0.5959 - val_accuracy: 0.6586\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5568 - accuracy: 0.7256 - val_loss: 0.5883 - val_accuracy: 0.6644\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.5549 - accuracy: 0.7284 - val_loss: 0.6007 - val_accuracy: 0.6520\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5535 - accuracy: 0.7281 - val_loss: 0.5992 - val_accuracy: 0.6529\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5531 - accuracy: 0.7263 - val_loss: 0.5900 - val_accuracy: 0.6613\n",
      "\n",
      "Training model with sample_size_ratio=1, target_eps=1.0...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 5.05 iterated over 83600 steps satisfies differential privacy with eps = 0.167 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.5749999999999997 iterated over 83600 steps satisfies differential privacy with eps = 0.34 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.3375 iterated over 83600 steps satisfies differential privacy with eps = 0.763 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.71875 iterated over 83600 steps satisfies differential privacy with eps = 2.77 and delta = 1e-05.\n",
      "The optimal RDP order is 7.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.028125 iterated over 83600 steps satisfies differential privacy with eps = 1.22 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.1828124999999998 iterated over 83600 steps satisfies differential privacy with eps = 0.938 and delta = 1e-05.\n",
      "The optimal RDP order is 20.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.10546875 iterated over 83600 steps satisfies differential privacy with eps = 1.05 and delta = 1e-05.\n",
      "The optimal RDP order is 17.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.144140625 iterated over 83600 steps satisfies differential privacy with eps = 0.991 and delta = 1e-05.\n",
      "The optimal RDP order is 18.0.\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6944 - accuracy: 0.5315 - val_loss: 0.7016 - val_accuracy: 0.4764\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6866 - accuracy: 0.5499 - val_loss: 0.6982 - val_accuracy: 0.5121\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6808 - accuracy: 0.5661 - val_loss: 0.6935 - val_accuracy: 0.5416\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6760 - accuracy: 0.5767 - val_loss: 0.6900 - val_accuracy: 0.5529\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6710 - accuracy: 0.5912 - val_loss: 0.6839 - val_accuracy: 0.5651\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6660 - accuracy: 0.5998 - val_loss: 0.6830 - val_accuracy: 0.5672\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6619 - accuracy: 0.6113 - val_loss: 0.6770 - val_accuracy: 0.5749\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.6587 - accuracy: 0.6153 - val_loss: 0.6730 - val_accuracy: 0.5807\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6559 - accuracy: 0.6204 - val_loss: 0.6672 - val_accuracy: 0.5916\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6525 - accuracy: 0.6252 - val_loss: 0.6683 - val_accuracy: 0.5905\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.6487 - accuracy: 0.6322 - val_loss: 0.6618 - val_accuracy: 0.6030\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6448 - accuracy: 0.6371 - val_loss: 0.6609 - val_accuracy: 0.6035\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6415 - accuracy: 0.6405 - val_loss: 0.6604 - val_accuracy: 0.6060\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6393 - accuracy: 0.6436 - val_loss: 0.6530 - val_accuracy: 0.6176\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6367 - accuracy: 0.6476 - val_loss: 0.6503 - val_accuracy: 0.6211\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6333 - accuracy: 0.6490 - val_loss: 0.6439 - val_accuracy: 0.6278\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6316 - accuracy: 0.6524 - val_loss: 0.6477 - val_accuracy: 0.6247\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6283 - accuracy: 0.6558 - val_loss: 0.6419 - val_accuracy: 0.6310\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.6264 - accuracy: 0.6571 - val_loss: 0.6387 - val_accuracy: 0.6343\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6232 - accuracy: 0.6610 - val_loss: 0.6347 - val_accuracy: 0.6380\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6213 - accuracy: 0.6619 - val_loss: 0.6337 - val_accuracy: 0.6380\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 539us/step - loss: 0.6189 - accuracy: 0.6656 - val_loss: 0.6287 - val_accuracy: 0.6418\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6162 - accuracy: 0.6687 - val_loss: 0.6320 - val_accuracy: 0.6383\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6153 - accuracy: 0.6685 - val_loss: 0.6277 - val_accuracy: 0.6416\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 501us/step - loss: 0.6123 - accuracy: 0.6713 - val_loss: 0.6315 - val_accuracy: 0.6367\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 522us/step - loss: 0.6110 - accuracy: 0.6742 - val_loss: 0.6289 - val_accuracy: 0.6383\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6087 - accuracy: 0.6755 - val_loss: 0.6279 - val_accuracy: 0.6393\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 514us/step - loss: 0.6063 - accuracy: 0.6770 - val_loss: 0.6252 - val_accuracy: 0.6423\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6058 - accuracy: 0.6763 - val_loss: 0.6257 - val_accuracy: 0.6418\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 508us/step - loss: 0.6026 - accuracy: 0.6807 - val_loss: 0.6181 - val_accuracy: 0.6503\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6017 - accuracy: 0.6798 - val_loss: 0.6264 - val_accuracy: 0.6404\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.5991 - accuracy: 0.6834 - val_loss: 0.6189 - val_accuracy: 0.6480\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5981 - accuracy: 0.6829 - val_loss: 0.6252 - val_accuracy: 0.6422\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5963 - accuracy: 0.6866 - val_loss: 0.6194 - val_accuracy: 0.6465\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5945 - accuracy: 0.6866 - val_loss: 0.6154 - val_accuracy: 0.6496\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.5930 - accuracy: 0.6904 - val_loss: 0.6148 - val_accuracy: 0.6502\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.5911 - accuracy: 0.6924 - val_loss: 0.6188 - val_accuracy: 0.6461\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5897 - accuracy: 0.6916 - val_loss: 0.6120 - val_accuracy: 0.6553\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.5881 - accuracy: 0.6936 - val_loss: 0.6117 - val_accuracy: 0.6549\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5873 - accuracy: 0.6949 - val_loss: 0.6201 - val_accuracy: 0.6426\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5852 - accuracy: 0.6962 - val_loss: 0.6160 - val_accuracy: 0.6483\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.5831 - accuracy: 0.6986 - val_loss: 0.6101 - val_accuracy: 0.6559\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.5826 - accuracy: 0.7012 - val_loss: 0.6130 - val_accuracy: 0.6513\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5813 - accuracy: 0.7004 - val_loss: 0.6104 - val_accuracy: 0.6553\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5789 - accuracy: 0.7035 - val_loss: 0.6095 - val_accuracy: 0.6577\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5779 - accuracy: 0.7045 - val_loss: 0.6091 - val_accuracy: 0.6582\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 498us/step - loss: 0.5764 - accuracy: 0.7059 - val_loss: 0.6068 - val_accuracy: 0.6604\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5755 - accuracy: 0.7056 - val_loss: 0.6075 - val_accuracy: 0.6587\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5735 - accuracy: 0.7060 - val_loss: 0.6005 - val_accuracy: 0.6650\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5727 - accuracy: 0.7082 - val_loss: 0.6047 - val_accuracy: 0.6608\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6862 - accuracy: 0.5457 - val_loss: 0.6727 - val_accuracy: 0.6218\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6719 - accuracy: 0.5847 - val_loss: 0.6773 - val_accuracy: 0.6032\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 502us/step - loss: 0.6647 - accuracy: 0.6015 - val_loss: 0.6680 - val_accuracy: 0.6234\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6620 - accuracy: 0.6066 - val_loss: 0.6710 - val_accuracy: 0.6101\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 509us/step - loss: 0.6557 - accuracy: 0.6179 - val_loss: 0.6684 - val_accuracy: 0.6127\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6527 - accuracy: 0.6229 - val_loss: 0.6657 - val_accuracy: 0.6185\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 495us/step - loss: 0.6488 - accuracy: 0.6285 - val_loss: 0.6631 - val_accuracy: 0.6218\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6462 - accuracy: 0.6309 - val_loss: 0.6570 - val_accuracy: 0.6309\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.6425 - accuracy: 0.6354 - val_loss: 0.6570 - val_accuracy: 0.6305\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.6412 - accuracy: 0.6363 - val_loss: 0.6524 - val_accuracy: 0.6367\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.6392 - accuracy: 0.6396 - val_loss: 0.6552 - val_accuracy: 0.6298\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6368 - accuracy: 0.6437 - val_loss: 0.6507 - val_accuracy: 0.6368\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6332 - accuracy: 0.6483 - val_loss: 0.6473 - val_accuracy: 0.6413\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6312 - accuracy: 0.6503 - val_loss: 0.6474 - val_accuracy: 0.6386\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6291 - accuracy: 0.6502 - val_loss: 0.6404 - val_accuracy: 0.6514\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6261 - accuracy: 0.6540 - val_loss: 0.6447 - val_accuracy: 0.6415\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6244 - accuracy: 0.6562 - val_loss: 0.6443 - val_accuracy: 0.6406\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6222 - accuracy: 0.6603 - val_loss: 0.6370 - val_accuracy: 0.6517\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6201 - accuracy: 0.6608 - val_loss: 0.6319 - val_accuracy: 0.6575\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6186 - accuracy: 0.6623 - val_loss: 0.6361 - val_accuracy: 0.6497\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6166 - accuracy: 0.6642 - val_loss: 0.6305 - val_accuracy: 0.6569\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6142 - accuracy: 0.6652 - val_loss: 0.6244 - val_accuracy: 0.6632\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6122 - accuracy: 0.6687 - val_loss: 0.6329 - val_accuracy: 0.6502\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6104 - accuracy: 0.6691 - val_loss: 0.6309 - val_accuracy: 0.6529\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.6096 - accuracy: 0.6709 - val_loss: 0.6291 - val_accuracy: 0.6549\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6066 - accuracy: 0.6729 - val_loss: 0.6305 - val_accuracy: 0.6511\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6062 - accuracy: 0.6743 - val_loss: 0.6294 - val_accuracy: 0.6518\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6050 - accuracy: 0.6739 - val_loss: 0.6177 - val_accuracy: 0.6681\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6025 - accuracy: 0.6788 - val_loss: 0.6226 - val_accuracy: 0.6604\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6008 - accuracy: 0.6793 - val_loss: 0.6193 - val_accuracy: 0.6638\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.5994 - accuracy: 0.6811 - val_loss: 0.6182 - val_accuracy: 0.6635\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5975 - accuracy: 0.6826 - val_loss: 0.6189 - val_accuracy: 0.6606\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.5963 - accuracy: 0.6845 - val_loss: 0.6202 - val_accuracy: 0.6583\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5953 - accuracy: 0.6837 - val_loss: 0.6190 - val_accuracy: 0.6584\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5943 - accuracy: 0.6846 - val_loss: 0.6146 - val_accuracy: 0.6632\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5928 - accuracy: 0.6870 - val_loss: 0.6152 - val_accuracy: 0.6608\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5912 - accuracy: 0.6874 - val_loss: 0.6124 - val_accuracy: 0.6619\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5896 - accuracy: 0.6904 - val_loss: 0.6178 - val_accuracy: 0.6560\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.5877 - accuracy: 0.6929 - val_loss: 0.6119 - val_accuracy: 0.6608\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5876 - accuracy: 0.6932 - val_loss: 0.6112 - val_accuracy: 0.6616\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.5856 - accuracy: 0.6934 - val_loss: 0.6151 - val_accuracy: 0.6575\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.5853 - accuracy: 0.6953 - val_loss: 0.6111 - val_accuracy: 0.6604\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.5838 - accuracy: 0.6951 - val_loss: 0.6125 - val_accuracy: 0.6581\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5823 - accuracy: 0.6971 - val_loss: 0.6099 - val_accuracy: 0.6593\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.5805 - accuracy: 0.6971 - val_loss: 0.6065 - val_accuracy: 0.6624\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5804 - accuracy: 0.6974 - val_loss: 0.6120 - val_accuracy: 0.6555\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5783 - accuracy: 0.6990 - val_loss: 0.6130 - val_accuracy: 0.6539\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5762 - accuracy: 0.7015 - val_loss: 0.6084 - val_accuracy: 0.6590\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.5760 - accuracy: 0.7014 - val_loss: 0.6032 - val_accuracy: 0.6647\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5743 - accuracy: 0.7034 - val_loss: 0.6011 - val_accuracy: 0.6659\n",
      "Epoch 1/50\n",
      "   1/1672 [..............................] - ETA: 0s - loss: 0.9347 - accuracy: 0.4062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.7090 - accuracy: 0.5454 - val_loss: 0.7588 - val_accuracy: 0.3195\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6753 - accuracy: 0.5842 - val_loss: 0.7115 - val_accuracy: 0.4733\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6681 - accuracy: 0.6038 - val_loss: 0.6969 - val_accuracy: 0.5142\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.6623 - accuracy: 0.6123 - val_loss: 0.6916 - val_accuracy: 0.5341\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6578 - accuracy: 0.6246 - val_loss: 0.6846 - val_accuracy: 0.5566\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6531 - accuracy: 0.6317 - val_loss: 0.6830 - val_accuracy: 0.5611\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6492 - accuracy: 0.6403 - val_loss: 0.6773 - val_accuracy: 0.5716\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6451 - accuracy: 0.6460 - val_loss: 0.6747 - val_accuracy: 0.5755\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6424 - accuracy: 0.6487 - val_loss: 0.6685 - val_accuracy: 0.5850\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6387 - accuracy: 0.6530 - val_loss: 0.6663 - val_accuracy: 0.5872\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6358 - accuracy: 0.6576 - val_loss: 0.6606 - val_accuracy: 0.5976\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6328 - accuracy: 0.6623 - val_loss: 0.6572 - val_accuracy: 0.6042\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6304 - accuracy: 0.6645 - val_loss: 0.6490 - val_accuracy: 0.6195\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6269 - accuracy: 0.6667 - val_loss: 0.6469 - val_accuracy: 0.6240\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6238 - accuracy: 0.6704 - val_loss: 0.6460 - val_accuracy: 0.6268\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.6209 - accuracy: 0.6733 - val_loss: 0.6415 - val_accuracy: 0.6313\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6185 - accuracy: 0.6775 - val_loss: 0.6352 - val_accuracy: 0.6385\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6167 - accuracy: 0.6787 - val_loss: 0.6447 - val_accuracy: 0.6263\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6145 - accuracy: 0.6782 - val_loss: 0.6378 - val_accuracy: 0.6328\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6123 - accuracy: 0.6828 - val_loss: 0.6392 - val_accuracy: 0.6312\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6106 - accuracy: 0.6840 - val_loss: 0.6337 - val_accuracy: 0.6357\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6079 - accuracy: 0.6865 - val_loss: 0.6363 - val_accuracy: 0.6333\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6076 - accuracy: 0.6876 - val_loss: 0.6331 - val_accuracy: 0.6347\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6047 - accuracy: 0.6898 - val_loss: 0.6315 - val_accuracy: 0.6346\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6026 - accuracy: 0.6922 - val_loss: 0.6304 - val_accuracy: 0.6356\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6014 - accuracy: 0.6930 - val_loss: 0.6296 - val_accuracy: 0.6359\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.5999 - accuracy: 0.6961 - val_loss: 0.6266 - val_accuracy: 0.6389\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.5988 - accuracy: 0.6952 - val_loss: 0.6318 - val_accuracy: 0.6323\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5968 - accuracy: 0.6981 - val_loss: 0.6291 - val_accuracy: 0.6357\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.5954 - accuracy: 0.6994 - val_loss: 0.6240 - val_accuracy: 0.6408\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5934 - accuracy: 0.6997 - val_loss: 0.6258 - val_accuracy: 0.6386\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5914 - accuracy: 0.6999 - val_loss: 0.6273 - val_accuracy: 0.6363\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5907 - accuracy: 0.7016 - val_loss: 0.6241 - val_accuracy: 0.6392\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5892 - accuracy: 0.7043 - val_loss: 0.6239 - val_accuracy: 0.6368\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.5869 - accuracy: 0.7055 - val_loss: 0.6202 - val_accuracy: 0.6397\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5864 - accuracy: 0.7061 - val_loss: 0.6151 - val_accuracy: 0.6444\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5847 - accuracy: 0.7066 - val_loss: 0.6163 - val_accuracy: 0.6428\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5827 - accuracy: 0.7088 - val_loss: 0.6215 - val_accuracy: 0.6373\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.5818 - accuracy: 0.7084 - val_loss: 0.6119 - val_accuracy: 0.6458\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5804 - accuracy: 0.7114 - val_loss: 0.6223 - val_accuracy: 0.6371\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 520us/step - loss: 0.5789 - accuracy: 0.7109 - val_loss: 0.6170 - val_accuracy: 0.6418\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5784 - accuracy: 0.7120 - val_loss: 0.6163 - val_accuracy: 0.6424\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5772 - accuracy: 0.7128 - val_loss: 0.6207 - val_accuracy: 0.6380\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.5758 - accuracy: 0.7121 - val_loss: 0.6176 - val_accuracy: 0.6416\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5733 - accuracy: 0.7138 - val_loss: 0.6161 - val_accuracy: 0.6424\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5731 - accuracy: 0.7131 - val_loss: 0.6136 - val_accuracy: 0.6449\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5713 - accuracy: 0.7147 - val_loss: 0.6152 - val_accuracy: 0.6437\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5707 - accuracy: 0.7142 - val_loss: 0.6187 - val_accuracy: 0.6404\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5696 - accuracy: 0.7165 - val_loss: 0.6061 - val_accuracy: 0.6516\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5684 - accuracy: 0.7173 - val_loss: 0.6132 - val_accuracy: 0.6449\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.7357 - accuracy: 0.5170 - val_loss: 0.7703 - val_accuracy: 0.1379\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.7002 - accuracy: 0.5173 - val_loss: 0.7244 - val_accuracy: 0.2800\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6924 - accuracy: 0.5372 - val_loss: 0.7192 - val_accuracy: 0.3364\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6883 - accuracy: 0.5529 - val_loss: 0.7144 - val_accuracy: 0.4074\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6845 - accuracy: 0.5646 - val_loss: 0.7072 - val_accuracy: 0.4482\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6788 - accuracy: 0.5787 - val_loss: 0.7037 - val_accuracy: 0.4761\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6746 - accuracy: 0.5921 - val_loss: 0.7030 - val_accuracy: 0.4809\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6703 - accuracy: 0.6041 - val_loss: 0.6943 - val_accuracy: 0.5117\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6658 - accuracy: 0.6130 - val_loss: 0.6906 - val_accuracy: 0.5211\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6637 - accuracy: 0.6195 - val_loss: 0.6906 - val_accuracy: 0.5214\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 517us/step - loss: 0.6602 - accuracy: 0.6272 - val_loss: 0.6865 - val_accuracy: 0.5312\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.6564 - accuracy: 0.6359 - val_loss: 0.6811 - val_accuracy: 0.5447\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 519us/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6784 - val_accuracy: 0.5516\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6498 - accuracy: 0.6476 - val_loss: 0.6750 - val_accuracy: 0.5639\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.6457 - accuracy: 0.6541 - val_loss: 0.6721 - val_accuracy: 0.5706\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6426 - accuracy: 0.6578 - val_loss: 0.6659 - val_accuracy: 0.5831\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6396 - accuracy: 0.6647 - val_loss: 0.6716 - val_accuracy: 0.5730\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6369 - accuracy: 0.6650 - val_loss: 0.6634 - val_accuracy: 0.5841\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6336 - accuracy: 0.6671 - val_loss: 0.6623 - val_accuracy: 0.5844\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6309 - accuracy: 0.6701 - val_loss: 0.6611 - val_accuracy: 0.5859\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6274 - accuracy: 0.6748 - val_loss: 0.6561 - val_accuracy: 0.5922\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6254 - accuracy: 0.6750 - val_loss: 0.6563 - val_accuracy: 0.5910\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6225 - accuracy: 0.6791 - val_loss: 0.6521 - val_accuracy: 0.5962\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6193 - accuracy: 0.6815 - val_loss: 0.6489 - val_accuracy: 0.6002\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6170 - accuracy: 0.6826 - val_loss: 0.6407 - val_accuracy: 0.6127\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6147 - accuracy: 0.6846 - val_loss: 0.6540 - val_accuracy: 0.5892\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6125 - accuracy: 0.6854 - val_loss: 0.6532 - val_accuracy: 0.5887\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 507us/step - loss: 0.6102 - accuracy: 0.6883 - val_loss: 0.6432 - val_accuracy: 0.6064\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6073 - accuracy: 0.6918 - val_loss: 0.6472 - val_accuracy: 0.5980\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6049 - accuracy: 0.6918 - val_loss: 0.6403 - val_accuracy: 0.6086\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.6032 - accuracy: 0.6930 - val_loss: 0.6401 - val_accuracy: 0.6078\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6010 - accuracy: 0.6937 - val_loss: 0.6343 - val_accuracy: 0.6150\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 523us/step - loss: 0.5982 - accuracy: 0.6970 - val_loss: 0.6352 - val_accuracy: 0.6131\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5956 - accuracy: 0.6975 - val_loss: 0.6416 - val_accuracy: 0.6037\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.5948 - accuracy: 0.6976 - val_loss: 0.6363 - val_accuracy: 0.6107\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 515us/step - loss: 0.5925 - accuracy: 0.7005 - val_loss: 0.6309 - val_accuracy: 0.6173\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.5901 - accuracy: 0.7024 - val_loss: 0.6209 - val_accuracy: 0.6293\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5893 - accuracy: 0.7015 - val_loss: 0.6271 - val_accuracy: 0.6208\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5859 - accuracy: 0.7060 - val_loss: 0.6226 - val_accuracy: 0.6265\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5849 - accuracy: 0.7047 - val_loss: 0.6237 - val_accuracy: 0.6257\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5822 - accuracy: 0.7069 - val_loss: 0.6255 - val_accuracy: 0.6234\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5808 - accuracy: 0.7065 - val_loss: 0.6220 - val_accuracy: 0.6276\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5791 - accuracy: 0.7086 - val_loss: 0.6134 - val_accuracy: 0.6352\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.5766 - accuracy: 0.7130 - val_loss: 0.6182 - val_accuracy: 0.6304\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5757 - accuracy: 0.7111 - val_loss: 0.6233 - val_accuracy: 0.6249\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5731 - accuracy: 0.7133 - val_loss: 0.6140 - val_accuracy: 0.6336\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 530us/step - loss: 0.5719 - accuracy: 0.7149 - val_loss: 0.6112 - val_accuracy: 0.6361\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.5703 - accuracy: 0.7138 - val_loss: 0.6109 - val_accuracy: 0.6357\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5684 - accuracy: 0.7159 - val_loss: 0.6137 - val_accuracy: 0.6336\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5675 - accuracy: 0.7180 - val_loss: 0.6144 - val_accuracy: 0.6319\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.7347 - accuracy: 0.5024 - val_loss: 0.7548 - val_accuracy: 0.2454\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.7073 - accuracy: 0.5043 - val_loss: 0.7150 - val_accuracy: 0.3983\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6969 - accuracy: 0.5237 - val_loss: 0.7019 - val_accuracy: 0.4949\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6895 - accuracy: 0.5436 - val_loss: 0.6941 - val_accuracy: 0.5383\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6831 - accuracy: 0.5621 - val_loss: 0.6908 - val_accuracy: 0.5641\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6749 - accuracy: 0.5805 - val_loss: 0.6811 - val_accuracy: 0.5950\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.6695 - accuracy: 0.5919 - val_loss: 0.6786 - val_accuracy: 0.6050\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6630 - accuracy: 0.6066 - val_loss: 0.6728 - val_accuracy: 0.6132\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6570 - accuracy: 0.6214 - val_loss: 0.6686 - val_accuracy: 0.6193\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.6521 - accuracy: 0.6304 - val_loss: 0.6675 - val_accuracy: 0.6173\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.6480 - accuracy: 0.6359 - val_loss: 0.6620 - val_accuracy: 0.6269\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6438 - accuracy: 0.6412 - val_loss: 0.6568 - val_accuracy: 0.6349\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.6410 - accuracy: 0.6432 - val_loss: 0.6582 - val_accuracy: 0.6282\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6371 - accuracy: 0.6484 - val_loss: 0.6483 - val_accuracy: 0.6458\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6347 - accuracy: 0.6502 - val_loss: 0.6484 - val_accuracy: 0.6418\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6311 - accuracy: 0.6557 - val_loss: 0.6446 - val_accuracy: 0.6475\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6279 - accuracy: 0.6582 - val_loss: 0.6429 - val_accuracy: 0.6474\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.6262 - accuracy: 0.6608 - val_loss: 0.6371 - val_accuracy: 0.6552\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 544us/step - loss: 0.6231 - accuracy: 0.6623 - val_loss: 0.6401 - val_accuracy: 0.6464\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6202 - accuracy: 0.6658 - val_loss: 0.6354 - val_accuracy: 0.6495\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6181 - accuracy: 0.6680 - val_loss: 0.6343 - val_accuracy: 0.6496\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6151 - accuracy: 0.6699 - val_loss: 0.6303 - val_accuracy: 0.6551\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6140 - accuracy: 0.6706 - val_loss: 0.6293 - val_accuracy: 0.6555\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.6110 - accuracy: 0.6729 - val_loss: 0.6261 - val_accuracy: 0.6592\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6091 - accuracy: 0.6758 - val_loss: 0.6203 - val_accuracy: 0.6639\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 524us/step - loss: 0.6071 - accuracy: 0.6790 - val_loss: 0.6244 - val_accuracy: 0.6590\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6045 - accuracy: 0.6805 - val_loss: 0.6264 - val_accuracy: 0.6547\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6039 - accuracy: 0.6818 - val_loss: 0.6224 - val_accuracy: 0.6584\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6011 - accuracy: 0.6816 - val_loss: 0.6179 - val_accuracy: 0.6613\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6007 - accuracy: 0.6826 - val_loss: 0.6214 - val_accuracy: 0.6576\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5984 - accuracy: 0.6841 - val_loss: 0.6150 - val_accuracy: 0.6622\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.5963 - accuracy: 0.6870 - val_loss: 0.6184 - val_accuracy: 0.6582\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5948 - accuracy: 0.6892 - val_loss: 0.6147 - val_accuracy: 0.6607\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.5938 - accuracy: 0.6908 - val_loss: 0.6102 - val_accuracy: 0.6626\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 521us/step - loss: 0.5921 - accuracy: 0.6924 - val_loss: 0.6151 - val_accuracy: 0.6574\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.5911 - accuracy: 0.6908 - val_loss: 0.6092 - val_accuracy: 0.6624\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5884 - accuracy: 0.6950 - val_loss: 0.6139 - val_accuracy: 0.6581\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5868 - accuracy: 0.6968 - val_loss: 0.6070 - val_accuracy: 0.6626\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5865 - accuracy: 0.6939 - val_loss: 0.6122 - val_accuracy: 0.6583\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 527us/step - loss: 0.5845 - accuracy: 0.7013 - val_loss: 0.6087 - val_accuracy: 0.6607\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5830 - accuracy: 0.7015 - val_loss: 0.6089 - val_accuracy: 0.6608\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 553us/step - loss: 0.5817 - accuracy: 0.7016 - val_loss: 0.6122 - val_accuracy: 0.6586\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5806 - accuracy: 0.7022 - val_loss: 0.6075 - val_accuracy: 0.6616\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5791 - accuracy: 0.7031 - val_loss: 0.6069 - val_accuracy: 0.6614\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.5782 - accuracy: 0.7040 - val_loss: 0.6029 - val_accuracy: 0.6636\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5770 - accuracy: 0.7058 - val_loss: 0.5995 - val_accuracy: 0.6656\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.5758 - accuracy: 0.7054 - val_loss: 0.6033 - val_accuracy: 0.6624\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 630us/step - loss: 0.5752 - accuracy: 0.7076 - val_loss: 0.6094 - val_accuracy: 0.6574\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.5729 - accuracy: 0.7103 - val_loss: 0.6022 - val_accuracy: 0.6619\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.5727 - accuracy: 0.7080 - val_loss: 0.6018 - val_accuracy: 0.6618\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.7059 - accuracy: 0.4882 - val_loss: 0.7222 - val_accuracy: 0.2752\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6989 - accuracy: 0.5065 - val_loss: 0.7188 - val_accuracy: 0.3010\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6899 - accuracy: 0.5364 - val_loss: 0.7116 - val_accuracy: 0.3613\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6849 - accuracy: 0.5504 - val_loss: 0.7083 - val_accuracy: 0.4341\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6801 - accuracy: 0.5624 - val_loss: 0.7021 - val_accuracy: 0.4832\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6774 - accuracy: 0.5714 - val_loss: 0.6974 - val_accuracy: 0.5129\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6729 - accuracy: 0.5832 - val_loss: 0.6916 - val_accuracy: 0.5451\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6697 - accuracy: 0.5941 - val_loss: 0.6888 - val_accuracy: 0.5699\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6664 - accuracy: 0.6008 - val_loss: 0.6852 - val_accuracy: 0.5828\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6627 - accuracy: 0.6073 - val_loss: 0.6853 - val_accuracy: 0.5757\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6595 - accuracy: 0.6155 - val_loss: 0.6789 - val_accuracy: 0.5938\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6568 - accuracy: 0.6207 - val_loss: 0.6779 - val_accuracy: 0.5928\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6552 - accuracy: 0.6263 - val_loss: 0.6782 - val_accuracy: 0.5886\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6520 - accuracy: 0.6281 - val_loss: 0.6721 - val_accuracy: 0.5977\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6486 - accuracy: 0.6355 - val_loss: 0.6679 - val_accuracy: 0.6054\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6452 - accuracy: 0.6415 - val_loss: 0.6646 - val_accuracy: 0.6141\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6424 - accuracy: 0.6429 - val_loss: 0.6630 - val_accuracy: 0.6190\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.6396 - accuracy: 0.6452 - val_loss: 0.6556 - val_accuracy: 0.6334\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6377 - accuracy: 0.6495 - val_loss: 0.6582 - val_accuracy: 0.6266\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6339 - accuracy: 0.6527 - val_loss: 0.6532 - val_accuracy: 0.6355\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6321 - accuracy: 0.6542 - val_loss: 0.6485 - val_accuracy: 0.6450\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6288 - accuracy: 0.6586 - val_loss: 0.6463 - val_accuracy: 0.6509\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 628us/step - loss: 0.6272 - accuracy: 0.6580 - val_loss: 0.6439 - val_accuracy: 0.6547\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6247 - accuracy: 0.6616 - val_loss: 0.6408 - val_accuracy: 0.6610\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.6226 - accuracy: 0.6627 - val_loss: 0.6397 - val_accuracy: 0.6612\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6205 - accuracy: 0.6644 - val_loss: 0.6400 - val_accuracy: 0.6592\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6183 - accuracy: 0.6675 - val_loss: 0.6362 - val_accuracy: 0.6622\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6148 - accuracy: 0.6724 - val_loss: 0.6350 - val_accuracy: 0.6622\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.6136 - accuracy: 0.6685 - val_loss: 0.6306 - val_accuracy: 0.6647\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6110 - accuracy: 0.6732 - val_loss: 0.6348 - val_accuracy: 0.6603\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6097 - accuracy: 0.6731 - val_loss: 0.6305 - val_accuracy: 0.6623\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.6076 - accuracy: 0.6757 - val_loss: 0.6288 - val_accuracy: 0.6632\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 607us/step - loss: 0.6056 - accuracy: 0.6779 - val_loss: 0.6279 - val_accuracy: 0.6625\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6037 - accuracy: 0.6793 - val_loss: 0.6260 - val_accuracy: 0.6626\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.6022 - accuracy: 0.6805 - val_loss: 0.6232 - val_accuracy: 0.6621\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6004 - accuracy: 0.6820 - val_loss: 0.6247 - val_accuracy: 0.6598\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5989 - accuracy: 0.6838 - val_loss: 0.6205 - val_accuracy: 0.6607\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.5973 - accuracy: 0.6840 - val_loss: 0.6188 - val_accuracy: 0.6601\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.5963 - accuracy: 0.6848 - val_loss: 0.6189 - val_accuracy: 0.6594\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5939 - accuracy: 0.6857 - val_loss: 0.6213 - val_accuracy: 0.6558\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.5930 - accuracy: 0.6879 - val_loss: 0.6216 - val_accuracy: 0.6547\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.5915 - accuracy: 0.6878 - val_loss: 0.6199 - val_accuracy: 0.6552\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.5896 - accuracy: 0.6925 - val_loss: 0.6151 - val_accuracy: 0.6582\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5881 - accuracy: 0.6915 - val_loss: 0.6157 - val_accuracy: 0.6571\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.5870 - accuracy: 0.6919 - val_loss: 0.6177 - val_accuracy: 0.6552\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.5857 - accuracy: 0.6923 - val_loss: 0.6204 - val_accuracy: 0.6531\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.5844 - accuracy: 0.6944 - val_loss: 0.6156 - val_accuracy: 0.6569\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.5822 - accuracy: 0.6973 - val_loss: 0.6144 - val_accuracy: 0.6576\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5808 - accuracy: 0.6985 - val_loss: 0.6127 - val_accuracy: 0.6583\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5805 - accuracy: 0.6983 - val_loss: 0.6128 - val_accuracy: 0.6575\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.7153 - accuracy: 0.5027 - val_loss: 0.6938 - val_accuracy: 0.5148\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6914 - accuracy: 0.5356 - val_loss: 0.6968 - val_accuracy: 0.5164\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6797 - accuracy: 0.5592 - val_loss: 0.6859 - val_accuracy: 0.5803\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6715 - accuracy: 0.5779 - val_loss: 0.6863 - val_accuracy: 0.5897\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6659 - accuracy: 0.5903 - val_loss: 0.6741 - val_accuracy: 0.6272\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6599 - accuracy: 0.6032 - val_loss: 0.6700 - val_accuracy: 0.6287\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6540 - accuracy: 0.6173 - val_loss: 0.6621 - val_accuracy: 0.6420\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.6511 - accuracy: 0.6208 - val_loss: 0.6618 - val_accuracy: 0.6378\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.6459 - accuracy: 0.6299 - val_loss: 0.6569 - val_accuracy: 0.6434\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6423 - accuracy: 0.6364 - val_loss: 0.6581 - val_accuracy: 0.6364\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 626us/step - loss: 0.6389 - accuracy: 0.6417 - val_loss: 0.6505 - val_accuracy: 0.6471\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.6366 - accuracy: 0.6434 - val_loss: 0.6536 - val_accuracy: 0.6371\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6337 - accuracy: 0.6488 - val_loss: 0.6426 - val_accuracy: 0.6509\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6306 - accuracy: 0.6525 - val_loss: 0.6445 - val_accuracy: 0.6445\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6290 - accuracy: 0.6539 - val_loss: 0.6389 - val_accuracy: 0.6518\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6263 - accuracy: 0.6590 - val_loss: 0.6398 - val_accuracy: 0.6462\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 549us/step - loss: 0.6233 - accuracy: 0.6622 - val_loss: 0.6447 - val_accuracy: 0.6351\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6201 - accuracy: 0.6663 - val_loss: 0.6340 - val_accuracy: 0.6493\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6191 - accuracy: 0.6664 - val_loss: 0.6336 - val_accuracy: 0.6477\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 551us/step - loss: 0.6171 - accuracy: 0.6700 - val_loss: 0.6310 - val_accuracy: 0.6508\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6141 - accuracy: 0.6699 - val_loss: 0.6317 - val_accuracy: 0.6480\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6130 - accuracy: 0.6736 - val_loss: 0.6347 - val_accuracy: 0.6427\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6099 - accuracy: 0.6759 - val_loss: 0.6279 - val_accuracy: 0.6519\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6079 - accuracy: 0.6768 - val_loss: 0.6295 - val_accuracy: 0.6488\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6056 - accuracy: 0.6802 - val_loss: 0.6311 - val_accuracy: 0.6445\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 541us/step - loss: 0.6036 - accuracy: 0.6826 - val_loss: 0.6340 - val_accuracy: 0.6391\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6037 - accuracy: 0.6838 - val_loss: 0.6229 - val_accuracy: 0.6491\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5997 - accuracy: 0.6873 - val_loss: 0.6211 - val_accuracy: 0.6500\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5985 - accuracy: 0.6874 - val_loss: 0.6243 - val_accuracy: 0.6443\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5968 - accuracy: 0.6902 - val_loss: 0.6211 - val_accuracy: 0.6458\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5947 - accuracy: 0.6927 - val_loss: 0.6272 - val_accuracy: 0.6367\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5928 - accuracy: 0.6940 - val_loss: 0.6192 - val_accuracy: 0.6464\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5916 - accuracy: 0.6956 - val_loss: 0.6214 - val_accuracy: 0.6418\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 548us/step - loss: 0.5892 - accuracy: 0.6962 - val_loss: 0.6218 - val_accuracy: 0.6404\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5884 - accuracy: 0.6965 - val_loss: 0.6125 - val_accuracy: 0.6534\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5867 - accuracy: 0.6964 - val_loss: 0.6201 - val_accuracy: 0.6438\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5841 - accuracy: 0.7014 - val_loss: 0.6216 - val_accuracy: 0.6403\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5832 - accuracy: 0.7026 - val_loss: 0.6128 - val_accuracy: 0.6498\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5815 - accuracy: 0.7022 - val_loss: 0.6134 - val_accuracy: 0.6469\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5802 - accuracy: 0.7028 - val_loss: 0.6131 - val_accuracy: 0.6471\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5790 - accuracy: 0.7057 - val_loss: 0.6159 - val_accuracy: 0.6431\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 547us/step - loss: 0.5769 - accuracy: 0.7063 - val_loss: 0.6129 - val_accuracy: 0.6455\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5749 - accuracy: 0.7094 - val_loss: 0.6099 - val_accuracy: 0.6468\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5740 - accuracy: 0.7095 - val_loss: 0.6081 - val_accuracy: 0.6483\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5726 - accuracy: 0.7091 - val_loss: 0.6160 - val_accuracy: 0.6395\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.5706 - accuracy: 0.7104 - val_loss: 0.6088 - val_accuracy: 0.6469\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5701 - accuracy: 0.7111 - val_loss: 0.6103 - val_accuracy: 0.6439\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.5681 - accuracy: 0.7142 - val_loss: 0.6031 - val_accuracy: 0.6543\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 537us/step - loss: 0.5670 - accuracy: 0.7133 - val_loss: 0.6039 - val_accuracy: 0.6534\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5658 - accuracy: 0.7136 - val_loss: 0.6027 - val_accuracy: 0.6543\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.6927 - accuracy: 0.5440 - val_loss: 0.6983 - val_accuracy: 0.5148\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6811 - accuracy: 0.5657 - val_loss: 0.6912 - val_accuracy: 0.5517\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6681 - accuracy: 0.5872 - val_loss: 0.6759 - val_accuracy: 0.6000\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 543us/step - loss: 0.6605 - accuracy: 0.6021 - val_loss: 0.6753 - val_accuracy: 0.5984\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6535 - accuracy: 0.6152 - val_loss: 0.6723 - val_accuracy: 0.6022\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6473 - accuracy: 0.6268 - val_loss: 0.6570 - val_accuracy: 0.6333\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6421 - accuracy: 0.6343 - val_loss: 0.6562 - val_accuracy: 0.6290\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 545us/step - loss: 0.6360 - accuracy: 0.6402 - val_loss: 0.6552 - val_accuracy: 0.6244\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6323 - accuracy: 0.6474 - val_loss: 0.6479 - val_accuracy: 0.6359\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.6278 - accuracy: 0.6540 - val_loss: 0.6456 - val_accuracy: 0.6350\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6232 - accuracy: 0.6598 - val_loss: 0.6455 - val_accuracy: 0.6311\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6199 - accuracy: 0.6659 - val_loss: 0.6430 - val_accuracy: 0.6332\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6178 - accuracy: 0.6656 - val_loss: 0.6417 - val_accuracy: 0.6337\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 534us/step - loss: 0.6145 - accuracy: 0.6704 - val_loss: 0.6328 - val_accuracy: 0.6496\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6112 - accuracy: 0.6746 - val_loss: 0.6357 - val_accuracy: 0.6416\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6086 - accuracy: 0.6796 - val_loss: 0.6364 - val_accuracy: 0.6391\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6064 - accuracy: 0.6805 - val_loss: 0.6315 - val_accuracy: 0.6462\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.6035 - accuracy: 0.6839 - val_loss: 0.6286 - val_accuracy: 0.6498\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6026 - accuracy: 0.6815 - val_loss: 0.6246 - val_accuracy: 0.6533\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5994 - accuracy: 0.6866 - val_loss: 0.6266 - val_accuracy: 0.6500\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 608us/step - loss: 0.5965 - accuracy: 0.6909 - val_loss: 0.6276 - val_accuracy: 0.6483\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 525us/step - loss: 0.5941 - accuracy: 0.6933 - val_loss: 0.6185 - val_accuracy: 0.6565\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5924 - accuracy: 0.6934 - val_loss: 0.6246 - val_accuracy: 0.6487\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 566us/step - loss: 0.5903 - accuracy: 0.6948 - val_loss: 0.6178 - val_accuracy: 0.6550\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.5879 - accuracy: 0.6992 - val_loss: 0.6148 - val_accuracy: 0.6558\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 532us/step - loss: 0.5866 - accuracy: 0.6983 - val_loss: 0.6158 - val_accuracy: 0.6539\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5851 - accuracy: 0.7009 - val_loss: 0.6098 - val_accuracy: 0.6601\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5825 - accuracy: 0.7021 - val_loss: 0.6159 - val_accuracy: 0.6521\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5828 - accuracy: 0.7034 - val_loss: 0.6125 - val_accuracy: 0.6562\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5801 - accuracy: 0.7040 - val_loss: 0.6154 - val_accuracy: 0.6527\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5781 - accuracy: 0.7073 - val_loss: 0.6120 - val_accuracy: 0.6569\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.5772 - accuracy: 0.7093 - val_loss: 0.6139 - val_accuracy: 0.6540\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5761 - accuracy: 0.7085 - val_loss: 0.6145 - val_accuracy: 0.6539\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5746 - accuracy: 0.7102 - val_loss: 0.6147 - val_accuracy: 0.6535\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5732 - accuracy: 0.7115 - val_loss: 0.6108 - val_accuracy: 0.6564\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5703 - accuracy: 0.7163 - val_loss: 0.6069 - val_accuracy: 0.6608\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.5699 - accuracy: 0.7160 - val_loss: 0.6035 - val_accuracy: 0.6644\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5682 - accuracy: 0.7138 - val_loss: 0.6094 - val_accuracy: 0.6582\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.5666 - accuracy: 0.7157 - val_loss: 0.6126 - val_accuracy: 0.6542\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 535us/step - loss: 0.5646 - accuracy: 0.7176 - val_loss: 0.6072 - val_accuracy: 0.6585\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5632 - accuracy: 0.7200 - val_loss: 0.6017 - val_accuracy: 0.6639\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.5622 - accuracy: 0.7201 - val_loss: 0.6087 - val_accuracy: 0.6550\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 615us/step - loss: 0.5619 - accuracy: 0.7197 - val_loss: 0.5956 - val_accuracy: 0.6675\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.5605 - accuracy: 0.7209 - val_loss: 0.6037 - val_accuracy: 0.6586\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5588 - accuracy: 0.7210 - val_loss: 0.6059 - val_accuracy: 0.6572\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5580 - accuracy: 0.7205 - val_loss: 0.6074 - val_accuracy: 0.6544\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5573 - accuracy: 0.7226 - val_loss: 0.5982 - val_accuracy: 0.6644\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 632us/step - loss: 0.5556 - accuracy: 0.7239 - val_loss: 0.6006 - val_accuracy: 0.6613\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5538 - accuracy: 0.7234 - val_loss: 0.6024 - val_accuracy: 0.6583\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.5529 - accuracy: 0.7251 - val_loss: 0.6023 - val_accuracy: 0.6581\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 635us/step - loss: 0.7298 - accuracy: 0.5067 - val_loss: 0.7262 - val_accuracy: 0.3629\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.7110 - accuracy: 0.5156 - val_loss: 0.7109 - val_accuracy: 0.4410\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.7009 - accuracy: 0.5292 - val_loss: 0.7121 - val_accuracy: 0.4472\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6935 - accuracy: 0.5402 - val_loss: 0.7028 - val_accuracy: 0.4837\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6871 - accuracy: 0.5509 - val_loss: 0.6964 - val_accuracy: 0.5102\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6831 - accuracy: 0.5601 - val_loss: 0.6951 - val_accuracy: 0.5147\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6788 - accuracy: 0.5691 - val_loss: 0.6956 - val_accuracy: 0.5129\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6740 - accuracy: 0.5799 - val_loss: 0.6908 - val_accuracy: 0.5281\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6702 - accuracy: 0.5850 - val_loss: 0.6918 - val_accuracy: 0.5222\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 550us/step - loss: 0.6678 - accuracy: 0.5940 - val_loss: 0.6885 - val_accuracy: 0.5289\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6639 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5435\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6613 - accuracy: 0.6078 - val_loss: 0.6847 - val_accuracy: 0.5423\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6570 - accuracy: 0.6168 - val_loss: 0.6813 - val_accuracy: 0.5514\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6533 - accuracy: 0.6231 - val_loss: 0.6815 - val_accuracy: 0.5527\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6510 - accuracy: 0.6274 - val_loss: 0.6794 - val_accuracy: 0.5570\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6470 - accuracy: 0.6350 - val_loss: 0.6753 - val_accuracy: 0.5661\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6446 - accuracy: 0.6402 - val_loss: 0.6784 - val_accuracy: 0.5569\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6432 - accuracy: 0.6406 - val_loss: 0.6676 - val_accuracy: 0.5796\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 555us/step - loss: 0.6404 - accuracy: 0.6463 - val_loss: 0.6694 - val_accuracy: 0.5758\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 561us/step - loss: 0.6378 - accuracy: 0.6493 - val_loss: 0.6671 - val_accuracy: 0.5788\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6359 - accuracy: 0.6520 - val_loss: 0.6652 - val_accuracy: 0.5819\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6335 - accuracy: 0.6577 - val_loss: 0.6616 - val_accuracy: 0.5879\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6302 - accuracy: 0.6633 - val_loss: 0.6605 - val_accuracy: 0.5886\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6282 - accuracy: 0.6622 - val_loss: 0.6652 - val_accuracy: 0.5767\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 748us/step - loss: 0.6253 - accuracy: 0.6696 - val_loss: 0.6579 - val_accuracy: 0.5916\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 701us/step - loss: 0.6239 - accuracy: 0.6702 - val_loss: 0.6520 - val_accuracy: 0.6019\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6209 - accuracy: 0.6724 - val_loss: 0.6602 - val_accuracy: 0.5848\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6185 - accuracy: 0.6742 - val_loss: 0.6556 - val_accuracy: 0.5917\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6164 - accuracy: 0.6751 - val_loss: 0.6469 - val_accuracy: 0.6053\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 646us/step - loss: 0.6142 - accuracy: 0.6807 - val_loss: 0.6529 - val_accuracy: 0.5950\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6122 - accuracy: 0.6819 - val_loss: 0.6516 - val_accuracy: 0.5967\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.6101 - accuracy: 0.6847 - val_loss: 0.6477 - val_accuracy: 0.6018\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6081 - accuracy: 0.6867 - val_loss: 0.6478 - val_accuracy: 0.6004\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6057 - accuracy: 0.6869 - val_loss: 0.6458 - val_accuracy: 0.6019\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6035 - accuracy: 0.6888 - val_loss: 0.6429 - val_accuracy: 0.6052\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6024 - accuracy: 0.6889 - val_loss: 0.6475 - val_accuracy: 0.6012\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5997 - accuracy: 0.6919 - val_loss: 0.6423 - val_accuracy: 0.6068\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5976 - accuracy: 0.6951 - val_loss: 0.6443 - val_accuracy: 0.6043\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.5955 - accuracy: 0.6957 - val_loss: 0.6413 - val_accuracy: 0.6089\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.5938 - accuracy: 0.6939 - val_loss: 0.6441 - val_accuracy: 0.6061\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.5922 - accuracy: 0.6975 - val_loss: 0.6350 - val_accuracy: 0.6176\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5904 - accuracy: 0.6979 - val_loss: 0.6404 - val_accuracy: 0.6110\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5881 - accuracy: 0.6986 - val_loss: 0.6344 - val_accuracy: 0.6178\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.5867 - accuracy: 0.7017 - val_loss: 0.6350 - val_accuracy: 0.6175\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.5846 - accuracy: 0.7026 - val_loss: 0.6324 - val_accuracy: 0.6207\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5835 - accuracy: 0.7045 - val_loss: 0.6317 - val_accuracy: 0.6208\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.5823 - accuracy: 0.7025 - val_loss: 0.6339 - val_accuracy: 0.6190\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5799 - accuracy: 0.7047 - val_loss: 0.6281 - val_accuracy: 0.6256\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5780 - accuracy: 0.7060 - val_loss: 0.6310 - val_accuracy: 0.6216\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5772 - accuracy: 0.7077 - val_loss: 0.6337 - val_accuracy: 0.6189\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.7277 - accuracy: 0.5170 - val_loss: 0.6901 - val_accuracy: 0.5392\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 637us/step - loss: 0.6959 - accuracy: 0.5412 - val_loss: 0.6925 - val_accuracy: 0.5358\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6880 - accuracy: 0.5584 - val_loss: 0.6860 - val_accuracy: 0.5582\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6783 - accuracy: 0.5731 - val_loss: 0.6814 - val_accuracy: 0.5743\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.6725 - accuracy: 0.5833 - val_loss: 0.6723 - val_accuracy: 0.5945\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6669 - accuracy: 0.5925 - val_loss: 0.6748 - val_accuracy: 0.5856\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6605 - accuracy: 0.6011 - val_loss: 0.6683 - val_accuracy: 0.5958\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6555 - accuracy: 0.6129 - val_loss: 0.6661 - val_accuracy: 0.5958\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6513 - accuracy: 0.6180 - val_loss: 0.6604 - val_accuracy: 0.6022\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.6465 - accuracy: 0.6249 - val_loss: 0.6559 - val_accuracy: 0.6077\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6440 - accuracy: 0.6291 - val_loss: 0.6557 - val_accuracy: 0.6030\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 729us/step - loss: 0.6393 - accuracy: 0.6349 - val_loss: 0.6503 - val_accuracy: 0.6095\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6376 - accuracy: 0.6387 - val_loss: 0.6515 - val_accuracy: 0.6058\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 750us/step - loss: 0.6341 - accuracy: 0.6422 - val_loss: 0.6471 - val_accuracy: 0.6111\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6314 - accuracy: 0.6448 - val_loss: 0.6470 - val_accuracy: 0.6109\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6296 - accuracy: 0.6491 - val_loss: 0.6457 - val_accuracy: 0.6112\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6284 - accuracy: 0.6486 - val_loss: 0.6392 - val_accuracy: 0.6204\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.6246 - accuracy: 0.6528 - val_loss: 0.6425 - val_accuracy: 0.6142\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6225 - accuracy: 0.6556 - val_loss: 0.6359 - val_accuracy: 0.6244\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6197 - accuracy: 0.6573 - val_loss: 0.6320 - val_accuracy: 0.6310\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 640us/step - loss: 0.6186 - accuracy: 0.6605 - val_loss: 0.6309 - val_accuracy: 0.6319\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.6160 - accuracy: 0.6632 - val_loss: 0.6376 - val_accuracy: 0.6197\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 648us/step - loss: 0.6138 - accuracy: 0.6658 - val_loss: 0.6346 - val_accuracy: 0.6235\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6116 - accuracy: 0.6668 - val_loss: 0.6315 - val_accuracy: 0.6278\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 643us/step - loss: 0.6102 - accuracy: 0.6690 - val_loss: 0.6338 - val_accuracy: 0.6217\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.6083 - accuracy: 0.6706 - val_loss: 0.6285 - val_accuracy: 0.6293\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.6084 - accuracy: 0.6718 - val_loss: 0.6219 - val_accuracy: 0.6381\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.6047 - accuracy: 0.6758 - val_loss: 0.6301 - val_accuracy: 0.6249\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6040 - accuracy: 0.6767 - val_loss: 0.6273 - val_accuracy: 0.6267\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6027 - accuracy: 0.6782 - val_loss: 0.6202 - val_accuracy: 0.6384\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.6002 - accuracy: 0.6809 - val_loss: 0.6205 - val_accuracy: 0.6371\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.5986 - accuracy: 0.6808 - val_loss: 0.6216 - val_accuracy: 0.6349\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.5967 - accuracy: 0.6862 - val_loss: 0.6177 - val_accuracy: 0.6389\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5950 - accuracy: 0.6855 - val_loss: 0.6192 - val_accuracy: 0.6375\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.5939 - accuracy: 0.6865 - val_loss: 0.6200 - val_accuracy: 0.6361\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5921 - accuracy: 0.6894 - val_loss: 0.6187 - val_accuracy: 0.6385\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5906 - accuracy: 0.6902 - val_loss: 0.6163 - val_accuracy: 0.6425\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 654us/step - loss: 0.5900 - accuracy: 0.6914 - val_loss: 0.6181 - val_accuracy: 0.6401\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5880 - accuracy: 0.6923 - val_loss: 0.6119 - val_accuracy: 0.6481\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.5866 - accuracy: 0.6948 - val_loss: 0.6157 - val_accuracy: 0.6424\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.5859 - accuracy: 0.6962 - val_loss: 0.6160 - val_accuracy: 0.6422\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.5841 - accuracy: 0.6949 - val_loss: 0.6164 - val_accuracy: 0.6413\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.5828 - accuracy: 0.6980 - val_loss: 0.6159 - val_accuracy: 0.6418\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 627us/step - loss: 0.5814 - accuracy: 0.6980 - val_loss: 0.6165 - val_accuracy: 0.6416\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5797 - accuracy: 0.7010 - val_loss: 0.6185 - val_accuracy: 0.6387\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5788 - accuracy: 0.7003 - val_loss: 0.6082 - val_accuracy: 0.6501\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5783 - accuracy: 0.7027 - val_loss: 0.6169 - val_accuracy: 0.6401\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.5757 - accuracy: 0.7022 - val_loss: 0.6111 - val_accuracy: 0.6462\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5752 - accuracy: 0.7034 - val_loss: 0.6082 - val_accuracy: 0.6475\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5740 - accuracy: 0.7039 - val_loss: 0.6112 - val_accuracy: 0.6441\n",
      "\n",
      "Training model with sample_size_ratio=1, target_eps=2.0...\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 5.05 iterated over 83600 steps satisfies differential privacy with eps = 0.167 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 2.5749999999999997 iterated over 83600 steps satisfies differential privacy with eps = 0.34 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.3375 iterated over 83600 steps satisfies differential privacy with eps = 0.763 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.71875 iterated over 83600 steps satisfies differential privacy with eps = 2.77 and delta = 1e-05.\n",
      "The optimal RDP order is 7.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 1.028125 iterated over 83600 steps satisfies differential privacy with eps = 1.22 and delta = 1e-05.\n",
      "The optimal RDP order is 15.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.8734375 iterated over 83600 steps satisfies differential privacy with eps = 1.7 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.79609375 iterated over 83600 steps satisfies differential privacy with eps = 2.12 and delta = 1e-05.\n",
      "The optimal RDP order is 8.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.834765625 iterated over 83600 steps satisfies differential privacy with eps = 1.89 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.8154296875 iterated over 83600 steps satisfies differential privacy with eps = 1.96 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.80576171875 iterated over 83600 steps satisfies differential privacy with eps = 2.08 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "DP-SGD with sampling rate = 0.0598% and noise_multiplier = 0.810595703125 iterated over 83600 steps satisfies differential privacy with eps = 2.01 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "Epoch 1/50\n",
      "1628/1672 [============================>.] - ETA: 0s - loss: 0.7647 - accuracy: 0.5081WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1672/1672 [==============================] - 1s 639us/step - loss: 0.7633 - accuracy: 0.5082 - val_loss: 0.7671 - val_accuracy: 0.2371\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.7099 - accuracy: 0.4995 - val_loss: 0.7287 - val_accuracy: 0.3499\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.6969 - accuracy: 0.5259 - val_loss: 0.7137 - val_accuracy: 0.4259\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6904 - accuracy: 0.5423 - val_loss: 0.7075 - val_accuracy: 0.4607\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6839 - accuracy: 0.5564 - val_loss: 0.6974 - val_accuracy: 0.5099\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.6778 - accuracy: 0.5692 - val_loss: 0.6885 - val_accuracy: 0.5452\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6720 - accuracy: 0.5831 - val_loss: 0.6877 - val_accuracy: 0.5487\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6687 - accuracy: 0.5926 - val_loss: 0.6779 - val_accuracy: 0.5777\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6657 - accuracy: 0.5967 - val_loss: 0.6826 - val_accuracy: 0.5660\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6625 - accuracy: 0.6030 - val_loss: 0.6725 - val_accuracy: 0.5859\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 574us/step - loss: 0.6580 - accuracy: 0.6125 - val_loss: 0.6717 - val_accuracy: 0.5868\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.6562 - accuracy: 0.6146 - val_loss: 0.6759 - val_accuracy: 0.5776\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6525 - accuracy: 0.6208 - val_loss: 0.6665 - val_accuracy: 0.5953\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6504 - accuracy: 0.6215 - val_loss: 0.6624 - val_accuracy: 0.6011\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6472 - accuracy: 0.6278 - val_loss: 0.6573 - val_accuracy: 0.6091\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6439 - accuracy: 0.6339 - val_loss: 0.6580 - val_accuracy: 0.6065\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6421 - accuracy: 0.6367 - val_loss: 0.6567 - val_accuracy: 0.6065\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6404 - accuracy: 0.6378 - val_loss: 0.6537 - val_accuracy: 0.6098\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6375 - accuracy: 0.6399 - val_loss: 0.6495 - val_accuracy: 0.6132\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6340 - accuracy: 0.6441 - val_loss: 0.6552 - val_accuracy: 0.6035\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6326 - accuracy: 0.6490 - val_loss: 0.6465 - val_accuracy: 0.6124\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6300 - accuracy: 0.6497 - val_loss: 0.6479 - val_accuracy: 0.6100\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6271 - accuracy: 0.6521 - val_loss: 0.6422 - val_accuracy: 0.6147\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6263 - accuracy: 0.6544 - val_loss: 0.6405 - val_accuracy: 0.6154\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6230 - accuracy: 0.6574 - val_loss: 0.6367 - val_accuracy: 0.6180\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6229 - accuracy: 0.6577 - val_loss: 0.6390 - val_accuracy: 0.6140\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.6193 - accuracy: 0.6607 - val_loss: 0.6378 - val_accuracy: 0.6140\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6168 - accuracy: 0.6637 - val_loss: 0.6401 - val_accuracy: 0.6104\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6147 - accuracy: 0.6663 - val_loss: 0.6374 - val_accuracy: 0.6115\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6131 - accuracy: 0.6690 - val_loss: 0.6321 - val_accuracy: 0.6183\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6111 - accuracy: 0.6689 - val_loss: 0.6316 - val_accuracy: 0.6167\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.6097 - accuracy: 0.6699 - val_loss: 0.6245 - val_accuracy: 0.6224\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6080 - accuracy: 0.6710 - val_loss: 0.6276 - val_accuracy: 0.6192\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.6073 - accuracy: 0.6717 - val_loss: 0.6290 - val_accuracy: 0.6172\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.6048 - accuracy: 0.6738 - val_loss: 0.6315 - val_accuracy: 0.6133\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.6029 - accuracy: 0.6773 - val_loss: 0.6232 - val_accuracy: 0.6194\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6015 - accuracy: 0.6783 - val_loss: 0.6231 - val_accuracy: 0.6184\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5989 - accuracy: 0.6800 - val_loss: 0.6245 - val_accuracy: 0.6155\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.5977 - accuracy: 0.6826 - val_loss: 0.6198 - val_accuracy: 0.6200\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5960 - accuracy: 0.6814 - val_loss: 0.6202 - val_accuracy: 0.6177\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 573us/step - loss: 0.5945 - accuracy: 0.6828 - val_loss: 0.6173 - val_accuracy: 0.6201\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 611us/step - loss: 0.5929 - accuracy: 0.6857 - val_loss: 0.6171 - val_accuracy: 0.6190\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 529us/step - loss: 0.5909 - accuracy: 0.6891 - val_loss: 0.6161 - val_accuracy: 0.6189\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5895 - accuracy: 0.6886 - val_loss: 0.6132 - val_accuracy: 0.6219\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5881 - accuracy: 0.6913 - val_loss: 0.6253 - val_accuracy: 0.6054\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5868 - accuracy: 0.6902 - val_loss: 0.6199 - val_accuracy: 0.6103\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5853 - accuracy: 0.6932 - val_loss: 0.6149 - val_accuracy: 0.6155\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5834 - accuracy: 0.6943 - val_loss: 0.6164 - val_accuracy: 0.6121\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.5826 - accuracy: 0.6940 - val_loss: 0.6137 - val_accuracy: 0.6142\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 552us/step - loss: 0.5804 - accuracy: 0.6970 - val_loss: 0.6150 - val_accuracy: 0.6121\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.7398 - accuracy: 0.5248 - val_loss: 0.7474 - val_accuracy: 0.2583\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6942 - accuracy: 0.5451 - val_loss: 0.7158 - val_accuracy: 0.3602\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.6828 - accuracy: 0.5703 - val_loss: 0.7012 - val_accuracy: 0.4345\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6735 - accuracy: 0.5936 - val_loss: 0.6945 - val_accuracy: 0.4940\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6663 - accuracy: 0.6075 - val_loss: 0.6888 - val_accuracy: 0.5277\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6608 - accuracy: 0.6192 - val_loss: 0.6849 - val_accuracy: 0.5445\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 528us/step - loss: 0.6571 - accuracy: 0.6268 - val_loss: 0.6752 - val_accuracy: 0.5693\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6523 - accuracy: 0.6351 - val_loss: 0.6737 - val_accuracy: 0.5732\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6487 - accuracy: 0.6420 - val_loss: 0.6711 - val_accuracy: 0.5788\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6458 - accuracy: 0.6472 - val_loss: 0.6678 - val_accuracy: 0.5848\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 540us/step - loss: 0.6417 - accuracy: 0.6514 - val_loss: 0.6609 - val_accuracy: 0.5980\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6389 - accuracy: 0.6582 - val_loss: 0.6624 - val_accuracy: 0.5952\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 570us/step - loss: 0.6354 - accuracy: 0.6595 - val_loss: 0.6597 - val_accuracy: 0.5990\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 565us/step - loss: 0.6329 - accuracy: 0.6627 - val_loss: 0.6566 - val_accuracy: 0.6027\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.6299 - accuracy: 0.6667 - val_loss: 0.6519 - val_accuracy: 0.6086\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 559us/step - loss: 0.6283 - accuracy: 0.6672 - val_loss: 0.6499 - val_accuracy: 0.6113\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 571us/step - loss: 0.6245 - accuracy: 0.6714 - val_loss: 0.6398 - val_accuracy: 0.6268\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 562us/step - loss: 0.6219 - accuracy: 0.6730 - val_loss: 0.6409 - val_accuracy: 0.6230\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6187 - accuracy: 0.6774 - val_loss: 0.6375 - val_accuracy: 0.6271\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 526us/step - loss: 0.6170 - accuracy: 0.6768 - val_loss: 0.6344 - val_accuracy: 0.6310\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6140 - accuracy: 0.6805 - val_loss: 0.6383 - val_accuracy: 0.6237\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6130 - accuracy: 0.6808 - val_loss: 0.6360 - val_accuracy: 0.6257\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.6103 - accuracy: 0.6815 - val_loss: 0.6299 - val_accuracy: 0.6339\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6087 - accuracy: 0.6840 - val_loss: 0.6284 - val_accuracy: 0.6349\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6068 - accuracy: 0.6849 - val_loss: 0.6332 - val_accuracy: 0.6278\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6035 - accuracy: 0.6867 - val_loss: 0.6243 - val_accuracy: 0.6403\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 536us/step - loss: 0.6030 - accuracy: 0.6881 - val_loss: 0.6328 - val_accuracy: 0.6258\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.6002 - accuracy: 0.6901 - val_loss: 0.6274 - val_accuracy: 0.6326\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 576us/step - loss: 0.5989 - accuracy: 0.6901 - val_loss: 0.6221 - val_accuracy: 0.6398\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5965 - accuracy: 0.6940 - val_loss: 0.6196 - val_accuracy: 0.6428\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.5956 - accuracy: 0.6933 - val_loss: 0.6186 - val_accuracy: 0.6434\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.5939 - accuracy: 0.6937 - val_loss: 0.6247 - val_accuracy: 0.6365\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5912 - accuracy: 0.6988 - val_loss: 0.6275 - val_accuracy: 0.6324\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.5898 - accuracy: 0.6985 - val_loss: 0.6210 - val_accuracy: 0.6392\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.5880 - accuracy: 0.6978 - val_loss: 0.6178 - val_accuracy: 0.6424\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5865 - accuracy: 0.7018 - val_loss: 0.6084 - val_accuracy: 0.6508\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5850 - accuracy: 0.7009 - val_loss: 0.6167 - val_accuracy: 0.6425\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 531us/step - loss: 0.5843 - accuracy: 0.7019 - val_loss: 0.6163 - val_accuracy: 0.6419\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5818 - accuracy: 0.7040 - val_loss: 0.6191 - val_accuracy: 0.6392\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5818 - accuracy: 0.7053 - val_loss: 0.6082 - val_accuracy: 0.6482\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.5783 - accuracy: 0.7072 - val_loss: 0.6087 - val_accuracy: 0.6469\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5772 - accuracy: 0.7093 - val_loss: 0.6084 - val_accuracy: 0.6475\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5766 - accuracy: 0.7070 - val_loss: 0.6112 - val_accuracy: 0.6441\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.5748 - accuracy: 0.7092 - val_loss: 0.6103 - val_accuracy: 0.6456\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.5730 - accuracy: 0.7097 - val_loss: 0.6118 - val_accuracy: 0.6438\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.5717 - accuracy: 0.7113 - val_loss: 0.6075 - val_accuracy: 0.6482\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5699 - accuracy: 0.7137 - val_loss: 0.6017 - val_accuracy: 0.6527\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.5690 - accuracy: 0.7137 - val_loss: 0.6106 - val_accuracy: 0.6441\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 848us/step - loss: 0.5683 - accuracy: 0.7131 - val_loss: 0.6067 - val_accuracy: 0.6470\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.5655 - accuracy: 0.7168 - val_loss: 0.6060 - val_accuracy: 0.6472\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 742us/step - loss: 0.7128 - accuracy: 0.5208 - val_loss: 0.7329 - val_accuracy: 0.2082\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 732us/step - loss: 0.7009 - accuracy: 0.5302 - val_loss: 0.7172 - val_accuracy: 0.2923\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.6876 - accuracy: 0.5543 - val_loss: 0.7141 - val_accuracy: 0.3429\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.6772 - accuracy: 0.5765 - val_loss: 0.7020 - val_accuracy: 0.4463\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.6699 - accuracy: 0.5923 - val_loss: 0.6935 - val_accuracy: 0.5190\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6632 - accuracy: 0.6081 - val_loss: 0.6906 - val_accuracy: 0.5344\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6564 - accuracy: 0.6210 - val_loss: 0.6818 - val_accuracy: 0.5621\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.6507 - accuracy: 0.6305 - val_loss: 0.6756 - val_accuracy: 0.5764\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 641us/step - loss: 0.6466 - accuracy: 0.6357 - val_loss: 0.6679 - val_accuracy: 0.5928\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6421 - accuracy: 0.6423 - val_loss: 0.6700 - val_accuracy: 0.5876\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6374 - accuracy: 0.6503 - val_loss: 0.6545 - val_accuracy: 0.6143\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 683us/step - loss: 0.6344 - accuracy: 0.6546 - val_loss: 0.6567 - val_accuracy: 0.6081\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.6305 - accuracy: 0.6557 - val_loss: 0.6529 - val_accuracy: 0.6115\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6281 - accuracy: 0.6588 - val_loss: 0.6560 - val_accuracy: 0.6062\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6238 - accuracy: 0.6648 - val_loss: 0.6529 - val_accuracy: 0.6085\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6212 - accuracy: 0.6675 - val_loss: 0.6503 - val_accuracy: 0.6103\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6181 - accuracy: 0.6709 - val_loss: 0.6376 - val_accuracy: 0.6295\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.6156 - accuracy: 0.6723 - val_loss: 0.6422 - val_accuracy: 0.6198\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 660us/step - loss: 0.6123 - accuracy: 0.6745 - val_loss: 0.6389 - val_accuracy: 0.6230\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.6100 - accuracy: 0.6788 - val_loss: 0.6367 - val_accuracy: 0.6240\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6063 - accuracy: 0.6799 - val_loss: 0.6359 - val_accuracy: 0.6229\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6046 - accuracy: 0.6813 - val_loss: 0.6267 - val_accuracy: 0.6377\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.6016 - accuracy: 0.6837 - val_loss: 0.6299 - val_accuracy: 0.6287\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.6000 - accuracy: 0.6855 - val_loss: 0.6233 - val_accuracy: 0.6396\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.5971 - accuracy: 0.6866 - val_loss: 0.6261 - val_accuracy: 0.6345\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.5947 - accuracy: 0.6882 - val_loss: 0.6283 - val_accuracy: 0.6304\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5925 - accuracy: 0.6898 - val_loss: 0.6288 - val_accuracy: 0.6298\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 638us/step - loss: 0.5902 - accuracy: 0.6911 - val_loss: 0.6243 - val_accuracy: 0.6344\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.5886 - accuracy: 0.6912 - val_loss: 0.6222 - val_accuracy: 0.6373\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5871 - accuracy: 0.6938 - val_loss: 0.6163 - val_accuracy: 0.6438\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5847 - accuracy: 0.6961 - val_loss: 0.6176 - val_accuracy: 0.6425\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.5830 - accuracy: 0.6953 - val_loss: 0.6148 - val_accuracy: 0.6440\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.5806 - accuracy: 0.6976 - val_loss: 0.6235 - val_accuracy: 0.6346\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 696us/step - loss: 0.5798 - accuracy: 0.6976 - val_loss: 0.6126 - val_accuracy: 0.6456\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 766us/step - loss: 0.5779 - accuracy: 0.7008 - val_loss: 0.6135 - val_accuracy: 0.6429\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 661us/step - loss: 0.5743 - accuracy: 0.7043 - val_loss: 0.6152 - val_accuracy: 0.6415\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.5735 - accuracy: 0.7049 - val_loss: 0.6189 - val_accuracy: 0.6385\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 677us/step - loss: 0.5720 - accuracy: 0.7047 - val_loss: 0.6090 - val_accuracy: 0.6492\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 649us/step - loss: 0.5709 - accuracy: 0.7056 - val_loss: 0.6155 - val_accuracy: 0.6416\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 647us/step - loss: 0.5683 - accuracy: 0.7073 - val_loss: 0.6055 - val_accuracy: 0.6529\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.5680 - accuracy: 0.7086 - val_loss: 0.6076 - val_accuracy: 0.6507\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.5662 - accuracy: 0.7101 - val_loss: 0.6152 - val_accuracy: 0.6410\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 659us/step - loss: 0.5640 - accuracy: 0.7113 - val_loss: 0.6051 - val_accuracy: 0.6539\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 650us/step - loss: 0.5622 - accuracy: 0.7113 - val_loss: 0.6112 - val_accuracy: 0.6455\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5613 - accuracy: 0.7139 - val_loss: 0.6028 - val_accuracy: 0.6549\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.5598 - accuracy: 0.7141 - val_loss: 0.6190 - val_accuracy: 0.6353\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.5589 - accuracy: 0.7144 - val_loss: 0.6088 - val_accuracy: 0.6471\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 652us/step - loss: 0.5580 - accuracy: 0.7151 - val_loss: 0.6122 - val_accuracy: 0.6419\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.5566 - accuracy: 0.7174 - val_loss: 0.6085 - val_accuracy: 0.6459\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5552 - accuracy: 0.7177 - val_loss: 0.5935 - val_accuracy: 0.6632\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.7281 - accuracy: 0.5049 - val_loss: 0.7647 - val_accuracy: 0.1661\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.7035 - accuracy: 0.5122 - val_loss: 0.7271 - val_accuracy: 0.3060\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6929 - accuracy: 0.5354 - val_loss: 0.7124 - val_accuracy: 0.4268\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 656us/step - loss: 0.6852 - accuracy: 0.5541 - val_loss: 0.7044 - val_accuracy: 0.4658\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 733us/step - loss: 0.6785 - accuracy: 0.5699 - val_loss: 0.6993 - val_accuracy: 0.4991\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.6724 - accuracy: 0.5840 - val_loss: 0.6970 - val_accuracy: 0.5141\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 758us/step - loss: 0.6676 - accuracy: 0.5971 - val_loss: 0.6882 - val_accuracy: 0.5537\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 731us/step - loss: 0.6623 - accuracy: 0.6059 - val_loss: 0.6842 - val_accuracy: 0.5621\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 739us/step - loss: 0.6580 - accuracy: 0.6144 - val_loss: 0.6818 - val_accuracy: 0.5675\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 771us/step - loss: 0.6527 - accuracy: 0.6221 - val_loss: 0.6747 - val_accuracy: 0.5889\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.6486 - accuracy: 0.6280 - val_loss: 0.6732 - val_accuracy: 0.5950\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6442 - accuracy: 0.6357 - val_loss: 0.6661 - val_accuracy: 0.6125\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 698us/step - loss: 0.6406 - accuracy: 0.6390 - val_loss: 0.6638 - val_accuracy: 0.6153\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.6364 - accuracy: 0.6457 - val_loss: 0.6574 - val_accuracy: 0.6247\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6335 - accuracy: 0.6487 - val_loss: 0.6537 - val_accuracy: 0.6292\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.6303 - accuracy: 0.6523 - val_loss: 0.6520 - val_accuracy: 0.6295\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6271 - accuracy: 0.6560 - val_loss: 0.6503 - val_accuracy: 0.6292\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.6245 - accuracy: 0.6589 - val_loss: 0.6510 - val_accuracy: 0.6257\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 620us/step - loss: 0.6211 - accuracy: 0.6630 - val_loss: 0.6460 - val_accuracy: 0.6310\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6198 - accuracy: 0.6631 - val_loss: 0.6464 - val_accuracy: 0.6293\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6167 - accuracy: 0.6674 - val_loss: 0.6457 - val_accuracy: 0.6280\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 651us/step - loss: 0.6139 - accuracy: 0.6698 - val_loss: 0.6415 - val_accuracy: 0.6316\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 575us/step - loss: 0.6112 - accuracy: 0.6739 - val_loss: 0.6379 - val_accuracy: 0.6360\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6110 - accuracy: 0.6715 - val_loss: 0.6346 - val_accuracy: 0.6402\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6083 - accuracy: 0.6748 - val_loss: 0.6395 - val_accuracy: 0.6303\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6062 - accuracy: 0.6765 - val_loss: 0.6330 - val_accuracy: 0.6391\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6040 - accuracy: 0.6804 - val_loss: 0.6353 - val_accuracy: 0.6340\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6017 - accuracy: 0.6802 - val_loss: 0.6330 - val_accuracy: 0.6354\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 554us/step - loss: 0.6009 - accuracy: 0.6806 - val_loss: 0.6302 - val_accuracy: 0.6396\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5977 - accuracy: 0.6845 - val_loss: 0.6252 - val_accuracy: 0.6461\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5960 - accuracy: 0.6861 - val_loss: 0.6270 - val_accuracy: 0.6425\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5944 - accuracy: 0.6897 - val_loss: 0.6241 - val_accuracy: 0.6467\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.5924 - accuracy: 0.6889 - val_loss: 0.6226 - val_accuracy: 0.6486\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.5908 - accuracy: 0.6912 - val_loss: 0.6243 - val_accuracy: 0.6450\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5896 - accuracy: 0.6907 - val_loss: 0.6225 - val_accuracy: 0.6477\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5885 - accuracy: 0.6951 - val_loss: 0.6229 - val_accuracy: 0.6471\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.5861 - accuracy: 0.6940 - val_loss: 0.6180 - val_accuracy: 0.6531\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5846 - accuracy: 0.6973 - val_loss: 0.6212 - val_accuracy: 0.6489\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.5834 - accuracy: 0.6973 - val_loss: 0.6131 - val_accuracy: 0.6591\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5817 - accuracy: 0.6979 - val_loss: 0.6164 - val_accuracy: 0.6520\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5802 - accuracy: 0.6994 - val_loss: 0.6211 - val_accuracy: 0.6460\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.5786 - accuracy: 0.7008 - val_loss: 0.6202 - val_accuracy: 0.6466\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5777 - accuracy: 0.6993 - val_loss: 0.6168 - val_accuracy: 0.6495\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.5766 - accuracy: 0.7029 - val_loss: 0.6186 - val_accuracy: 0.6476\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5742 - accuracy: 0.7047 - val_loss: 0.6095 - val_accuracy: 0.6541\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5735 - accuracy: 0.7035 - val_loss: 0.6198 - val_accuracy: 0.6466\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5712 - accuracy: 0.7060 - val_loss: 0.6117 - val_accuracy: 0.6519\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 572us/step - loss: 0.5704 - accuracy: 0.7061 - val_loss: 0.6152 - val_accuracy: 0.6500\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5687 - accuracy: 0.7082 - val_loss: 0.6148 - val_accuracy: 0.6500\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.5687 - accuracy: 0.7074 - val_loss: 0.6076 - val_accuracy: 0.6575\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 617us/step - loss: 0.6797 - accuracy: 0.5660 - val_loss: 0.7106 - val_accuracy: 0.4817\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6732 - accuracy: 0.5813 - val_loss: 0.7026 - val_accuracy: 0.5207\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 564us/step - loss: 0.6678 - accuracy: 0.5944 - val_loss: 0.6937 - val_accuracy: 0.5539\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6629 - accuracy: 0.6024 - val_loss: 0.6856 - val_accuracy: 0.5783\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 577us/step - loss: 0.6589 - accuracy: 0.6097 - val_loss: 0.6834 - val_accuracy: 0.5872\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.6545 - accuracy: 0.6199 - val_loss: 0.6791 - val_accuracy: 0.5947\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 546us/step - loss: 0.6500 - accuracy: 0.6269 - val_loss: 0.6778 - val_accuracy: 0.5968\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6476 - accuracy: 0.6304 - val_loss: 0.6725 - val_accuracy: 0.6049\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6442 - accuracy: 0.6375 - val_loss: 0.6695 - val_accuracy: 0.6081\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.6409 - accuracy: 0.6440 - val_loss: 0.6590 - val_accuracy: 0.6231\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6382 - accuracy: 0.6429 - val_loss: 0.6621 - val_accuracy: 0.6164\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6352 - accuracy: 0.6482 - val_loss: 0.6642 - val_accuracy: 0.6115\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6324 - accuracy: 0.6545 - val_loss: 0.6626 - val_accuracy: 0.6127\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.6308 - accuracy: 0.6563 - val_loss: 0.6560 - val_accuracy: 0.6204\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6279 - accuracy: 0.6584 - val_loss: 0.6575 - val_accuracy: 0.6167\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6257 - accuracy: 0.6625 - val_loss: 0.6530 - val_accuracy: 0.6220\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 533us/step - loss: 0.6232 - accuracy: 0.6675 - val_loss: 0.6552 - val_accuracy: 0.6171\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6217 - accuracy: 0.6685 - val_loss: 0.6511 - val_accuracy: 0.6215\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6182 - accuracy: 0.6720 - val_loss: 0.6466 - val_accuracy: 0.6272\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.6159 - accuracy: 0.6744 - val_loss: 0.6481 - val_accuracy: 0.6231\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6144 - accuracy: 0.6774 - val_loss: 0.6418 - val_accuracy: 0.6314\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6138 - accuracy: 0.6764 - val_loss: 0.6459 - val_accuracy: 0.6231\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6107 - accuracy: 0.6798 - val_loss: 0.6359 - val_accuracy: 0.6386\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.6090 - accuracy: 0.6819 - val_loss: 0.6354 - val_accuracy: 0.6372\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6070 - accuracy: 0.6850 - val_loss: 0.6400 - val_accuracy: 0.6276\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6041 - accuracy: 0.6860 - val_loss: 0.6335 - val_accuracy: 0.6368\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 557us/step - loss: 0.6034 - accuracy: 0.6876 - val_loss: 0.6343 - val_accuracy: 0.6343\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6009 - accuracy: 0.6897 - val_loss: 0.6357 - val_accuracy: 0.6305\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5999 - accuracy: 0.6895 - val_loss: 0.6356 - val_accuracy: 0.6295\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.5973 - accuracy: 0.6921 - val_loss: 0.6291 - val_accuracy: 0.6388\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 556us/step - loss: 0.5949 - accuracy: 0.6950 - val_loss: 0.6330 - val_accuracy: 0.6321\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 584us/step - loss: 0.5935 - accuracy: 0.6974 - val_loss: 0.6326 - val_accuracy: 0.6326\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.5912 - accuracy: 0.7006 - val_loss: 0.6288 - val_accuracy: 0.6360\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5901 - accuracy: 0.6985 - val_loss: 0.6225 - val_accuracy: 0.6415\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5893 - accuracy: 0.6991 - val_loss: 0.6355 - val_accuracy: 0.6265\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.5866 - accuracy: 0.7009 - val_loss: 0.6319 - val_accuracy: 0.6295\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 625us/step - loss: 0.5858 - accuracy: 0.7011 - val_loss: 0.6326 - val_accuracy: 0.6283\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5823 - accuracy: 0.7042 - val_loss: 0.6236 - val_accuracy: 0.6367\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5817 - accuracy: 0.7042 - val_loss: 0.6261 - val_accuracy: 0.6339\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5801 - accuracy: 0.7045 - val_loss: 0.6295 - val_accuracy: 0.6283\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5780 - accuracy: 0.7061 - val_loss: 0.6212 - val_accuracy: 0.6374\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5774 - accuracy: 0.7058 - val_loss: 0.6185 - val_accuracy: 0.6401\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.5753 - accuracy: 0.7061 - val_loss: 0.6204 - val_accuracy: 0.6360\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.5750 - accuracy: 0.7077 - val_loss: 0.6203 - val_accuracy: 0.6360\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.5730 - accuracy: 0.7096 - val_loss: 0.6174 - val_accuracy: 0.6393\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.5718 - accuracy: 0.7077 - val_loss: 0.6185 - val_accuracy: 0.6387\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.5699 - accuracy: 0.7118 - val_loss: 0.6213 - val_accuracy: 0.6341\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.5688 - accuracy: 0.7121 - val_loss: 0.6218 - val_accuracy: 0.6341\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5675 - accuracy: 0.7095 - val_loss: 0.6178 - val_accuracy: 0.6381\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 563us/step - loss: 0.5665 - accuracy: 0.7128 - val_loss: 0.6175 - val_accuracy: 0.6382\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.7188 - accuracy: 0.5074 - val_loss: 0.7913 - val_accuracy: 0.1190\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.7063 - accuracy: 0.4959 - val_loss: 0.7572 - val_accuracy: 0.1289\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6978 - accuracy: 0.5157 - val_loss: 0.7412 - val_accuracy: 0.1482\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6920 - accuracy: 0.5362 - val_loss: 0.7342 - val_accuracy: 0.1914\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 582us/step - loss: 0.6867 - accuracy: 0.5542 - val_loss: 0.7281 - val_accuracy: 0.2493\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6827 - accuracy: 0.5689 - val_loss: 0.7248 - val_accuracy: 0.3033\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6780 - accuracy: 0.5862 - val_loss: 0.7185 - val_accuracy: 0.3587\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 583us/step - loss: 0.6745 - accuracy: 0.5969 - val_loss: 0.7155 - val_accuracy: 0.3918\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6709 - accuracy: 0.6066 - val_loss: 0.7112 - val_accuracy: 0.4358\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 578us/step - loss: 0.6671 - accuracy: 0.6187 - val_loss: 0.7104 - val_accuracy: 0.4521\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6636 - accuracy: 0.6240 - val_loss: 0.7066 - val_accuracy: 0.4772\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 580us/step - loss: 0.6608 - accuracy: 0.6304 - val_loss: 0.7044 - val_accuracy: 0.4892\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6589 - accuracy: 0.6328 - val_loss: 0.7010 - val_accuracy: 0.5027\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6554 - accuracy: 0.6394 - val_loss: 0.6979 - val_accuracy: 0.5204\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.6530 - accuracy: 0.6454 - val_loss: 0.6944 - val_accuracy: 0.5344\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6514 - accuracy: 0.6474 - val_loss: 0.6917 - val_accuracy: 0.5433\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 581us/step - loss: 0.6486 - accuracy: 0.6515 - val_loss: 0.6899 - val_accuracy: 0.5482\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6465 - accuracy: 0.6519 - val_loss: 0.6897 - val_accuracy: 0.5496\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 585us/step - loss: 0.6442 - accuracy: 0.6543 - val_loss: 0.6858 - val_accuracy: 0.5597\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 710us/step - loss: 0.6418 - accuracy: 0.6583 - val_loss: 0.6839 - val_accuracy: 0.5661\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 791us/step - loss: 0.6396 - accuracy: 0.6617 - val_loss: 0.6808 - val_accuracy: 0.5718\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 717us/step - loss: 0.6383 - accuracy: 0.6635 - val_loss: 0.6807 - val_accuracy: 0.5733\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.6351 - accuracy: 0.6635 - val_loss: 0.6755 - val_accuracy: 0.5826\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 734us/step - loss: 0.6342 - accuracy: 0.6658 - val_loss: 0.6755 - val_accuracy: 0.5824\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 692us/step - loss: 0.6316 - accuracy: 0.6678 - val_loss: 0.6763 - val_accuracy: 0.5808\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.6301 - accuracy: 0.6690 - val_loss: 0.6721 - val_accuracy: 0.5870\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6277 - accuracy: 0.6703 - val_loss: 0.6674 - val_accuracy: 0.5949\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 697us/step - loss: 0.6265 - accuracy: 0.6689 - val_loss: 0.6627 - val_accuracy: 0.6064\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 723us/step - loss: 0.6240 - accuracy: 0.6731 - val_loss: 0.6650 - val_accuracy: 0.5996\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 675us/step - loss: 0.6225 - accuracy: 0.6745 - val_loss: 0.6604 - val_accuracy: 0.6081\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6200 - accuracy: 0.6766 - val_loss: 0.6599 - val_accuracy: 0.6095\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 662us/step - loss: 0.6181 - accuracy: 0.6764 - val_loss: 0.6623 - val_accuracy: 0.6033\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 674us/step - loss: 0.6161 - accuracy: 0.6775 - val_loss: 0.6560 - val_accuracy: 0.6156\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6133 - accuracy: 0.6813 - val_loss: 0.6505 - val_accuracy: 0.6250\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6132 - accuracy: 0.6794 - val_loss: 0.6524 - val_accuracy: 0.6215\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6116 - accuracy: 0.6815 - val_loss: 0.6527 - val_accuracy: 0.6205\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6095 - accuracy: 0.6829 - val_loss: 0.6501 - val_accuracy: 0.6232\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6067 - accuracy: 0.6852 - val_loss: 0.6463 - val_accuracy: 0.6290\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.6064 - accuracy: 0.6835 - val_loss: 0.6441 - val_accuracy: 0.6325\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.6050 - accuracy: 0.6864 - val_loss: 0.6426 - val_accuracy: 0.6345\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 671us/step - loss: 0.6028 - accuracy: 0.6864 - val_loss: 0.6415 - val_accuracy: 0.6344\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.6008 - accuracy: 0.6901 - val_loss: 0.6432 - val_accuracy: 0.6310\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.5999 - accuracy: 0.6905 - val_loss: 0.6421 - val_accuracy: 0.6325\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 767us/step - loss: 0.5992 - accuracy: 0.6880 - val_loss: 0.6386 - val_accuracy: 0.6370\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 668us/step - loss: 0.5967 - accuracy: 0.6921 - val_loss: 0.6365 - val_accuracy: 0.6396\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.5953 - accuracy: 0.6934 - val_loss: 0.6348 - val_accuracy: 0.6407\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.5934 - accuracy: 0.6949 - val_loss: 0.6344 - val_accuracy: 0.6405\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 669us/step - loss: 0.5919 - accuracy: 0.6968 - val_loss: 0.6341 - val_accuracy: 0.6410\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 663us/step - loss: 0.5898 - accuracy: 0.6983 - val_loss: 0.6301 - val_accuracy: 0.6444\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.5889 - accuracy: 0.6983 - val_loss: 0.6324 - val_accuracy: 0.6425\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 774us/step - loss: 0.7295 - accuracy: 0.4633 - val_loss: 0.7340 - val_accuracy: 0.3092\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.7092 - accuracy: 0.5011 - val_loss: 0.7214 - val_accuracy: 0.3555\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6935 - accuracy: 0.5317 - val_loss: 0.7111 - val_accuracy: 0.4492\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.6833 - accuracy: 0.5584 - val_loss: 0.7033 - val_accuracy: 0.4811\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 704us/step - loss: 0.6753 - accuracy: 0.5769 - val_loss: 0.6976 - val_accuracy: 0.5099\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6698 - accuracy: 0.5901 - val_loss: 0.6921 - val_accuracy: 0.5421\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 665us/step - loss: 0.6630 - accuracy: 0.6053 - val_loss: 0.6842 - val_accuracy: 0.5705\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 657us/step - loss: 0.6583 - accuracy: 0.6163 - val_loss: 0.6814 - val_accuracy: 0.5755\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.6533 - accuracy: 0.6230 - val_loss: 0.6800 - val_accuracy: 0.5774\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 664us/step - loss: 0.6474 - accuracy: 0.6324 - val_loss: 0.6714 - val_accuracy: 0.5958\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6425 - accuracy: 0.6393 - val_loss: 0.6688 - val_accuracy: 0.5990\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6398 - accuracy: 0.6446 - val_loss: 0.6605 - val_accuracy: 0.6136\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.6364 - accuracy: 0.6526 - val_loss: 0.6595 - val_accuracy: 0.6131\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 708us/step - loss: 0.6332 - accuracy: 0.6546 - val_loss: 0.6558 - val_accuracy: 0.6175\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 672us/step - loss: 0.6303 - accuracy: 0.6560 - val_loss: 0.6561 - val_accuracy: 0.6150\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.6281 - accuracy: 0.6589 - val_loss: 0.6497 - val_accuracy: 0.6253\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 673us/step - loss: 0.6254 - accuracy: 0.6621 - val_loss: 0.6502 - val_accuracy: 0.6226\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 705us/step - loss: 0.6232 - accuracy: 0.6630 - val_loss: 0.6399 - val_accuracy: 0.6378\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 670us/step - loss: 0.6208 - accuracy: 0.6682 - val_loss: 0.6414 - val_accuracy: 0.6331\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.6186 - accuracy: 0.6675 - val_loss: 0.6365 - val_accuracy: 0.6373\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6169 - accuracy: 0.6680 - val_loss: 0.6374 - val_accuracy: 0.6339\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.6136 - accuracy: 0.6737 - val_loss: 0.6362 - val_accuracy: 0.6341\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6123 - accuracy: 0.6731 - val_loss: 0.6309 - val_accuracy: 0.6413\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6102 - accuracy: 0.6751 - val_loss: 0.6363 - val_accuracy: 0.6319\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6081 - accuracy: 0.6788 - val_loss: 0.6332 - val_accuracy: 0.6347\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 682us/step - loss: 0.6065 - accuracy: 0.6785 - val_loss: 0.6247 - val_accuracy: 0.6482\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 779us/step - loss: 0.6049 - accuracy: 0.6792 - val_loss: 0.6265 - val_accuracy: 0.6441\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.6019 - accuracy: 0.6841 - val_loss: 0.6247 - val_accuracy: 0.6455\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6008 - accuracy: 0.6819 - val_loss: 0.6219 - val_accuracy: 0.6475\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.5989 - accuracy: 0.6865 - val_loss: 0.6227 - val_accuracy: 0.6457\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 685us/step - loss: 0.5970 - accuracy: 0.6869 - val_loss: 0.6198 - val_accuracy: 0.6479\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.5949 - accuracy: 0.6884 - val_loss: 0.6250 - val_accuracy: 0.6413\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.5937 - accuracy: 0.6889 - val_loss: 0.6220 - val_accuracy: 0.6447\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.5920 - accuracy: 0.6903 - val_loss: 0.6173 - val_accuracy: 0.6480\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 711us/step - loss: 0.5903 - accuracy: 0.6908 - val_loss: 0.6138 - val_accuracy: 0.6516\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 681us/step - loss: 0.5890 - accuracy: 0.6908 - val_loss: 0.6121 - val_accuracy: 0.6527\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 742us/step - loss: 0.5871 - accuracy: 0.6963 - val_loss: 0.6139 - val_accuracy: 0.6500\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.5860 - accuracy: 0.6959 - val_loss: 0.6111 - val_accuracy: 0.6519\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 695us/step - loss: 0.5846 - accuracy: 0.6974 - val_loss: 0.6122 - val_accuracy: 0.6490\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 612us/step - loss: 0.5829 - accuracy: 0.6985 - val_loss: 0.6144 - val_accuracy: 0.6467\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5813 - accuracy: 0.6998 - val_loss: 0.6079 - val_accuracy: 0.6530\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.5799 - accuracy: 0.6999 - val_loss: 0.6118 - val_accuracy: 0.6472\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5787 - accuracy: 0.7009 - val_loss: 0.6002 - val_accuracy: 0.6635\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5775 - accuracy: 0.7021 - val_loss: 0.6110 - val_accuracy: 0.6464\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.5755 - accuracy: 0.7046 - val_loss: 0.6012 - val_accuracy: 0.6602\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5751 - accuracy: 0.7046 - val_loss: 0.6139 - val_accuracy: 0.6425\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 558us/step - loss: 0.5739 - accuracy: 0.7069 - val_loss: 0.6100 - val_accuracy: 0.6475\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 589us/step - loss: 0.5721 - accuracy: 0.7062 - val_loss: 0.6065 - val_accuracy: 0.6518\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5708 - accuracy: 0.7084 - val_loss: 0.6068 - val_accuracy: 0.6511\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5700 - accuracy: 0.7092 - val_loss: 0.6057 - val_accuracy: 0.6520\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 644us/step - loss: 0.7216 - accuracy: 0.4932 - val_loss: 0.7018 - val_accuracy: 0.4825\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6982 - accuracy: 0.5278 - val_loss: 0.7012 - val_accuracy: 0.4853\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6898 - accuracy: 0.5499 - val_loss: 0.6944 - val_accuracy: 0.5162\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6836 - accuracy: 0.5570 - val_loss: 0.6983 - val_accuracy: 0.5081\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.6767 - accuracy: 0.5751 - val_loss: 0.6886 - val_accuracy: 0.5435\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.6711 - accuracy: 0.5866 - val_loss: 0.6833 - val_accuracy: 0.5635\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6674 - accuracy: 0.5924 - val_loss: 0.6785 - val_accuracy: 0.5822\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6618 - accuracy: 0.6081 - val_loss: 0.6761 - val_accuracy: 0.5890\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6569 - accuracy: 0.6174 - val_loss: 0.6676 - val_accuracy: 0.6099\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6519 - accuracy: 0.6245 - val_loss: 0.6677 - val_accuracy: 0.6072\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6487 - accuracy: 0.6329 - val_loss: 0.6667 - val_accuracy: 0.6083\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6442 - accuracy: 0.6396 - val_loss: 0.6609 - val_accuracy: 0.6171\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6412 - accuracy: 0.6449 - val_loss: 0.6602 - val_accuracy: 0.6163\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6375 - accuracy: 0.6498 - val_loss: 0.6545 - val_accuracy: 0.6263\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6336 - accuracy: 0.6553 - val_loss: 0.6498 - val_accuracy: 0.6356\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6309 - accuracy: 0.6598 - val_loss: 0.6489 - val_accuracy: 0.6366\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 606us/step - loss: 0.6274 - accuracy: 0.6658 - val_loss: 0.6468 - val_accuracy: 0.6414\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6249 - accuracy: 0.6673 - val_loss: 0.6445 - val_accuracy: 0.6476\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 567us/step - loss: 0.6217 - accuracy: 0.6691 - val_loss: 0.6482 - val_accuracy: 0.6384\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.6188 - accuracy: 0.6734 - val_loss: 0.6412 - val_accuracy: 0.6527\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6156 - accuracy: 0.6762 - val_loss: 0.6413 - val_accuracy: 0.6507\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.6131 - accuracy: 0.6788 - val_loss: 0.6341 - val_accuracy: 0.6622\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6115 - accuracy: 0.6812 - val_loss: 0.6326 - val_accuracy: 0.6616\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6084 - accuracy: 0.6842 - val_loss: 0.6306 - val_accuracy: 0.6605\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6061 - accuracy: 0.6848 - val_loss: 0.6302 - val_accuracy: 0.6591\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 624us/step - loss: 0.6039 - accuracy: 0.6879 - val_loss: 0.6285 - val_accuracy: 0.6595\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6023 - accuracy: 0.6894 - val_loss: 0.6313 - val_accuracy: 0.6539\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 636us/step - loss: 0.6003 - accuracy: 0.6932 - val_loss: 0.6187 - val_accuracy: 0.6680\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 616us/step - loss: 0.5985 - accuracy: 0.6939 - val_loss: 0.6164 - val_accuracy: 0.6689\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 605us/step - loss: 0.5954 - accuracy: 0.6960 - val_loss: 0.6211 - val_accuracy: 0.6605\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 614us/step - loss: 0.5943 - accuracy: 0.6965 - val_loss: 0.6185 - val_accuracy: 0.6608\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 653us/step - loss: 0.5925 - accuracy: 0.6957 - val_loss: 0.6213 - val_accuracy: 0.6581\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 569us/step - loss: 0.5902 - accuracy: 0.7024 - val_loss: 0.6168 - val_accuracy: 0.6614\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 593us/step - loss: 0.5884 - accuracy: 0.7029 - val_loss: 0.6182 - val_accuracy: 0.6561\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 613us/step - loss: 0.5871 - accuracy: 0.7031 - val_loss: 0.6122 - val_accuracy: 0.6634\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.5850 - accuracy: 0.7054 - val_loss: 0.6181 - val_accuracy: 0.6532\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5829 - accuracy: 0.7073 - val_loss: 0.6108 - val_accuracy: 0.6624\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 603us/step - loss: 0.5809 - accuracy: 0.7082 - val_loss: 0.6060 - val_accuracy: 0.6664\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 602us/step - loss: 0.5798 - accuracy: 0.7104 - val_loss: 0.6157 - val_accuracy: 0.6541\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5792 - accuracy: 0.7082 - val_loss: 0.6094 - val_accuracy: 0.6603\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.5772 - accuracy: 0.7103 - val_loss: 0.6126 - val_accuracy: 0.6568\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.5753 - accuracy: 0.7120 - val_loss: 0.6069 - val_accuracy: 0.6600\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.5733 - accuracy: 0.7128 - val_loss: 0.6030 - val_accuracy: 0.6640\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 609us/step - loss: 0.5723 - accuracy: 0.7138 - val_loss: 0.6051 - val_accuracy: 0.6598\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.5700 - accuracy: 0.7160 - val_loss: 0.6082 - val_accuracy: 0.6577\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.5707 - accuracy: 0.7159 - val_loss: 0.6137 - val_accuracy: 0.6522\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 592us/step - loss: 0.5687 - accuracy: 0.7158 - val_loss: 0.6116 - val_accuracy: 0.6534\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 590us/step - loss: 0.5675 - accuracy: 0.7168 - val_loss: 0.6137 - val_accuracy: 0.6514\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.5659 - accuracy: 0.7183 - val_loss: 0.6058 - val_accuracy: 0.6555\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 560us/step - loss: 0.5638 - accuracy: 0.7197 - val_loss: 0.6022 - val_accuracy: 0.6576\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.7093 - accuracy: 0.4947 - val_loss: 0.7280 - val_accuracy: 0.2707\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.7007 - accuracy: 0.5176 - val_loss: 0.7258 - val_accuracy: 0.3218\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6932 - accuracy: 0.5350 - val_loss: 0.7199 - val_accuracy: 0.4044\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 618us/step - loss: 0.6865 - accuracy: 0.5473 - val_loss: 0.7131 - val_accuracy: 0.4703\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6815 - accuracy: 0.5625 - val_loss: 0.7094 - val_accuracy: 0.4984\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6766 - accuracy: 0.5737 - val_loss: 0.7010 - val_accuracy: 0.5307\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 601us/step - loss: 0.6722 - accuracy: 0.5853 - val_loss: 0.6971 - val_accuracy: 0.5478\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 621us/step - loss: 0.6690 - accuracy: 0.5922 - val_loss: 0.6921 - val_accuracy: 0.5599\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 610us/step - loss: 0.6667 - accuracy: 0.5973 - val_loss: 0.6951 - val_accuracy: 0.5531\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 600us/step - loss: 0.6630 - accuracy: 0.6038 - val_loss: 0.6902 - val_accuracy: 0.5634\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 633us/step - loss: 0.6614 - accuracy: 0.6066 - val_loss: 0.6875 - val_accuracy: 0.5701\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6589 - accuracy: 0.6134 - val_loss: 0.6833 - val_accuracy: 0.5777\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6561 - accuracy: 0.6158 - val_loss: 0.6801 - val_accuracy: 0.5848\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 623us/step - loss: 0.6530 - accuracy: 0.6240 - val_loss: 0.6806 - val_accuracy: 0.5853\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 604us/step - loss: 0.6500 - accuracy: 0.6270 - val_loss: 0.6762 - val_accuracy: 0.5971\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6492 - accuracy: 0.6280 - val_loss: 0.6741 - val_accuracy: 0.6012\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 629us/step - loss: 0.6463 - accuracy: 0.6321 - val_loss: 0.6679 - val_accuracy: 0.6150\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 594us/step - loss: 0.6450 - accuracy: 0.6354 - val_loss: 0.6678 - val_accuracy: 0.6133\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 599us/step - loss: 0.6432 - accuracy: 0.6383 - val_loss: 0.6679 - val_accuracy: 0.6116\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 588us/step - loss: 0.6411 - accuracy: 0.6431 - val_loss: 0.6655 - val_accuracy: 0.6164\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 591us/step - loss: 0.6387 - accuracy: 0.6440 - val_loss: 0.6641 - val_accuracy: 0.6196\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 642us/step - loss: 0.6367 - accuracy: 0.6455 - val_loss: 0.6594 - val_accuracy: 0.6283\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 579us/step - loss: 0.6345 - accuracy: 0.6513 - val_loss: 0.6599 - val_accuracy: 0.6256\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 568us/step - loss: 0.6328 - accuracy: 0.6522 - val_loss: 0.6572 - val_accuracy: 0.6309\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 634us/step - loss: 0.6312 - accuracy: 0.6546 - val_loss: 0.6584 - val_accuracy: 0.6269\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 587us/step - loss: 0.6284 - accuracy: 0.6565 - val_loss: 0.6551 - val_accuracy: 0.6318\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 586us/step - loss: 0.6275 - accuracy: 0.6586 - val_loss: 0.6557 - val_accuracy: 0.6289\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6254 - accuracy: 0.6599 - val_loss: 0.6545 - val_accuracy: 0.6290\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 676us/step - loss: 0.6231 - accuracy: 0.6639 - val_loss: 0.6488 - val_accuracy: 0.6384\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 619us/step - loss: 0.6214 - accuracy: 0.6642 - val_loss: 0.6495 - val_accuracy: 0.6349\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 631us/step - loss: 0.6196 - accuracy: 0.6674 - val_loss: 0.6507 - val_accuracy: 0.6313\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 597us/step - loss: 0.6183 - accuracy: 0.6707 - val_loss: 0.6446 - val_accuracy: 0.6398\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 596us/step - loss: 0.6150 - accuracy: 0.6721 - val_loss: 0.6428 - val_accuracy: 0.6420\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 622us/step - loss: 0.6139 - accuracy: 0.6738 - val_loss: 0.6452 - val_accuracy: 0.6370\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 595us/step - loss: 0.6118 - accuracy: 0.6788 - val_loss: 0.6385 - val_accuracy: 0.6481\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 598us/step - loss: 0.6103 - accuracy: 0.6807 - val_loss: 0.6376 - val_accuracy: 0.6499\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.6084 - accuracy: 0.6796 - val_loss: 0.6402 - val_accuracy: 0.6435\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 725us/step - loss: 0.6072 - accuracy: 0.6824 - val_loss: 0.6429 - val_accuracy: 0.6368\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 797us/step - loss: 0.6042 - accuracy: 0.6849 - val_loss: 0.6370 - val_accuracy: 0.6451\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 756us/step - loss: 0.6031 - accuracy: 0.6863 - val_loss: 0.6403 - val_accuracy: 0.6376\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 760us/step - loss: 0.6007 - accuracy: 0.6885 - val_loss: 0.6340 - val_accuracy: 0.6449\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 707us/step - loss: 0.5988 - accuracy: 0.6909 - val_loss: 0.6315 - val_accuracy: 0.6469\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.5973 - accuracy: 0.6919 - val_loss: 0.6306 - val_accuracy: 0.6468\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 645us/step - loss: 0.5951 - accuracy: 0.6926 - val_loss: 0.6299 - val_accuracy: 0.6464\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5936 - accuracy: 0.6954 - val_loss: 0.6295 - val_accuracy: 0.6456\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 722us/step - loss: 0.5923 - accuracy: 0.6958 - val_loss: 0.6260 - val_accuracy: 0.6488\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.5909 - accuracy: 0.6995 - val_loss: 0.6265 - val_accuracy: 0.6481\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.5896 - accuracy: 0.6991 - val_loss: 0.6195 - val_accuracy: 0.6574\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 655us/step - loss: 0.5876 - accuracy: 0.7008 - val_loss: 0.6212 - val_accuracy: 0.6524\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.5853 - accuracy: 0.7019 - val_loss: 0.6207 - val_accuracy: 0.6513\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.7280 - accuracy: 0.4557 - val_loss: 0.6910 - val_accuracy: 0.5288\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 1s 666us/step - loss: 0.7064 - accuracy: 0.4752 - val_loss: 0.7142 - val_accuracy: 0.3212\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 1s 713us/step - loss: 0.6993 - accuracy: 0.4985 - val_loss: 0.7123 - val_accuracy: 0.3491\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 1s 680us/step - loss: 0.6945 - accuracy: 0.5121 - val_loss: 0.7065 - val_accuracy: 0.3949\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.6894 - accuracy: 0.5274 - val_loss: 0.6996 - val_accuracy: 0.4732\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 1s 667us/step - loss: 0.6834 - accuracy: 0.5498 - val_loss: 0.6944 - val_accuracy: 0.5190\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6771 - accuracy: 0.5686 - val_loss: 0.6886 - val_accuracy: 0.5410\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.6733 - accuracy: 0.5829 - val_loss: 0.6846 - val_accuracy: 0.5611\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.6693 - accuracy: 0.5945 - val_loss: 0.6810 - val_accuracy: 0.5759\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 1s 693us/step - loss: 0.6657 - accuracy: 0.6039 - val_loss: 0.6776 - val_accuracy: 0.5850\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 1s 688us/step - loss: 0.6616 - accuracy: 0.6145 - val_loss: 0.6762 - val_accuracy: 0.5832\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 1s 694us/step - loss: 0.6575 - accuracy: 0.6239 - val_loss: 0.6696 - val_accuracy: 0.5977\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 1s 691us/step - loss: 0.6530 - accuracy: 0.6326 - val_loss: 0.6601 - val_accuracy: 0.6151\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.6496 - accuracy: 0.6397 - val_loss: 0.6614 - val_accuracy: 0.6150\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 1s 679us/step - loss: 0.6447 - accuracy: 0.6421 - val_loss: 0.6549 - val_accuracy: 0.6277\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 1s 730us/step - loss: 0.6418 - accuracy: 0.6476 - val_loss: 0.6534 - val_accuracy: 0.6284\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 1s 678us/step - loss: 0.6387 - accuracy: 0.6527 - val_loss: 0.6521 - val_accuracy: 0.6274\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6358 - accuracy: 0.6536 - val_loss: 0.6525 - val_accuracy: 0.6246\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 1s 840us/step - loss: 0.6326 - accuracy: 0.6601 - val_loss: 0.6444 - val_accuracy: 0.6366\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.6308 - accuracy: 0.6591 - val_loss: 0.6455 - val_accuracy: 0.6321\n",
      "Epoch 21/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.6268 - accuracy: 0.6679 - val_loss: 0.6440 - val_accuracy: 0.6314\n",
      "Epoch 22/50\n",
      "1672/1672 [==============================] - 1s 686us/step - loss: 0.6253 - accuracy: 0.6678 - val_loss: 0.6455 - val_accuracy: 0.6276\n",
      "Epoch 23/50\n",
      "1672/1672 [==============================] - 1s 726us/step - loss: 0.6222 - accuracy: 0.6718 - val_loss: 0.6398 - val_accuracy: 0.6341\n",
      "Epoch 24/50\n",
      "1672/1672 [==============================] - 1s 715us/step - loss: 0.6197 - accuracy: 0.6736 - val_loss: 0.6410 - val_accuracy: 0.6314\n",
      "Epoch 25/50\n",
      "1672/1672 [==============================] - 1s 746us/step - loss: 0.6183 - accuracy: 0.6742 - val_loss: 0.6376 - val_accuracy: 0.6344\n",
      "Epoch 26/50\n",
      "1672/1672 [==============================] - 1s 700us/step - loss: 0.6154 - accuracy: 0.6762 - val_loss: 0.6362 - val_accuracy: 0.6344\n",
      "Epoch 27/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.6135 - accuracy: 0.6805 - val_loss: 0.6297 - val_accuracy: 0.6423\n",
      "Epoch 28/50\n",
      "1672/1672 [==============================] - 1s 689us/step - loss: 0.6117 - accuracy: 0.6817 - val_loss: 0.6310 - val_accuracy: 0.6387\n",
      "Epoch 29/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.6097 - accuracy: 0.6825 - val_loss: 0.6267 - val_accuracy: 0.6436\n",
      "Epoch 30/50\n",
      "1672/1672 [==============================] - 1s 716us/step - loss: 0.6074 - accuracy: 0.6842 - val_loss: 0.6236 - val_accuracy: 0.6460\n",
      "Epoch 31/50\n",
      "1672/1672 [==============================] - 1s 702us/step - loss: 0.6054 - accuracy: 0.6857 - val_loss: 0.6254 - val_accuracy: 0.6415\n",
      "Epoch 32/50\n",
      "1672/1672 [==============================] - 1s 738us/step - loss: 0.6031 - accuracy: 0.6887 - val_loss: 0.6286 - val_accuracy: 0.6378\n",
      "Epoch 33/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.6007 - accuracy: 0.6910 - val_loss: 0.6269 - val_accuracy: 0.6386\n",
      "Epoch 34/50\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.5993 - accuracy: 0.6918 - val_loss: 0.6200 - val_accuracy: 0.6456\n",
      "Epoch 35/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5967 - accuracy: 0.6928 - val_loss: 0.6235 - val_accuracy: 0.6408\n",
      "Epoch 36/50\n",
      "1672/1672 [==============================] - 1s 687us/step - loss: 0.5955 - accuracy: 0.6951 - val_loss: 0.6191 - val_accuracy: 0.6448\n",
      "Epoch 37/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.5939 - accuracy: 0.6975 - val_loss: 0.6190 - val_accuracy: 0.6453\n",
      "Epoch 38/50\n",
      "1672/1672 [==============================] - 1s 745us/step - loss: 0.5910 - accuracy: 0.6999 - val_loss: 0.6152 - val_accuracy: 0.6499\n",
      "Epoch 39/50\n",
      "1672/1672 [==============================] - 1s 743us/step - loss: 0.5900 - accuracy: 0.6992 - val_loss: 0.6133 - val_accuracy: 0.6509\n",
      "Epoch 40/50\n",
      "1672/1672 [==============================] - 1s 718us/step - loss: 0.5880 - accuracy: 0.7023 - val_loss: 0.6179 - val_accuracy: 0.6451\n",
      "Epoch 41/50\n",
      "1672/1672 [==============================] - 1s 703us/step - loss: 0.5860 - accuracy: 0.7034 - val_loss: 0.6177 - val_accuracy: 0.6436\n",
      "Epoch 42/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.5843 - accuracy: 0.7050 - val_loss: 0.6220 - val_accuracy: 0.6386\n",
      "Epoch 43/50\n",
      "1672/1672 [==============================] - 1s 720us/step - loss: 0.5827 - accuracy: 0.7053 - val_loss: 0.6195 - val_accuracy: 0.6405\n",
      "Epoch 44/50\n",
      "1672/1672 [==============================] - 1s 727us/step - loss: 0.5815 - accuracy: 0.7058 - val_loss: 0.6144 - val_accuracy: 0.6454\n",
      "Epoch 45/50\n",
      "1672/1672 [==============================] - 1s 754us/step - loss: 0.5799 - accuracy: 0.7075 - val_loss: 0.6149 - val_accuracy: 0.6438\n",
      "Epoch 46/50\n",
      "1672/1672 [==============================] - 1s 712us/step - loss: 0.5786 - accuracy: 0.7093 - val_loss: 0.6102 - val_accuracy: 0.6471\n",
      "Epoch 47/50\n",
      "1672/1672 [==============================] - 1s 728us/step - loss: 0.5763 - accuracy: 0.7098 - val_loss: 0.6157 - val_accuracy: 0.6404\n",
      "Epoch 48/50\n",
      "1672/1672 [==============================] - 1s 708us/step - loss: 0.5745 - accuracy: 0.7123 - val_loss: 0.6091 - val_accuracy: 0.6456\n",
      "Epoch 49/50\n",
      "1672/1672 [==============================] - 1s 658us/step - loss: 0.5740 - accuracy: 0.7121 - val_loss: 0.6098 - val_accuracy: 0.6447\n",
      "Epoch 50/50\n",
      "1672/1672 [==============================] - 1s 827us/step - loss: 0.5718 - accuracy: 0.7144 - val_loss: 0.6129 - val_accuracy: 0.6404\n",
      "\n",
      "Training model with sample_size_ratio=0.5, target_eps=0.5...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 5.05 iterated over 41800 steps satisfies differential privacy with eps = 0.245 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.5749999999999997 iterated over 41800 steps satisfies differential privacy with eps = 0.481 and delta = 1e-05.\n",
      "The optimal RDP order is 49.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3375 iterated over 41800 steps satisfies differential privacy with eps = 1.05 and delta = 1e-05.\n",
      "The optimal RDP order is 22.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.9562499999999998 iterated over 41800 steps satisfies differential privacy with eps = 0.655 and delta = 1e-05.\n",
      "The optimal RDP order is 36.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.265625 iterated over 41800 steps satisfies differential privacy with eps = 0.554 and delta = 1e-05.\n",
      "The optimal RDP order is 43.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.4203124999999996 iterated over 41800 steps satisfies differential privacy with eps = 0.515 and delta = 1e-05.\n",
      "The optimal RDP order is 46.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.4976562499999995 iterated over 41800 steps satisfies differential privacy with eps = 0.497 and delta = 1e-05.\n",
      "The optimal RDP order is 48.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.6937 - accuracy: 0.5162 - val_loss: 0.6959 - val_accuracy: 0.4987\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6876 - accuracy: 0.5381 - val_loss: 0.7094 - val_accuracy: 0.4275\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6847 - accuracy: 0.5516 - val_loss: 0.7087 - val_accuracy: 0.4366\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6793 - accuracy: 0.5668 - val_loss: 0.7077 - val_accuracy: 0.4539\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6764 - accuracy: 0.5728 - val_loss: 0.7036 - val_accuracy: 0.4817\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 789us/step - loss: 0.6745 - accuracy: 0.5765 - val_loss: 0.6995 - val_accuracy: 0.5028\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.6709 - accuracy: 0.5912 - val_loss: 0.6946 - val_accuracy: 0.5234\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6692 - accuracy: 0.5918 - val_loss: 0.6932 - val_accuracy: 0.5305\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6652 - accuracy: 0.5990 - val_loss: 0.6906 - val_accuracy: 0.5435\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6638 - accuracy: 0.6035 - val_loss: 0.6859 - val_accuracy: 0.5671\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6617 - accuracy: 0.6081 - val_loss: 0.6834 - val_accuracy: 0.5785\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6598 - accuracy: 0.6129 - val_loss: 0.6826 - val_accuracy: 0.5821\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6575 - accuracy: 0.6124 - val_loss: 0.6811 - val_accuracy: 0.5879\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6565 - accuracy: 0.6198 - val_loss: 0.6787 - val_accuracy: 0.5955\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 721us/step - loss: 0.6550 - accuracy: 0.6211 - val_loss: 0.6783 - val_accuracy: 0.5956\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 663us/step - loss: 0.6534 - accuracy: 0.6235 - val_loss: 0.6760 - val_accuracy: 0.6025\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6536 - accuracy: 0.6210 - val_loss: 0.6755 - val_accuracy: 0.6032\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6510 - accuracy: 0.6253 - val_loss: 0.6734 - val_accuracy: 0.6080\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 719us/step - loss: 0.6503 - accuracy: 0.6268 - val_loss: 0.6700 - val_accuracy: 0.6141\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6482 - accuracy: 0.6324 - val_loss: 0.6721 - val_accuracy: 0.6074\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6463 - accuracy: 0.6339 - val_loss: 0.6708 - val_accuracy: 0.6085\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6449 - accuracy: 0.6381 - val_loss: 0.6672 - val_accuracy: 0.6162\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.6436 - accuracy: 0.6371 - val_loss: 0.6664 - val_accuracy: 0.6157\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6419 - accuracy: 0.6412 - val_loss: 0.6634 - val_accuracy: 0.6190\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.6411 - accuracy: 0.6410 - val_loss: 0.6643 - val_accuracy: 0.6145\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 707us/step - loss: 0.6378 - accuracy: 0.6468 - val_loss: 0.6604 - val_accuracy: 0.6193\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 813us/step - loss: 0.6379 - accuracy: 0.6458 - val_loss: 0.6597 - val_accuracy: 0.6199\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.6348 - accuracy: 0.6483 - val_loss: 0.6562 - val_accuracy: 0.6256\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.6352 - accuracy: 0.6450 - val_loss: 0.6535 - val_accuracy: 0.6294\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6316 - accuracy: 0.6508 - val_loss: 0.6480 - val_accuracy: 0.6382\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6323 - accuracy: 0.6468 - val_loss: 0.6486 - val_accuracy: 0.6371\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.6290 - accuracy: 0.6557 - val_loss: 0.6486 - val_accuracy: 0.6366\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6268 - accuracy: 0.6580 - val_loss: 0.6449 - val_accuracy: 0.6439\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 647us/step - loss: 0.6272 - accuracy: 0.6553 - val_loss: 0.6462 - val_accuracy: 0.6409\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6251 - accuracy: 0.6558 - val_loss: 0.6448 - val_accuracy: 0.6428\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6260 - accuracy: 0.6547 - val_loss: 0.6439 - val_accuracy: 0.6440\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6241 - accuracy: 0.6570 - val_loss: 0.6450 - val_accuracy: 0.6419\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.6228 - accuracy: 0.6605 - val_loss: 0.6443 - val_accuracy: 0.6427\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6219 - accuracy: 0.6596 - val_loss: 0.6434 - val_accuracy: 0.6438\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6210 - accuracy: 0.6586 - val_loss: 0.6419 - val_accuracy: 0.6453\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6209 - accuracy: 0.6594 - val_loss: 0.6416 - val_accuracy: 0.6454\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6191 - accuracy: 0.6618 - val_loss: 0.6414 - val_accuracy: 0.6453\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6178 - accuracy: 0.6632 - val_loss: 0.6399 - val_accuracy: 0.6461\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6175 - accuracy: 0.6631 - val_loss: 0.6394 - val_accuracy: 0.6461\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.6164 - accuracy: 0.6636 - val_loss: 0.6393 - val_accuracy: 0.6460\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6152 - accuracy: 0.6665 - val_loss: 0.6383 - val_accuracy: 0.6464\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6140 - accuracy: 0.6666 - val_loss: 0.6377 - val_accuracy: 0.6467\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6131 - accuracy: 0.6684 - val_loss: 0.6370 - val_accuracy: 0.6468\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 708us/step - loss: 0.6127 - accuracy: 0.6677 - val_loss: 0.6394 - val_accuracy: 0.6428\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 730us/step - loss: 0.6131 - accuracy: 0.6655 - val_loss: 0.6361 - val_accuracy: 0.6470\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6960 - accuracy: 0.5496 - val_loss: 0.7328 - val_accuracy: 0.2934\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6883 - accuracy: 0.5586 - val_loss: 0.7147 - val_accuracy: 0.3982\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6832 - accuracy: 0.5674 - val_loss: 0.7075 - val_accuracy: 0.4468\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6820 - accuracy: 0.5668 - val_loss: 0.7093 - val_accuracy: 0.4493\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6775 - accuracy: 0.5785 - val_loss: 0.7029 - val_accuracy: 0.4736\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.6774 - accuracy: 0.5791 - val_loss: 0.6970 - val_accuracy: 0.4907\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6727 - accuracy: 0.5876 - val_loss: 0.6957 - val_accuracy: 0.5005\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6687 - accuracy: 0.5928 - val_loss: 0.6964 - val_accuracy: 0.5018\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6693 - accuracy: 0.5944 - val_loss: 0.6906 - val_accuracy: 0.5203\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.6646 - accuracy: 0.6015 - val_loss: 0.6887 - val_accuracy: 0.5315\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 690us/step - loss: 0.6633 - accuracy: 0.6057 - val_loss: 0.6872 - val_accuracy: 0.5386\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6603 - accuracy: 0.6121 - val_loss: 0.6829 - val_accuracy: 0.5567\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6578 - accuracy: 0.6162 - val_loss: 0.6846 - val_accuracy: 0.5538\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.6546 - accuracy: 0.6223 - val_loss: 0.6772 - val_accuracy: 0.5806\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 598us/step - loss: 0.6552 - accuracy: 0.6159 - val_loss: 0.6752 - val_accuracy: 0.5872\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.6524 - accuracy: 0.6255 - val_loss: 0.6750 - val_accuracy: 0.5877\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.6502 - accuracy: 0.6284 - val_loss: 0.6739 - val_accuracy: 0.5901\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6492 - accuracy: 0.6323 - val_loss: 0.6727 - val_accuracy: 0.5924\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6463 - accuracy: 0.6349 - val_loss: 0.6718 - val_accuracy: 0.5937\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6449 - accuracy: 0.6392 - val_loss: 0.6682 - val_accuracy: 0.6004\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 636us/step - loss: 0.6428 - accuracy: 0.6386 - val_loss: 0.6625 - val_accuracy: 0.6116\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.6404 - accuracy: 0.6410 - val_loss: 0.6627 - val_accuracy: 0.6100\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 687us/step - loss: 0.6395 - accuracy: 0.6423 - val_loss: 0.6642 - val_accuracy: 0.6075\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.6370 - accuracy: 0.6441 - val_loss: 0.6622 - val_accuracy: 0.6103\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6338 - accuracy: 0.6500 - val_loss: 0.6577 - val_accuracy: 0.6180\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 711us/step - loss: 0.6343 - accuracy: 0.6499 - val_loss: 0.6559 - val_accuracy: 0.6205\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6332 - accuracy: 0.6484 - val_loss: 0.6493 - val_accuracy: 0.6302\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6309 - accuracy: 0.6511 - val_loss: 0.6517 - val_accuracy: 0.6262\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6299 - accuracy: 0.6524 - val_loss: 0.6482 - val_accuracy: 0.6310\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 730us/step - loss: 0.6279 - accuracy: 0.6573 - val_loss: 0.6466 - val_accuracy: 0.6328\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6256 - accuracy: 0.6612 - val_loss: 0.6435 - val_accuracy: 0.6372\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 824us/step - loss: 0.6259 - accuracy: 0.6551 - val_loss: 0.6441 - val_accuracy: 0.6359\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6226 - accuracy: 0.6626 - val_loss: 0.6443 - val_accuracy: 0.6349\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6223 - accuracy: 0.6626 - val_loss: 0.6419 - val_accuracy: 0.6391\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 639us/step - loss: 0.6209 - accuracy: 0.6633 - val_loss: 0.6382 - val_accuracy: 0.6456\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6181 - accuracy: 0.6651 - val_loss: 0.6418 - val_accuracy: 0.6382\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.6164 - accuracy: 0.6663 - val_loss: 0.6329 - val_accuracy: 0.6519\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 704us/step - loss: 0.6140 - accuracy: 0.6725 - val_loss: 0.6344 - val_accuracy: 0.6474\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6135 - accuracy: 0.6685 - val_loss: 0.6319 - val_accuracy: 0.6501\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6106 - accuracy: 0.6751 - val_loss: 0.6288 - val_accuracy: 0.6545\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 733us/step - loss: 0.6112 - accuracy: 0.6740 - val_loss: 0.6297 - val_accuracy: 0.6512\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 708us/step - loss: 0.6103 - accuracy: 0.6743 - val_loss: 0.6296 - val_accuracy: 0.6503\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 633us/step - loss: 0.6091 - accuracy: 0.6729 - val_loss: 0.6247 - val_accuracy: 0.6568\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 719us/step - loss: 0.6077 - accuracy: 0.6736 - val_loss: 0.6296 - val_accuracy: 0.6487\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6063 - accuracy: 0.6786 - val_loss: 0.6282 - val_accuracy: 0.6503\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6050 - accuracy: 0.6768 - val_loss: 0.6263 - val_accuracy: 0.6519\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 704us/step - loss: 0.6037 - accuracy: 0.6800 - val_loss: 0.6258 - val_accuracy: 0.6518\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6028 - accuracy: 0.6782 - val_loss: 0.6236 - val_accuracy: 0.6539\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6011 - accuracy: 0.6816 - val_loss: 0.6226 - val_accuracy: 0.6541\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 736us/step - loss: 0.6016 - accuracy: 0.6799 - val_loss: 0.6206 - val_accuracy: 0.6560\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6905 - accuracy: 0.5385 - val_loss: 0.6859 - val_accuracy: 0.5788\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6866 - accuracy: 0.5478 - val_loss: 0.6901 - val_accuracy: 0.5445\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 717us/step - loss: 0.6843 - accuracy: 0.5570 - val_loss: 0.6881 - val_accuracy: 0.5532\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6794 - accuracy: 0.5686 - val_loss: 0.6860 - val_accuracy: 0.5636\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6776 - accuracy: 0.5711 - val_loss: 0.6833 - val_accuracy: 0.5769\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.6762 - accuracy: 0.5741 - val_loss: 0.6815 - val_accuracy: 0.5852\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6741 - accuracy: 0.5806 - val_loss: 0.6805 - val_accuracy: 0.5874\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 686us/step - loss: 0.6717 - accuracy: 0.5849 - val_loss: 0.6786 - val_accuracy: 0.5936\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6711 - accuracy: 0.5886 - val_loss: 0.6784 - val_accuracy: 0.5907\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6691 - accuracy: 0.5922 - val_loss: 0.6775 - val_accuracy: 0.5942\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6657 - accuracy: 0.5979 - val_loss: 0.6759 - val_accuracy: 0.6002\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6634 - accuracy: 0.6016 - val_loss: 0.6766 - val_accuracy: 0.5944\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6626 - accuracy: 0.6082 - val_loss: 0.6727 - val_accuracy: 0.6073\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6596 - accuracy: 0.6114 - val_loss: 0.6717 - val_accuracy: 0.6085\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6586 - accuracy: 0.6116 - val_loss: 0.6694 - val_accuracy: 0.6134\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6583 - accuracy: 0.6089 - val_loss: 0.6679 - val_accuracy: 0.6178\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6573 - accuracy: 0.6099 - val_loss: 0.6655 - val_accuracy: 0.6231\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6543 - accuracy: 0.6168 - val_loss: 0.6635 - val_accuracy: 0.6247\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 872us/step - loss: 0.6531 - accuracy: 0.6189 - val_loss: 0.6639 - val_accuracy: 0.6206\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6504 - accuracy: 0.6246 - val_loss: 0.6599 - val_accuracy: 0.6295\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6483 - accuracy: 0.6255 - val_loss: 0.6578 - val_accuracy: 0.6315\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6466 - accuracy: 0.6286 - val_loss: 0.6556 - val_accuracy: 0.6325\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.6441 - accuracy: 0.6331 - val_loss: 0.6534 - val_accuracy: 0.6349\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 607us/step - loss: 0.6435 - accuracy: 0.6340 - val_loss: 0.6532 - val_accuracy: 0.6312\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6422 - accuracy: 0.6372 - val_loss: 0.6515 - val_accuracy: 0.6319\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6415 - accuracy: 0.6375 - val_loss: 0.6490 - val_accuracy: 0.6345\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 679us/step - loss: 0.6392 - accuracy: 0.6369 - val_loss: 0.6485 - val_accuracy: 0.6344\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6365 - accuracy: 0.6433 - val_loss: 0.6480 - val_accuracy: 0.6343\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 623us/step - loss: 0.6364 - accuracy: 0.6434 - val_loss: 0.6458 - val_accuracy: 0.6361\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.6355 - accuracy: 0.6462 - val_loss: 0.6454 - val_accuracy: 0.6359\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 717us/step - loss: 0.6341 - accuracy: 0.6463 - val_loss: 0.6439 - val_accuracy: 0.6375\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6308 - accuracy: 0.6533 - val_loss: 0.6410 - val_accuracy: 0.6439\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 690us/step - loss: 0.6299 - accuracy: 0.6546 - val_loss: 0.6393 - val_accuracy: 0.6461\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6287 - accuracy: 0.6542 - val_loss: 0.6390 - val_accuracy: 0.6453\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6272 - accuracy: 0.6571 - val_loss: 0.6367 - val_accuracy: 0.6465\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6261 - accuracy: 0.6589 - val_loss: 0.6372 - val_accuracy: 0.6437\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.6239 - accuracy: 0.6615 - val_loss: 0.6348 - val_accuracy: 0.6453\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6250 - accuracy: 0.6587 - val_loss: 0.6336 - val_accuracy: 0.6451\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 719us/step - loss: 0.6230 - accuracy: 0.6646 - val_loss: 0.6332 - val_accuracy: 0.6448\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6214 - accuracy: 0.6667 - val_loss: 0.6308 - val_accuracy: 0.6459\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.6203 - accuracy: 0.6661 - val_loss: 0.6316 - val_accuracy: 0.6443\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.6192 - accuracy: 0.6674 - val_loss: 0.6323 - val_accuracy: 0.6438\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6164 - accuracy: 0.6724 - val_loss: 0.6310 - val_accuracy: 0.6439\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.6159 - accuracy: 0.6734 - val_loss: 0.6303 - val_accuracy: 0.6433\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6148 - accuracy: 0.6770 - val_loss: 0.6322 - val_accuracy: 0.6406\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6153 - accuracy: 0.6732 - val_loss: 0.6304 - val_accuracy: 0.6423\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 650us/step - loss: 0.6146 - accuracy: 0.6733 - val_loss: 0.6261 - val_accuracy: 0.6481\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6120 - accuracy: 0.6779 - val_loss: 0.6282 - val_accuracy: 0.6449\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6109 - accuracy: 0.6799 - val_loss: 0.6272 - val_accuracy: 0.6451\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 708us/step - loss: 0.6102 - accuracy: 0.6787 - val_loss: 0.6258 - val_accuracy: 0.6458\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.7487 - accuracy: 0.5114 - val_loss: 0.8797 - val_accuracy: 0.1178\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.7132 - accuracy: 0.5050 - val_loss: 0.7874 - val_accuracy: 0.1321\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.7029 - accuracy: 0.5124 - val_loss: 0.7477 - val_accuracy: 0.2145\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6976 - accuracy: 0.5185 - val_loss: 0.7290 - val_accuracy: 0.2899\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6968 - accuracy: 0.5205 - val_loss: 0.7202 - val_accuracy: 0.3408\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6948 - accuracy: 0.5256 - val_loss: 0.7147 - val_accuracy: 0.3756\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 707us/step - loss: 0.6931 - accuracy: 0.5341 - val_loss: 0.7124 - val_accuracy: 0.3959\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6916 - accuracy: 0.5352 - val_loss: 0.7114 - val_accuracy: 0.4059\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.7105 - val_accuracy: 0.4180\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 720us/step - loss: 0.6885 - accuracy: 0.5450 - val_loss: 0.7082 - val_accuracy: 0.4334\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 741us/step - loss: 0.6863 - accuracy: 0.5538 - val_loss: 0.7067 - val_accuracy: 0.4493\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 717us/step - loss: 0.6847 - accuracy: 0.5586 - val_loss: 0.7045 - val_accuracy: 0.4640\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6838 - accuracy: 0.5589 - val_loss: 0.7032 - val_accuracy: 0.4736\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6823 - accuracy: 0.5651 - val_loss: 0.7017 - val_accuracy: 0.4814\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6806 - accuracy: 0.5686 - val_loss: 0.6992 - val_accuracy: 0.4922\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6798 - accuracy: 0.5712 - val_loss: 0.6981 - val_accuracy: 0.4995\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.6782 - accuracy: 0.5789 - val_loss: 0.6968 - val_accuracy: 0.5046\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6771 - accuracy: 0.5836 - val_loss: 0.6955 - val_accuracy: 0.5097\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.6748 - accuracy: 0.5898 - val_loss: 0.6941 - val_accuracy: 0.5151\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6743 - accuracy: 0.5889 - val_loss: 0.6920 - val_accuracy: 0.5253\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6735 - accuracy: 0.5880 - val_loss: 0.6915 - val_accuracy: 0.5301\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 669us/step - loss: 0.6707 - accuracy: 0.5980 - val_loss: 0.6888 - val_accuracy: 0.5386\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.6690 - accuracy: 0.6048 - val_loss: 0.6874 - val_accuracy: 0.5426\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6688 - accuracy: 0.6017 - val_loss: 0.6857 - val_accuracy: 0.5475\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 677us/step - loss: 0.6666 - accuracy: 0.6022 - val_loss: 0.6840 - val_accuracy: 0.5552\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6647 - accuracy: 0.6080 - val_loss: 0.6833 - val_accuracy: 0.5589\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6636 - accuracy: 0.6090 - val_loss: 0.6824 - val_accuracy: 0.5615\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6621 - accuracy: 0.6161 - val_loss: 0.6815 - val_accuracy: 0.5652\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 891us/step - loss: 0.6619 - accuracy: 0.6141 - val_loss: 0.6801 - val_accuracy: 0.5702\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 979us/step - loss: 0.6601 - accuracy: 0.6194 - val_loss: 0.6799 - val_accuracy: 0.5702\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6578 - accuracy: 0.6217 - val_loss: 0.6785 - val_accuracy: 0.5753\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6578 - accuracy: 0.6190 - val_loss: 0.6760 - val_accuracy: 0.5831\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6561 - accuracy: 0.6224 - val_loss: 0.6741 - val_accuracy: 0.5898\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6557 - accuracy: 0.6220 - val_loss: 0.6726 - val_accuracy: 0.5944\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6535 - accuracy: 0.6299 - val_loss: 0.6713 - val_accuracy: 0.5976\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6517 - accuracy: 0.6295 - val_loss: 0.6695 - val_accuracy: 0.6015\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 965us/step - loss: 0.6520 - accuracy: 0.6292 - val_loss: 0.6683 - val_accuracy: 0.6032\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 801us/step - loss: 0.6512 - accuracy: 0.6275 - val_loss: 0.6680 - val_accuracy: 0.6030\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6492 - accuracy: 0.6321 - val_loss: 0.6686 - val_accuracy: 0.6012\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6480 - accuracy: 0.6350 - val_loss: 0.6658 - val_accuracy: 0.6065\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 826us/step - loss: 0.6464 - accuracy: 0.6371 - val_loss: 0.6644 - val_accuracy: 0.6089\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6460 - accuracy: 0.6370 - val_loss: 0.6626 - val_accuracy: 0.6125\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.6432 - accuracy: 0.6408 - val_loss: 0.6606 - val_accuracy: 0.6162\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6439 - accuracy: 0.6412 - val_loss: 0.6593 - val_accuracy: 0.6182\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6425 - accuracy: 0.6395 - val_loss: 0.6597 - val_accuracy: 0.6171\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6403 - accuracy: 0.6413 - val_loss: 0.6572 - val_accuracy: 0.6215\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 806us/step - loss: 0.6392 - accuracy: 0.6440 - val_loss: 0.6563 - val_accuracy: 0.6220\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 797us/step - loss: 0.6389 - accuracy: 0.6436 - val_loss: 0.6550 - val_accuracy: 0.6238\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6376 - accuracy: 0.6450 - val_loss: 0.6536 - val_accuracy: 0.6263\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 719us/step - loss: 0.6379 - accuracy: 0.6430 - val_loss: 0.6522 - val_accuracy: 0.6287\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 809us/step - loss: 0.7180 - accuracy: 0.4645 - val_loss: 0.7275 - val_accuracy: 0.2772\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.7106 - accuracy: 0.4870 - val_loss: 0.7330 - val_accuracy: 0.2208\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.7068 - accuracy: 0.4952 - val_loss: 0.7311 - val_accuracy: 0.2218\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.7018 - accuracy: 0.5090 - val_loss: 0.7287 - val_accuracy: 0.2427\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.6972 - accuracy: 0.5213 - val_loss: 0.7289 - val_accuracy: 0.2477\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6934 - accuracy: 0.5312 - val_loss: 0.7235 - val_accuracy: 0.2632\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6900 - accuracy: 0.5379 - val_loss: 0.7200 - val_accuracy: 0.2801\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 810us/step - loss: 0.6866 - accuracy: 0.5488 - val_loss: 0.7159 - val_accuracy: 0.3280\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6837 - accuracy: 0.5623 - val_loss: 0.7130 - val_accuracy: 0.3628\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6789 - accuracy: 0.5741 - val_loss: 0.7087 - val_accuracy: 0.4024\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6765 - accuracy: 0.5806 - val_loss: 0.7040 - val_accuracy: 0.4524\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 808us/step - loss: 0.6733 - accuracy: 0.5896 - val_loss: 0.7040 - val_accuracy: 0.4609\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6692 - accuracy: 0.6007 - val_loss: 0.7004 - val_accuracy: 0.4847\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.6673 - accuracy: 0.6013 - val_loss: 0.6982 - val_accuracy: 0.4954\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6655 - accuracy: 0.6076 - val_loss: 0.6959 - val_accuracy: 0.5022\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 808us/step - loss: 0.6632 - accuracy: 0.6140 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.6609 - accuracy: 0.6228 - val_loss: 0.6896 - val_accuracy: 0.5234\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6590 - accuracy: 0.6238 - val_loss: 0.6874 - val_accuracy: 0.5300\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.6570 - accuracy: 0.6284 - val_loss: 0.6835 - val_accuracy: 0.5438\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 923us/step - loss: 0.6559 - accuracy: 0.6348 - val_loss: 0.6830 - val_accuracy: 0.5464\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6522 - accuracy: 0.6395 - val_loss: 0.6816 - val_accuracy: 0.5514\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6512 - accuracy: 0.6394 - val_loss: 0.6794 - val_accuracy: 0.5601\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6500 - accuracy: 0.6415 - val_loss: 0.6794 - val_accuracy: 0.5615\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6468 - accuracy: 0.6470 - val_loss: 0.6747 - val_accuracy: 0.5767\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6467 - accuracy: 0.6485 - val_loss: 0.6728 - val_accuracy: 0.5811\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 717us/step - loss: 0.6445 - accuracy: 0.6499 - val_loss: 0.6690 - val_accuracy: 0.5915\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6423 - accuracy: 0.6540 - val_loss: 0.6673 - val_accuracy: 0.5943\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6416 - accuracy: 0.6515 - val_loss: 0.6691 - val_accuracy: 0.5883\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6402 - accuracy: 0.6527 - val_loss: 0.6641 - val_accuracy: 0.5974\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6378 - accuracy: 0.6557 - val_loss: 0.6656 - val_accuracy: 0.5935\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 711us/step - loss: 0.6362 - accuracy: 0.6640 - val_loss: 0.6645 - val_accuracy: 0.5942\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6334 - accuracy: 0.6631 - val_loss: 0.6623 - val_accuracy: 0.5974\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6340 - accuracy: 0.6616 - val_loss: 0.6606 - val_accuracy: 0.5990\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6319 - accuracy: 0.6651 - val_loss: 0.6584 - val_accuracy: 0.6036\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6300 - accuracy: 0.6644 - val_loss: 0.6537 - val_accuracy: 0.6115\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6296 - accuracy: 0.6646 - val_loss: 0.6570 - val_accuracy: 0.6056\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 784us/step - loss: 0.6283 - accuracy: 0.6659 - val_loss: 0.6562 - val_accuracy: 0.6064\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6257 - accuracy: 0.6658 - val_loss: 0.6504 - val_accuracy: 0.6131\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 800us/step - loss: 0.6242 - accuracy: 0.6699 - val_loss: 0.6481 - val_accuracy: 0.6159\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6243 - accuracy: 0.6708 - val_loss: 0.6453 - val_accuracy: 0.6201\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6229 - accuracy: 0.6724 - val_loss: 0.6433 - val_accuracy: 0.6231\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 815us/step - loss: 0.6202 - accuracy: 0.6749 - val_loss: 0.6426 - val_accuracy: 0.6229\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 795us/step - loss: 0.6190 - accuracy: 0.6757 - val_loss: 0.6437 - val_accuracy: 0.6190\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6192 - accuracy: 0.6750 - val_loss: 0.6423 - val_accuracy: 0.6199\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.6177 - accuracy: 0.6765 - val_loss: 0.6381 - val_accuracy: 0.6283\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6149 - accuracy: 0.6790 - val_loss: 0.6400 - val_accuracy: 0.6240\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 914us/step - loss: 0.6161 - accuracy: 0.6723 - val_loss: 0.6380 - val_accuracy: 0.6262\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 805us/step - loss: 0.6139 - accuracy: 0.6789 - val_loss: 0.6407 - val_accuracy: 0.6211\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6127 - accuracy: 0.6791 - val_loss: 0.6350 - val_accuracy: 0.6297\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6109 - accuracy: 0.6808 - val_loss: 0.6377 - val_accuracy: 0.6241\n",
      "Epoch 1/50\n",
      "780/836 [==========================>...] - ETA: 0s - loss: 0.7666 - accuracy: 0.4752WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0009s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.7648 - accuracy: 0.4739 - val_loss: 0.6091 - val_accuracy: 0.8643\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.7214 - accuracy: 0.4601 - val_loss: 0.6740 - val_accuracy: 0.6785\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.7092 - accuracy: 0.4759 - val_loss: 0.7046 - val_accuracy: 0.3710\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.7020 - accuracy: 0.4995 - val_loss: 0.7153 - val_accuracy: 0.2908\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6971 - accuracy: 0.5153 - val_loss: 0.7175 - val_accuracy: 0.2946\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 805us/step - loss: 0.6923 - accuracy: 0.5261 - val_loss: 0.7135 - val_accuracy: 0.3479\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6888 - accuracy: 0.5367 - val_loss: 0.7102 - val_accuracy: 0.4106\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6858 - accuracy: 0.5500 - val_loss: 0.7084 - val_accuracy: 0.4490\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6848 - accuracy: 0.5564 - val_loss: 0.7058 - val_accuracy: 0.4730\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 801us/step - loss: 0.6810 - accuracy: 0.5666 - val_loss: 0.7028 - val_accuracy: 0.4959\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 795us/step - loss: 0.6780 - accuracy: 0.5735 - val_loss: 0.7000 - val_accuracy: 0.5122\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.6766 - accuracy: 0.5784 - val_loss: 0.6975 - val_accuracy: 0.5271\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6743 - accuracy: 0.5878 - val_loss: 0.6963 - val_accuracy: 0.5349\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 809us/step - loss: 0.6733 - accuracy: 0.5902 - val_loss: 0.6931 - val_accuracy: 0.5465\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6702 - accuracy: 0.5975 - val_loss: 0.6907 - val_accuracy: 0.5517\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 805us/step - loss: 0.6683 - accuracy: 0.5991 - val_loss: 0.6885 - val_accuracy: 0.5562\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 804us/step - loss: 0.6677 - accuracy: 0.6030 - val_loss: 0.6854 - val_accuracy: 0.5625\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6649 - accuracy: 0.6084 - val_loss: 0.6808 - val_accuracy: 0.5725\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6623 - accuracy: 0.6150 - val_loss: 0.6784 - val_accuracy: 0.5799\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6601 - accuracy: 0.6180 - val_loss: 0.6767 - val_accuracy: 0.5845\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 826us/step - loss: 0.6575 - accuracy: 0.6240 - val_loss: 0.6725 - val_accuracy: 0.5948\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6552 - accuracy: 0.6297 - val_loss: 0.6680 - val_accuracy: 0.6043\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6533 - accuracy: 0.6324 - val_loss: 0.6661 - val_accuracy: 0.6074\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6515 - accuracy: 0.6323 - val_loss: 0.6638 - val_accuracy: 0.6113\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6487 - accuracy: 0.6347 - val_loss: 0.6611 - val_accuracy: 0.6162\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 805us/step - loss: 0.6473 - accuracy: 0.6399 - val_loss: 0.6599 - val_accuracy: 0.6177\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6457 - accuracy: 0.6429 - val_loss: 0.6569 - val_accuracy: 0.6231\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6442 - accuracy: 0.6427 - val_loss: 0.6525 - val_accuracy: 0.6318\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.6416 - accuracy: 0.6453 - val_loss: 0.6516 - val_accuracy: 0.6324\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6411 - accuracy: 0.6433 - val_loss: 0.6529 - val_accuracy: 0.6284\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6384 - accuracy: 0.6523 - val_loss: 0.6522 - val_accuracy: 0.6286\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 801us/step - loss: 0.6376 - accuracy: 0.6531 - val_loss: 0.6502 - val_accuracy: 0.6305\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6379 - accuracy: 0.6513 - val_loss: 0.6496 - val_accuracy: 0.6304\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6351 - accuracy: 0.6536 - val_loss: 0.6479 - val_accuracy: 0.6319\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6345 - accuracy: 0.6577 - val_loss: 0.6468 - val_accuracy: 0.6325\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6322 - accuracy: 0.6571 - val_loss: 0.6450 - val_accuracy: 0.6343\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6323 - accuracy: 0.6570 - val_loss: 0.6465 - val_accuracy: 0.6313\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6312 - accuracy: 0.6596 - val_loss: 0.6476 - val_accuracy: 0.6283\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 796us/step - loss: 0.6298 - accuracy: 0.6568 - val_loss: 0.6446 - val_accuracy: 0.6322\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.6285 - accuracy: 0.6610 - val_loss: 0.6398 - val_accuracy: 0.6370\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.6265 - accuracy: 0.6610 - val_loss: 0.6409 - val_accuracy: 0.6353\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 806us/step - loss: 0.6253 - accuracy: 0.6665 - val_loss: 0.6399 - val_accuracy: 0.6360\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6246 - accuracy: 0.6670 - val_loss: 0.6404 - val_accuracy: 0.6347\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6230 - accuracy: 0.6684 - val_loss: 0.6382 - val_accuracy: 0.6371\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6226 - accuracy: 0.6669 - val_loss: 0.6379 - val_accuracy: 0.6375\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6204 - accuracy: 0.6675 - val_loss: 0.6405 - val_accuracy: 0.6341\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 745us/step - loss: 0.6198 - accuracy: 0.6719 - val_loss: 0.6381 - val_accuracy: 0.6374\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 917us/step - loss: 0.6183 - accuracy: 0.6690 - val_loss: 0.6337 - val_accuracy: 0.6406\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 789us/step - loss: 0.6183 - accuracy: 0.6723 - val_loss: 0.6339 - val_accuracy: 0.6402\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6167 - accuracy: 0.6747 - val_loss: 0.6337 - val_accuracy: 0.6401\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 801us/step - loss: 0.7102 - accuracy: 0.5129 - val_loss: 0.6771 - val_accuracy: 0.5822\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6945 - accuracy: 0.5319 - val_loss: 0.7060 - val_accuracy: 0.4542\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6904 - accuracy: 0.5388 - val_loss: 0.7120 - val_accuracy: 0.4439\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6859 - accuracy: 0.5489 - val_loss: 0.7073 - val_accuracy: 0.4754\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 730us/step - loss: 0.6822 - accuracy: 0.5549 - val_loss: 0.7081 - val_accuracy: 0.4657\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6778 - accuracy: 0.5691 - val_loss: 0.7031 - val_accuracy: 0.4890\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6750 - accuracy: 0.5719 - val_loss: 0.6992 - val_accuracy: 0.5006\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 655us/step - loss: 0.6704 - accuracy: 0.5806 - val_loss: 0.6972 - val_accuracy: 0.5022\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6693 - accuracy: 0.5862 - val_loss: 0.6954 - val_accuracy: 0.5040\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6655 - accuracy: 0.5950 - val_loss: 0.6930 - val_accuracy: 0.5053\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6650 - accuracy: 0.5954 - val_loss: 0.6909 - val_accuracy: 0.5068\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.6615 - accuracy: 0.6029 - val_loss: 0.6864 - val_accuracy: 0.5163\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.6601 - accuracy: 0.6041 - val_loss: 0.6839 - val_accuracy: 0.5231\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6578 - accuracy: 0.6069 - val_loss: 0.6828 - val_accuracy: 0.5270\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6551 - accuracy: 0.6152 - val_loss: 0.6814 - val_accuracy: 0.5269\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.6523 - accuracy: 0.6198 - val_loss: 0.6799 - val_accuracy: 0.5312\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 675us/step - loss: 0.6510 - accuracy: 0.6243 - val_loss: 0.6780 - val_accuracy: 0.5353\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6505 - accuracy: 0.6214 - val_loss: 0.6760 - val_accuracy: 0.5401\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6473 - accuracy: 0.6296 - val_loss: 0.6749 - val_accuracy: 0.5411\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6455 - accuracy: 0.6331 - val_loss: 0.6737 - val_accuracy: 0.5442\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.6440 - accuracy: 0.6346 - val_loss: 0.6719 - val_accuracy: 0.5493\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6422 - accuracy: 0.6364 - val_loss: 0.6694 - val_accuracy: 0.5567\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6404 - accuracy: 0.6387 - val_loss: 0.6667 - val_accuracy: 0.5632\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6386 - accuracy: 0.6423 - val_loss: 0.6661 - val_accuracy: 0.5665\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6374 - accuracy: 0.6443 - val_loss: 0.6651 - val_accuracy: 0.5697\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 704us/step - loss: 0.6359 - accuracy: 0.6457 - val_loss: 0.6642 - val_accuracy: 0.5733\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6351 - accuracy: 0.6487 - val_loss: 0.6619 - val_accuracy: 0.5781\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6330 - accuracy: 0.6497 - val_loss: 0.6610 - val_accuracy: 0.5799\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 707us/step - loss: 0.6317 - accuracy: 0.6509 - val_loss: 0.6609 - val_accuracy: 0.5812\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 670us/step - loss: 0.6310 - accuracy: 0.6530 - val_loss: 0.6586 - val_accuracy: 0.5858\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6284 - accuracy: 0.6533 - val_loss: 0.6557 - val_accuracy: 0.5929\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 887us/step - loss: 0.6262 - accuracy: 0.6577 - val_loss: 0.6528 - val_accuracy: 0.6006\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 657us/step - loss: 0.6267 - accuracy: 0.6580 - val_loss: 0.6511 - val_accuracy: 0.6065\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.6238 - accuracy: 0.6606 - val_loss: 0.6516 - val_accuracy: 0.6044\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6238 - accuracy: 0.6634 - val_loss: 0.6519 - val_accuracy: 0.6039\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6207 - accuracy: 0.6649 - val_loss: 0.6474 - val_accuracy: 0.6156\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6207 - accuracy: 0.6641 - val_loss: 0.6472 - val_accuracy: 0.6153\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6187 - accuracy: 0.6678 - val_loss: 0.6478 - val_accuracy: 0.6138\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6182 - accuracy: 0.6668 - val_loss: 0.6465 - val_accuracy: 0.6163\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6169 - accuracy: 0.6708 - val_loss: 0.6459 - val_accuracy: 0.6168\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 628us/step - loss: 0.6140 - accuracy: 0.6753 - val_loss: 0.6439 - val_accuracy: 0.6197\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6131 - accuracy: 0.6755 - val_loss: 0.6426 - val_accuracy: 0.6209\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6133 - accuracy: 0.6758 - val_loss: 0.6442 - val_accuracy: 0.6188\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 720us/step - loss: 0.6119 - accuracy: 0.6751 - val_loss: 0.6406 - val_accuracy: 0.6250\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6085 - accuracy: 0.6809 - val_loss: 0.6403 - val_accuracy: 0.6253\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6085 - accuracy: 0.6796 - val_loss: 0.6401 - val_accuracy: 0.6247\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 664us/step - loss: 0.6080 - accuracy: 0.6791 - val_loss: 0.6383 - val_accuracy: 0.6269\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.6066 - accuracy: 0.6790 - val_loss: 0.6385 - val_accuracy: 0.6267\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.6043 - accuracy: 0.6829 - val_loss: 0.6348 - val_accuracy: 0.6322\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6034 - accuracy: 0.6836 - val_loss: 0.6322 - val_accuracy: 0.6351\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.7254 - accuracy: 0.5092 - val_loss: 0.6169 - val_accuracy: 0.8635\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.6880 - accuracy: 0.5478 - val_loss: 0.6772 - val_accuracy: 0.6174\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6851 - accuracy: 0.5567 - val_loss: 0.6927 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6775 - accuracy: 0.5736 - val_loss: 0.6976 - val_accuracy: 0.5441\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.6739 - accuracy: 0.5862 - val_loss: 0.6976 - val_accuracy: 0.5478\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6725 - accuracy: 0.5855 - val_loss: 0.6963 - val_accuracy: 0.5498\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6710 - accuracy: 0.5919 - val_loss: 0.6927 - val_accuracy: 0.5579\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 720us/step - loss: 0.6698 - accuracy: 0.5897 - val_loss: 0.6930 - val_accuracy: 0.5583\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6655 - accuracy: 0.5987 - val_loss: 0.6889 - val_accuracy: 0.5692\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 638us/step - loss: 0.6654 - accuracy: 0.6032 - val_loss: 0.6872 - val_accuracy: 0.5753\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6613 - accuracy: 0.6097 - val_loss: 0.6830 - val_accuracy: 0.5840\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 704us/step - loss: 0.6593 - accuracy: 0.6137 - val_loss: 0.6811 - val_accuracy: 0.5869\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.6567 - accuracy: 0.6169 - val_loss: 0.6822 - val_accuracy: 0.5851\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6559 - accuracy: 0.6181 - val_loss: 0.6802 - val_accuracy: 0.5880\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 715us/step - loss: 0.6540 - accuracy: 0.6249 - val_loss: 0.6766 - val_accuracy: 0.5934\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6520 - accuracy: 0.6260 - val_loss: 0.6763 - val_accuracy: 0.5939\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.6500 - accuracy: 0.6310 - val_loss: 0.6749 - val_accuracy: 0.5960\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 708us/step - loss: 0.6482 - accuracy: 0.6356 - val_loss: 0.6733 - val_accuracy: 0.5984\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 635us/step - loss: 0.6475 - accuracy: 0.6355 - val_loss: 0.6687 - val_accuracy: 0.6053\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.6448 - accuracy: 0.6402 - val_loss: 0.6709 - val_accuracy: 0.5999\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6441 - accuracy: 0.6370 - val_loss: 0.6713 - val_accuracy: 0.5989\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.6433 - accuracy: 0.6398 - val_loss: 0.6709 - val_accuracy: 0.5987\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 627us/step - loss: 0.6415 - accuracy: 0.6420 - val_loss: 0.6708 - val_accuracy: 0.5986\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.6402 - accuracy: 0.6444 - val_loss: 0.6668 - val_accuracy: 0.6043\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.6406 - accuracy: 0.6477 - val_loss: 0.6669 - val_accuracy: 0.6037\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.6391 - accuracy: 0.6505 - val_loss: 0.6659 - val_accuracy: 0.6048\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 624us/step - loss: 0.6387 - accuracy: 0.6472 - val_loss: 0.6650 - val_accuracy: 0.6056\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6385 - accuracy: 0.6481 - val_loss: 0.6644 - val_accuracy: 0.6065\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.6352 - accuracy: 0.6514 - val_loss: 0.6611 - val_accuracy: 0.6120\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 741us/step - loss: 0.6333 - accuracy: 0.6508 - val_loss: 0.6604 - val_accuracy: 0.6123\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 701us/step - loss: 0.6331 - accuracy: 0.6544 - val_loss: 0.6611 - val_accuracy: 0.6105\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.6317 - accuracy: 0.6570 - val_loss: 0.6587 - val_accuracy: 0.6141\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6301 - accuracy: 0.6594 - val_loss: 0.6572 - val_accuracy: 0.6153\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.6294 - accuracy: 0.6600 - val_loss: 0.6570 - val_accuracy: 0.6152\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.6284 - accuracy: 0.6613 - val_loss: 0.6549 - val_accuracy: 0.6177\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6268 - accuracy: 0.6640 - val_loss: 0.6540 - val_accuracy: 0.6186\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6262 - accuracy: 0.6654 - val_loss: 0.6557 - val_accuracy: 0.6168\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6263 - accuracy: 0.6668 - val_loss: 0.6543 - val_accuracy: 0.6186\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6254 - accuracy: 0.6643 - val_loss: 0.6516 - val_accuracy: 0.6219\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6228 - accuracy: 0.6684 - val_loss: 0.6544 - val_accuracy: 0.6179\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6209 - accuracy: 0.6708 - val_loss: 0.6518 - val_accuracy: 0.6210\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.6200 - accuracy: 0.6682 - val_loss: 0.6511 - val_accuracy: 0.6226\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6203 - accuracy: 0.6705 - val_loss: 0.6512 - val_accuracy: 0.6224\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 630us/step - loss: 0.6189 - accuracy: 0.6719 - val_loss: 0.6491 - val_accuracy: 0.6255\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.6174 - accuracy: 0.6737 - val_loss: 0.6468 - val_accuracy: 0.6282\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 691us/step - loss: 0.6162 - accuracy: 0.6756 - val_loss: 0.6439 - val_accuracy: 0.6329\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 741us/step - loss: 0.6159 - accuracy: 0.6731 - val_loss: 0.6465 - val_accuracy: 0.6286\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6141 - accuracy: 0.6752 - val_loss: 0.6435 - val_accuracy: 0.6345\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6126 - accuracy: 0.6811 - val_loss: 0.6441 - val_accuracy: 0.6334\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 640us/step - loss: 0.6134 - accuracy: 0.6779 - val_loss: 0.6450 - val_accuracy: 0.6315\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.7544 - accuracy: 0.4794 - val_loss: 0.6107 - val_accuracy: 0.8457\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.7065 - accuracy: 0.4917 - val_loss: 0.6745 - val_accuracy: 0.6245\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 744us/step - loss: 0.6963 - accuracy: 0.5118 - val_loss: 0.6961 - val_accuracy: 0.4796\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6912 - accuracy: 0.5246 - val_loss: 0.7010 - val_accuracy: 0.4605\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 661us/step - loss: 0.6891 - accuracy: 0.5319 - val_loss: 0.7003 - val_accuracy: 0.4794\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.6854 - accuracy: 0.5424 - val_loss: 0.6971 - val_accuracy: 0.5072\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.6845 - accuracy: 0.5446 - val_loss: 0.6926 - val_accuracy: 0.5354\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 643us/step - loss: 0.6797 - accuracy: 0.5598 - val_loss: 0.6900 - val_accuracy: 0.5466\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6778 - accuracy: 0.5663 - val_loss: 0.6868 - val_accuracy: 0.5562\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6749 - accuracy: 0.5718 - val_loss: 0.6825 - val_accuracy: 0.5709\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.6714 - accuracy: 0.5848 - val_loss: 0.6802 - val_accuracy: 0.5790\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6715 - accuracy: 0.5823 - val_loss: 0.6792 - val_accuracy: 0.5809\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6690 - accuracy: 0.5876 - val_loss: 0.6779 - val_accuracy: 0.5859\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.6671 - accuracy: 0.5951 - val_loss: 0.6767 - val_accuracy: 0.5904\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 631us/step - loss: 0.6655 - accuracy: 0.5976 - val_loss: 0.6750 - val_accuracy: 0.5947\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6651 - accuracy: 0.5973 - val_loss: 0.6737 - val_accuracy: 0.5986\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6626 - accuracy: 0.6042 - val_loss: 0.6724 - val_accuracy: 0.6035\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 962us/step - loss: 0.6621 - accuracy: 0.6023 - val_loss: 0.6724 - val_accuracy: 0.6015\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6587 - accuracy: 0.6132 - val_loss: 0.6714 - val_accuracy: 0.6035\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 687us/step - loss: 0.6580 - accuracy: 0.6137 - val_loss: 0.6722 - val_accuracy: 0.6019\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6567 - accuracy: 0.6159 - val_loss: 0.6703 - val_accuracy: 0.6050\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.6548 - accuracy: 0.6177 - val_loss: 0.6681 - val_accuracy: 0.6085\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.6541 - accuracy: 0.6212 - val_loss: 0.6671 - val_accuracy: 0.6109\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6511 - accuracy: 0.6272 - val_loss: 0.6645 - val_accuracy: 0.6174\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.6503 - accuracy: 0.6228 - val_loss: 0.6650 - val_accuracy: 0.6158\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 698us/step - loss: 0.6493 - accuracy: 0.6273 - val_loss: 0.6657 - val_accuracy: 0.6138\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.6476 - accuracy: 0.6292 - val_loss: 0.6632 - val_accuracy: 0.6175\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.6467 - accuracy: 0.6334 - val_loss: 0.6611 - val_accuracy: 0.6219\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6461 - accuracy: 0.6343 - val_loss: 0.6609 - val_accuracy: 0.6204\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6451 - accuracy: 0.6333 - val_loss: 0.6591 - val_accuracy: 0.6220\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 626us/step - loss: 0.6434 - accuracy: 0.6376 - val_loss: 0.6578 - val_accuracy: 0.6224\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6413 - accuracy: 0.6384 - val_loss: 0.6564 - val_accuracy: 0.6242\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6411 - accuracy: 0.6391 - val_loss: 0.6553 - val_accuracy: 0.6241\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 642us/step - loss: 0.6396 - accuracy: 0.6408 - val_loss: 0.6548 - val_accuracy: 0.6228\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6387 - accuracy: 0.6434 - val_loss: 0.6551 - val_accuracy: 0.6209\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6373 - accuracy: 0.6423 - val_loss: 0.6530 - val_accuracy: 0.6229\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6362 - accuracy: 0.6445 - val_loss: 0.6535 - val_accuracy: 0.6218\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6353 - accuracy: 0.6452 - val_loss: 0.6508 - val_accuracy: 0.6257\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 632us/step - loss: 0.6344 - accuracy: 0.6463 - val_loss: 0.6508 - val_accuracy: 0.6252\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6334 - accuracy: 0.6466 - val_loss: 0.6509 - val_accuracy: 0.6244\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 741us/step - loss: 0.6315 - accuracy: 0.6491 - val_loss: 0.6495 - val_accuracy: 0.6261\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6311 - accuracy: 0.6471 - val_loss: 0.6466 - val_accuracy: 0.6311\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 634us/step - loss: 0.6304 - accuracy: 0.6506 - val_loss: 0.6462 - val_accuracy: 0.6316\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6284 - accuracy: 0.6544 - val_loss: 0.6457 - val_accuracy: 0.6319\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.6284 - accuracy: 0.6527 - val_loss: 0.6456 - val_accuracy: 0.6314\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6274 - accuracy: 0.6558 - val_loss: 0.6461 - val_accuracy: 0.6301\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 710us/step - loss: 0.6244 - accuracy: 0.6594 - val_loss: 0.6448 - val_accuracy: 0.6320\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 641us/step - loss: 0.6242 - accuracy: 0.6582 - val_loss: 0.6437 - val_accuracy: 0.6328\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6247 - accuracy: 0.6562 - val_loss: 0.6429 - val_accuracy: 0.6335\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6232 - accuracy: 0.6584 - val_loss: 0.6399 - val_accuracy: 0.6374\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 796us/step - loss: 0.7110 - accuracy: 0.4848 - val_loss: 0.7290 - val_accuracy: 0.3001\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 744us/step - loss: 0.7062 - accuracy: 0.4928 - val_loss: 0.7366 - val_accuracy: 0.2345\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.7012 - accuracy: 0.5069 - val_loss: 0.7351 - val_accuracy: 0.2302\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6983 - accuracy: 0.5135 - val_loss: 0.7286 - val_accuracy: 0.2674\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 656us/step - loss: 0.6944 - accuracy: 0.5227 - val_loss: 0.7274 - val_accuracy: 0.2778\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.6912 - accuracy: 0.5248 - val_loss: 0.7216 - val_accuracy: 0.3156\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 690us/step - loss: 0.6893 - accuracy: 0.5329 - val_loss: 0.7230 - val_accuracy: 0.3275\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.6852 - accuracy: 0.5415 - val_loss: 0.7175 - val_accuracy: 0.3939\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 637us/step - loss: 0.6824 - accuracy: 0.5497 - val_loss: 0.7146 - val_accuracy: 0.4375\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6795 - accuracy: 0.5541 - val_loss: 0.7118 - val_accuracy: 0.4694\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 691us/step - loss: 0.6771 - accuracy: 0.5636 - val_loss: 0.7055 - val_accuracy: 0.5236\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.6757 - accuracy: 0.5629 - val_loss: 0.7046 - val_accuracy: 0.5309\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 809us/step - loss: 0.6734 - accuracy: 0.5738 - val_loss: 0.7037 - val_accuracy: 0.5367\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 916us/step - loss: 0.6703 - accuracy: 0.5758 - val_loss: 0.7007 - val_accuracy: 0.5465\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6685 - accuracy: 0.5823 - val_loss: 0.6990 - val_accuracy: 0.5503\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 716us/step - loss: 0.6663 - accuracy: 0.5861 - val_loss: 0.6975 - val_accuracy: 0.5538\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6653 - accuracy: 0.5876 - val_loss: 0.6948 - val_accuracy: 0.5609\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.6650 - accuracy: 0.5912 - val_loss: 0.6907 - val_accuracy: 0.5698\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 795us/step - loss: 0.6631 - accuracy: 0.5908 - val_loss: 0.6922 - val_accuracy: 0.5653\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.6586 - accuracy: 0.5997 - val_loss: 0.6879 - val_accuracy: 0.5737\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6576 - accuracy: 0.6062 - val_loss: 0.6842 - val_accuracy: 0.5819\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6559 - accuracy: 0.6060 - val_loss: 0.6841 - val_accuracy: 0.5806\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 797us/step - loss: 0.6559 - accuracy: 0.6065 - val_loss: 0.6834 - val_accuracy: 0.5808\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6529 - accuracy: 0.6129 - val_loss: 0.6785 - val_accuracy: 0.5908\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6504 - accuracy: 0.6169 - val_loss: 0.6802 - val_accuracy: 0.5856\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.6491 - accuracy: 0.6200 - val_loss: 0.6795 - val_accuracy: 0.5860\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6467 - accuracy: 0.6207 - val_loss: 0.6768 - val_accuracy: 0.5902\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6455 - accuracy: 0.6208 - val_loss: 0.6747 - val_accuracy: 0.5922\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6452 - accuracy: 0.6223 - val_loss: 0.6731 - val_accuracy: 0.5935\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6421 - accuracy: 0.6297 - val_loss: 0.6728 - val_accuracy: 0.5922\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6426 - accuracy: 0.6215 - val_loss: 0.6704 - val_accuracy: 0.5952\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6404 - accuracy: 0.6260 - val_loss: 0.6689 - val_accuracy: 0.5962\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6379 - accuracy: 0.6309 - val_loss: 0.6662 - val_accuracy: 0.6013\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6363 - accuracy: 0.6369 - val_loss: 0.6656 - val_accuracy: 0.6011\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6366 - accuracy: 0.6326 - val_loss: 0.6640 - val_accuracy: 0.6032\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6340 - accuracy: 0.6356 - val_loss: 0.6630 - val_accuracy: 0.6043\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6328 - accuracy: 0.6356 - val_loss: 0.6602 - val_accuracy: 0.6092\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6306 - accuracy: 0.6379 - val_loss: 0.6598 - val_accuracy: 0.6084\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6300 - accuracy: 0.6406 - val_loss: 0.6581 - val_accuracy: 0.6112\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6274 - accuracy: 0.6403 - val_loss: 0.6576 - val_accuracy: 0.6117\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6273 - accuracy: 0.6429 - val_loss: 0.6556 - val_accuracy: 0.6150\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 806us/step - loss: 0.6279 - accuracy: 0.6424 - val_loss: 0.6541 - val_accuracy: 0.6174\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6255 - accuracy: 0.6437 - val_loss: 0.6549 - val_accuracy: 0.6146\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6232 - accuracy: 0.6445 - val_loss: 0.6519 - val_accuracy: 0.6190\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6219 - accuracy: 0.6450 - val_loss: 0.6498 - val_accuracy: 0.6208\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6222 - accuracy: 0.6468 - val_loss: 0.6548 - val_accuracy: 0.6115\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6187 - accuracy: 0.6525 - val_loss: 0.6512 - val_accuracy: 0.6172\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6185 - accuracy: 0.6508 - val_loss: 0.6493 - val_accuracy: 0.6190\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6181 - accuracy: 0.6495 - val_loss: 0.6467 - val_accuracy: 0.6220\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6174 - accuracy: 0.6525 - val_loss: 0.6463 - val_accuracy: 0.6221\n",
      "\n",
      "Training model with sample_size_ratio=0.5, target_eps=1.0...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 5.05 iterated over 41800 steps satisfies differential privacy with eps = 0.245 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.5749999999999997 iterated over 41800 steps satisfies differential privacy with eps = 0.481 and delta = 1e-05.\n",
      "The optimal RDP order is 49.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3375 iterated over 41800 steps satisfies differential privacy with eps = 1.05 and delta = 1e-05.\n",
      "The optimal RDP order is 22.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.9562499999999998 iterated over 41800 steps satisfies differential privacy with eps = 0.655 and delta = 1e-05.\n",
      "The optimal RDP order is 36.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.6468749999999999 iterated over 41800 steps satisfies differential privacy with eps = 0.804 and delta = 1e-05.\n",
      "The optimal RDP order is 30.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.4921875 iterated over 41800 steps satisfies differential privacy with eps = 0.91 and delta = 1e-05.\n",
      "The optimal RDP order is 27.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.41484375 iterated over 41800 steps satisfies differential privacy with eps = 0.975 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3761718749999998 iterated over 41800 steps satisfies differential privacy with eps = 1.01 and delta = 1e-05.\n",
      "The optimal RDP order is 24.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3955078125 iterated over 41800 steps satisfies differential privacy with eps = 0.993 and delta = 1e-05.\n",
      "The optimal RDP order is 24.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 890us/step - loss: 0.7124 - accuracy: 0.5021 - val_loss: 0.7615 - val_accuracy: 0.2002\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.7056 - accuracy: 0.5034 - val_loss: 0.7428 - val_accuracy: 0.2584\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.7022 - accuracy: 0.5092 - val_loss: 0.7322 - val_accuracy: 0.2954\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6982 - accuracy: 0.5164 - val_loss: 0.7294 - val_accuracy: 0.2969\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 810us/step - loss: 0.6949 - accuracy: 0.5216 - val_loss: 0.7263 - val_accuracy: 0.3064\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6940 - accuracy: 0.5251 - val_loss: 0.7224 - val_accuracy: 0.3253\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 808us/step - loss: 0.6906 - accuracy: 0.5338 - val_loss: 0.7179 - val_accuracy: 0.3518\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6860 - accuracy: 0.5413 - val_loss: 0.7161 - val_accuracy: 0.3635\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 810us/step - loss: 0.6850 - accuracy: 0.5416 - val_loss: 0.7139 - val_accuracy: 0.3697\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6810 - accuracy: 0.5574 - val_loss: 0.7114 - val_accuracy: 0.3818\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 723us/step - loss: 0.6779 - accuracy: 0.5650 - val_loss: 0.7085 - val_accuracy: 0.4030\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 862us/step - loss: 0.6752 - accuracy: 0.5724 - val_loss: 0.7065 - val_accuracy: 0.4242\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 979us/step - loss: 0.6730 - accuracy: 0.5761 - val_loss: 0.7056 - val_accuracy: 0.4536\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 731us/step - loss: 0.6706 - accuracy: 0.5813 - val_loss: 0.7011 - val_accuracy: 0.4964\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.6684 - accuracy: 0.5882 - val_loss: 0.7003 - val_accuracy: 0.5161\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 815us/step - loss: 0.6662 - accuracy: 0.5925 - val_loss: 0.6983 - val_accuracy: 0.5305\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6631 - accuracy: 0.6015 - val_loss: 0.6955 - val_accuracy: 0.5464\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6600 - accuracy: 0.6107 - val_loss: 0.6933 - val_accuracy: 0.5534\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6590 - accuracy: 0.6110 - val_loss: 0.6925 - val_accuracy: 0.5565\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6562 - accuracy: 0.6186 - val_loss: 0.6881 - val_accuracy: 0.5720\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6550 - accuracy: 0.6204 - val_loss: 0.6850 - val_accuracy: 0.5802\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 894us/step - loss: 0.6524 - accuracy: 0.6261 - val_loss: 0.6844 - val_accuracy: 0.5797\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 796us/step - loss: 0.6498 - accuracy: 0.6285 - val_loss: 0.6813 - val_accuracy: 0.5883\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6481 - accuracy: 0.6361 - val_loss: 0.6832 - val_accuracy: 0.5810\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 815us/step - loss: 0.6459 - accuracy: 0.6385 - val_loss: 0.6819 - val_accuracy: 0.5844\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.6446 - accuracy: 0.6397 - val_loss: 0.6780 - val_accuracy: 0.5943\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.6424 - accuracy: 0.6418 - val_loss: 0.6751 - val_accuracy: 0.6005\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6408 - accuracy: 0.6451 - val_loss: 0.6731 - val_accuracy: 0.6032\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6401 - accuracy: 0.6450 - val_loss: 0.6720 - val_accuracy: 0.6023\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 796us/step - loss: 0.6372 - accuracy: 0.6491 - val_loss: 0.6691 - val_accuracy: 0.6083\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 795us/step - loss: 0.6373 - accuracy: 0.6517 - val_loss: 0.6680 - val_accuracy: 0.6085\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.6351 - accuracy: 0.6529 - val_loss: 0.6668 - val_accuracy: 0.6116\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 800us/step - loss: 0.6321 - accuracy: 0.6565 - val_loss: 0.6665 - val_accuracy: 0.6112\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 809us/step - loss: 0.6322 - accuracy: 0.6583 - val_loss: 0.6660 - val_accuracy: 0.6128\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6289 - accuracy: 0.6615 - val_loss: 0.6616 - val_accuracy: 0.6226\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 824us/step - loss: 0.6282 - accuracy: 0.6598 - val_loss: 0.6589 - val_accuracy: 0.6265\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6268 - accuracy: 0.6618 - val_loss: 0.6582 - val_accuracy: 0.6270\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6254 - accuracy: 0.6637 - val_loss: 0.6553 - val_accuracy: 0.6314\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6247 - accuracy: 0.6658 - val_loss: 0.6563 - val_accuracy: 0.6290\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 806us/step - loss: 0.6250 - accuracy: 0.6623 - val_loss: 0.6552 - val_accuracy: 0.6291\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6223 - accuracy: 0.6668 - val_loss: 0.6510 - val_accuracy: 0.6349\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6208 - accuracy: 0.6678 - val_loss: 0.6506 - val_accuracy: 0.6342\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 796us/step - loss: 0.6200 - accuracy: 0.6698 - val_loss: 0.6516 - val_accuracy: 0.6314\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6177 - accuracy: 0.6736 - val_loss: 0.6482 - val_accuracy: 0.6359\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6174 - accuracy: 0.6700 - val_loss: 0.6476 - val_accuracy: 0.6360\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 811us/step - loss: 0.6149 - accuracy: 0.6747 - val_loss: 0.6485 - val_accuracy: 0.6337\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6147 - accuracy: 0.6776 - val_loss: 0.6440 - val_accuracy: 0.6388\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6129 - accuracy: 0.6739 - val_loss: 0.6432 - val_accuracy: 0.6393\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 948us/step - loss: 0.6124 - accuracy: 0.6802 - val_loss: 0.6436 - val_accuracy: 0.6377\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6115 - accuracy: 0.6776 - val_loss: 0.6436 - val_accuracy: 0.6370\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.7313 - accuracy: 0.4898 - val_loss: 0.7210 - val_accuracy: 0.3858\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.7232 - accuracy: 0.4969 - val_loss: 0.7296 - val_accuracy: 0.3648\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 778us/step - loss: 0.7192 - accuracy: 0.5035 - val_loss: 0.7285 - val_accuracy: 0.3693\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.7135 - accuracy: 0.5097 - val_loss: 0.7259 - val_accuracy: 0.3811\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7125 - accuracy: 0.5126 - val_loss: 0.7240 - val_accuracy: 0.3937\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.7081 - accuracy: 0.5238 - val_loss: 0.7231 - val_accuracy: 0.4073\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.7051 - accuracy: 0.5233 - val_loss: 0.7220 - val_accuracy: 0.4188\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.7028 - accuracy: 0.5270 - val_loss: 0.7166 - val_accuracy: 0.4504\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6961 - accuracy: 0.5414 - val_loss: 0.7154 - val_accuracy: 0.4686\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.6937 - accuracy: 0.5450 - val_loss: 0.7130 - val_accuracy: 0.4889\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6917 - accuracy: 0.5453 - val_loss: 0.7133 - val_accuracy: 0.4961\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6898 - accuracy: 0.5507 - val_loss: 0.7111 - val_accuracy: 0.5046\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6850 - accuracy: 0.5650 - val_loss: 0.7090 - val_accuracy: 0.5133\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.6843 - accuracy: 0.5640 - val_loss: 0.7053 - val_accuracy: 0.5208\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6807 - accuracy: 0.5687 - val_loss: 0.7020 - val_accuracy: 0.5283\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6791 - accuracy: 0.5734 - val_loss: 0.7009 - val_accuracy: 0.5333\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6772 - accuracy: 0.5780 - val_loss: 0.7001 - val_accuracy: 0.5369\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6733 - accuracy: 0.5868 - val_loss: 0.6954 - val_accuracy: 0.5516\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6726 - accuracy: 0.5877 - val_loss: 0.6955 - val_accuracy: 0.5532\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6714 - accuracy: 0.5912 - val_loss: 0.6917 - val_accuracy: 0.5646\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6682 - accuracy: 0.5970 - val_loss: 0.6899 - val_accuracy: 0.5692\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6673 - accuracy: 0.5975 - val_loss: 0.6901 - val_accuracy: 0.5693\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 808us/step - loss: 0.6661 - accuracy: 0.6001 - val_loss: 0.6898 - val_accuracy: 0.5706\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6640 - accuracy: 0.6047 - val_loss: 0.6841 - val_accuracy: 0.5859\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6637 - accuracy: 0.6078 - val_loss: 0.6834 - val_accuracy: 0.5890\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6605 - accuracy: 0.6119 - val_loss: 0.6816 - val_accuracy: 0.5932\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6597 - accuracy: 0.6123 - val_loss: 0.6815 - val_accuracy: 0.5939\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6596 - accuracy: 0.6143 - val_loss: 0.6815 - val_accuracy: 0.5952\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6574 - accuracy: 0.6139 - val_loss: 0.6805 - val_accuracy: 0.5978\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6544 - accuracy: 0.6217 - val_loss: 0.6756 - val_accuracy: 0.6038\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.6538 - accuracy: 0.6220 - val_loss: 0.6736 - val_accuracy: 0.6043\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6519 - accuracy: 0.6260 - val_loss: 0.6751 - val_accuracy: 0.5996\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.6523 - accuracy: 0.6259 - val_loss: 0.6733 - val_accuracy: 0.6017\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6498 - accuracy: 0.6320 - val_loss: 0.6740 - val_accuracy: 0.6022\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6474 - accuracy: 0.6336 - val_loss: 0.6723 - val_accuracy: 0.6051\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6466 - accuracy: 0.6376 - val_loss: 0.6682 - val_accuracy: 0.6094\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 728us/step - loss: 0.6456 - accuracy: 0.6368 - val_loss: 0.6659 - val_accuracy: 0.6132\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6452 - accuracy: 0.6385 - val_loss: 0.6643 - val_accuracy: 0.6164\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 681us/step - loss: 0.6426 - accuracy: 0.6416 - val_loss: 0.6679 - val_accuracy: 0.6119\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6417 - accuracy: 0.6420 - val_loss: 0.6655 - val_accuracy: 0.6151\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.6401 - accuracy: 0.6459 - val_loss: 0.6650 - val_accuracy: 0.6150\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6394 - accuracy: 0.6459 - val_loss: 0.6638 - val_accuracy: 0.6173\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 753us/step - loss: 0.6388 - accuracy: 0.6469 - val_loss: 0.6638 - val_accuracy: 0.6171\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6377 - accuracy: 0.6487 - val_loss: 0.6619 - val_accuracy: 0.6188\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6357 - accuracy: 0.6510 - val_loss: 0.6632 - val_accuracy: 0.6167\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 674us/step - loss: 0.6340 - accuracy: 0.6567 - val_loss: 0.6602 - val_accuracy: 0.6207\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 771us/step - loss: 0.6339 - accuracy: 0.6511 - val_loss: 0.6596 - val_accuracy: 0.6214\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.6342 - accuracy: 0.6532 - val_loss: 0.6570 - val_accuracy: 0.6236\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 659us/step - loss: 0.6342 - accuracy: 0.6549 - val_loss: 0.6580 - val_accuracy: 0.6227\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6321 - accuracy: 0.6569 - val_loss: 0.6573 - val_accuracy: 0.6228\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.7534 - accuracy: 0.4963 - val_loss: 0.5925 - val_accuracy: 0.8705\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6928 - accuracy: 0.5395 - val_loss: 0.6667 - val_accuracy: 0.6629\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6871 - accuracy: 0.5542 - val_loss: 0.6878 - val_accuracy: 0.5350\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6842 - accuracy: 0.5624 - val_loss: 0.6935 - val_accuracy: 0.5071\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 704us/step - loss: 0.6833 - accuracy: 0.5635 - val_loss: 0.6914 - val_accuracy: 0.5225\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6785 - accuracy: 0.5748 - val_loss: 0.6944 - val_accuracy: 0.5131\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6803 - accuracy: 0.5721 - val_loss: 0.6912 - val_accuracy: 0.5264\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6750 - accuracy: 0.5815 - val_loss: 0.6901 - val_accuracy: 0.5315\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6739 - accuracy: 0.5833 - val_loss: 0.6886 - val_accuracy: 0.5365\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6743 - accuracy: 0.5831 - val_loss: 0.6864 - val_accuracy: 0.5436\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6707 - accuracy: 0.5948 - val_loss: 0.6839 - val_accuracy: 0.5504\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6691 - accuracy: 0.5957 - val_loss: 0.6846 - val_accuracy: 0.5486\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6677 - accuracy: 0.6047 - val_loss: 0.6827 - val_accuracy: 0.5546\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6660 - accuracy: 0.6084 - val_loss: 0.6796 - val_accuracy: 0.5614\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6634 - accuracy: 0.6118 - val_loss: 0.6786 - val_accuracy: 0.5642\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6627 - accuracy: 0.6138 - val_loss: 0.6781 - val_accuracy: 0.5647\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 741us/step - loss: 0.6607 - accuracy: 0.6208 - val_loss: 0.6753 - val_accuracy: 0.5728\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 679us/step - loss: 0.6583 - accuracy: 0.6231 - val_loss: 0.6751 - val_accuracy: 0.5744\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6565 - accuracy: 0.6269 - val_loss: 0.6735 - val_accuracy: 0.5783\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6560 - accuracy: 0.6290 - val_loss: 0.6694 - val_accuracy: 0.5913\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6542 - accuracy: 0.6323 - val_loss: 0.6710 - val_accuracy: 0.5881\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6523 - accuracy: 0.6346 - val_loss: 0.6677 - val_accuracy: 0.5945\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6514 - accuracy: 0.6361 - val_loss: 0.6641 - val_accuracy: 0.6033\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6486 - accuracy: 0.6400 - val_loss: 0.6667 - val_accuracy: 0.5971\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6486 - accuracy: 0.6421 - val_loss: 0.6641 - val_accuracy: 0.6029\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 808us/step - loss: 0.6455 - accuracy: 0.6518 - val_loss: 0.6618 - val_accuracy: 0.6074\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6453 - accuracy: 0.6482 - val_loss: 0.6627 - val_accuracy: 0.6049\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6430 - accuracy: 0.6489 - val_loss: 0.6606 - val_accuracy: 0.6083\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6416 - accuracy: 0.6535 - val_loss: 0.6591 - val_accuracy: 0.6105\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 676us/step - loss: 0.6405 - accuracy: 0.6555 - val_loss: 0.6555 - val_accuracy: 0.6168\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 949us/step - loss: 0.6416 - accuracy: 0.6540 - val_loss: 0.6533 - val_accuracy: 0.6216\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6392 - accuracy: 0.6543 - val_loss: 0.6582 - val_accuracy: 0.6092\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 753us/step - loss: 0.6368 - accuracy: 0.6623 - val_loss: 0.6548 - val_accuracy: 0.6153\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.6347 - accuracy: 0.6644 - val_loss: 0.6531 - val_accuracy: 0.6179\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6360 - accuracy: 0.6610 - val_loss: 0.6509 - val_accuracy: 0.6210\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6333 - accuracy: 0.6647 - val_loss: 0.6525 - val_accuracy: 0.6174\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6320 - accuracy: 0.6642 - val_loss: 0.6543 - val_accuracy: 0.6132\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6328 - accuracy: 0.6644 - val_loss: 0.6520 - val_accuracy: 0.6172\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6299 - accuracy: 0.6696 - val_loss: 0.6495 - val_accuracy: 0.6206\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 713us/step - loss: 0.6302 - accuracy: 0.6673 - val_loss: 0.6492 - val_accuracy: 0.6196\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6277 - accuracy: 0.6724 - val_loss: 0.6469 - val_accuracy: 0.6220\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6263 - accuracy: 0.6772 - val_loss: 0.6476 - val_accuracy: 0.6204\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.6263 - accuracy: 0.6734 - val_loss: 0.6456 - val_accuracy: 0.6226\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.6240 - accuracy: 0.6750 - val_loss: 0.6453 - val_accuracy: 0.6220\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 883us/step - loss: 0.6235 - accuracy: 0.6770 - val_loss: 0.6413 - val_accuracy: 0.6265\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 691us/step - loss: 0.6213 - accuracy: 0.6782 - val_loss: 0.6461 - val_accuracy: 0.6198\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 651us/step - loss: 0.6205 - accuracy: 0.6781 - val_loss: 0.6420 - val_accuracy: 0.6241\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6203 - accuracy: 0.6805 - val_loss: 0.6417 - val_accuracy: 0.6238\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6197 - accuracy: 0.6811 - val_loss: 0.6429 - val_accuracy: 0.6219\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6171 - accuracy: 0.6831 - val_loss: 0.6392 - val_accuracy: 0.6256\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.7338 - accuracy: 0.4819 - val_loss: 0.7393 - val_accuracy: 0.2188\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.7297 - accuracy: 0.4830 - val_loss: 0.7299 - val_accuracy: 0.2571\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.7221 - accuracy: 0.4980 - val_loss: 0.7279 - val_accuracy: 0.2783\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.7156 - accuracy: 0.5032 - val_loss: 0.7242 - val_accuracy: 0.3148\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.7120 - accuracy: 0.5113 - val_loss: 0.7206 - val_accuracy: 0.3533\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.7083 - accuracy: 0.5169 - val_loss: 0.7161 - val_accuracy: 0.4089\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 649us/step - loss: 0.7061 - accuracy: 0.5246 - val_loss: 0.7139 - val_accuracy: 0.4370\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6998 - accuracy: 0.5364 - val_loss: 0.7110 - val_accuracy: 0.4658\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6974 - accuracy: 0.5418 - val_loss: 0.7083 - val_accuracy: 0.4827\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.6952 - accuracy: 0.5404 - val_loss: 0.7042 - val_accuracy: 0.5049\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6905 - accuracy: 0.5518 - val_loss: 0.7008 - val_accuracy: 0.5197\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6889 - accuracy: 0.5581 - val_loss: 0.6964 - val_accuracy: 0.5406\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6835 - accuracy: 0.5635 - val_loss: 0.6949 - val_accuracy: 0.5509\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6825 - accuracy: 0.5692 - val_loss: 0.6911 - val_accuracy: 0.5659\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6767 - accuracy: 0.5844 - val_loss: 0.6894 - val_accuracy: 0.5760\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6766 - accuracy: 0.5831 - val_loss: 0.6881 - val_accuracy: 0.5804\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6739 - accuracy: 0.5898 - val_loss: 0.6880 - val_accuracy: 0.5785\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 663us/step - loss: 0.6709 - accuracy: 0.5952 - val_loss: 0.6831 - val_accuracy: 0.5885\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.6670 - accuracy: 0.6038 - val_loss: 0.6819 - val_accuracy: 0.5884\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6664 - accuracy: 0.6035 - val_loss: 0.6800 - val_accuracy: 0.5904\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6627 - accuracy: 0.6139 - val_loss: 0.6759 - val_accuracy: 0.5991\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.6613 - accuracy: 0.6125 - val_loss: 0.6730 - val_accuracy: 0.6093\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6598 - accuracy: 0.6157 - val_loss: 0.6705 - val_accuracy: 0.6141\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6588 - accuracy: 0.6207 - val_loss: 0.6709 - val_accuracy: 0.6126\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 970us/step - loss: 0.6580 - accuracy: 0.6214 - val_loss: 0.6670 - val_accuracy: 0.6180\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 704us/step - loss: 0.6554 - accuracy: 0.6277 - val_loss: 0.6695 - val_accuracy: 0.6141\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6531 - accuracy: 0.6346 - val_loss: 0.6688 - val_accuracy: 0.6150\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6514 - accuracy: 0.6331 - val_loss: 0.6648 - val_accuracy: 0.6200\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 698us/step - loss: 0.6525 - accuracy: 0.6309 - val_loss: 0.6672 - val_accuracy: 0.6167\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6502 - accuracy: 0.6367 - val_loss: 0.6662 - val_accuracy: 0.6175\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6470 - accuracy: 0.6429 - val_loss: 0.6644 - val_accuracy: 0.6188\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6457 - accuracy: 0.6434 - val_loss: 0.6657 - val_accuracy: 0.6158\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6473 - accuracy: 0.6446 - val_loss: 0.6627 - val_accuracy: 0.6196\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 797us/step - loss: 0.6443 - accuracy: 0.6492 - val_loss: 0.6582 - val_accuracy: 0.6256\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6423 - accuracy: 0.6540 - val_loss: 0.6600 - val_accuracy: 0.6209\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 895us/step - loss: 0.6423 - accuracy: 0.6531 - val_loss: 0.6603 - val_accuracy: 0.6197\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6408 - accuracy: 0.6549 - val_loss: 0.6553 - val_accuracy: 0.6286\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.6364 - accuracy: 0.6595 - val_loss: 0.6580 - val_accuracy: 0.6208\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6383 - accuracy: 0.6578 - val_loss: 0.6537 - val_accuracy: 0.6278\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6362 - accuracy: 0.6608 - val_loss: 0.6526 - val_accuracy: 0.6279\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.6359 - accuracy: 0.6611 - val_loss: 0.6506 - val_accuracy: 0.6302\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 771us/step - loss: 0.6337 - accuracy: 0.6622 - val_loss: 0.6554 - val_accuracy: 0.6242\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.6329 - accuracy: 0.6667 - val_loss: 0.6551 - val_accuracy: 0.6230\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6327 - accuracy: 0.6662 - val_loss: 0.6513 - val_accuracy: 0.6281\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6312 - accuracy: 0.6666 - val_loss: 0.6538 - val_accuracy: 0.6228\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6300 - accuracy: 0.6699 - val_loss: 0.6500 - val_accuracy: 0.6282\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6278 - accuracy: 0.6712 - val_loss: 0.6497 - val_accuracy: 0.6270\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6271 - accuracy: 0.6713 - val_loss: 0.6456 - val_accuracy: 0.6305\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 810us/step - loss: 0.6254 - accuracy: 0.6727 - val_loss: 0.6440 - val_accuracy: 0.6315\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 729us/step - loss: 0.6269 - accuracy: 0.6739 - val_loss: 0.6444 - val_accuracy: 0.6299\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.7321 - accuracy: 0.4722 - val_loss: 0.6875 - val_accuracy: 0.5519\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.7089 - accuracy: 0.4934 - val_loss: 0.7252 - val_accuracy: 0.3712\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.7046 - accuracy: 0.5037 - val_loss: 0.7335 - val_accuracy: 0.3593\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.7006 - accuracy: 0.5153 - val_loss: 0.7307 - val_accuracy: 0.3747\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 720us/step - loss: 0.6973 - accuracy: 0.5192 - val_loss: 0.7280 - val_accuracy: 0.3967\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 687us/step - loss: 0.6929 - accuracy: 0.5334 - val_loss: 0.7245 - val_accuracy: 0.4265\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6895 - accuracy: 0.5391 - val_loss: 0.7221 - val_accuracy: 0.4523\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6858 - accuracy: 0.5457 - val_loss: 0.7163 - val_accuracy: 0.4780\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6821 - accuracy: 0.5550 - val_loss: 0.7136 - val_accuracy: 0.4866\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6801 - accuracy: 0.5624 - val_loss: 0.7105 - val_accuracy: 0.5004\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6759 - accuracy: 0.5739 - val_loss: 0.7099 - val_accuracy: 0.4994\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 730us/step - loss: 0.6741 - accuracy: 0.5755 - val_loss: 0.7092 - val_accuracy: 0.4966\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6732 - accuracy: 0.5763 - val_loss: 0.7045 - val_accuracy: 0.5152\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6669 - accuracy: 0.5929 - val_loss: 0.6984 - val_accuracy: 0.5327\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6681 - accuracy: 0.5876 - val_loss: 0.6976 - val_accuracy: 0.5375\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6659 - accuracy: 0.5973 - val_loss: 0.6936 - val_accuracy: 0.5505\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6626 - accuracy: 0.6058 - val_loss: 0.6959 - val_accuracy: 0.5467\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 741us/step - loss: 0.6600 - accuracy: 0.6065 - val_loss: 0.6939 - val_accuracy: 0.5494\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6588 - accuracy: 0.6155 - val_loss: 0.6896 - val_accuracy: 0.5631\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 902us/step - loss: 0.6558 - accuracy: 0.6180 - val_loss: 0.6873 - val_accuracy: 0.5720\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6535 - accuracy: 0.6203 - val_loss: 0.6837 - val_accuracy: 0.5830\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6510 - accuracy: 0.6231 - val_loss: 0.6861 - val_accuracy: 0.5772\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.6489 - accuracy: 0.6247 - val_loss: 0.6865 - val_accuracy: 0.5772\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 727us/step - loss: 0.6468 - accuracy: 0.6314 - val_loss: 0.6782 - val_accuracy: 0.5973\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6450 - accuracy: 0.6356 - val_loss: 0.6785 - val_accuracy: 0.5960\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.6421 - accuracy: 0.6382 - val_loss: 0.6754 - val_accuracy: 0.6006\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 780us/step - loss: 0.6404 - accuracy: 0.6443 - val_loss: 0.6715 - val_accuracy: 0.6104\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 780us/step - loss: 0.6387 - accuracy: 0.6440 - val_loss: 0.6698 - val_accuracy: 0.6137\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6368 - accuracy: 0.6450 - val_loss: 0.6656 - val_accuracy: 0.6260\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6361 - accuracy: 0.6479 - val_loss: 0.6697 - val_accuracy: 0.6102\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 753us/step - loss: 0.6348 - accuracy: 0.6485 - val_loss: 0.6665 - val_accuracy: 0.6184\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.6325 - accuracy: 0.6513 - val_loss: 0.6665 - val_accuracy: 0.6165\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 721us/step - loss: 0.6319 - accuracy: 0.6483 - val_loss: 0.6629 - val_accuracy: 0.6257\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6293 - accuracy: 0.6538 - val_loss: 0.6574 - val_accuracy: 0.6425\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6282 - accuracy: 0.6570 - val_loss: 0.6563 - val_accuracy: 0.6428\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6264 - accuracy: 0.6579 - val_loss: 0.6557 - val_accuracy: 0.6413\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 908us/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6548 - val_accuracy: 0.6413\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6235 - accuracy: 0.6600 - val_loss: 0.6529 - val_accuracy: 0.6450\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6233 - accuracy: 0.6595 - val_loss: 0.6551 - val_accuracy: 0.6383\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6204 - accuracy: 0.6651 - val_loss: 0.6545 - val_accuracy: 0.6384\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6200 - accuracy: 0.6633 - val_loss: 0.6509 - val_accuracy: 0.6443\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.6174 - accuracy: 0.6692 - val_loss: 0.6488 - val_accuracy: 0.6474\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6179 - accuracy: 0.6651 - val_loss: 0.6466 - val_accuracy: 0.6497\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 898us/step - loss: 0.6166 - accuracy: 0.6677 - val_loss: 0.6466 - val_accuracy: 0.6486\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 809us/step - loss: 0.6138 - accuracy: 0.6715 - val_loss: 0.6456 - val_accuracy: 0.6491\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6121 - accuracy: 0.6727 - val_loss: 0.6440 - val_accuracy: 0.6518\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6126 - accuracy: 0.6677 - val_loss: 0.6414 - val_accuracy: 0.6556\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6102 - accuracy: 0.6745 - val_loss: 0.6358 - val_accuracy: 0.6657\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6078 - accuracy: 0.6763 - val_loss: 0.6332 - val_accuracy: 0.6688\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6082 - accuracy: 0.6775 - val_loss: 0.6322 - val_accuracy: 0.6689\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.7011 - accuracy: 0.5312 - val_loss: 0.7173 - val_accuracy: 0.5195\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6927 - accuracy: 0.5455 - val_loss: 0.7213 - val_accuracy: 0.5150\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6888 - accuracy: 0.5548 - val_loss: 0.7183 - val_accuracy: 0.5160\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6857 - accuracy: 0.5642 - val_loss: 0.7172 - val_accuracy: 0.5164\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6797 - accuracy: 0.5737 - val_loss: 0.7085 - val_accuracy: 0.5379\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6766 - accuracy: 0.5846 - val_loss: 0.7084 - val_accuracy: 0.5265\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6736 - accuracy: 0.5910 - val_loss: 0.7019 - val_accuracy: 0.5450\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6687 - accuracy: 0.6020 - val_loss: 0.6998 - val_accuracy: 0.5433\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6664 - accuracy: 0.6057 - val_loss: 0.6940 - val_accuracy: 0.5557\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6623 - accuracy: 0.6133 - val_loss: 0.6909 - val_accuracy: 0.5614\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 887us/step - loss: 0.6599 - accuracy: 0.6202 - val_loss: 0.6859 - val_accuracy: 0.5693\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 881us/step - loss: 0.6585 - accuracy: 0.6183 - val_loss: 0.6826 - val_accuracy: 0.5759\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6554 - accuracy: 0.6291 - val_loss: 0.6803 - val_accuracy: 0.5817\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6519 - accuracy: 0.6344 - val_loss: 0.6782 - val_accuracy: 0.5876\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6495 - accuracy: 0.6388 - val_loss: 0.6744 - val_accuracy: 0.5927\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6471 - accuracy: 0.6434 - val_loss: 0.6721 - val_accuracy: 0.5970\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6470 - accuracy: 0.6469 - val_loss: 0.6727 - val_accuracy: 0.5958\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6451 - accuracy: 0.6500 - val_loss: 0.6710 - val_accuracy: 0.5983\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 898us/step - loss: 0.6429 - accuracy: 0.6512 - val_loss: 0.6713 - val_accuracy: 0.5978\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6418 - accuracy: 0.6492 - val_loss: 0.6696 - val_accuracy: 0.6013\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 897us/step - loss: 0.6391 - accuracy: 0.6541 - val_loss: 0.6658 - val_accuracy: 0.6065\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 870us/step - loss: 0.6375 - accuracy: 0.6572 - val_loss: 0.6651 - val_accuracy: 0.6068\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.6363 - accuracy: 0.6619 - val_loss: 0.6636 - val_accuracy: 0.6079\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6356 - accuracy: 0.6630 - val_loss: 0.6609 - val_accuracy: 0.6099\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6344 - accuracy: 0.6628 - val_loss: 0.6614 - val_accuracy: 0.6078\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6338 - accuracy: 0.6624 - val_loss: 0.6614 - val_accuracy: 0.6060\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6309 - accuracy: 0.6675 - val_loss: 0.6628 - val_accuracy: 0.6032\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 893us/step - loss: 0.6294 - accuracy: 0.6689 - val_loss: 0.6586 - val_accuracy: 0.6067\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6284 - accuracy: 0.6704 - val_loss: 0.6605 - val_accuracy: 0.6033\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6258 - accuracy: 0.6710 - val_loss: 0.6578 - val_accuracy: 0.6053\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6247 - accuracy: 0.6731 - val_loss: 0.6570 - val_accuracy: 0.6063\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6238 - accuracy: 0.6725 - val_loss: 0.6550 - val_accuracy: 0.6085\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6227 - accuracy: 0.6751 - val_loss: 0.6522 - val_accuracy: 0.6113\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 862us/step - loss: 0.6225 - accuracy: 0.6785 - val_loss: 0.6515 - val_accuracy: 0.6113\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 920us/step - loss: 0.6205 - accuracy: 0.6798 - val_loss: 0.6525 - val_accuracy: 0.6090\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6185 - accuracy: 0.6816 - val_loss: 0.6529 - val_accuracy: 0.6086\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6179 - accuracy: 0.6780 - val_loss: 0.6515 - val_accuracy: 0.6090\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6166 - accuracy: 0.6820 - val_loss: 0.6515 - val_accuracy: 0.6077\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6152 - accuracy: 0.6851 - val_loss: 0.6521 - val_accuracy: 0.6061\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6150 - accuracy: 0.6854 - val_loss: 0.6490 - val_accuracy: 0.6090\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6127 - accuracy: 0.6850 - val_loss: 0.6455 - val_accuracy: 0.6155\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6118 - accuracy: 0.6869 - val_loss: 0.6460 - val_accuracy: 0.6141\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6109 - accuracy: 0.6853 - val_loss: 0.6425 - val_accuracy: 0.6185\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.6098 - accuracy: 0.6875 - val_loss: 0.6416 - val_accuracy: 0.6188\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 946us/step - loss: 0.6089 - accuracy: 0.6897 - val_loss: 0.6441 - val_accuracy: 0.6158\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6077 - accuracy: 0.6905 - val_loss: 0.6428 - val_accuracy: 0.6164\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6068 - accuracy: 0.6901 - val_loss: 0.6391 - val_accuracy: 0.6214\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6054 - accuracy: 0.6919 - val_loss: 0.6421 - val_accuracy: 0.6165\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 820us/step - loss: 0.6056 - accuracy: 0.6918 - val_loss: 0.6403 - val_accuracy: 0.6188\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6025 - accuracy: 0.6970 - val_loss: 0.6402 - val_accuracy: 0.6186\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 903us/step - loss: 0.6656 - accuracy: 0.5932 - val_loss: 0.6565 - val_accuracy: 0.6157\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6581 - accuracy: 0.6157 - val_loss: 0.6698 - val_accuracy: 0.5928\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6530 - accuracy: 0.6261 - val_loss: 0.6700 - val_accuracy: 0.5901\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6483 - accuracy: 0.6347 - val_loss: 0.6683 - val_accuracy: 0.5918\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6457 - accuracy: 0.6385 - val_loss: 0.6648 - val_accuracy: 0.5968\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 915us/step - loss: 0.6434 - accuracy: 0.6379 - val_loss: 0.6599 - val_accuracy: 0.6030\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.6428 - accuracy: 0.6412 - val_loss: 0.6620 - val_accuracy: 0.6000\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 895us/step - loss: 0.6375 - accuracy: 0.6471 - val_loss: 0.6517 - val_accuracy: 0.6103\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6354 - accuracy: 0.6498 - val_loss: 0.6542 - val_accuracy: 0.6073\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 867us/step - loss: 0.6346 - accuracy: 0.6505 - val_loss: 0.6524 - val_accuracy: 0.6101\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 938us/step - loss: 0.6335 - accuracy: 0.6562 - val_loss: 0.6529 - val_accuracy: 0.6095\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6311 - accuracy: 0.6589 - val_loss: 0.6498 - val_accuracy: 0.6134\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 919us/step - loss: 0.6299 - accuracy: 0.6576 - val_loss: 0.6462 - val_accuracy: 0.6189\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 915us/step - loss: 0.6277 - accuracy: 0.6609 - val_loss: 0.6474 - val_accuracy: 0.6175\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 902us/step - loss: 0.6251 - accuracy: 0.6606 - val_loss: 0.6501 - val_accuracy: 0.6127\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 919us/step - loss: 0.6238 - accuracy: 0.6679 - val_loss: 0.6499 - val_accuracy: 0.6136\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 907us/step - loss: 0.6249 - accuracy: 0.6622 - val_loss: 0.6474 - val_accuracy: 0.6174\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 894us/step - loss: 0.6216 - accuracy: 0.6685 - val_loss: 0.6427 - val_accuracy: 0.6238\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6196 - accuracy: 0.6705 - val_loss: 0.6432 - val_accuracy: 0.6228\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6189 - accuracy: 0.6717 - val_loss: 0.6389 - val_accuracy: 0.6292\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6188 - accuracy: 0.6711 - val_loss: 0.6400 - val_accuracy: 0.6273\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 927us/step - loss: 0.6175 - accuracy: 0.6718 - val_loss: 0.6397 - val_accuracy: 0.6273\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6154 - accuracy: 0.6726 - val_loss: 0.6410 - val_accuracy: 0.6258\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6142 - accuracy: 0.6746 - val_loss: 0.6350 - val_accuracy: 0.6330\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 870us/step - loss: 0.6155 - accuracy: 0.6711 - val_loss: 0.6362 - val_accuracy: 0.6318\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 885us/step - loss: 0.6119 - accuracy: 0.6749 - val_loss: 0.6290 - val_accuracy: 0.6380\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6109 - accuracy: 0.6754 - val_loss: 0.6366 - val_accuracy: 0.6297\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6097 - accuracy: 0.6767 - val_loss: 0.6309 - val_accuracy: 0.6356\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 880us/step - loss: 0.6084 - accuracy: 0.6793 - val_loss: 0.6295 - val_accuracy: 0.6368\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6074 - accuracy: 0.6802 - val_loss: 0.6320 - val_accuracy: 0.6346\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6058 - accuracy: 0.6815 - val_loss: 0.6300 - val_accuracy: 0.6356\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 871us/step - loss: 0.6068 - accuracy: 0.6777 - val_loss: 0.6320 - val_accuracy: 0.6340\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6050 - accuracy: 0.6811 - val_loss: 0.6303 - val_accuracy: 0.6349\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 858us/step - loss: 0.6043 - accuracy: 0.6829 - val_loss: 0.6262 - val_accuracy: 0.6372\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 900us/step - loss: 0.6026 - accuracy: 0.6832 - val_loss: 0.6276 - val_accuracy: 0.6360\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6018 - accuracy: 0.6821 - val_loss: 0.6308 - val_accuracy: 0.6336\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 871us/step - loss: 0.6003 - accuracy: 0.6853 - val_loss: 0.6273 - val_accuracy: 0.6353\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6009 - accuracy: 0.6847 - val_loss: 0.6267 - val_accuracy: 0.6351\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.5990 - accuracy: 0.6855 - val_loss: 0.6240 - val_accuracy: 0.6373\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 858us/step - loss: 0.5981 - accuracy: 0.6868 - val_loss: 0.6231 - val_accuracy: 0.6387\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.5975 - accuracy: 0.6894 - val_loss: 0.6224 - val_accuracy: 0.6388\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.5976 - accuracy: 0.6886 - val_loss: 0.6213 - val_accuracy: 0.6388\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.5964 - accuracy: 0.6894 - val_loss: 0.6222 - val_accuracy: 0.6373\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.5957 - accuracy: 0.6900 - val_loss: 0.6267 - val_accuracy: 0.6319\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.5947 - accuracy: 0.6888 - val_loss: 0.6209 - val_accuracy: 0.6380\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.5934 - accuracy: 0.6905 - val_loss: 0.6186 - val_accuracy: 0.6404\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 821us/step - loss: 0.5931 - accuracy: 0.6915 - val_loss: 0.6156 - val_accuracy: 0.6423\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.5930 - accuracy: 0.6907 - val_loss: 0.6164 - val_accuracy: 0.6409\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.5917 - accuracy: 0.6956 - val_loss: 0.6188 - val_accuracy: 0.6385\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.5895 - accuracy: 0.6944 - val_loss: 0.6200 - val_accuracy: 0.6375\n",
      "Epoch 1/50\n",
      "779/836 [==========================>...] - ETA: 0s - loss: 0.7030 - accuracy: 0.5228WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 946us/step - loss: 0.7029 - accuracy: 0.5227 - val_loss: 0.7321 - val_accuracy: 0.3341\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6975 - accuracy: 0.5286 - val_loss: 0.7105 - val_accuracy: 0.4416\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6944 - accuracy: 0.5315 - val_loss: 0.7057 - val_accuracy: 0.4725\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 708us/step - loss: 0.6913 - accuracy: 0.5408 - val_loss: 0.7033 - val_accuracy: 0.4851\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6885 - accuracy: 0.5412 - val_loss: 0.7043 - val_accuracy: 0.4805\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6848 - accuracy: 0.5514 - val_loss: 0.6990 - val_accuracy: 0.5055\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 956us/step - loss: 0.6822 - accuracy: 0.5577 - val_loss: 0.6939 - val_accuracy: 0.5237\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 794us/step - loss: 0.6795 - accuracy: 0.5576 - val_loss: 0.6954 - val_accuracy: 0.5171\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.6795 - accuracy: 0.5605 - val_loss: 0.6922 - val_accuracy: 0.5265\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6774 - accuracy: 0.5661 - val_loss: 0.6905 - val_accuracy: 0.5336\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.6743 - accuracy: 0.5742 - val_loss: 0.6943 - val_accuracy: 0.5162\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6725 - accuracy: 0.5796 - val_loss: 0.6887 - val_accuracy: 0.5448\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6707 - accuracy: 0.5789 - val_loss: 0.6889 - val_accuracy: 0.5429\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.6687 - accuracy: 0.5890 - val_loss: 0.6852 - val_accuracy: 0.5563\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 737us/step - loss: 0.6675 - accuracy: 0.5914 - val_loss: 0.6825 - val_accuracy: 0.5623\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6622 - accuracy: 0.5972 - val_loss: 0.6835 - val_accuracy: 0.5574\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 797us/step - loss: 0.6632 - accuracy: 0.5998 - val_loss: 0.6806 - val_accuracy: 0.5650\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6616 - accuracy: 0.6016 - val_loss: 0.6832 - val_accuracy: 0.5525\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 771us/step - loss: 0.6596 - accuracy: 0.6078 - val_loss: 0.6745 - val_accuracy: 0.5778\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6576 - accuracy: 0.6114 - val_loss: 0.6773 - val_accuracy: 0.5659\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6560 - accuracy: 0.6144 - val_loss: 0.6763 - val_accuracy: 0.5659\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 795us/step - loss: 0.6558 - accuracy: 0.6155 - val_loss: 0.6735 - val_accuracy: 0.5715\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6522 - accuracy: 0.6229 - val_loss: 0.6743 - val_accuracy: 0.5695\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6511 - accuracy: 0.6270 - val_loss: 0.6705 - val_accuracy: 0.5767\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6501 - accuracy: 0.6261 - val_loss: 0.6700 - val_accuracy: 0.5778\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 703us/step - loss: 0.6476 - accuracy: 0.6314 - val_loss: 0.6710 - val_accuracy: 0.5743\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6472 - accuracy: 0.6336 - val_loss: 0.6694 - val_accuracy: 0.5771\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6464 - accuracy: 0.6365 - val_loss: 0.6670 - val_accuracy: 0.5808\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6436 - accuracy: 0.6388 - val_loss: 0.6656 - val_accuracy: 0.5828\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 701us/step - loss: 0.6418 - accuracy: 0.6466 - val_loss: 0.6661 - val_accuracy: 0.5806\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6421 - accuracy: 0.6405 - val_loss: 0.6635 - val_accuracy: 0.5850\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6390 - accuracy: 0.6490 - val_loss: 0.6594 - val_accuracy: 0.5927\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6376 - accuracy: 0.6509 - val_loss: 0.6618 - val_accuracy: 0.5872\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6369 - accuracy: 0.6521 - val_loss: 0.6598 - val_accuracy: 0.5915\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 734us/step - loss: 0.6355 - accuracy: 0.6548 - val_loss: 0.6568 - val_accuracy: 0.5949\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6331 - accuracy: 0.6565 - val_loss: 0.6579 - val_accuracy: 0.5923\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6332 - accuracy: 0.6585 - val_loss: 0.6569 - val_accuracy: 0.5931\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6313 - accuracy: 0.6601 - val_loss: 0.6567 - val_accuracy: 0.5919\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 947us/step - loss: 0.6288 - accuracy: 0.6617 - val_loss: 0.6543 - val_accuracy: 0.5952\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6285 - accuracy: 0.6656 - val_loss: 0.6515 - val_accuracy: 0.5981\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6267 - accuracy: 0.6713 - val_loss: 0.6551 - val_accuracy: 0.5919\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6258 - accuracy: 0.6693 - val_loss: 0.6524 - val_accuracy: 0.5950\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6242 - accuracy: 0.6719 - val_loss: 0.6492 - val_accuracy: 0.5992\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6228 - accuracy: 0.6739 - val_loss: 0.6472 - val_accuracy: 0.6021\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6209 - accuracy: 0.6760 - val_loss: 0.6449 - val_accuracy: 0.6048\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 790us/step - loss: 0.6210 - accuracy: 0.6754 - val_loss: 0.6480 - val_accuracy: 0.6001\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 666us/step - loss: 0.6197 - accuracy: 0.6772 - val_loss: 0.6438 - val_accuracy: 0.6044\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6173 - accuracy: 0.6816 - val_loss: 0.6458 - val_accuracy: 0.6010\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6163 - accuracy: 0.6808 - val_loss: 0.6444 - val_accuracy: 0.6023\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6157 - accuracy: 0.6798 - val_loss: 0.6436 - val_accuracy: 0.6040\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.7122 - accuracy: 0.5257 - val_loss: 0.6701 - val_accuracy: 0.6329\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6926 - accuracy: 0.5506 - val_loss: 0.6999 - val_accuracy: 0.5266\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.6870 - accuracy: 0.5615 - val_loss: 0.7071 - val_accuracy: 0.5138\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6852 - accuracy: 0.5723 - val_loss: 0.7027 - val_accuracy: 0.5238\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6847 - accuracy: 0.5696 - val_loss: 0.7002 - val_accuracy: 0.5287\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 646us/step - loss: 0.6808 - accuracy: 0.5764 - val_loss: 0.6942 - val_accuracy: 0.5426\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6779 - accuracy: 0.5833 - val_loss: 0.6929 - val_accuracy: 0.5459\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 784us/step - loss: 0.6757 - accuracy: 0.5900 - val_loss: 0.6861 - val_accuracy: 0.5634\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6718 - accuracy: 0.5929 - val_loss: 0.6859 - val_accuracy: 0.5651\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6689 - accuracy: 0.6019 - val_loss: 0.6855 - val_accuracy: 0.5667\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.6679 - accuracy: 0.6021 - val_loss: 0.6831 - val_accuracy: 0.5710\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6662 - accuracy: 0.6059 - val_loss: 0.6845 - val_accuracy: 0.5684\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 784us/step - loss: 0.6642 - accuracy: 0.6086 - val_loss: 0.6811 - val_accuracy: 0.5722\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6622 - accuracy: 0.6161 - val_loss: 0.6801 - val_accuracy: 0.5733\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6595 - accuracy: 0.6202 - val_loss: 0.6819 - val_accuracy: 0.5710\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6588 - accuracy: 0.6160 - val_loss: 0.6772 - val_accuracy: 0.5786\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6564 - accuracy: 0.6219 - val_loss: 0.6752 - val_accuracy: 0.5824\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6550 - accuracy: 0.6280 - val_loss: 0.6716 - val_accuracy: 0.5881\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6537 - accuracy: 0.6258 - val_loss: 0.6687 - val_accuracy: 0.5921\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6519 - accuracy: 0.6340 - val_loss: 0.6674 - val_accuracy: 0.5929\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6483 - accuracy: 0.6393 - val_loss: 0.6677 - val_accuracy: 0.5933\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6477 - accuracy: 0.6386 - val_loss: 0.6701 - val_accuracy: 0.5906\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 951us/step - loss: 0.6464 - accuracy: 0.6376 - val_loss: 0.6653 - val_accuracy: 0.5949\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 756us/step - loss: 0.6446 - accuracy: 0.6419 - val_loss: 0.6624 - val_accuracy: 0.5980\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6446 - accuracy: 0.6414 - val_loss: 0.6625 - val_accuracy: 0.5991\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6415 - accuracy: 0.6471 - val_loss: 0.6603 - val_accuracy: 0.6023\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 693us/step - loss: 0.6386 - accuracy: 0.6500 - val_loss: 0.6555 - val_accuracy: 0.6065\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 781us/step - loss: 0.6388 - accuracy: 0.6524 - val_loss: 0.6554 - val_accuracy: 0.6062\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6381 - accuracy: 0.6509 - val_loss: 0.6502 - val_accuracy: 0.6106\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6364 - accuracy: 0.6519 - val_loss: 0.6535 - val_accuracy: 0.6082\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6337 - accuracy: 0.6588 - val_loss: 0.6523 - val_accuracy: 0.6094\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6332 - accuracy: 0.6551 - val_loss: 0.6535 - val_accuracy: 0.6070\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6321 - accuracy: 0.6593 - val_loss: 0.6470 - val_accuracy: 0.6122\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6314 - accuracy: 0.6600 - val_loss: 0.6515 - val_accuracy: 0.6081\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6295 - accuracy: 0.6600 - val_loss: 0.6461 - val_accuracy: 0.6121\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6290 - accuracy: 0.6610 - val_loss: 0.6413 - val_accuracy: 0.6168\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6281 - accuracy: 0.6629 - val_loss: 0.6466 - val_accuracy: 0.6130\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 681us/step - loss: 0.6272 - accuracy: 0.6634 - val_loss: 0.6468 - val_accuracy: 0.6133\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6254 - accuracy: 0.6656 - val_loss: 0.6483 - val_accuracy: 0.6124\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.6266 - accuracy: 0.6625 - val_loss: 0.6461 - val_accuracy: 0.6144\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 730us/step - loss: 0.6233 - accuracy: 0.6686 - val_loss: 0.6460 - val_accuracy: 0.6145\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6227 - accuracy: 0.6670 - val_loss: 0.6428 - val_accuracy: 0.6172\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 732us/step - loss: 0.6209 - accuracy: 0.6702 - val_loss: 0.6420 - val_accuracy: 0.6179\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6206 - accuracy: 0.6699 - val_loss: 0.6353 - val_accuracy: 0.6256\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 790us/step - loss: 0.6181 - accuracy: 0.6720 - val_loss: 0.6397 - val_accuracy: 0.6205\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 660us/step - loss: 0.6185 - accuracy: 0.6719 - val_loss: 0.6409 - val_accuracy: 0.6188\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.6179 - accuracy: 0.6723 - val_loss: 0.6404 - val_accuracy: 0.6195\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 753us/step - loss: 0.6175 - accuracy: 0.6733 - val_loss: 0.6395 - val_accuracy: 0.6207\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6165 - accuracy: 0.6718 - val_loss: 0.6399 - val_accuracy: 0.6208\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6155 - accuracy: 0.6729 - val_loss: 0.6387 - val_accuracy: 0.6222\n",
      "Epoch 1/50\n",
      "810/836 [============================>.] - ETA: 0s - loss: 0.6990 - accuracy: 0.5319WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6986 - accuracy: 0.5326 - val_loss: 0.6941 - val_accuracy: 0.5440\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 704us/step - loss: 0.6931 - accuracy: 0.5447 - val_loss: 0.6947 - val_accuracy: 0.5468\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6905 - accuracy: 0.5460 - val_loss: 0.6913 - val_accuracy: 0.5607\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6834 - accuracy: 0.5560 - val_loss: 0.6917 - val_accuracy: 0.5610\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.6816 - accuracy: 0.5631 - val_loss: 0.6902 - val_accuracy: 0.5645\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.6771 - accuracy: 0.5758 - val_loss: 0.6880 - val_accuracy: 0.5704\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6757 - accuracy: 0.5762 - val_loss: 0.6815 - val_accuracy: 0.5869\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6689 - accuracy: 0.5887 - val_loss: 0.6814 - val_accuracy: 0.5855\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6663 - accuracy: 0.5971 - val_loss: 0.6761 - val_accuracy: 0.5989\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 780us/step - loss: 0.6632 - accuracy: 0.5995 - val_loss: 0.6748 - val_accuracy: 0.6010\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 933us/step - loss: 0.6621 - accuracy: 0.5987 - val_loss: 0.6724 - val_accuracy: 0.6053\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 795us/step - loss: 0.6569 - accuracy: 0.6122 - val_loss: 0.6715 - val_accuracy: 0.6061\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6565 - accuracy: 0.6159 - val_loss: 0.6698 - val_accuracy: 0.6078\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 714us/step - loss: 0.6531 - accuracy: 0.6181 - val_loss: 0.6697 - val_accuracy: 0.6075\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6523 - accuracy: 0.6188 - val_loss: 0.6651 - val_accuracy: 0.6120\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6485 - accuracy: 0.6263 - val_loss: 0.6642 - val_accuracy: 0.6122\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6473 - accuracy: 0.6286 - val_loss: 0.6633 - val_accuracy: 0.6131\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6460 - accuracy: 0.6305 - val_loss: 0.6612 - val_accuracy: 0.6158\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 780us/step - loss: 0.6419 - accuracy: 0.6389 - val_loss: 0.6590 - val_accuracy: 0.6182\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 771us/step - loss: 0.6406 - accuracy: 0.6375 - val_loss: 0.6593 - val_accuracy: 0.6166\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.6380 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6214\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6360 - accuracy: 0.6494 - val_loss: 0.6531 - val_accuracy: 0.6277\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 698us/step - loss: 0.6348 - accuracy: 0.6450 - val_loss: 0.6551 - val_accuracy: 0.6225\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 746us/step - loss: 0.6342 - accuracy: 0.6475 - val_loss: 0.6509 - val_accuracy: 0.6308\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6309 - accuracy: 0.6499 - val_loss: 0.6485 - val_accuracy: 0.6350\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.6313 - accuracy: 0.6529 - val_loss: 0.6482 - val_accuracy: 0.6351\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 746us/step - loss: 0.6271 - accuracy: 0.6578 - val_loss: 0.6463 - val_accuracy: 0.6363\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 746us/step - loss: 0.6269 - accuracy: 0.6595 - val_loss: 0.6443 - val_accuracy: 0.6381\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6262 - accuracy: 0.6575 - val_loss: 0.6428 - val_accuracy: 0.6410\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6227 - accuracy: 0.6630 - val_loss: 0.6427 - val_accuracy: 0.6397\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6230 - accuracy: 0.6615 - val_loss: 0.6410 - val_accuracy: 0.6426\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 741us/step - loss: 0.6214 - accuracy: 0.6639 - val_loss: 0.6396 - val_accuracy: 0.6447\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6202 - accuracy: 0.6654 - val_loss: 0.6406 - val_accuracy: 0.6410\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.6187 - accuracy: 0.6676 - val_loss: 0.6393 - val_accuracy: 0.6425\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6172 - accuracy: 0.6701 - val_loss: 0.6370 - val_accuracy: 0.6455\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 691us/step - loss: 0.6162 - accuracy: 0.6704 - val_loss: 0.6372 - val_accuracy: 0.6437\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 779us/step - loss: 0.6150 - accuracy: 0.6731 - val_loss: 0.6349 - val_accuracy: 0.6464\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.6121 - accuracy: 0.6733 - val_loss: 0.6335 - val_accuracy: 0.6476\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 720us/step - loss: 0.6128 - accuracy: 0.6694 - val_loss: 0.6325 - val_accuracy: 0.6482\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6105 - accuracy: 0.6736 - val_loss: 0.6299 - val_accuracy: 0.6518\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6090 - accuracy: 0.6769 - val_loss: 0.6303 - val_accuracy: 0.6492\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6077 - accuracy: 0.6799 - val_loss: 0.6286 - val_accuracy: 0.6516\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6066 - accuracy: 0.6785 - val_loss: 0.6291 - val_accuracy: 0.6496\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6071 - accuracy: 0.6767 - val_loss: 0.6279 - val_accuracy: 0.6506\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 700us/step - loss: 0.6049 - accuracy: 0.6782 - val_loss: 0.6287 - val_accuracy: 0.6479\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 802us/step - loss: 0.6053 - accuracy: 0.6806 - val_loss: 0.6279 - val_accuracy: 0.6485\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6032 - accuracy: 0.6817 - val_loss: 0.6295 - val_accuracy: 0.6459\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 941us/step - loss: 0.6036 - accuracy: 0.6807 - val_loss: 0.6278 - val_accuracy: 0.6468\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.5994 - accuracy: 0.6853 - val_loss: 0.6244 - val_accuracy: 0.6511\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.5994 - accuracy: 0.6844 - val_loss: 0.6237 - val_accuracy: 0.6521\n",
      "\n",
      "Training model with sample_size_ratio=0.5, target_eps=2.0...\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 5.05 iterated over 41800 steps satisfies differential privacy with eps = 0.245 and delta = 1e-05.\n",
      "The optimal RDP order is 128.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 2.5749999999999997 iterated over 41800 steps satisfies differential privacy with eps = 0.481 and delta = 1e-05.\n",
      "The optimal RDP order is 49.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.3375 iterated over 41800 steps satisfies differential privacy with eps = 1.05 and delta = 1e-05.\n",
      "The optimal RDP order is 22.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.71875 iterated over 41800 steps satisfies differential privacy with eps = 3.62 and delta = 1e-05.\n",
      "The optimal RDP order is 6.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 1.028125 iterated over 41800 steps satisfies differential privacy with eps = 1.6 and delta = 1e-05.\n",
      "The optimal RDP order is 13.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.8734375 iterated over 41800 steps satisfies differential privacy with eps = 2.21 and delta = 1e-05.\n",
      "The optimal RDP order is 9.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.9507812499999999 iterated over 41800 steps satisfies differential privacy with eps = 1.85 and delta = 1e-05.\n",
      "The optimal RDP order is 11.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.912109375 iterated over 41800 steps satisfies differential privacy with eps = 2.02 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.9314453125 iterated over 41800 steps satisfies differential privacy with eps = 1.95 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.92177734375 iterated over 41800 steps satisfies differential privacy with eps = 1.98 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "DP-SGD with sampling rate = 0.12% and noise_multiplier = 0.916943359375 iterated over 41800 steps satisfies differential privacy with eps = 2 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7435 - accuracy: 0.4921 - val_loss: 0.6086 - val_accuracy: 0.8774\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6976 - accuracy: 0.5256 - val_loss: 0.6739 - val_accuracy: 0.6532\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.6893 - accuracy: 0.5478 - val_loss: 0.6953 - val_accuracy: 0.5253\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 979us/step - loss: 0.6847 - accuracy: 0.5539 - val_loss: 0.6964 - val_accuracy: 0.5243\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 798us/step - loss: 0.6806 - accuracy: 0.5704 - val_loss: 0.6943 - val_accuracy: 0.5328\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 817us/step - loss: 0.6783 - accuracy: 0.5783 - val_loss: 0.6932 - val_accuracy: 0.5343\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 819us/step - loss: 0.6728 - accuracy: 0.5898 - val_loss: 0.6889 - val_accuracy: 0.5454\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6707 - accuracy: 0.5938 - val_loss: 0.6865 - val_accuracy: 0.5523\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6668 - accuracy: 0.6037 - val_loss: 0.6854 - val_accuracy: 0.5515\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6620 - accuracy: 0.6143 - val_loss: 0.6804 - val_accuracy: 0.5686\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6623 - accuracy: 0.6157 - val_loss: 0.6786 - val_accuracy: 0.5735\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6601 - accuracy: 0.6211 - val_loss: 0.6764 - val_accuracy: 0.5781\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6559 - accuracy: 0.6256 - val_loss: 0.6752 - val_accuracy: 0.5798\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6520 - accuracy: 0.6344 - val_loss: 0.6721 - val_accuracy: 0.5845\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 898us/step - loss: 0.6514 - accuracy: 0.6376 - val_loss: 0.6693 - val_accuracy: 0.5895\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 815us/step - loss: 0.6489 - accuracy: 0.6406 - val_loss: 0.6662 - val_accuracy: 0.5954\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 856us/step - loss: 0.6464 - accuracy: 0.6476 - val_loss: 0.6661 - val_accuracy: 0.5933\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6446 - accuracy: 0.6454 - val_loss: 0.6634 - val_accuracy: 0.5975\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6424 - accuracy: 0.6509 - val_loss: 0.6617 - val_accuracy: 0.5998\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6385 - accuracy: 0.6516 - val_loss: 0.6619 - val_accuracy: 0.5958\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 815us/step - loss: 0.6373 - accuracy: 0.6597 - val_loss: 0.6570 - val_accuracy: 0.6065\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6372 - accuracy: 0.6534 - val_loss: 0.6556 - val_accuracy: 0.6082\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6349 - accuracy: 0.6584 - val_loss: 0.6529 - val_accuracy: 0.6122\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 881us/step - loss: 0.6304 - accuracy: 0.6651 - val_loss: 0.6540 - val_accuracy: 0.6061\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6293 - accuracy: 0.6663 - val_loss: 0.6532 - val_accuracy: 0.6065\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 877us/step - loss: 0.6277 - accuracy: 0.6692 - val_loss: 0.6503 - val_accuracy: 0.6111\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6263 - accuracy: 0.6694 - val_loss: 0.6484 - val_accuracy: 0.6141\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 859us/step - loss: 0.6253 - accuracy: 0.6696 - val_loss: 0.6486 - val_accuracy: 0.6120\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6235 - accuracy: 0.6745 - val_loss: 0.6427 - val_accuracy: 0.6222\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6229 - accuracy: 0.6708 - val_loss: 0.6406 - val_accuracy: 0.6253\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 881us/step - loss: 0.6211 - accuracy: 0.6740 - val_loss: 0.6405 - val_accuracy: 0.6244\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6206 - accuracy: 0.6752 - val_loss: 0.6423 - val_accuracy: 0.6188\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6172 - accuracy: 0.6767 - val_loss: 0.6398 - val_accuracy: 0.6234\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 814us/step - loss: 0.6166 - accuracy: 0.6794 - val_loss: 0.6385 - val_accuracy: 0.6240\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 823us/step - loss: 0.6153 - accuracy: 0.6800 - val_loss: 0.6367 - val_accuracy: 0.6256\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6133 - accuracy: 0.6822 - val_loss: 0.6354 - val_accuracy: 0.6267\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 838us/step - loss: 0.6120 - accuracy: 0.6810 - val_loss: 0.6329 - val_accuracy: 0.6310\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6109 - accuracy: 0.6828 - val_loss: 0.6307 - val_accuracy: 0.6334\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6080 - accuracy: 0.6854 - val_loss: 0.6319 - val_accuracy: 0.6302\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6092 - accuracy: 0.6846 - val_loss: 0.6320 - val_accuracy: 0.6287\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6075 - accuracy: 0.6843 - val_loss: 0.6281 - val_accuracy: 0.6345\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6045 - accuracy: 0.6881 - val_loss: 0.6272 - val_accuracy: 0.6354\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6040 - accuracy: 0.6868 - val_loss: 0.6286 - val_accuracy: 0.6312\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6038 - accuracy: 0.6874 - val_loss: 0.6299 - val_accuracy: 0.6287\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6023 - accuracy: 0.6894 - val_loss: 0.6283 - val_accuracy: 0.6309\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6008 - accuracy: 0.6876 - val_loss: 0.6253 - val_accuracy: 0.6360\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 943us/step - loss: 0.6012 - accuracy: 0.6889 - val_loss: 0.6221 - val_accuracy: 0.6395\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.5975 - accuracy: 0.6938 - val_loss: 0.6184 - val_accuracy: 0.6464\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.5979 - accuracy: 0.6922 - val_loss: 0.6179 - val_accuracy: 0.6471\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 875us/step - loss: 0.5965 - accuracy: 0.6919 - val_loss: 0.6224 - val_accuracy: 0.6374\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 946us/step - loss: 0.7297 - accuracy: 0.4840 - val_loss: 0.6140 - val_accuracy: 0.8652\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6985 - accuracy: 0.5149 - val_loss: 0.6691 - val_accuracy: 0.6164\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 989us/step - loss: 0.6932 - accuracy: 0.5287 - val_loss: 0.6866 - val_accuracy: 0.5370\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 854us/step - loss: 0.6887 - accuracy: 0.5423 - val_loss: 0.6905 - val_accuracy: 0.5263\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6862 - accuracy: 0.5470 - val_loss: 0.6897 - val_accuracy: 0.5325\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 871us/step - loss: 0.6832 - accuracy: 0.5581 - val_loss: 0.6868 - val_accuracy: 0.5426\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6814 - accuracy: 0.5600 - val_loss: 0.6829 - val_accuracy: 0.5584\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 905us/step - loss: 0.6784 - accuracy: 0.5690 - val_loss: 0.6798 - val_accuracy: 0.5708\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6749 - accuracy: 0.5752 - val_loss: 0.6756 - val_accuracy: 0.5848\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6734 - accuracy: 0.5819 - val_loss: 0.6750 - val_accuracy: 0.5854\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6710 - accuracy: 0.5880 - val_loss: 0.6739 - val_accuracy: 0.5880\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 835us/step - loss: 0.6679 - accuracy: 0.5958 - val_loss: 0.6722 - val_accuracy: 0.5911\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6674 - accuracy: 0.5976 - val_loss: 0.6695 - val_accuracy: 0.5973\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6650 - accuracy: 0.6023 - val_loss: 0.6711 - val_accuracy: 0.5931\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 968us/step - loss: 0.6631 - accuracy: 0.6018 - val_loss: 0.6710 - val_accuracy: 0.5913\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6614 - accuracy: 0.6086 - val_loss: 0.6660 - val_accuracy: 0.6026\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6587 - accuracy: 0.6156 - val_loss: 0.6642 - val_accuracy: 0.6052\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6574 - accuracy: 0.6148 - val_loss: 0.6632 - val_accuracy: 0.6071\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6544 - accuracy: 0.6231 - val_loss: 0.6637 - val_accuracy: 0.6062\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6533 - accuracy: 0.6265 - val_loss: 0.6615 - val_accuracy: 0.6089\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 778us/step - loss: 0.6536 - accuracy: 0.6246 - val_loss: 0.6595 - val_accuracy: 0.6104\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 836us/step - loss: 0.6508 - accuracy: 0.6308 - val_loss: 0.6586 - val_accuracy: 0.6110\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 864us/step - loss: 0.6492 - accuracy: 0.6310 - val_loss: 0.6602 - val_accuracy: 0.6073\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6471 - accuracy: 0.6354 - val_loss: 0.6556 - val_accuracy: 0.6155\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 875us/step - loss: 0.6474 - accuracy: 0.6344 - val_loss: 0.6580 - val_accuracy: 0.6092\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 872us/step - loss: 0.6453 - accuracy: 0.6390 - val_loss: 0.6557 - val_accuracy: 0.6127\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6433 - accuracy: 0.6425 - val_loss: 0.6551 - val_accuracy: 0.6124\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6429 - accuracy: 0.6417 - val_loss: 0.6511 - val_accuracy: 0.6190\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.6425 - accuracy: 0.6427 - val_loss: 0.6531 - val_accuracy: 0.6147\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 911us/step - loss: 0.6379 - accuracy: 0.6498 - val_loss: 0.6507 - val_accuracy: 0.6178\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 867us/step - loss: 0.6391 - accuracy: 0.6469 - val_loss: 0.6522 - val_accuracy: 0.6137\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6373 - accuracy: 0.6497 - val_loss: 0.6462 - val_accuracy: 0.6242\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 870us/step - loss: 0.6375 - accuracy: 0.6503 - val_loss: 0.6475 - val_accuracy: 0.6201\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6355 - accuracy: 0.6543 - val_loss: 0.6477 - val_accuracy: 0.6190\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6337 - accuracy: 0.6536 - val_loss: 0.6459 - val_accuracy: 0.6210\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6323 - accuracy: 0.6566 - val_loss: 0.6463 - val_accuracy: 0.6195\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 832us/step - loss: 0.6313 - accuracy: 0.6565 - val_loss: 0.6434 - val_accuracy: 0.6249\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 918us/step - loss: 0.6304 - accuracy: 0.6599 - val_loss: 0.6466 - val_accuracy: 0.6178\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 918us/step - loss: 0.6290 - accuracy: 0.6592 - val_loss: 0.6394 - val_accuracy: 0.6309\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6282 - accuracy: 0.6607 - val_loss: 0.6433 - val_accuracy: 0.6232\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6261 - accuracy: 0.6659 - val_loss: 0.6415 - val_accuracy: 0.6247\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6246 - accuracy: 0.6662 - val_loss: 0.6386 - val_accuracy: 0.6291\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 910us/step - loss: 0.6242 - accuracy: 0.6656 - val_loss: 0.6427 - val_accuracy: 0.6222\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6240 - accuracy: 0.6666 - val_loss: 0.6396 - val_accuracy: 0.6263\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6224 - accuracy: 0.6674 - val_loss: 0.6395 - val_accuracy: 0.6261\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 878us/step - loss: 0.6210 - accuracy: 0.6686 - val_loss: 0.6373 - val_accuracy: 0.6290\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6199 - accuracy: 0.6688 - val_loss: 0.6361 - val_accuracy: 0.6307\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 919us/step - loss: 0.6194 - accuracy: 0.6715 - val_loss: 0.6318 - val_accuracy: 0.6365\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 780us/step - loss: 0.6169 - accuracy: 0.6739 - val_loss: 0.6308 - val_accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6170 - accuracy: 0.6742 - val_loss: 0.6338 - val_accuracy: 0.6309\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.7153 - accuracy: 0.4780 - val_loss: 0.7661 - val_accuracy: 0.1312\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.7097 - accuracy: 0.4807 - val_loss: 0.7488 - val_accuracy: 0.1500\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.7057 - accuracy: 0.4883 - val_loss: 0.7402 - val_accuracy: 0.1630\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.7020 - accuracy: 0.4974 - val_loss: 0.7336 - val_accuracy: 0.1828\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6979 - accuracy: 0.5109 - val_loss: 0.7308 - val_accuracy: 0.1887\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 822us/step - loss: 0.6979 - accuracy: 0.5110 - val_loss: 0.7287 - val_accuracy: 0.2019\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.6945 - accuracy: 0.5255 - val_loss: 0.7278 - val_accuracy: 0.2140\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6911 - accuracy: 0.5378 - val_loss: 0.7253 - val_accuracy: 0.2415\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 861us/step - loss: 0.6899 - accuracy: 0.5393 - val_loss: 0.7230 - val_accuracy: 0.2727\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6882 - accuracy: 0.5413 - val_loss: 0.7204 - val_accuracy: 0.3048\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6859 - accuracy: 0.5553 - val_loss: 0.7197 - val_accuracy: 0.3271\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6846 - accuracy: 0.5579 - val_loss: 0.7180 - val_accuracy: 0.3544\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6816 - accuracy: 0.5665 - val_loss: 0.7159 - val_accuracy: 0.3810\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6804 - accuracy: 0.5748 - val_loss: 0.7145 - val_accuracy: 0.3972\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 995us/step - loss: 0.6790 - accuracy: 0.5764 - val_loss: 0.7128 - val_accuracy: 0.4156\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.6768 - accuracy: 0.5850 - val_loss: 0.7106 - val_accuracy: 0.4299\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6762 - accuracy: 0.5827 - val_loss: 0.7092 - val_accuracy: 0.4386\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6743 - accuracy: 0.5892 - val_loss: 0.7077 - val_accuracy: 0.4460\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6727 - accuracy: 0.5952 - val_loss: 0.7052 - val_accuracy: 0.4568\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6714 - accuracy: 0.5988 - val_loss: 0.7047 - val_accuracy: 0.4602\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.6704 - accuracy: 0.6076 - val_loss: 0.7038 - val_accuracy: 0.4658\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6681 - accuracy: 0.6107 - val_loss: 0.7020 - val_accuracy: 0.4763\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6665 - accuracy: 0.6133 - val_loss: 0.6997 - val_accuracy: 0.4870\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 736us/step - loss: 0.6656 - accuracy: 0.6155 - val_loss: 0.7002 - val_accuracy: 0.4857\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 813us/step - loss: 0.6657 - accuracy: 0.6170 - val_loss: 0.6987 - val_accuracy: 0.4940\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6635 - accuracy: 0.6237 - val_loss: 0.6985 - val_accuracy: 0.4944\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6611 - accuracy: 0.6281 - val_loss: 0.6961 - val_accuracy: 0.5029\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6606 - accuracy: 0.6274 - val_loss: 0.6951 - val_accuracy: 0.5066\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6598 - accuracy: 0.6293 - val_loss: 0.6942 - val_accuracy: 0.5096\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 746us/step - loss: 0.6587 - accuracy: 0.6346 - val_loss: 0.6916 - val_accuracy: 0.5213\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6555 - accuracy: 0.6401 - val_loss: 0.6908 - val_accuracy: 0.5246\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.6554 - accuracy: 0.6380 - val_loss: 0.6898 - val_accuracy: 0.5271\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 949us/step - loss: 0.6530 - accuracy: 0.6429 - val_loss: 0.6888 - val_accuracy: 0.5309\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 889us/step - loss: 0.6523 - accuracy: 0.6395 - val_loss: 0.6877 - val_accuracy: 0.5336\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6503 - accuracy: 0.6500 - val_loss: 0.6856 - val_accuracy: 0.5415\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6495 - accuracy: 0.6497 - val_loss: 0.6858 - val_accuracy: 0.5384\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6493 - accuracy: 0.6474 - val_loss: 0.6834 - val_accuracy: 0.5462\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6482 - accuracy: 0.6475 - val_loss: 0.6811 - val_accuracy: 0.5520\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 648us/step - loss: 0.6468 - accuracy: 0.6507 - val_loss: 0.6801 - val_accuracy: 0.5538\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 778us/step - loss: 0.6440 - accuracy: 0.6581 - val_loss: 0.6790 - val_accuracy: 0.5549\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6445 - accuracy: 0.6516 - val_loss: 0.6769 - val_accuracy: 0.5599\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6414 - accuracy: 0.6600 - val_loss: 0.6767 - val_accuracy: 0.5583\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6402 - accuracy: 0.6592 - val_loss: 0.6744 - val_accuracy: 0.5626\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 736us/step - loss: 0.6407 - accuracy: 0.6614 - val_loss: 0.6756 - val_accuracy: 0.5598\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6375 - accuracy: 0.6651 - val_loss: 0.6740 - val_accuracy: 0.5631\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 794us/step - loss: 0.6378 - accuracy: 0.6587 - val_loss: 0.6721 - val_accuracy: 0.5671\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 712us/step - loss: 0.6352 - accuracy: 0.6654 - val_loss: 0.6704 - val_accuracy: 0.5710\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6339 - accuracy: 0.6683 - val_loss: 0.6696 - val_accuracy: 0.5722\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 747us/step - loss: 0.6334 - accuracy: 0.6663 - val_loss: 0.6695 - val_accuracy: 0.5722\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 679us/step - loss: 0.6315 - accuracy: 0.6706 - val_loss: 0.6673 - val_accuracy: 0.5765\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 803us/step - loss: 0.7279 - accuracy: 0.5330 - val_loss: 0.8120 - val_accuracy: 0.1340\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 645us/step - loss: 0.7008 - accuracy: 0.5362 - val_loss: 0.7430 - val_accuracy: 0.2163\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 752us/step - loss: 0.6967 - accuracy: 0.5422 - val_loss: 0.7246 - val_accuracy: 0.3024\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6941 - accuracy: 0.5434 - val_loss: 0.7214 - val_accuracy: 0.3266\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6921 - accuracy: 0.5502 - val_loss: 0.7182 - val_accuracy: 0.3532\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6887 - accuracy: 0.5534 - val_loss: 0.7157 - val_accuracy: 0.3771\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6858 - accuracy: 0.5600 - val_loss: 0.7134 - val_accuracy: 0.3947\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 719us/step - loss: 0.6841 - accuracy: 0.5641 - val_loss: 0.7101 - val_accuracy: 0.4161\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 784us/step - loss: 0.6813 - accuracy: 0.5709 - val_loss: 0.7087 - val_accuracy: 0.4322\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 709us/step - loss: 0.6784 - accuracy: 0.5771 - val_loss: 0.7059 - val_accuracy: 0.4508\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6763 - accuracy: 0.5817 - val_loss: 0.7041 - val_accuracy: 0.4640\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6747 - accuracy: 0.5829 - val_loss: 0.7026 - val_accuracy: 0.4764\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6727 - accuracy: 0.5905 - val_loss: 0.6985 - val_accuracy: 0.4972\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6704 - accuracy: 0.5957 - val_loss: 0.7002 - val_accuracy: 0.4921\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6701 - accuracy: 0.5943 - val_loss: 0.6972 - val_accuracy: 0.5040\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 943us/step - loss: 0.6694 - accuracy: 0.5980 - val_loss: 0.6958 - val_accuracy: 0.5114\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 952us/step - loss: 0.6654 - accuracy: 0.6068 - val_loss: 0.6925 - val_accuracy: 0.5267\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 789us/step - loss: 0.6625 - accuracy: 0.6146 - val_loss: 0.6941 - val_accuracy: 0.5193\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6628 - accuracy: 0.6094 - val_loss: 0.6927 - val_accuracy: 0.5256\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6615 - accuracy: 0.6132 - val_loss: 0.6871 - val_accuracy: 0.5494\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 653us/step - loss: 0.6600 - accuracy: 0.6169 - val_loss: 0.6861 - val_accuracy: 0.5527\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6586 - accuracy: 0.6185 - val_loss: 0.6868 - val_accuracy: 0.5507\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6563 - accuracy: 0.6240 - val_loss: 0.6848 - val_accuracy: 0.5568\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 741us/step - loss: 0.6558 - accuracy: 0.6294 - val_loss: 0.6853 - val_accuracy: 0.5550\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 688us/step - loss: 0.6538 - accuracy: 0.6290 - val_loss: 0.6839 - val_accuracy: 0.5591\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6519 - accuracy: 0.6344 - val_loss: 0.6794 - val_accuracy: 0.5737\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6516 - accuracy: 0.6339 - val_loss: 0.6809 - val_accuracy: 0.5665\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6471 - accuracy: 0.6430 - val_loss: 0.6775 - val_accuracy: 0.5760\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6497 - accuracy: 0.6352 - val_loss: 0.6759 - val_accuracy: 0.5789\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6461 - accuracy: 0.6442 - val_loss: 0.6730 - val_accuracy: 0.5844\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 698us/step - loss: 0.6445 - accuracy: 0.6477 - val_loss: 0.6740 - val_accuracy: 0.5817\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6426 - accuracy: 0.6515 - val_loss: 0.6723 - val_accuracy: 0.5842\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6412 - accuracy: 0.6542 - val_loss: 0.6710 - val_accuracy: 0.5863\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6409 - accuracy: 0.6506 - val_loss: 0.6694 - val_accuracy: 0.5883\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6388 - accuracy: 0.6543 - val_loss: 0.6699 - val_accuracy: 0.5870\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6379 - accuracy: 0.6561 - val_loss: 0.6674 - val_accuracy: 0.5910\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6358 - accuracy: 0.6568 - val_loss: 0.6624 - val_accuracy: 0.6047\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6352 - accuracy: 0.6578 - val_loss: 0.6615 - val_accuracy: 0.6053\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6342 - accuracy: 0.6610 - val_loss: 0.6599 - val_accuracy: 0.6085\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 681us/step - loss: 0.6320 - accuracy: 0.6627 - val_loss: 0.6601 - val_accuracy: 0.6068\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.6310 - accuracy: 0.6625 - val_loss: 0.6603 - val_accuracy: 0.6054\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6302 - accuracy: 0.6642 - val_loss: 0.6592 - val_accuracy: 0.6064\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.6270 - accuracy: 0.6694 - val_loss: 0.6552 - val_accuracy: 0.6124\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6272 - accuracy: 0.6678 - val_loss: 0.6516 - val_accuracy: 0.6195\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6265 - accuracy: 0.6675 - val_loss: 0.6527 - val_accuracy: 0.6152\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6243 - accuracy: 0.6710 - val_loss: 0.6530 - val_accuracy: 0.6133\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6240 - accuracy: 0.6684 - val_loss: 0.6515 - val_accuracy: 0.6159\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6227 - accuracy: 0.6718 - val_loss: 0.6480 - val_accuracy: 0.6224\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6208 - accuracy: 0.6720 - val_loss: 0.6486 - val_accuracy: 0.6196\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 753us/step - loss: 0.6205 - accuracy: 0.6722 - val_loss: 0.6447 - val_accuracy: 0.6262\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 806us/step - loss: 0.6875 - accuracy: 0.5441 - val_loss: 0.7083 - val_accuracy: 0.4914\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.6862 - accuracy: 0.5509 - val_loss: 0.7084 - val_accuracy: 0.4962\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6833 - accuracy: 0.5534 - val_loss: 0.7075 - val_accuracy: 0.5044\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6805 - accuracy: 0.5630 - val_loss: 0.7063 - val_accuracy: 0.5103\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6789 - accuracy: 0.5654 - val_loss: 0.7031 - val_accuracy: 0.5203\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6766 - accuracy: 0.5680 - val_loss: 0.7002 - val_accuracy: 0.5285\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6759 - accuracy: 0.5714 - val_loss: 0.6989 - val_accuracy: 0.5350\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6753 - accuracy: 0.5720 - val_loss: 0.6966 - val_accuracy: 0.5424\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6725 - accuracy: 0.5804 - val_loss: 0.6947 - val_accuracy: 0.5480\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 730us/step - loss: 0.6699 - accuracy: 0.5871 - val_loss: 0.6941 - val_accuracy: 0.5498\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6700 - accuracy: 0.5876 - val_loss: 0.6947 - val_accuracy: 0.5487\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6670 - accuracy: 0.5918 - val_loss: 0.6934 - val_accuracy: 0.5518\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 726us/step - loss: 0.6664 - accuracy: 0.5940 - val_loss: 0.6891 - val_accuracy: 0.5618\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 760us/step - loss: 0.6656 - accuracy: 0.5952 - val_loss: 0.6877 - val_accuracy: 0.5659\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 755us/step - loss: 0.6628 - accuracy: 0.6012 - val_loss: 0.6865 - val_accuracy: 0.5686\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 733us/step - loss: 0.6613 - accuracy: 0.6029 - val_loss: 0.6863 - val_accuracy: 0.5692\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 718us/step - loss: 0.6609 - accuracy: 0.6045 - val_loss: 0.6851 - val_accuracy: 0.5733\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6608 - accuracy: 0.6041 - val_loss: 0.6839 - val_accuracy: 0.5766\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6569 - accuracy: 0.6137 - val_loss: 0.6819 - val_accuracy: 0.5788\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 901us/step - loss: 0.6586 - accuracy: 0.6109 - val_loss: 0.6808 - val_accuracy: 0.5801\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 818us/step - loss: 0.6562 - accuracy: 0.6116 - val_loss: 0.6811 - val_accuracy: 0.5798\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6550 - accuracy: 0.6162 - val_loss: 0.6796 - val_accuracy: 0.5834\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.6530 - accuracy: 0.6216 - val_loss: 0.6774 - val_accuracy: 0.5868\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6515 - accuracy: 0.6218 - val_loss: 0.6763 - val_accuracy: 0.5892\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 689us/step - loss: 0.6501 - accuracy: 0.6219 - val_loss: 0.6728 - val_accuracy: 0.5966\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6496 - accuracy: 0.6258 - val_loss: 0.6713 - val_accuracy: 0.5998\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 692us/step - loss: 0.6499 - accuracy: 0.6253 - val_loss: 0.6722 - val_accuracy: 0.5986\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6466 - accuracy: 0.6267 - val_loss: 0.6730 - val_accuracy: 0.5970\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 740us/step - loss: 0.6457 - accuracy: 0.6310 - val_loss: 0.6683 - val_accuracy: 0.6056\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.6446 - accuracy: 0.6304 - val_loss: 0.6686 - val_accuracy: 0.6054\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 733us/step - loss: 0.6445 - accuracy: 0.6345 - val_loss: 0.6698 - val_accuracy: 0.6031\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6426 - accuracy: 0.6374 - val_loss: 0.6694 - val_accuracy: 0.6037\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6406 - accuracy: 0.6406 - val_loss: 0.6677 - val_accuracy: 0.6062\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6407 - accuracy: 0.6364 - val_loss: 0.6654 - val_accuracy: 0.6101\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 742us/step - loss: 0.6399 - accuracy: 0.6386 - val_loss: 0.6649 - val_accuracy: 0.6106\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 735us/step - loss: 0.6381 - accuracy: 0.6398 - val_loss: 0.6619 - val_accuracy: 0.6153\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6383 - accuracy: 0.6412 - val_loss: 0.6624 - val_accuracy: 0.6143\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6354 - accuracy: 0.6437 - val_loss: 0.6637 - val_accuracy: 0.6116\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6346 - accuracy: 0.6479 - val_loss: 0.6605 - val_accuracy: 0.6153\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 708us/step - loss: 0.6344 - accuracy: 0.6435 - val_loss: 0.6595 - val_accuracy: 0.6168\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6352 - accuracy: 0.6453 - val_loss: 0.6548 - val_accuracy: 0.6226\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 683us/step - loss: 0.6323 - accuracy: 0.6493 - val_loss: 0.6567 - val_accuracy: 0.6198\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6322 - accuracy: 0.6468 - val_loss: 0.6557 - val_accuracy: 0.6211\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 739us/step - loss: 0.6304 - accuracy: 0.6470 - val_loss: 0.6534 - val_accuracy: 0.6234\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 958us/step - loss: 0.6280 - accuracy: 0.6551 - val_loss: 0.6512 - val_accuracy: 0.6248\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6281 - accuracy: 0.6534 - val_loss: 0.6518 - val_accuracy: 0.6234\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 743us/step - loss: 0.6273 - accuracy: 0.6528 - val_loss: 0.6498 - val_accuracy: 0.6250\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 825us/step - loss: 0.6258 - accuracy: 0.6536 - val_loss: 0.6490 - val_accuracy: 0.6252\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 806us/step - loss: 0.6253 - accuracy: 0.6568 - val_loss: 0.6488 - val_accuracy: 0.6253\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 749us/step - loss: 0.6231 - accuracy: 0.6570 - val_loss: 0.6507 - val_accuracy: 0.6217\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.7017 - accuracy: 0.5231 - val_loss: 0.6456 - val_accuracy: 0.7803\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6812 - accuracy: 0.5531 - val_loss: 0.6832 - val_accuracy: 0.5759\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 725us/step - loss: 0.6750 - accuracy: 0.5624 - val_loss: 0.6906 - val_accuracy: 0.5398\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 736us/step - loss: 0.6743 - accuracy: 0.5609 - val_loss: 0.6911 - val_accuracy: 0.5390\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 681us/step - loss: 0.6718 - accuracy: 0.5692 - val_loss: 0.6895 - val_accuracy: 0.5477\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6688 - accuracy: 0.5761 - val_loss: 0.6889 - val_accuracy: 0.5515\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 748us/step - loss: 0.6662 - accuracy: 0.5825 - val_loss: 0.6834 - val_accuracy: 0.5729\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6650 - accuracy: 0.5856 - val_loss: 0.6841 - val_accuracy: 0.5681\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 706us/step - loss: 0.6623 - accuracy: 0.5928 - val_loss: 0.6817 - val_accuracy: 0.5780\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6593 - accuracy: 0.5968 - val_loss: 0.6789 - val_accuracy: 0.5881\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 684us/step - loss: 0.6569 - accuracy: 0.6030 - val_loss: 0.6804 - val_accuracy: 0.5804\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6551 - accuracy: 0.6044 - val_loss: 0.6771 - val_accuracy: 0.5913\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 780us/step - loss: 0.6535 - accuracy: 0.6114 - val_loss: 0.6756 - val_accuracy: 0.5936\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 721us/step - loss: 0.6510 - accuracy: 0.6157 - val_loss: 0.6735 - val_accuracy: 0.6010\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 750us/step - loss: 0.6491 - accuracy: 0.6204 - val_loss: 0.6734 - val_accuracy: 0.5981\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 738us/step - loss: 0.6478 - accuracy: 0.6174 - val_loss: 0.6703 - val_accuracy: 0.6077\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 815us/step - loss: 0.6466 - accuracy: 0.6234 - val_loss: 0.6677 - val_accuracy: 0.6146\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 878us/step - loss: 0.6440 - accuracy: 0.6287 - val_loss: 0.6664 - val_accuracy: 0.6167\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 946us/step - loss: 0.6435 - accuracy: 0.6292 - val_loss: 0.6662 - val_accuracy: 0.6156\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 996us/step - loss: 0.6411 - accuracy: 0.6299 - val_loss: 0.6637 - val_accuracy: 0.6226\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6405 - accuracy: 0.6296 - val_loss: 0.6657 - val_accuracy: 0.6137\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 990us/step - loss: 0.6385 - accuracy: 0.6354 - val_loss: 0.6597 - val_accuracy: 0.6295\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6353 - accuracy: 0.6371 - val_loss: 0.6555 - val_accuracy: 0.6360\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 899us/step - loss: 0.6350 - accuracy: 0.6402 - val_loss: 0.6594 - val_accuracy: 0.6269\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 893us/step - loss: 0.6347 - accuracy: 0.6392 - val_loss: 0.6584 - val_accuracy: 0.6266\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 815us/step - loss: 0.6309 - accuracy: 0.6462 - val_loss: 0.6548 - val_accuracy: 0.6328\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 900us/step - loss: 0.6296 - accuracy: 0.6437 - val_loss: 0.6530 - val_accuracy: 0.6336\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6277 - accuracy: 0.6490 - val_loss: 0.6509 - val_accuracy: 0.6360\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 826us/step - loss: 0.6253 - accuracy: 0.6523 - val_loss: 0.6509 - val_accuracy: 0.6346\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6252 - accuracy: 0.6524 - val_loss: 0.6488 - val_accuracy: 0.6374\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6247 - accuracy: 0.6543 - val_loss: 0.6475 - val_accuracy: 0.6396\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6219 - accuracy: 0.6580 - val_loss: 0.6442 - val_accuracy: 0.6445\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6209 - accuracy: 0.6568 - val_loss: 0.6444 - val_accuracy: 0.6424\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6209 - accuracy: 0.6553 - val_loss: 0.6444 - val_accuracy: 0.6413\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 816us/step - loss: 0.6176 - accuracy: 0.6613 - val_loss: 0.6453 - val_accuracy: 0.6391\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 953us/step - loss: 0.6172 - accuracy: 0.6604 - val_loss: 0.6444 - val_accuracy: 0.6397\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 909us/step - loss: 0.6155 - accuracy: 0.6605 - val_loss: 0.6401 - val_accuracy: 0.6458\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6156 - accuracy: 0.6608 - val_loss: 0.6425 - val_accuracy: 0.6396\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6137 - accuracy: 0.6643 - val_loss: 0.6375 - val_accuracy: 0.6474\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 833us/step - loss: 0.6121 - accuracy: 0.6654 - val_loss: 0.6352 - val_accuracy: 0.6513\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6114 - accuracy: 0.6671 - val_loss: 0.6360 - val_accuracy: 0.6497\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6101 - accuracy: 0.6681 - val_loss: 0.6335 - val_accuracy: 0.6503\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6097 - accuracy: 0.6683 - val_loss: 0.6337 - val_accuracy: 0.6499\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6073 - accuracy: 0.6714 - val_loss: 0.6347 - val_accuracy: 0.6479\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6073 - accuracy: 0.6736 - val_loss: 0.6321 - val_accuracy: 0.6508\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 869us/step - loss: 0.6057 - accuracy: 0.6735 - val_loss: 0.6263 - val_accuracy: 0.6581\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 828us/step - loss: 0.6048 - accuracy: 0.6719 - val_loss: 0.6277 - val_accuracy: 0.6551\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6041 - accuracy: 0.6735 - val_loss: 0.6307 - val_accuracy: 0.6502\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6025 - accuracy: 0.6772 - val_loss: 0.6277 - val_accuracy: 0.6537\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6021 - accuracy: 0.6748 - val_loss: 0.6244 - val_accuracy: 0.6573\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 928us/step - loss: 0.7555 - accuracy: 0.5069 - val_loss: 0.8664 - val_accuracy: 0.1197\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.7253 - accuracy: 0.4831 - val_loss: 0.7852 - val_accuracy: 0.1556\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 895us/step - loss: 0.7167 - accuracy: 0.4796 - val_loss: 0.7552 - val_accuracy: 0.2120\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 878us/step - loss: 0.7126 - accuracy: 0.4868 - val_loss: 0.7426 - val_accuracy: 0.2421\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.7073 - accuracy: 0.4911 - val_loss: 0.7351 - val_accuracy: 0.2629\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 865us/step - loss: 0.7058 - accuracy: 0.4970 - val_loss: 0.7288 - val_accuracy: 0.2961\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.7028 - accuracy: 0.5025 - val_loss: 0.7258 - val_accuracy: 0.3163\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.7012 - accuracy: 0.5072 - val_loss: 0.7225 - val_accuracy: 0.3396\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6956 - accuracy: 0.5265 - val_loss: 0.7193 - val_accuracy: 0.3698\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6939 - accuracy: 0.5303 - val_loss: 0.7171 - val_accuracy: 0.3947\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 842us/step - loss: 0.6904 - accuracy: 0.5413 - val_loss: 0.7149 - val_accuracy: 0.4172\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 877us/step - loss: 0.6880 - accuracy: 0.5489 - val_loss: 0.7120 - val_accuracy: 0.4354\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6849 - accuracy: 0.5592 - val_loss: 0.7088 - val_accuracy: 0.4565\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6841 - accuracy: 0.5602 - val_loss: 0.7082 - val_accuracy: 0.4630\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6815 - accuracy: 0.5690 - val_loss: 0.7057 - val_accuracy: 0.4778\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6789 - accuracy: 0.5769 - val_loss: 0.7027 - val_accuracy: 0.4940\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6764 - accuracy: 0.5840 - val_loss: 0.7017 - val_accuracy: 0.5001\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6762 - accuracy: 0.5844 - val_loss: 0.7000 - val_accuracy: 0.5123\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 920us/step - loss: 0.6714 - accuracy: 0.5953 - val_loss: 0.6961 - val_accuracy: 0.5308\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 790us/step - loss: 0.6714 - accuracy: 0.5992 - val_loss: 0.6949 - val_accuracy: 0.5358\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6694 - accuracy: 0.6079 - val_loss: 0.6940 - val_accuracy: 0.5379\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6673 - accuracy: 0.6055 - val_loss: 0.6901 - val_accuracy: 0.5484\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 877us/step - loss: 0.6671 - accuracy: 0.6086 - val_loss: 0.6897 - val_accuracy: 0.5509\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.6630 - accuracy: 0.6168 - val_loss: 0.6871 - val_accuracy: 0.5563\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6617 - accuracy: 0.6210 - val_loss: 0.6860 - val_accuracy: 0.5590\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6606 - accuracy: 0.6240 - val_loss: 0.6831 - val_accuracy: 0.5649\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6583 - accuracy: 0.6283 - val_loss: 0.6826 - val_accuracy: 0.5641\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6582 - accuracy: 0.6273 - val_loss: 0.6810 - val_accuracy: 0.5674\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6566 - accuracy: 0.6292 - val_loss: 0.6771 - val_accuracy: 0.5765\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6534 - accuracy: 0.6380 - val_loss: 0.6771 - val_accuracy: 0.5755\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6533 - accuracy: 0.6397 - val_loss: 0.6750 - val_accuracy: 0.5790\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 861us/step - loss: 0.6505 - accuracy: 0.6410 - val_loss: 0.6731 - val_accuracy: 0.5817\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6482 - accuracy: 0.6417 - val_loss: 0.6718 - val_accuracy: 0.5834\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6476 - accuracy: 0.6471 - val_loss: 0.6711 - val_accuracy: 0.5844\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 858us/step - loss: 0.6460 - accuracy: 0.6503 - val_loss: 0.6692 - val_accuracy: 0.5863\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 827us/step - loss: 0.6452 - accuracy: 0.6466 - val_loss: 0.6686 - val_accuracy: 0.5865\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 834us/step - loss: 0.6438 - accuracy: 0.6530 - val_loss: 0.6668 - val_accuracy: 0.5903\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 914us/step - loss: 0.6424 - accuracy: 0.6524 - val_loss: 0.6649 - val_accuracy: 0.5935\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6402 - accuracy: 0.6538 - val_loss: 0.6631 - val_accuracy: 0.5957\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6403 - accuracy: 0.6538 - val_loss: 0.6643 - val_accuracy: 0.5935\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6373 - accuracy: 0.6597 - val_loss: 0.6645 - val_accuracy: 0.5925\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 984us/step - loss: 0.6369 - accuracy: 0.6565 - val_loss: 0.6614 - val_accuracy: 0.5964\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 960us/step - loss: 0.6346 - accuracy: 0.6609 - val_loss: 0.6586 - val_accuracy: 0.5988\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6341 - accuracy: 0.6630 - val_loss: 0.6590 - val_accuracy: 0.5980\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.6324 - accuracy: 0.6641 - val_loss: 0.6570 - val_accuracy: 0.6000\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 858us/step - loss: 0.6310 - accuracy: 0.6613 - val_loss: 0.6570 - val_accuracy: 0.5994\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6305 - accuracy: 0.6660 - val_loss: 0.6527 - val_accuracy: 0.6043\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6282 - accuracy: 0.6696 - val_loss: 0.6541 - val_accuracy: 0.6008\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.6284 - accuracy: 0.6660 - val_loss: 0.6538 - val_accuracy: 0.6013\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 862us/step - loss: 0.6271 - accuracy: 0.6708 - val_loss: 0.6513 - val_accuracy: 0.6049\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 978us/step - loss: 0.6877 - accuracy: 0.5598 - val_loss: 0.6974 - val_accuracy: 0.4954\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 850us/step - loss: 0.6832 - accuracy: 0.5696 - val_loss: 0.7072 - val_accuracy: 0.4470\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 840us/step - loss: 0.6792 - accuracy: 0.5810 - val_loss: 0.7057 - val_accuracy: 0.4563\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6755 - accuracy: 0.5860 - val_loss: 0.7025 - val_accuracy: 0.4799\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6752 - accuracy: 0.5877 - val_loss: 0.6998 - val_accuracy: 0.5033\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 872us/step - loss: 0.6708 - accuracy: 0.5998 - val_loss: 0.6982 - val_accuracy: 0.5183\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 922us/step - loss: 0.6690 - accuracy: 0.6077 - val_loss: 0.6962 - val_accuracy: 0.5269\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 863us/step - loss: 0.6656 - accuracy: 0.6086 - val_loss: 0.6952 - val_accuracy: 0.5270\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 869us/step - loss: 0.6623 - accuracy: 0.6223 - val_loss: 0.6910 - val_accuracy: 0.5395\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6608 - accuracy: 0.6202 - val_loss: 0.6880 - val_accuracy: 0.5517\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 848us/step - loss: 0.6583 - accuracy: 0.6274 - val_loss: 0.6862 - val_accuracy: 0.5594\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 901us/step - loss: 0.6568 - accuracy: 0.6297 - val_loss: 0.6835 - val_accuracy: 0.5681\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 849us/step - loss: 0.6534 - accuracy: 0.6377 - val_loss: 0.6848 - val_accuracy: 0.5650\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 952us/step - loss: 0.6520 - accuracy: 0.6419 - val_loss: 0.6815 - val_accuracy: 0.5760\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.6519 - accuracy: 0.6430 - val_loss: 0.6803 - val_accuracy: 0.5774\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 887us/step - loss: 0.6493 - accuracy: 0.6456 - val_loss: 0.6763 - val_accuracy: 0.5875\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 799us/step - loss: 0.6464 - accuracy: 0.6512 - val_loss: 0.6759 - val_accuracy: 0.5865\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 844us/step - loss: 0.6446 - accuracy: 0.6489 - val_loss: 0.6750 - val_accuracy: 0.5894\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 924us/step - loss: 0.6442 - accuracy: 0.6541 - val_loss: 0.6744 - val_accuracy: 0.5907\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 830us/step - loss: 0.6428 - accuracy: 0.6545 - val_loss: 0.6734 - val_accuracy: 0.5932\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 888us/step - loss: 0.6413 - accuracy: 0.6548 - val_loss: 0.6695 - val_accuracy: 0.6004\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 857us/step - loss: 0.6400 - accuracy: 0.6540 - val_loss: 0.6724 - val_accuracy: 0.5937\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 875us/step - loss: 0.6365 - accuracy: 0.6619 - val_loss: 0.6660 - val_accuracy: 0.6074\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6372 - accuracy: 0.6573 - val_loss: 0.6656 - val_accuracy: 0.6090\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6355 - accuracy: 0.6614 - val_loss: 0.6619 - val_accuracy: 0.6157\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6342 - accuracy: 0.6601 - val_loss: 0.6651 - val_accuracy: 0.6095\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 921us/step - loss: 0.6325 - accuracy: 0.6636 - val_loss: 0.6618 - val_accuracy: 0.6143\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 841us/step - loss: 0.6312 - accuracy: 0.6655 - val_loss: 0.6606 - val_accuracy: 0.6152\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 876us/step - loss: 0.6305 - accuracy: 0.6685 - val_loss: 0.6580 - val_accuracy: 0.6189\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 848us/step - loss: 0.6278 - accuracy: 0.6702 - val_loss: 0.6578 - val_accuracy: 0.6195\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 853us/step - loss: 0.6270 - accuracy: 0.6723 - val_loss: 0.6548 - val_accuracy: 0.6240\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 933us/step - loss: 0.6257 - accuracy: 0.6730 - val_loss: 0.6536 - val_accuracy: 0.6249\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 890us/step - loss: 0.6257 - accuracy: 0.6664 - val_loss: 0.6532 - val_accuracy: 0.6244\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 852us/step - loss: 0.6221 - accuracy: 0.6740 - val_loss: 0.6511 - val_accuracy: 0.6277\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 809us/step - loss: 0.6227 - accuracy: 0.6754 - val_loss: 0.6513 - val_accuracy: 0.6259\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 860us/step - loss: 0.6201 - accuracy: 0.6760 - val_loss: 0.6495 - val_accuracy: 0.6283\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 848us/step - loss: 0.6205 - accuracy: 0.6761 - val_loss: 0.6486 - val_accuracy: 0.6290\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 809us/step - loss: 0.6187 - accuracy: 0.6762 - val_loss: 0.6538 - val_accuracy: 0.6189\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 807us/step - loss: 0.6180 - accuracy: 0.6799 - val_loss: 0.6446 - val_accuracy: 0.6333\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 789us/step - loss: 0.6172 - accuracy: 0.6796 - val_loss: 0.6443 - val_accuracy: 0.6323\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 831us/step - loss: 0.6149 - accuracy: 0.6804 - val_loss: 0.6454 - val_accuracy: 0.6288\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 773us/step - loss: 0.6147 - accuracy: 0.6806 - val_loss: 0.6425 - val_accuracy: 0.6341\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 783us/step - loss: 0.6125 - accuracy: 0.6854 - val_loss: 0.6412 - val_accuracy: 0.6354\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6111 - accuracy: 0.6843 - val_loss: 0.6397 - val_accuracy: 0.6367\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.6098 - accuracy: 0.6839 - val_loss: 0.6400 - val_accuracy: 0.6345\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6088 - accuracy: 0.6862 - val_loss: 0.6377 - val_accuracy: 0.6380\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6073 - accuracy: 0.6897 - val_loss: 0.6357 - val_accuracy: 0.6409\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 778us/step - loss: 0.6071 - accuracy: 0.6875 - val_loss: 0.6324 - val_accuracy: 0.6455\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 769us/step - loss: 0.6057 - accuracy: 0.6903 - val_loss: 0.6376 - val_accuracy: 0.6343\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 724us/step - loss: 0.6036 - accuracy: 0.6893 - val_loss: 0.6322 - val_accuracy: 0.6429\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 837us/step - loss: 0.7267 - accuracy: 0.4930 - val_loss: 0.8052 - val_accuracy: 0.1177\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 855us/step - loss: 0.7164 - accuracy: 0.4922 - val_loss: 0.7735 - val_accuracy: 0.1253\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 705us/step - loss: 0.7137 - accuracy: 0.4906 - val_loss: 0.7576 - val_accuracy: 0.1459\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 800us/step - loss: 0.7099 - accuracy: 0.4948 - val_loss: 0.7509 - val_accuracy: 0.1659\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.7059 - accuracy: 0.5024 - val_loss: 0.7481 - val_accuracy: 0.1810\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 772us/step - loss: 0.7042 - accuracy: 0.5087 - val_loss: 0.7438 - val_accuracy: 0.1975\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.7031 - accuracy: 0.5115 - val_loss: 0.7391 - val_accuracy: 0.2232\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.7001 - accuracy: 0.5183 - val_loss: 0.7376 - val_accuracy: 0.2345\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 839us/step - loss: 0.6972 - accuracy: 0.5237 - val_loss: 0.7367 - val_accuracy: 0.2456\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6949 - accuracy: 0.5275 - val_loss: 0.7333 - val_accuracy: 0.2768\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6926 - accuracy: 0.5345 - val_loss: 0.7304 - val_accuracy: 0.2936\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 770us/step - loss: 0.6906 - accuracy: 0.5416 - val_loss: 0.7280 - val_accuracy: 0.3065\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 981us/step - loss: 0.6883 - accuracy: 0.5472 - val_loss: 0.7261 - val_accuracy: 0.3176\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 968us/step - loss: 0.6869 - accuracy: 0.5519 - val_loss: 0.7239 - val_accuracy: 0.3302\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 696us/step - loss: 0.6851 - accuracy: 0.5577 - val_loss: 0.7231 - val_accuracy: 0.3396\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6837 - accuracy: 0.5612 - val_loss: 0.7226 - val_accuracy: 0.3511\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 782us/step - loss: 0.6813 - accuracy: 0.5648 - val_loss: 0.7209 - val_accuracy: 0.3696\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6818 - accuracy: 0.5718 - val_loss: 0.7191 - val_accuracy: 0.3886\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 809us/step - loss: 0.6803 - accuracy: 0.5699 - val_loss: 0.7177 - val_accuracy: 0.4051\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6778 - accuracy: 0.5783 - val_loss: 0.7161 - val_accuracy: 0.4167\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6764 - accuracy: 0.5850 - val_loss: 0.7156 - val_accuracy: 0.4220\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 851us/step - loss: 0.6752 - accuracy: 0.5854 - val_loss: 0.7152 - val_accuracy: 0.4285\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 777us/step - loss: 0.6741 - accuracy: 0.5945 - val_loss: 0.7153 - val_accuracy: 0.4317\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 868us/step - loss: 0.6726 - accuracy: 0.5926 - val_loss: 0.7130 - val_accuracy: 0.4429\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6721 - accuracy: 0.5972 - val_loss: 0.7122 - val_accuracy: 0.4465\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 879us/step - loss: 0.6705 - accuracy: 0.6010 - val_loss: 0.7098 - val_accuracy: 0.4536\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6697 - accuracy: 0.6046 - val_loss: 0.7082 - val_accuracy: 0.4611\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 753us/step - loss: 0.6690 - accuracy: 0.6046 - val_loss: 0.7067 - val_accuracy: 0.4650\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6666 - accuracy: 0.6115 - val_loss: 0.7067 - val_accuracy: 0.4681\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6667 - accuracy: 0.6106 - val_loss: 0.7045 - val_accuracy: 0.4736\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6658 - accuracy: 0.6153 - val_loss: 0.7033 - val_accuracy: 0.4804\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6646 - accuracy: 0.6160 - val_loss: 0.7018 - val_accuracy: 0.4869\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 787us/step - loss: 0.6626 - accuracy: 0.6220 - val_loss: 0.7010 - val_accuracy: 0.4913\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 702us/step - loss: 0.6617 - accuracy: 0.6240 - val_loss: 0.6985 - val_accuracy: 0.5007\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6602 - accuracy: 0.6287 - val_loss: 0.6983 - val_accuracy: 0.5029\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6596 - accuracy: 0.6283 - val_loss: 0.6969 - val_accuracy: 0.5078\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 846us/step - loss: 0.6580 - accuracy: 0.6283 - val_loss: 0.6963 - val_accuracy: 0.5110\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 707us/step - loss: 0.6579 - accuracy: 0.6284 - val_loss: 0.6953 - val_accuracy: 0.5160\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 829us/step - loss: 0.6565 - accuracy: 0.6320 - val_loss: 0.6929 - val_accuracy: 0.5262\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.6549 - accuracy: 0.6361 - val_loss: 0.6933 - val_accuracy: 0.5247\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 704us/step - loss: 0.6540 - accuracy: 0.6352 - val_loss: 0.6920 - val_accuracy: 0.5306\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 802us/step - loss: 0.6517 - accuracy: 0.6442 - val_loss: 0.6895 - val_accuracy: 0.5411\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 765us/step - loss: 0.6509 - accuracy: 0.6392 - val_loss: 0.6897 - val_accuracy: 0.5402\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 800us/step - loss: 0.6501 - accuracy: 0.6442 - val_loss: 0.6869 - val_accuracy: 0.5496\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 694us/step - loss: 0.6498 - accuracy: 0.6438 - val_loss: 0.6855 - val_accuracy: 0.5548\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6476 - accuracy: 0.6472 - val_loss: 0.6839 - val_accuracy: 0.5587\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6477 - accuracy: 0.6478 - val_loss: 0.6837 - val_accuracy: 0.5597\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 882us/step - loss: 0.6474 - accuracy: 0.6482 - val_loss: 0.6820 - val_accuracy: 0.5639\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 691us/step - loss: 0.6460 - accuracy: 0.6476 - val_loss: 0.6787 - val_accuracy: 0.5717\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 767us/step - loss: 0.6444 - accuracy: 0.6502 - val_loss: 0.6783 - val_accuracy: 0.5726\n",
      "Epoch 1/50\n",
      "836/836 [==============================] - 1s 938us/step - loss: 0.7305 - accuracy: 0.4916 - val_loss: 0.7385 - val_accuracy: 0.3097\n",
      "Epoch 2/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.7304 - accuracy: 0.4919 - val_loss: 0.7364 - val_accuracy: 0.3108\n",
      "Epoch 3/50\n",
      "836/836 [==============================] - 1s 695us/step - loss: 0.7256 - accuracy: 0.4953 - val_loss: 0.7352 - val_accuracy: 0.3263\n",
      "Epoch 4/50\n",
      "836/836 [==============================] - 1s 812us/step - loss: 0.7182 - accuracy: 0.5048 - val_loss: 0.7301 - val_accuracy: 0.3576\n",
      "Epoch 5/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.7157 - accuracy: 0.5067 - val_loss: 0.7228 - val_accuracy: 0.3781\n",
      "Epoch 6/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.7106 - accuracy: 0.5158 - val_loss: 0.7209 - val_accuracy: 0.3835\n",
      "Epoch 7/50\n",
      "836/836 [==============================] - 1s 763us/step - loss: 0.7064 - accuracy: 0.5252 - val_loss: 0.7177 - val_accuracy: 0.4198\n",
      "Epoch 8/50\n",
      "836/836 [==============================] - 1s 790us/step - loss: 0.7002 - accuracy: 0.5342 - val_loss: 0.7112 - val_accuracy: 0.4466\n",
      "Epoch 9/50\n",
      "836/836 [==============================] - 1s 751us/step - loss: 0.6983 - accuracy: 0.5342 - val_loss: 0.7087 - val_accuracy: 0.4545\n",
      "Epoch 10/50\n",
      "836/836 [==============================] - 1s 791us/step - loss: 0.6913 - accuracy: 0.5508 - val_loss: 0.7096 - val_accuracy: 0.4552\n",
      "Epoch 11/50\n",
      "836/836 [==============================] - 1s 758us/step - loss: 0.6899 - accuracy: 0.5507 - val_loss: 0.7064 - val_accuracy: 0.4598\n",
      "Epoch 12/50\n",
      "836/836 [==============================] - 1s 801us/step - loss: 0.6857 - accuracy: 0.5597 - val_loss: 0.7026 - val_accuracy: 0.4810\n",
      "Epoch 13/50\n",
      "836/836 [==============================] - 1s 759us/step - loss: 0.6841 - accuracy: 0.5629 - val_loss: 0.7010 - val_accuracy: 0.5030\n",
      "Epoch 14/50\n",
      "836/836 [==============================] - 1s 796us/step - loss: 0.6810 - accuracy: 0.5677 - val_loss: 0.6970 - val_accuracy: 0.5189\n",
      "Epoch 15/50\n",
      "836/836 [==============================] - 1s 697us/step - loss: 0.6810 - accuracy: 0.5679 - val_loss: 0.6939 - val_accuracy: 0.5328\n",
      "Epoch 16/50\n",
      "836/836 [==============================] - 1s 856us/step - loss: 0.6757 - accuracy: 0.5821 - val_loss: 0.6946 - val_accuracy: 0.5307\n",
      "Epoch 17/50\n",
      "836/836 [==============================] - 1s 722us/step - loss: 0.6716 - accuracy: 0.5883 - val_loss: 0.6899 - val_accuracy: 0.5435\n",
      "Epoch 18/50\n",
      "836/836 [==============================] - 1s 843us/step - loss: 0.6724 - accuracy: 0.5827 - val_loss: 0.6878 - val_accuracy: 0.5477\n",
      "Epoch 19/50\n",
      "836/836 [==============================] - 1s 802us/step - loss: 0.6681 - accuracy: 0.5935 - val_loss: 0.6859 - val_accuracy: 0.5532\n",
      "Epoch 20/50\n",
      "836/836 [==============================] - 1s 788us/step - loss: 0.6666 - accuracy: 0.6009 - val_loss: 0.6846 - val_accuracy: 0.5544\n",
      "Epoch 21/50\n",
      "836/836 [==============================] - 1s 761us/step - loss: 0.6651 - accuracy: 0.6006 - val_loss: 0.6848 - val_accuracy: 0.5536\n",
      "Epoch 22/50\n",
      "836/836 [==============================] - 1s 704us/step - loss: 0.6618 - accuracy: 0.6047 - val_loss: 0.6801 - val_accuracy: 0.5647\n",
      "Epoch 23/50\n",
      "836/836 [==============================] - 1s 1ms/step - loss: 0.6621 - accuracy: 0.6053 - val_loss: 0.6784 - val_accuracy: 0.5686\n",
      "Epoch 24/50\n",
      "836/836 [==============================] - 1s 847us/step - loss: 0.6591 - accuracy: 0.6121 - val_loss: 0.6765 - val_accuracy: 0.5738\n",
      "Epoch 25/50\n",
      "836/836 [==============================] - 1s 886us/step - loss: 0.6560 - accuracy: 0.6164 - val_loss: 0.6771 - val_accuracy: 0.5714\n",
      "Epoch 26/50\n",
      "836/836 [==============================] - 1s 797us/step - loss: 0.6540 - accuracy: 0.6238 - val_loss: 0.6748 - val_accuracy: 0.5747\n",
      "Epoch 27/50\n",
      "836/836 [==============================] - 1s 776us/step - loss: 0.6535 - accuracy: 0.6185 - val_loss: 0.6745 - val_accuracy: 0.5736\n",
      "Epoch 28/50\n",
      "836/836 [==============================] - 1s 869us/step - loss: 0.6525 - accuracy: 0.6234 - val_loss: 0.6725 - val_accuracy: 0.5770\n",
      "Epoch 29/50\n",
      "836/836 [==============================] - 1s 699us/step - loss: 0.6497 - accuracy: 0.6314 - val_loss: 0.6689 - val_accuracy: 0.5838\n",
      "Epoch 30/50\n",
      "836/836 [==============================] - 1s 775us/step - loss: 0.6474 - accuracy: 0.6338 - val_loss: 0.6664 - val_accuracy: 0.5886\n",
      "Epoch 31/50\n",
      "836/836 [==============================] - 1s 754us/step - loss: 0.6456 - accuracy: 0.6348 - val_loss: 0.6668 - val_accuracy: 0.5871\n",
      "Epoch 32/50\n",
      "836/836 [==============================] - 1s 717us/step - loss: 0.6437 - accuracy: 0.6370 - val_loss: 0.6643 - val_accuracy: 0.5896\n",
      "Epoch 33/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6439 - accuracy: 0.6390 - val_loss: 0.6615 - val_accuracy: 0.5934\n",
      "Epoch 34/50\n",
      "836/836 [==============================] - 1s 789us/step - loss: 0.6400 - accuracy: 0.6436 - val_loss: 0.6619 - val_accuracy: 0.5919\n",
      "Epoch 35/50\n",
      "836/836 [==============================] - 1s 796us/step - loss: 0.6387 - accuracy: 0.6459 - val_loss: 0.6610 - val_accuracy: 0.5913\n",
      "Epoch 36/50\n",
      "836/836 [==============================] - 1s 762us/step - loss: 0.6394 - accuracy: 0.6446 - val_loss: 0.6573 - val_accuracy: 0.5985\n",
      "Epoch 37/50\n",
      "836/836 [==============================] - 1s 786us/step - loss: 0.6356 - accuracy: 0.6513 - val_loss: 0.6546 - val_accuracy: 0.6019\n",
      "Epoch 38/50\n",
      "836/836 [==============================] - 1s 845us/step - loss: 0.6350 - accuracy: 0.6483 - val_loss: 0.6533 - val_accuracy: 0.6033\n",
      "Epoch 39/50\n",
      "836/836 [==============================] - 1s 793us/step - loss: 0.6328 - accuracy: 0.6562 - val_loss: 0.6529 - val_accuracy: 0.6012\n",
      "Epoch 40/50\n",
      "836/836 [==============================] - 1s 766us/step - loss: 0.6313 - accuracy: 0.6539 - val_loss: 0.6500 - val_accuracy: 0.6059\n",
      "Epoch 41/50\n",
      "836/836 [==============================] - 1s 785us/step - loss: 0.6308 - accuracy: 0.6554 - val_loss: 0.6553 - val_accuracy: 0.5947\n",
      "Epoch 42/50\n",
      "836/836 [==============================] - 1s 757us/step - loss: 0.6286 - accuracy: 0.6603 - val_loss: 0.6518 - val_accuracy: 0.6005\n",
      "Epoch 43/50\n",
      "836/836 [==============================] - 1s 774us/step - loss: 0.6279 - accuracy: 0.6585 - val_loss: 0.6497 - val_accuracy: 0.6033\n",
      "Epoch 44/50\n",
      "836/836 [==============================] - 1s 797us/step - loss: 0.6247 - accuracy: 0.6645 - val_loss: 0.6513 - val_accuracy: 0.5991\n",
      "Epoch 45/50\n",
      "836/836 [==============================] - 1s 721us/step - loss: 0.6249 - accuracy: 0.6661 - val_loss: 0.6471 - val_accuracy: 0.6079\n",
      "Epoch 46/50\n",
      "836/836 [==============================] - 1s 764us/step - loss: 0.6230 - accuracy: 0.6674 - val_loss: 0.6449 - val_accuracy: 0.6107\n",
      "Epoch 47/50\n",
      "836/836 [==============================] - 1s 873us/step - loss: 0.6224 - accuracy: 0.6667 - val_loss: 0.6422 - val_accuracy: 0.6143\n",
      "Epoch 48/50\n",
      "836/836 [==============================] - 1s 792us/step - loss: 0.6202 - accuracy: 0.6656 - val_loss: 0.6445 - val_accuracy: 0.6099\n",
      "Epoch 49/50\n",
      "836/836 [==============================] - 1s 768us/step - loss: 0.6192 - accuracy: 0.6685 - val_loss: 0.6400 - val_accuracy: 0.6156\n",
      "Epoch 50/50\n",
      "836/836 [==============================] - 1s 924us/step - loss: 0.6182 - accuracy: 0.6704 - val_loss: 0.6380 - val_accuracy: 0.6185\n",
      "\n",
      "Training model with sample_size_ratio=0.25, target_eps=0.5...\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 5.05 iterated over 20900 steps satisfies differential privacy with eps = 0.337 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 2.5749999999999997 iterated over 20900 steps satisfies differential privacy with eps = 0.684 and delta = 1e-05.\n",
      "The optimal RDP order is 35.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 3.8125 iterated over 20900 steps satisfies differential privacy with eps = 0.449 and delta = 1e-05.\n",
      "The optimal RDP order is 53.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 3.1937499999999996 iterated over 20900 steps satisfies differential privacy with eps = 0.542 and delta = 1e-05.\n",
      "The optimal RDP order is 44.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 3.503125 iterated over 20900 steps satisfies differential privacy with eps = 0.491 and delta = 1e-05.\n",
      "The optimal RDP order is 48.0.\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 978us/step - loss: 0.7200 - accuracy: 0.5021 - val_loss: 0.8364 - val_accuracy: 0.1184\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 991us/step - loss: 0.7115 - accuracy: 0.4957 - val_loss: 0.7952 - val_accuracy: 0.1251\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7043 - accuracy: 0.5003 - val_loss: 0.7690 - val_accuracy: 0.1414\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 796us/step - loss: 0.7020 - accuracy: 0.4975 - val_loss: 0.7517 - val_accuracy: 0.1776\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 923us/step - loss: 0.6988 - accuracy: 0.5013 - val_loss: 0.7391 - val_accuracy: 0.2310\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 824us/step - loss: 0.6974 - accuracy: 0.5039 - val_loss: 0.7300 - val_accuracy: 0.2673\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5117 - val_loss: 0.7230 - val_accuracy: 0.3228\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5224 - val_loss: 0.7177 - val_accuracy: 0.3622\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6920 - accuracy: 0.5261 - val_loss: 0.7136 - val_accuracy: 0.3942\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5267 - val_loss: 0.7098 - val_accuracy: 0.4238\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 821us/step - loss: 0.6887 - accuracy: 0.5422 - val_loss: 0.7067 - val_accuracy: 0.4406\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 823us/step - loss: 0.6891 - accuracy: 0.5413 - val_loss: 0.7043 - val_accuracy: 0.4538\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5475 - val_loss: 0.7024 - val_accuracy: 0.4705\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6847 - accuracy: 0.5478 - val_loss: 0.7006 - val_accuracy: 0.4828\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6848 - accuracy: 0.5522 - val_loss: 0.6995 - val_accuracy: 0.4904\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 864us/step - loss: 0.6836 - accuracy: 0.5583 - val_loss: 0.6978 - val_accuracy: 0.5006\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6818 - accuracy: 0.5612 - val_loss: 0.6962 - val_accuracy: 0.5133\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 967us/step - loss: 0.6792 - accuracy: 0.5709 - val_loss: 0.6953 - val_accuracy: 0.5197\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 784us/step - loss: 0.6793 - accuracy: 0.5707 - val_loss: 0.6941 - val_accuracy: 0.5248\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 799us/step - loss: 0.6777 - accuracy: 0.5767 - val_loss: 0.6925 - val_accuracy: 0.5300\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5766 - val_loss: 0.6915 - val_accuracy: 0.5347\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.6767 - accuracy: 0.5789 - val_loss: 0.6903 - val_accuracy: 0.5382\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 966us/step - loss: 0.6759 - accuracy: 0.5802 - val_loss: 0.6903 - val_accuracy: 0.5379\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5825 - val_loss: 0.6892 - val_accuracy: 0.5412\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6736 - accuracy: 0.5972 - val_loss: 0.6883 - val_accuracy: 0.5455\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 872us/step - loss: 0.6737 - accuracy: 0.5875 - val_loss: 0.6874 - val_accuracy: 0.5485\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.6711 - accuracy: 0.5945 - val_loss: 0.6869 - val_accuracy: 0.5508\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 796us/step - loss: 0.6708 - accuracy: 0.6021 - val_loss: 0.6857 - val_accuracy: 0.5555\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6694 - accuracy: 0.6024 - val_loss: 0.6855 - val_accuracy: 0.5562\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 863us/step - loss: 0.6678 - accuracy: 0.6051 - val_loss: 0.6846 - val_accuracy: 0.5586\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 823us/step - loss: 0.6680 - accuracy: 0.6069 - val_loss: 0.6845 - val_accuracy: 0.5600\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 987us/step - loss: 0.6675 - accuracy: 0.6062 - val_loss: 0.6831 - val_accuracy: 0.5649\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 995us/step - loss: 0.6656 - accuracy: 0.6069 - val_loss: 0.6816 - val_accuracy: 0.5715\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 827us/step - loss: 0.6652 - accuracy: 0.6133 - val_loss: 0.6818 - val_accuracy: 0.5703\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.6648 - accuracy: 0.6104 - val_loss: 0.6808 - val_accuracy: 0.5737\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 837us/step - loss: 0.6647 - accuracy: 0.6137 - val_loss: 0.6802 - val_accuracy: 0.5768\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.6201 - val_loss: 0.6797 - val_accuracy: 0.5785\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.6638 - accuracy: 0.6179 - val_loss: 0.6793 - val_accuracy: 0.5806\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 822us/step - loss: 0.6606 - accuracy: 0.6272 - val_loss: 0.6787 - val_accuracy: 0.5831\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6187 - val_loss: 0.6778 - val_accuracy: 0.5843\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 808us/step - loss: 0.6610 - accuracy: 0.6203 - val_loss: 0.6773 - val_accuracy: 0.5848\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 967us/step - loss: 0.6596 - accuracy: 0.6276 - val_loss: 0.6769 - val_accuracy: 0.5841\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 823us/step - loss: 0.6590 - accuracy: 0.6327 - val_loss: 0.6754 - val_accuracy: 0.5877\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6355 - val_loss: 0.6747 - val_accuracy: 0.5892\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 943us/step - loss: 0.6564 - accuracy: 0.6314 - val_loss: 0.6736 - val_accuracy: 0.5913\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6411 - val_loss: 0.6730 - val_accuracy: 0.5911\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6570 - accuracy: 0.6367 - val_loss: 0.6728 - val_accuracy: 0.5907\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6381 - val_loss: 0.6722 - val_accuracy: 0.5908\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6541 - accuracy: 0.6367 - val_loss: 0.6714 - val_accuracy: 0.5926\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6360 - val_loss: 0.6708 - val_accuracy: 0.5933\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7516 - accuracy: 0.4894 - val_loss: 0.5891 - val_accuracy: 0.8770\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.7144 - accuracy: 0.4936 - val_loss: 0.6508 - val_accuracy: 0.7488\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5074 - val_loss: 0.6806 - val_accuracy: 0.5810\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6994 - accuracy: 0.5152 - val_loss: 0.6926 - val_accuracy: 0.5119\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5278 - val_loss: 0.6965 - val_accuracy: 0.4920\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5286 - val_loss: 0.6993 - val_accuracy: 0.4802\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 934us/step - loss: 0.6899 - accuracy: 0.5371 - val_loss: 0.6982 - val_accuracy: 0.4879\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5469 - val_loss: 0.6953 - val_accuracy: 0.5035\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5499 - val_loss: 0.6929 - val_accuracy: 0.5203\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5572 - val_loss: 0.6900 - val_accuracy: 0.5402\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.6811 - accuracy: 0.5594 - val_loss: 0.6877 - val_accuracy: 0.5528\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5603 - val_loss: 0.6850 - val_accuracy: 0.5638\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.6762 - accuracy: 0.5732 - val_loss: 0.6839 - val_accuracy: 0.5678\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.5689 - val_loss: 0.6825 - val_accuracy: 0.5746\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6723 - accuracy: 0.5786 - val_loss: 0.6809 - val_accuracy: 0.5791\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 909us/step - loss: 0.6709 - accuracy: 0.5766 - val_loss: 0.6800 - val_accuracy: 0.5817\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.5896 - val_loss: 0.6785 - val_accuracy: 0.5859\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 921us/step - loss: 0.6689 - accuracy: 0.5819 - val_loss: 0.6772 - val_accuracy: 0.5893\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5848 - val_loss: 0.6741 - val_accuracy: 0.5975\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.5958 - val_loss: 0.6740 - val_accuracy: 0.5978\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.5966 - val_loss: 0.6745 - val_accuracy: 0.5980\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 910us/step - loss: 0.6634 - accuracy: 0.5923 - val_loss: 0.6725 - val_accuracy: 0.6025\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6625 - accuracy: 0.5933 - val_loss: 0.6705 - val_accuracy: 0.6054\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6634 - accuracy: 0.5940 - val_loss: 0.6685 - val_accuracy: 0.6090\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6011 - val_loss: 0.6681 - val_accuracy: 0.6100\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 923us/step - loss: 0.6569 - accuracy: 0.6038 - val_loss: 0.6684 - val_accuracy: 0.6091\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6036 - val_loss: 0.6686 - val_accuracy: 0.6083\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6068 - val_loss: 0.6662 - val_accuracy: 0.6113\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6557 - accuracy: 0.6118 - val_loss: 0.6649 - val_accuracy: 0.6137\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6117 - val_loss: 0.6638 - val_accuracy: 0.6154\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 915us/step - loss: 0.6542 - accuracy: 0.6118 - val_loss: 0.6634 - val_accuracy: 0.6159\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6180 - val_loss: 0.6623 - val_accuracy: 0.6178\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 919us/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.6636 - val_accuracy: 0.6132\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6154 - val_loss: 0.6614 - val_accuracy: 0.6183\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6501 - accuracy: 0.6193 - val_loss: 0.6597 - val_accuracy: 0.6219\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6203 - val_loss: 0.6593 - val_accuracy: 0.6226\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6230 - val_loss: 0.6593 - val_accuracy: 0.6211\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6461 - accuracy: 0.6283 - val_loss: 0.6574 - val_accuracy: 0.6238\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6219 - val_loss: 0.6585 - val_accuracy: 0.6203\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6451 - accuracy: 0.6277 - val_loss: 0.6587 - val_accuracy: 0.6190\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6244 - val_loss: 0.6582 - val_accuracy: 0.6195\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6346 - val_loss: 0.6553 - val_accuracy: 0.6260\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.6432 - accuracy: 0.6325 - val_loss: 0.6551 - val_accuracy: 0.6258\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.6407 - val_loss: 0.6538 - val_accuracy: 0.6274\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6286 - val_loss: 0.6522 - val_accuracy: 0.6303\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6394 - val_loss: 0.6532 - val_accuracy: 0.6270\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6400 - accuracy: 0.6400 - val_loss: 0.6521 - val_accuracy: 0.6278\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6383 - val_loss: 0.6526 - val_accuracy: 0.6260\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.6388 - accuracy: 0.6423 - val_loss: 0.6511 - val_accuracy: 0.6284\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6390 - accuracy: 0.6389 - val_loss: 0.6513 - val_accuracy: 0.6263\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7331 - accuracy: 0.5186 - val_loss: 0.7828 - val_accuracy: 0.1962\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.5286 - val_loss: 0.7320 - val_accuracy: 0.3209\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.5351 - val_loss: 0.7096 - val_accuracy: 0.4171\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 941us/step - loss: 0.7074 - accuracy: 0.5372 - val_loss: 0.6979 - val_accuracy: 0.4839\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.5425 - val_loss: 0.6975 - val_accuracy: 0.4743\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.5443 - val_loss: 0.6958 - val_accuracy: 0.4800\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.5527 - val_loss: 0.6920 - val_accuracy: 0.4951\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.6943 - accuracy: 0.5566 - val_loss: 0.6894 - val_accuracy: 0.5080\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5624 - val_loss: 0.6883 - val_accuracy: 0.5158\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5555 - val_loss: 0.6861 - val_accuracy: 0.5325\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5622 - val_loss: 0.6817 - val_accuracy: 0.5565\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5692 - val_loss: 0.6803 - val_accuracy: 0.5649\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.6818 - accuracy: 0.5736 - val_loss: 0.6780 - val_accuracy: 0.5772\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5675 - val_loss: 0.6735 - val_accuracy: 0.5966\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 934us/step - loss: 0.6788 - accuracy: 0.5798 - val_loss: 0.6710 - val_accuracy: 0.6063\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5809 - val_loss: 0.6705 - val_accuracy: 0.6073\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.5909 - val_loss: 0.6681 - val_accuracy: 0.6161\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.5917 - val_loss: 0.6712 - val_accuracy: 0.6016\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 911us/step - loss: 0.6702 - accuracy: 0.5910 - val_loss: 0.6698 - val_accuracy: 0.6083\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.5900 - val_loss: 0.6700 - val_accuracy: 0.6060\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.6671 - accuracy: 0.5962 - val_loss: 0.6694 - val_accuracy: 0.6079\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6659 - accuracy: 0.5975 - val_loss: 0.6670 - val_accuracy: 0.6211\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 986us/step - loss: 0.6647 - accuracy: 0.5972 - val_loss: 0.6668 - val_accuracy: 0.6230\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.6079 - val_loss: 0.6658 - val_accuracy: 0.6259\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.5961 - val_loss: 0.6619 - val_accuracy: 0.6401\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6089 - val_loss: 0.6632 - val_accuracy: 0.6353\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6172 - val_loss: 0.6621 - val_accuracy: 0.6371\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6566 - accuracy: 0.6148 - val_loss: 0.6616 - val_accuracy: 0.6368\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6163 - val_loss: 0.6592 - val_accuracy: 0.6435\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 932us/step - loss: 0.6572 - accuracy: 0.6173 - val_loss: 0.6581 - val_accuracy: 0.6457\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6137 - val_loss: 0.6583 - val_accuracy: 0.6446\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6190 - val_loss: 0.6585 - val_accuracy: 0.6457\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.6501 - accuracy: 0.6244 - val_loss: 0.6587 - val_accuracy: 0.6465\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6236 - val_loss: 0.6568 - val_accuracy: 0.6516\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6328 - val_loss: 0.6584 - val_accuracy: 0.6474\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.6463 - accuracy: 0.6340 - val_loss: 0.6557 - val_accuracy: 0.6535\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6302 - val_loss: 0.6537 - val_accuracy: 0.6598\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6340 - val_loss: 0.6531 - val_accuracy: 0.6601\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 922us/step - loss: 0.6472 - accuracy: 0.6311 - val_loss: 0.6504 - val_accuracy: 0.6657\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6377 - val_loss: 0.6520 - val_accuracy: 0.6624\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 980us/step - loss: 0.6457 - accuracy: 0.6361 - val_loss: 0.6499 - val_accuracy: 0.6649\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.6364 - val_loss: 0.6481 - val_accuracy: 0.6665\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6434 - val_loss: 0.6469 - val_accuracy: 0.6679\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6384 - accuracy: 0.6428 - val_loss: 0.6498 - val_accuracy: 0.6614\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6467 - val_loss: 0.6502 - val_accuracy: 0.6602\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 935us/step - loss: 0.6386 - accuracy: 0.6473 - val_loss: 0.6459 - val_accuracy: 0.6660\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6385 - accuracy: 0.6414 - val_loss: 0.6442 - val_accuracy: 0.6678\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 939us/step - loss: 0.6358 - accuracy: 0.6495 - val_loss: 0.6452 - val_accuracy: 0.6655\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.6520 - val_loss: 0.6434 - val_accuracy: 0.6675\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6351 - accuracy: 0.6447 - val_loss: 0.6443 - val_accuracy: 0.6653\n",
      "Epoch 1/50\n",
      "  1/418 [..............................] - ETA: 0s - loss: 0.7308 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.4934 - val_loss: 0.6273 - val_accuracy: 0.8586\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.5015 - val_loss: 0.6703 - val_accuracy: 0.6759\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 987us/step - loss: 0.7032 - accuracy: 0.5089 - val_loss: 0.6939 - val_accuracy: 0.5214\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.5170 - val_loss: 0.7029 - val_accuracy: 0.4785\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.5235 - val_loss: 0.7069 - val_accuracy: 0.4596\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.6974 - accuracy: 0.5202 - val_loss: 0.7067 - val_accuracy: 0.4639\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.5236 - val_loss: 0.7078 - val_accuracy: 0.4620\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5354 - val_loss: 0.7072 - val_accuracy: 0.4693\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.6914 - accuracy: 0.5381 - val_loss: 0.7043 - val_accuracy: 0.4876\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5493 - val_loss: 0.7041 - val_accuracy: 0.4953\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 935us/step - loss: 0.6890 - accuracy: 0.5494 - val_loss: 0.7044 - val_accuracy: 0.4950\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6879 - accuracy: 0.5502 - val_loss: 0.7022 - val_accuracy: 0.5101\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5573 - val_loss: 0.7023 - val_accuracy: 0.5131\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5529 - val_loss: 0.7013 - val_accuracy: 0.5191\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5606 - val_loss: 0.7013 - val_accuracy: 0.5196\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5625 - val_loss: 0.6999 - val_accuracy: 0.5276\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5552 - val_loss: 0.6987 - val_accuracy: 0.5358\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 925us/step - loss: 0.6823 - accuracy: 0.5621 - val_loss: 0.6983 - val_accuracy: 0.5392\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5719 - val_loss: 0.6971 - val_accuracy: 0.5446\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5675 - val_loss: 0.6985 - val_accuracy: 0.5411\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.6776 - accuracy: 0.5782 - val_loss: 0.6957 - val_accuracy: 0.5515\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.5810 - val_loss: 0.6945 - val_accuracy: 0.5561\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5855 - val_loss: 0.6939 - val_accuracy: 0.5589\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5818 - val_loss: 0.6925 - val_accuracy: 0.5638\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6750 - accuracy: 0.5830 - val_loss: 0.6905 - val_accuracy: 0.5701\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.5993 - val_loss: 0.6901 - val_accuracy: 0.5708\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6742 - accuracy: 0.5934 - val_loss: 0.6904 - val_accuracy: 0.5680\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.5955 - val_loss: 0.6895 - val_accuracy: 0.5716\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6704 - accuracy: 0.5999 - val_loss: 0.6877 - val_accuracy: 0.5761\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 976us/step - loss: 0.6687 - accuracy: 0.6022 - val_loss: 0.6863 - val_accuracy: 0.5796\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.6015 - val_loss: 0.6858 - val_accuracy: 0.5808\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6682 - accuracy: 0.6059 - val_loss: 0.6852 - val_accuracy: 0.5810\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.6106 - val_loss: 0.6820 - val_accuracy: 0.5912\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 974us/step - loss: 0.6667 - accuracy: 0.6051 - val_loss: 0.6824 - val_accuracy: 0.5885\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.6031 - val_loss: 0.6811 - val_accuracy: 0.5918\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6643 - accuracy: 0.6154 - val_loss: 0.6812 - val_accuracy: 0.5908\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.6224 - val_loss: 0.6812 - val_accuracy: 0.5898\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6213 - val_loss: 0.6806 - val_accuracy: 0.5907\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.6608 - accuracy: 0.6233 - val_loss: 0.6785 - val_accuracy: 0.5965\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6224 - val_loss: 0.6769 - val_accuracy: 0.5990\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.6256 - val_loss: 0.6778 - val_accuracy: 0.5969\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 955us/step - loss: 0.6591 - accuracy: 0.6295 - val_loss: 0.6752 - val_accuracy: 0.6023\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6253 - val_loss: 0.6757 - val_accuracy: 0.6002\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6579 - accuracy: 0.6242 - val_loss: 0.6748 - val_accuracy: 0.6016\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6334 - val_loss: 0.6729 - val_accuracy: 0.6049\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.6539 - accuracy: 0.6398 - val_loss: 0.6705 - val_accuracy: 0.6088\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6364 - val_loss: 0.6715 - val_accuracy: 0.6065\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6349 - val_loss: 0.6709 - val_accuracy: 0.6071\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 985us/step - loss: 0.6515 - accuracy: 0.6373 - val_loss: 0.6709 - val_accuracy: 0.6065\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6397 - val_loss: 0.6690 - val_accuracy: 0.6095\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7063 - accuracy: 0.5031 - val_loss: 0.7474 - val_accuracy: 0.2370\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1000us/step - loss: 0.7042 - accuracy: 0.5002 - val_loss: 0.7363 - val_accuracy: 0.2899\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.5094 - val_loss: 0.7299 - val_accuracy: 0.3241\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5132 - val_loss: 0.7275 - val_accuracy: 0.3341\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.5046 - val_loss: 0.7274 - val_accuracy: 0.3343\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6974 - accuracy: 0.5148 - val_loss: 0.7228 - val_accuracy: 0.3532\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 919us/step - loss: 0.6963 - accuracy: 0.5221 - val_loss: 0.7232 - val_accuracy: 0.3517\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5258 - val_loss: 0.7214 - val_accuracy: 0.3620\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 906us/step - loss: 0.6945 - accuracy: 0.5229 - val_loss: 0.7185 - val_accuracy: 0.3797\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5298 - val_loss: 0.7195 - val_accuracy: 0.3785\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6902 - accuracy: 0.5384 - val_loss: 0.7164 - val_accuracy: 0.3984\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5354 - val_loss: 0.7152 - val_accuracy: 0.4086\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6882 - accuracy: 0.5377 - val_loss: 0.7149 - val_accuracy: 0.4145\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5486 - val_loss: 0.7126 - val_accuracy: 0.4326\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 927us/step - loss: 0.6852 - accuracy: 0.5490 - val_loss: 0.7124 - val_accuracy: 0.4386\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5552 - val_loss: 0.7127 - val_accuracy: 0.4438\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5528 - val_loss: 0.7116 - val_accuracy: 0.4567\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 930us/step - loss: 0.6802 - accuracy: 0.5684 - val_loss: 0.7113 - val_accuracy: 0.4656\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5618 - val_loss: 0.7087 - val_accuracy: 0.4836\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.6783 - accuracy: 0.5701 - val_loss: 0.7063 - val_accuracy: 0.4978\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.5754 - val_loss: 0.7085 - val_accuracy: 0.4907\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5810 - val_loss: 0.7061 - val_accuracy: 0.5046\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.5834 - val_loss: 0.7020 - val_accuracy: 0.5221\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6746 - accuracy: 0.5772 - val_loss: 0.7020 - val_accuracy: 0.5249\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.5917 - val_loss: 0.7009 - val_accuracy: 0.5286\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6708 - accuracy: 0.5847 - val_loss: 0.6999 - val_accuracy: 0.5320\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 953us/step - loss: 0.6689 - accuracy: 0.5917 - val_loss: 0.6980 - val_accuracy: 0.5402\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 925us/step - loss: 0.6698 - accuracy: 0.5964 - val_loss: 0.6989 - val_accuracy: 0.5375\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5972 - val_loss: 0.6965 - val_accuracy: 0.5462\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 923us/step - loss: 0.6684 - accuracy: 0.5967 - val_loss: 0.6943 - val_accuracy: 0.5530\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 922us/step - loss: 0.6682 - accuracy: 0.5963 - val_loss: 0.6906 - val_accuracy: 0.5628\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6043 - val_loss: 0.6902 - val_accuracy: 0.5635\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 955us/step - loss: 0.6655 - accuracy: 0.6047 - val_loss: 0.6916 - val_accuracy: 0.5587\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6627 - accuracy: 0.6106 - val_loss: 0.6898 - val_accuracy: 0.5622\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6041 - val_loss: 0.6902 - val_accuracy: 0.5604\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.6160 - val_loss: 0.6887 - val_accuracy: 0.5638\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 856us/step - loss: 0.6622 - accuracy: 0.6113 - val_loss: 0.6883 - val_accuracy: 0.5656\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6182 - val_loss: 0.6865 - val_accuracy: 0.5714\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 849us/step - loss: 0.6589 - accuracy: 0.6198 - val_loss: 0.6874 - val_accuracy: 0.5682\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6214 - val_loss: 0.6865 - val_accuracy: 0.5699\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6580 - accuracy: 0.6231 - val_loss: 0.6845 - val_accuracy: 0.5748\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.6568 - accuracy: 0.6216 - val_loss: 0.6844 - val_accuracy: 0.5748\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 913us/step - loss: 0.6560 - accuracy: 0.6277 - val_loss: 0.6831 - val_accuracy: 0.5785\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 977us/step - loss: 0.6556 - accuracy: 0.6193 - val_loss: 0.6823 - val_accuracy: 0.5801\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6550 - accuracy: 0.6269 - val_loss: 0.6824 - val_accuracy: 0.5796\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6249 - val_loss: 0.6809 - val_accuracy: 0.5822\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 991us/step - loss: 0.6512 - accuracy: 0.6331 - val_loss: 0.6804 - val_accuracy: 0.5840\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 926us/step - loss: 0.6512 - accuracy: 0.6286 - val_loss: 0.6788 - val_accuracy: 0.5885\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.6523 - accuracy: 0.6288 - val_loss: 0.6794 - val_accuracy: 0.5861\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 968us/step - loss: 0.6506 - accuracy: 0.6364 - val_loss: 0.6796 - val_accuracy: 0.5854\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7453 - accuracy: 0.4993 - val_loss: 0.6180 - val_accuracy: 0.8101\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.4932 - val_loss: 0.6671 - val_accuracy: 0.6729\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 849us/step - loss: 0.7111 - accuracy: 0.5101 - val_loss: 0.6951 - val_accuracy: 0.5015\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.5098 - val_loss: 0.7107 - val_accuracy: 0.4044\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.5126 - val_loss: 0.7165 - val_accuracy: 0.3814\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.5210 - val_loss: 0.7195 - val_accuracy: 0.3686\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.5303 - val_loss: 0.7208 - val_accuracy: 0.3651\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 866us/step - loss: 0.7009 - accuracy: 0.5252 - val_loss: 0.7193 - val_accuracy: 0.3741\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 955us/step - loss: 0.7002 - accuracy: 0.5298 - val_loss: 0.7190 - val_accuracy: 0.3764\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 879us/step - loss: 0.6966 - accuracy: 0.5374 - val_loss: 0.7185 - val_accuracy: 0.3800\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 975us/step - loss: 0.6952 - accuracy: 0.5398 - val_loss: 0.7166 - val_accuracy: 0.3987\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 821us/step - loss: 0.6909 - accuracy: 0.5467 - val_loss: 0.7139 - val_accuracy: 0.4239\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5513 - val_loss: 0.7125 - val_accuracy: 0.4387\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5488 - val_loss: 0.7108 - val_accuracy: 0.4514\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6909 - accuracy: 0.5520 - val_loss: 0.7090 - val_accuracy: 0.4601\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 953us/step - loss: 0.6888 - accuracy: 0.5570 - val_loss: 0.7071 - val_accuracy: 0.4732\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6855 - accuracy: 0.5629 - val_loss: 0.7067 - val_accuracy: 0.4744\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5733 - val_loss: 0.7050 - val_accuracy: 0.4815\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6836 - accuracy: 0.5655 - val_loss: 0.7023 - val_accuracy: 0.4947\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.6834 - accuracy: 0.5701 - val_loss: 0.7016 - val_accuracy: 0.4961\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.6809 - accuracy: 0.5751 - val_loss: 0.7002 - val_accuracy: 0.5011\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5736 - val_loss: 0.6989 - val_accuracy: 0.5040\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6801 - accuracy: 0.5772 - val_loss: 0.6983 - val_accuracy: 0.5048\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5772 - val_loss: 0.6971 - val_accuracy: 0.5076\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1000us/step - loss: 0.6778 - accuracy: 0.5895 - val_loss: 0.6973 - val_accuracy: 0.5069\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 916us/step - loss: 0.6760 - accuracy: 0.5871 - val_loss: 0.6957 - val_accuracy: 0.5110\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.6762 - accuracy: 0.5890 - val_loss: 0.6959 - val_accuracy: 0.5108\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6748 - accuracy: 0.5911 - val_loss: 0.6950 - val_accuracy: 0.5137\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5866 - val_loss: 0.6937 - val_accuracy: 0.5187\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 831us/step - loss: 0.6727 - accuracy: 0.5987 - val_loss: 0.6924 - val_accuracy: 0.5234\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 895us/step - loss: 0.6726 - accuracy: 0.5994 - val_loss: 0.6899 - val_accuracy: 0.5331\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 956us/step - loss: 0.6715 - accuracy: 0.6035 - val_loss: 0.6892 - val_accuracy: 0.5354\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6719 - accuracy: 0.5956 - val_loss: 0.6895 - val_accuracy: 0.5344\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 948us/step - loss: 0.6693 - accuracy: 0.6026 - val_loss: 0.6885 - val_accuracy: 0.5384\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.6055 - val_loss: 0.6885 - val_accuracy: 0.5380\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.6673 - accuracy: 0.6061 - val_loss: 0.6873 - val_accuracy: 0.5416\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6127 - val_loss: 0.6859 - val_accuracy: 0.5453\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 817us/step - loss: 0.6660 - accuracy: 0.6106 - val_loss: 0.6855 - val_accuracy: 0.5467\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6642 - accuracy: 0.6124 - val_loss: 0.6849 - val_accuracy: 0.5482\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 866us/step - loss: 0.6649 - accuracy: 0.6127 - val_loss: 0.6836 - val_accuracy: 0.5511\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.6644 - accuracy: 0.6169 - val_loss: 0.6828 - val_accuracy: 0.5545\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 955us/step - loss: 0.6622 - accuracy: 0.6198 - val_loss: 0.6834 - val_accuracy: 0.5537\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 890us/step - loss: 0.6612 - accuracy: 0.6229 - val_loss: 0.6818 - val_accuracy: 0.5572\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 827us/step - loss: 0.6604 - accuracy: 0.6269 - val_loss: 0.6794 - val_accuracy: 0.5622\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 975us/step - loss: 0.6570 - accuracy: 0.6322 - val_loss: 0.6789 - val_accuracy: 0.5622\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6597 - accuracy: 0.6224 - val_loss: 0.6790 - val_accuracy: 0.5624\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 980us/step - loss: 0.6587 - accuracy: 0.6249 - val_loss: 0.6782 - val_accuracy: 0.5650\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6296 - val_loss: 0.6784 - val_accuracy: 0.5641\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6568 - accuracy: 0.6272 - val_loss: 0.6779 - val_accuracy: 0.5652\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6335 - val_loss: 0.6765 - val_accuracy: 0.5676\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7420 - accuracy: 0.5070 - val_loss: 0.8506 - val_accuracy: 0.1208\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 858us/step - loss: 0.7252 - accuracy: 0.4957 - val_loss: 0.7976 - val_accuracy: 0.1536\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.7204 - accuracy: 0.4948 - val_loss: 0.7697 - val_accuracy: 0.2187\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.7145 - accuracy: 0.4954 - val_loss: 0.7535 - val_accuracy: 0.2572\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.7126 - accuracy: 0.4919 - val_loss: 0.7463 - val_accuracy: 0.2765\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.5013 - val_loss: 0.7393 - val_accuracy: 0.3029\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.7051 - accuracy: 0.5032 - val_loss: 0.7359 - val_accuracy: 0.3111\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 928us/step - loss: 0.7013 - accuracy: 0.5095 - val_loss: 0.7325 - val_accuracy: 0.3204\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.5151 - val_loss: 0.7292 - val_accuracy: 0.3347\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 837us/step - loss: 0.6967 - accuracy: 0.5256 - val_loss: 0.7290 - val_accuracy: 0.3254\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.5250 - val_loss: 0.7256 - val_accuracy: 0.3358\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 989us/step - loss: 0.6941 - accuracy: 0.5301 - val_loss: 0.7243 - val_accuracy: 0.3435\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.6911 - accuracy: 0.5358 - val_loss: 0.7217 - val_accuracy: 0.3584\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.6903 - accuracy: 0.5292 - val_loss: 0.7199 - val_accuracy: 0.3679\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5446 - val_loss: 0.7190 - val_accuracy: 0.3759\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6881 - accuracy: 0.5375 - val_loss: 0.7169 - val_accuracy: 0.3949\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6888 - accuracy: 0.5351 - val_loss: 0.7133 - val_accuracy: 0.4205\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.6829 - accuracy: 0.5501 - val_loss: 0.7127 - val_accuracy: 0.4288\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6820 - accuracy: 0.5492 - val_loss: 0.7112 - val_accuracy: 0.4403\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.5618 - val_loss: 0.7102 - val_accuracy: 0.4468\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6815 - accuracy: 0.5502 - val_loss: 0.7103 - val_accuracy: 0.4515\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 990us/step - loss: 0.6807 - accuracy: 0.5567 - val_loss: 0.7086 - val_accuracy: 0.4647\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6761 - accuracy: 0.5698 - val_loss: 0.7079 - val_accuracy: 0.4769\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 829us/step - loss: 0.6765 - accuracy: 0.5683 - val_loss: 0.7052 - val_accuracy: 0.4989\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 953us/step - loss: 0.6735 - accuracy: 0.5765 - val_loss: 0.7043 - val_accuracy: 0.5138\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 907us/step - loss: 0.6746 - accuracy: 0.5702 - val_loss: 0.7036 - val_accuracy: 0.5190\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6735 - accuracy: 0.5756 - val_loss: 0.7026 - val_accuracy: 0.5233\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.5787 - val_loss: 0.7020 - val_accuracy: 0.5269\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5825 - val_loss: 0.7023 - val_accuracy: 0.5274\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 899us/step - loss: 0.6704 - accuracy: 0.5783 - val_loss: 0.7012 - val_accuracy: 0.5336\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.6677 - accuracy: 0.5869 - val_loss: 0.7001 - val_accuracy: 0.5403\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5911 - val_loss: 0.6985 - val_accuracy: 0.5476\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 949us/step - loss: 0.6671 - accuracy: 0.5899 - val_loss: 0.6978 - val_accuracy: 0.5506\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.5932 - val_loss: 0.6968 - val_accuracy: 0.5551\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.5955 - val_loss: 0.6957 - val_accuracy: 0.5586\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 854us/step - loss: 0.6643 - accuracy: 0.5947 - val_loss: 0.6944 - val_accuracy: 0.5670\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6632 - accuracy: 0.5953 - val_loss: 0.6925 - val_accuracy: 0.5751\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6038 - val_loss: 0.6922 - val_accuracy: 0.5792\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6620 - accuracy: 0.6039 - val_loss: 0.6919 - val_accuracy: 0.5813\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6620 - accuracy: 0.6026 - val_loss: 0.6892 - val_accuracy: 0.5893\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6588 - accuracy: 0.6084 - val_loss: 0.6890 - val_accuracy: 0.5893\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.6596 - accuracy: 0.6080 - val_loss: 0.6886 - val_accuracy: 0.5901\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6097 - val_loss: 0.6876 - val_accuracy: 0.5918\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 852us/step - loss: 0.6589 - accuracy: 0.6068 - val_loss: 0.6859 - val_accuracy: 0.5959\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6560 - accuracy: 0.6139 - val_loss: 0.6855 - val_accuracy: 0.5977\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 799us/step - loss: 0.6561 - accuracy: 0.6186 - val_loss: 0.6833 - val_accuracy: 0.6072\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 881us/step - loss: 0.6528 - accuracy: 0.6210 - val_loss: 0.6838 - val_accuracy: 0.6059\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 997us/step - loss: 0.6547 - accuracy: 0.6103 - val_loss: 0.6834 - val_accuracy: 0.6082\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6514 - accuracy: 0.6271 - val_loss: 0.6822 - val_accuracy: 0.6099\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6205 - val_loss: 0.6828 - val_accuracy: 0.6096\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7108 - accuracy: 0.5071 - val_loss: 0.7626 - val_accuracy: 0.1722\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.7025 - accuracy: 0.5128 - val_loss: 0.7443 - val_accuracy: 0.2556\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.5232 - val_loss: 0.7320 - val_accuracy: 0.3024\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 831us/step - loss: 0.6985 - accuracy: 0.5251 - val_loss: 0.7232 - val_accuracy: 0.3598\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.6955 - accuracy: 0.5316 - val_loss: 0.7163 - val_accuracy: 0.3899\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5464 - val_loss: 0.7103 - val_accuracy: 0.4160\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5471 - val_loss: 0.7070 - val_accuracy: 0.4364\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 920us/step - loss: 0.6879 - accuracy: 0.5526 - val_loss: 0.7037 - val_accuracy: 0.4570\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 986us/step - loss: 0.6843 - accuracy: 0.5644 - val_loss: 0.7009 - val_accuracy: 0.4694\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6835 - accuracy: 0.5593 - val_loss: 0.6972 - val_accuracy: 0.4883\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 851us/step - loss: 0.6798 - accuracy: 0.5702 - val_loss: 0.6946 - val_accuracy: 0.5012\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.6790 - accuracy: 0.5759 - val_loss: 0.6918 - val_accuracy: 0.5112\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6755 - accuracy: 0.5818 - val_loss: 0.6882 - val_accuracy: 0.5268\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 946us/step - loss: 0.6730 - accuracy: 0.5916 - val_loss: 0.6854 - val_accuracy: 0.5384\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.5986 - val_loss: 0.6816 - val_accuracy: 0.5510\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5959 - val_loss: 0.6786 - val_accuracy: 0.5600\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 829us/step - loss: 0.6670 - accuracy: 0.6019 - val_loss: 0.6782 - val_accuracy: 0.5625\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 974us/step - loss: 0.6663 - accuracy: 0.6003 - val_loss: 0.6768 - val_accuracy: 0.5671\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 943us/step - loss: 0.6632 - accuracy: 0.6055 - val_loss: 0.6732 - val_accuracy: 0.5734\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6138 - val_loss: 0.6706 - val_accuracy: 0.5797\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6118 - val_loss: 0.6719 - val_accuracy: 0.5767\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 977us/step - loss: 0.6609 - accuracy: 0.6127 - val_loss: 0.6713 - val_accuracy: 0.5785\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6213 - val_loss: 0.6704 - val_accuracy: 0.5823\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 866us/step - loss: 0.6581 - accuracy: 0.6134 - val_loss: 0.6685 - val_accuracy: 0.5872\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 967us/step - loss: 0.6575 - accuracy: 0.6188 - val_loss: 0.6685 - val_accuracy: 0.5863\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 843us/step - loss: 0.6544 - accuracy: 0.6284 - val_loss: 0.6692 - val_accuracy: 0.5853\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6543 - accuracy: 0.6283 - val_loss: 0.6698 - val_accuracy: 0.5831\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6555 - accuracy: 0.6216 - val_loss: 0.6665 - val_accuracy: 0.5926\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6230 - val_loss: 0.6664 - val_accuracy: 0.5923\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6361 - val_loss: 0.6673 - val_accuracy: 0.5894\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 949us/step - loss: 0.6510 - accuracy: 0.6317 - val_loss: 0.6670 - val_accuracy: 0.5900\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 957us/step - loss: 0.6494 - accuracy: 0.6361 - val_loss: 0.6661 - val_accuracy: 0.5913\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 944us/step - loss: 0.6492 - accuracy: 0.6352 - val_loss: 0.6661 - val_accuracy: 0.5906\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 870us/step - loss: 0.6469 - accuracy: 0.6388 - val_loss: 0.6645 - val_accuracy: 0.5939\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 967us/step - loss: 0.6459 - accuracy: 0.6385 - val_loss: 0.6640 - val_accuracy: 0.5945\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 821us/step - loss: 0.6455 - accuracy: 0.6378 - val_loss: 0.6640 - val_accuracy: 0.5935\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 950us/step - loss: 0.6464 - accuracy: 0.6406 - val_loss: 0.6632 - val_accuracy: 0.5949\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 822us/step - loss: 0.6447 - accuracy: 0.6400 - val_loss: 0.6604 - val_accuracy: 0.6012\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6428 - accuracy: 0.6453 - val_loss: 0.6595 - val_accuracy: 0.6020\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.6436 - accuracy: 0.6374 - val_loss: 0.6595 - val_accuracy: 0.6018\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6397 - accuracy: 0.6442 - val_loss: 0.6586 - val_accuracy: 0.6027\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6480 - val_loss: 0.6578 - val_accuracy: 0.6028\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 824us/step - loss: 0.6391 - accuracy: 0.6482 - val_loss: 0.6563 - val_accuracy: 0.6036\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6383 - accuracy: 0.6512 - val_loss: 0.6557 - val_accuracy: 0.6038\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 913us/step - loss: 0.6410 - accuracy: 0.6430 - val_loss: 0.6559 - val_accuracy: 0.6038\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 952us/step - loss: 0.6386 - accuracy: 0.6468 - val_loss: 0.6549 - val_accuracy: 0.6059\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 812us/step - loss: 0.6360 - accuracy: 0.6515 - val_loss: 0.6531 - val_accuracy: 0.6082\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6533 - val_loss: 0.6533 - val_accuracy: 0.6071\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 943us/step - loss: 0.6365 - accuracy: 0.6521 - val_loss: 0.6541 - val_accuracy: 0.6054\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6491 - val_loss: 0.6525 - val_accuracy: 0.6082\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5171 - val_loss: 0.6767 - val_accuracy: 0.5683\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.6951 - accuracy: 0.5295 - val_loss: 0.6850 - val_accuracy: 0.4963\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 812us/step - loss: 0.6949 - accuracy: 0.5263 - val_loss: 0.6900 - val_accuracy: 0.4652\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5278 - val_loss: 0.6940 - val_accuracy: 0.4324\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 808us/step - loss: 0.6911 - accuracy: 0.5382 - val_loss: 0.6964 - val_accuracy: 0.4193\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5322 - val_loss: 0.6982 - val_accuracy: 0.4085\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.6887 - accuracy: 0.5500 - val_loss: 0.6991 - val_accuracy: 0.4051\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6881 - accuracy: 0.5500 - val_loss: 0.7001 - val_accuracy: 0.3990\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 952us/step - loss: 0.6869 - accuracy: 0.5505 - val_loss: 0.7010 - val_accuracy: 0.3958\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 997us/step - loss: 0.6872 - accuracy: 0.5500 - val_loss: 0.7007 - val_accuracy: 0.3972\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 808us/step - loss: 0.6860 - accuracy: 0.5546 - val_loss: 0.7002 - val_accuracy: 0.4036\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 978us/step - loss: 0.6854 - accuracy: 0.5597 - val_loss: 0.7001 - val_accuracy: 0.4057\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 932us/step - loss: 0.6827 - accuracy: 0.5693 - val_loss: 0.6999 - val_accuracy: 0.4086\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 981us/step - loss: 0.6822 - accuracy: 0.5702 - val_loss: 0.6992 - val_accuracy: 0.4186\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.6830 - accuracy: 0.5656 - val_loss: 0.6985 - val_accuracy: 0.4252\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 877us/step - loss: 0.6821 - accuracy: 0.5635 - val_loss: 0.6982 - val_accuracy: 0.4275\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6809 - accuracy: 0.5747 - val_loss: 0.6973 - val_accuracy: 0.4332\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5802 - val_loss: 0.6965 - val_accuracy: 0.4398\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5766 - val_loss: 0.6964 - val_accuracy: 0.4419\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5718 - val_loss: 0.6964 - val_accuracy: 0.4464\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6794 - accuracy: 0.5789 - val_loss: 0.6955 - val_accuracy: 0.4557\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 976us/step - loss: 0.6766 - accuracy: 0.5824 - val_loss: 0.6952 - val_accuracy: 0.4627\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 814us/step - loss: 0.6767 - accuracy: 0.5875 - val_loss: 0.6948 - val_accuracy: 0.4694\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 955us/step - loss: 0.6771 - accuracy: 0.5855 - val_loss: 0.6943 - val_accuracy: 0.4767\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 876us/step - loss: 0.6741 - accuracy: 0.5984 - val_loss: 0.6938 - val_accuracy: 0.4834\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 814us/step - loss: 0.6758 - accuracy: 0.5882 - val_loss: 0.6934 - val_accuracy: 0.4882\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.5902 - val_loss: 0.6927 - val_accuracy: 0.4936\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.6747 - accuracy: 0.5938 - val_loss: 0.6920 - val_accuracy: 0.5009\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 941us/step - loss: 0.6724 - accuracy: 0.6025 - val_loss: 0.6913 - val_accuracy: 0.5072\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6715 - accuracy: 0.5925 - val_loss: 0.6902 - val_accuracy: 0.5174\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6693 - accuracy: 0.6051 - val_loss: 0.6901 - val_accuracy: 0.5210\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 972us/step - loss: 0.6699 - accuracy: 0.6047 - val_loss: 0.6899 - val_accuracy: 0.5245\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 797us/step - loss: 0.6708 - accuracy: 0.6063 - val_loss: 0.6897 - val_accuracy: 0.5302\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 815us/step - loss: 0.6683 - accuracy: 0.6156 - val_loss: 0.6884 - val_accuracy: 0.5414\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.6105 - val_loss: 0.6876 - val_accuracy: 0.5474\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.6133 - val_loss: 0.6876 - val_accuracy: 0.5489\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 827us/step - loss: 0.6676 - accuracy: 0.6151 - val_loss: 0.6873 - val_accuracy: 0.5515\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.6169 - val_loss: 0.6870 - val_accuracy: 0.5526\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.6181 - val_loss: 0.6863 - val_accuracy: 0.5548\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6245 - val_loss: 0.6854 - val_accuracy: 0.5580\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6643 - accuracy: 0.6187 - val_loss: 0.6842 - val_accuracy: 0.5641\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6646 - accuracy: 0.6245 - val_loss: 0.6830 - val_accuracy: 0.5684\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.6633 - accuracy: 0.6281 - val_loss: 0.6823 - val_accuracy: 0.5699\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 908us/step - loss: 0.6630 - accuracy: 0.6240 - val_loss: 0.6816 - val_accuracy: 0.5722\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 944us/step - loss: 0.6615 - accuracy: 0.6284 - val_loss: 0.6810 - val_accuracy: 0.5729\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6625 - accuracy: 0.6288 - val_loss: 0.6805 - val_accuracy: 0.5740\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 955us/step - loss: 0.6614 - accuracy: 0.6316 - val_loss: 0.6807 - val_accuracy: 0.5736\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6281 - val_loss: 0.6798 - val_accuracy: 0.5758\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 817us/step - loss: 0.6610 - accuracy: 0.6288 - val_loss: 0.6795 - val_accuracy: 0.5756\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6275 - val_loss: 0.6785 - val_accuracy: 0.5780\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.8285 - accuracy: 0.5170 - val_loss: 1.0073 - val_accuracy: 0.1283\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.7422 - accuracy: 0.5119 - val_loss: 0.8363 - val_accuracy: 0.1373\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.7178 - accuracy: 0.5110 - val_loss: 0.7619 - val_accuracy: 0.1908\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.5113 - val_loss: 0.7266 - val_accuracy: 0.3218\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.7019 - accuracy: 0.5258 - val_loss: 0.7104 - val_accuracy: 0.4085\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 981us/step - loss: 0.6980 - accuracy: 0.5285 - val_loss: 0.6995 - val_accuracy: 0.4721\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5433 - val_loss: 0.6964 - val_accuracy: 0.4997\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 816us/step - loss: 0.6933 - accuracy: 0.5391 - val_loss: 0.6918 - val_accuracy: 0.5270\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 804us/step - loss: 0.6895 - accuracy: 0.5498 - val_loss: 0.6884 - val_accuracy: 0.5471\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5564 - val_loss: 0.6843 - val_accuracy: 0.5655\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 968us/step - loss: 0.6789 - accuracy: 0.5687 - val_loss: 0.6824 - val_accuracy: 0.5735\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 999us/step - loss: 0.6805 - accuracy: 0.5657 - val_loss: 0.6788 - val_accuracy: 0.5875\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6782 - accuracy: 0.5769 - val_loss: 0.6776 - val_accuracy: 0.5903\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 823us/step - loss: 0.6744 - accuracy: 0.5819 - val_loss: 0.6772 - val_accuracy: 0.5908\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 981us/step - loss: 0.6729 - accuracy: 0.5852 - val_loss: 0.6769 - val_accuracy: 0.5904\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 910us/step - loss: 0.6717 - accuracy: 0.5896 - val_loss: 0.6729 - val_accuracy: 0.6001\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 989us/step - loss: 0.6657 - accuracy: 0.5980 - val_loss: 0.6701 - val_accuracy: 0.6067\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.5844 - val_loss: 0.6690 - val_accuracy: 0.6075\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 816us/step - loss: 0.6672 - accuracy: 0.5937 - val_loss: 0.6704 - val_accuracy: 0.6011\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.6626 - accuracy: 0.6056 - val_loss: 0.6678 - val_accuracy: 0.6080\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 975us/step - loss: 0.6614 - accuracy: 0.6060 - val_loss: 0.6653 - val_accuracy: 0.6138\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.6081 - val_loss: 0.6635 - val_accuracy: 0.6182\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 985us/step - loss: 0.6616 - accuracy: 0.6050 - val_loss: 0.6619 - val_accuracy: 0.6224\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6601 - accuracy: 0.6074 - val_loss: 0.6605 - val_accuracy: 0.6248\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6567 - accuracy: 0.6133 - val_loss: 0.6615 - val_accuracy: 0.6209\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6567 - accuracy: 0.6158 - val_loss: 0.6606 - val_accuracy: 0.6217\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6201 - val_loss: 0.6592 - val_accuracy: 0.6236\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6532 - accuracy: 0.6196 - val_loss: 0.6573 - val_accuracy: 0.6286\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6217 - val_loss: 0.6557 - val_accuracy: 0.6322\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6536 - accuracy: 0.6222 - val_loss: 0.6550 - val_accuracy: 0.6321\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6279 - val_loss: 0.6546 - val_accuracy: 0.6321\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6310 - val_loss: 0.6529 - val_accuracy: 0.6349\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6287 - val_loss: 0.6530 - val_accuracy: 0.6330\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.6261 - val_loss: 0.6505 - val_accuracy: 0.6383\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6429 - val_loss: 0.6507 - val_accuracy: 0.6370\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.6382 - val_loss: 0.6496 - val_accuracy: 0.6377\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.6397 - val_loss: 0.6502 - val_accuracy: 0.6354\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6391 - val_loss: 0.6466 - val_accuracy: 0.6417\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.6379 - val_loss: 0.6464 - val_accuracy: 0.6418\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6372 - val_loss: 0.6444 - val_accuracy: 0.6458\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6380 - accuracy: 0.6452 - val_loss: 0.6439 - val_accuracy: 0.6456\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6378 - accuracy: 0.6456 - val_loss: 0.6437 - val_accuracy: 0.6451\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6362 - accuracy: 0.6526 - val_loss: 0.6448 - val_accuracy: 0.6426\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.6355 - accuracy: 0.6438 - val_loss: 0.6431 - val_accuracy: 0.6450\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 991us/step - loss: 0.6381 - accuracy: 0.6426 - val_loss: 0.6430 - val_accuracy: 0.6448\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6341 - accuracy: 0.6488 - val_loss: 0.6414 - val_accuracy: 0.6478\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6493 - val_loss: 0.6404 - val_accuracy: 0.6492\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.6318 - accuracy: 0.6527 - val_loss: 0.6411 - val_accuracy: 0.6477\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 936us/step - loss: 0.6312 - accuracy: 0.6540 - val_loss: 0.6389 - val_accuracy: 0.6518\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.6482 - val_loss: 0.6400 - val_accuracy: 0.6492\n",
      "\n",
      "Training model with sample_size_ratio=0.25, target_eps=1.0...\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 5.05 iterated over 20900 steps satisfies differential privacy with eps = 0.337 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 2.5749999999999997 iterated over 20900 steps satisfies differential privacy with eps = 0.684 and delta = 1e-05.\n",
      "The optimal RDP order is 35.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.3375 iterated over 20900 steps satisfies differential privacy with eps = 1.51 and delta = 1e-05.\n",
      "The optimal RDP order is 16.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.9562499999999998 iterated over 20900 steps satisfies differential privacy with eps = 0.934 and delta = 1e-05.\n",
      "The optimal RDP order is 26.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.6468749999999999 iterated over 20900 steps satisfies differential privacy with eps = 1.15 and delta = 1e-05.\n",
      "The optimal RDP order is 21.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.8015624999999997 iterated over 20900 steps satisfies differential privacy with eps = 1.03 and delta = 1e-05.\n",
      "The optimal RDP order is 24.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.8789062499999998 iterated over 20900 steps satisfies differential privacy with eps = 0.979 and delta = 1e-05.\n",
      "The optimal RDP order is 25.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.8402343749999996 iterated over 20900 steps satisfies differential privacy with eps = 1 and delta = 1e-05.\n",
      "The optimal RDP order is 24.0.\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.5282 - val_loss: 0.8664 - val_accuracy: 0.1661\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.5318 - val_loss: 0.7810 - val_accuracy: 0.2420\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 935us/step - loss: 0.6997 - accuracy: 0.5342 - val_loss: 0.7394 - val_accuracy: 0.3439\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.6975 - accuracy: 0.5317 - val_loss: 0.7215 - val_accuracy: 0.4034\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5357 - val_loss: 0.7112 - val_accuracy: 0.4451\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6914 - accuracy: 0.5446 - val_loss: 0.7054 - val_accuracy: 0.4675\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5412 - val_loss: 0.7034 - val_accuracy: 0.4819\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5365 - val_loss: 0.7013 - val_accuracy: 0.4907\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5469 - val_loss: 0.6990 - val_accuracy: 0.4973\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5525 - val_loss: 0.6983 - val_accuracy: 0.5013\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5565 - val_loss: 0.6963 - val_accuracy: 0.5090\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 996us/step - loss: 0.6831 - accuracy: 0.5573 - val_loss: 0.6962 - val_accuracy: 0.5128\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5597 - val_loss: 0.6937 - val_accuracy: 0.5232\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5693 - val_loss: 0.6918 - val_accuracy: 0.5307\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 980us/step - loss: 0.6784 - accuracy: 0.5704 - val_loss: 0.6880 - val_accuracy: 0.5443\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5735 - val_loss: 0.6877 - val_accuracy: 0.5475\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 941us/step - loss: 0.6757 - accuracy: 0.5745 - val_loss: 0.6844 - val_accuracy: 0.5586\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.5804 - val_loss: 0.6829 - val_accuracy: 0.5639\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.5816 - val_loss: 0.6818 - val_accuracy: 0.5682\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6717 - accuracy: 0.5819 - val_loss: 0.6791 - val_accuracy: 0.5766\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6687 - accuracy: 0.5854 - val_loss: 0.6784 - val_accuracy: 0.5802\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 943us/step - loss: 0.6648 - accuracy: 0.5963 - val_loss: 0.6787 - val_accuracy: 0.5806\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.5942 - val_loss: 0.6789 - val_accuracy: 0.5801\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.5921 - val_loss: 0.6774 - val_accuracy: 0.5845\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6652 - accuracy: 0.5938 - val_loss: 0.6776 - val_accuracy: 0.5840\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.5977 - val_loss: 0.6733 - val_accuracy: 0.5913\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6020 - val_loss: 0.6731 - val_accuracy: 0.5916\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.6598 - accuracy: 0.6059 - val_loss: 0.6724 - val_accuracy: 0.5927\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.6035 - val_loss: 0.6734 - val_accuracy: 0.5913\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6069 - val_loss: 0.6704 - val_accuracy: 0.5988\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6012 - val_loss: 0.6711 - val_accuracy: 0.5968\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6128 - val_loss: 0.6708 - val_accuracy: 0.5979\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6178 - val_loss: 0.6692 - val_accuracy: 0.5996\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6195 - val_loss: 0.6697 - val_accuracy: 0.5995\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6539 - accuracy: 0.6136 - val_loss: 0.6710 - val_accuracy: 0.5973\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6171 - val_loss: 0.6679 - val_accuracy: 0.6018\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6185 - val_loss: 0.6680 - val_accuracy: 0.6015\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6183 - val_loss: 0.6683 - val_accuracy: 0.6002\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6237 - val_loss: 0.6690 - val_accuracy: 0.5996\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6208 - val_loss: 0.6676 - val_accuracy: 0.6019\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6225 - val_loss: 0.6670 - val_accuracy: 0.6026\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6492 - accuracy: 0.6234 - val_loss: 0.6660 - val_accuracy: 0.6029\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6275 - val_loss: 0.6650 - val_accuracy: 0.6048\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6260 - val_loss: 0.6642 - val_accuracy: 0.6062\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6452 - accuracy: 0.6298 - val_loss: 0.6636 - val_accuracy: 0.6079\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.6295 - val_loss: 0.6646 - val_accuracy: 0.6058\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 999us/step - loss: 0.6458 - accuracy: 0.6234 - val_loss: 0.6618 - val_accuracy: 0.6111\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6327 - val_loss: 0.6608 - val_accuracy: 0.6133\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6309 - val_loss: 0.6589 - val_accuracy: 0.6164\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.6348 - val_loss: 0.6584 - val_accuracy: 0.6169\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7097 - accuracy: 0.5048 - val_loss: 0.7792 - val_accuracy: 0.1476\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 958us/step - loss: 0.7046 - accuracy: 0.5093 - val_loss: 0.7660 - val_accuracy: 0.1674\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 999us/step - loss: 0.7017 - accuracy: 0.5137 - val_loss: 0.7591 - val_accuracy: 0.1787\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.5172 - val_loss: 0.7523 - val_accuracy: 0.1929\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5239 - val_loss: 0.7474 - val_accuracy: 0.2115\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5336 - val_loss: 0.7428 - val_accuracy: 0.2312\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.6915 - accuracy: 0.5431 - val_loss: 0.7399 - val_accuracy: 0.2441\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5470 - val_loss: 0.7350 - val_accuracy: 0.2639\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5507 - val_loss: 0.7321 - val_accuracy: 0.2786\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 953us/step - loss: 0.6856 - accuracy: 0.5576 - val_loss: 0.7297 - val_accuracy: 0.3020\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5662 - val_loss: 0.7254 - val_accuracy: 0.3291\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 935us/step - loss: 0.6797 - accuracy: 0.5672 - val_loss: 0.7224 - val_accuracy: 0.3532\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6780 - accuracy: 0.5761 - val_loss: 0.7199 - val_accuracy: 0.3720\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.6766 - accuracy: 0.5731 - val_loss: 0.7172 - val_accuracy: 0.3893\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6738 - accuracy: 0.5885 - val_loss: 0.7142 - val_accuracy: 0.4022\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.5878 - val_loss: 0.7118 - val_accuracy: 0.4142\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.5956 - val_loss: 0.7114 - val_accuracy: 0.4209\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5943 - val_loss: 0.7085 - val_accuracy: 0.4361\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 946us/step - loss: 0.6698 - accuracy: 0.5977 - val_loss: 0.7074 - val_accuracy: 0.4442\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5979 - val_loss: 0.7057 - val_accuracy: 0.4544\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6653 - accuracy: 0.6075 - val_loss: 0.7037 - val_accuracy: 0.4636\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6646 - accuracy: 0.6115 - val_loss: 0.7029 - val_accuracy: 0.4671\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6615 - accuracy: 0.6150 - val_loss: 0.7007 - val_accuracy: 0.4730\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.6198 - val_loss: 0.7000 - val_accuracy: 0.4758\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6588 - accuracy: 0.6205 - val_loss: 0.6981 - val_accuracy: 0.4826\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 983us/step - loss: 0.6576 - accuracy: 0.6263 - val_loss: 0.6967 - val_accuracy: 0.4877\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6188 - val_loss: 0.6956 - val_accuracy: 0.4917\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6280 - val_loss: 0.6929 - val_accuracy: 0.4992\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6296 - val_loss: 0.6918 - val_accuracy: 0.5041\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6330 - val_loss: 0.6913 - val_accuracy: 0.5071\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6538 - accuracy: 0.6335 - val_loss: 0.6888 - val_accuracy: 0.5165\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6393 - val_loss: 0.6886 - val_accuracy: 0.5166\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6437 - val_loss: 0.6872 - val_accuracy: 0.5208\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 958us/step - loss: 0.6491 - accuracy: 0.6394 - val_loss: 0.6851 - val_accuracy: 0.5281\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6403 - val_loss: 0.6845 - val_accuracy: 0.5300\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6463 - val_loss: 0.6833 - val_accuracy: 0.5320\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 968us/step - loss: 0.6474 - accuracy: 0.6400 - val_loss: 0.6817 - val_accuracy: 0.5370\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.6510 - val_loss: 0.6803 - val_accuracy: 0.5416\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 994us/step - loss: 0.6449 - accuracy: 0.6515 - val_loss: 0.6815 - val_accuracy: 0.5384\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6559 - val_loss: 0.6792 - val_accuracy: 0.5450\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.6529 - val_loss: 0.6768 - val_accuracy: 0.5518\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6411 - accuracy: 0.6511 - val_loss: 0.6766 - val_accuracy: 0.5532\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6551 - val_loss: 0.6749 - val_accuracy: 0.5573\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 993us/step - loss: 0.6381 - accuracy: 0.6581 - val_loss: 0.6721 - val_accuracy: 0.5634\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.6578 - val_loss: 0.6720 - val_accuracy: 0.5625\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.6594 - val_loss: 0.6703 - val_accuracy: 0.5666\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6358 - accuracy: 0.6597 - val_loss: 0.6698 - val_accuracy: 0.5681\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6346 - accuracy: 0.6622 - val_loss: 0.6690 - val_accuracy: 0.5697\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 972us/step - loss: 0.6333 - accuracy: 0.6616 - val_loss: 0.6679 - val_accuracy: 0.5725\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.6601 - val_loss: 0.6672 - val_accuracy: 0.5743\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.8242 - accuracy: 0.4720 - val_loss: 0.5562 - val_accuracy: 0.8658\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 922us/step - loss: 0.7447 - accuracy: 0.4759 - val_loss: 0.6384 - val_accuracy: 0.8033\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.4783 - val_loss: 0.6861 - val_accuracy: 0.5550\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.7180 - accuracy: 0.4861 - val_loss: 0.7112 - val_accuracy: 0.3360\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.4889 - val_loss: 0.7234 - val_accuracy: 0.2726\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 930us/step - loss: 0.7122 - accuracy: 0.4994 - val_loss: 0.7288 - val_accuracy: 0.2563\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.5052 - val_loss: 0.7302 - val_accuracy: 0.2580\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.5147 - val_loss: 0.7307 - val_accuracy: 0.2647\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.5056 - val_loss: 0.7300 - val_accuracy: 0.2738\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7049 - accuracy: 0.5156 - val_loss: 0.7295 - val_accuracy: 0.2846\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.5256 - val_loss: 0.7293 - val_accuracy: 0.2918\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5153 - val_loss: 0.7256 - val_accuracy: 0.3139\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.5271 - val_loss: 0.7244 - val_accuracy: 0.3273\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5271 - val_loss: 0.7235 - val_accuracy: 0.3388\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5382 - val_loss: 0.7222 - val_accuracy: 0.3482\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5388 - val_loss: 0.7234 - val_accuracy: 0.3521\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.5353 - val_loss: 0.7192 - val_accuracy: 0.3722\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 979us/step - loss: 0.6924 - accuracy: 0.5457 - val_loss: 0.7169 - val_accuracy: 0.3870\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6910 - accuracy: 0.5473 - val_loss: 0.7168 - val_accuracy: 0.3948\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5494 - val_loss: 0.7169 - val_accuracy: 0.4006\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5563 - val_loss: 0.7138 - val_accuracy: 0.4165\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5656 - val_loss: 0.7137 - val_accuracy: 0.4210\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5702 - val_loss: 0.7117 - val_accuracy: 0.4329\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.6851 - accuracy: 0.5630 - val_loss: 0.7094 - val_accuracy: 0.4443\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5658 - val_loss: 0.7069 - val_accuracy: 0.4587\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5730 - val_loss: 0.7065 - val_accuracy: 0.4633\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5713 - val_loss: 0.7064 - val_accuracy: 0.4670\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5798 - val_loss: 0.7044 - val_accuracy: 0.4795\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5877 - val_loss: 0.7036 - val_accuracy: 0.4870\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6769 - accuracy: 0.5844 - val_loss: 0.7037 - val_accuracy: 0.4892\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5822 - val_loss: 0.7040 - val_accuracy: 0.4902\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 957us/step - loss: 0.6734 - accuracy: 0.5913 - val_loss: 0.7025 - val_accuracy: 0.4955\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.5896 - val_loss: 0.6998 - val_accuracy: 0.5057\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6733 - accuracy: 0.5961 - val_loss: 0.6984 - val_accuracy: 0.5103\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.5951 - val_loss: 0.6983 - val_accuracy: 0.5106\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.6023 - val_loss: 0.6975 - val_accuracy: 0.5126\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6712 - accuracy: 0.5991 - val_loss: 0.6960 - val_accuracy: 0.5177\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5979 - val_loss: 0.6951 - val_accuracy: 0.5205\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 956us/step - loss: 0.6682 - accuracy: 0.6076 - val_loss: 0.6959 - val_accuracy: 0.5182\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.6091 - val_loss: 0.6958 - val_accuracy: 0.5196\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 952us/step - loss: 0.6653 - accuracy: 0.6120 - val_loss: 0.6931 - val_accuracy: 0.5277\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.6086 - val_loss: 0.6923 - val_accuracy: 0.5306\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.6130 - val_loss: 0.6917 - val_accuracy: 0.5337\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.6189 - val_loss: 0.6913 - val_accuracy: 0.5351\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.6136 - val_loss: 0.6898 - val_accuracy: 0.5402\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.6216 - val_loss: 0.6883 - val_accuracy: 0.5455\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.6637 - accuracy: 0.6154 - val_loss: 0.6886 - val_accuracy: 0.5454\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6607 - accuracy: 0.6242 - val_loss: 0.6872 - val_accuracy: 0.5508\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.6614 - accuracy: 0.6210 - val_loss: 0.6881 - val_accuracy: 0.5495\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6266 - val_loss: 0.6863 - val_accuracy: 0.5562\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7482 - accuracy: 0.4608 - val_loss: 0.6430 - val_accuracy: 0.7944\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7229 - accuracy: 0.4593 - val_loss: 0.6953 - val_accuracy: 0.5008\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.4670 - val_loss: 0.7193 - val_accuracy: 0.3378\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.4673 - val_loss: 0.7275 - val_accuracy: 0.2974\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 882us/step - loss: 0.7104 - accuracy: 0.4791 - val_loss: 0.7311 - val_accuracy: 0.2901\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7062 - accuracy: 0.4816 - val_loss: 0.7305 - val_accuracy: 0.2965\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 919us/step - loss: 0.7053 - accuracy: 0.4895 - val_loss: 0.7297 - val_accuracy: 0.3034\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.4999 - val_loss: 0.7256 - val_accuracy: 0.3306\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.5077 - val_loss: 0.7244 - val_accuracy: 0.3503\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.5018 - val_loss: 0.7231 - val_accuracy: 0.3647\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 906us/step - loss: 0.6949 - accuracy: 0.5153 - val_loss: 0.7211 - val_accuracy: 0.3823\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5135 - val_loss: 0.7189 - val_accuracy: 0.4054\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6906 - accuracy: 0.5290 - val_loss: 0.7174 - val_accuracy: 0.4255\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.7183 - val_accuracy: 0.4334\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5288 - val_loss: 0.7140 - val_accuracy: 0.4620\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.6883 - accuracy: 0.5305 - val_loss: 0.7133 - val_accuracy: 0.4719\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5369 - val_loss: 0.7132 - val_accuracy: 0.4768\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.6846 - accuracy: 0.5409 - val_loss: 0.7114 - val_accuracy: 0.4853\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 979us/step - loss: 0.6840 - accuracy: 0.5402 - val_loss: 0.7097 - val_accuracy: 0.4943\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 902us/step - loss: 0.6817 - accuracy: 0.5502 - val_loss: 0.7081 - val_accuracy: 0.5053\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6839 - accuracy: 0.5443 - val_loss: 0.7079 - val_accuracy: 0.5106\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.6801 - accuracy: 0.5516 - val_loss: 0.7044 - val_accuracy: 0.5260\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5594 - val_loss: 0.7061 - val_accuracy: 0.5210\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 949us/step - loss: 0.6773 - accuracy: 0.5645 - val_loss: 0.7045 - val_accuracy: 0.5289\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 833us/step - loss: 0.6750 - accuracy: 0.5689 - val_loss: 0.7038 - val_accuracy: 0.5304\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.5622 - val_loss: 0.7031 - val_accuracy: 0.5331\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6745 - accuracy: 0.5687 - val_loss: 0.7019 - val_accuracy: 0.5363\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6745 - accuracy: 0.5715 - val_loss: 0.6999 - val_accuracy: 0.5438\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 861us/step - loss: 0.6739 - accuracy: 0.5729 - val_loss: 0.6998 - val_accuracy: 0.5438\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 953us/step - loss: 0.6716 - accuracy: 0.5754 - val_loss: 0.7013 - val_accuracy: 0.5391\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6723 - accuracy: 0.5750 - val_loss: 0.6987 - val_accuracy: 0.5465\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6717 - accuracy: 0.5748 - val_loss: 0.6971 - val_accuracy: 0.5511\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.6681 - accuracy: 0.5831 - val_loss: 0.6969 - val_accuracy: 0.5520\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 870us/step - loss: 0.6682 - accuracy: 0.5801 - val_loss: 0.6966 - val_accuracy: 0.5526\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.6681 - accuracy: 0.5841 - val_loss: 0.6946 - val_accuracy: 0.5569\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.6658 - accuracy: 0.5902 - val_loss: 0.6929 - val_accuracy: 0.5608\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.6676 - accuracy: 0.5887 - val_loss: 0.6914 - val_accuracy: 0.5646\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 878us/step - loss: 0.6665 - accuracy: 0.5913 - val_loss: 0.6899 - val_accuracy: 0.5682\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6678 - accuracy: 0.5854 - val_loss: 0.6893 - val_accuracy: 0.5696\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.6634 - accuracy: 0.5976 - val_loss: 0.6906 - val_accuracy: 0.5672\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.5887 - val_loss: 0.6905 - val_accuracy: 0.5678\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 972us/step - loss: 0.6623 - accuracy: 0.5970 - val_loss: 0.6887 - val_accuracy: 0.5720\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 824us/step - loss: 0.6612 - accuracy: 0.6006 - val_loss: 0.6877 - val_accuracy: 0.5749\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 996us/step - loss: 0.6619 - accuracy: 0.5989 - val_loss: 0.6867 - val_accuracy: 0.5768\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6039 - val_loss: 0.6874 - val_accuracy: 0.5756\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 927us/step - loss: 0.6602 - accuracy: 0.6044 - val_loss: 0.6878 - val_accuracy: 0.5748\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6594 - accuracy: 0.6014 - val_loss: 0.6861 - val_accuracy: 0.5791\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6077 - val_loss: 0.6865 - val_accuracy: 0.5776\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6584 - accuracy: 0.6107 - val_loss: 0.6858 - val_accuracy: 0.5788\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6580 - accuracy: 0.6083 - val_loss: 0.6854 - val_accuracy: 0.5795\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.5219 - val_loss: 0.7835 - val_accuracy: 0.2083\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.5262 - val_loss: 0.7498 - val_accuracy: 0.2819\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 864us/step - loss: 0.7062 - accuracy: 0.5272 - val_loss: 0.7347 - val_accuracy: 0.3394\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 843us/step - loss: 0.6991 - accuracy: 0.5410 - val_loss: 0.7285 - val_accuracy: 0.3726\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.5325 - val_loss: 0.7265 - val_accuracy: 0.3884\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.5371 - val_loss: 0.7221 - val_accuracy: 0.4125\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 827us/step - loss: 0.6936 - accuracy: 0.5438 - val_loss: 0.7175 - val_accuracy: 0.4359\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6951 - accuracy: 0.5435 - val_loss: 0.7165 - val_accuracy: 0.4484\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5520 - val_loss: 0.7122 - val_accuracy: 0.4688\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.6888 - accuracy: 0.5563 - val_loss: 0.7127 - val_accuracy: 0.4754\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 982us/step - loss: 0.6887 - accuracy: 0.5532 - val_loss: 0.7097 - val_accuracy: 0.4928\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 907us/step - loss: 0.6865 - accuracy: 0.5626 - val_loss: 0.7077 - val_accuracy: 0.5034\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 883us/step - loss: 0.6853 - accuracy: 0.5618 - val_loss: 0.7050 - val_accuracy: 0.5144\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5732 - val_loss: 0.7028 - val_accuracy: 0.5235\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 819us/step - loss: 0.6802 - accuracy: 0.5740 - val_loss: 0.7038 - val_accuracy: 0.5234\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.5745 - val_loss: 0.7005 - val_accuracy: 0.5365\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6766 - accuracy: 0.5773 - val_loss: 0.6999 - val_accuracy: 0.5402\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 993us/step - loss: 0.6724 - accuracy: 0.5881 - val_loss: 0.6955 - val_accuracy: 0.5498\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 888us/step - loss: 0.6768 - accuracy: 0.5830 - val_loss: 0.6959 - val_accuracy: 0.5490\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 996us/step - loss: 0.6764 - accuracy: 0.5813 - val_loss: 0.6923 - val_accuracy: 0.5567\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 953us/step - loss: 0.6711 - accuracy: 0.5914 - val_loss: 0.6930 - val_accuracy: 0.5561\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.6708 - accuracy: 0.5905 - val_loss: 0.6928 - val_accuracy: 0.5570\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 968us/step - loss: 0.6681 - accuracy: 0.5992 - val_loss: 0.6896 - val_accuracy: 0.5642\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6668 - accuracy: 0.6021 - val_loss: 0.6878 - val_accuracy: 0.5651\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 948us/step - loss: 0.6651 - accuracy: 0.6004 - val_loss: 0.6865 - val_accuracy: 0.5683\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6009 - val_loss: 0.6829 - val_accuracy: 0.5755\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6630 - accuracy: 0.6035 - val_loss: 0.6827 - val_accuracy: 0.5772\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.6623 - accuracy: 0.6062 - val_loss: 0.6800 - val_accuracy: 0.5828\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 950us/step - loss: 0.6592 - accuracy: 0.6112 - val_loss: 0.6819 - val_accuracy: 0.5804\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 824us/step - loss: 0.6607 - accuracy: 0.6066 - val_loss: 0.6819 - val_accuracy: 0.5802\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6142 - val_loss: 0.6811 - val_accuracy: 0.5828\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.6577 - accuracy: 0.6124 - val_loss: 0.6804 - val_accuracy: 0.5832\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 810us/step - loss: 0.6560 - accuracy: 0.6186 - val_loss: 0.6771 - val_accuracy: 0.5890\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6139 - val_loss: 0.6742 - val_accuracy: 0.5922\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 951us/step - loss: 0.6518 - accuracy: 0.6239 - val_loss: 0.6728 - val_accuracy: 0.5938\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 822us/step - loss: 0.6524 - accuracy: 0.6214 - val_loss: 0.6752 - val_accuracy: 0.5914\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6251 - val_loss: 0.6729 - val_accuracy: 0.5943\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6499 - accuracy: 0.6260 - val_loss: 0.6703 - val_accuracy: 0.5973\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6219 - val_loss: 0.6684 - val_accuracy: 0.5999\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6487 - accuracy: 0.6280 - val_loss: 0.6670 - val_accuracy: 0.6018\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 986us/step - loss: 0.6460 - accuracy: 0.6305 - val_loss: 0.6676 - val_accuracy: 0.6011\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 932us/step - loss: 0.6471 - accuracy: 0.6311 - val_loss: 0.6644 - val_accuracy: 0.6042\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6442 - accuracy: 0.6380 - val_loss: 0.6621 - val_accuracy: 0.6078\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6438 - accuracy: 0.6355 - val_loss: 0.6625 - val_accuracy: 0.6067\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6439 - accuracy: 0.6374 - val_loss: 0.6614 - val_accuracy: 0.6079\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6349 - val_loss: 0.6628 - val_accuracy: 0.6072\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 809us/step - loss: 0.6384 - accuracy: 0.6422 - val_loss: 0.6635 - val_accuracy: 0.6067\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6373 - val_loss: 0.6627 - val_accuracy: 0.6077\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 821us/step - loss: 0.6397 - accuracy: 0.6410 - val_loss: 0.6634 - val_accuracy: 0.6067\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6426 - val_loss: 0.6612 - val_accuracy: 0.6092\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 977us/step - loss: 0.7475 - accuracy: 0.4803 - val_loss: 0.6062 - val_accuracy: 0.8529\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.4845 - val_loss: 0.6552 - val_accuracy: 0.7368\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 948us/step - loss: 0.7098 - accuracy: 0.4983 - val_loss: 0.6851 - val_accuracy: 0.5420\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.7035 - accuracy: 0.5093 - val_loss: 0.7026 - val_accuracy: 0.4123\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.7009 - accuracy: 0.5140 - val_loss: 0.7136 - val_accuracy: 0.3500\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7007 - accuracy: 0.5182 - val_loss: 0.7196 - val_accuracy: 0.3084\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.5192 - val_loss: 0.7238 - val_accuracy: 0.2874\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 944us/step - loss: 0.6971 - accuracy: 0.5215 - val_loss: 0.7264 - val_accuracy: 0.2761\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 898us/step - loss: 0.6978 - accuracy: 0.5194 - val_loss: 0.7271 - val_accuracy: 0.2738\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.6961 - accuracy: 0.5288 - val_loss: 0.7267 - val_accuracy: 0.2761\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 998us/step - loss: 0.6948 - accuracy: 0.5318 - val_loss: 0.7267 - val_accuracy: 0.2777\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 853us/step - loss: 0.6936 - accuracy: 0.5351 - val_loss: 0.7263 - val_accuracy: 0.2815\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6929 - accuracy: 0.5351 - val_loss: 0.7259 - val_accuracy: 0.2838\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 869us/step - loss: 0.6914 - accuracy: 0.5464 - val_loss: 0.7256 - val_accuracy: 0.2888\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6908 - accuracy: 0.5428 - val_loss: 0.7251 - val_accuracy: 0.2945\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 957us/step - loss: 0.6884 - accuracy: 0.5487 - val_loss: 0.7233 - val_accuracy: 0.3071\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 996us/step - loss: 0.6897 - accuracy: 0.5443 - val_loss: 0.7231 - val_accuracy: 0.3112\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 825us/step - loss: 0.6877 - accuracy: 0.5561 - val_loss: 0.7224 - val_accuracy: 0.3178\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.6871 - accuracy: 0.5514 - val_loss: 0.7208 - val_accuracy: 0.3320\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 933us/step - loss: 0.6846 - accuracy: 0.5602 - val_loss: 0.7207 - val_accuracy: 0.3356\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5627 - val_loss: 0.7198 - val_accuracy: 0.3475\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 805us/step - loss: 0.6834 - accuracy: 0.5661 - val_loss: 0.7182 - val_accuracy: 0.3607\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5671 - val_loss: 0.7168 - val_accuracy: 0.3745\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 822us/step - loss: 0.6802 - accuracy: 0.5769 - val_loss: 0.7153 - val_accuracy: 0.3904\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5716 - val_loss: 0.7149 - val_accuracy: 0.3992\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 822us/step - loss: 0.6793 - accuracy: 0.5752 - val_loss: 0.7138 - val_accuracy: 0.4150\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5750 - val_loss: 0.7121 - val_accuracy: 0.4335\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6798 - accuracy: 0.5730 - val_loss: 0.7111 - val_accuracy: 0.4469\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 934us/step - loss: 0.6770 - accuracy: 0.5834 - val_loss: 0.7106 - val_accuracy: 0.4521\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6761 - accuracy: 0.5863 - val_loss: 0.7088 - val_accuracy: 0.4664\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 831us/step - loss: 0.6760 - accuracy: 0.5831 - val_loss: 0.7085 - val_accuracy: 0.4729\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 932us/step - loss: 0.6757 - accuracy: 0.5866 - val_loss: 0.7070 - val_accuracy: 0.4809\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 870us/step - loss: 0.6732 - accuracy: 0.5955 - val_loss: 0.7055 - val_accuracy: 0.4901\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.5976 - val_loss: 0.7045 - val_accuracy: 0.4968\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.6733 - accuracy: 0.5927 - val_loss: 0.7040 - val_accuracy: 0.5006\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.6027 - val_loss: 0.7034 - val_accuracy: 0.5040\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 818us/step - loss: 0.6712 - accuracy: 0.6032 - val_loss: 0.7028 - val_accuracy: 0.5075\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6697 - accuracy: 0.6035 - val_loss: 0.7014 - val_accuracy: 0.5116\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6712 - accuracy: 0.6062 - val_loss: 0.7020 - val_accuracy: 0.5096\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6695 - accuracy: 0.6080 - val_loss: 0.7004 - val_accuracy: 0.5134\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 966us/step - loss: 0.6694 - accuracy: 0.6047 - val_loss: 0.6995 - val_accuracy: 0.5156\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 985us/step - loss: 0.6675 - accuracy: 0.6086 - val_loss: 0.6992 - val_accuracy: 0.5169\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 820us/step - loss: 0.6662 - accuracy: 0.6178 - val_loss: 0.6990 - val_accuracy: 0.5170\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 948us/step - loss: 0.6660 - accuracy: 0.6139 - val_loss: 0.6978 - val_accuracy: 0.5186\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6670 - accuracy: 0.6138 - val_loss: 0.6972 - val_accuracy: 0.5194\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.6212 - val_loss: 0.6971 - val_accuracy: 0.5194\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6643 - accuracy: 0.6254 - val_loss: 0.6961 - val_accuracy: 0.5227\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.6225 - val_loss: 0.6952 - val_accuracy: 0.5257\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6642 - accuracy: 0.6204 - val_loss: 0.6948 - val_accuracy: 0.5268\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.6249 - val_loss: 0.6937 - val_accuracy: 0.5305\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.8174 - accuracy: 0.5277 - val_loss: 1.1361 - val_accuracy: 0.1170\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7538 - accuracy: 0.5273 - val_loss: 0.9930 - val_accuracy: 0.1170\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.5265 - val_loss: 0.9095 - val_accuracy: 0.1170\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.7116 - accuracy: 0.5231 - val_loss: 0.8580 - val_accuracy: 0.1170\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.5182 - val_loss: 0.8247 - val_accuracy: 0.1171\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.5153 - val_loss: 0.8033 - val_accuracy: 0.1171\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 917us/step - loss: 0.7008 - accuracy: 0.5114 - val_loss: 0.7879 - val_accuracy: 0.1174\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6995 - accuracy: 0.5125 - val_loss: 0.7771 - val_accuracy: 0.1183\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 849us/step - loss: 0.6969 - accuracy: 0.5123 - val_loss: 0.7703 - val_accuracy: 0.1197\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5243 - val_loss: 0.7641 - val_accuracy: 0.1215\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 930us/step - loss: 0.6931 - accuracy: 0.5242 - val_loss: 0.7593 - val_accuracy: 0.1237\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5215 - val_loss: 0.7559 - val_accuracy: 0.1272\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 980us/step - loss: 0.6916 - accuracy: 0.5292 - val_loss: 0.7539 - val_accuracy: 0.1324\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6904 - accuracy: 0.5258 - val_loss: 0.7519 - val_accuracy: 0.1436\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 843us/step - loss: 0.6903 - accuracy: 0.5306 - val_loss: 0.7506 - val_accuracy: 0.1591\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5419 - val_loss: 0.7492 - val_accuracy: 0.1751\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 930us/step - loss: 0.6880 - accuracy: 0.5409 - val_loss: 0.7471 - val_accuracy: 0.1943\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6861 - accuracy: 0.5471 - val_loss: 0.7454 - val_accuracy: 0.2171\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 966us/step - loss: 0.6858 - accuracy: 0.5458 - val_loss: 0.7448 - val_accuracy: 0.2353\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6838 - accuracy: 0.5532 - val_loss: 0.7435 - val_accuracy: 0.2520\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 918us/step - loss: 0.6840 - accuracy: 0.5507 - val_loss: 0.7421 - val_accuracy: 0.2631\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.6822 - accuracy: 0.5613 - val_loss: 0.7410 - val_accuracy: 0.2718\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6797 - accuracy: 0.5635 - val_loss: 0.7401 - val_accuracy: 0.2789\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5661 - val_loss: 0.7391 - val_accuracy: 0.2876\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 934us/step - loss: 0.6780 - accuracy: 0.5739 - val_loss: 0.7373 - val_accuracy: 0.2997\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 991us/step - loss: 0.6791 - accuracy: 0.5634 - val_loss: 0.7361 - val_accuracy: 0.3133\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6783 - accuracy: 0.5713 - val_loss: 0.7347 - val_accuracy: 0.3296\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.5817 - val_loss: 0.7329 - val_accuracy: 0.3450\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6750 - accuracy: 0.5829 - val_loss: 0.7310 - val_accuracy: 0.3603\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 962us/step - loss: 0.6740 - accuracy: 0.5822 - val_loss: 0.7299 - val_accuracy: 0.3719\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 946us/step - loss: 0.6747 - accuracy: 0.5851 - val_loss: 0.7284 - val_accuracy: 0.3828\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6715 - accuracy: 0.5890 - val_loss: 0.7274 - val_accuracy: 0.3918\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6722 - accuracy: 0.5891 - val_loss: 0.7262 - val_accuracy: 0.4000\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6716 - accuracy: 0.5884 - val_loss: 0.7244 - val_accuracy: 0.4098\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5908 - val_loss: 0.7235 - val_accuracy: 0.4145\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6696 - accuracy: 0.5973 - val_loss: 0.7226 - val_accuracy: 0.4190\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5977 - val_loss: 0.7220 - val_accuracy: 0.4232\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6685 - accuracy: 0.6007 - val_loss: 0.7213 - val_accuracy: 0.4264\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.5991 - val_loss: 0.7200 - val_accuracy: 0.4312\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6655 - accuracy: 0.6081 - val_loss: 0.7194 - val_accuracy: 0.4362\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 952us/step - loss: 0.6671 - accuracy: 0.6012 - val_loss: 0.7190 - val_accuracy: 0.4385\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6657 - accuracy: 0.6036 - val_loss: 0.7184 - val_accuracy: 0.4408\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 998us/step - loss: 0.6669 - accuracy: 0.6037 - val_loss: 0.7176 - val_accuracy: 0.4443\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 949us/step - loss: 0.6652 - accuracy: 0.6079 - val_loss: 0.7176 - val_accuracy: 0.4454\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.6641 - accuracy: 0.6087 - val_loss: 0.7168 - val_accuracy: 0.4508\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6644 - accuracy: 0.6103 - val_loss: 0.7160 - val_accuracy: 0.4550\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6637 - accuracy: 0.6161 - val_loss: 0.7154 - val_accuracy: 0.4578\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 955us/step - loss: 0.6631 - accuracy: 0.6115 - val_loss: 0.7146 - val_accuracy: 0.4616\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 906us/step - loss: 0.6623 - accuracy: 0.6100 - val_loss: 0.7139 - val_accuracy: 0.4659\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6125 - val_loss: 0.7131 - val_accuracy: 0.4701\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.8090 - accuracy: 0.4732 - val_loss: 0.4969 - val_accuracy: 0.8826\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 989us/step - loss: 0.7334 - accuracy: 0.4849 - val_loss: 0.5602 - val_accuracy: 0.8812\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.4996 - val_loss: 0.6098 - val_accuracy: 0.8658\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5261 - val_loss: 0.6459 - val_accuracy: 0.7764\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6872 - accuracy: 0.5349 - val_loss: 0.6691 - val_accuracy: 0.6624\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5505 - val_loss: 0.6845 - val_accuracy: 0.5503\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 888us/step - loss: 0.6823 - accuracy: 0.5564 - val_loss: 0.6926 - val_accuracy: 0.5074\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5559 - val_loss: 0.6993 - val_accuracy: 0.4794\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 863us/step - loss: 0.6823 - accuracy: 0.5625 - val_loss: 0.7018 - val_accuracy: 0.4714\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 994us/step - loss: 0.6778 - accuracy: 0.5706 - val_loss: 0.7032 - val_accuracy: 0.4693\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 867us/step - loss: 0.6788 - accuracy: 0.5646 - val_loss: 0.7030 - val_accuracy: 0.4743\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 956us/step - loss: 0.6767 - accuracy: 0.5755 - val_loss: 0.7025 - val_accuracy: 0.4807\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6776 - accuracy: 0.5686 - val_loss: 0.7008 - val_accuracy: 0.4959\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 876us/step - loss: 0.6754 - accuracy: 0.5788 - val_loss: 0.7010 - val_accuracy: 0.4995\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 963us/step - loss: 0.6743 - accuracy: 0.5852 - val_loss: 0.7000 - val_accuracy: 0.5116\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 830us/step - loss: 0.6741 - accuracy: 0.5878 - val_loss: 0.6981 - val_accuracy: 0.5242\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.6737 - accuracy: 0.5872 - val_loss: 0.6983 - val_accuracy: 0.5264\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.5886 - val_loss: 0.6981 - val_accuracy: 0.5317\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 979us/step - loss: 0.6700 - accuracy: 0.5969 - val_loss: 0.6983 - val_accuracy: 0.5358\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6697 - accuracy: 0.5915 - val_loss: 0.6978 - val_accuracy: 0.5412\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.6690 - accuracy: 0.5946 - val_loss: 0.6978 - val_accuracy: 0.5451\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6696 - accuracy: 0.5921 - val_loss: 0.6962 - val_accuracy: 0.5549\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 951us/step - loss: 0.6682 - accuracy: 0.5979 - val_loss: 0.6944 - val_accuracy: 0.5619\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.6026 - val_loss: 0.6943 - val_accuracy: 0.5647\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.6063 - val_loss: 0.6931 - val_accuracy: 0.5693\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6644 - accuracy: 0.6094 - val_loss: 0.6933 - val_accuracy: 0.5696\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.6020 - val_loss: 0.6929 - val_accuracy: 0.5723\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6648 - accuracy: 0.6059 - val_loss: 0.6917 - val_accuracy: 0.5755\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.6208 - val_loss: 0.6904 - val_accuracy: 0.5800\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.6115 - val_loss: 0.6897 - val_accuracy: 0.5813\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 832us/step - loss: 0.6614 - accuracy: 0.6153 - val_loss: 0.6902 - val_accuracy: 0.5806\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6617 - accuracy: 0.6121 - val_loss: 0.6890 - val_accuracy: 0.5829\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 873us/step - loss: 0.6597 - accuracy: 0.6199 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.6598 - accuracy: 0.6157 - val_loss: 0.6875 - val_accuracy: 0.5852\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6592 - accuracy: 0.6167 - val_loss: 0.6864 - val_accuracy: 0.5864\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 957us/step - loss: 0.6581 - accuracy: 0.6214 - val_loss: 0.6865 - val_accuracy: 0.5862\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6578 - accuracy: 0.6194 - val_loss: 0.6856 - val_accuracy: 0.5882\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 975us/step - loss: 0.6574 - accuracy: 0.6232 - val_loss: 0.6853 - val_accuracy: 0.5883\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6550 - accuracy: 0.6310 - val_loss: 0.6856 - val_accuracy: 0.5872\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 981us/step - loss: 0.6556 - accuracy: 0.6273 - val_loss: 0.6841 - val_accuracy: 0.5901\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 859us/step - loss: 0.6556 - accuracy: 0.6243 - val_loss: 0.6833 - val_accuracy: 0.5916\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6239 - val_loss: 0.6828 - val_accuracy: 0.5924\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.6237 - val_loss: 0.6820 - val_accuracy: 0.5934\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6286 - val_loss: 0.6812 - val_accuracy: 0.5947\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6527 - accuracy: 0.6312 - val_loss: 0.6804 - val_accuracy: 0.5954\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6357 - val_loss: 0.6794 - val_accuracy: 0.5970\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6500 - accuracy: 0.6383 - val_loss: 0.6786 - val_accuracy: 0.5975\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6483 - accuracy: 0.6407 - val_loss: 0.6773 - val_accuracy: 0.5987\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6357 - val_loss: 0.6760 - val_accuracy: 0.6007\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6494 - accuracy: 0.6378 - val_loss: 0.6764 - val_accuracy: 0.6000\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.8990 - accuracy: 0.4796 - val_loss: 0.4566 - val_accuracy: 0.8828\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.7456 - accuracy: 0.5064 - val_loss: 0.5527 - val_accuracy: 0.8789\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.5404 - val_loss: 0.6192 - val_accuracy: 0.8121\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6876 - accuracy: 0.5544 - val_loss: 0.6563 - val_accuracy: 0.6585\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5583 - val_loss: 0.6757 - val_accuracy: 0.6007\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5617 - val_loss: 0.6882 - val_accuracy: 0.5649\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 944us/step - loss: 0.6829 - accuracy: 0.5563 - val_loss: 0.6927 - val_accuracy: 0.5496\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 966us/step - loss: 0.6808 - accuracy: 0.5619 - val_loss: 0.6950 - val_accuracy: 0.5435\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6771 - accuracy: 0.5701 - val_loss: 0.6945 - val_accuracy: 0.5484\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 932us/step - loss: 0.6786 - accuracy: 0.5725 - val_loss: 0.6951 - val_accuracy: 0.5467\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.5662 - val_loss: 0.6947 - val_accuracy: 0.5498\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6773 - accuracy: 0.5692 - val_loss: 0.6941 - val_accuracy: 0.5525\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.5707 - val_loss: 0.6938 - val_accuracy: 0.5549\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 931us/step - loss: 0.6751 - accuracy: 0.5745 - val_loss: 0.6930 - val_accuracy: 0.5579\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.5785 - val_loss: 0.6914 - val_accuracy: 0.5624\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6725 - accuracy: 0.5801 - val_loss: 0.6909 - val_accuracy: 0.5642\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 977us/step - loss: 0.6724 - accuracy: 0.5832 - val_loss: 0.6898 - val_accuracy: 0.5666\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.5846 - val_loss: 0.6894 - val_accuracy: 0.5675\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 997us/step - loss: 0.6708 - accuracy: 0.5822 - val_loss: 0.6896 - val_accuracy: 0.5666\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.5852 - val_loss: 0.6889 - val_accuracy: 0.5683\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.5917 - val_loss: 0.6887 - val_accuracy: 0.5692\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.5866 - val_loss: 0.6880 - val_accuracy: 0.5708\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.5903 - val_loss: 0.6876 - val_accuracy: 0.5714\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.6657 - accuracy: 0.5922 - val_loss: 0.6873 - val_accuracy: 0.5716\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.5932 - val_loss: 0.6875 - val_accuracy: 0.5704\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 928us/step - loss: 0.6672 - accuracy: 0.5918 - val_loss: 0.6857 - val_accuracy: 0.5741\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6636 - accuracy: 0.5944 - val_loss: 0.6859 - val_accuracy: 0.5730\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6647 - accuracy: 0.5939 - val_loss: 0.6850 - val_accuracy: 0.5748\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6625 - accuracy: 0.5967 - val_loss: 0.6853 - val_accuracy: 0.5741\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 926us/step - loss: 0.6594 - accuracy: 0.6081 - val_loss: 0.6850 - val_accuracy: 0.5737\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 991us/step - loss: 0.6620 - accuracy: 0.5945 - val_loss: 0.6827 - val_accuracy: 0.5782\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.6048 - val_loss: 0.6840 - val_accuracy: 0.5749\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 928us/step - loss: 0.6606 - accuracy: 0.6003 - val_loss: 0.6821 - val_accuracy: 0.5779\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6080 - val_loss: 0.6809 - val_accuracy: 0.5790\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6064 - val_loss: 0.6790 - val_accuracy: 0.5823\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6587 - accuracy: 0.6076 - val_loss: 0.6795 - val_accuracy: 0.5803\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 943us/step - loss: 0.6571 - accuracy: 0.6107 - val_loss: 0.6773 - val_accuracy: 0.5852\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6085 - val_loss: 0.6765 - val_accuracy: 0.5869\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6121 - val_loss: 0.6748 - val_accuracy: 0.5915\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 991us/step - loss: 0.6561 - accuracy: 0.6121 - val_loss: 0.6754 - val_accuracy: 0.5892\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 924us/step - loss: 0.6555 - accuracy: 0.6145 - val_loss: 0.6749 - val_accuracy: 0.5904\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6151 - val_loss: 0.6749 - val_accuracy: 0.5901\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 975us/step - loss: 0.6547 - accuracy: 0.6161 - val_loss: 0.6751 - val_accuracy: 0.5894\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6152 - val_loss: 0.6738 - val_accuracy: 0.5923\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6126 - val_loss: 0.6722 - val_accuracy: 0.5962\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6509 - accuracy: 0.6236 - val_loss: 0.6716 - val_accuracy: 0.5969\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 979us/step - loss: 0.6512 - accuracy: 0.6183 - val_loss: 0.6697 - val_accuracy: 0.6010\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6206 - val_loss: 0.6701 - val_accuracy: 0.5979\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 956us/step - loss: 0.6484 - accuracy: 0.6236 - val_loss: 0.6700 - val_accuracy: 0.5975\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6234 - val_loss: 0.6699 - val_accuracy: 0.5966\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.4845 - val_loss: 0.8014 - val_accuracy: 0.1778\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.4791 - val_loss: 0.7768 - val_accuracy: 0.2077\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7287 - accuracy: 0.4797 - val_loss: 0.7659 - val_accuracy: 0.2180\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.4874 - val_loss: 0.7592 - val_accuracy: 0.2212\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.4909 - val_loss: 0.7558 - val_accuracy: 0.2243\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.4994 - val_loss: 0.7510 - val_accuracy: 0.2358\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.5008 - val_loss: 0.7478 - val_accuracy: 0.2434\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.5031 - val_loss: 0.7444 - val_accuracy: 0.2486\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 981us/step - loss: 0.7072 - accuracy: 0.5123 - val_loss: 0.7418 - val_accuracy: 0.2560\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7023 - accuracy: 0.5213 - val_loss: 0.7377 - val_accuracy: 0.2704\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 951us/step - loss: 0.7013 - accuracy: 0.5258 - val_loss: 0.7354 - val_accuracy: 0.2790\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.5248 - val_loss: 0.7327 - val_accuracy: 0.2935\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.5283 - val_loss: 0.7306 - val_accuracy: 0.3068\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.5309 - val_loss: 0.7288 - val_accuracy: 0.3185\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 931us/step - loss: 0.6947 - accuracy: 0.5348 - val_loss: 0.7268 - val_accuracy: 0.3299\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5371 - val_loss: 0.7261 - val_accuracy: 0.3362\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5498 - val_loss: 0.7237 - val_accuracy: 0.3451\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.6877 - accuracy: 0.5552 - val_loss: 0.7238 - val_accuracy: 0.3483\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5541 - val_loss: 0.7213 - val_accuracy: 0.3611\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 972us/step - loss: 0.6849 - accuracy: 0.5583 - val_loss: 0.7213 - val_accuracy: 0.3667\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5610 - val_loss: 0.7194 - val_accuracy: 0.3764\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5666 - val_loss: 0.7175 - val_accuracy: 0.3887\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 956us/step - loss: 0.6790 - accuracy: 0.5696 - val_loss: 0.7167 - val_accuracy: 0.3996\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5697 - val_loss: 0.7140 - val_accuracy: 0.4196\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6793 - accuracy: 0.5705 - val_loss: 0.7124 - val_accuracy: 0.4313\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5810 - val_loss: 0.7123 - val_accuracy: 0.4368\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 941us/step - loss: 0.6756 - accuracy: 0.5778 - val_loss: 0.7118 - val_accuracy: 0.4443\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.5847 - val_loss: 0.7097 - val_accuracy: 0.4573\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 936us/step - loss: 0.6730 - accuracy: 0.5912 - val_loss: 0.7081 - val_accuracy: 0.4680\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5881 - val_loss: 0.7044 - val_accuracy: 0.4857\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.5940 - val_loss: 0.7035 - val_accuracy: 0.4912\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.6690 - accuracy: 0.5972 - val_loss: 0.7042 - val_accuracy: 0.4922\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.6073 - val_loss: 0.7050 - val_accuracy: 0.4925\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 953us/step - loss: 0.6641 - accuracy: 0.6068 - val_loss: 0.7024 - val_accuracy: 0.5032\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.6657 - accuracy: 0.6056 - val_loss: 0.7007 - val_accuracy: 0.5113\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.6104 - val_loss: 0.6990 - val_accuracy: 0.5195\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6162 - val_loss: 0.6968 - val_accuracy: 0.5292\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.6100 - val_loss: 0.6962 - val_accuracy: 0.5326\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6112 - val_loss: 0.6937 - val_accuracy: 0.5434\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6170 - val_loss: 0.6933 - val_accuracy: 0.5469\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6579 - accuracy: 0.6231 - val_loss: 0.6915 - val_accuracy: 0.5528\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6169 - val_loss: 0.6883 - val_accuracy: 0.5626\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.6247 - val_loss: 0.6880 - val_accuracy: 0.5662\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6219 - val_loss: 0.6865 - val_accuracy: 0.5705\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6519 - accuracy: 0.6334 - val_loss: 0.6858 - val_accuracy: 0.5747\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6304 - val_loss: 0.6835 - val_accuracy: 0.5824\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6512 - accuracy: 0.6380 - val_loss: 0.6801 - val_accuracy: 0.5911\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6486 - accuracy: 0.6381 - val_loss: 0.6820 - val_accuracy: 0.5860\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6352 - val_loss: 0.6806 - val_accuracy: 0.5895\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6504 - accuracy: 0.6369 - val_loss: 0.6794 - val_accuracy: 0.5922\n",
      "\n",
      "Training model with sample_size_ratio=0.25, target_eps=2.0...\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 5.05 iterated over 20900 steps satisfies differential privacy with eps = 0.337 and delta = 1e-05.\n",
      "The optimal RDP order is 63.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 2.5749999999999997 iterated over 20900 steps satisfies differential privacy with eps = 0.684 and delta = 1e-05.\n",
      "The optimal RDP order is 35.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.3375 iterated over 20900 steps satisfies differential privacy with eps = 1.51 and delta = 1e-05.\n",
      "The optimal RDP order is 16.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 0.71875 iterated over 20900 steps satisfies differential privacy with eps = 5.07 and delta = 1e-05.\n",
      "The optimal RDP order is 5.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.028125 iterated over 20900 steps satisfies differential privacy with eps = 2.25 and delta = 1e-05.\n",
      "The optimal RDP order is 11.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.1828124999999998 iterated over 20900 steps satisfies differential privacy with eps = 1.8 and delta = 1e-05.\n",
      "The optimal RDP order is 14.0.\n",
      "DP-SGD with sampling rate = 0.239% and noise_multiplier = 1.10546875 iterated over 20900 steps satisfies differential privacy with eps = 2 and delta = 1e-05.\n",
      "The optimal RDP order is 13.0.\n",
      "Epoch 1/50\n",
      "  1/418 [..............................] - ETA: 0s - loss: 0.7580 - accuracy: 0.4688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7135 - accuracy: 0.5164 - val_loss: 0.8273 - val_accuracy: 0.1392\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.5112 - val_loss: 0.7922 - val_accuracy: 0.1564\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.5056 - val_loss: 0.7696 - val_accuracy: 0.1786\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.5133 - val_loss: 0.7554 - val_accuracy: 0.1989\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.5295 - val_loss: 0.7458 - val_accuracy: 0.2249\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 951us/step - loss: 0.6992 - accuracy: 0.5136 - val_loss: 0.7388 - val_accuracy: 0.2496\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.5179 - val_loss: 0.7333 - val_accuracy: 0.2747\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5312 - val_loss: 0.7309 - val_accuracy: 0.2871\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5344 - val_loss: 0.7275 - val_accuracy: 0.3102\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5307 - val_loss: 0.7242 - val_accuracy: 0.3320\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 995us/step - loss: 0.6913 - accuracy: 0.5337 - val_loss: 0.7222 - val_accuracy: 0.3470\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5467 - val_loss: 0.7213 - val_accuracy: 0.3572\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5368 - val_loss: 0.7203 - val_accuracy: 0.3692\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5467 - val_loss: 0.7178 - val_accuracy: 0.3898\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5516 - val_loss: 0.7163 - val_accuracy: 0.4012\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5540 - val_loss: 0.7163 - val_accuracy: 0.4073\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5506 - val_loss: 0.7138 - val_accuracy: 0.4240\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5594 - val_loss: 0.7128 - val_accuracy: 0.4322\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 994us/step - loss: 0.6835 - accuracy: 0.5594 - val_loss: 0.7115 - val_accuracy: 0.4418\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5647 - val_loss: 0.7101 - val_accuracy: 0.4480\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 992us/step - loss: 0.6832 - accuracy: 0.5573 - val_loss: 0.7103 - val_accuracy: 0.4504\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5675 - val_loss: 0.7094 - val_accuracy: 0.4558\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.5771 - val_loss: 0.7081 - val_accuracy: 0.4635\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.5762 - val_loss: 0.7065 - val_accuracy: 0.4713\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.5750 - val_loss: 0.7054 - val_accuracy: 0.4761\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5787 - val_loss: 0.7042 - val_accuracy: 0.4824\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6764 - accuracy: 0.5768 - val_loss: 0.7045 - val_accuracy: 0.4840\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5835 - val_loss: 0.7042 - val_accuracy: 0.4863\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.5867 - val_loss: 0.7026 - val_accuracy: 0.4935\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6723 - accuracy: 0.5890 - val_loss: 0.7021 - val_accuracy: 0.4967\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6725 - accuracy: 0.5901 - val_loss: 0.7007 - val_accuracy: 0.5014\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5946 - val_loss: 0.6996 - val_accuracy: 0.5071\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.5906 - val_loss: 0.6982 - val_accuracy: 0.5106\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.6019 - val_loss: 0.6978 - val_accuracy: 0.5131\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 930us/step - loss: 0.6692 - accuracy: 0.6004 - val_loss: 0.6972 - val_accuracy: 0.5163\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5982 - val_loss: 0.6966 - val_accuracy: 0.5192\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.6002 - val_loss: 0.6957 - val_accuracy: 0.5229\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.6068 - val_loss: 0.6952 - val_accuracy: 0.5246\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.6065 - val_loss: 0.6944 - val_accuracy: 0.5268\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6097 - val_loss: 0.6929 - val_accuracy: 0.5312\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6104 - val_loss: 0.6916 - val_accuracy: 0.5365\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 957us/step - loss: 0.6634 - accuracy: 0.6138 - val_loss: 0.6908 - val_accuracy: 0.5385\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.6154 - val_loss: 0.6903 - val_accuracy: 0.5402\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6112 - val_loss: 0.6908 - val_accuracy: 0.5403\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.6140 - val_loss: 0.6900 - val_accuracy: 0.5413\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.6125 - val_loss: 0.6889 - val_accuracy: 0.5436\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.6139 - val_loss: 0.6879 - val_accuracy: 0.5465\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6582 - accuracy: 0.6221 - val_loss: 0.6877 - val_accuracy: 0.5461\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6243 - val_loss: 0.6868 - val_accuracy: 0.5496\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 957us/step - loss: 0.6575 - accuracy: 0.6259 - val_loss: 0.6861 - val_accuracy: 0.5517\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7482 - accuracy: 0.5214 - val_loss: 0.9024 - val_accuracy: 0.1268\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.5235 - val_loss: 0.8077 - val_accuracy: 0.1383\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7056 - accuracy: 0.5266 - val_loss: 0.7650 - val_accuracy: 0.1912\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5236 - val_loss: 0.7450 - val_accuracy: 0.2339\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 998us/step - loss: 0.7018 - accuracy: 0.5281 - val_loss: 0.7302 - val_accuracy: 0.2621\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5403 - val_loss: 0.7225 - val_accuracy: 0.2949\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5417 - val_loss: 0.7177 - val_accuracy: 0.3263\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6895 - accuracy: 0.5523 - val_loss: 0.7120 - val_accuracy: 0.3724\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5424 - val_loss: 0.7092 - val_accuracy: 0.4051\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 992us/step - loss: 0.6891 - accuracy: 0.5495 - val_loss: 0.7072 - val_accuracy: 0.4215\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 928us/step - loss: 0.6866 - accuracy: 0.5581 - val_loss: 0.7036 - val_accuracy: 0.4473\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5610 - val_loss: 0.7031 - val_accuracy: 0.4536\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5615 - val_loss: 0.7015 - val_accuracy: 0.4636\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5712 - val_loss: 0.6980 - val_accuracy: 0.4785\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 920us/step - loss: 0.6805 - accuracy: 0.5743 - val_loss: 0.6973 - val_accuracy: 0.4815\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5786 - val_loss: 0.6959 - val_accuracy: 0.4907\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.5822 - val_loss: 0.6934 - val_accuracy: 0.5032\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.5869 - val_loss: 0.6938 - val_accuracy: 0.5012\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.5881 - val_loss: 0.6914 - val_accuracy: 0.5133\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1000us/step - loss: 0.6742 - accuracy: 0.5881 - val_loss: 0.6892 - val_accuracy: 0.5238\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.5881 - val_loss: 0.6895 - val_accuracy: 0.5229\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.5915 - val_loss: 0.6891 - val_accuracy: 0.5252\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 985us/step - loss: 0.6714 - accuracy: 0.5985 - val_loss: 0.6882 - val_accuracy: 0.5301\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.6015 - val_loss: 0.6885 - val_accuracy: 0.5331\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.6017 - val_loss: 0.6882 - val_accuracy: 0.5357\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6088 - val_loss: 0.6865 - val_accuracy: 0.5419\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.6118 - val_loss: 0.6863 - val_accuracy: 0.5420\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 855us/step - loss: 0.6650 - accuracy: 0.6085 - val_loss: 0.6860 - val_accuracy: 0.5457\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 968us/step - loss: 0.6646 - accuracy: 0.6125 - val_loss: 0.6847 - val_accuracy: 0.5507\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6182 - val_loss: 0.6825 - val_accuracy: 0.5561\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 943us/step - loss: 0.6596 - accuracy: 0.6160 - val_loss: 0.6810 - val_accuracy: 0.5605\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6266 - val_loss: 0.6793 - val_accuracy: 0.5647\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6203 - val_loss: 0.6799 - val_accuracy: 0.5605\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6245 - val_loss: 0.6780 - val_accuracy: 0.5698\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.6286 - val_loss: 0.6763 - val_accuracy: 0.5760\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 837us/step - loss: 0.6544 - accuracy: 0.6254 - val_loss: 0.6780 - val_accuracy: 0.5695\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6326 - val_loss: 0.6774 - val_accuracy: 0.5710\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6523 - accuracy: 0.6299 - val_loss: 0.6753 - val_accuracy: 0.5780\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6307 - val_loss: 0.6726 - val_accuracy: 0.5895\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 880us/step - loss: 0.6509 - accuracy: 0.6366 - val_loss: 0.6733 - val_accuracy: 0.5862\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 925us/step - loss: 0.6517 - accuracy: 0.6298 - val_loss: 0.6739 - val_accuracy: 0.5847\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6382 - val_loss: 0.6717 - val_accuracy: 0.5941\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6410 - val_loss: 0.6698 - val_accuracy: 0.5995\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 851us/step - loss: 0.6480 - accuracy: 0.6381 - val_loss: 0.6690 - val_accuracy: 0.6017\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6402 - val_loss: 0.6680 - val_accuracy: 0.6036\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6462 - val_loss: 0.6662 - val_accuracy: 0.6075\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6457 - accuracy: 0.6417 - val_loss: 0.6664 - val_accuracy: 0.6065\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 887us/step - loss: 0.6469 - accuracy: 0.6393 - val_loss: 0.6664 - val_accuracy: 0.6059\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 834us/step - loss: 0.6425 - accuracy: 0.6455 - val_loss: 0.6646 - val_accuracy: 0.6107\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6491 - val_loss: 0.6652 - val_accuracy: 0.6086\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.8112 - accuracy: 0.4799 - val_loss: 0.5341 - val_accuracy: 0.8817\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.4822 - val_loss: 0.6144 - val_accuracy: 0.8714\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 966us/step - loss: 0.7097 - accuracy: 0.4836 - val_loss: 0.6607 - val_accuracy: 0.7306\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.4993 - val_loss: 0.6833 - val_accuracy: 0.5605\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 922us/step - loss: 0.7002 - accuracy: 0.5055 - val_loss: 0.6964 - val_accuracy: 0.4766\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.5033 - val_loss: 0.7017 - val_accuracy: 0.4502\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5141 - val_loss: 0.7046 - val_accuracy: 0.4355\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.6927 - accuracy: 0.5232 - val_loss: 0.7051 - val_accuracy: 0.4360\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5212 - val_loss: 0.7048 - val_accuracy: 0.4461\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.6899 - accuracy: 0.5295 - val_loss: 0.7031 - val_accuracy: 0.4649\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5350 - val_loss: 0.7016 - val_accuracy: 0.4803\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 921us/step - loss: 0.6864 - accuracy: 0.5408 - val_loss: 0.6998 - val_accuracy: 0.4941\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5449 - val_loss: 0.6982 - val_accuracy: 0.5067\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5484 - val_loss: 0.6982 - val_accuracy: 0.5103\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 974us/step - loss: 0.6813 - accuracy: 0.5585 - val_loss: 0.6959 - val_accuracy: 0.5264\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 902us/step - loss: 0.6820 - accuracy: 0.5548 - val_loss: 0.6927 - val_accuracy: 0.5412\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.5612 - val_loss: 0.6939 - val_accuracy: 0.5369\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 986us/step - loss: 0.6771 - accuracy: 0.5663 - val_loss: 0.6907 - val_accuracy: 0.5499\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 848us/step - loss: 0.6763 - accuracy: 0.5706 - val_loss: 0.6895 - val_accuracy: 0.5530\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.5756 - val_loss: 0.6879 - val_accuracy: 0.5611\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 934us/step - loss: 0.6711 - accuracy: 0.5890 - val_loss: 0.6875 - val_accuracy: 0.5633\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.5862 - val_loss: 0.6853 - val_accuracy: 0.5734\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.5916 - val_loss: 0.6838 - val_accuracy: 0.5783\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 901us/step - loss: 0.6679 - accuracy: 0.5920 - val_loss: 0.6818 - val_accuracy: 0.5859\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.6684 - accuracy: 0.5884 - val_loss: 0.6808 - val_accuracy: 0.5874\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.5976 - val_loss: 0.6785 - val_accuracy: 0.5957\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6020 - val_loss: 0.6764 - val_accuracy: 0.6007\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.6058 - val_loss: 0.6743 - val_accuracy: 0.6054\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 898us/step - loss: 0.6634 - accuracy: 0.6026 - val_loss: 0.6729 - val_accuracy: 0.6086\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 890us/step - loss: 0.6630 - accuracy: 0.6062 - val_loss: 0.6715 - val_accuracy: 0.6127\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 987us/step - loss: 0.6606 - accuracy: 0.6174 - val_loss: 0.6703 - val_accuracy: 0.6133\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 931us/step - loss: 0.6580 - accuracy: 0.6180 - val_loss: 0.6689 - val_accuracy: 0.6153\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6121 - val_loss: 0.6683 - val_accuracy: 0.6148\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.6569 - accuracy: 0.6198 - val_loss: 0.6667 - val_accuracy: 0.6173\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6163 - val_loss: 0.6642 - val_accuracy: 0.6237\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6538 - accuracy: 0.6243 - val_loss: 0.6621 - val_accuracy: 0.6291\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6539 - accuracy: 0.6250 - val_loss: 0.6606 - val_accuracy: 0.6319\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6257 - val_loss: 0.6603 - val_accuracy: 0.6310\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 872us/step - loss: 0.6506 - accuracy: 0.6279 - val_loss: 0.6581 - val_accuracy: 0.6359\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6299 - val_loss: 0.6576 - val_accuracy: 0.6353\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6326 - val_loss: 0.6562 - val_accuracy: 0.6370\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6494 - accuracy: 0.6312 - val_loss: 0.6561 - val_accuracy: 0.6359\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 961us/step - loss: 0.6472 - accuracy: 0.6373 - val_loss: 0.6572 - val_accuracy: 0.6325\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.6466 - accuracy: 0.6387 - val_loss: 0.6568 - val_accuracy: 0.6318\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.6376 - val_loss: 0.6546 - val_accuracy: 0.6359\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 978us/step - loss: 0.6459 - accuracy: 0.6374 - val_loss: 0.6521 - val_accuracy: 0.6412\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 911us/step - loss: 0.6438 - accuracy: 0.6390 - val_loss: 0.6541 - val_accuracy: 0.6351\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6452 - accuracy: 0.6408 - val_loss: 0.6532 - val_accuracy: 0.6365\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6423 - val_loss: 0.6516 - val_accuracy: 0.6401\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6407 - accuracy: 0.6453 - val_loss: 0.6507 - val_accuracy: 0.6406\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.5268 - val_loss: 0.8753 - val_accuracy: 0.1275\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5379 - val_loss: 0.8151 - val_accuracy: 0.1422\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5527 - val_loss: 0.7752 - val_accuracy: 0.1818\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.6799 - accuracy: 0.5632 - val_loss: 0.7480 - val_accuracy: 0.2676\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 963us/step - loss: 0.6746 - accuracy: 0.5851 - val_loss: 0.7299 - val_accuracy: 0.3547\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 916us/step - loss: 0.6746 - accuracy: 0.5893 - val_loss: 0.7172 - val_accuracy: 0.4290\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.5958 - val_loss: 0.7079 - val_accuracy: 0.4788\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 842us/step - loss: 0.6694 - accuracy: 0.6045 - val_loss: 0.7010 - val_accuracy: 0.5012\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.6055 - val_loss: 0.6953 - val_accuracy: 0.5208\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.6167 - val_loss: 0.6921 - val_accuracy: 0.5309\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 862us/step - loss: 0.6648 - accuracy: 0.6188 - val_loss: 0.6890 - val_accuracy: 0.5377\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.6231 - val_loss: 0.6860 - val_accuracy: 0.5477\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.6594 - accuracy: 0.6272 - val_loss: 0.6839 - val_accuracy: 0.5563\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6599 - accuracy: 0.6285 - val_loss: 0.6821 - val_accuracy: 0.5687\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 926us/step - loss: 0.6605 - accuracy: 0.6288 - val_loss: 0.6799 - val_accuracy: 0.5749\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 985us/step - loss: 0.6585 - accuracy: 0.6332 - val_loss: 0.6786 - val_accuracy: 0.5772\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 922us/step - loss: 0.6569 - accuracy: 0.6319 - val_loss: 0.6775 - val_accuracy: 0.5795\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6327 - val_loss: 0.6765 - val_accuracy: 0.5811\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6346 - val_loss: 0.6754 - val_accuracy: 0.5823\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6388 - val_loss: 0.6746 - val_accuracy: 0.5830\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6418 - val_loss: 0.6732 - val_accuracy: 0.5847\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 946us/step - loss: 0.6511 - accuracy: 0.6437 - val_loss: 0.6721 - val_accuracy: 0.5863\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6504 - val_loss: 0.6711 - val_accuracy: 0.5884\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6493 - accuracy: 0.6501 - val_loss: 0.6700 - val_accuracy: 0.5895\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 988us/step - loss: 0.6472 - accuracy: 0.6512 - val_loss: 0.6689 - val_accuracy: 0.5916\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 939us/step - loss: 0.6487 - accuracy: 0.6460 - val_loss: 0.6674 - val_accuracy: 0.5925\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.6525 - val_loss: 0.6664 - val_accuracy: 0.5953\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 935us/step - loss: 0.6470 - accuracy: 0.6476 - val_loss: 0.6645 - val_accuracy: 0.5994\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6521 - val_loss: 0.6630 - val_accuracy: 0.6025\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6565 - val_loss: 0.6614 - val_accuracy: 0.6054\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 983us/step - loss: 0.6420 - accuracy: 0.6571 - val_loss: 0.6595 - val_accuracy: 0.6078\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 851us/step - loss: 0.6419 - accuracy: 0.6588 - val_loss: 0.6589 - val_accuracy: 0.6080\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.6394 - accuracy: 0.6597 - val_loss: 0.6575 - val_accuracy: 0.6093\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6378 - accuracy: 0.6657 - val_loss: 0.6562 - val_accuracy: 0.6105\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6367 - accuracy: 0.6636 - val_loss: 0.6557 - val_accuracy: 0.6109\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6610 - val_loss: 0.6546 - val_accuracy: 0.6109\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6663 - val_loss: 0.6536 - val_accuracy: 0.6121\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.6624 - val_loss: 0.6516 - val_accuracy: 0.6159\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 851us/step - loss: 0.6334 - accuracy: 0.6660 - val_loss: 0.6513 - val_accuracy: 0.6161\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6672 - val_loss: 0.6505 - val_accuracy: 0.6185\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 948us/step - loss: 0.6322 - accuracy: 0.6676 - val_loss: 0.6502 - val_accuracy: 0.6190\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.6647 - val_loss: 0.6487 - val_accuracy: 0.6220\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 969us/step - loss: 0.6317 - accuracy: 0.6701 - val_loss: 0.6488 - val_accuracy: 0.6217\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 0.6724 - val_loss: 0.6477 - val_accuracy: 0.6241\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6699 - val_loss: 0.6474 - val_accuracy: 0.6245\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.6284 - accuracy: 0.6718 - val_loss: 0.6466 - val_accuracy: 0.6266\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6681 - val_loss: 0.6451 - val_accuracy: 0.6294\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 977us/step - loss: 0.6270 - accuracy: 0.6724 - val_loss: 0.6439 - val_accuracy: 0.6311\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 937us/step - loss: 0.6262 - accuracy: 0.6773 - val_loss: 0.6436 - val_accuracy: 0.6311\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6266 - accuracy: 0.6710 - val_loss: 0.6433 - val_accuracy: 0.6314\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7640 - accuracy: 0.5011 - val_loss: 0.8961 - val_accuracy: 0.1398\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 898us/step - loss: 0.7324 - accuracy: 0.4899 - val_loss: 0.8110 - val_accuracy: 0.1853\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.4914 - val_loss: 0.7721 - val_accuracy: 0.2406\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.4995 - val_loss: 0.7512 - val_accuracy: 0.3047\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 930us/step - loss: 0.7102 - accuracy: 0.5017 - val_loss: 0.7417 - val_accuracy: 0.3571\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.5070 - val_loss: 0.7354 - val_accuracy: 0.3894\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 934us/step - loss: 0.7048 - accuracy: 0.5176 - val_loss: 0.7289 - val_accuracy: 0.4155\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.5203 - val_loss: 0.7260 - val_accuracy: 0.4275\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.7002 - accuracy: 0.5266 - val_loss: 0.7238 - val_accuracy: 0.4313\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.5263 - val_loss: 0.7166 - val_accuracy: 0.4525\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 878us/step - loss: 0.6949 - accuracy: 0.5346 - val_loss: 0.7146 - val_accuracy: 0.4587\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6934 - accuracy: 0.5408 - val_loss: 0.7124 - val_accuracy: 0.4672\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5480 - val_loss: 0.7089 - val_accuracy: 0.4839\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5510 - val_loss: 0.7072 - val_accuracy: 0.4939\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5634 - val_loss: 0.7065 - val_accuracy: 0.4943\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 873us/step - loss: 0.6830 - accuracy: 0.5645 - val_loss: 0.7060 - val_accuracy: 0.4963\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5644 - val_loss: 0.7055 - val_accuracy: 0.4968\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 889us/step - loss: 0.6795 - accuracy: 0.5694 - val_loss: 0.7019 - val_accuracy: 0.5088\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6790 - accuracy: 0.5653 - val_loss: 0.7010 - val_accuracy: 0.5111\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5749 - val_loss: 0.6995 - val_accuracy: 0.5184\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 994us/step - loss: 0.6747 - accuracy: 0.5798 - val_loss: 0.6976 - val_accuracy: 0.5273\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 947us/step - loss: 0.6768 - accuracy: 0.5783 - val_loss: 0.6960 - val_accuracy: 0.5361\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 976us/step - loss: 0.6722 - accuracy: 0.5820 - val_loss: 0.6956 - val_accuracy: 0.5383\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.5879 - val_loss: 0.6925 - val_accuracy: 0.5434\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6728 - accuracy: 0.5859 - val_loss: 0.6923 - val_accuracy: 0.5442\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.6681 - accuracy: 0.5919 - val_loss: 0.6920 - val_accuracy: 0.5446\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5929 - val_loss: 0.6920 - val_accuracy: 0.5457\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 845us/step - loss: 0.6677 - accuracy: 0.5966 - val_loss: 0.6903 - val_accuracy: 0.5500\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 857us/step - loss: 0.6688 - accuracy: 0.5909 - val_loss: 0.6897 - val_accuracy: 0.5528\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.5935 - val_loss: 0.6889 - val_accuracy: 0.5545\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 993us/step - loss: 0.6626 - accuracy: 0.6053 - val_loss: 0.6874 - val_accuracy: 0.5572\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 846us/step - loss: 0.6593 - accuracy: 0.6109 - val_loss: 0.6863 - val_accuracy: 0.5598\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 860us/step - loss: 0.6633 - accuracy: 0.6044 - val_loss: 0.6844 - val_accuracy: 0.5622\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 965us/step - loss: 0.6612 - accuracy: 0.6056 - val_loss: 0.6857 - val_accuracy: 0.5599\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.6596 - accuracy: 0.6071 - val_loss: 0.6850 - val_accuracy: 0.5603\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6107 - val_loss: 0.6823 - val_accuracy: 0.5640\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 881us/step - loss: 0.6557 - accuracy: 0.6154 - val_loss: 0.6814 - val_accuracy: 0.5657\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6108 - val_loss: 0.6802 - val_accuracy: 0.5687\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 844us/step - loss: 0.6551 - accuracy: 0.6180 - val_loss: 0.6796 - val_accuracy: 0.5692\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6217 - val_loss: 0.6792 - val_accuracy: 0.5685\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 838us/step - loss: 0.6531 - accuracy: 0.6236 - val_loss: 0.6780 - val_accuracy: 0.5695\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.6502 - accuracy: 0.6280 - val_loss: 0.6785 - val_accuracy: 0.5702\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6238 - val_loss: 0.6767 - val_accuracy: 0.5715\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 847us/step - loss: 0.6497 - accuracy: 0.6232 - val_loss: 0.6757 - val_accuracy: 0.5728\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 884us/step - loss: 0.6485 - accuracy: 0.6292 - val_loss: 0.6755 - val_accuracy: 0.5727\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6268 - val_loss: 0.6739 - val_accuracy: 0.5755\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 858us/step - loss: 0.6481 - accuracy: 0.6300 - val_loss: 0.6733 - val_accuracy: 0.5764\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 964us/step - loss: 0.6449 - accuracy: 0.6382 - val_loss: 0.6743 - val_accuracy: 0.5745\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6435 - accuracy: 0.6372 - val_loss: 0.6714 - val_accuracy: 0.5814\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6287 - val_loss: 0.6721 - val_accuracy: 0.5807\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.4850 - val_loss: 0.6205 - val_accuracy: 0.8642\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.4904 - val_loss: 0.6592 - val_accuracy: 0.7761\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 943us/step - loss: 0.7132 - accuracy: 0.4977 - val_loss: 0.6820 - val_accuracy: 0.6085\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.4960 - val_loss: 0.6946 - val_accuracy: 0.4796\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.7091 - accuracy: 0.5038 - val_loss: 0.7015 - val_accuracy: 0.3912\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 978us/step - loss: 0.7094 - accuracy: 0.5052 - val_loss: 0.7060 - val_accuracy: 0.3323\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.5111 - val_loss: 0.7084 - val_accuracy: 0.3059\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7058 - accuracy: 0.5044 - val_loss: 0.7099 - val_accuracy: 0.2914\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.7027 - accuracy: 0.5185 - val_loss: 0.7087 - val_accuracy: 0.2995\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 970us/step - loss: 0.7014 - accuracy: 0.5183 - val_loss: 0.7080 - val_accuracy: 0.3096\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 906us/step - loss: 0.6996 - accuracy: 0.5200 - val_loss: 0.7085 - val_accuracy: 0.3061\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.5206 - val_loss: 0.7077 - val_accuracy: 0.3194\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 868us/step - loss: 0.6962 - accuracy: 0.5327 - val_loss: 0.7074 - val_accuracy: 0.3236\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5307 - val_loss: 0.7056 - val_accuracy: 0.3491\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5341 - val_loss: 0.7044 - val_accuracy: 0.3755\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5372 - val_loss: 0.7042 - val_accuracy: 0.3886\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5374 - val_loss: 0.7036 - val_accuracy: 0.4051\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.6880 - accuracy: 0.5467 - val_loss: 0.7019 - val_accuracy: 0.4255\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5452 - val_loss: 0.7006 - val_accuracy: 0.4420\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 835us/step - loss: 0.6894 - accuracy: 0.5451 - val_loss: 0.6996 - val_accuracy: 0.4538\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5520 - val_loss: 0.6971 - val_accuracy: 0.4759\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 836us/step - loss: 0.6832 - accuracy: 0.5646 - val_loss: 0.6950 - val_accuracy: 0.4939\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 976us/step - loss: 0.6835 - accuracy: 0.5594 - val_loss: 0.6919 - val_accuracy: 0.5172\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 896us/step - loss: 0.6813 - accuracy: 0.5709 - val_loss: 0.6910 - val_accuracy: 0.5215\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 971us/step - loss: 0.6806 - accuracy: 0.5718 - val_loss: 0.6903 - val_accuracy: 0.5275\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5707 - val_loss: 0.6886 - val_accuracy: 0.5399\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 828us/step - loss: 0.6788 - accuracy: 0.5733 - val_loss: 0.6886 - val_accuracy: 0.5388\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.5760 - val_loss: 0.6874 - val_accuracy: 0.5438\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 957us/step - loss: 0.6761 - accuracy: 0.5805 - val_loss: 0.6855 - val_accuracy: 0.5535\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 840us/step - loss: 0.6758 - accuracy: 0.5819 - val_loss: 0.6844 - val_accuracy: 0.5586\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.5883 - val_loss: 0.6826 - val_accuracy: 0.5654\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 831us/step - loss: 0.6741 - accuracy: 0.5838 - val_loss: 0.6820 - val_accuracy: 0.5673\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5811 - val_loss: 0.6826 - val_accuracy: 0.5614\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 885us/step - loss: 0.6734 - accuracy: 0.5863 - val_loss: 0.6816 - val_accuracy: 0.5639\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 973us/step - loss: 0.6736 - accuracy: 0.5850 - val_loss: 0.6824 - val_accuracy: 0.5591\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 905us/step - loss: 0.6710 - accuracy: 0.5908 - val_loss: 0.6804 - val_accuracy: 0.5652\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6698 - accuracy: 0.5955 - val_loss: 0.6803 - val_accuracy: 0.5644\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 894us/step - loss: 0.6681 - accuracy: 0.5952 - val_loss: 0.6801 - val_accuracy: 0.5631\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 878us/step - loss: 0.6684 - accuracy: 0.5982 - val_loss: 0.6792 - val_accuracy: 0.5657\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 941us/step - loss: 0.6670 - accuracy: 0.6060 - val_loss: 0.6791 - val_accuracy: 0.5636\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 868us/step - loss: 0.6665 - accuracy: 0.6029 - val_loss: 0.6787 - val_accuracy: 0.5631\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 839us/step - loss: 0.6655 - accuracy: 0.6049 - val_loss: 0.6765 - val_accuracy: 0.5682\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.6115 - val_loss: 0.6766 - val_accuracy: 0.5662\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 938us/step - loss: 0.6639 - accuracy: 0.6084 - val_loss: 0.6757 - val_accuracy: 0.5684\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 850us/step - loss: 0.6637 - accuracy: 0.6080 - val_loss: 0.6742 - val_accuracy: 0.5718\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6612 - accuracy: 0.6178 - val_loss: 0.6748 - val_accuracy: 0.5683\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6617 - accuracy: 0.6133 - val_loss: 0.6742 - val_accuracy: 0.5695\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 997us/step - loss: 0.6606 - accuracy: 0.6150 - val_loss: 0.6726 - val_accuracy: 0.5740\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6179 - val_loss: 0.6724 - val_accuracy: 0.5724\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 934us/step - loss: 0.6587 - accuracy: 0.6152 - val_loss: 0.6718 - val_accuracy: 0.5723\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7491 - accuracy: 0.4892 - val_loss: 0.5491 - val_accuracy: 0.8784\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7094 - accuracy: 0.5117 - val_loss: 0.6079 - val_accuracy: 0.8665\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6924 - accuracy: 0.5342 - val_loss: 0.6448 - val_accuracy: 0.8317\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 944us/step - loss: 0.6876 - accuracy: 0.5412 - val_loss: 0.6679 - val_accuracy: 0.7058\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5532 - val_loss: 0.6799 - val_accuracy: 0.6168\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6810 - accuracy: 0.5590 - val_loss: 0.6866 - val_accuracy: 0.5789\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5567 - val_loss: 0.6887 - val_accuracy: 0.5643\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 911us/step - loss: 0.6801 - accuracy: 0.5638 - val_loss: 0.6889 - val_accuracy: 0.5634\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5605 - val_loss: 0.6892 - val_accuracy: 0.5644\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.5773 - val_loss: 0.6885 - val_accuracy: 0.5714\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.5796 - val_loss: 0.6875 - val_accuracy: 0.5777\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6746 - accuracy: 0.5758 - val_loss: 0.6857 - val_accuracy: 0.5842\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.5807 - val_loss: 0.6835 - val_accuracy: 0.5903\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.5930 - val_loss: 0.6817 - val_accuracy: 0.5952\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 932us/step - loss: 0.6690 - accuracy: 0.5927 - val_loss: 0.6817 - val_accuracy: 0.5957\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.5983 - val_loss: 0.6802 - val_accuracy: 0.6007\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5957 - val_loss: 0.6794 - val_accuracy: 0.6040\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.6006 - val_loss: 0.6792 - val_accuracy: 0.6061\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 976us/step - loss: 0.6661 - accuracy: 0.5947 - val_loss: 0.6789 - val_accuracy: 0.6072\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.6037 - val_loss: 0.6783 - val_accuracy: 0.6093\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 999us/step - loss: 0.6631 - accuracy: 0.6065 - val_loss: 0.6762 - val_accuracy: 0.6138\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.6068 - val_loss: 0.6760 - val_accuracy: 0.6137\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6621 - accuracy: 0.6039 - val_loss: 0.6752 - val_accuracy: 0.6154\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.6118 - val_loss: 0.6744 - val_accuracy: 0.6167\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6598 - accuracy: 0.6134 - val_loss: 0.6738 - val_accuracy: 0.6171\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6586 - accuracy: 0.6193 - val_loss: 0.6741 - val_accuracy: 0.6163\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6553 - accuracy: 0.6222 - val_loss: 0.6725 - val_accuracy: 0.6193\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6145 - val_loss: 0.6724 - val_accuracy: 0.6182\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6209 - val_loss: 0.6710 - val_accuracy: 0.6200\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6557 - accuracy: 0.6247 - val_loss: 0.6691 - val_accuracy: 0.6227\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1000us/step - loss: 0.6560 - accuracy: 0.6247 - val_loss: 0.6681 - val_accuracy: 0.6240\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6545 - accuracy: 0.6251 - val_loss: 0.6684 - val_accuracy: 0.6234\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6215 - val_loss: 0.6685 - val_accuracy: 0.6226\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6314 - val_loss: 0.6678 - val_accuracy: 0.6224\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6303 - val_loss: 0.6671 - val_accuracy: 0.6229\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6306 - val_loss: 0.6669 - val_accuracy: 0.6227\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 981us/step - loss: 0.6512 - accuracy: 0.6263 - val_loss: 0.6663 - val_accuracy: 0.6230\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6290 - val_loss: 0.6650 - val_accuracy: 0.6251\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6357 - val_loss: 0.6638 - val_accuracy: 0.6262\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6317 - val_loss: 0.6623 - val_accuracy: 0.6287\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.6397 - val_loss: 0.6618 - val_accuracy: 0.6291\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 996us/step - loss: 0.6455 - accuracy: 0.6354 - val_loss: 0.6612 - val_accuracy: 0.6305\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6378 - val_loss: 0.6596 - val_accuracy: 0.6341\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 929us/step - loss: 0.6438 - accuracy: 0.6382 - val_loss: 0.6582 - val_accuracy: 0.6360\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 940us/step - loss: 0.6439 - accuracy: 0.6419 - val_loss: 0.6589 - val_accuracy: 0.6345\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6382 - val_loss: 0.6573 - val_accuracy: 0.6368\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 930us/step - loss: 0.6425 - accuracy: 0.6448 - val_loss: 0.6571 - val_accuracy: 0.6365\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6404 - accuracy: 0.6444 - val_loss: 0.6547 - val_accuracy: 0.6420\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6422 - val_loss: 0.6555 - val_accuracy: 0.6399\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.6465 - val_loss: 0.6550 - val_accuracy: 0.6406\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.8316 - accuracy: 0.5193 - val_loss: 1.0920 - val_accuracy: 0.1205\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.5229 - val_loss: 0.8996 - val_accuracy: 0.1251\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.5353 - val_loss: 0.8082 - val_accuracy: 0.1764\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5416 - val_loss: 0.7634 - val_accuracy: 0.2640\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6869 - accuracy: 0.5528 - val_loss: 0.7401 - val_accuracy: 0.3244\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5613 - val_loss: 0.7285 - val_accuracy: 0.3696\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 996us/step - loss: 0.6820 - accuracy: 0.5609 - val_loss: 0.7203 - val_accuracy: 0.3975\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6807 - accuracy: 0.5655 - val_loss: 0.7161 - val_accuracy: 0.4189\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6798 - accuracy: 0.5721 - val_loss: 0.7122 - val_accuracy: 0.4384\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6779 - accuracy: 0.5703 - val_loss: 0.7096 - val_accuracy: 0.4492\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.5822 - val_loss: 0.7071 - val_accuracy: 0.4614\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.5838 - val_loss: 0.7065 - val_accuracy: 0.4657\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.5932 - val_loss: 0.7057 - val_accuracy: 0.4714\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.5919 - val_loss: 0.7034 - val_accuracy: 0.4837\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.5945 - val_loss: 0.7006 - val_accuracy: 0.4971\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.5999 - val_loss: 0.7007 - val_accuracy: 0.5001\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6654 - accuracy: 0.5997 - val_loss: 0.6988 - val_accuracy: 0.5093\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6647 - accuracy: 0.6046 - val_loss: 0.6968 - val_accuracy: 0.5174\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.6129 - val_loss: 0.6942 - val_accuracy: 0.5266\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.6167 - val_loss: 0.6924 - val_accuracy: 0.5327\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 963us/step - loss: 0.6594 - accuracy: 0.6114 - val_loss: 0.6907 - val_accuracy: 0.5372\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6161 - val_loss: 0.6900 - val_accuracy: 0.5405\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 985us/step - loss: 0.6561 - accuracy: 0.6147 - val_loss: 0.6883 - val_accuracy: 0.5467\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6228 - val_loss: 0.6876 - val_accuracy: 0.5490\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6252 - val_loss: 0.6864 - val_accuracy: 0.5527\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6231 - val_loss: 0.6851 - val_accuracy: 0.5558\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6243 - val_loss: 0.6843 - val_accuracy: 0.5581\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 1000us/step - loss: 0.6499 - accuracy: 0.6301 - val_loss: 0.6837 - val_accuracy: 0.5602\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6337 - val_loss: 0.6821 - val_accuracy: 0.5636\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6349 - val_loss: 0.6815 - val_accuracy: 0.5662\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6331 - val_loss: 0.6801 - val_accuracy: 0.5697\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6332 - val_loss: 0.6794 - val_accuracy: 0.5726\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6462 - accuracy: 0.6374 - val_loss: 0.6790 - val_accuracy: 0.5735\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 993us/step - loss: 0.6448 - accuracy: 0.6366 - val_loss: 0.6799 - val_accuracy: 0.5712\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6449 - accuracy: 0.6361 - val_loss: 0.6786 - val_accuracy: 0.5735\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6436 - accuracy: 0.6407 - val_loss: 0.6778 - val_accuracy: 0.5746\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.6376 - val_loss: 0.6744 - val_accuracy: 0.5824\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6417 - accuracy: 0.6416 - val_loss: 0.6752 - val_accuracy: 0.5810\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6398 - val_loss: 0.6742 - val_accuracy: 0.5837\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6459 - val_loss: 0.6753 - val_accuracy: 0.5809\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 997us/step - loss: 0.6404 - accuracy: 0.6441 - val_loss: 0.6740 - val_accuracy: 0.5834\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.6385 - accuracy: 0.6473 - val_loss: 0.6739 - val_accuracy: 0.5838\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.6456 - val_loss: 0.6717 - val_accuracy: 0.5869\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6491 - val_loss: 0.6714 - val_accuracy: 0.5868\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6369 - accuracy: 0.6485 - val_loss: 0.6705 - val_accuracy: 0.5886\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6530 - val_loss: 0.6691 - val_accuracy: 0.5906\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6367 - accuracy: 0.6477 - val_loss: 0.6678 - val_accuracy: 0.5924\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6358 - accuracy: 0.6492 - val_loss: 0.6668 - val_accuracy: 0.5941\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6531 - val_loss: 0.6648 - val_accuracy: 0.5987\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6349 - accuracy: 0.6522 - val_loss: 0.6646 - val_accuracy: 0.5988\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7283 - accuracy: 0.5290 - val_loss: 0.8089 - val_accuracy: 0.1664\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.5283 - val_loss: 0.7587 - val_accuracy: 0.2763\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.7165 - accuracy: 0.5310 - val_loss: 0.7347 - val_accuracy: 0.3705\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.5386 - val_loss: 0.7218 - val_accuracy: 0.4431\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.5398 - val_loss: 0.7152 - val_accuracy: 0.4746\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 987us/step - loss: 0.7073 - accuracy: 0.5435 - val_loss: 0.7104 - val_accuracy: 0.4959\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 959us/step - loss: 0.7013 - accuracy: 0.5490 - val_loss: 0.7071 - val_accuracy: 0.5107\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5538 - val_loss: 0.7037 - val_accuracy: 0.5210\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.5522 - val_loss: 0.7022 - val_accuracy: 0.5250\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5606 - val_loss: 0.6998 - val_accuracy: 0.5314\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5623 - val_loss: 0.6988 - val_accuracy: 0.5328\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5687 - val_loss: 0.6969 - val_accuracy: 0.5377\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 980us/step - loss: 0.6863 - accuracy: 0.5763 - val_loss: 0.6951 - val_accuracy: 0.5442\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 952us/step - loss: 0.6805 - accuracy: 0.5807 - val_loss: 0.6928 - val_accuracy: 0.5490\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5773 - val_loss: 0.6886 - val_accuracy: 0.5609\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5794 - val_loss: 0.6860 - val_accuracy: 0.5659\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5900 - val_loss: 0.6838 - val_accuracy: 0.5708\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5852 - val_loss: 0.6833 - val_accuracy: 0.5703\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.5952 - val_loss: 0.6810 - val_accuracy: 0.5762\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.5976 - val_loss: 0.6794 - val_accuracy: 0.5785\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.5975 - val_loss: 0.6807 - val_accuracy: 0.5746\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.6003 - val_loss: 0.6803 - val_accuracy: 0.5741\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.5955 - val_loss: 0.6791 - val_accuracy: 0.5761\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6690 - accuracy: 0.5994 - val_loss: 0.6771 - val_accuracy: 0.5811\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6678 - accuracy: 0.6069 - val_loss: 0.6760 - val_accuracy: 0.5841\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6126 - val_loss: 0.6759 - val_accuracy: 0.5822\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.6170 - val_loss: 0.6727 - val_accuracy: 0.5891\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 992us/step - loss: 0.6617 - accuracy: 0.6138 - val_loss: 0.6733 - val_accuracy: 0.5854\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6198 - val_loss: 0.6711 - val_accuracy: 0.5908\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6612 - accuracy: 0.6166 - val_loss: 0.6705 - val_accuracy: 0.5921\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6577 - accuracy: 0.6196 - val_loss: 0.6682 - val_accuracy: 0.5975\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6219 - val_loss: 0.6682 - val_accuracy: 0.5960\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.6215 - val_loss: 0.6678 - val_accuracy: 0.5960\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6281 - val_loss: 0.6661 - val_accuracy: 0.6008\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 994us/step - loss: 0.6557 - accuracy: 0.6234 - val_loss: 0.6645 - val_accuracy: 0.6036\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6314 - val_loss: 0.6625 - val_accuracy: 0.6070\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6376 - val_loss: 0.6638 - val_accuracy: 0.6039\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6337 - val_loss: 0.6615 - val_accuracy: 0.6084\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6326 - val_loss: 0.6617 - val_accuracy: 0.6064\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 993us/step - loss: 0.6453 - accuracy: 0.6382 - val_loss: 0.6619 - val_accuracy: 0.6048\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.6426 - val_loss: 0.6615 - val_accuracy: 0.6039\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 945us/step - loss: 0.6436 - accuracy: 0.6389 - val_loss: 0.6603 - val_accuracy: 0.6050\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6382 - val_loss: 0.6578 - val_accuracy: 0.6090\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.6422 - val_loss: 0.6566 - val_accuracy: 0.6098\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6390 - accuracy: 0.6509 - val_loss: 0.6548 - val_accuracy: 0.6132\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 978us/step - loss: 0.6404 - accuracy: 0.6486 - val_loss: 0.6542 - val_accuracy: 0.6127\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6527 - val_loss: 0.6543 - val_accuracy: 0.6111\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6361 - accuracy: 0.6524 - val_loss: 0.6531 - val_accuracy: 0.6127\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.6531 - val_loss: 0.6510 - val_accuracy: 0.6172\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6521 - val_loss: 0.6513 - val_accuracy: 0.6150\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.8265 - accuracy: 0.4861 - val_loss: 0.4944 - val_accuracy: 0.8831\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.7132 - accuracy: 0.5189 - val_loss: 0.5909 - val_accuracy: 0.8790\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5372 - val_loss: 0.6420 - val_accuracy: 0.7610\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.6871 - accuracy: 0.5490 - val_loss: 0.6637 - val_accuracy: 0.6440\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 0s 954us/step - loss: 0.6835 - accuracy: 0.5548 - val_loss: 0.6738 - val_accuracy: 0.5956\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5571 - val_loss: 0.6789 - val_accuracy: 0.5779\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5585 - val_loss: 0.6772 - val_accuracy: 0.5819\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5620 - val_loss: 0.6764 - val_accuracy: 0.5851\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 0s 975us/step - loss: 0.6809 - accuracy: 0.5609 - val_loss: 0.6744 - val_accuracy: 0.5901\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 0s 951us/step - loss: 0.6794 - accuracy: 0.5591 - val_loss: 0.6731 - val_accuracy: 0.5935\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.5740 - val_loss: 0.6728 - val_accuracy: 0.5924\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5662 - val_loss: 0.6722 - val_accuracy: 0.5936\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 0s 957us/step - loss: 0.6774 - accuracy: 0.5629 - val_loss: 0.6692 - val_accuracy: 0.6035\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 0s 999us/step - loss: 0.6708 - accuracy: 0.5783 - val_loss: 0.6679 - val_accuracy: 0.6081\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5773 - val_loss: 0.6672 - val_accuracy: 0.6124\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5808 - val_loss: 0.6660 - val_accuracy: 0.6180\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.5841 - val_loss: 0.6643 - val_accuracy: 0.6244\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.5884 - val_loss: 0.6630 - val_accuracy: 0.6276\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 0s 995us/step - loss: 0.6641 - accuracy: 0.5881 - val_loss: 0.6619 - val_accuracy: 0.6290\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.5889 - val_loss: 0.6625 - val_accuracy: 0.6258\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.5937 - val_loss: 0.6636 - val_accuracy: 0.6215\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6606 - accuracy: 0.5969 - val_loss: 0.6632 - val_accuracy: 0.6216\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.5925 - val_loss: 0.6613 - val_accuracy: 0.6265\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.5997 - val_loss: 0.6602 - val_accuracy: 0.6283\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.6010 - val_loss: 0.6588 - val_accuracy: 0.6315\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 0s 982us/step - loss: 0.6587 - accuracy: 0.5952 - val_loss: 0.6581 - val_accuracy: 0.6323\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.6017 - val_loss: 0.6576 - val_accuracy: 0.6321\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 0s 999us/step - loss: 0.6551 - accuracy: 0.6068 - val_loss: 0.6568 - val_accuracy: 0.6335\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.6065 - val_loss: 0.6585 - val_accuracy: 0.6291\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6109 - val_loss: 0.6560 - val_accuracy: 0.6331\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6143 - val_loss: 0.6576 - val_accuracy: 0.6298\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6144 - val_loss: 0.6561 - val_accuracy: 0.6310\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 0.6526 - accuracy: 0.6133 - val_loss: 0.6522 - val_accuracy: 0.6393\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 0s 960us/step - loss: 0.6498 - accuracy: 0.6116 - val_loss: 0.6520 - val_accuracy: 0.6387\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 0s 895us/step - loss: 0.6495 - accuracy: 0.6189 - val_loss: 0.6514 - val_accuracy: 0.6394\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6218 - val_loss: 0.6509 - val_accuracy: 0.6403\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6205 - val_loss: 0.6492 - val_accuracy: 0.6425\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 0s 998us/step - loss: 0.6481 - accuracy: 0.6167 - val_loss: 0.6522 - val_accuracy: 0.6359\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.6251 - val_loss: 0.6502 - val_accuracy: 0.6392\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6206 - val_loss: 0.6510 - val_accuracy: 0.6363\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 0s 944us/step - loss: 0.6441 - accuracy: 0.6258 - val_loss: 0.6492 - val_accuracy: 0.6403\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6281 - val_loss: 0.6469 - val_accuracy: 0.6447\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 0s 927us/step - loss: 0.6428 - accuracy: 0.6253 - val_loss: 0.6493 - val_accuracy: 0.6393\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.6249 - val_loss: 0.6479 - val_accuracy: 0.6409\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6306 - val_loss: 0.6480 - val_accuracy: 0.6404\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.6317 - val_loss: 0.6496 - val_accuracy: 0.6361\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 0s 994us/step - loss: 0.6388 - accuracy: 0.6352 - val_loss: 0.6454 - val_accuracy: 0.6454\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6385 - accuracy: 0.6317 - val_loss: 0.6452 - val_accuracy: 0.6450\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6392 - val_loss: 0.6437 - val_accuracy: 0.6476\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 0s 913us/step - loss: 0.6348 - accuracy: 0.6413 - val_loss: 0.6435 - val_accuracy: 0.6472\n"
     ]
    }
   ],
   "source": [
    "# 2. Vary sample_size_ratio with target epsilon\n",
    "results_sample_size = {}\n",
    "eps_sample_size = {}\n",
    "noise_sample_size = {}\n",
    "for ssr in sample_size_ratio_values:\n",
    "    for target_eps in target_eps_values:\n",
    "        print(f\"\\nTraining model with sample_size_ratio={ssr}, target_eps={target_eps}...\")\n",
    "        X_sub, y_sub = subsample_data(X_train_filtered, y_train_filtered, ssr)\n",
    "        n = len(X_sub)\n",
    "        num_microbatches = min(default_batch_size // 4, default_batch_size)\n",
    "        noise_multiplier, eps = adjust_noise_multiplier(n, default_batch_size, epochs, target_eps, delta)\n",
    "        results = run_iterations(\n",
    "            X_sub, y_sub, X_test_filtered, y_test_filtered,\n",
    "            batch_size=default_batch_size, epochs=epochs, use_dp=True, n_iterations=n_iterations,\n",
    "            num_microbatches=num_microbatches, l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier\n",
    "        )\n",
    "        key = (ssr, target_eps)\n",
    "        results_sample_size[key] = compute_statistics(results)\n",
    "        eps_sample_size[key] = eps\n",
    "        noise_sample_size[key] = noise_multiplier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89d44c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to 'results/CDP_adjusted_results.csv'\n",
      "\n",
      "Results (Averages):\n",
      "                No DP (mean)  batch_size=16 (=0.50, noise=1.47) (mean)  \\\n",
      "ROC AUC              0.9004                                     0.7573   \n",
      "Accuracy             0.8067                                     0.5518   \n",
      "Precision            0.3622                                     0.1824   \n",
      "Recall               0.8525                                     0.8127   \n",
      "F1 Score             0.5081                                     0.2979   \n",
      "Type I Error         0.1994                                     0.4828   \n",
      "Type II Error        0.1475                                     0.1873   \n",
      "\n",
      "               batch_size=16 (=0.99, noise=1.01) (mean)  \\\n",
      "ROC AUC                                           0.7559   \n",
      "Accuracy                                          0.5414   \n",
      "Precision                                         0.1797   \n",
      "Recall                                            0.8181   \n",
      "F1 Score                                          0.2946   \n",
      "Type I Error                                      0.4953   \n",
      "Type II Error                                     0.1819   \n",
      "\n",
      "               batch_size=16 (=2.00, noise=0.74) (mean)  \\\n",
      "ROC AUC                                           0.7586   \n",
      "Accuracy                                          0.5547   \n",
      "Precision                                         0.1835   \n",
      "Recall                                            0.8129   \n",
      "F1 Score                                          0.2994   \n",
      "Type I Error                                      0.4795   \n",
      "Type II Error                                     0.1871   \n",
      "\n",
      "               batch_size=32 (=0.51, noise=1.80) (mean)  \\\n",
      "ROC AUC                                           0.7301   \n",
      "Accuracy                                          0.4807   \n",
      "Precision                                         0.1654   \n",
      "Recall                                            0.8447   \n",
      "F1 Score                                          0.2764   \n",
      "Type I Error                                      0.5676   \n",
      "Type II Error                                     0.1553   \n",
      "\n",
      "               batch_size=32 (=0.99, noise=1.14) (mean)  \\\n",
      "ROC AUC                                           0.7316   \n",
      "Accuracy                                          0.4925   \n",
      "Precision                                         0.1675   \n",
      "Recall                                            0.8402   \n",
      "F1 Score                                          0.2793   \n",
      "Type I Error                                      0.5535   \n",
      "Type II Error                                     0.1598   \n",
      "\n",
      "               batch_size=32 (=2.01, noise=0.81) (mean)  \\\n",
      "ROC AUC                                           0.7321   \n",
      "Accuracy                                          0.4918   \n",
      "Precision                                         0.1674   \n",
      "Recall                                            0.8402   \n",
      "F1 Score                                          0.2791   \n",
      "Type I Error                                      0.5544   \n",
      "Type II Error                                     0.1598   \n",
      "\n",
      "               batch_size=64 (=0.50, noise=2.50) (mean)  \\\n",
      "ROC AUC                                           0.7139   \n",
      "Accuracy                                          0.4091   \n",
      "Precision                                         0.1525   \n",
      "Recall                                            0.8876   \n",
      "F1 Score                                          0.2603   \n",
      "Type I Error                                      0.6543   \n",
      "Type II Error                                     0.1124   \n",
      "\n",
      "               batch_size=64 (=0.99, noise=1.40) (mean)  \\\n",
      "ROC AUC                                           0.7115   \n",
      "Accuracy                                          0.4091   \n",
      "Precision                                         0.1526   \n",
      "Recall                                            0.8871   \n",
      "F1 Score                                          0.2603   \n",
      "Type I Error                                      0.6542   \n",
      "Type II Error                                     0.1129   \n",
      "\n",
      "               batch_size=64 (=2.00, noise=0.92) (mean)  ...  \\\n",
      "ROC AUC                                           0.7124  ...   \n",
      "Accuracy                                          0.3931  ...   \n",
      "Precision                                         0.1499  ...   \n",
      "Recall                                            0.8950  ...   \n",
      "F1 Score                                          0.2567  ...   \n",
      "Type I Error                                      0.6735  ...   \n",
      "Type II Error                                     0.1050  ...   \n",
      "\n",
      "               batch_size=128 (=2.00, noise=1.11) (mean)  \\\n",
      "ROC AUC                                            0.6847   \n",
      "Accuracy                                           0.2323   \n",
      "Precision                                          0.1299   \n",
      "Recall                                             0.9667   \n",
      "F1 Score                                           0.2288   \n",
      "Type I Error                                       0.8650   \n",
      "Type II Error                                      0.0333   \n",
      "\n",
      "               sample_size_ratio=1 (=0.51, noise=1.80) (mean)  \\\n",
      "ROC AUC                                                 0.7383   \n",
      "Accuracy                                                0.5008   \n",
      "Precision                                               0.1699   \n",
      "Recall                                                  0.8390   \n",
      "F1 Score                                                0.2825   \n",
      "Type I Error                                            0.5440   \n",
      "Type II Error                                           0.1610   \n",
      "\n",
      "               sample_size_ratio=1 (=0.99, noise=1.14) (mean)  \\\n",
      "ROC AUC                                                 0.7344   \n",
      "Accuracy                                                0.4937   \n",
      "Precision                                               0.1677   \n",
      "Recall                                                  0.8387   \n",
      "F1 Score                                                0.2794   \n",
      "Type I Error                                            0.5520   \n",
      "Type II Error                                           0.1613   \n",
      "\n",
      "               sample_size_ratio=1 (=2.01, noise=0.81) (mean)  \\\n",
      "ROC AUC                                                 0.7340   \n",
      "Accuracy                                                0.4923   \n",
      "Precision                                               0.1680   \n",
      "Recall                                                  0.8436   \n",
      "F1 Score                                                0.2802   \n",
      "Type I Error                                            0.5543   \n",
      "Type II Error                                           0.1564   \n",
      "\n",
      "               sample_size_ratio=0.5 (=0.50, noise=2.50) (mean)  \\\n",
      "ROC AUC                                                   0.7079   \n",
      "Accuracy                                                  0.3866   \n",
      "Precision                                                 0.1491   \n",
      "Recall                                                    0.8981   \n",
      "F1 Score                                                  0.2556   \n",
      "Type I Error                                              0.6812   \n",
      "Type II Error                                             0.1019   \n",
      "\n",
      "               sample_size_ratio=0.5 (=0.99, noise=1.40) (mean)  \\\n",
      "ROC AUC                                                   0.7082   \n",
      "Accuracy                                                  0.4033   \n",
      "Precision                                                 0.1515   \n",
      "Recall                                                    0.8880   \n",
      "F1 Score                                                  0.2587   \n",
      "Type I Error                                              0.6609   \n",
      "Type II Error                                             0.1120   \n",
      "\n",
      "               sample_size_ratio=0.5 (=2.00, noise=0.92) (mean)  \\\n",
      "ROC AUC                                                   0.7063   \n",
      "Accuracy                                                  0.3643   \n",
      "Precision                                                 0.1465   \n",
      "Recall                                                    0.9095   \n",
      "F1 Score                                                  0.2520   \n",
      "Type I Error                                              0.7079   \n",
      "Type II Error                                             0.0905   \n",
      "\n",
      "               sample_size_ratio=0.25 (=0.49, noise=3.50) (mean)  \\\n",
      "ROC AUC                                                   0.6903    \n",
      "Accuracy                                                  0.2361    \n",
      "Precision                                                 0.1300    \n",
      "Recall                                                    0.9617    \n",
      "F1 Score                                                  0.2287    \n",
      "Type I Error                                              0.8600    \n",
      "Type II Error                                             0.0383    \n",
      "\n",
      "               sample_size_ratio=0.25 (=1.00, noise=1.84) (mean)  \\\n",
      "ROC AUC                                                   0.6757    \n",
      "Accuracy                                                  0.2042    \n",
      "Precision                                                 0.1257    \n",
      "Recall                                                    0.9682    \n",
      "F1 Score                                                  0.2224    \n",
      "Type I Error                                              0.8970    \n",
      "Type II Error                                             0.0318    \n",
      "\n",
      "               sample_size_ratio=0.25 (=2.00, noise=1.11) (mean)  \n",
      "ROC AUC                                                   0.6907   \n",
      "Accuracy                                                  0.2625   \n",
      "Precision                                                 0.1324   \n",
      "Recall                                                    0.9485   \n",
      "F1 Score                                                  0.2322   \n",
      "Type I Error                                              0.8284   \n",
      "Type II Error                                             0.0515   \n",
      "\n",
      "[7 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save results to CSV\n",
    "results_stats = {\n",
    "    'batch_size': results_batch_size,\n",
    "    'sample_size_ratio': results_sample_size\n",
    "}\n",
    "data = {}\n",
    "\n",
    "# Add results for non-DP model\n",
    "data['No DP (mean)'] = results_no_dp_stats['mean']\n",
    "data['No DP (min)'] = results_no_dp_stats['min']\n",
    "data['No DP (max)'] = results_no_dp_stats['max']\n",
    "\n",
    "# Add results for DP models\n",
    "for param, stats_dict in results_stats.items():\n",
    "    for (value, target_eps), stats in stats_dict.items():\n",
    "        eps = eps_batch_size.get((value, target_eps), float('inf')) if param == 'batch_size' else eps_sample_size.get((value, target_eps), float('inf'))\n",
    "        noise = noise_batch_size.get((value, target_eps), 0) if param == 'batch_size' else noise_sample_size.get((value, target_eps), 0)\n",
    "        model = f'{param}={value} (={eps:.2f}, noise={noise:.2f})'\n",
    "        data[f'{model} (mean)'] = stats['mean']\n",
    "        data[f'{model} (min)'] = stats['min']\n",
    "        data[f'{model} (max)'] = stats['max']\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(data).round(4)\n",
    "results_df.to_csv('results/CDP_adjusted_results.csv')\n",
    "print(\"\\nResults saved to 'results/CDP_adjusted_results.csv'\")\n",
    "print(\"\\nResults (Averages):\\n\", results_df[[col for col in results_df.columns if 'mean' in col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40266d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to plot results, including No DP model\n",
    "def plot_parameter_results(stats_dict, eps_dict, noise_dict, param_name, colors, no_dp_stats):\n",
    "    metrics = list(no_dp_stats['mean'].keys())\n",
    "    values = sorted(set(val for val, _ in stats_dict.keys()))\n",
    "    eps_values = sorted(set(eps for _, eps in stats_dict.keys()))\n",
    "    n_metrics = len(metrics)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x_positions = np.arange(n_metrics)\n",
    "    \n",
    "    # Plot No DP model\n",
    "    means = [no_dp_stats['mean'][metric] for metric in metrics]\n",
    "    mins = [no_dp_stats['min'][metric] for metric in metrics]\n",
    "    maxs = [no_dp_stats['max'][metric] for metric in metrics]\n",
    "    plt.scatter(x_positions, means, color=colors[0], label='No DP', s=100)\n",
    "    for metric_idx in range(n_metrics):\n",
    "        plt.vlines(x_positions[metric_idx], mins[metric_idx], maxs[metric_idx], color=colors[0], linestyle='-', linewidth=1)\n",
    "    \n",
    "    # Plot results for each combination\n",
    "    color_idx = 1\n",
    "    for value in values:\n",
    "        for target_eps in eps_values:\n",
    "            key = (value, target_eps)\n",
    "            if key in stats_dict:\n",
    "                means = [stats_dict[key]['mean'][metric] for metric in metrics]\n",
    "                mins = [stats_dict[key]['min'][metric] for metric in metrics]\n",
    "                maxs = [stats_dict[key]['max'][metric] for metric in metrics]\n",
    "                noise = noise_dict[key]\n",
    "                plt.scatter(x_positions + (color_idx - len(values) * len(eps_values) / 2) * 0.1, means, \n",
    "                            color=colors[color_idx % len(colors)], \n",
    "                            label=f'{param_name}={value} (={eps_dict[key]:.2f}, noise={noise:.2f})', s=100)\n",
    "                for metric_idx in range(n_metrics):\n",
    "                    plt.vlines(x_positions[metric_idx] + (color_idx - len(values) * len(eps_values) / 2) * 0.1, \n",
    "                               mins[metric_idx], maxs[metric_idx], \n",
    "                               color=colors[color_idx % len(colors)], linestyle='-', linewidth=1)\n",
    "                color_idx += 1\n",
    "    \n",
    "    plt.xticks(x_positions, metrics, rotation=45)\n",
    "    plt.title(f'Effect of Varying {param_name} on Model Performance')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(title=f'{param_name} Configurations', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/Effect_of_{param_name}_adjusted.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db74f182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJoAAAJOCAYAAAD/Fm2FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXxM1/vA8c8kkslkFxKxJJJKEBEERewtEvtOLZVQWqpqK1qtrfRLfdFSaqs2KVVq/6q1EWKJpWopRf1EEUsSS3ZZZLm/P9JMMzJJJgup9nm/XvNizj333nPv3JnMfeac56gURVEQQgghhBBCCCGEEKKEjMq6AUIIIYQQQgghhBDin0ECTUIIIYQQQgghhBCiVEigSQghhBBCCCGEEEKUCgk0CSGEEEIIIYQQQohSIYEmIYQQQgghhBBCCFEqJNAkhBBCCCGEEEIIIUqFBJqEEEIIIYQQQgghRKmQQJMQQgghhBBCCCGEKBUSaBJCCCGEEEIIIYQQpUICTeIfJSkpiREjRuDo6IhKpWL8+PEAREdH07dvXypUqIBKpWLx4sVl2s6iyO+YXhQuLi4MHTq0rJvxwggKCkKlUnHz5s1/5f6fNbkei2bo0KG4uLgUa922bdvStm3bUm1PSV27dg1fX19sbGxQqVTs2LGjrJskhBBCCPGPI4Em8beXc+Ob3+PkyZPaunPnziUoKIi3336bdevWMWTIEAAmTJjA/v37mTp1KuvWraNjx46l3s65c+c+k5uW/I4pt7Nnz6JSqZg2bVq+27l27RoqlYqJEyeWehuF+Ds5fvw4s2bNIi4urqybUmpyPu9GjBihd/lHH32krfPw4cPn3LqScXFx0flMd3BwoFWrVmzfvr3U9xUQEMDFixf5z3/+w7p162jcuHGp70MIIYQQ4t9OpSiKUtaNEKIgQUFBDBs2jNmzZ+Pq6ppneceOHalYsSIAzZo1o1y5chw7dkynjqOjI+3bt+e77757Zu20tLSkb9++BAUFlep28zump3l4ePDkyROuX7+ud/nHH3/MrFmzOHPmDA0bNizVNhYkLS0NIyMjTExMnts+X2Q51/uNGzeK3ZOkJDIzM0lPT0etVqNSqZ77/kvDwoULmTx5st5z+KJejyqVCjMzM8zMzIiOjsbU1FRn+UsvvURkZCSpqak8ePBA+5lYUkOHDiU0NLRYPdxyejOFhoYWWM/FxYXy5cvz3nvvAXDv3j1WrVrFH3/8wYoVKxg1alSR961PSkoK5ubmfPTRR3zyySelsk0hhBBCCJFXubJugBCG6tSpU6G/Pt+/f586deroLbe1tX1GLXu28jumpw0ePJjp06dz8uRJmjVrlmf5hg0bqF27domDTMnJyZibmxtcX61Wl2h/4vkyNjbG2Ni4rJuh4/Hjx1hYWJTKtl7k67Fjx47s3LmTvXv30qNHD2358ePHuXHjBn369GHr1q1l2MLiq1q1Kq+//rr2ub+/P25ubnz++eclDjSlpqZiamrKgwcPAEr1b0FpXptCCCGEEP8UMnRO/COEhoaiUqm4ceMGu3fv1g7ByBl2pygKX375pbY8R1xcHOPHj8fJyQm1Wo2bmxvz588nKytLZ/tZWVksWbIELy8vzMzMsLe3p2PHjvzyyy9Adm+Dx48f8+2332r3UVgemPv37zN8+HAqVaqEmZkZ9evX59tvvy30mPLrWTB48GAAvv/++zzLzpw5w9WrV7V1/ve//9GlSxeqVKmCWq2mRo0azJkzh8zMTJ312rZtS926dTlz5gytW7fG3NycDz/8kICAACpWrEh6enqeffn6+lKrVi3t86dz4uS8JmFhYUycOBF7e3ssLCzo1auX9kYwR1ZWFrNmzaJKlSqYm5vzyiuvcPnyZYPz7GzcuJFGjRphZWWFtbU1Xl5eLFmyRLs8JiaGSZMm4eXlhaWlJdbW1nTq1Ilff/1VZzs5r8WmTZv4+OOPqVq1KlZWVvTt25f4+HjS0tIYP348Dg4OWFpaMmzYMNLS0nS2oVKpGDNmDOvXr6dWrVqYmZnRqFEjjhw5UuhxAOzdu5dWrVphYWGBlZUVXbp04dKlSwatm9vSpUvx9PTE3Nyc8uXL07hxY51r5ukcTbNmzcp32Gru1yArK4vFixfj6emJmZkZlSpVYuTIkcTGxhapfTn7u3z5MoMGDaJ8+fK0bNkSgAsXLjB06FBeeuklzMzMcHR05I033uDRo0c660+ePBkAV1fXPO8bfdfOH3/8Qb9+/bCzs8Pc3JxmzZqxe/dug9qbkZHBnDlzqFGjBmq1GhcXFz788MM8r7+Liwtdu3bl2LFjNGnSBDMzM1566SXWrl1r8LmpWrUqrVu3zvMeX79+PV5eXtStW1fveps3b6ZRo0ZoNBoqVqzI66+/zt27d/PU27FjB3Xr1sXMzIy6devmO3SttF7rgjg6OuLh4cGNGze0ZXfv3uWNN96gUqVKqNVqPD09+eabb3TWy3mvbty4kWnTplG1alXMzc2ZOHEi1atXB2Dy5MmoVCqd3m7nzp2jU6dOWFtbY2lpSbt27XSGZcNf743Dhw8zevRoHBwcqFatGvDXZ+WFCxdo06YN5ubmuLm5sWXLFgAOHz5M06ZN0Wg01KpViwMHDuhs+9atW4wePZpatWqh0WioUKEC/fr1y/N5X5TPT8j+3GjTpo32M/Dll1/Oc/2cOnWKjh07YmNjg7m5OW3atCEsLMyAV0kIIYQQQj/p0SReGPHx8Xlyj6hUKipUqICHhwfr1q1jwoQJVKtWTTsEw9vbW5vXqEOHDvj7+2vXTU5Opk2bNty9e5eRI0fi7OzM8ePHmTp1KpGRkToJw4cPH05QUBCdOnVixIgRZGRkcPToUU6ePEnjxo1Zt24dI0aMoEmTJrz11lsA1KhRI99jSUlJoW3btoSHhzNmzBhcXV3ZvHkzQ4cOJS4ujnHjxuV7TPb29nq36erqSvPmzdm0aROff/65Tq+UnBuLQYMGAdk3K5aWlkycOBFLS0sOHjzIjBkzSEhIYMGCBTrbffToEZ06dWLAgAG8/vrrVKpUCQsLC9auXcv+/fvp2rWrtm5UVBQHDx5k5syZ+R57jnfffZfy5cszc+ZMbt68yeLFixkzZgw//PCDts7UqVP573//S7du3fDz8+PXX3/Fz8+P1NTUQrcfHBzMwIEDadeuHfPnzwfgypUrhIWFMW7cOCA7wLBjxw769euHq6sr0dHRrFq1ijZt2nD58mWqVKmis8158+ah0Wj44IMPCA8PZ+nSpZiYmGBkZERsbCyzZs3i5MmTBAUF4erqyowZM3TWP3z4MD/88ANjx45FrVazfPlyOnbsyM8//5xvkABg3bp1BAQE4Ofnx/z580lOTmbFihW0bNmSc+fOGTzE7quvvmLs2LH07duXcePGkZqayoULFzh16pT22nha7969cXNz0yk7c+YMixcvxsHBQVs2cuRI7bC/sWPHcuPGDZYtW8a5c+cICwsr8lC1fv364e7uzty5c8kZ4R0cHMwff/zBsGHDcHR05NKlS6xevZpLly5x8uRJVCoVvXv35v/+7//YsGEDn3/+uXYIWX7vm+joaJo3b05ycjJjx46lQoUKfPvtt3Tv3p0tW7bQq1evAts5YsQIvv32W/r27ct7773HqVOnmDdvHleuXMkTqAkPD6dv374MHz6cgIAAvvnmG4YOHUqjRo3w9PQ06LwMGjSIcePGkZSUhKWlJRkZGWzevJmJEyfqfV/kvCYvv/wy8+bNIzo6miVLlhAWFsa5c+e0vXt++ukn+vTpQ506dZg3bx6PHj1i2LBh2kBKbqX9WuuTnp7O7du3qVChApD9OjVr1kwbsLW3t2fv3r0MHz6chISEPJMkzJkzB1NTUyZNmkRaWhqdO3fGxcWFCRMmMHDgQDp37oylpSUAly5dolWrVlhbWzNlyhRMTExYtWoVbdu21QaIchs9ejT29vbMmDGDx48fa8tjY2Pp2rUrAwYMoF+/fqxYsYIBAwawfv16xo8fz6hRoxg0aBALFiygb9++3L59GysrKwBOnz7N8ePHGTBgANWqVePmzZusWLGCtm3bcvny5Ty9SA35/AwKCuKNN97A09OTqVOnYmtry7lz59i3b5/2/X7w4EE6depEo0aNmDlzJkZGRgQGBvLqq69y9OhRmjRpUuLXUgghhBD/QooQf3OBgYEKoPehVqt16lavXl3p0qVLnm0AyjvvvKNTNmfOHMXCwkL5v//7P53yDz74QDE2NlYiIiIURVGUgwcPKoAyduzYPNvNysrS/t/CwkIJCAgw6JgWL16sAMp3332nLXvy5Ini4+OjWFpaKgkJCYUekz5ffvmlAij79+/XlmVmZipVq1ZVfHx8tGXJycl51h05cqRibm6upKamasvatGmjAMrKlSt16mZmZirVqlVTXnvtNZ3yzz77TFGpVMoff/yh0/7c5yXn9Wzfvr3O+ZswYYJibGysxMXFKYqiKFFRUUq5cuWUnj176uxj1qxZClDouR43bpxibW2tZGRk5FsnNTVVyczM1Cm7ceOGolarldmzZ2vLDh06pABK3bp1lSdPnmjLBw4cqKhUKqVTp0462/Dx8VGqV6+uU5Zzzf7yyy/aslu3bilmZmZKr169tGU55+fGjRuKoihKYmKiYmtrq7z55ps624uKilJsbGzylBekR48eiqenZ4F1nt7/0x48eKA4OzsrXl5eSlJSkqIoinL06FEFUNavX69Td9++fXrLCzJz5kwFUAYOHJhnmb7rdsOGDQqgHDlyRFu2YMGCfI/h6etx/PjxCqAcPXpUW5aYmKi4uroqLi4uea6P3M6fP68AyogRI3TKJ02apADKwYMHdfb7dDvv37+vqNVq5b333st3HzlyPsNiYmIUU1NTZd26dYqiKMru3bsVlUql3Lx5U3vuHjx4oChK9meKg4ODUrduXSUlJUW7rV27dimAMmPGDG1ZgwYNlMqVK2vff4qiKD/99JMC6FzLRXmt27Rpo7Rp06bQY6tevbri6+urPHjwQHnw4IHy66+/KgMGDFAA5d1331UURVGGDx+uVK5cWXn48KHOugMGDFBsbGy010bOe/Wll17Kc73cuHFDAZQFCxbolPfs2VMxNTVVrl+/ri27d++eYmVlpbRu3VpblvPeaNmyZZ7PlZzPyu+//15b9vvvvyuAYmRkpJw8eVJbvn//fgVQAgMDtWX6ru0TJ04ogLJ27do8bSjs8zMuLk6xsrJSmjZtqvPaK8pff7eysrIUd3d3xc/PT2dbycnJiqurq9KhQ4c8bRJCCCGEMIQMnRMvjC+//JLg4GCdx969e4u9vc2bN9OqVSvKly/Pw4cPtY/27duTmZmpHdK0detWVCqV3l46xU2WvGfPHhwdHRk4cKC2zMTEhLFjx5KUlMThw4eLtd3XXnsNExMTnaERhw8f5u7du9phcwAajUb7/8TERB4+fEirVq1ITk7m999/19mmWq1m2LBhOmVGRkYMHjyYnTt3kpiYqC1fv349zZs315u0/WlvvfWWzvlr1aoVmZmZ3Lp1C4CQkBAyMjIYPXq0znrvvvtuoduG7Dwsjx8/Jjg4ON86arUaI6Psj8HMzEwePXqEpaUltWrV4uzZs3nq+/v76/TWaNq0KYqi8MYbb+jUa9q0Kbdv3yYjI0On3MfHh0aNGmmfOzs706NHD/bv359n2GKO4OBg4uLiGDhwoM51amxsTNOmTTl06FDhJ+NPtra23Llzh9OnTxu8Tm6ZmZkMHDiQxMREtm/frs1Ns3nzZmxsbOjQoYNOGxs1aoSlpWWR2phDX16e3NdtamoqDx8+1OYj0/d6GWLPnj00adJEOzwPshP7v/XWW9y8eZPLly8XuC6QZybHnN6HTw+/q1OnDq1atdI+t7e3p1atWvzxxx8Gt7d8+fJ07NiRDRs2ANm9FZs3b64dFpbbL7/8wv379xk9ejRmZmba8i5dulC7dm1t+yIjIzl//jwBAQHY2Nho63Xo0CFPfrhn8VpDdo8qe3t77O3tqV+/Pps3b2bIkCHMnz8fRVHYunUr3bp1Q1EUnf36+fkRHx+f5/UPCAjQuV7yk5mZyU8//UTPnj156aWXtOWVK1dm0KBBHDt2jISEBJ113nzzTb15zCwtLRkwYID2ea1atbC1tcXDw0OnV1TO/3O/7rnbmp6ezqNHj3Bzc8PW1lbvtV3Y52dwcDCJiYl88MEHOq89/PV36/z581y7do1Bgwbx6NEj7Tl9/Pgx7dq148iRI3mGkQshhBBCGEKGzokXRpMmTUp1Kupr165x4cKFfIfU3L9/H4Dr169TpUoV7OzsSm3ft27dwt3dXRvkyOHh4aFdXhwVKlTAz8+P7du3s3LlSszMzPj+++8pV64c/fv319a7dOkS06ZN4+DBg3luouLj43WeV61aNc8MV5AddJk/fz7bt2/H39+fq1evcubMGVauXGlQW52dnXWely9fHkCb5yXnHDw9bMvOzk5btyCjR49m06ZNdOrUiapVq+Lr60v//v3p2LGjtk5O7q3ly5dz48YNnWBPzpCdgtqcc1Pu5OSUpzwrK4v4+Hid7bi7u+fZZs2aNUlOTubBgwc4OjrmWX7t2jUAXn31Vb3HaW1trbdcn/fff58DBw7QpEkT3Nzc8PX1ZdCgQbRo0cKg9XOumd27d+sMDb127Rrx8fE6Q+lyy3kvFYW+YGVMTAwff/wxGzduzLPNp69bQ926dSvP0CjQfS/mN6zx1q1bGBkZ5blGHR0dsbW1zfM+fvr6gezrvqi5jQYNGsSQIUOIiIhgx44d/Pe//823fYBOzrQctWvX1s5kmVNP3/X5dND1WbzWkB18+eSTT1CpVJibm+Ph4aEd1nf//n3i4uJYvXo1q1evNmi/hgS7AR48eEBycrLec+Th4UFWVha3b9/WGdqY37arVauW58cHGxsbvZ8PgM7rnpKSwrx58wgMDOTu3bva4aKg/9ou7PMzZ/bRgobk5ny2BAQE5FsnPj7eoM9bIYQQQojcJNAk/rWysrLo0KEDU6ZM0bu8Zs2az7lFpeP1119n165d7Nq1i+7du7N161Z8fX21AbW4uDjatGmDtbU1s2fPpkaNGpiZmXH27Fnef//9PL9g59croE6dOjRq1IjvvvsOf39/vvvuO0xNTXUCWgXJb2az3DdYJeHg4MD58+fZv38/e/fuZe/evQQGBuLv769Nuj537lymT5/OG2+8wZw5c7Czs8PIyIjx48fr/SU/vzY/y2PJace6dev0BqLKlTP8Y9zDw4OrV6+ya9cu9u3bx9atW1m+fDkzZszg448/LnDdHTt2MH/+fObMmaMTrMtpo4ODA+vXr9e7bn7B3ILou+769+/P8ePHmTx5Mg0aNMDS0pKsrCw6duxYpj0vDO3ZWFrXSffu3VGr1QQEBJCWlmbwe640PIvXGqBixYq0b98+331C9mdbfkGRevXq6Tw3pDdTceW37ZJ8Prz77rsEBgYyfvx4fHx8sLGxQaVSMWDAgCJ9FhXlWsrZ7oIFC2jQoIHeOjl5rIQQQgghikICTeJfq0aNGiQlJeV7c5O73v79+4mJiSmwV1NRhtFVr16dCxcukJWVpdOrKWfYmr5hMIbq3r07VlZWfP/995iYmBAbG6szbC40NJRHjx6xbds2WrdurS3PPbuTofz9/Zk4cSKRkZF8//33dOnSpdR+/c45B+Hh4To9CB49emRwDxBTU1O6detGt27dyMrKYvTo0axatYrp06drZ4R65ZVX+Prrr3XWi4uL0yaRLk05PQhy+7//+z/Mzc3zvUHP6Tnk4OBQ6LVqCAsLC1577TVee+01njx5Qu/evfnPf/7D1KlT8wyxyd3GgIAAevbsyYcffqi3jQcOHKBFixbP7AY/NjaWkJAQPv74Y50k6/rOaVHfi1evXs1Tbsh7sXr16mRlZXHt2jVtDyjITlwdFxdXovdxQTQaDT179uS7776jU6dO+V6rOfu/evVqnh5xV69e1S7P+VffuXz63DyP1/pp9vb2WFlZkZmZWSrvgae3bW5unu81YGRklKdH0rOwZcsWAgICWLRokbYsNTWVuLi4Ym0v53Pjt99+y9Pj7uk61tbWpX5ehRBCCPHvJjmaxL9W//79OXHiBPv378+zLC4uTptfp0+fPiiKorfHR+5fjy0sLAy+KejcuTNRUVE6MwRlZGSwdOlSLC0tadOmTRGP5i8ajYZevXqxZ88eVqxYgYWFBT169NAuz/klPHfbnzx5wvLly4u8r4EDB6JSqRg3bhx//PEHr7/+erHb/bR27dpRrlw5VqxYoVO+bNkyg9bPPeU9ZOeVyun1kDP1vLGxcZ4eAJs3b9Y79XtpOHHihM4wpNu3b/O///0PX1/ffHso+Pn5YW1tzdy5c0lPT8+zXN+U5vl5+pyYmppSp04dFEXRu22ApKQkevXqRdWqVfn222/1BnH69+9PZmYmc+bMybMsIyOj2DfLuem7bgGd2SFz5OSOMmS/nTt35ueff+bEiRPassePH7N69WpcXFzy5Ch6el19bfjss8+A7FxIz8qkSZOYOXMm06dPz7dO48aNcXBwYOXKldprHrKnvL9y5Yq2fZUrV6ZBgwZ8++23OsO0goOD8+Soeh6v9dOMjY3p06cPW7du5bfffsuzvCjvAX3b9vX15X//+x83b97UlkdHR/P999/TsmXLIg1PLUk7nr62ly5dmm/utsL4+vpiZWXFvHnz8sxGmLOfRo0aUaNGDRYuXEhSUlKebZTkvAohhBDi3016NIkXxt69e/MkqgZo3ry5ThJXQ02ePJmdO3fStWtX7RTjjx8/5uLFi2zZsoWbN29SsWJFXnnlFYYMGcIXX3zBtWvXtMN0jh49yiuvvMKYMWOA7C/tBw4c4LPPPqNKlSq4urrqzf0C2YlcV61axdChQzlz5gwuLi5s2bKFsLAwFi9erJ3yurhef/111q5dy/79+xk8eLD2xhuyz1f58uUJCAhg7NixqFQq1q1bV6xhXvb29nTs2JHNmzdja2tbqjfWlSpVYty4cSxatIju3bvTsWNHfv31V/bu3UvFihUL7bUyYsQIYmJiePXVV6lWrRq3bt1i6dKlNGjQQNv7pGvXrsyePZthw4bRvHlzLl68yPr164t1PRmibt26+Pn5MXbsWNRqtTa4V9CwNWtra1asWMGQIUNo2LAhAwYMwN7enoiICHbv3k2LFi0MDr75+vri6OhIixYtqFSpEleuXGHZsmV06dIl32vu448/5vLly0ybNo3//e9/Ostq1KiBj48Pbdq0YeTIkcybN4/z58/j6+uLiYkJ165dY/PmzSxZsoS+ffsaeJbyPw+tW7fmv//9L+np6VStWpWffvpJb0+8nITrH330EQMGDMDExIRu3brpvA9yfPDBB2zYsIFOnToxduxY7Ozs+Pbbb7lx4wZbt27Nk0ctt/r16xMQEMDq1au1Q1J//vlnvv32W3r27Mkrr7xSomMuSP369alfv36BdUxMTJg/fz7Dhg2jTZs2DBw4kOjoaJYsWYKLiwsTJkzQ1p03bx5dunShZcuWvPHGG8TExLB06VI8PT11ghDP47XW59NPP+XQoUM0bdqUN998kzp16hATE8PZs2c5cOAAMTExxd72J598QnBwMC1btmT06NGUK1eOVatWkZaWlm/+q9LWtWtX1q1bh42NDXXq1OHEiRMcOHBAb644Q1hbW/P5558zYsQIXn75ZQYNGkT58uX59ddfSU5O5ttvv8XIyIg1a9bQqVMnPD09GTZsGFWrVuXu3bscOnQIa2trfvzxx1I+UiGEEEL8Kzzvae6EKKqc6Zzze+SeIrp69epKly5d8myDP6cGf1piYqIydepUxc3NTTE1NVUqVqyoNG/eXFm4cKHONPYZGRnKggULlNq1ayumpqaKvb290qlTJ+XMmTPaOr///rvSunVrRaPRKIDOFOr6REdHK8OGDVMqVqyomJqaKl5eXjrHUtgxFSQjI0OpXLmyAih79uzJszwsLExp1qyZotFolCpVqihTpkzRTrl96NAhbb02bdoonp6eBe5r06ZNCqC89dZbepc/PZ18zut5+vRpnXo505Ln3n9GRoYyffp0xdHRUdFoNMqrr76qXLlyRalQoYIyatSoAtu1ZcsWxdfXV3FwcFBMTU0VZ2dnZeTIkUpkZKS2TmpqqvLee+8plStXVjQajdKiRQvlxIkTeaZlz2nb5s2bdfaR37E8Pc28ovx1DX733XeKu7u7olarFW9vb53jzb3NGzdu5Dk/fn5+io2NjWJmZqbUqFFDGTp0qPLLL78UeB5yW7VqldK6dWulQoUKilqtVmrUqKFMnjxZiY+Pz3f/AQEB+b73nr7GV69erTRq1EjRaDSKlZWV4uXlpUyZMkW5d++ewW3Ud+5y3LlzR+nVq5dia2ur2NjYKP369VPu3bunAMrMmTN16s6ZM0epWrWqYmRkpHM8T1+PiqIo169fV/r27avY2toqZmZmSpMmTZRdu3YZ1N709HTl448/VlxdXRUTExPFyclJmTp1qpKamqpTL7/38dPXWn7y+wzLLb9z98MPPyje3t6KWq1W7OzslMGDByt37tzJs/7WrVsVDw8PRa1WK3Xq1FG2bdumBAQEKNWrV89T15DX2tBjM/QzLjo6WnnnnXcUJycnxcTERHF0dFTatWunrF69Wlsnv/eqoijKjRs3FEBZsGBBnmVnz55V/Pz8FEtLS8Xc3Fx55ZVXlOPHj+vUye/9nnOs+j4rDf2bFBsbq/17YGlpqfj5+Sm///57iT4/FUVRdu7cqTRv3lzRaDSKtbW10qRJE2XDhg06dc6dO6f07t1b+7lQvXp1pX///kpISEiedgshhBBCGEKlKKWUeVcI8a/0v//9j549e3LkyBGdqduflbi4OMqXL88nn3zCRx999Mz3V1pUKhXvvPOOwb2PhBBCCCGEEOJFJDmahBAl8tVXX/HSSy/RsmXLUt92SkpKnrKcfDht27Yt9f0JIYQQQgghhCgZydEkhCiWjRs3cuHCBXbv3s2SJUuKNNOXoX744QeCgoLo3LkzlpaWHDt2jA0bNuDr60uLFi1KfX8vqidPnhSao8bGxua5zRKmT1JSkt6Ew7nZ29vnmxRdCCGEEEII8WKQQJMQolgGDhyIpaUlw4cPZ/To0c9kH/Xq1aNcuXL897//JSEhQZsg/JNPPnkm+3tRHT9+vNDE04GBgQwdOvT5NEiPhQsXFpj0HODGjRu4uLg8nwYJIYQQQgghngnJ0SSEEC+42NhYzpw5U2AdT09PKleu/JxalNcff/zBH3/8UWCdli1bYmZm9pxaJIQQQgghhHgWJNAkhBBCCCGEEEIIIUqFJAMXQgghhBBCCCGEEKXiX5ejKSsri3v37mFlZfVMkhcLIYQQQgjxvCmKQmJiIlWqVMHISH5LFkIIUXb+dYGme/fu4eTkVNbNEEIIIYQQotTdvn2batWqlXUzhBBC/Iv96wJNVlZWQPYfYWtr6zJujRBCCCGEECWXkJCAk5OT9ruuEEIIUVb+dYGmnOFy1tbWEmgSQgghhBD/KJIaQgghRFmTAdxCCCGEEEIIIYQQolRIoEkIIYQQQgghhBBClAoJNAkhhBBCCCGEEEKIUvGvy9EkhBBCCCGEKFuZmZmkp6eXdTOEEEIYyNTUFCMjw/oqSaBJCCGEEEII8VwoikJUVBRxcXFl3RQhhBBFYGRkhKurK6ampoXWlUCTEEIIIYQQ4rnICTI5ODhgbm4us+QJIcQLICsri3v37hEZGYmzs3Ohn90SaBJCCCGEEEI8c5mZmdogU4UKFcq6OUIIIYrA3t6ee/fukZGRgYmJSYF1JRm4EEIIIYQQ4pnLyclkbm5exi0RQghRVDlD5jIzMwutK4EmIYQQQgghxHMjw+WEEOLFU5TPbgk0CSGEEEIIIYQQQohSIYEmIYQQQgghhBB6DR06lJ49ez7z/dy8eROVSsX58+ef+b5K26xZs2jQoEFZN8NgiqLw1ltvYWdnpz3nbdu2Zfz48WXdtAIFBQVha2tb1s0QBpBAkxBCCCGEEEKIMuXk5ERkZCR169Yt66YUSKVSsWPHDp2ySZMmERISUuJtR0VF8e677/LSSy+hVqtxcnKiW7dupbLt3Pbt20dQUBC7du3SnvNt27YxZ86cUt1PSbi4uLB48WKdstdee43/+7//K5sGiSKRWeeEEEIIIYQQQpQpY2NjHB0dy2TfmZmZqFQqjIyK1w/D0tISS0vLErXh5s2btGjRAltbWxYsWICXlxfp6ens37+fd955h99//71E28/t+vXrVK5cmebNm2vL7OzsSm37+VEUhczMTMqVK14YQqPRoNFoSrlV4lko0x5NR44coVu3blSpUkVvZFif0NBQGjZsiFqtxs3NjaCgoGfeTiGEEEIIIYR4lrZs2YKXlxcajYYKFSrQvn17Hj9+DMDp06fp0KEDFStWxMbGhjZt2nD27Fmd9VUqFatWraJr166Ym5vj4eHBiRMnCA8Pp23btlhYWNC8eXOuX7+uXSdnyNeqVatwcnLC3Nyc/v37Ex8fn287s7KymDdvHq6urmg0GurXr8+WLVsMOsbY2FgGDx6Mvb09Go0Gd3d3AgMDgbxD54YOHYpKpcrzCA0NBSAtLY1JkyZRtWpVLCwsaNq0qXZZYXKGYO3cuZM6deqgVquJiIgo9Dy7uLgA0KtXL1Qqlfb500PnsrKymD17NtWqVUOtVtOgQQP27dtXYJtGjx6NSqXi559/pk+fPtSsWRNPT08mTpzIyZMntfUiIiLo0aMHlpaWWFtb079/f6Kjo7XLc9qybt06XFxcsLGxYcCAASQmJmrP67vvvktERITOMTw9dC4yMpIuXbqg0WhwdXXl+++/1+llpG+oY1xcnM5rFBoaikqlYu/evTRq1Ai1Ws2xY8e4fv06PXr0oFKlSlhaWvLyyy9z4MAB7Xbatm3LrVu3mDBhgvZ1z/265bZixQpq1KiBqakptWrVYt26dTrLVSoVa9asoVevXpibm+Pu7s7OnTu1ywu6JkXxlWmg6fHjx9SvX58vv/zSoPo3btygS5cuvPLKK5w/f57x48czYsQI9u/f/4xbKoQQQgghhBDPRmRkJAMHDuSNN97gypUrhIaG0rt3bxRFASAxMZGAgACOHTvGyZMncXd3p3PnztrgQY45c+bg7+/P+fPnqV27NoMGDWLkyJFMnTqVX375BUVRGDNmjM464eHhbNq0iR9//JF9+/Zx7tw5Ro8enW9b582bx9q1a1m5ciWXLl1iwoQJvP766xw+fLjQ45w+fTqXL19m7969XLlyhRUrVlCxYkW9dZcsWUJkZKT2MW7cOBwcHKhduzYAY8aM4cSJE2zcuJELFy7Qr18/OnbsyLVr1wptB0BycjLz589nzZo1XLp0CQcHh0LP8+nTpwEIDAwkMjJS+1xf2xctWsTChQu5cOECfn5+dO/ePd+2xcTEsG/fPt555x0sLCzyLM8JrmRlZdGjRw9iYmI4fPgwwcHB/PHHH7z22ms69a9fv86OHTvYtWsXu3bt4vDhw3z66afatuUEwQo6Bn9/f+7du0doaChbt25l9erV3L9/v/ATq8cHH3zAp59+ypUrV6hXrx5JSUl07tyZkJAQzp07R8eOHenWrRsREREAbNu2jWrVqjF79mzt66/P9u3bGTduHO+99x6//fYbI0eOZNiwYRw6dEin3scff0z//v25cOECnTt3ZvDgwcTExABFuyZFESh/E4Cyffv2AutMmTJF8fT01Cl77bXXFD8/P4P3Ex8frwBKfHx8cZophBBCCCHE386L8B03JSVFuXz5spKSklLWTfnbOXPmjAIoN2/eNKh+ZmamYmVlpfz444/aMkCZNm2a9vmJEycUQPn666+1ZRs2bFDMzMy0z2fOnKkYGxsrd+7c0Zbt3btXMTIyUiIjIxVFUZSAgAClR48eiqIoSmpqqmJubq4cP35cpz3Dhw9XBg4cWGi7u3XrpgwbNkzvshs3biiAcu7cuTzLtm7dqpiZmSnHjh1TFEVRbt26pRgbGyt3797VqdeuXTtl6tSphbYjMDBQAZTz588XWC+/8/z0fevMmTOV+vXra59XqVJF+c9//qNT5+WXX1ZGjx6tdz+nTp1SAGXbtm0Ftuenn35SjI2NlYiICG3ZpUuXFED5+eeftW0xNzdXEhIStHUmT56sNG3aVPv8888/V6pXr66z7TZt2ijjxo1TFEVRrly5ogDK6dOntcuvXbumAMrnn3+uKIr+1ys2NlYBlEOHDimKoiiHDh1SAGXHjh0FHpeiKIqnp6eydOlS7fPq1atr95UjMDBQsbGx0T5v3ry58uabb+rU6devn9K5c2ft86ffF0lJSQqg7N27V1GUgq9Joason+EvVDLwEydO0L59e50yPz8/Tpw4UUYtEkIIIYQQQoiSqV+/Pu3atcPLy4t+/frx1VdfERsbq10eHR3Nm2++ibu7OzY2NlhbW5OUlKTtAZKjXr162v9XqlQJAC8vL52y1NRUEhIStGXOzs5UrVpV+9zHx4esrCyuXr2ap53h4eEkJyfToUMHbV4iS0tL1q5dqzMkLz9vv/02GzdupEGDBkyZMoXjx48Xus65c+cYMmQIy5Yto0WLFgBcvHiRzMxMatasqdOOw4cPG9QOAFNTU53zBYaf54IkJCRw7949bVtztGjRgitXruhdR/mz51phrly5gpOTE05OTtqyOnXqYGtrq7NtFxcXrKystM8rV65cpN5IV69epVy5cjRs2FBb5ubmRvny5Q3eRm6NGzfWeZ6UlMSkSZPw8PDA1tYWS0tLrly5UqTzDNnnw5DznPt1trCwwNraWns+inNNisK9UMnAo6KitB+YOSpVqkRCQgIpKSl6E4OlpaWRlpamfZ77Q1UIIYQQQgghypqxsTHBwcEcP36cn376iaVLl/LRRx9x6tQpXF1dCQgI4NGjRyxZsoTq1aujVqvx8fHhyZMnOtsxMTHR/j8nr42+sqysrGK1MykpCYDdu3frBKcA1Gp1oet36tSJW7dusWfPHoKDg2nXrh3vvPMOCxcu1Fs/KiqK7t27M2LECIYPH67TDmNjY86cOYOxsbHOOoYm5dZoNNrzkcPQ81za3N3dUalUpZbwO/drDtmve3Ff8/zkJE7PHSRLT0/XW/fp4YCTJk0iODiYhQsX4ubmhkajoW/fvs/sPBd0Pop6TQrDvFA9mopj3rx52NjYaB+5o79CCPFvkpicTMjZ8yQmJxdY7/79+3yx9Itij8MXoqwZeq0LIcTfiUqlokWLFnz88cecO3cOU1NTtm/fDkBYWBhjx46lc+fOeHp6olarefjwYansNyIignv37mmfnzx5EiMjI2rVqpWnbu7E2W5ubjoPQ++z7O3tCQgI4LvvvmPx4sWsXr1ab73U1FR69OhB7dq1+eyzz3SWeXt7k5mZyf379/O0oyQz1xlynk1MTMjMzMx3G9bW1lSpUoWwsLA8265Tp47edezs7PDz8+PLL7/UJoDPLS4uDgAPDw9u377N7du3tcsuX75MXFxcvtsujlq1apGRkcG5c+e0ZeHh4Tq97Ozt7QF08iflTgxekLCwMIYOHUqvXr3w8vLC0dGRmzdv6tQxNTUt8DxD9vkoynnOj6HXpDDcC9WjydHRUSejPmR3b7S2ts53msOpU6cyceJE7fOEhAQJNgkh/pUSk1M4dO5XPJydsDI3z7fegwcPWLpsKe1ebYeDg8NzbKEQpcPQa10IIf4uTp06RUhICL6+vjg4OHDq1CkePHiAh4cHkN3jZd26dTRu3JiEhAQmT55catO8m5mZERAQwMKFC0lISGDs2LH0799fb8DGysqKSZMmMWHCBLKysmjZsiXx8fGEhYVhbW1NQEBAgfuaMWMGjRo1wtPTk7S0NHbt2qU9xqeNHDmS27dvExISwoMHD7TldnZ21KxZk8GDB+Pv78+iRYvw9vbmwYMHhISEUK9ePbp06VKsc2HIeXZxcSEkJIQWLVqgVqv1DiebPHkyM2fOpEaNGjRo0IDAwEDOnz/P+vXr8933l19+SYsWLWjSpAmzZ8+mXr16ZGRkEBwczIoVK7hy5Qrt27fHy8uLwYMHs3jxYjIyMhg9ejRt2rTJMzytJGrXrk379u156623WLFiBSYmJrz33ns6vcA0Gg3NmjXj008/xdXVlfv37zNt2jSDtu/u7s62bdvo1q0bKpWK6dOn5+lx5eLiwpEjRxgwYABqtVpvgu7JkyfTv39/vL29ad++PT/++CPbtm3TmcGuMEW5JoXhXqgeTT4+PoSEhOiUBQcH4+Pjk+86arUaa2trnYcQQvzjPLkPEYuz/xVCCCHEC8Xa2pojR47QuXNnatasybRp01i0aBGdOnUC4OuvvyY2NpaGDRsyZMgQxo4dW2o/Brm5udG7d286d+6Mr68v9erVY/ny5fnWnzNnDtOnT2fevHl4eHjQsWNHdu/ejaura6H7MjU1ZerUqdSrV4/WrVtjbGzMxo0b9dY9fPgwkZGR1KlTh8qVK2sfOTl0AgMD8ff357333qNWrVr07NmT06dP4+zsXLwTgWHnedGiRQQHB+Pk5IS3t7fe7YwdO5aJEyfy3nvv4eXlxb59+9i5cyfu7u757vull17i7NmzvPLKK7z33nvUrVuXDh06EBISwooVK4DsXm//+9//KF++PK1bt6Z9+/a89NJL/PDDD8U+5vysXbuWSpUq0bp1a3r16sWbb76JlZUVZmZm2jrffPMNGRkZNGrUiPHjx/PJJ58YtO3PPvuM8uXL07x5c7p164afn59OPiiA2bNnc/PmTWrUqKHtPfW0nj17smTJEhYuXIinpyerVq0iMDCQtm3bGnycRbkmheFUiqGZx56BpKQkwsPDgezuj5999hmvvPIKdnZ2ODs7M3XqVO7evcvatWsBuHHjBnXr1uWdd97hjTfe4ODBg4wdO5bdu3fj5+dn0D4TEhKwsbEhPj5egk5CiH+OpN/gQjeo9yNY1tVb5d7DRyz/3y5G9+hKlYoV8t3UpUuX6Nm7Jzu27cDT0/NZtViIZ8bQa12If5IX4TtuamoqN27cwNXVVedmVZSdWbNmsWPHDoOHPIl/rzt37uDk5MSBAwdo165dWTdHlIGifIaXaY+mX375BW9vb20keOLEiXh7ezNjxgwge7xn7szzrq6u7N69m+DgYOrXr8+iRYtYs2aNwUEmIYQQQgiQXGRCCCFEQQ4ePMjOnTu5ceMGx48fZ8CAAbi4uNC6deuybpp4AZRpjqa2bdsWOJVjUFCQ3nVyJyUTQghROEVRSHmSPQNnypM0FEXJM9OKEP8mkotMCCFK36hRo/juu+/0Lnv99ddZuXLlc2lHp06dOHr0qN5lH374IR9++OFzaceLLD09nQ8//JA//vgDKysrmjdvzvr16/PM4CaEPi9UMnAhhBBFk5L2hHPXwjl5+XdiEhMBCNwbjJ2VFc3q1Mbb3Q2N2rSMWymEEEKIsjBr1ixmzZpVatubPXs2kyZN0rvseQ7pXLNmDSkpKXqX2dnZPbd2vMj8/Pxk5JAoNgk0CSHEi05RICM++/8Z8dnPVSqu3bnLhpBQnmRk5FklJjGRPadOc+DMOQa2a4t7tarPudFCCCGE+KdxcHD4W/QSrVpVvtcIUZYk0CSEEC+qjAS4vxUigyDtz3x2l18HtTPXyg1l7Rnj7KBTAdIzMlj7Uwj+vu0k2CSEEEIIIYQosTJNBi6EEKKYYg/DLz5wcw6k3dZZlJJ8nw1nMkDJpLBpRRUARWFDSCgpaU+eVWuFEEIIIYQQ/xISaBJCiBdN7GG48gZkpZAdKtINJ52Lr88TxQTFwI94BXiSkcH58Oul3lSDPLkPEYuz/xVCCCGEEEK80CTQJIQQL5KMBLg6Gn0BJsgeKXcypmmxNn3i0pUCZwJ9Zp7chztLJNAkhBBCCCHEP4AEmoQQ4kVyf2uunkx5pWaaEZNuB6iKvOmYxERS0tJK1j4hniXp/SaE+JOiKDxKSOVWdCKPElLL5ocSIYQQekkycCGEeFEoSnbi7wKkKyX7WE99kk58QvYMdvEJ8SiKgkpV9KCVEM9ETu83u/ZgWvazGgkhnr+4pDS+PxTOql1XuBGVqC13dbRiZFcPBr3ihq2lugxbKIQQQno0CSHEiyIj9s/Z5fL/1dZElVGsTT9JTeX/fvmZPr16EDA0AICAoQG0921P0LdBJCQkFGu7QgghRGk5cPYuHsM3MfXrn7kZnaiz7GZ0IlO//hmP4Zs4cPZuqe976NChqFQqPv30U53yHTt2lPgHmaCgIFQqFSqVCmNjY8qXL0/Tpk2ZPXs28fHxetuhUqkwNTXFzc2N2bNnk5FRvL//QgjxLEigSQghXhSZyYVWMTNOxc4kBsgyeLORN67z44olnDv4E3fv3tFZdvv2bebOm0urNq04evRoUVsshBBClIoDZ+/Sb04wKWkZKEp2J9/ccspS0jLoNyf4mQSbzMzMmD9/PrGxsaW+bWtrayIjI7lz5w7Hjx/nrbfeYu3atTRo0IB79+7p1O3YsSORkZFcu3aN9957j1mzZrFgwYJSb5MQQhSXBJqEEOJFYWxeaBWVCprZncLQHE2RN65zdMtGMtLTAfLkuFAUBUVRSElJYcRbIyTYJIQQ4rmLS0pjyPyDKIpCViGpmLKU7L9dQ+YfJC6pdPMOtm/fHkdHR+bNm1dgva1bt+Lp6YlarcbFxYVFixYVum2VSoWjoyOVK1fGw8OD4cOHc/z4cZKSkpgyZYpOXbVajaOjI9WrV+ftt9+mffv27Ny5s0THJoQQpUkCTUII8aIoVx7UzhQWRPK2+RVTVTqqQno1PUlN5fiOLQYlUM0JOI0ZO4aEhATSE2O4F7KB9MSYohyBEEIIUWTfHwonOS2j0CBTjiwFktMy2HDoeqm2w9jYmLlz57J06VLu3Lmjt86ZM2fo378/AwYM4OLFi8yaNYvp06cTFBRU5P05ODgwePBgdu7cSWZmZr71NBoNT548KfL2hRDiWZFAkxBCvChUKqg8tNBqGuNUBlb7IXuVAoJNN3+7oO3JZIicnk3bd2wnPTGWyEM/kJ5Y+sMHhBBCiByKorBq15WC0hPma+Wuy6U+G12vXr1o0KABM2fO1Lv8s88+o127dkyfPp2aNWsydOhQxowZU+yhbbVr1yYxMZFHjx7lWaYoCgcOHGD//v28+uqrxdq+EEI8CxJoEkKIF4lDHzDSUFivJnfL6/g7rf8zOXjeL9mKovB/Z08Xqwlr162VaaSFEEI8FzGJadyISixynElR4EZUIjGJpTt8DmD+/Pl8++23XLlyJc+yK1eu0KJFC52yFi1acO3atQJ7JeUn5+9t7oTju3btwtLSEjMzMzp16sRrr73GrFmzirxtIYR4ViTQJIQQL5Jy1lBrOdmBpsKCTX8w2f1zutSvgJ2Vlc4yc2NjHscVvTeSoihERESQmJhYeGUhhBCihJJSDO95+yzW16d169b4+fkxderUUt/2065cuYK1tTUVKlTQlr3yyiucP3+ea9eukZKSwrfffouFhcUzb4sQQhiqXFk3QAghRBGVbwMe38DV0ZCV8mdh7t96/wxAGWnQ1FmBj21rmjVSuBEZyTd7g3mjUwdMMjMJ+nR2sZuQkpJa7HWFEEIIQ1lqTMp0/fx8+umnNGjQgFq1aumUe3h4EBYWplMWFhZGzZo1MTY2LtI+7t+/z/fff0/Pnj0xMvqrf4CFhQVubm7Fb7wQQjxjEmgSQogXUfk20PgEPNgK94IgLeKvZWonqDIU7Ptk94Aiu8u9makaADNTNWZGhs1Klx+NxqxE6wshhBCGsLNS4+poxc3oRIoyalulApdKVthZqZ9Ju7y8vBg8eDBffPGFTvl7773Hyy+/zJw5c3jttdc4ceIEy5YtY/ny5QVuT1EUoqKiUBSFuLg4Tpw4wdy5c7GxseHTTz99JscghBDPigydE0KIF1U5a6g8DBqGQp312WV11mc/rzxMG2TSp3z58jg7O+vkfDCESqXC2dkZq6eG4gkhhBDPgkqlYmRXj2KtO6prnSL/nSuK2bNnk5WlO+lGw4YN2bRpExs3bqRu3brMmDGD2bNnM3To0AK3lZCQQOXKlalatSo+Pj6sWrWKgIAAzp07R+XKlZ/ZMQghxLMgPZqEEOJFp1L9FVQqZ539vNBVVAx5fQhz580t8u78h/g/0y/uQgghRG6DXnFjzndnSUnLIMuAXk1GKtCoyzHwlRql1oagoKA8ZS4uLqSl5U023qdPH/r06WPwtocOHVpoIKqgdgghxN+N9GgSQoh/qd69eqPRaAwOGhkZGaHRaOjVs9czbpkQQgjxF1tLNevefxWVSkVhI7+NVNk/pnz3wavYWj6bYXNCCCEKJoEmIYT4l7K2tmbZF8tQqVSFBptyli9bugxr6/yH5AkhhBDPQvuGVdk8vQMadTlUqrydd3PKNOpybJnRgXbeVcumoUIIISTQJIQQ/2atWrVizeo12p5NTweccso0Gg1rvlpDq5atyqilQggh/u3aN6zKla/78+nwprhU0s0V6FLJik+HN+X3b16TIJMQQpQxydEkhBD/cq1ateLo4aNs37GdtevWEhHx1wx2Tk5O+A/xp3ev3pIAXAghRJmztVTzdrc6jOrqQUxiGkkp6VhqTLCzUkv+QCGE+JuQQJMQQgisra0J8A/Af4g/J0+exH+oP2uD1tKsWbNn+8VdUSAjPvv/GfHZz+VGQQghRCFUKhUVrM2oYG1W1k0RQgjxFAk0CSHEv4SVuYZXvOtjZa7Jt45KpdLmYLK2tn52QaaMBLi/FSKDIO3PHlSXXwe1M1QeCg59/ppJTwghhBBCCPHCkBxNQgjxL2Flbk67hg2wMjcv24bEHoZffODmHEi7rbss7XZ2+S8+2fWEEEIIIYQQLxQJNAkhhHh+Yg/DlTcgKwVQ/nzk9mdZVkp2PQk2CSGEEEII8UKRQNO/jKIoPEpI5VZ0Io8SUlGUp2/yhBCiYIqikJHyGICMlMeGf45kJMDV0egPMOXZS/bj6ujs9YQQQojcFAXSYyD1Tva/8p1WCCH+NiTQ9C8Rl5TG8h8v0WDUVlyHbMDrrS24DtlAg1FbWf7jJeKS0sq6iUKIv7mMlCSij//Ipc/f5lrgDACuBc7g0udvE338RzJSkgrewP2tuXoyGeLPnk0Ptpao3eLfRVEUUp5k/01LeZImP6gI8U+TkQD3AuFsWzjdCM62+vPfttnl/7IfJ4YOHUrPnj2f+X5u3ryJSqXi/Pnzz3xfpW3WrFk0aNCgrJvxXLVu3Zrvv/++rJvxQnqRr/WS2LdvHw0aNCArK6tUtieBpn+BA2fv4jF8E1O//pmb0Yk6y25GJzL165/xGL6JA2fvllELhRB/J/b29rw75l3s7e21ZfHXznFxwQju7PmGtJhonfppMdHc2fMNFxeMIP7aOW15VEwyczecIyomOfuX5sig4jXoXpD8Ui0KlZL2hOO/XebzzdsJ3BsMQODeYD7fvJ3jv10mJe1JGbdQCFFikuOvzDg5OREZGUndunXLuikFUqlU7NixQ6ds0qRJhISEPNP9hoaG0rBhQ9RqNW5ubgQFBRVav0ePHlSuXBkLCwsaNGjA+vXrdeoEBQWhUql0HmZmhc+yuHPnTqKjoxkwYEBJDilfiqIwY8YMKleujEajoX379ly7ds3g9T/99FNUKhXjx4/XKb9+/Tq9evXC3t4ea2tr+vfvT3R0tP6NPENlfa2PHDmSGjVqoNFosLe3p0ePHvz+++8FrjN06NA810rHjh116sTExDB48GCsra2xtbVl+PDhJCX99SNxx44dMTExyXMdFpcEmv7hDpy9S785waSkZaAoee/VcspS0jLoNydYgk1CCBwcHBj77lgcHByA7CBT+No5ZKWnUVBepaz0NMLXztEGm6Jik/l043miYpMhI/bP2eWKGjBSstfLiCvRMYl/tmt37rJg42b2nDpNTKLuDyoxiYnsOXWaBRs3c+2O/I0T4oUlOf7KlLGxMY6OjpQr9/wnLc/MzCxRLwtLS0sqVKhQii3SdePGDbp06cIrr7zC+fPnGT9+PCNGjGD//v35rnP8+HHq1avH1q1buXDhAsOGDcPf359du3bp1LO2tiYyMlL7uHXrVqHt+eKLLxg2bBhGRs/mVv+///0vX3zxBStXruTUqVNYWFjg5+dHampqoeuePn2aVatWUa9ePZ3yx48f4+vri0ql4uDBg4SFhfHkyRO6detWaj1sDFWW1zpAo0aNCAwM5MqVK+zfvx9FUfD19SUzM7PA9Tp27KhzrWzYsEFn+eDBg7l06RLBwcHs2rWLI0eO8NZbb+nUGTp0KF988UWpHIcEmv7B4pLSGDL/IIqikFXIvV2Wkh2dHjL/oAyjE+JFZOoA1cZl/1uKMlKS+GPDfEBPpPppSvaX/D82zM87jC4zuWQNyXxcsvXFP9a1O3dZ+1MI6RkZBdZLz8hg7U8hEmwS4kX0N8jxt2XLFry8vNBoNFSoUIH27dvz+HH236bTp0/ToUMHKlasiI2NDW3atOHs2bM666tUKlatWkXXrl0xNzfHw8ODEydOEB4eTtu2bbGwsKB58+Zcv35du07OkK9Vq1bh5OSEubk5/fv3Jz4+Pt92ZmVlMW/ePFxdXdFoNNSvX58tW7YYdIyxsbEMHjwYe3t7NBoN7u7uBAYGAnmHE+nrQaFSqQgNDQUgLS2NSZMmUbVqVSwsLGjatKl2WWGCgoKwtbVl586d1KlTB7VaTURERKHn2cXFBYBevXqhUqm0z58eOpeVlcXs2bOpVq0aarWaBg0asG/fPoPaps/KlStxdXVl0aJFeHh4MGbMGPr27cvnn3+e7zoffvghc+bMoXnz5tSoUYNx48bRsWNHtm3bplNPpVLh6OiofVSqVKnAtjx48ICDBw/SrVs3nfJ169ZRp04dzMzMKF++PD4+PgYFhp6mKAqLFy9m2rRp9OjRg3r16rF27Vru3buXpyfZ05KSkhg8eDBfffUV5cuX11kWFhbGzZs3CQoKwsvLCy8vL7799lt++eUXDh48aHD7cq6d/fv34+HhgaWlpTYAk6Ow1//pa72g9wXA7du36d+/P7a2ttjZ2dGjRw9u3rxpcJuf9tZbb9G6dWtcXFxo2LAhn3zyCbdv3y50m2q1WudayX2Or1y5wr59+1izZg1NmzalZcuWLF26lI0bN3Lv3j1tvW7duvHLL7/ofA4VlwSa/sG+PxROclpGoUGmHFkKJKdlsOFQyS8sIcRzZuoAzuNLPdD06Nwhsp6kGT50TVHIepLGo3OHiH+cPVQp/vETFCNNyRpibFGy9cU/UkraEzaEhIKiGHTriaKwISRUhtEJ8aIp4xx/kZGRDBw4kDfeeIMrV64QGhpK7969tTngEhMTCQgI4NixY5w8eRJ3d3c6d+5M4lM9LOfMmYO/vz/nz5+ndu3aDBo0iJEjRzJ16lR++eUXFEVhzJgxOuuEh4ezadMmfvzxR/bt28e5c+cYPXp0vm2dN28ea9euZeXKlVy6dIkJEybw+uuvc/hw4T28pk+fzuXLl9m7dy9XrlxhxYoVVKxYUW/dJUuW6PSeGDduHA4ODtSuXRuAMWPGcOLECTZu3MiFCxfo168fHTt2NHiIVXJyMvPnz2fNmjVcunQJBweHQs/z6dOnAQgMDCQyMlL7XF/bFy1axMKFC7lw4QJ+fn50795dp22enp5YWlrm++jUqZO27okTJ2jfvr3OPvz8/Dhx4oRBx5ojPj4eOzs7nbKkpCSqV6+Ok5MTPXr04NKlSwVu49ixY9pAZo6bN28SEBDA8OHD+f333zl16hSTJ0/G2NgYgKNHjxZ4rJaWltrhVDdu3CAqKkrneG1sbGjatGmhx/vOO+/QpUuXPOcKsgOTKpUKtVqtLTMzM8PIyIhjx44VuN2nJScns3DhQtatW8eRI0eIiIhg0qRJ2uWGvP65FfS+SE9Px8/PDysrK44ePUpYWJg2uPXkSfZ3jfXr1xd6fo8ePap3348fPyYwMBBXV1ecnJwKPO7Q0FAcHByoVasWb7/9No8ePdIuO3HiBLa2tjRu3Fhb1r59e4yMjDh16pS2zNnZmUqVKuXbnqIom/5g4plTFIVVu64UfZQKsHLXZUZ19UClUpV+w4QQLwxFUXhwcjdF+SBJyizHvlhndiy5w93UhwB0m74fV0dLjrzuiLVxNKoifTCpQO0E5WyL1Hbx73DuWjhPCunJlJsCPMnI4Hz4dayfXbP0e3Ifor4Hx0GlHhAW4h+tpDn+HIdCCb/TRkZGkpGRQe/evalevToAXl5e2uWvvvqqTv3Vq1dja2vL4cOH6dq1q7Z82LBh9O/fH4D3338fHx8fpk+fjp+fHwDjxo1j2LBhOttKTU1l7dq1VK1aFYClS5fSpUsXFi1ahKOjo07dtLQ05s6dy4EDB/Dx8QHgpZde4tixY6xatYo2bdoUeJwRERF4e3trb0ZzegTpY2Njg42NDQDbtm1j1apVHDhwAEdHRyIiIggMDCQiIoIqVaoA2XmS9u3bR2BgIHPnzi2wHZB9A798+XLq16+vLSvsPOfklrS1tc1zbnJbuHAh77//vjaH0fz58zl06BCLFy/myy+/BGDPnj2kp6fnuw2N5q8f0KKiovL0NKpUqRIJCQmkpKTo1M3Ppk2btMPKctSqVYtvvvmGevXqER8fz8KFC2nevDmXLl2iWrVqerdz69YtKlWqpDNsLuPPv5O1a9fWvqY1a9bULm/cuHGhia9zji8qKkrnee7lOcv02bhxI2fPns03+NesWTMsLCx4//33mTt3Loqi8MEHH5CZmanTG8kQ6enprFy5kho1agDZQc/Zs2drlxvy+udW0Pvihx9+ICsrizVr1mjvnQMDA7G1tSU0NBRfX1+6d+9O06ZNC2xzzvs7x/Lly5kyZQqPHz+mVq1aBAcHY2pqmu/6HTt2pHfv3ri6unL9+nU+/PBDOnXqxIkTJzA2NiYqKkqbEiNHuXLlsLOzy/O6ValSxaAhmoWRQNM/VExiGjeiEguv+BRFgRtRicQkplHBuvBkc0KIf67M5ETSYvL/0vC0nxPtmRnRhLQs4zzLbkYnMTe0PvNe3V/07/tVhpb4JkH88yiKwsnLBSfHzM+JS1fwrVOz8Iql6cl9uLME7NpLoEmIotDm+CuqXDn+TMoXWrsg9evXp127dnh5eeHn54evry99+/bVDk2Jjo5m2rRphIaGcv/+fTIzM0lOTiYiQrfdufPS5Nyo5w5YVapUidTUVBISErC2zg6HOzs769yE+vj4kJWVxdWrV/MEU8LDw0lOTqZDhw465U+ePMHb27vQ43z77bfp06cPZ8+exdfXl549e9K8efMC1zl37hxDhgxh2bJltGjRAoCLFy+SmZmpE8yA7ECYobmSTE1N8+TxMfQ8FyQhIYF79+5p25qjRYsW/Prrr9rnOQHF5+HQoUMMGzaMr776Ck9PT225j4+PNmAI0Lx5czw8PFi1ahVz5szRu62UlJQ8CcPd3Nz45ptv6NevH5mZmTRq1Ijjx49rl2s0Gtzc3Er5qP5y+/Ztxo0bR3BwcL7JzO3t7dm8eTNvv/02X3zxBUZGRgwcOJCGDRsWOdeUubm5NsgEULlyZe7fvw8Y/vrnVtD74tdffyU8PBwrKyuddVJTU7XDz6ysrPIsL8zgwYPp0KEDkZGRLFy4kP79+xMWFpbv+cud+N3Ly4t69epRo0YNQkNDadeuXZH2rdFoSE4uYcoLJND0j5WUkn8E3tD1JdAkxL9b5pMUg+v+nGjP1JvNUFChkDcopCjw/cX6TG91EE25dIwN+s5gBEZmYN/H8EaLf43ktLQ8ib8NFZOYSFq6DJ8T4oVQGjn+ShhoMjY2Jjg4mOPHj/PTTz+xdOlSPvroI06dOoWrqysBAQE8evSIJUuWUL16ddRqNT4+PtqhMzlMTEy0/8/p/aCvrLjJj3NmkNq9e3eeHhK5hyTlp1OnTty6dYs9e/YQHBxMu3bteOedd1i4cKHe+lFRUXTv3p0RI0YwfPhwnXYYGxtz5swZ7fCsHJaWlgYdi0ajyTO6wtDzXBo8PT0L7NXRqlUr9u7dC4Cjo2Oe2dGio6OxtrYutDfT4cOH6datG59//jn+/v4F1jUxMcHb25vw8PB861SsWJHY2Fidsvv37/PRRx8xZcoU+vbtq+2JluPo0aM6QwH1WbVqFYMHD9YGN6Ojo6lcubJ2eXR0tE4erNzOnDnD/fv3adiwobYsMzOTI0eOsGzZMtLS0jA2NsbX15fr16/z8OFDypUrp+2Z9tJLLxXYtqflfk9B9vtKKcHsxQW9L5KSkmjUqJHemdpyetitX7+ekSNHFriPvXv30qpVK+3znB6D7u7uNGvWjPLly7N9+3YGDhxoUJtfeuklKlasSHh4OO3atcPR0VEbbMuRkZFBTExMnoB1TEyMzszTxSWBpn8oS41J4ZWe4fpCiBefsalheZWSMssxM6JJvkGmHPFpZgzZ0Y/NfTeQmQXGRgX90f9zO7VXQLnnPshJvACepBs+ZE7v+hkFz94ihPibMDYv4fqlk+NPpVLRokULWrRowYwZM6hevTrbt29n4sSJhIWFsXz5cjp37gxk9+B4+PBhqew3IiKCe/fuaYegnTx5EiMjI2rVqpWnbu7E2YUNk8uPvb09AQEBBAQE0KpVKyZPnqw30JSamkqPHj2oXbs2n332mc4yb29vMjMzuX//vs7Nc0kZcp5NTEwKnJ3L2tqaKlWqEBYWpnOOwsLCaNKkifZ5UYbO+fj4sGfPHp3lwcHBOr2R9AkNDaVr167Mnz8/z+xf+mRmZnLx4kXt8evj7e1NVFQUsbGx2h53R44cITk5mVmzZuldpyhD51xdXXF0dCQkJEQbWEpISODUqVO8/fbbetdt164dFy9e1CkbNmwYtWvX5v33388TjMzJf3Tw4EHu379P9+7dC2xbURj6+j8tv/dFw4YN+eGHH3BwcND2QnxacYbO5aYoCoqikJZm+IRdd+7c4dGjR9pgoI+PD3FxcZw5c4ZGjRoB2ec3KytLp205PbEM6QFZGAk0/UPZWalxdbTiZnSiwTl8IXt0ikslK+ysCv/VQwjxz2ZsboXazpG0mGgKytO0L9aZtCzjAoNMOUJuuNFvy0DW9dyMhUnGnyPicm/7z20YabKDTLatS3II4h/M1KRkX2FMy+Ud4imE+BsqVx7UzpB2m6IlHy29HH+nTp0iJCQEX19fHBwcOHXqFA8ePNAmXHZ3d2fdunU0btyYhIQEJk+ebFBeHkOYmZkREBDAwoULSUhIYOzYsfTv319vDiIrKysmTZrEhAkTyMrKomXLlsTHxxMWFoa1tTUBAQEF7mvGjBk0atQIT09P0tLS2LVrl05S6dxGjhzJ7du3CQkJ4cGDB9pyOzs7atasyeDBg/H392fRokV4e3vz4MEDQkJCqFevHl26dCnWuTDkPLu4uBASEkKLFi1Qq9V5ZjcDmDx5MjNnzqRGjRo0aNCAwMBAzp8/r9MrpShD50aNGsWyZcuYMmUKb7zxBgcPHmTTpk3s3r1bW2fZsmVs376dkJAQIHu4XNeuXRk3bhx9+vTR5skxNTXVJgSfPXs2zZo1w83Njbi4OBYsWMCtW7cYMWJEvm3x9vamYsWKhIWFafODeXl5kZSUxLRp0xgyZAjlypXjwoUL1KpVizp16hRp6JxKpWL8+PF88sknuLu74+rqyvTp06lSpQo9e/bU1mvXrh29evVizJgxWFlZUbduXZ3tWFhYUKFCBZ3ywMBAPDw8sLe358SJE4wbN44JEyboDaqWhCGvf24FvS8GDx7MggUL6NGjh3Ymu1u3brFt2zamTJlCtWrVijR07o8//uCHH37A19cXe3t77ty5w6effopGo9EJMNauXZt58+bRq1cvkpKS+Pjjj+nTpw+Ojo5cv36dKVOm4Obmps3/5uHhQceOHXnzzTdZuXIl6enpjBkzhgEDBmiD2JAdyM7pKVhSMuvcP5RKpWJkV/1/GAozqmsdSQQuhEClUmHfrOAvg4oC2x+5Fumrf8gNN+qsmMB/f+6Oon5qBg21E7hOh8YnJMgkCmSuVmNXxJwHOeysrFCb5J9UUwjxN6JSQeWhxVu3lHL8WVtbc+TIETp37kzNmjWZNm0aixYt0g43+vrrr4mNjaVhw4YMGTKEsWPH5km8W1xubm707t2bzp074+vrS7169Vi+fHm+9efMmcP06dOZN2+e9uZy9+7duLq6FrovU1NTpk6dSr169WjdujXGxsZs3LhRb93Dhw8TGRlJnTp1qFy5svaRk/snMDAQf39/3nvvPWrVqkXPnj05ffo0zs7OxTsRGHaeFy1aRHBwME5OTvn2yhg7diwTJ07kvffew8vLi3379rFz507c3d2L1S5XV1d2795NcHAw9evXZ9GiRaxZs0Z7kw/w8OFDnSnjv/32W5KTk5k3b57O+evdu7e2TmxsLG+++SYeHh507tyZhIQEjh8/Tp06dfJti7GxMcOGDdMJmtSqVYutW7cSHBzMyy+/TL169fjkk0+KPeRwypQpvPvuu7z11lu8/PLLJCUlsW/fPp38QTlD4Iri6tWr9OzZEw8PD2bPns1HH32Upzdd27ZtGTp0aLHanaOor39B7wtzc3OOHDmCs7MzvXv3xsPDg+HDh5OamppvD6eCmJmZcfToUTp37oybmxuvvfYaVlZWHD9+XOdav3r1KvHx8UD2a37hwgW6d+9OzZo1GT58OI0aNeLo0aM6Q2bXr19P7dq1adeuHZ07d6Zly5asXr1aZ/8bNmxg8ODBmJuXsCcpoFJKMmDxBZSQkICNjQ3x8fHFevFfJHFJaXgM30RKWgZZBrzKRirQqMtx5ev+2FpKjyYhBGSkJHFxwQiy0tPQ1z0yMaMc3a8U75dJgBtrB1BBOQeXB0Od9WDjI4m/Rf6SfoML3aDej2BZl+O/XWbPKf0z2BSkS7MmWJNFz9492bFth07y1WfmqbYLUdpehO+4qamp3LhxA1dX13yT2uqVkQC/+EBWCob1avozx1/jEy/08OtZs2axY8eOQoc1CZFbVFQUnp6enD179rkmNX8eqlevzscff1ziYJPI6+HDh9SqVYtffvkl38B0UT7DpUfTP5itpZp177+KSqXCqJD7NiNVdu+F7z54VYJMQgitchpLXhr4PqDSGwBKU0o2/CgpNeOvm4By1hJkEkXi7e6GablyBgzazKYCTMuVo4FbjULrCiH+RspZQ63lZL+LC3vHS44/8e/m6OjI119/XaTZ+F4Ely5dwsbGptCk6aJ4bt68yfLlyw3q/WgICTT9w7VvWJXN0zugUZdDpec+MadMoy7HlhkdaOedfyIyIcS/k427N27+0zEyUfP0l3y1qmQJlWXiAVESGrUpA9u1BZXKsFtPlYqB7dqiUcuwOSFeOOXbgMc32Tn89Aac/iwz0kCdQBl+rceoUaOwtLTU+xg1atRza0enTp3ybcfcuXOfWzv+yXr27Fmqidj/Djw9Pblw4QJGRhLCeBYaN27Ma6+9Vmrbk2Tg/wLtG1blytf92XDoOit3XeZG1F/TQbtUsmJU1zoMetUNGwv54i2E0M/G3RuvyWuIOR/K/RO7SIvJTlppaZxBVbNU7qWaFS1Fa+6JBx4/mzaLfwf3alXx923HhpBQnmTkPxOdSblyDGzXFvdq8oOKEC+s8m2yh8M92Ar3giAtV48NtVN2Tib7Pv+YnkyzZs3Kd6aw4pg9ezaTJk3Su+x5Drdcs2YNKSkpepflJMIWQrzYJND0L2FrqebtbnUY1dWDmMQ0klLSsdSYYGellsTfQgiDlNNY4uDTFftmXUh9cJsHp3/C/mVf3j2ZyNRvfi7aZEDIxAOiiBQFMrITX5IRn/38z+vHvVpVJg/ox/nw65y4dIWYxL9+ULGzssLH0wNv9xqYmcoPKkK88MpZQ+Vh4DgUMuIg8zEYW2TPLid/Uwrk4OBQaknKS6KgqdyFEP8MEmj6l1GpVFSwNqOCdRESMAohRC4qlQqNgzPOXbKn1x30ahpz1p8t8sQDA1+RPDnCABkJcH8rRAb91Xvh8uvZ051XHgoO2b0XNGpTfDw9aFanNjciI/lmbzBvdOqAa+XKEtAU4p9IpQKT8tkPIYQQfysywFEIIUSJvGgTD6QnxnAvZAPpiTFlsn9RBLGHs2eaujkH0m7rLku7nV3+i092vT+pVCrMTLOvLTNT6bUrhBBCCPG8SaBJCCFEibXzrsKikc0w+jPS9HeeeCA9MZbIQz+QnhhbZm0QBog9DFfeyDWd+dPd5f4sy0rJrpcr2CSEEEIIIcqODJ0TQghRbHFJaXx/KJxVu67oTDRgbKQiI/OvwIBMPCCKJCMBro5Gf4DpaX8uvzo6O0nwPyQJsBBCCCHEi0oCTUIIIYrlwNm7DJl/kOS0vDN95Q4yfezfiPG9vWQIkzDc/a25ejIZ4s+eTQ+2ZicJFkL84ymKQnJaGk/SMzA1KYe5WobKCiHE34UMnRNCCFFkB87epd+cYFLSMlCU7AnA8vPxujOEnLtXov0lJicTcvY8icnJJdqOeAEoSnbi7+K4F1TwxSiEeOGlpD3h+G+X+Xzzduat/4FFm7Yyb/0PfL55O8d/u0xK2pOybuJzNXToUHr27PnM93Pz5k1UKhXnz59/5vsqbbNmzaJBgwZl3YznqnXr1nz//fdl3YwX0ot8rZfEw4cPcXBw4M6dO6WyPQk0CSGEKJK4pDSGzD+IoigGzTKnKDBk/kHiktKKvc/E5BQOnfuVxOSUYm8juy0KGSmPAchIeYwiQYm/n4zYP2eXK+pro2SvlxH3DBolhPg7uHbnLgs2bmbPqdPEJCbqLItJTGTPqdMs2LiZa3fullEL/7mcnJyIjIykbt26Zd2UAqlUKnbs2KFTNmnSJEJCQp7pfkNDQ2nYsCFqtRo3NzeCgoIKrd+jRw8qV66MhYUFDRo0YP369Tp1goKCUKlUOg8zs8JnDt+5cyfR0dEMGDCgJIeUr23btuHr60uFChWKFJDZvHkztWvXxszMDC8vL/bs2aOzXFEUZsyYQeXKldFoNLRv355r1649gyMoWFlf66tXr6Zt27ZYW1ujUqmIi4srdJ3MzEymT5+Oq6srGo2GGjVqMGfOnHy/544aNQqVSsXixYu1ZRUrVsTf35+ZM2eWynFIoEkIIUSRfH8onOS0DIOCTJAdLkhOy2DDoevPtF3379/ni6VfcP/+/TzLMlKSiD7+I5c+f5trgTMAuBY4g0ufv0308R/JSEl6pm0TRZBZwl5rmY9Lpx1CiL+Va3fusvanENIz8g7Xzi09I4O1P4VIsKmUGRsb4+joSLlyzz/zSmZmJllZWcVe39LSkgoVKpRii3TduHGDLl268Morr3D+/HnGjx/PiBEj2L9/f77rHD9+nHr16rF161YuXLjAsGHD8Pf3Z9euXTr1rK2tiYyM1D5u3bpVaHu++OILhg0bhpHRs7nVf/z4MS1btmT+/PkGr3P8+HEGDhzI8OHDOXfuHD179qRnz5789ttv2jr//e9/+eKLL1i5ciWnTp3CwsICPz8/UlNTn8Vh5Kssr3WA5ORkOnbsyIcffmjwOvPnz2fFihUsW7aMK1euMH/+fP773/+ydOnSPHW3b9/OyZMnqVKlSp5lw4YNY/369cTElHxmZgk0CSGEMJiiKKzadaXonU2Albsu6/9lxdQBqo3L/jeffaY8ye4NlfIkTe82FEUh/Ho4S5ctJfx6uE6d+GvnuLhgBHf2fENaTLTOemkx0dzZ8w0XF4wg/tq5oh+UKH3G5iVc36J02iGE+NtISXvChpBQUBTDpgdQFDaEhJbqMLotW7bg5eWFRqOhQoUKtG/fnsePswPbp0+fpkOHDlSsWBEbGxvatGnD2bNnddZXqVSsWrWKrl27Ym5ujoeHBydOnCA8PJy2bdtiYWFB8+bNuX79rx9lcoZ8rVq1CicnJ8zNzenfvz/x8fH5tjMrK4t58+ZpezbUr1+fLVu2GHSMsbGxDB48GHt7ezQaDe7u7gQGBgJ5hxMNHTo0T28blUpFaGgoAGlpaUyaNImqVatiYWFB06ZNtcsKExQUhK2tLTt37qROnTqo1WoiIiIKPc8uLi4A9OrVC5VKpX3+9NC5rKwsZs+eTbVq1VCr1TRo0IB9+/YZ1DZ9Vq5ciaurK4sWLcLDw4MxY8bQt29fPv/883zX+fDDD5kzZw7NmzenRo0ajBs3jo4dO7Jt2zadeiqVCkdHR+2jUqVKBbblwYMHHDx4kG7duumUr1u3jjp16mBmZkb58uXx8fEpdgBnyJAhzJgxg/bt2xu8zpIlS+jYsSOTJ0/Gw8ODOXPm0LBhQ5YtWwZkf49bvHgx06ZNo0ePHtSrV4+1a9dy7969PD3UCpJz7ezfvx8PDw8sLS3p2LEjkZGR2jqFvf5PX+sFvS8Abt++Tf/+/bG1tcXOzo4ePXpw8+ZNg9v8tPHjx/PBBx/QrFkzg9c5fvw4PXr0oEuXLri4uNC3b198fX35+eefderdvXuXd999l/Xr12NiYpJnO56enlSpUoXt27cXu/05JNAkhBDCYDGJadyISiz6oCYFbkQlEpOoZ/icqQM4j88TaMqdhyNwbzAAgXuDdfJwJCQkEPRtEO192xMwNACAgKEBtPdtT9C3QUT+eozwtXPISk9D/wxm2WVZ6WmEr50jwaa/g3LlQe0MFDWpryp7vXK2z6BRQoiydO5aOE8yMooyPQBPMjI4H146PWkjIyMZOHAgb7zxBleuXCE0NJTevXtrf9RITEwkICCAY8eOcfLkSdzd3encuTOJTw3vmzNnDv7+/pw/f57atWszaNAgRo4cydSpU/nll19QFIUxY8borBMeHs6mTZv48ccf2bdvH+fOnWP06NH5tnXevHmsXbuWlStXcunSJSZMmMDrr7/O4cOHCz3O6dOnc/nyZfbu3cuVK1dYsWIFFStW1Ft3yZIlOj1txo0bh4ODA7Vr1wZgzJgxnDhxgo0bN3LhwgX69etHx44dDR4KlZyczPz581mzZg2XLl3CwcGh0PN8+vRpAAIDA4mMjNQ+19f2RYsWsXDhQi5cuICfnx/du3fXaZunpyeWlpb5Pjp16qSte+LEiTxBFz8/P06cOGHQseaIj4/Hzs5OpywpKYnq1avj5OREjx49uHTpUoHbOHbsmDaQmePmzZsEBAQwfPhwfv/9d06dOsXkyZMxNjYG4OjRowUeq6WlZZ5hfUVV2Dm6ceMGUVFROnVsbGxo2rRpkc9jcnIyCxcuZN26dRw5coSIiAgmTZqkXW7I659bQe+L9PR0/Pz8sLKy4ujRo4SFhWmDW0+eZAe6169fX+j5PXr0aJGO8WnNmzcnJCSE//u//wPg119/5dixYzrXaVZWFkOGDGHy5Ml4enrmu60mTZqUuD0gs84JIYQogqSU9BKvX8G68PwC1+7cZUNIKE/0DJHIycOxdvNmwnZsIS0tb/Dq9u3bLF74Ke5daqIuZ1R4yEJRQAV/bJiP1+Q1lNNYGnhEotSpVFB5KNycU/R1qwzNXl8I8Y+hKAonL/9erHVPXLpCszq1SzwbXWRkJBkZGfTu3Zvq1asD4OXlpV3+6quv6tRfvXo1tra2HD58mK5du2rLhw0bRv/+/QF4//338fHxYfr06fj5+QEwbtw4hg3TnTkzNTWVtWvXUrVqVQCWLl1Kly5dWLRoEY6Ojjp109LSmDt3LgcOHMDHxweAl156iWPHjrFq1SratGlT4HFGRETg7e1N48aNgb96COljY2ODjY0NkJ2zZ9WqVRw4cABHR0ciIiIIDAwkIiJCOzxn0qRJ7Nu3j8DAQObOnVtgOyD7Bn758uXUr19fW1bYeba3twfA1tY2z7nJbeHChbz//vvaHEbz58/n0KFDLF68mC+//BKAPXv2kJ6e/3cejUaj/X9UVFSenkaVKlUiISGBlJQUnbr52bRpE6dPn2bVqlXaslq1avHNN99Qr1494uPjWbhwIc2bN+fSpUtUq1ZN73Zu3bpFpUqVdIbNZfz5Xap27dra17RmzZra5Y0bNy40z1JhPakKk985ioqK0i7Xt5/cdQyVnp7OypUrqVGjBpAd9Jw9e7Z2uSGvf24FvS9++OEHsrKyWLNmjfZzJjAwEFtbW0JDQ/H19aV79+40bdq0wDbnvL+L64MPPiAhIYHatWtjbGxMZmYm//nPfxg8eLC2zvz58ylXrhxjx44tcFtVqlTh3LmS//AqgSYhhBAGs9Tk7WZb2uvn5OEoaPawyBvXObplY75JDhVFobWzDabGKsP7xSgKWU/SiDkfioNP18Lri2fHoQ9ELISsFAwbp2kERmZg3+dZt0wI8Zwlp6XlSfxtqJjERFLS0jA3IIFyQerXr0+7du3w8vLCz88PX19f+vbtS/ny5QGIjo5m2rRphIaGcv/+fTIzM0lOTiYiIkJnO/Xq1dP+P+eGOnfAqlKlSqSmppKQkIC1tTUAzs7OOjehPj4+ZGVlcfXq1TzBlPDwcJKTk+nQoYNO+ZMnT/D29i70ON9++2369OnD2bNn8fX1pWfPnjRv3rzAdc6dO8eQIUNYtmwZLVq0AODixYtkZmbqBDMgOxBmaK4kU1NTnfMFhp/ngiQkJHDv3j1tW3O0aNGCX3/9Vfs8J6D4PBw6dIhhw4bx1Vdf6fQ08fHx0QYMIbvXioeHB6tWrWLOHP0/xqSkpORJGO7m5sY333xDv379yMzMpFGjRhw/fly7XKPR4ObmVspHVXbMzc21QSaAypUra/N3Gvr651bQ++LXX38lPDwcKysrnXVSU1O1w2CtrKzyLC9tmzZtYv369Xz//fd4enpqc4VVqVKFgIAAzpw5w5IlSzh79myhgXeNRkNyKczyLIEmIYQQBrOzUuPqaMXN6MQizSKvUoFLJSvsrNQF1jMkD8eT1FSO79hS6Ixxfu52BS7Pz/0Tu7Bv1qXEv4CLEihnDbWWw5U3/iwo6LX+83WqvSJ7PQMoikJ8QnaOk/iEeBRFkddbiL+pJ+kFJ/8uTFp6BuYlizNhbGxMcHAwx48f56effmLp0qV89NFHnDp1CldXVwICAnj06BFLliyhevXqqNVqfHx8tENncuTOiZLzmaOvrLiJr5OSsie22L17d54eEmp1wX9/ATp16sStW7fYs2cPwcHBtGvXjnfeeYeFCxfqrR8VFUX37t0ZMWIEw4cP12mHsbExZ86c0Q7PymFpaViPYY1Gk+dz2dDzXBo8PT0LTLzdqlUr9u7dC4CjoyPR0bo5IKOjo7G2ti60N9Phw4fp1q0bn3/+Of7+/gXWNTExwdvbm/Dw8HzrVKxYkdjYWJ2y+/fv89FHHzFlyhT69u2r7YmW4+jRozpDrPRZtWqVTu+YosrvHOUES3P+jY6OpnLlyjp1cufXMsTTuYdUKlWJZhku6H2RlJREo0aN9A4tzOlht379ekaOHFngPvbu3UurVq2K3cbJkyfzwQcfaHtpeXl5cevWLebNm0dAQABHjx7l/v37ODs7a9fJzMzkvffeY/HixTo5pWJiYrRtLwkJNAkhhDCYSqViZFcPpn79c+GVnzKqa51Cb+Zz8nAU5OZvF8gooDs7gJWpMY6WhX+pzkshLSaKzJREypkbFrQQz0j5NuDxDVwd/WfPJtANOP15LRlpsoNMtq0L3WRCQgLbtm9j3XfrtL+ABwwNwNnZmSGvD6F3r97aXgRCiL8HU5OS3a6oS7h+DpVKRYsWLWjRogUzZsygevXqbN++nYkTJxIWFsby5cvp3LkzkD18++HDh6Wy34iICO7du6cdgnby5EmMjIyoVatWnrq5E2cXNkwuP/b29gQEBBAQEECrVq2YPHmy3kBTamoqPXr0oHbt2nz22Wc6y7y9vcnMzOT+/fslunl+miHn2cTEhMzMzHy3YW1tTZUqVQgLC9M5R2FhYTRp0kT7vChD53x8fNizZ4/O8uDgYJ3eSPqEhobStWtX5s+fz1tvvVVgXcgODFy8eFF7/Pp4e3sTFRVFbGystsfdkSNHSE5OZtasWXrXeR5D53x8fAgJCWH8+PHastznyNXVFUdHR0JCQrSBpYSEBE6dOsXbb79don3nZujr/7T83hcNGzbkhx9+wMHBId/vD89j6FxycnKeWQaNjY21QeshQ4bozZE1ZMiQPMN1f/vtN9q2bVui9oAEmoQQQhTRoFfcmPPdWVLSMsgy4AciIxVo1OUY+EqNAusZkodDURT+76z+5J65mZUr2VwXmWkpEmj6OyjfBhqfgAdb4V4QpOUaHqF2ys7JZN/HoJ5MR48eZczYMaSkpORZdvv2bebOm8vniz9n2RfLSvXGSAhRMuZqNXZWVsUaPmdnZYXGgJ48hTl16hQhISH4+vri4ODAqVOnePDggTbhsru7O+vWraNx48YkJCQwefJkg/LyGMLMzIyAgAAWLlxIQkICY8eOpX///npzEFlZWTFp0iQmTJhAVlYWLVu2JD4+nrCwMKytrQkICChwXzNmzKBRo0Z4enqSlpbGrl27dJJK5zZy5Ehu375NSEgIDx480Jbb2dlRs2ZNBg8ejL+/P4sWLcLb25sHDx4QEhJCvXr16NKlS7HOhSHn2cXFhZCQEFq0aIFardYGW3KbPHkyM2fOpEaNGjRo0IDAwEDOnz+v0yulKEPnRo0axbJly5gyZQpvvPEGBw8eZNOmTezevVtbZ9myZWzfvp2QkBAge7hc165dGTduHH369NHmITI1NdUmBJ89ezbNmjXDzc2NuLg4FixYwK1btxgxYkS+bfH29qZixYqEhYVp84N5eXmRlJTEtGnTGDJkCOXKlePChQvUqlWLOnXqFHnoXExMjDYACnD16lUA7cx4AP7+/lStWpV58+YB2fnH2rRpw6JFi+jSpQsbN27kl19+YfXq1UB2IHf8+PF88sknuLu74+rqyvTp06lSpQo9e/Y0uG2GMOT1z62g98XgwYNZsGABPXr00M5kd+vWLbZt28aUKVOoVq1akYfORUVFERUVpe25dvHiRaysrHB2dtZeG+3ataNXr17ayQO6devGf/7zH5ydnfH09OTcuXN89tlnvPFGds/wChUq5Bm2amJigqOjo07QOjk5mTNnzhiUR60wMuucEEKIIrG1VLPu/VdRqVQYFTLayEiV/eXhuw9exbaQHkaG5OFIT03lcVxsgXUAUjOKN+wgh7G6dG4QRCkoZw2Vh0HDUKjz55fAOuuzn1ceZnCQacRbI0hJSUFRlDxd6HPKUlJSGPHWiFKZbUUIUTpUKhXN6tQu1ro+nh6lMizW2tqaI0eO0LlzZ2rWrMm0adNYtGiRdrjR119/TWxsLA0bNmTIkCGMHTsWBweHQrZqGDc3N3r37k3nzp3x9fWlXr16LF++PN/6c+bMYfr06cybNw8PDw86duzI7t27cXV1LXRfpqamTJ06lXr16tG6dWuMjY3ZuHGj3rqHDx8mMjKSOnXqULlyZe0jJ/dPYGAg/v7+vPfee9SqVYuePXty+vRpnaE7RWXIeV60aBHBwcE4OTnlm5dq7NixTJw4kffeew8vLy/27dvHzp07cXd3L1a7XF1d2b17N8HBwdSvX59FixaxZs0abZJ3gIcPH2pz9gB8++23JCcnM2/ePJ3z17t3b22d2NhY3nzzTTw8POjcuTMJCQkcP36cOnXq5NsWY2Njhg0bphM0qVWrFlu3biU4OJiXX36ZevXq8cknnxR7yOHOnTvx9vbWBgwHDBiAt7c3K1eu1NaJiIggMjJS+7x58+Z8//33rF69mvr167NlyxZ27NhB3bp1tXWmTJnCu+++y1tvvcXLL79MUlIS+/bt08k51bZtW4YOHVqsduco6utf0PvC3NycI0eO4OzsTO/evfHw8GD48OGkpqYWu4f0ypUr8fb25s033wSgdevWeHt7s3PnTm2d69ev6/TmW7p0KX379mX06NF4eHgwadIkRo4cmW8ur/z873//w9nZuVR+cFMpJRmw+AJKSEjAxsaG+Ph46R4vhBAlcODsXYbMP0hyWvZQt9x/TXK+15ury/HdB6/SzrvwLsGxiUks2rS1wDopiYnsXLHEoPYt7uSGg4UpRkW6yVChtquE54QVkrPn7yjpN7jQDer9CJZ186127+Ejlv9vF6N7dMXS1IRWbVppg0yFUalUaDQajh4+WrrfEwxsuxDF9SJ8x01NTeXGjRu4urrmSVhckJS0JyzYuJn0jAyDpgdQASblyjF5QD80atNit7eszZo1ix07dhQ6rEmI3KKiovD09OTs2bPPNan581C9enU+/vjjEgebhH7NmjVj7NixDBo0SO/yonyGS48mIYQQxdK+YVWufN2fT4c3xaWSbpdgl0pWfDq8Kb9/85pBQSYwLA+HcTnDR3zvvxZjcN3cHHy6SpDpH2Tb9m0GB5kAbc+m7Tu2P+OWCSEMpVGbMrBdW1AVPpOoCkClYmC7ti90kEmI4nJ0dOTrr78u0mx8L4JLly5hY2NTaNJ0UTwPHz6kd+/eDBw4sFS2J4EmIYQQxWZrqebtbnU4v7IPP87J7iL+4xw/zq/sw9vd6mBjYfiX/Jw8HAUxMTPDwjZvvgV9Dt+K40lmFlmGdtxVqTAyVWPXoK1h9cXfnqIorPtuXbHWXbtubYlmqRFClC73alXx922HSSE/OJiUK4e/bzvcq5Usue4/0ahRo7C0tNT7GDVq1HNrR6dOnfJtR2nkhhHQs2fPf1y+QU9PTy5cuJAn6bUoHRUrVmTKlCml9mOrJAMXQghRYiqVShtUsrEwLdYfqZw8HHtO5Z/sW6VSUbPhy5w7+FOh20tOz+Kz47d5v2V1slAKHkKnUgEqagx8n3Iaw6ZeFn9/CYkJxfpFV1EUIiIiiIuL05tIVghRNtyrVWXygH6cD7/OiUtXdPL62VlZ4ePpgbd7DcxM/xk9mWbNmpXvTGHFMXv2bCZNmqR32fMcbrlmzRq9EzMA2mTHQogXmwSahHgOomKS+Wb/Vd7wq4WjnXlZN0eIvy1vdzcOnDlXYB4Ol7r1uHj0EBkFTDuc40L0YxYcv834ZtVyzUSXe8vZwScjEzU1Br6Ptbv+xKHixZSamlqi9R8/fiyBJiH+ZjRqU3w8PWhWpzYpaWmkpWegNimHRq2WYc+FcHBwKLUk5SVR0qnchRB/f9LvTIhnTFEUrt6J49ON57l6J06GYghRAEPycJiamdG8Z1+DbihUKhUXoh+T5fcuTl2Go7arpLNcbVcJpy7DqTflawky/QMVJdmwPhYWFqXUEiFEaVOpVJibmVHeyhJzMzMJMgkhxN+I9GgS4hmJS0rj+0PhrNp1hRtR2V27u03fj6ujFSO7ejDoFbdCp3sX4t8oJw/HhpBQnmRk6K1T2bUGr742mLAdW0hLSwPQCeLm3HBoNBqWLV1Gq5bZeQrsm3UhMyWRzLQUjNUajDVWcnPyD2ZtZY2zszO3b98uUpBfpVLh5OSEra3ts2ucEEIIIcQ/lPRoEuIZOHD2Lh7DNzH165+5GZ2os+xmdCJTv/4Zj+GbOHD2bhm1UIi/t5w8HF2aNcmTINzOyoouzZqw+KOphB0N46MPP8LJyUmnjpOTEx99+BHHjhzTBpkgO4BQztwadflKlDO3liDTP5xKpWLI60OKta7/EH+5PoQQQgghikF6NAlRyg6cvUu/OcEoioK+H9BzylLSMug3J5jN0zvQvqGMVRfiabnzcDyIi+P079d4ubY79ra22gCAmakpAf4B+A/xJzw8nB82/cBr/V/Dzc1NggQCgN69evP54s9JSUkxqFeTkZERZmZm9OrZ6zm0TgghhBDin0d6NAlRiuKS0hgy/yCKopBVyP1MlpI91GfI/IPEJaU9nwYK8Qw5ljfngwENcCxfugnvVSoVDuXL08WnCQ7ly+sNIKlUKtzd3Zn20TTc3d0lyCS0rK2tWfbFMlQqVaHXRc7yZUuXYW1tTXpiDPdCNpCeGPM8miqEKAJFUYiJieHOnTvExMRIDkwhhPgbkUCTEKXo+0PhJKdlFBpkypGlQHJaBhsOXX+2DRPiOXC0M+fDgd4ys6L422nVqhVrVq9Bo9HoDTjllGk0GtZ8tUY73DI9MZbIQz+QnhhbFs0WQuiRkJBA0LdBtPdtT1OfprzS7hWa+jSlvW97gr4NIiEhoayb+FwNHTqUnj17PvP93Lx5E5VKxfnz55/5vkrbrFmzaNCgQVk347lq3bo133//fVk344UUGhqKSqUiLi6urJvyXD18+BAHBwfu3LlTKtsr80DTl19+iYuLC2ZmZjRt2pSff/65wPqLFy+mVq1aaDQanJycmDBhQomnLxaiNCiKwqpdV8h3TvYCrNx1WX6JE0KIZ6hVq1YcPXy0SDm9hBB/L0ePHqVVm1bMnTeX27dv6yy7ffs2c+fNpVWbVhw9erSMWvjP5eTkRGRkJHXr1i3rphRIpVKxY8cOnbJJkyYREhLyTPcbGhpKw4YNUavVuLm5ERQUVGj9Hj16ULlyZSwsLGjQoAHr16/XqRMUFKT9ISTnYchsqjt37iQ6OpoBAwaU5JD0Sk9P5/3338fLywsLCwuqVKmCv78/9+7dK3Tdwu77U1NTeeedd6hQoQKWlpb06dOH6OjoUj+GwjRv3pzIyEhsbGye+74B/vOf/9C8eXPMzc0NnpRk27Zt+Pr6UqFChXwDwqtXr6Zt27ZYW1vrDaRVrFgRf39/Zs6cWfKDoIwDTT/88AMTJ05k5syZnD17lvr16+Pn58f9+/f11v/+++/54IMPmDlzJleuXOHrr7/mhx9+4MMPP3zOLRcir5jENG5EJRY5zqQocCMqkZhEGT4nhBDPkrW1NQH+ARz46QBrg9YCsDZoLQd+OkCAfwBWTyWeF0L8fRw9epQRb43Q5lt7+ge6nLKUlBRGvDVCgk2lzNjYGEdHR8qVe/4pfjMzM8nKyir2+paWllSoUKEUW6Trxo0bdOnShVdeeYXz588zfvx4RowYwf79+/Nd5/jx49SrV4+tW7dy4cIFhg0bhr+/P7t27dKpZ21tTWRkpPZx69atQtvzxRdfMGzYMIyMSv9WPzk5mbNnzzJ9+nTOnj3Ltm3buHr1Kt27dy9wPUPu+ydMmMCPP/7I5s2bOXz4MPfu3aN3796lfgyFMTU1xdHRsczSMDx58oR+/frx9ttvG7zO48ePadmyJfPnz8+3TnJyMh07diwwdjJs2DDWr19PTEzJUwaUaaDps88+480332TYsGHUqVOHlStXYm5uzjfffKO3/vHjx2nRogWDBg3CxcUFX19fBg4cWGgvKCGeh6SU9DJdXwghhGFUKhXW1tYA2l/2hBB/XwkJCYwZO0ZvgOlpOXXGjB1TqsPotmzZgpeXFxqNhgoVKtC+fXseP34MwOnTp+nQoQMVK1bExsaGNm3acPbsWZ31VSoVq1atomvXrpibm+Ph4cGJEycIDw+nbdu2WFhY0Lx5c65f/yudQs6Qr1WrVuHk5IS5uTn9+/cnPj4+33ZmZWUxb948XF1d0Wg01K9fny1bthh0jLGxsQwePBh7e3s0Gg3u7u4EBgYCeYfODR06NE9vG5VKRWhoKABpaWlMmjSJqlWrYmFhQdOmTbXLChMUFIStrS07d+6kTp06qNVqIiIiCj3PLi4uAPTq1QuVSqV9/vTQuaysLGbPnk21atVQq9U0aNCAffv2GdQ2fVauXImrqyuLFi3Cw8ODMWPG0LdvXz7//PN81/nwww+ZM2cOzZs3p0aNGowbN46OHTuybds2nXoqlQpHR0fto1KlSgW25cGDBxw8eJBu3brplK9bt446depgZmZG+fLl8fHxKdaoIBsbG4KDg+nfvz+1atWiWbNmLFu2jDNnzhAREZHveoXd98fHx/P111/z2Wef8eqrr9KoUSMCAwM5fvw4J0+eNLh9Oa/1unXrcHFxwcbGhgEDBpCY+Ncs4GlpaYwdOxYHBwfMzMxo2bIlp0+f1i5/eujcrVu36NatG+XLl8fCwgJPT0/27Nmjrf/bb7/RqVMnLC0tqVSpEkOGDOHhw4cGt/lpH3/8MRMmTMDLy8vgdYYMGcKMGTNo3759vnXGjx/PBx98QLNmzfKt4+npSZUqVdi+fXuR2qxPmQWanjx5wpkzZ3ROhpGREe3bt+fEiRN612nevDlnzpzRBpb++OMP9uzZQ+fOnZ9Lm4UoiKXGpEzXF0IIIYT4J9q2fZvBM0cC2p5N23eU/GYJIDIykoEDB/LGG29w5coVQkND6d27t7Y9iYmJBAQEcOzYMU6ePIm7uzudO3fWubkFmDNnDv7+/pw/f57atWszaNAgRo4cydSpU/nll1+yA2RjxuisEx4ezqZNm/jxxx/Zt28f586dY/To0fm2dd68eaxdu5aVK1dy6dIlJkyYwOuvv87hw4cLPc7p06dz+fJl9u7dy5UrV1ixYgUVK1bUW3fJkiU6PW3GjRuHg4MDtWvXBmDMmDGcOHGCjRs3cuHCBfr160fHjh25du1aoe2A7N4X8+fPZ82aNVy6dAkHB4dCz3NOsCAwMJDIyEid4MHTbV+0aBELFy7kwoUL+Pn50b17d522eXp6Ymlpme+jU6dO2ronTpzIc4Pv5+eX7z1tfuLj47Gzs9MpS0pKonr16jg5OdGjRw8uXbpU4DaOHTumDWTmuHnzJgEBAQwfPpzff/+dU6dOMXnyZIyNjYHs3oIFHaulpWWeYX1Pt1ulUuU7zMuQ+/4zZ86Qnp6uU6d27do4OzsX+Txev36dHTt2sGvXLnbt2sXhw4f59NNPtcunTJnC1q1b+fbbbzl79ixubm74+fnl24vnnXfeIS0tjSNHjnDx4kXmz5+PpaUlAHFxcbz66qt4e3vzyy+/sG/fPqKjo+nfv792/blz5xZ6fgsK0j1vTZo0KZUeoc+/7+OfHj58SGZmZp6obKVKlfj999/1rjNo0CAePnxIy5YtURSFjIwMRo0aVWD3r7S0NNLS/hqS9G9LECieHzsrNa6OVtyMTqQo6ZZUKnCpZIWdlfrZNU4IIYQQ4gWkKArrvltXrHXXrluL/xD/EvdajIyMJCMjg969e1O9enUAnd4Gr776qk791atXY2try+HDh+natau2fNiwYdob0Pfffx8fHx+mT5+On58fAOPGjWPYsGE620pNTWXt2rVUrVoVgKVLl9KlSxcWLVqEo6OjTt20tDTmzp3LgQMH8PHxAeCll17i2LFjrFq1ijZt2hR4nBEREXh7e9O4cWPgrx5C+tjY2Ghz2Gzbto1Vq1Zx4MABHB0diYiIIDAwkIiICKpUqQJk50nat28fgYGBzJ07t8B2QHYuoOXLl1O/fn1tWWHn2d7eHgBbW9s85ya3hQsX8v7772tzGM2fP59Dhw6xePFivvzySwD27NlDenr+ow00Go32/1FRUXrvaRMSEkhJSdGpm59NmzZx+vRpVq1apS2rVasW33zzDfXq1SM+Pp6FCxfSvHlzLl26RLVq1fRu59atW1SqVEln2FxGRgaQHbjJeU1r1qypXd64ceNCk7zn15MqNTWV999/n4EDB2p7Cj/NkPv+qKgoTE1N8wSrKlWqRFRUVIFte1pWVhZBQUHa4fBDhgwhJCSE//znPzx+/JgVK1YQFBSkDRZ+9dVXBAcH8/XXXzN58uQ824uIiKBPnz7a9/xLL72kXbZs2TK8vb11rulvvvkGJycn/u///o+aNWsyatQoncCTPjnvk7+DKlWqcO7cuRJvp8wCTcURGhrK3LlzWb58OU2bNiU8PJxx48YxZ84cpk+frnedefPm8fHHHz/nlop/I5VKxciuHkz9uuhDOUd1rSNDN4QQQgghnhIbG1usX/sVRSEiIoK4uDjKly9fojbUr1+fdu3a4eXlhZ+fH76+vvTt21e73ejoaKZNm0ZoaCj3798nMzOT5OTkPO2uV6+e9v85N925A1aVKlUiNTWVhIQE7U27s7OzNsgE4OPjQ1ZWFlevXs0TTAkPDyc5OZkOHTrolD958gRvb+9Cj/Ptt9+mT58+nD17Fl9fX3r27Enz5s0LXOfcuXMMGTKEZcuW0aJFCwAuXrxIZmamTjADsgNhhuZKMjU11TlfYPh5LkhCQgL37t3TtjVHixYt+PXXX7XPcwKKz8OhQ4cYNmwYX331FZ6entpyHx8fbcAQskf3eHh4sGrVKubMmaN3WykpKXkShru5ufHNN9/Qr18/MjMzadSoEcePH9cu12g0uLm5Fbnd6enp9O/fH0VRWLFiRZHXf1ZcXFx0ci5WrlxZmwvq+vXrpKen67z+JiYmNGnShCtXrujd3tixY3n77bf56aefaN++PX369NFem7/++iuHDh3S9nDK7fr169SsWRM7O7s8PdX+zjQaDcnJySXeTpkFmipWrIixsXGeTPLR0dH5RqCnT5/OkCFDGDFiBJD9wfz48WPeeustPvroI70Jz6ZOncrEiRO1zxMSEvLMNiNEaRn0ihtzvjtLSloGWQb0ajJSgUZdjoGv1Hj2jRNCCCGEeMGU9Ibn8ePHJQ40GRsbExwczPHjx/npp59YunQpH330EadOncLV1ZWAgAAePXrEkiVLqF69Omq1Gh8fH548eaKzHROTv9Ik5PzAqK+suImvk5KSANi9e7dOcApArS6853ynTp24desWe/bsITg4mHbt2vHOO++wcOFCvfWjoqLo3r07I0aMYPjw4TrtMDY25syZM9rhWTn03ZDro9Fo8vwIa+h5Lg2enp4FJt5u1aoVe/fuBcDR0VHvPa21tXWhvZkOHz5Mt27d+Pzzz/H39y+wromJCd7e3oSHh+dbp2LFisTGxuqU3b9/n48++ogpU6bQt2/fPLOpHT16VGcooD6rVq1i8ODB2uc5QaZbt25x8ODBfHsz5bSpsPt+R0dHnjx5QlxcnE6vpoJiA/nJ/Z6C7PdVSZLJjxgxAj8/P3bv3s1PP/3EvHnzWLRoEe+++y5JSUl069ZNbxLuypUrA9lD5wrrxXf58mWcnZ2L3cbSFBMTo+0dWBJlFmgyNTWlUaNGhISE0LNnTyD7QzUkJCTP2OQcycnJeYJJOR9e+Y3ZVqvVBn2wClEabC3VrHv/VfrNCcYIpcBgk5Eq+4Pvuw9exdZSrlEhhBBCiKeZm5uXaH0LC4tSaYdKpaJFixa0aNGCGTNmUL16dbZv387EiRMJCwtj+fLl2ryxt2/fLlEy4NwiIiK4d++edmjNyZMnMTIyolatWnnq5k6cXdgwufzY29sTEBBAQEAArVq1YvLkyXoDTampqfTo0YPatWvz2Wef6Szz9vYmMzOT+/fv06pVq2K1Qx9DzrOJiQmZmZn5bsPa2poqVaoQFhamc47CwsJo0qSJ9nlRhs75+PjoJIcGCA4O1umNpE9oaChdu3Zl/vz5vPXWWwXWhezZ9y5evFhgfmJvb2+ioqKIjY3VBliPHDlCcnIys2bN0rtOUYfO5QSZrl27xqFDhwrtpWbIfX+jRo0wMTEhJCSEPn36AHD16lUiIiIKPY9FUaNGDUxNTQkLC9P2WktPT+f06dOMHz8+3/WcnJwYNWoUo0aNYurUqXz11Ve8++67NGzYkK1bt+Li4pLvjIwv2tC53377jbZt25Z4O2U6dG7ixIkEBATQuHFjmjRpwuLFi3n8+LF2bLK/vz9Vq1Zl3rx5AHTr1o3PPvsMb29v7dC56dOn061btzzRciHKSvuGVdk8vQND5h8kOS17THTuOGjOjzMadTm+++BV2nlX1bMVIYQQQghRvnx5nJ2duX37tsHJwCE7MOTk5JRvguKiOHXqFCEhIfj6+uLg4MCpU6d48OCBNuGyu7s769ato3HjxiQkJDB58mSD8vIYwszMjICAABYuXEhCQgJjx46lf//+ent5WFlZMWnSJCZMmEBWVhYtW7YkPj6esLAwrK2tCQgIKHBfM2bMoFGjRnh6epKWlsauXbt0kkrnNnLkSG7fvk1ISAgPHjzQltvZ2VGzZk0GDx6Mv78/ixYtwtvbmwcPHhASEkK9evXo0qVLsc6FIefZxcWFkJAQWrRogVqt1tubbfLkycycOZMaNWrQoEEDAgMDOX/+vE7C66IMnRs1ahTLli1jypQpvPHGGxw8eJBNmzaxe/dubZ1ly5axfft2QkJCgOzhcl27dmXcuHH06dNHm4fI1NRUO8xq9uzZNGvWDDc3N+Li4liwYAG3bt3Sju7Rx9vbm4oVKxIWFqbND+bl5UVSUhLTpk1jyJAhlCtXjgsXLlCrVi3q1KlTpKFz6enp9O3bl7Nnz7Jr1y4yMzO1bbezs8PU1BSAdu3a0atXL20gqbD7fhsbG4YPH87EiROxs7PD2tqad999Fx8fnwJnSSsqCwsL3n77bSZPnoydnR3Ozs7897//JTk5WadXXm7jx4+nU6dO1KxZk9jYWA4dOqR9X7zzzjt89dVXDBw4kClTpmBnZ0d4eDgbN25kzZo1GBsbF3noXEREBDExMURERJCZmakNArq5uWl7BNauXZt58+bRq1cvAG39e/fuAdlBOkA7WyFk90CMiorS9oi7ePEiVlZWODs7a9uXnJzMmTNnDMqjViiljC1dulRxdnZWTE1NlSZNmignT57ULmvTpo0SEBCgfZ6enq7MmjVLqVGjhmJmZqY4OTkpo0ePVmJjYw3eX3x8vAIo8fHxpXgUQuQVm5iqLN95San31mbFqvs32ke9tzYry3deUuKS0sq6iUII8WJJvKgoYS7Z/xbg7oOHykdrgpS7Dx7mW+e3335T3Gq6Kb/99lu+dR7fDVf+n717j8v57h84/ro6XV2dRalIhU5IhSGtOaWcFzMTU04b24wxZu4p3dw3t02mmzn9mozb2Bxv543IHCJUM3IbZkLlsFBUV4fr+/sjXXPpdHUS9nk+HteDvt/P5/t9f79dV13Xu8/n/Tn92evSo5uXqx2ympaxC0J1vQjvcXNzc6WUlBQpNze3Sv1i1sRIzq7OUkuXllo/nF2dpTXfrKmVuFNSUqTAwEDJyspKksvlkouLi7RkyRL1/sTERKlDhw6SoaGh5OzsLG3atElycHCQvvzyS3UbQNq2bZv666tXr0qAlJSUpN526NAhCVB/tpk9e7bk6ekpLVu2TLKzs5MMDQ2lIUOGSJmZmeo+oaGh0uuvv67+WqVSSYsXL5ZcXV0lfX19ycrKSgoMDJQOHz5c6XXOnTtXcnd3lxQKhWRpaSm9/vrr0m+//VZmvA4ODhJQ6nHo0CFJkiQpPz9fCg8PlxwdHSV9fX3J1tZWGjRokHT27NlK44iJiZHMzc1LbdfmPu/YsUNq2bKlpKenJzk4OGjcxxJFRUVSRESE1KRJE0lfX1/y9PSU9u7dW2lcFTl06JDk5eUlGRgYSM2bN5diYmI09s+ePVsdjyQVf9/Kun9du3ZVt/noo4/Un5MbN24s9e3bV0pMTKw0lk8++UQaNmyYxrb//ve/UseOHSVTU1PJyMhIateuncZzT1slz4OKvveSVPz8mD17tkbfij73S1Lxz4f3339fatCggWRkZCQNGjRISk9P12hT1nGf9PT3WpIk6csvv9S497m5udKHH34oNWrUSJLL5ZKvr6+UkJCg3v/063DixIlSixYtJLlcLllZWUkjR46U7t798/3Fr7/+Kg0aNEiysLCQFAqF5ObmJn300UeSSqUq/0ZWoLznxpP3F9B4jsXExJTZ58l7NXv27DLbPHmcb7/9VnJ1dS03tqr8DJc9DvQvIysrC3Nzcx48eFDhXFJBqC2SJJGZreRhbgEmCn0sTeWi8LcgCEJ1PDwHZwdA251g0qbcZml3/2DZf3fx/uv9sWtU9pD+8+fPEzQ4iO1bt2sUX31STtoVLiz7GPf3IzGyq2EtPS1jF4TqehHe4+bl5XH16lWcnJxKFSyuSFZWFn5d/cjNzdVqVJOOjg6GhoYcOXzkub0X2oiIiGD79u2VTmsShCdlZGTQunVrEhMTn2lR87qWk5NDw4YN2bt3b61M7RJK69y5M5MmTWL48OFl7q/Kz/DS1bMFQahVMpmMhmaGODQ2paGZoUgyCYIgCIIgVIGZmRlL/70UmUxW6fuokv1Llyx9oZNMglBdNjY2fP3119VarfF5dujQIXr06CGSTHXk7t27DB48mODg4Fo5nkg0CYIgCIIgCILwXPPz8yN6VbR6NbKnE04l2xQKBdH/F43fq7VXhPplMWHCBExMTMp8TJgw4ZnF0adPn3LjqJXaMAJBQUG1Woj9edCvXz+NuldC7WrUqBGffPJJrQ2KqNdi4IIgCIIgCIIgCNrw8/PjyOEjbNu+jbXr1mqM2LC3tydkZAiDBw3G1NS0HqOsPREREeWuFFYdc+bMYdq0aWXue5ajv6Kjo8nNzS1zX1WKJguC8PwSiSZBEARBEARBEF4IZmZmhIaEEjIyhPv37/Po0SOMjY2xsLAQ5QkqYW1tjbW1dX2HQZMmYsVlQXjZiUSTIAiCIAiCIAgvFJlMRoMGDcpcvl4QBEGoX6JGkyAIgiAIgiAIgiAIglArRKJJEARBEARBEARBEARBqBUi0SQIgiAIgiAIgiAIgiDUClGjSRAEQRAEQRCEF4okSRTlZFOUn4uugQJdI1NRDFwQBOE5IUY0CYIgCIIgCILwQijMfcit4zs5/+V7/Dw/hHOR4/l5fgjnv3yPW8d3Upj7sL5DfKZGjRpFUFBQnZ/n999/RyaTkZycXOfnqm0RERF4eXnVdxi1JiwsjHfffbe+w3hhyWQytm/fXt9hPFMpKSk0bdqUR48ePbNzikSTIAiCIAiCIAjPvQeXkvjli3Hc2LMaZeYtjX3KzFvc2LOaX74Yx4NLSfUU4cvL3t6e9PR02rRpU9+hVKisJMK0adOIjY2t0/PGxcXRrl075HI5LVu2ZM2aNRW2L0ncPf04ceJEhf0yMjKIioris88+q8XoNW3atAk3NzcMDQ3x8PBgz549FbaPi4sr81oyMjI02n311Vc4OjpiaGhIp06dSEhIqLNrqEh6ejp9+vR55uctKChgxowZeHh4YGxsjJ2dHSEhIaSlpVXYLyIiotS9dXNz02iTl5fHBx98QMOGDTExMeGNN97g1q0/f0a2atWKzp07s2jRojq5trKIRJNQayRJ4lFeHveyH/IoLw9Jkuo7JEEQBEEQBOEl8OBSEpfXzkVVoASkx48nFW9TFSi5vHauSDbVMl1dXWxsbNDTe/aVV4qKilCpVNXub2JiQsOGDWsxIk1Xr16lX79+dO/eneTkZD766CPGjRvHDz/8UGnfAwcOkJ6ern60b9++wvbR0dF06dIFBweH2gpfw/HjxwkODmbs2LEkJSURFBREUFAQ586dq7TvxYsXNa7F2tpave+7775j6tSpzJ49m8TERDw9PQkMDOT27dt1ch0VsbGxQS6XP/Pz5uTkkJiYSFhYGImJiWzdupWLFy8ycODASvu2bt1a494ePXpUY/+UKVPYuXMnmzZt4vDhw6SlpTF48GCNNqNHj2b58uUUFhbW6nWVRySahBrLVeZz/FwKX27axvz13xH5/Rbmr/+OLzdt4/i5FHKV+eq2kiSRmZnJjRs3yMzMFMkoQRAEodaZGino7u2JqZGivkMRBKEWFOY+5LcNCwAJKnvvKBUnnH7bsKBWp9Ft3rwZDw8PFAoFDRs2xN/fXz0N5dSpU/Tq1YtGjRphbm5O165dSUxM1Ogvk8lYuXIl/fv3x8jICHd3d+Lj47l8+TLdunXD2NiYLl26cOXKFXWfkilfK1euxN7eHiMjI4YOHcqDBw/KjVOlUjF//nycnJxQKBR4enqyefNmra7x3r17jBgxAisrKxQKBc7OzsTExAClp86NGjWqzFEscXFxACiVSqZNm0aTJk0wNjamU6dO6n2VWbNmDRYWFuzYsYNWrVohl8tJTU2t9D47OjoCMGjQIGQymfrrp6fOqVQq5syZQ9OmTZHL5Xh5ebFv3z6tYivLihUrcHJyIjIyEnd3dyZOnMiQIUP48ssvK+3bsGFDbGxs1A99ff0K22/cuJEBAwZobEtISMDPzw9TU1OMjY3x8PDg1KlT1bqWqKgoevfuzfTp03F3d2fu3Lm0a9eOpUuXVtrX2tpa41p0dP5MNSxatIh33nmH0aNH06pVK1asWIGRkRGrV6/WOraSkVOxsbF06NABIyMjunTpwsWLFzXaLV++nBYtWmBgYICrqyvr1q3T2P/kqLf8/HwmTpyIra0thoaGODg4MH/+fHXb+/fvM27cOKysrDAzM6NHjx78/PPPWsf8JHNzc/bv38/QoUNxdXWlc+fOLF26lDNnzpCamlphXz09PY1726hRI/W+Bw8e8PXXX7No0SJ69OhB+/btiYmJ4fjx4xoj5Hr16kVmZiaHDx+uVvxVJRJNQo1cunGTLzZuYs/JU2RmZ2vsy8zOZs/JU3yxcRNJ//sfa75Zg3+AP518OtG9Z3c6+XTCP8CfNd+sISsrS91PkiRyb6WSujua3FupIhklCIIgVImpkRE923lhamRU36EIglAL/kg6hCpfWXmSqYQkocpXkpkcVyvnT09PJzg4mDFjxnDhwgXi4uIYPHiw+j1qdnY2oaGhHD16lBMnTuDs7Ezfvn3Jfuq98dy5cwkJCSE5ORk3NzeGDx/O+PHjmTlzJqdPn0aSJCZOnKjR5/Lly3z//ffs3LmTffv2kZSUxPvvv19urPPnz2ft2rWsWLGC8+fPM2XKFN5++22tPlyGhYWRkpLC3r17uXDhAsuXL9f4QPukqKgojREWkydPxtraWj2lZ+LEicTHx7Nx40bOnj3Lm2++Se/evbl06VKlcUDx6I8FCxYQHR3N+fPnsba2rvQ+lyRXYmJiSE9PLzfZEhUVRWRkJAsXLuTs2bMEBgYycOBAjdhat26NiYlJuY8np17Fx8fj7++vcY7AwEDi4+Mrvc6BAwdibW3Nq6++yo4dOypsm5mZSUpKCh06dNDYPmzYMBwcHEhISODcuXMsXryYxo0bq/dXdB0mJiZMmDChVq7Fy8sLW1tbevXqxbFjx9Tb8/PzOXPmjMZxdXR08Pf31+q4T/vss8+IjIzk9OnT6OnpMWbMGPW+bdu2MXnyZD7++GPOnTvH+PHjGT16NIcOHSrzWP/+97/ZsWMH33//PRcvXmT9+vXqBCXAm2++ye3bt9m7dy9nzpyhXbt29OzZk8zMTACOHDlS6f1dv359udfy4MEDZDIZFhYWFV7zpUuXsLOzo3nz5owYMUIjMXXmzBkKCgo07q+bmxvNmjXTuL8GBgZ4eXlx5MiRCs9VW8Sqc0K1Xbpxk7U/xlb6Sz/10kWGf/FPisoYpnf9+nXmzZ/Hl4u/ZGnkQlwM87hzYjfKzOI5vXfidyG3tMGqcz8aendHT2FSJ9ciCIIgCIIgPH8kSeLOid2UnipXudvxu7Dq3K/Gq9Glp6dTWFjI4MGD1VOWPDw81Pt79Oih0X7VqlVYWFhw+PBh+vfvr94+evRohg4dCsCMGTPw8fEhLCyMwMBAACZPnszo0aM1jpWXl8fatWtp0qQJAEuWLKFfv35ERkZiY2Oj0VapVDJv3jwOHDiAj48PAM2bN+fo0aOsXLmSrl27VnidqampeHt7qxMZT37gfpq5uTnm5uYAbN26lZUrV3LgwAFsbGxITU0lJiaG1NRU7OzsgOI6Sfv27SMmJoZ58+ZVGAcU17NZtmwZnp6e6m2V3WcrKysALCwsSt2bJy1cuJAZM2YwbNgwABYsWMChQ4dYvHgxX331FQB79uyhoKCg3GMoFH+OmM3IyNBI7AA0btyYrKwscnNzNdqWMDExITIyEl9fX3R0dNiyZQtBQUFs37693KlUqanFf4AvuaclCgsLadasGS1btkRfXx8nJyeN/ZUVcDczM6v0Wp6ut/QkW1tbVqxYQYcOHVAqlURHR9OtWzdOnjxJu3btuHv3LkVFRWUe93//+1+FsZXln//8p/q5/Omnn9KvXz/y8vIwNDRk4cKFjBo1Sp2MnTp1KidOnGDhwoV079691LFSU1Nxdnbm1VdfRSaTaUxJPHr0KAkJCdy+fVs91W7hwoVs376dzZs38+6779KhQ4dK7+/T110iLy+PGTNmEBwcrPE9eFqnTp1Ys2YNrq6upKen8/e//x0/Pz/OnTuHqakpGRkZGBgYlEpWlfV9s7Oz49q1axXGW1tEokmollxlPhti40CSKvy1n371Ckc2byx3VFLJdmczHXR+XMJ1PR1kaL4ZKCnumHZgPc2DZ2Du7F1LVyEIgiAIgiA8z4pystV/gKwaCWVmBkW52egZlf8hThuenp707NkTDw8PAgMDCQgIYMiQITRo0ACAW7duMWvWLOLi4rh9+zZFRUXk5OSUmg7Ttm1b9f9LPnw+mbBq3LgxeXl5ZGVlqT94NmvWTJ1kAvDx8UGlUnHx4sVSyZTLly+Tk5NDr169NLbn5+fj7V35++f33nuPN954g8TERAICAggKCqJLly4V9klKSmLkyJEsXboUX19fAH755ReKiopwcXHRaKtUKrWulWRgYKBxv0D7+1yRrKws0tLS1LGW8PX11ZgSVVc1kEo0atSIqVOnqr9+5ZVXSEtL44svvig30ZSbmwuAoaGhxvatW7cyaNAgPv/8cwwNDbl586Y6CQjQsmXLOriCP7m6uuLq6qr+umQK6Jdffllq2lptePJ5YWtrC8Dt27dp1qwZFy5cKLUin6+vL1FRUWUea9SoUfTq1QtXV1d69+5N//79CQgIAODnn3/m4cOHpZ6zubm56imuCoWiWve3oKCAoUOHIkkSy5cvr7Dtk6Pn2rZtS6dOnXBwcOD7779n7NixVTqvQqEgJyenyvFWh0g0CdWSdOky+ZUUEsvPy+P49s2VTn1r29iYT3ybIZPxOMVUVnFH1MUdW4aEiWSTIAiCIAjCX0BRfm7N+itza5xo0tXVZf/+/Rw/fpwff/yRJUuW8Nlnn3Hy5EmcnJwIDQ3ljz/+ICoqCgcHB+RyOT4+PuTn52sc58n6OyWjrMraVt3C1w8fFtek2r17t0ZyCtCq+HGfPn24du0ae/bsYf/+/fTs2ZMPPviAhQsXltk+IyODgQMHMm7cOI0PvA8fPkRXV5czZ86gq6ur0cfERLvZCQqFotRING3vc21o3bp1hSM//Pz82Lt3L1BcXPrJFb6gOClmZmZW5mim8nTq1In9+/eXu79kGuO9e/fUo7cAZs6cySuvvMKnn36KpaUlpqamGv0qu+dvv/02K1asqPBaKhohVpaOHTuqC1Y3atQIXV3dWjku1O5rpl27dly9epW9e/dy4MABhg4dir+/P5s3b+bhw4fY2tqWWVusZPTQkSNHKl3BbuXKlYwYMUL9dUmS6dq1axw8eLDC0UxlsbCwwMXFhcuXLwPF37P8/Hzu37+vMaqprPubmZlJixYtqnS+6hKJJqHKJEniRErlwxx/P3eWwgqGnAIY6eswtYs9MhnoVDasWZJABr9tWIDH9GgxjU4QBEEQBOElp2tQs6L+uvLaWRRAJpPh6+uLr68v4eHhODg4sG3bNqZOncqxY8dYtmwZffv2BYpLQ9y9e7dWzpuamkpaWpp6utSJEyfQ0dHRGEFS4snC2ZVNkyuPlZUVoaGhhIaG4ufnx/Tp08tMNOXl5fH666/j5uZWasl0b29vioqKuH37Nn5+ftWKoyza3Gd9fX2KiorKPYaZmRl2dnYcO3ZM4x4dO3aMjh07qr+uytQ5Hx8f9uzZo7F///796umL2kpOTlaP0ClLixYtMDMzIyUlRT1a7O7duxw4cIDk5GSNaYZPH7ciTyY6fHx8iI2N5aOPPlJvq+m1GBgY0L59e2JjYwkKCgKKE0OxsbGlapLVlLu7O8eOHSM0NFS97dixY7Rq1arcPmZmZrz11lu89dZbDBkyhN69e5OZmUm7du3IyMhAT0+v3GmkVZ06V5JkunTpEocOHarWaogPHz7kypUrjBw5EoD27dujr69PbGwsb7zxBlC8AmBqamqp79u5c+cYMmRIlc9ZHSLRJFRZjlJZqvD30yRJ4tfEylc76OpggYGuTuVJpj8PrC7uaO3Tv/L2giAIgiAIwgtL18gUuaUNysxbVK1Okwy5ZWN0FaaVN63EyZMniY2NJSAgAGtra06ePMmdO3dwd3cHwNnZmXXr1tGhQweysrKYPn16lUayVMTQ0JDQ0FAWLlxIVlYWkyZNYujQoWWOBDE1NWXatGlMmTIFlUrFq6++yoMHDzh27BhmZmYaH77LEh4eTvv27WndujVKpZJdu3apr/Fp48eP5/r168TGxnLnzh31dktLS1xcXBgxYgQhISFERkbi7e3NnTt3iI2NpW3btvTr169a90Kb++zo6EhsbCy+vr7I5XL19MYnTZ8+ndmzZ9OiRQu8vLyIiYkhOTlZo2hzVabOTZgwgaVLl/LJJ58wZswYDh48yPfff8/u3bvVbZYuXcq2bduIjY0F4JtvvsHAwEA9pXHr1q2sXr2a6Ojocs9TUkD76NGj6oRNo0aNsLe3Jzw8nPDwcBo1asTVq1fJz89XTwGrytSuyZMn07VrVyIjI+nXrx8bN27k9OnTrFq1St1m5syZ3Lx5k7Vr1wKwePFinJycaN26NXl5eURHR3Pw4EF+/PFHdZ+pU6cSGhpKhw4d6NixI4sXL+bRo0elapLV1PTp0xk6dCje3t74+/uzc+dOtm7dyoEDB8psv2jRImxtbfH29kZHR4dNmzZhY2ODhYUF/v7++Pj4EBQUxOeff46LiwtpaWns3r2bQYMG0aFDhypNnSsoKGDIkCEkJiaya9cuioqK1DWULC0tMTAwAKBnz54MGjRInYSbNm0aAwYMwMHBgbS0NGbPno2uri7BwcFAcb20sWPHMnXqVCwtLTEzM+PDDz/Ex8eHzp07q8//+++/c/PmzVLF3uuKWHVOqLL8goqnzAEU5OXx6P69StsFOltWK4bb8bvEanSCIAhCtVlZWfHhxA81ph8IgvD8kclkWHWuXmLC2qd/jQuBQ/GIh59++om+ffvi4uLCrFmziIyMVE+Z+frrr7l37x7t2rVj5MiRTJo0CWtr6xqfF4qTBIMHD6Zv374EBATQtm1bli1bVm77uXPnEhYWxvz583F3d6d3797s3r27VIHoshgYGDBz5kzatm3La6+9hq6uLhs3biyz7eHDh0lPT6dVq1bY2tqqH8ePHweKV34LCQnh448/xtXVlaCgIE6dOkWzZs2qdyPQ7j5HRkayf/9+7O3ty61LNWnSJKZOncrHH3+Mh4cH+/btY8eOHTg7O1crLicnJ3bv3s3+/fvx9PQkMjKS6OhodZF3KB55VFLXp8TcuXNp3749nTp14r///S/fffddpYmXcePGsXHjRo2pYnv37kWlUhEYGIiLiwvvvPNOqWlq2urSpQvffvstq1atwtPTk82bN7N9+3batGmjbpOenq5RFys/P199L7t27crPP//MgQMH6Nmzp7rNW2+9xcKFCwkPD8fLy4vk5GT27dunMdpn1KhRdOvWrVpxlwgKCiIqKoqFCxfSunVrVq5cSUxMTLnHNTU15fPPP6dDhw688sor/P777+zZswcdHR1kMhl79uzhtddeY/To0bi4uDBs2DCuXbtWboHvity8eZMdO3Zw48YN9Qp9T79uAK5cuaIxUu/GjRsEBwfj6urK0KFDadiwISdOnNB4//Lll1/Sv39/3njjDV577TVsbGzYunWrxvk3bNhAQEBAndcfKyGT/mKf1rOysjA3N+fBgwdVng8pFHuUl8f89d9V2CY3O5sdy8suulbCSE+H1YPK/iuJNjz/trbGc+4FQRCEF8jDc3B2ALTdCSZtKm9fQzlpV7iw7GPc34/EyK6GNQ2ecezCX8+L8B43Ly+Pq1ev4uTkVKqgcUUKcx/yyxfjUBUoK13tGACZDB19+QtfaiEiIoLt27dXOjVH+OuQJIlOnToxZcoU9YiWl0XXrl3p3r07ERER9R3KSyc/Px9nZ2e+/fbbUoXwq6IqP8PFiCahyozkcixNKx6GrKtX+axMA72aPf2KlDUrDikIgiAIgiA8//QUJjQPngHIoLIRSjIZIKNF8IwXOskkCGWRyWSsWrWKwkoWZXrRPHjwgCtXrjBt2rT6DuWllJqayt/+9rcaJZmqSiSahCqTyWR0buVWYRt9Q0OMLUrPiX5SfmH1VgcoUVvFHQVBEARBEITnm7mzNy1DwtDRl1O8TvHTCafibTr6cpxDwjATKxSXMmHCBExMTMp8TJgw4ZnF0adPn3LjmDdv3jOL40Xl5eWlLgT9sjA3N+fGjRtar0ooVE3Lli0ZP378Mz2nKAb+EpMkiaKcbIryc9E1UKBrZFpqnrokSWRmK3mYW4CJQh9LU7lWc9m9nVty4EwSBYWFZZZllMlkuLR7haSDP5axt1hOoYqMh0qsjQ20LwZefPRaK+4oCIIgCHVOkqDwQfH/Cx88XkW15nVjBOGvxtzZG4/p0WQmx3E7fhfKzAz1PrllY6x9+tPQuzu6hsb1GGXtiYiIqNVpRHPmzCl3xMiznG4ZHR1Nbm7ZMxMsLatXv1UQhOeLSDS9hApzH/JH0iHunNj91C9gG6w696Ohd3ceFunz7aHLrNx1gasZf64g52Rjyvj+7gzv3hILE3nxRkmCnF/h1nfQ+C0wckEhNyC4ZzfW/hiLTJLKTDY5tmnLL0cOUVjB0qA/XMpkpFfpVTMqU1vFHQVBEIQXiIE1NJ1c/O+LoDALbm+B9DWgfFw4NeVtkDcD21Fg/QboPZ+1dATheaWnMMHapz9WnftRlJtNkTIXXbkCXUXpP6gKmqytrWutSHlNNGnSpL5DEAShjoli4C+ZB5eS+G3DAlT5ysdbnvz2Fv/yPZ1rx+zUjuQWFE9de/IZUPL72Uiux4ZPXqGbbbzmG2TQeIN8KSObDbFx5JczTzj96hWObN74+Dyln2pG+jos6++Cga6OdqOaXpLijoIgCMLzr0bFwO8dhovvg6rkr/alfx+jowDXZdCga22EK/zFvQjvcatbDFwQBEGof6IY+F/Ug0tJXF47t3hFDiQoNc5IIiG7ETMutyM3vwhJKr1wR8k2H9v/0SF7INLvc0F5XbOR8jr8PhdO++BsfJnpw96kX+eOpQqEW5qaMi44mOXLV6BQKJDJZKX+0pRbKPFl/I3i81Z2gaK4oyAIgvAiuHcYLox5nGQq+/cxSMX7L4wpbi8IgiAIgvCSEFPnXhKFuQ/5bcMCoIzs0WMPi/SYndoRCRlSqQKKf+rpdJnvh2yooNXj4z9+g6xwX41P6650buVGrlKJsqAQub4eCvnjek+t3Tly+Ajbtm9j7bq1pKb+OTrK3t6eASNDaObZkvT/LqlwJJaOvpwWwTNEcUdBEATh+VWYVTySqcwE09Me77/4PnSIF9PoBEEQBEF4KYhE03MoOyeHhP/9Skc3F0yNjLTq80fSocdJmvLf1O671wylSrfCJJO5PI91QZuQIaFb6Xg3zTfIMj0zjAwNMSpjFJ2ZmRmhIaGEjAzh/v37PHr0CGNjYywsLNSjnBq5eP5lijsKgiAIL6nbW54YyaSNxyOb7mwB29F1GZkgCIIgCMIzIRJNz6HsnFwOJf2MezN7rRJNkiRx58RuKnpTK0mw7Q+nSt/2Dm/zM0b6BehoXUuxam+QZTIZDRo0oEGDBqX2ieKOgiAIwgtNkorrGlZH2hqwGSVWoxMEQRAE4YUnajQ9S5IEBZmQd6P43xrUYZckiczMTG7cuMHdtFSNEUBleVikR1q+CVQwmgkkxrdPqF5AaWtqdD1Pkslk6BmZIW/QGD0jM5FkEgRBEF4MhfceL55R1d+HUnG/wvt1EJQgvJwkSeKPrDyu3crmj6y8Mhed+SsYNWoUQUFBdX6e33//HZlMRnJycp2fq7ZFRETg5eVV32HUmrCwMN599936DuOF1a1bNz766KP6DuOZ69y5M1u2bHlm5xOJpmehMAvSYiCxG5xqD4l+j//tVry9MEvrQ2VlZbHmmzX4B/jTyacT3Xt25/X+fSrtp5R0K21jJs+jeYN7VRjNVEK8QRYEQRAEinJq2P9R7cQhCC+x+w+VLNt5Hq8JW3AauQGPdzfjNHIDXhO2sGznee4/VFZ+EKHK7O3tSU9Pp02bNvUdSoVkMhnbt2/X2DZt2jRiY2Pr9LxxcXG0a9cOuVxOy5YtWbNmTYXtSxJ3Tz9OnDhRYb+MjAyioqL47LPPajF6TZs2bcLNzQ1DQ0M8PDzYs2dPpX2++uor3N3dUSgUuLq6snbtWo39BQUFzJkzhxYtWmBoaIinpyf79u2rq0uo0NatW5k7d269nPv8+fO88cYbODo6IpPJWLx4cZX6X758GVNTUywsLErtq+z7NmvWLD799FNUKlUNrkB7ItFU1+4dhtM+xau0VbB6mzYrzhw5cgS/rn7Mmz+P69f/PFZeYeVPFrmsqNI2RnqFlbapkHiDLAiCIPwFZWTmMG9DEhlZNXxbpSvqEApCRQ4k3sR97PfM/DqB329la+z7/VY2M79OwH3s9xxIvFlPEb68dHV1sbGxQU/v2VdeKSoqqtGHYxMTExo2bFiLEWm6evUq/fr1o3v37iQnJ/PRRx8xbtw4fvjhh0r7HjhwgPT0dPWjffv2FbaPjo6mS5cuODg41Fb4Go4fP05wcDBjx44lKSmJoKAggoKCOHfuXLl9li9fzsyZM4mIiOD8+fP8/e9/54MPPmDnzp3qNrNmzWLlypUsWbKElJQUJkyYwKBBg0hKSqqT66iIpaUlpk+tlv6s5OTk0Lx5c/71r39hY2NTpb4FBQUEBwfj5+dXap8237c+ffqQnZ3N3r17a3wd2hCJprpUi8sbHzlyhHHvjiM3NxdJkjSGB2fnF5HxUImqgiHDJrqF2Bk8RFbBcP6cwhr+4hBvkAVBEIS/oIx7OfxrYzIZWQYgb0bF09TLIivup2dRB9EJwsvhQOJN3py7n1xlIVIZiyyXbMtVFvLm3P21nmzavHkzHh4eKBQKGjZsiL+/P48eFf+R9dSpU/Tq1YtGjRphbm5O165dSUxM1Ogvk8lYuXIl/fv3x8jICHd3d+Lj47l8+TLdunXD2NiYLl26cOXKFXWfkilfK1euxN7eHiMjI4YOHcqDBw/KjVOlUjF//nycnJxQKBR4enqyefNmra7x3r17jBgxAisrKxQKBc7OzsTExAClp86NGjWqzBE5cXFxACiVSqZNm0aTJk0wNjamU6dO6n2VWbNmDRYWFuzYsYNWrVohl8tJTU2t9D47OjoCMGjQIGQymfrrp6fOqVQq5syZQ9OmTZHL5Xh5edVodM2KFStwcnIiMjISd3d3Jk6cyJAhQ/jyyy8r7duwYUNsbGzUD319/Qrbb9y4kQEDBmhsS0hIwM/PD1NTU4yNjfHw8ODUqVPVupaoqCh69+7N9OnTcXd3Z+7cubRr146lS5eW22fdunWMHz+et956i+bNmzNs2DDeffddFixYoNHmb3/7G3379qV58+a899579O3bl8jIyCrFJ5PJiI6OZtCgQRgZGeHs7MyOHTs02hw+fJiOHTsil8uxtbXl008/pbDwzwEVT0+dW7ZsGc7OzhgaGtK4cWOGDBmi3leT11NZXnnlFb744guGDRuGXC6vUt9Zs2bh5ubG0KFDS+3T5vumq6tL37592bhxY7XjrwqRaKorVV7eWCpuX8Y0uqysLCZOmlgqwfSkHy5lVngGmQwGNbxaYZsspSG/3WtA1f9gIN4gC4IgCC8XSZIozC3+EFmY+0i7+i8ywHZU9U5oN0oUAheEctx/qGTkgoNIkoSqkpeiSip+/Y5ccLDWptGlp6cTHBzMmDFjuHDhAnFxcQwePFj9cyE7O5vQ0FCOHj3KiRMncHZ2pm/fvmRna466mjt3LiEhISQnJ+Pm5sbw4cMZP348M2fO5PTp00iSxMSJEzX6XL58me+//56dO3eyb98+kpKSeP/998uNdf78+axdu5YVK1Zw/vx5pkyZwttvv83hw5XPnggLCyMlJYW9e/dy4cIFli9fTqNGjcpsGxUVpTESZ/LkyVhbW+Pm5gbAxIkTiY+PZ+PGjZw9e5Y333yT3r17c+nSpUrjgOKRHwsWLCA6Oprz589jbW1d6X0uSa7ExMSQnp5ebrIlKiqKyMhIFi5cyNmzZwkMDGTgwIEasbVu3RoTE5NyH336/Fm6JD4+Hn9/f41zBAYGEh8fX+l1Dhw4EGtra1599dVSCZOnZWZmkpKSQocOHTS2Dxs2DAcHBxISEjh37hyLFy+mcePG6v0VXYeJiQkTJkyo0bUolUoMDTWXHVcoFCQkJFBQUFBhm6NHj1Z4zWX5+9//ztChQzl79ix9+/ZlxIgRZGYWfxa+efMmffv25ZVXXuHnn39m+fLlfP311/zjH/8o81inT59m0qRJzJkzh4sXL7Jv3z5ee+019X5tXk9Vub/VdfDgQTZt2sRXX31V5n5tv28dO3bkyJEjNY5HG2LVubpSk+WN9Qdq7Nm6bat6JFN5Dl+7z1se1hjo6qBTzhvV3g1S+fqWO0qVLlKZf22VsfJMR+b3rHyYZyniDbIgCILwEijMfcgfSYe4c2K3eqGNSzHhyC1tsOrcj4be3dFTmJR/AOs3IHVhFd4D6ICOIVi9USvxC8LL6NtDl8l5PJJJGyoJcpSFbDh0hfcGtKrx+dPT0yksLGTw4MHqKUseHh7q/T169NBov2rVKiwsLDh8+DD9+/dXbx89erR6NMKMGTPw8fEhLCyMwMBAACZPnszo0ZqrOOfl5bF27VqaNGkCwJIlS+jXrx+RkZGlpt4olUrmzZvHgQMH8PHxAaB58+YcPXqUlStX0rVr1wqvMzU1FW9vb3Uio2REUFnMzc0xNzcHimverFy5kgMHDmBjY0NqaioxMTGkpqZiZ2cHFNdJ2rdvHzExMcybN6/COKB4mtCyZcvw9PRUb6vsPltZWQFgYWFR4bSkhQsXMmPGDIYNGwbAggULOHToEIsXL1Z/kN+zZ486SVIWhUKh/n9GRoZGYgegcePGZGVlkZubq9G2hImJCZGRkfj6+qKjo8OWLVsICgpi+/btDBw4sFR7KP7+SJKkvqclCgsLadasGS1btkRfXx8nJyeN/ZUVcDczM6v0WjIyyl94KjAwkOjoaIKCgmjXrh1nzpwhOjqagoIC7t69i62tLYGBgSxatIjXXnuNFi1aEBsby9atWykqqry8y9NGjRpFcHAwAPPmzePf//43CQkJ9O7dm2XLlmFvb8/SpUuRyWS4ubmRlpbGjBkzCA8PR0dHc5xNamoqxsbG9O/fH1NTUxwcHPD29ga0fz1V5f5Wxx9//MGoUaP4z3/+U+6xtP2+2dnZcf36dVQqVal7UdtEoqku1GB5Y+nmGnJti3/Z5OYrUalUrPvPukr75RSoWHT8OjNedUCFVGayyUS3kL83S2Dm752Lz1VGsunbc56EvXYQhV4Bulo998QbZEEQBOHl8OBSEr9tWIAqv/QoCGXmLW7sWU3agfU0D56BubN32QfRMwPXZcVT4oGKk02Pfw+7LS/uJwhCKZIksXLXhaov5gis2JXChP7uNV7B2NPTk549e+Lh4UFgYCABAQEMGTKEBg0aAHDr1i1mzZpFXFwct2/fpqioiJycHFJTUzWO07ZtW/X/Sz4UPpmwaty4MXl5eWRlZak/UDZr1kydZALw8fFBpVJx8eLFUsmUy5cvk5OTQ69evTS25+fnqz88V+S9997jjTfeIDExkYCAAIKCgujSpUuFfZKSkhg5ciRLly7F19cXgF9++YWioiJcXFw02iqVSq1rJRkYGGjcL9D+PlckKyuLtLQ0dawlfH19+fnnn9Vf11UNpBKNGjVi6tSp6q9feeUV0tLS+OKLL8pNNOXm5gKUGhm0detWBg0axOeff46hoSE3b95UJwEBWrZsWQdX8KewsDAyMjLo3LkzkiTRuHFjQkND+fzzz9XJjKioKN555x3c3NyQyWS0aNGC0aNHs3r16iqf78nnhbGxMWZmZty+fRuACxcu4OPjo/Ga9/X15eHDh9y4cYNmzZppHKtXr144ODjQvHlzevfuTe/evdXT8rR9PdX1/X3nnXcYPny4xkir6lIoFKhUKpRKZZkJ0Nokps7VhWosb5xbZMjxzI58mRJEzL79AMTs3c/8b9ars9eVOXvrEQuOXiO/SIVKksqo2SSjo+ldFrRMRGGgi0xWehBSVr4hIdvfREJWzqgnzeMB4g2yIAiC8MJ7cCmJy2vnoipQUlFdRVWBkstr5/LgUgUFTBt0BffVoKOg+Hfl079PH2/TUUCrGLCo+ZtHQXhZZWYruZqRXeU8kyTB1YxsMrNrPn1OV1eX/fv3s3fvXlq1asWSJUtwdXXl6tXishShoaEkJycTFRXF8ePHSU5OpmHDhuTn52sc58n6OyUfhMvaVt3C1w8fPgRg9+7dJCcnqx8pKSla1ZXp06cP165dY8qUKaSlpdGzZ0+mTZtWbvuMjAwGDhzIuHHjGDt2rEYcurq6nDlzRiOOCxcuEBUVpdW1KBSKUglCbe9zbajK1DkbGxtu3bql0f/WrVuYmZlV6cN8p06duHz5crn7S6Yx3rt3T2P7zJkzeeWVV9T35OlC11WZ2lXetVQ0QkyhULB69WpycnL4/fffSU1NxdHREVNTU/UoMysrK7Zv386jR4+4du0a//vf/zAxMaF58+ba3ZwnPF3HSiaTVfs1Y2pqSmJiIhs2bMDW1pbw8HA8PT25f/++1q+nup46d/DgQRYuXIienh56enqMHTuWBw8eoKenp07Uaft9y8zMxNjYuM6TTCBGNNWNKi5vfOlhCzbceIt8SZ+n39jevVdx7aWnnb31iPd3/cprDhb0drbExuTPImNyy8ZY+/THy7s7bxXqseHQFVbsSuFqxp/zxx0bm9Kr5wiULXpgfG3S46H/PBXX4x/6OoriJJN4gywIgiC8wApzH/LbhgVAGRWGnyZJIIPfNizAY3p0+dPoGnSFDvHFU+LT1jz+A9RjcvviKedWb4g/1AhCJR7mlj99Sdv+Dc0MK29YCZlMhq+vL76+voSHh+Pg4MC2bduYOnUqx44dY9myZfTt2xeA69evc/fu3RqfE4qn9qSlpamnS504cQIdHR1cXV1LtX2ycHZl0+TKY2VlRWhoKKGhofj5+TF9+nQWLlxYql1eXh6vv/46bm5uLFq0SGOft7c3RUVF3L59u8wVsqpLm/usr69f4XQsMzMz7OzsOHbsmMY9OnbsGB07dlR/XZWpcz4+PqWWkt+/f796upW2kpOTsbW1LXd/ixYtMDMzIyUlRT1a7O7duxw4cIDk5GSNaYZPH7ciT07H8vHxITY2VqNYtrbXoq+vT9OmTYHiouX9+/cvNT3L0NCQJk2aUFBQwJYtW8osbF0T7u7ubNmyBUmS1InKY8eOYWpqqo7taXp6evj7++Pv78/s2bOxsLDg4MGD9OrVS6vXU11PnYuPj9d4Tv/3v/9lwYIFHD9+XD3aUdvv27lz57Qa3VgbRKKpLugaad300sMWrL0+4vFXpf/qqadvUOXT5xSo2Hc5k32XM4k/dBBThQG6cgW6ClP1C84CeG9AKyb0d+enX9IZEPYDO+cG8pqH7eM2rcBKvEEWBEEQXn5/JB16PF1OyzETkoQqX0lmchzWPv3Lb6dnBrajwWYUPIiHlBHQaj2Y+4i6hoKgJRNFxatw1XV/gJMnTxIbG0tAQADW1tacPHmSO3fu4O7uDoCzszPr1q2jQ4cOZGVlMX369FobMWBoaEhoaCgLFy4kKyuLSZMmMXTo0DJHmJiamjJt2jSmTJmCSqXi1Vdf5cGDBxw7dgwzMzNCQ0MrPFd4eDjt27endevWKJVKdu3apb7Gp40fP57r168TGxvLnTt31NstLS1xcXFhxIgRhISEEBkZibe3N3fu3CE2Npa2bdvSr1+/at0Lbe6zo6MjsbGx+Pr6IpfL1dMbnzR9+nRmz55NixYt8PLyIiYmhuTkZNavX69uU5WpcxMmTGDp0qV88sknjBkzhoMHD/L999+ze/dudZulS5eybds2YmNjAfjmm28wMDBQf+jfunUrq1evJjo6utzz6Ojo4O/vz9GjRwkKCgKKRznZ29sTHh5OeHg4jRo14urVq+Tn5xMQEABUbWrX5MmT6dq1K5GRkfTr14+NGzdy+vRpVq1apW4zc+ZMbt68ydq1awH49ddfSUhIoFOnTty7d49FixZx7tw5vvnmG3WfkydPcvPmTby8vLh58yYRERGoVCo++eQTrWPTxvvvv8/ixYv58MMPmThxIhcvXmT27NlMnTq1zJpEu3bt4rfffuO1116jQYMG7NmzB5VKhaurq9avp6rc3/z8fFJSUtT/v3nzJsnJyZiYmKiP8/Rz5enX4OnTp9HR0aFNmzbqbdp836B4JfuS50VdE1Pn6oJeA62WN84tMmTDjbcAkMr5VhgoFBhblP4BWRmZTEazZs1oaNsUeYPG6BmZlTk/XSaTYW5cnMwyNzbQbFPyBrldHLySCO2OPP43rni7SDIJgiAILzhJkrhzYjfVKQBzO36XlqvRyf78nalnJpJMglAFlqZynGxMq/yykcnAycYUS9OqLSFeFjMzM3766Sf69u2Li4sLs2bNIjIyUj196uuvv+bevXu0a9eOkSNHMmnSJKytrWt8Xij+EDt48GD69u1LQEAAbdu2ZdmyZeW2nzt3LmFhYcyfPx93d3d69+7N7t27SxWILouBgQEzZ86kbdu2vPbaa+jq6pa7FPrhw4dJT0+nVatW2Nraqh/Hjx8Hild+CwkJ4eOPP8bV1ZWgoCBOnTpVqkZOVWhznyMjI9m/fz/29vbljtyYNGkSU6dO5eOPP8bDw4N9+/axY8cOnJ2dqxWXk5MTu3fvZv/+/Xh6ehIZGUl0dLS6yDsUjzy6cuWKRr+5c+fSvn17OnXqxH//+1++++67UsXgnzZu3Dg2btyoMVVs7969qFQqAgMDcXFx4Z133ik1jUpbXbp04dtvv2XVqlV4enqyefNmtm/frpHUSE9P16iLVVRURGRkJJ6envTq1Yu8vDyOHz+uUUw+Ly+PWbNm0apVKwYNGkSTJk04evQoFhYW6jZr1qypcT21Jk2asGfPHhISEvD09GTChAmMHTuWWbNmldnewsKCrVu30qNHD9zd3VmxYgUbNmygdevWQM1eT2VJS0vD29sbb29v0tPTWbhwId7e3owbN07dpqznSmW0+b7dvHmT48ePV/ocqy0ySat3SC+PrKwszM3NefDgQY2HsVUoLQZ+n0tFb1yPZ3Ziz63eVJaQ+vV0AkkHf6zS6WUyGZ/97TNCQyr+ywVA8pW7vDZ1Jz8tGoBXi7KXMBUEQRCEl1Hhoyx+nh9S7f6ef1vLufT8yn+PPjwHZwdA251g0qbsNoJQA8/sPW4N5OXlcfXqVZycnEoVNK7Isp3nmfl1gtarzkFxoulfYzvVyqpz9SUiIoLt27dXOjVH+OuQJIlOnToxZcoU9cprL4vZs2dz+PBh4uLi6juUl9KMGTO4d+9eqVFOVVGVn+FiRFNdsX7jiSKgpUkSnMjspNWhHNu0RU9f+2G/Ojo6KBQKBgUN0rqPIAiCIPwVFeXnVt6oAoV5OTx4VFyI9sGjfO1GOAmCUCXDu7fESK6HjpaDHXRkYCTXI7h7i7oNTBCeMZlMxqpVqygsLKzvUGrd3r17+fzzz+s7jJeWtbU1c+fOfWbnE4mmulKyvHGZq81AXpEhmQWWZe57moGhIV2Chmg1lLCkzdIlS5/bv2YJgiAIwvNC16B6dVQeFumx+W5zOn36EwPCfgBgQNgPeE3YwrKd57n/sOYrXQmCUMzCRM66GT2QyWSVJpt0ZMXvh//zaQ8sTGo+be5lMmHChDpbGasq+vTpU24c8+bNe2ZxvKi8vLwYOXJkfYdR6xISEjQKsgu16+OPP6Zx48bP7Hxi6lxdu3cYLr5favW2+/lmLLwytUqHSr96hePbN1NYUIBMJtP4q2lJgkmhULB0yVL8XtV+hYeMzBxW/3CRMYGu2FhqX8hcEARBEF50kiRx/sv3UGbeQts6TQnZVsxO7YhSpQsymcZ0npK/CRnJ9Vg3owf+7YpXhBFT54S69jJPnStxIPEmIxccJEdZPJqjvNfefz7tQU/vJrUR8kvl9u3bZGVllbnPzMys1upKVebmzZvk5pY9mtTS0hJLS8tnEocgCFVTlZ/hItH0LBRmlVq97VGhEfMvVb3Kfn5eHr+fP8udixe4ceO6enuzZs0IGRnC4EGDMTU1ra3IBUEQBOGld+v4Tm7sWY02iaaEbCtm/t4ZCRlSBaOSS0ZVbArrVZxsEokmoY79FRJNAPcfKtlw6AordqVwNSNbvd3JxpQJ/VsxvEdL9UI3giAIQu2pys9wvWcU01/bk8sbF96HokcY6RhhmRFHZnZ2Zb01GBga0rlbTz5auoSTJ08SMiqEtWvW0rlz5xpX6RcEQRCEv6KG3t1JO7AeVYGSiqoNPyzSY3Zqx0qTTAAqCXSQGLngIBe+HopFLccsCH9VFiZy3hvQign93cnMVvIwtwAThT6WpnLxXlgQBOE5IWo0PUsyGeg3AMOmyAws6dzKrVqH8Wntjo6OjvqvVWZmZuIXqyAIgiBUk57ChObBMwAZFa2hvu9eM5Qq3UqTTCVUEuQoC9lwqGrLFAuCUDmZTEZDM0McGpvS0MxQvBcWBEF4johEUz3ydm6JgZ6elm9Xi8uGG+jp4dWyeAUNKysrPpz4IVZWVnUWoyAIgiD8FZg7e9MyJAwdfTllLeQhSTK2/dG8WsdesStFrEYnCIIgCMJfhkg01SOF3IDgnt1AJqs02SQDkMkI7tkNhbx43rm1tTWTPpz0zAr3CYIgCMLLzNzZG4/p0dj3G4vcUnNlljyzJqTlG2s9mqmEJMHVjGwe5OTXZqiCIAiCIAjPLZFoqmfOTZsQEtATfb2Ky2Xp6+kREtAT56ZiBQ1BEARBqCt6ChOsffrTespynMfMAcB5zByahtZsye3cx6tkCYIgCIIgvOxEouk54Ny0CdOHvUm/zh2xfGrFOEtTU/p17sgnwW+KJJMgCIIgPCMymQw9Q2MA9AyNMTWq2SpWCrlYf0UQapUkQUEm5N0o/vcvOj111KhRBAUF1fl5fv/9d2QyGcnJyXV+rtoWERGBl5dXfYdRa8LCwnj33XfrO4wXlkwmY/v27fUdxjN19+5drK2tuXHjxjM7p0g0PScUcgN8Wrsz5c1BjOnTC4AxfXox5c1B+LR2x9BALNMqCIIgCPXF0lSOk41pRbXCyySTFS+7bl7DRJUgCI8VZkFaDCR2g1PtIdHv8b/dircXZtV3hC8le3t70tPTadOmTX2HUqGykgjTpk0jNja2Ts8bFxdHu3btkMvltGzZkjVr1lTYviRx9/TjxIkTFfbLyMggKiqKzz77rBaj/9P//d//4efnR4MGDWjQoAH+/v4kJCRU2k+b6//qq69wdHTE0NCQTp06aXXcupCenk6fPn3q5dySJBEeHo6trS0KhQJ/f38uXbpUYZ/s7Gw++ugjHBwcUCgUdOnShVOnTqn3FxQUMGPGDDw8PDA2NsbOzo6QkBDS0tLUbRo1akRISAizZ8+us2t7mkg0PWdkMhmGBnIADA3EMq2CIAiC8DyQyWSM7+9erb4T+rcSv88FoTbcOwynfeD3uaC8rrlPeb14+2mf4nZCrdLV1cXGxga9Ssp91IWioiJUKlW1+5uYmNCwYcNajEjT1atX6devH927dyc5OZmPPvqIcePG8cMPP1Ta98CBA6Snp6sf7du3r7B9dHQ0Xbp0wcHBobbC1xAXF0dwcDCHDh0iPj4ee3t7AgICuHnzZrl9tLn+7777jqlTpzJ79mwSExPx9PQkMDCQ27dv18l1VMTGxga5XP7Mzwvw+eef8+9//5sVK1Zw8uRJjI2NCQwMJC8vr9w+48aNY//+/axbt45ffvmFgIAA/P391d+TnJwcEhMTCQsLIzExka1bt3Lx4kUGDhyocZzRo0ezfv16MjMz6/QaS4hEkyAIgiAIghaGd2+JkVwPHS1zRjoyMJLrEdy9Rd0GJgh/BfcOw4UxoMoFpMePJz3epsotblfLyabNmzfj4eGBQqGgYcOG+Pv78+jRIwBOnTpFr169aNSoEebm5nTt2pXExESN/jKZjJUrV9K/f3+MjIxwd3cnPj6ey5cv061bN4yNjenSpQtXrlxR9ymZ8rVy5Urs7e0xMjJi6NChPHjwoNw4VSoV8+fPx8nJCYVCgaenJ5s3b9bqGu/du8eIESOwsrJCoVDg7OxMTEwMUHrq3KhRo8ockRMXFweAUqlk2rRpNGnSBGNjYzp16qTeV5k1a9ZgYWHBjh07aNWqFXK5nNTU1Ervs6OjIwCDBg1CJpOpv3566pxKpWLOnDk0bdoUuVyOl5cX+/bt0yq2sqxYsQInJyciIyNxd3dn4sSJDBkyhC+//LLSvg0bNsTGxkb90NfXr7D9xo0bGTBggMa2hIQE/Pz8MDU1xdjYGA8PD40RL1Wxfv163n//fby8vHBzcyM6OhqVSlXhiDBtrn/RokW88847jB49mlatWrFixQqMjIxYvXq11rHFxcUhk8mIjY2lQ4cOGBkZ0aVLFy5evKjRbvny5bRo0QIDAwNcXV1Zt26dxv4nR73l5+czceJEbG1tMTQ0xMHBgfnz56vb3r9/n3HjxmFlZYWZmRk9evTg559/1jrmJ0mSxOLFi5k1axavv/46bdu2Ze3ataSlpZU7lS83N5ctW7bw+eef89prr9GyZUsiIiJo2bIly5cvB8Dc3Jz9+/czdOhQXF1d6dy5M0uXLuXMmTOkpqaqj9W6dWvs7OzYtm1bteKvKpFoEgRBEARB0IKFiZx1M3ogk8kqTTbpyIrfzP7n0x5YmNTPX04F4aVRmAUX36fsBNPTHre5+H6tTaNLT08nODiYMWPGcOHCBeLi4hg8eDDS47pQ2dnZhIaGcvToUU6cOIGzszN9+/YlOztb4zhz584lJCSE5ORk3NzcGD58OOPHj2fmzJmcPn0aSZKYOHGiRp/Lly/z/fffs3PnTvbt20dSUhLvv/9+ubHOnz+ftWvXsmLFCs6fP8+UKVN4++23OXy48sRbWFgYKSkp7N27lwsXLrB8+XIaNWpUZtuoqCiNkTiTJ0/G2toaNzc3ACZOnEh8fDwbN27k7NmzvPnmm/Tu3bvSaUIlcnJyWLBgAdHR0Zw/fx5ra+tK73NJciUmJob09PRyky1RUVFERkaycOFCzp49S2BgIAMHDtSIrXXr1piYmJT7eHLqVXx8PP7+/hrnCAwMJD4+vtLrHDhwINbW1rz66qvs2LGjwraZmZmkpKTQoUMHje3Dhg3DwcGBhIQEzp07x+LFi2nc+M+VUyu6DhMTEyZMmFDuOXNycigoKMDS0rLcNpVdf35+PmfOnNFoo6Ojg7+/v1b36GmfffYZkZGRnD59Gj09PcaMGaPet23bNiZPnszHH3/MuXPnGD9+PKNHj+bQoUNlHuvf//43O3bs4Pvvv+fixYusX79enaAEePPNN7l9+zZ79+7lzJkztGvXjp49e6pHBR05cqTS+7t+/XqgeORXRkaGxn0wNzenU6dO5d6HwsJCioqKMDQ01NiuUCg4evRouffowYMHyGQyLCwsNLZ37NiRI0eOlNuvNonKlIIgCIIgCFryb9eETWG9GLngIDmPV5J7sgZxyQw5hVyP/3zag57eYiEPQaix21ueGMmkjccjm+5sAdvRNT59eno6hYWFDB48WD1lycPDQ72/R48eGu1XrVqFhYUFhw8fpn///urto0ePZujQoQDMmDEDHx8fwsLCCAwMBGDy5MmMHq0Zb15eHmvXrqVJk+KfJUuWLKFfv35ERkZiY2Oj0VapVDJv3jwOHDiAj48PAM2bN+fo0aOsXLmSrl27VnidqampeHt7qxMZT37gfpq5uTnm5uYAbN26lZUrV3LgwAFsbGxITU0lJiaG1NRU7OzsgOI6Sfv27SMmJoZ58ypfxbOgoIBly5bh6emp3lbZfbaysgLAwsKi1L150sKFC5kxYwbDhg0DYMGCBRw6dIjFixfz1VdfAbBnzx4KCgrKPYZCoVD/PyMjQyOxA9C4cWOysrLIzc3VaFvCxMSEyMhIfH190dHRYcuWLQQFBbF9+/ZSU55KpKamIkmS+p6WKCwspFmzZrRs2RJ9fX2cnJw09ldWwN3MzKzcfTNmzMDOzq5UIulJlV3/vXv3KCoqKrPN//73vwpjK8s///lP9XP5008/pV+/fuTl5WFoaMjChQsZNWqUOhk7depUTpw4wcKFC+nevXupY6WmpuLs7Myrr76KTCbTmJJ49OhREhISuH37tnqq3cKFC9m+fTubN2/m3XffpUOHDpXe35LrzsjI0Pj6yf0l+55mamqKj48Pc+fOxd3dncaNG7Nhwwbi4+Np2bJlmX3y8vKYMWMGwcHBpb63dnZ2JCUlVRhvbRGJpueQqZGC7t6emBqV/qEkCIIgCEL98m/XhAtfD2XDoSus2JXC1Yw/Ry04NjZlQv9WDO/REnNjUQBcEGpMkiB9TfX6pq0Bm1FUuYr/Uzw9PenZsyceHh4EBgYSEBDAkCFDaNCgAQC3bt1i1qxZxMXFcfv2bYqKisjJydGYtgLQtm1b9f9LPmw+mbBq3LgxeXl5ZGVlqT8gNmvWTJ1kAvDx8UGlUnHx4sVSyZTLly+Tk5NDr169NLbn5+fj7e1d6XW+9957vPHGGyQmJhIQEEBQUBBdunSpsE9SUhIjR45k6dKl+Pr6AvDLL79QVFSEi4uLRlulUql1rSQDAwON+wXa3+eKZGVlkZaWpo61hK+vr8aUqLqqgVSiUaNGTJ06Vf31K6+8QlpaGl988UW5iabc3FyAUqNbtm7dyqBBg/j8888xNDTk5s2b6iQgUG5CojL/+te/2LhxI3FxcaXOWZ+efF7Y2toCcPv2bZo1a8aFCxdKrcjn6+tLVFRUmccaNWoUvXr1wtXVld69e9O/f38CAgIA+Pnnn3n48GGp52xubq56iqtCoaj2/dXWunXrGDNmDE2aNEFXV5d27doRHBzMmTNnSrUtKChg6NChSJKknlr3JIVCQU5OTp3GW0Ikmp5DpkZG9GznVd9hCIIgCIJQDgsTOe8NaMWE/u789Es6A8J+YOfcQF7zsBWFvwWhNhXeA6X2iYQ/ScX9Cu+DfoMahaCrq8v+/fs5fvw4P/74I0uWLOGzzz7j5MmTODk5ERoayh9//EFUVBQODg7I5XJ8fHzIz8/XOM6T9XdKfk6Uta26ha8fPnwIwO7duzWSU4BWxY/79OnDtWvX2LNnD/v376dnz5588MEHLFy4sMz2GRkZDBw4kHHjxjF27FiNOHR1dTlz5gy6uroafUxMTLS6FoVCUepnqbb3uTa0bt2aa9eulbvfz8+PvXv3AsXFpW/duqWx/9atW5iZmZU5mqk8nTp1Yv/+/eXuL5nGeO/ePfXoLYCZM2fyyiuv8Omnn2JpaYmpqalGv8ru+dtvv82KFSs0ti1cuJB//etfHDhwoFTC72mVXb+uri66urpltqlo5Fl5avM1065dO65evcrevXs5cOAAQ4cOxd/fn82bN/Pw4UNsbW3LrC1WMiXtyJEjla5gt3LlSkaMGKG+1lu3bqkTZCVfP1lD7GktWrTg8OHDPHr0iKysLGxtbXnrrbdo3ry5RruSJNO1a9c4ePBgmSPVMjMzNZ47dUkkmgRBEARBEKpJJpOpRy6ZGxuIJJMg1LaiGv71vehRjRNNUPxa9/X1xdfXl/DwcBwcHNi2bRtTp07l2LFjLFu2jL59+wJw/fp17t69W+NzQvHUnrS0NPV0qRMnTqCjo4Orq2uptk8Wzq5smlx5rKysCA0NJTQ0FD8/P6ZPn15moikvL4/XX38dNzc3Fi1apLHP29uboqIibt++jZ+fX7XiKIs291lfX5+ioqJyj2FmZoadnR3Hjh3TuEfHjh2jY8eO6q+rMnXOx8eHPXv2aOzfv3+/evqitpKTkzUSEE9r0aIFZmZmpKSkqEeL3b17lwMHDpCcnKwxzfDp41bk6YTE559/zj//+U9++OGHUvWgylLZ9RsYGNC+fXtiY2MJCgoCUBcYf7omWU25u7tz7NgxQkND1duOHTtGq1atyu1jZmbGW2+9xVtvvcWQIUPo3bs3mZmZtGvXjoyMDPT09MqdRlqVqXNOTk7Y2NgQGxurTixlZWVx8uRJ3nvvvUqvzdjYGGNjY+7du8cPP/zA559/rt5XkmS6dOkShw4dKnfk4Llz5+jWrVul56oNItEkCIIgCIIgCMLzSdeohv2NaxzCyZMniY2NJSAgAGtra06ePMmdO3dwd3cHwNnZmXXr1tGhQweysrKYPn16lUayVMTQ0JDQ0FAWLlxIVlYWkyZNYujQoWWOBDE1NWXatGlMmTIFlUrFq6++yoMHDzh27BhmZmYaH77LEh4eTvv27WndujVKpZJdu3apr/Fp48eP5/r168TGxnLnzh31dktLS1xcXBgxYgQhISFERkbi7e3NnTt3iI2NpW3btvTr169a90Kb++zo6EhsbCy+vr7I5XL19MYnTZ8+ndmzZ9OiRQu8vLyIiYkhOTlZXbQZqjZ1bsKECSxdupRPPvmEMWPGcPDgQb7//nt2796tbrN06VK2bdumXr3tm2++wcDAQD2lcevWraxevZro6Ohyz1NSQPvo0aPqhE2jRo2wt7cnPDyc8PBwGjVqxNWrV8nPz1dPAavK1K4FCxYQHh7Ot99+i6Ojo7p2UElhaygeQXXz5k3Wrl2r9fVPnTqV0NBQOnToQMeOHVm8eDGPHj0qVZOspqZPn87QoUPx9vbG39+fnTt3snXrVg4cOFBm+0WLFmFra4u3tzc6Ojps2rQJGxsbLCws8Pf3x8fHh6CgID7//HNcXFxIS0tj9+7dDBo0iA4dOlRp6pxMJuOjjz7iH//4B87Ozjg5OREWFoadnZ36+wnQs2dPBg0apE7C/fDDD0iShKurK5cvX2b69Om4ubmp711BQQFDhgwhMTGRXbt2UVRUpP6+WVpaYmBQ/MewnJwczpw5o1WNtFoh/cU8ePBAAqQHDx7UdyiCIAiCIDzHHt28LJ3+7HXp0c3LFbZLunxHMh24Wkq6fKf8Rtm/SNIxx+J/BaEOvAjvcXNzc6WUlBQpNzdX+04qlSSdfk2SjjkVv4a0fjgV91Opahx3SkqKFBgYKFlZWUlyuVxycXGRlixZot6fmJgodejQQTI0NJScnZ2lTZs2SQ4ODtKXX36pbgNI27ZtU3999epVCZCSkpLU2w4dOiQB0r179yRJkqTZs2dLnp6e0rJlyyQ7OzvJ0NBQGjJkiJSZmanuExoaKr3++utP3C6VtHjxYsnV1VXS19eXrKyspMDAQOnw4cOVXufcuXMld3d3SaFQSJaWltLrr78u/fbbb2XG6+DgULIEoMbj0KFDkiRJUn5+vhQeHi45OjpK+vr6kq2trTRo0CDp7NmzlcYRExMjmZubl9quzX3esWOH1LJlS0lPT09ycHDQuI8lioqKpIiICKlJkyaSvr6+5OnpKe3du7fSuCpy6NAhycvLSzIwMJCaN28uxcTEaOyfPXu2Oh5JkqQ1a9ZI7u7ukpGRkWRmZiZ17NhR2rRpU6Xn2bNnj9SkSROpqKhIve3cuXNS//79pYYNG0oGBgZSy5YtpbVr11brOsr7vs6ePVvdJjQ0VOratatGv8quX5IkacmSJVKzZs0kAwMDqWPHjtKJEyc09pd13KfP8eTrQ5IkKSkpSQKkq1evqrctW7ZMat68uaSvry+5uLiUuhdPvhZXrVoleXl5ScbGxpKZmZnUs2dPKTExUd02KytL+vDDDyU7OztJX19fsre3l0aMGCGlpqaWG2dFVCqVFBYWJjVu3FiSy+VSz549pYsXL2q0cXBw0Ljf3333ndS8eXPJwMBAsrGxkT744APp/v376v0lr82KXo+SJEnffvut5OrqWq24S1TlZ7hMkp5cK+Xll5WVhbm5OQ8ePKiwwr4gCIIgCH9tBdmZ3En4AauOgeiblr+0c/KVu7w2dSc/LRqAV4uylwLn4Tk4OwDa7gSTNnUUsfBX9iK8x83Ly+Pq1as4OTlVrbhwWgz8PhftV50DkIFTWK2sOldfIiIi2L59e6VTc4S/DkmS6NSpE1OmTCE4OLi+w6lVXbt2pXv37kRERNR3KC+lzp07M2nSJIYPH17tY1TlZ7hOtc8iCIIgCILwEtM3tcSuZ3CFSSZBEJ4B6zdARwFoWwNNp7i91Rt1GZUgPHMymYxVq1ZRWFhY36HUqgcPHnDlyhWmTZtW36G8lO7evcvgwYOfaXJSJJoEQRAEQRAEQXh+6ZmB6zKKE02VJZse73dbXtxPUJswYYK61s7TjwkTJjyzOPr06VNuHM+sfswLzMvLi5EjR9Z3GLXK3NycGzduaL0qoVA1jRo14pNPPnmmC5aIYuCCIAiCIAh1zcAamk4u/lcQhKpr0BXcV8PF90GV+3jjk1PpHn+A0lEUJ5ksXnvWEda6iIiIWp1GNGfOnHJHjDzL6ZbR0dHk5uaWuc/SUowgFYSXgUg0CYIgCIIg1DUDa2j2UX1HIQgvtgZdoUM83NkCaWtAmfrnPrk92I0qni4nRjKVydraGmvr+k92N2nSpL5DEAShjolEkyAIgiAIgiAILwY9s+IC3zajoPA+FD0CXWPQs4BnOC1EEARBKJ9INAmCIAiCIAiC8GKRyUC/QfFDEARBeK6IYuCCIAiCIAiCIAiCIAhCrRCJJkEQBEEQBEEQBEEQBKFW1Hui6auvvsLR0RFDQ0M6depEQkJChe3v37/PBx98gK2tLXK5HBcXF/bs2fOMohUEQRAEQRAEQRAEQRDKU6+Jpu+++46pU6cye/ZsEhMT8fT0JDAwkNu3b5fZPj8/n169evH777+zefNmLl68yP/93/+JlQsEQRAEQRCeUJCdSVrsBgqyM+s7FEGoE5Ik8Sgvj3vZD3mUl4ckSfUdkiAIgvBYvSaaFi1axDvvvMPo0aNp1aoVK1aswMjIiNWrV5fZfvXq1WRmZrJ9+3Z8fX1xdHSka9eueHp6PuPIBUEQBEEQnl8F2fdIP/QdBdn36jsUQahVucp8jp9L4ctN25i//jsiv9/C/PXf8eWmbRw/l0KuMr++Q3ymRo0aRVBQUJ2f5/fff0cmk5GcnFzn56ptEREReHl51XcYZQoLC+Pdd9+t7zBeWI6OjixevLi+w3jmOnfuzJYtW+o7jArVW6IpPz+fM2fO4O/v/2cwOjr4+/sTHx9fZp8dO3bg4+PDBx98QOPGjWnTpg3z5s2jqKio3PMolUqysrI0HoIgCIIgCIIgvFgu3bjJFxs3sefkKTKzszX2ZWZns+fkKb7YuIlLN27WU4QvL3t7e9LT02nTpk19h1IhmUzG9u3bNbZNmzaN2NjYOjtneno6w4cPx8XFBR0dHT766COt+mVkZBAVFcVnn31WZ7Ft2rQJNzc3DA0N8fDwqLTkTFxcHDKZrNQjIyND3eann35iwIAB2NnZlXm/n6VTp07VW6Kuuvdh/fr1eHp6YmRkhK2tLWPGjOGPP/7QaFPZ923WrFl8+umnqFSq2rqcWldviaa7d+9SVFRE48aNNbY3btxY44n8pN9++43NmzdTVFTEnj17CAsLIzIykn/84x/lnmf+/PmYm5urH/b29rV6HYIgCIIgCIIg1K1LN26y9sdYCgoLK2xXUFjI2h9jRbKplunq6mJjY4Oent4zP3dRUVGNPlCbmJjQsGHDWoxIk1KpxMrKilmzZlVppk10dDRdunTBwcGhTuI6fvw4wcHBjB07lqSkJIKCgggKCuLcuXOV9r148SLp6enqh7W1tXrfo0eP8PT05KuvvqqTuKvCysoKIyOjejl3de7DsWPHCAkJYezYsZw/f55NmzaRkJDAO++8o26jzfetT58+ZGdns3fv3lq9ptpU78XAq0KlUmFtbc2qVato3749b731Fp999hkrVqwot8/MmTN58OCB+nH9+vVnGLEgCIIgCIIgCDWRq8xnQ2wcSBKVVWKSACSJDbFxtTqNbvPmzXh4eKBQKGjYsCH+/v48evQIKB5V0atXLxo1aoS5uTldu3YlMTFRo79MJmPlypX0798fIyMj3N3diY+P5/Lly3Tr1g1jY2O6dOnClStX1H1KpnytXLkSe3t7jIyMGDp0KA8ePCg3TpVKxfz583FyckKhUODp6cnmzZu1usZ79+4xYsQIrKysUCgUODs7ExMTA5SeOjdq1KgyR77ExcUBxcmXadOm0aRJE4yNjenUqZN6X2XWrFmDhYUFO3bsoFWrVsjlclJTUyu9z46OjgAMGjQImUym/vrpqXMqlYo5c+bQtGlT5HI5Xl5e7Nu3T6vYyuLo6EhUVBQhISGYm5tr3W/jxo0MGDBAY1tCQgJ+fn6YmppibGyMh4cHp06dqlZcUVFR9O7dm+nTp+Pu7s7cuXNp164dS5curbSvtbU1NjY26oeOzp9pgz59+vCPf/yDQYMGVSsu+PP5tHXrVrp3746RkRGenp6lZjZt2bKF1q1bI5fLcXR0JDIyUmP/k1PnJEkiIiKCZs2aIZfLsbOzY9KkSeq2NXlOlqU69yE+Ph5HR0cmTZqEk5MTr776KuPHj9dYEE2b75uuri59+/Zl48aN1Y6/rtVboqlRo0bo6upy69Ytje23bt3CxsamzD62tra4uLigq6ur3ubu7k5GRgb5+WX/IpHL5ZiZmWk8BEEQBEEQnjfZOTnEJiaTnZNTYbvbt2/z7yX/LnfxFEF42SRdukx+YWGlSaYSEpBfWEjy5SuVttVGeno6wcHBjBkzhgsXLhAXF8fgwYPVBcizs7MJDQ3l6NGjnDhxAmdnZ/r27Uv2U9P75s6dS0hICMnJybi5uTF8+HDGjx/PzJkzOX36NJIkMXHiRI0+ly9f5vvvv2fnzp3s27ePpKQk3n///XJjnT9/PmvXrmXFihWcP3+eKVOm8Pbbb3P48OFKrzMsLIyUlBT27t3LhQsXWL58OY0aNSqzbVRUlMaIl8mTJ2NtbY2bmxsAEydOJD4+no0bN3L27FnefPNNevfuzaVLlyqNAyAnJ4cFCxYQHR3N+fPnsba2rvQ+lyRkYmJiSE9PLzdBExUVRWRkJAsXLuTs2bMEBgYycOBAjdhat26NiYlJuY8+ffpodR3lyczMJCUlhQ4dOmhsHzZsGA4ODiQkJHDu3DkWL16sMQOoophMTEyYMGGCum18fLxGmRqAwMDAcsvUPMnLywtbW1t69erFsWPHanStFfnss8+YNm0aycnJuLi4EBwcTOHjUYtnzpxh6NChDBs2jF9++YWIiAjCwsJYs2ZNmcfasmULX375JStXruTSpUts374dDw8P9f7KnpOpqamV3t958+bV6Hp9fHy4fv06e/bsQZIkbt26xebNm+nbt6+6jbbft44dO3LkyJEaxVOXnv3Yx8cMDAxo3749sbGx6gJ2KpWK2NjYUj9gS/j6+vLtt9+iUqnUWdVff/0VW1tbDAwMnlXogiAIgiAItS47J5dDST/j3swe0wqmAty5c4clS5fQs0dPjekMgvAykiSJEyn/q1bf+PMX6NzKDZlMVqMY0tPTKSwsZPDgweppTk9+gO3Ro4dG+1WrVmFhYcHhw4fp37+/evvo0aMZOnQoADNmzMDHx4ewsDACAwMBmDx5MqNHj9Y4Vl5eHmvXrlWvsr1kyRL69etHZGRkqT/OK5VK5s2bx4EDB/Dx8QGgefPmHD16lJUrV9K1a9cKrzM1NRVvb2918qNkRFBZSsqSAGzdupWVK1dy4MABbGxsSE1NJSYmhtTUVOzs7IDiOkn79u0jJiZGqw/rBQUFLFu2TGMqWmX32crKCgALC4tyBy4ALFy4kBkzZjBs2DAAFixYwKFDh1i8eLF6GtSePXsoKCgo9xgKhaLSa6hIamoqkiSp70+JwsJCmjVrRsuWLdHX18fJyUljf2XF2J8cVJGRkVGlMjVQPLBjxYoVdOjQAaVSSXR0NN26dePkyZO0a9dOy6vT3rRp0+jXrx8Af//732ndujWXL1/Gzc2NRYsW0bNnT8LCwgBwcXEhJSWFL774glGjRpU6VmpqKjY2Nvj7+6Ovr0+zZs3o2LGjel9lz0k7O7tK76+lpWWNrtfX15f169fz1ltvkZeXR2FhIQMGDNCYfqft983Ozo7r169r5EaeJ/WWaAKYOnUqoaGhdOjQgY4dO7J48WIePXqk/gEbEhJCkyZNmD9/PgDvvfceS5cuZfLkyXz44YdcunSJefPmaQyJEwRBEARBEATh5ZCjVJYq/K2tzOxscpVKjAwNaxSDp6cnPXv2xMPDg8DAQAICAhgyZAgNGjQAimdkzJo1i7i4OG7fvk1RURE5OTmkpqZqHKdt27bq/5d8kHwyYdW4cWPy8vLIyspSJwyaNWumTjJB8YgIlUrFxYsXSyVTLl++TE5ODr169dLYnp+fj7e3d6XX+d577/HGG2+QmJhIQEAAQUFBdOnSpcI+SUlJjBw5kqVLl+Lr6wvAL7/8QlFRES4uLhptlUql1rWSDAwMNO4XaH+fK5KVlUVaWpo61hK+vr78/PPP6q/rqm5SidzcXAAMn3pubt26lUGDBvH5559jaGjIzZs3NabjtWzZsk7jcnV1xdXVVf11yXTOL7/8knXr1tX6+Z78Htva2gLFo3bd3Ny4cOECr7/+ukZ7X19fFi9eTFFRkcYsJ4A333yTxYsX07x5c3r37k3fvn0ZMGAAenp6Wj0n9fT06vz+pqSkMHnyZMLDwwkMDCQ9PZ3p06czYcIEvv766yodS6FQoFKpUCqVNU581oV6TTS99dZb3Llzh/DwcDIyMtTzY0t+8Kampmpk5+zt7fnhhx+YMmUKbdu2pUmTJkyePJkZM2bU1yUIgiAIgiAIglBH8gsqLv5dGWVBIUY1yzOhq6vL/v37OX78OD/++CNLlizhs88+4+TJkzg5OREaGsoff/xBVFQUDg4OyOVyfHx8SpX20NfXV/+/ZJRVWduqW/j64cOHAOzevVsjOQXF5UQq06dPH65du8aePXvYv38/PXv25IMPPmDhwoVlts/IyGDgwIGMGzeOsWPHasShq6vLmTNnSiUDTExMtLoWhUJRaiSatve5NrRu3Zpr166Vu9/Pz69GhZhLpiTeu3dPPRILiusLv/LKK3z66adYWlpiamqq0a+y+/f222+r6xfb2NhUqUxNeTp27MjRo0er1Edbtfn8t7e35+LFixw4cID9+/fz/vvv88UXX3D48GGtnpOpqam0atWqwnP87W9/429/+1u14oPiqa2+vr5Mnz4dKE60GRsb4+fnxz/+8Q9sbW21/r5lZmZibGz8XCaZoJ4TTVA8V7K8qXJlFefy8fHhxIkTdRyVIAiCIAiCIAj1zUC/Zh9X5DXsX0Imk+Hr64uvry/h4eE4ODiwbds2pk6dyrFjx1i2bJm6zsr169e5e/durZw3NTWVtLQ09XSfEydOoKOjozHqpMSThbMrmyZXHisrK0JDQwkNDcXPz4/p06eXmWjKy8vj9ddfV09xepK3tzdFRUXcvn0bPz+/asVRFm3us76+PkVFReUew8zMDDs7O44dO6Zxj44dO6aeZgV1P3WuRYsWmJmZkZKSoh5lc/fuXQ4cOEBycnK5q9dVZeqcj48PsbGxfPTRR+pt+/fvV0+r1FZycrJ6tNGz5O7uXqo+1LFjx0rVbH6SQqFgwIABDBgwgA8++AA3Nzd++eUXrZ6Tz2LqXE5OTqmVG0uupaTmm7bft3Pnzmk1UrG+1HuiSRAEQRAE4UVm08CIT4d5YdOgfpZYFoSXmZFcjqWpabWmz1mamqLQYiRPZU6ePElsbCwBAQFYW1tz8uRJ7ty5g7u7OwDOzs6sW7eODh06kJWVxfTp02ttlIGhoSGhoaEsXLiQrKwsJk2axNChQ8sclWJqasq0adOYMmUKKpWKV199lQcPHnDs2DHMzMwIDQ2t8Fzh4eG0b9+e1q1bo1Qq2bVrl/oanzZ+/HiuX79ObGwsd+7cUW+3tLTExcWFESNGEBISQmRkJN7e3ty5c4fY2Fjatm2rrslTVdrcZ0dHR2JjY/H19UUul6unNz5p+vTpzJ49mxYtWuDl5UVMTAzJycmsX79e3aaqU+dKEhQPHz7kzp07JCcnY2BgUO4IGR0dHfz9/Tl69Ki6XnGjRo2wt7cnPDyc8PBwGjVqxNWrV8nPzycgIACo2tS5yZMn07VrVyIjI+nXrx8bN27k9OnTrFq1St1m5syZ3Lx5k7Vr1wKwePFinJycaN26NXl5eURHR3Pw4EF+/PFHdZ+HDx9y+fJl9ddXr14lOTkZS0tLmjVrpnV8lfn444955ZVXmDt3Lm+99Rbx8fEsXbqUZcuWldl+zZo1FBUV0alTJ4yMjPjPf/6DQqHAwcGBhg0bVvqcrOrUOW3uw9P3d8CAAbzzzjssX75cPXXuo48+omPHjupksjbfN4AjR46onxfPo+evapQgCIIgCMILxMbSiL8Fe2NjKRJNglDbZDIZnVu5VauvT2v3GhcCh+JRIj/99BN9+/bFxcWFWbNmERkZqV557Ouvv+bevXu0a9eOkSNHMmnSpFor1N+yZUsGDx5M3759CQgIoG3btuV+0Ibile3CwsKYP38+7u7u9O7dm927d5cqKl0WAwMDZs6cSdu2bXnttdfQ1dUtd/n0w4cPk56eTqtWrbC1tVU/jh8/DhSv/BYSEsLHH3+Mq6srQUFBnDp1qkaJCG3uc2RkJPv378fe3r7c0R6TJk1i6tSpfPzxx3h4eLBv3z527NiBs7NztWPz9vbG29ubM2fO8O233+Lt7a2xklhZxo0bx8aNGzWmiu3duxeVSkVgYCAuLi688847paZRaatLly58++23rFq1Ck9PTzZv3sz27dtp06aNuk16erpGjav8/Hz1fenatSs///wzBw4coGfPnuo2p0+fVl8vFNdd9vb2Jjw8XN0mIiKiwmLy2mjXrh3ff/89GzdupE2bNoSHhzNnzpwyC4FDcRH4//u//8PX15e2bdty4MABdu7cqa7BVNvPSW3uw9P3d9SoUSxatIilS5fSpk0b3nzzTVxdXdm6dau6jTbft5s3b3L8+PFSiwc8T2RSyRitv4isrCzMzc158OCBxtBCQRAEQRCE+pR29w+W/XcX77/eH7tG5RfMPX/+PEGDg9i+dTutW7cus01O2hUuLPsY9/cjMbJrUVchC8+RF+E9bl5eHlevXsXJyalUEeSK5Crz+WLjJgoKC9Hmg4sM0NfTY/qwN1HIX9yVqSMiIti+fXul03mEF5MkSXTq1IkpU6YQHBxc3+HUqtDQUGQyGWvWrKnvUF5KM2bM4N69e6VGOdW1qvwMFyOaBEEQBEEQBEF4binkBgT37AYyGZWNT5IByGQE9+z2QieZhJefTCZj1apVFBbWrOD980aSJOLi4pg7d259h/LSsra2fu7vr0g0CYIgCIIgvEQkSaIw9xEAhbmP+IsNXhdeUs5NmxAS0BN9vYpLzOrr6RES0BPnpk0qbPdXNGHCBExMTMp8TJgw4ZnF0adPn3LjmDdv3jOL43ng5eXFyJEj6zuMWiWTybh27Rr29vb1HcpL6+OPP6Zx48b1HUaFRDFwQRAEQRCEF4QkSTzIegDAg6wHSJKkrkFTmPuQP5IOcefEbpSZGQBciglHbmmDVed+NPTujp5Cu6XFBeF55Ny0CdOHvUny5SvEn7+gUSDc0tQUn9bueDu3wNDg5RjJFBERQURERK0db86cOUybNq3Mfc9yumV0dDS5ubll7qvpql6CIDwfRKJJEARBEAThOZeVlcXWbVtZ95916sKioaNCadasGSPfHkmgV0sy/rsUVb6yVF9l5i1u7FlN2oH1NA+egbnz87scsiBURiE3wKe1O51buZGrVKIsKESur4dCLq+Vwt8vM2tr61orUl4TTZqI0WaC8LITiSZBEARBEITn2JEjR5g4aWKZIwCuX7/OrtVRtPJtho5OefVriqfOqQqUXF47l5YhYSLZJLzwZDIZRoaGGGlfU1wQBEF4RkSNJkEQBEEQhHomSRK5j0cj5eYr1XWVjhw5wrh3x5Gbm4skSaXqLSn0ZEzxaYpMRqVFkpEkQOK3DQsozH1Y+xchCIIgCIKAGNEkCIIgCIJQb3KV+SRdusyJlP+p683E7N2PpakpHg5N+fjDD8pMMJXo6mCBga4OOtpOGZIkVPlKMpPjsPbpX1uXIQiCIAiCoCYSTYIgCIIgCPXg0o2bbIiNI7+Mpa0zs7P5vzXflFswt0Sgc/UK596O34VV536ipo0gCIIgCLVOJJoEQRAEQRCesUs3brL2x9jH09lKkySJXxNPVXgMIz0dbEzk1Ti7hDIzg6LcbPSMnt1KU4JQmyRJ4t69e+Tk5GBkZESDBg1E4lQQBOE5IWo0CYIgCIIgPEO5ynw2xMaBJFF2mgnyc3N5dP9ehccx0KvZ27giZcWjpQTheZSVlcWab9bgH+BPJ59OdO/ZnU4+nfAP8GfNN2vIysqq7xCfqVGjRhEUFFTn5/n999+RyWQkJyfX+blqW0REBF5eXvUdRpnCwsJ499136zuMF1a3bt346KOP6juMZ27YsGFERkbWdxgVEokmQRAEQRCEZyjp0mXyCwvLTTIBFBbkV3qc/EJVjeLQlStq1F8QnrUjR47g19WPefPncf36dY19169fZ978efh19ePIkSP1FOHLy97envT0dNq0aVPfoVRIJpOxfft2jW3Tpk0jNja2zs6Znp7O8OHDcXFxQUdHR+vER0ZGBlFRUXz22Wd1FtumTZtwc3PD0NAQDw8P9uzZU2mfr776Cnd3dxQKBa6urqxdu1Zjf0FBAXPmzKFFixYYGhri6enJvn376uoSKrR161bmzp1bL+c+f/48b7zxBo6OjshkMhYvXlxpn7y8PEaNGoWHhwd6enqVJomPHTuGnp5eqUTprFmz+Oc//8mDBw+qfwF1TCSaBEEQBEEQnhFJkjiR8r9K2+npG1TaJqdQRcZDJapypt+VT4bc0gZdhWkV+wlC/alsBcaSbbm5uYx7d5xINtUyXV1dbGxs0NN79pVXioqKUKmqn1g3MTGhYcOGtRiRJqVSiZWVFbNmzcLT01PrftHR0XTp0gUHB4c6iev48eMEBwczduxYkpKSCAoKIigoiHPnzpXbZ/ny5cycOZOIiAjOnz/P3//+dz744AN27typbjNr1ixWrlzJkiVLSElJYcKECQwaNIikpKQ6uY6KWFpaYmpaP7/LcnJyaN68Of/617+wsbHRqk9RUREKhYJJkybh7+9fYdv79+8TEhJCz549S+1r06YNLVq04D//+U+1Yn8WRKJJEARBEAThGclRKtWry1XEQKHA2KJBpe1+uJRZrTisffqLejbCCyMrK4uJkyZWuAJjiZI2EydNrNVpdJs3b8bDwwOFQkHDhg3x9/fn0aNHAJw6dYpevXrRqFEjzM3N6dq1K4mJiRr9ZTIZK1eupH///hgZGeHu7k58fDyXL1+mW7duGBsb06VLF65cuaLuUzLla+XKldjb22NkZMTQoUMrHMWgUqmYP38+Tk5OKBQKPD092bx5s1bXeO/ePUaMGIGVlRUKhQJnZ2diYmKA0lPnRo0ahUwmK/WIi4sDipMv06ZNo0mTJhgbG9OpUyf1vsqsWbMGCwsLduzYQatWrZDL5aSmplZ6nx0dHQEYNGgQMplM/fXTU+dUKhVz5syhadOmyOVyvLy8ajQix9HRkaioKEJCQjA3N9e638aNGxkwYIDGtoSEBPz8/DA1NcXY2BgPDw9Onaq4Xl95oqKi6N27N9OnT8fd3Z25c+fSrl07li5dWm6fdevWMX78eN566y2aN2/OsGHDePfdd1mwYIFGm7/97W/07duX5s2b895779G3b98qT+WSyWRER0czaNAgjIyMcHZ2ZseOHRptDh8+TMeOHZHL5dja2vLpp59S+MQCGk9PnVu2bBnOzs4YGhrSuHFjhgwZot5Xk9dGWV555RW++OILhg0bhlyuXb1EY2Njli9fzjvvvFNpcmrChAkMHz4cHx+fMvcPGDCAjRs3VjnuZ0UkmgRBEARBEJ6R/ILSK8yVRSaT4dLulUrbHb52n/wilfajmmQydAzkWHp10669IDwHtm7bqh7JpI2SkU3btm+rlfOnp6cTHBzMmDFjuHDhAnFxcQwePFgdT3Z2NqGhoRw9epQTJ07g7OxM3759yX4qqTx37lxCQkJITk7Gzc2N4cOHM378eGbOnMnp06eLE2QTJ2r0uXz5Mt9//z07d+5k3759JCUl8f7775cb6/z581m7di0rVqzg/PnzTJkyhbfffpvDhw9Xep1hYWGkpKSwd+9eLly4wPLly2nUqFGZbaOiokhPT1c/Jk+ejLW1NW5ubgBMnDiR+Ph4Nm7cyNmzZ3nzzTfp3bs3ly5dqjQOKB4tsmDBAqKjozl//jzW1taV3ueShExMTAzp6enlJmiioqKIjIxk4cKFnD17lsDAQAYOHKgRW+vWrTExMSn30adPH62uozyZmZmkpKTQoUMHje3Dhg3DwcGBhIQEzp07x+LFi2ncuLF6f0UxmZiYMGHCBHXb+Pj4UqNmAgMDiY+PLzcupVKJoaGhxjaFQkFCQgIFBQUVtjl69GjVbgLw97//naFDh3L27Fn69u3LiBEjyMws/gPKzZs36du3L6+88go///wzy5cv5+uvv+Yf//hHmcc6ffo0kyZNYs6cOVy8eJF9+/bx2muvqfdr89qoyv2tSzExMfz222/Mnj273DYdO3YkISEBpVL5TGKqqmqNfSwsLCQuLo4rV64wfPhwTE1NSUtLw8zMDBMTk9qOURAEQRAE4aVgoK/9Wy/HNm355cghCh+/uS9LToGKRcevM+NVB1RI6FQ0SkkmA2S0CJ6BnkK8XxNeDJIkse4/66rVd+26tYSMDKnx6L309HQKCwsZPHiwepqTh4eHen+PHj002q9atQoLCwsOHz5M//791dtHjx7N0KFDAZgxYwY+Pj6EhYURGBgIwOTJkxk9erTGsfLy8li7di1NmjQBYMmSJfTr14/IyMhSIyKUSiXz5s3jwIED6lEQzZs35+jRo6xcuZKuXbtWeJ2pqal4e3urkx8lI4LKYm5urh69s3XrVlauXMmBAwewsbEhNTWVmJgYUlNTsbOzA4rrJO3bt4+YmBjmzZtXYRxQXAdo2bJlGlPRKrvPVlZWAFhYWFQ4WmThwoXMmDGDYcOGAbBgwQIOHTrE4sWL+eqrrwDYs2ePOrFSFoWiZjXuUlNTkSRJfX9KFBYW0qxZM1q2bIm+vj5OTk4a+ysrxm5m9udKohkZGRpJKoDGjRuTkZFRbv/AwECio6MJCgqiXbt2nDlzhujoaAoKCrh79y62trYEBgayaNEiXnvtNVq0aEFsbCxbt26lqKhIy6v/06hRowgODgZg3rx5/Pvf/yYhIYHevXuzbNky7O3tWbp0KTKZDDc3N9LS0pgxYwbh4eHo6GiOmUlNTcXY2Jj+/ftjamqKg4MD3t7egPavjarc37py6dIlPv30U44cOVLhVFU7Ozvy8/PJyMios+mXNVHlRNO1a9fo3bs3qampKJVKevXqhampKQsWLECpVLJixYq6iFMQBEEQBOGFZySXY2lqqt30OUNDugQN4cjmjRWO5Dh76xGfH0tlio89cj0ZMmSgUWq8+EO2jr6cFsEzMHP2ruFVCMKzc+/ePVJTU6vcT5IkUlNTuX//Pg0aVD4NtSKenp707NkTDw8PAgMDCQgIYMiQIerj3rp1i1mzZhEXF8ft27cpKioiJyenVNxt27ZV/78kAfBkwqpx48bk5eWRlZWl/kDbrFkzdZIJwMfHB5VKxcWLF0slUy5fvkxOTg69evXS2J6fn6/+wF2R9957jzfeeIPExEQCAgIICgqiS5cuFfZJSkpi5MiRLF26FF9fXwB++eUXioqKcHFx0WirVCq1rpVkYGCgcb9A+/tckaysLNLS0tSxlvD19eXnn39Wf13XH9xzc4tX/Xx6ZNDWrVsZNGgQn3/+OYaGhty8eVNjOl7Lli3rNK6wsDAyMjLo3LkzkiTRuHFjQkND+fzzz9WJnaioKN555x3c3NyQyWS0aNGC0aNHs3r16iqf78nvsbGxMWZmZty+fRuACxcu4OPjo5Eo9vX15eHDh9y4cYNmzZppHKtXr144ODjQvHlzevfuTe/evdXT8rR9bdT1/a1MUVERw4cP5+9//3up18/TSpKdOTk5zyK0Kqtyomny5Ml06NCBn3/+WeMHxaBBg3jnnXdqNThBEARBEISXiUwmo3MrN/ac1K7mhq1TC/yGDOP49s0UPa5L8WTSqeQN+KUsFarAD2lmqOR2/C6UmX/+xVpu2Rhrn/409O6OrqFxLV6NINS9mn6IevToUY0TTbq6uuzfv5/jx4/z448/smTJEj777DNOnjyJk5MToaGh/PHHH0RFReHg4IBcLsfHx4f8fM3VI/X19dX/L3ntlrWtuoWvHz58CMDu3bs1klOAVjVk+vTpw7Vr19izZw/79++nZ8+efPDBByxcuLDM9hkZGQwcOJBx48YxduxYjTh0dXU5c+YMurq6Gn20nf2iUChKjUTT9j7XhtatW3Pt2rVy9/v5+bF3795qH79kSuK9e/fUI7EAZs6cySuvvMKnn35aZqHryu7f22+/rR74YWNjw61btzT237p1q8LRXgqFgtWrV7Ny5Upu3bqFra0tq1atwtTUVB2nlZUV27dvJy8vjz/++AM7Ozs+/fRTmjdvrv0NeOzJ5z8Uvwaq+/w3NTUlMTGRuLg4fvzxR8LDw4mIiODUqVNavzaqcn/rQnZ2NqdPnyYpKUk9jValUiFJEnp6evz444/qkX0lUwyffP48T6qcaDpy5AjHjx/HwEBzNRRHR0du3rxZa4EJgiAIgiC8jLydW3LgTBIFhYVoU3HGzqkFb3w4FUd9HTZsWK/x13t7e3tCRoYweNBg9QcSq879yL76C5dWh+M8Zg6mTh6i8LfwwjIyMqpRf2Pj2kmuymQyfH198fX1JTw8HAcHB7Zt28bUqVM5duwYy5Yto2/fvgBcv36du3fv1sp5U1NTSUtLU0+xOnHiBDo6Ori6upZq+2Th7MqmyZXHysqK0NBQQkND8fPzY/r06WUmmvLy8nj99ddxc3Nj0aJFGvu8vb0pKiri9u3b+Pn5VSuOsmhzn/X19SucwmVmZoadnR3Hjh3TuEfHjh2jY8eO6q/reupcixYtMDMzIyUlRT1y5e7duxw4cIDk5ORyV6+rytQuHx8fYmNjNYpl79+/v9zi0k/S19enadOmQHHR8v79+5eaqmZoaEiTJk0oKChgy5Yt6mmhtcXd3Z0tW7YgSZL6d9ixY8cwNTVVx/Y0PT09/P398ff3Z/bs2VhYWHDw4EF69eql1WujvqfOmZmZ8csvv2hsW7ZsGQcPHmTz5s0aUynPnTtH06ZNy62jVt+qnGhSqVRlvnhv3LhRb0sLCoIgCIIgvCgUcgOCe3Zj7Y+xyCSpwmSTDEAmI7RfH5ybNmHsEqsq/gAAnq9JREFU6NGcOHGCkFEhrF2zls6dO5dKIslkMvQej1zSMzQWSSbhhdagQQOaNWvG9evXtS4GDsWvA3t7eywsLGocw8mTJ4mNjSUgIABra2tOnjzJnTt3cHd3B8DZ2Zl169bRoUMHsrKymD59eo0TESUMDQ0JDQ1l4cKFZGVlMWnSJIYOHVrmqBRTU1OmTZvGlClTUKlUvPrqqzx48IBjx45hZmZGaGhohecKDw+nffv2tG7dGqVSya5du9TX+LTx48dz/fp1YmNjuXPnjnq7paUlLi4ujBgxgpCQECIjI/H29ubOnTvExsbStm1b+vXrV617oc19dnR0JDY2Fl9fX+RyeZmj2aZPn87s2bNp0aIFXl5exMTEkJyczPr169Vtqjp1riRB8fDhQ+7cuUNycjIGBga0atWqzPY6Ojr4+/tz9OhRgoKCgOJRTvb29oSHhxMeHk6jRo24evUq+fn5BAQEAFWb2jV58mS6du1KZGQk/fr1Y+PGjZw+fZpVq1ap28ycOZObN2+ydu1aAH799VcSEhLo1KkT9+7dY9GiRZw7d45vvvlG3efkyZPcvHkTLy8vbt68SUREBCqVik8++aQqt6xS77//PosXL+bDDz9k4sSJXLx4kdmzZzN16tRSSS+AXbt28dtvv/Haa6/RoEED9uzZg0qlwtXVVevXRlXub35+PikpKer/37x5k+TkZExMTNTHWbp0Kdu2bSM2NlbdLyUlhfz8fDIzM8nOzlY/d7y8vNDR0aFNmzYa57G2tsbQ0LDU9iNHjqifF8+jKq86FxAQwOLFi9Vfy2QyHj58yOzZs9XZZUEQBEEQBKF8zk2bEBLQE/0KCn0C6OvpERLQE+emxUP9S+phfDjxQ1q0aCGSSMJLTyaTMfLtkdXqWxuFwKF4lMFPP/1E3759cXFxYdasWURGRqpXHvv666+5d+8e7dq1Y+TIkUyaNAlra+sanxeKP/gOHjyYvn37EhAQQNu2bVm2bFm57efOnUtYWBjz58/H3d2d3r17s3v37lJFpctiYGDAzJkzadu2La+99hq6urrlLp9++PBh0tPTadWqFba2turH8ePHgeJVs0JCQvj4449xdXUlKCiIU6dOlaqrUxXa3OfIyEj279+Pvb19uXWpJk2axNSpU/n444/x8PBg37597NixA2dn52rH5u3tjbe3N2fOnOHbb7/F29u70s/G48aNY+PGjRpTxfbu3YtKpSIwMBAXFxfeeeedUtPftNWlSxe+/fZbVq1ahaenJ5s3b2b79u0aCYv09HSNUbJFRUVERkbi6elJr169yMvL4/jx4xqF4fPy8pg1axatWrVi0KBBNGnShKNHj2okddesWVPj116TJk3Ys2cPCQkJeHp6MmHCBMaOHcusWbPKbG9hYcHWrVvp0aMH7u7urFixgg0bNtC6dWugZq+NsqSlpam/7+np6SxcuBBvb2/GjRunbnP37l2uXLmi0a9v3754e3uzc+dO4uLi1Meoiry8PLZv3/5cly6SSVX50wDFI5cCAwORJIlLly7RoUMHLl26RKNGjfjpp59q7YdqXcnKysLc3JwHDx48k6rxglDXsnNySPjfr3R0c8G0BsPLC7IzuZPwA1YdA9E3tazFCAVBqAuSJPG/6/dZ88NFRgW64mZvIZIOL6BcZT7Jl68Qf/6CRoFwS1NTfFq74+3cAsOnyhVoIyftCheWfYz7+5EY2bWozZCF59SL8B43Ly+Pq1ev4uTkVKoIckWysrLw6+pHbm6uVqOadHR0MDQ05MjhI8/tvdBGREQE27dvr3Q6j/BikiSJTp06MWXKFPXKay+L2bNnc/jwYeLi4uo7lJfS8uXL2bZtGz/++OMzPW9VfoZXeepc06ZN+fnnn9m4cSNnz57l4cOHjB07lhEjRtTaEFFBELSXnZPLoaSfcW9mX8NE0z3SD32HhXtHkWgShOfY/YdKvj10mZW7LnA1ozgxsXzXBZxsTBnf353h3VtiYVJ50Vfh+aCQG+DT2p3Ordy4mp7O6r37GdOnF062tiJxKAiPmZmZsfTfSxn3bvFIgYqSTSWvm6VLlr7QSSbh5SeTyVi1alWpmjwvg71797J06dL6DuOlpa+vz5IlS+o7jApVOdEExUW23n777dqORRAEQRCEChxIvMnIBQfJURaW2vf7rWxmfp3A3P8ksm5GD/zbNSnjCMLzSiaTYWhQnCA0NJCLJJMgPMXPz4/oVdFMnDRRvTR8WSswKhQKli5Zit+rtVeE+mUxYcIE/vOf/5S5r65X03pSnz59OHLkSJn7/va3v/G3v/3tmcTxPPDy8sLLy6u+w6h1CQkJ9R3CS+3J6XnPqyonmkoKhZUnJCSk2sEIglA1kiSRm68EIDdfqbEqgyAIL5cDiTd5c+5+JEmirD/ml2zLVRby5tz9bArrJZJNgiC8VPz8/Dhy+Ajbtm9j7bq1la7A+KKLiIggIiKi1o43Z84cpk2bVua+Zzn6Kzo6Wp0sfJqlpRhVLwgvgyonmiZPnqzxdUFBATk5ORgYGGBkZCQSTYLwDOQq80m6dJkTKf9T1/SI2bsfS1NTOrdyw9u5JQp51Wt6CILwfLr/UMnIBQeRJAlVJeVJVBLoIDFywUEufD1UTKMTBOGlYmZmRmhIKCEjQ7h//z6PHj3C2NgYCwtRp64y1tbWz0U93SZNxB9BBOFlV+VE071790ptu3TpEu+99x7Tp0+vlaAEQSjfpRs32RAbR35h6akzmdnZ7Dl5igNnkgju2U29SpEgCC+2bw9dJkdZWOZIprKoJMhRFrLh0BXeG1D20sqCIAgvMplMRoMGDcpcvl4QBEGoXzq1cRBnZ2f+9a9/lRrtJAhC7bp04yZrf4yloIwk05MKCgtZ+2Msl27cRJIkfv31V/7xz3/w66+/lllAU5IkCnMfAVCY+0irFV0EQXg2JEli5a4LUI2X5YpdKeL1/AIxNVLQ3dsTU6OaL66ib9oA2+5voW8qPoQLgiAIgvBsVasYeJkH0tMjLS2ttg4nCMJTcpX5bIiNA0mq9POmBBTk5hI+/1/cunie69evA/DN2m9o1qwZI98eyeBBgzHS1+GPpEPcObEbZWYGAJdiwpFb2mDVuR8NvbujpzCp0+sSBKFimdlK9epyVSFJcDUjm8xsJQ3NtF9GXKg/pkZG9GznVSvH0je1xK7ny7VctiAIgiAIL4YqJ5p27Nih8bUkSaSnp7N06VJ8fX1rLTBBEDQlXbpc5nS5sqRfvcLx7ZspLCgoVa/g+vXrzJs/jx//s4KpXeyRFZU+pjLzFjf2rCbtwHqaB8/A3Nm7Vq5BEISqe5hbUOP+ItEkCIIgCIIgPCtVTjQFBQVpfC2TybCysqJHjx5ERkbWVlyCIDxBkiROpPxPq7bpV69wZPNG9XSZp6fNSJJE28bGfPRKY6TC/HIKZxb3URUoubx2Li1DwkSySRDqiYlCv177C4IgPI8kSaIoJ5ui/Fx0DRToGpmKYuCCIAjPiSrXaFKpVBqPoqIiMjIy+Pbbb7G1ta2LGAXhLy9HqVSvLleR/Lw8jm/fXGFNFiN9neKRTDLQqewNmSQBEr9tWEBh7sMqRi0IQm2wNJXjZGNKVT8/yWTgZGOKpalYdU4QhJdHYe5Dbh3fyfkv3+Pn+SGcixzPz/NDOP/le9w6vvMv935l1KhRpQYC1IXff/8dmUxGcnJynZ+rtkVERODl5VXfYZQpLCyMd999t77DeGE5OjqyePHi+g7jmevcuTNbtmyp7zAqVCvFwAVBqFv5BdpNmfv93FkKCyqeZtPVwQIDXZ3Kk0wlJAlVvpLM5Djt2guCUKtkMhnj+7tXq++E/q3EX/gFQXhpPLiUxC9fjOPGntUoM29p7CuZ9v/LF+N4cCmpniJ8ednb25Oenk6bNm3qO5QKyWQytm/frrFt2rRpxMbG1tk509PTGT58OC4uLujo6PDRRx9p1S8jI4OoqCg+++yzOonr//7v//Dz81Ovzujv709CQkKl/eLi4mjXrh1yuZyWLVuyZs0ajf0//fQTAwYMwM7Orsz7/SydOnWqXhN1X331FY6OjhgaGtKpUyet7u/ixYtxdXVFoVBgb2/PlClTyMvLU+/X5v7OmjWLTz/9FJVKVZuXU6u0mjo3depUrQ+4aNGiagcjCELZDPQrf6lKksSviacqbRfobFmtGG7H78Kqcz/xoVUQ6sHw7i2Z+59EcpWFqLRYRE5HBgq5HsHdW9R9cIIgCM/Ag0tJXF47l+Lp/WX9IBTT/uuSrq4uNjY29XLuoqIiZDIZOjrVGyNhYmKCiUndLW6jVCqxsrJi1qxZfPnll1r3i46OpkuXLjg4ONRJXHFxcQQHB9OlSxcMDQ1ZsGABAQEBnD9/niZNmpTZ5+rVq/Tr148JEyawfv16YmNjGTduHLa2tgQGBgLw6NEjPD09GTNmDIMHD66T2LVlZWVVb+f+7rvvmDp1KitWrKBTp04sXryYwMBALl68iLW1dZl9vv32Wz799FNWr15Nly5d+PXXXxk1ahQymUydR9Hm/vbp04dx48axd+9e+vXrV2fXWBNavVqTkpK0eryIQykF4UVgJJdjaWpaYZuCvDwe3b9X8XH0dLAxkWs/mklNQpmZQVFu1Ve+EgSh5ixM5Kyb0aP4jXYlL18dWfFfdP/zaQ8sTMS0OUEQXnyFuQ/5bcMCQHo8rb8CdTTtf/PmzXh4eKBQKGjYsCH+/v48evQIKB5V0atXLxo1aoS5uTldu3YlMTFRo79MJmPlypX0798fIyMj3N3diY+P5/Lly3Tr1g1jY2O6dOnClStX1H1KpnytXLkSe3t7jIyMGDp0KA8ePCg3TpVKxfz583FyckKhUODp6cnmzZu1usZ79+4xYsQIrKysUCgUODs7ExMTA5SeOlfy4fjpR1xcHFCcfJk2bRpNmjTB2NiYTp06qfdVZs2aNVhYWLBjxw5atWqFXC4nNTW10vvs6OgIwKBBg5DJZOqvn546p1KpmDNnDk2bNkUul+Pl5cW+ffu0iq0sjo6OREVFERISgrm5udb9Nm7cyIABAzS2JSQk4Ofnh6mpKcbGxnh4eHDqVOV/SC7L+vXref/99/Hy8sLNzY3o6GhUKlWFo7tWrFiBk5MTkZGRuLu7M3HiRIYMGaKRQOvTpw//+Mc/GDRoULXigj+fT1u3bqV79+4YGRnh6elJfHy8RrstW7bQunVr5HI5jo6OpWpCPzl1TpIkIiIiaNasGXK5HDs7OyZNmqRuW5PnZFkWLVrEO++8w+jRo2nVqhUrVqzAyMiI1atXl9vn+PHj+Pr6Mnz4cBwdHQkICCA4OFhjJJQ291dXV5e+ffuycePGasdf17RKNB06dEirx8GDB+s6XkH4S5LJZHRu5VZhmyItVqQz0KvZbNkiZW6N+guCUH3+7ZqwKawXCrkeMhmlajaVbFPI9dgc3oue3mX/tVIQBOFF80fSIVT5ysqTTCVqedp/eno6wcHBjBkzhgsXLhAXF8fgwYPVNTGzs7MJDQ3l6NGjnDhxAmdnZ/r27Uv2U/U1586dS0hICMnJybi5uTF8+HDG/z979x0eRdWFAfydrdk0kgAhlAQQgoQmoUcEpQhIUXpTAgFUpARFEJAmRJr0DgIBQQRByidFFJBeldBrQDChhARC+mazZb4/ll2zpG0K2ZT39zx5QmbuzJ6dLJOZM/ee++mnGD9+PP7++2+Ioojhw4dbbHPnzh1s3boVu3fvxv79+3HhwgUMHTo0w1hnzpyJDRs2YOXKlbh27Rq++OILfPTRRzh69GiW73PSpEm4fv06fvvtN9y4cQMrVqxAqVKl0m27aNEiPH782Pw1cuRIuLu7o3p14/Xq8OHDcfr0aWzZsgWXL19Gjx490K5dO4SGhmYZBwAkJSVh9uzZWLNmDa5duwZ3d/csj7MpIbNu3To8fvw4wwTNokWLMG/ePMydOxeXL19G27Zt8f7771vEVrNmTXNPqPS+3nvvPaveR0aio6Nx/fp1NGjQwGJ57969UbFiRZw7dw5Xr17FwoULUaZMGfP6zGJydHTEkCFDMnzNpKQkaLVauLllPLrh9OnTaN26tcWytm3bpkkA5ZUJEyZg9OjRuHjxIqpVq4Y+ffpA9+Ke5vz58+jZsyd69+6NK1eu4JtvvsGkSZPSDOUz2b59OxYsWIBVq1YhNDQUu3btQu3atc3rs/pMhoWFZXl8Z8yYAQBISUnB+fPnLY6VRCJB69atMz1Wb775Js6fP29OLP3zzz/Yt28f2rdvn+1j16hRIxw/fjzb2+WXbM86R0S24etdFQfPX4BWp0u3w7hUlvV/5xRd7sbxSpWqXG1PRLnTul553FjbE5sP38XKPddxL+K/m5hKZZwwpGMN9G1ZFSUcFDaMkogo74iiiKgze5H+cLnM5dWw/8ePH0On06Fr167mYU6pb2Bbtmxp0f7777+Hi4sLjh49io4dO5qXBwQEoGfPngCAsWPHws/PD5MmTTIPSRo5ciQCAgIs9pWcnIwNGzaYhzotWbIEHTp0wLx589IMZdNoNJgxYwYOHjwIPz8/AMBrr72GEydOYNWqVXj77bczfZ9hYWHw9fU1Jz9MPYLSU6JECXPvnR07dmDVqlU4ePAgPDw8EBYWhnXr1iEsLAzlypUDYKyTtH//fqxbt858s54ZrVaL5cuX44033jAvy+o4m4ZRubi4ZDrMb+7cuRg7dix69+4NAJg9ezYOHz6MhQsXYtmyZQCAffv2QZtJ3VOVKnfXxGFhYRBF0Xx8THQ6Hby8vFC1alXI5XJUrlzZYn1WI4icnZ0zXDd27FiUK1cuTSIptYiICIvEFgCUKVMGcXFxUKvVuX7fLxs9erR56NfUqVNRs2ZN3LlzB9WrV8f8+fPRqlUrTJo0CQBQrVo1XL9+HXPmzMGAAQPS7CssLAweHh5o3bo15HI5vLy80KhRI/O6rD6T5cqVy/L4mpJ0T58+hV6vT/dY3byZ8Uzhffv2xdOnT/HWW29BFEXodDoMGTIEX3/9tVXHK7Vy5cohPDwcBoMhx8NKX6UcJZr+/vtvbN26FWFhYUhJSbFYt2PHjjwJjIgsqZQK9Gn1Djb8cQiCKKa53JLb2cHBxTXT4XNJOgMiEjRwd1Bkc/icAKVbGUhVmQ/fI6JXz8VRic861cCQjj6IjtcgQa2Fo0oONycla6gRUZGjT4qHJjoiB1v+N+xfZp/xzbc13njjDbRq1Qq1a9dG27Zt0aZNG3Tv3h2urq4AgCdPnmDixIk4cuQIIiMjodfrkZSUhLCwMIv91KlTx/xv0w1q6oRVmTJlkJycjLi4OHPCwMvLy6Kejp+fHwwGA27dupUmmXLnzh0kJSXh3XfftViekpICX9+s61V99tln6NatG0JCQtCmTRt07twZb775ZqbbXLhwAf369cPSpUvRtGlTAMCVK1eg1+tRrVo1i7YajQYlS5bMMg4AUCgUFscLsP44ZyYuLg6PHj0yx2rStGlTXLp0yfzzq6qbZKJWG0cJ2NnZWSzfsWMHunTpgu+++w52dnZ4+PChxXC8qlWr5uj1Zs2ahS1btuDIkSNpXtOWUv+OTTPYR0ZGonr16rhx4wY++OADi/ZNmzbFwoULodfrIZVKLdb16NEDCxcuxGuvvYZ27dqhffv26NSpE2QymVWfSZlMluPja60jR45gxowZWL58ORo3bow7d+5g5MiRCAoKMifUrKVSqWAwGKDRaPI8AZgXsp1o2rJlC/z9/dG2bVv88ccfaNOmDW7fvo0nT57kapwmEWXNu0J5+Ldphc2HjiDlpaFygiCgWr2GuPDnH5nu4/fQaPSrm/1iju5+HXkTS1SACIKAks52KOlccC4YiYjymj4ld8P29Rp1rhNNUqkUBw4cwKlTp/DHH39gyZIlmDBhAs6ePYvKlSujf//+ePbsGRYtWoSKFStCqVTCz88vzQN5uVxu/rfpmiq9ZTmdSSohwViTau/evWmKPSuVWdfse++99/Dvv/9i3759OHDgAFq1aoVhw4Zh7ty56baPiIjA+++/j8GDB2PQoEEWcUilUpw/fz5NMsDaotwqlSrNdae1xzkv1KxZE//++2+G65s1a4bffvstx/s3DUl8/vy5RUHr8ePHo2HDhhg3bhzc3Nzg9FKN1qyO30cffYSVK1daLJs7dy5mzZqFgwcPpknevczDwwNPnljO6PjkyRM4Ozu/kmRGXn7+PT09cevWLRw8eBAHDhzA0KFDMWfOHBw9etSqz2RYWBhq1KiR6Wt8/fXX+Prrr1GqVClIpdJ0j1VmvekmTZqEfv36YfDgwQCMiebExER88sknmDBhQrZ6JkVHR8PBwaFAJpmAHCSaZsyYgQULFmDYsGFwcnLCokWLULlyZXz66afmLCQRvTreFcpjTO8euHjnLk5fu4HoVOP/fZu8ieunjiFFozHXDXjZ0X9j0Ku2OxRSiXW9mgQBErkSbnXfyaN3QERERGQdqSJ3N1F5NexfEAQ0bdoUTZs2xeTJk1GxYkXs3LkTo0aNwsmTJ7F8+XJznZXw8HA8ffo0T143LCwMjx49Mg/3OXPmDCQSCV5//fU0bVMXzs5qmFxGSpcujf79+6N///5o1qwZxowZk26iKTk5GR988IF5iFNqvr6+0Ov1iIyMRLNmzXIUR3qsOc5yuRx6vT7DfTg7O6NcuXI4efKkxTE6efKkeZgV8OqHzlWpUgXOzs64fv26uZfN06dPcfDgQVy8eNFiyGBq2R06991332H69On4/fff09SDSo+fnx/27dtnsezAgQPmoZj5ycfHBydPnrRYdvLkSVSrVi1NsshEpVKhU6dO6NSpE4YNG4bq1avjypUrVn0mszN0TqFQoH79+jh06BA6d+4MAOZC6y/XWUstKSkpTTLJ9F4yunfLyNWrV63qqWgr2U403b171zyOUqFQIDExEYIg4IsvvkDLli0xderUPA+SiCyplAr41fRBkxrVce/xYwT/dgAD33sXlcuWxVuveWHwJ8YseXonrCStAfNPhWPsWxVhgJh5skkQAAio0mcsZKpXNy0sERERUXqk9k5QunlAE/0E2avTlHfD/s+ePYtDhw6hTZs2cHd3x9mzZxEVFQUfHx8AgLe3NzZu3IgGDRogLi4OY8aMybNeBnZ2dujfvz/mzp2LuLg4BAYGomfPnun2mnBycsLo0aPxxRdfwGAw4K233kJsbCxOnjwJZ2dn9O/fP9PXmjx5MurXr4+aNWtCo9Fgz5495vf4sk8//RTh4eE4dOgQoqKizMvd3NxQrVo1fPjhh/D398e8efPg6+uLqKgoHDp0CHXq1MnxdOzWHOdKlSrh0KFDaNq0KZRKpXl4Y2pjxozBlClTUKVKFdStWxfr1q3DxYsXsWnTJnOb7A6dMyUoEhISEBUVhYsXL0KhUGTYQ8ZUOPrEiRPmREWpUqXg6emJyZMnY/LkyShVqhTu3buHlJQUtGnTBkD2hs7Nnj0bkydPxk8//YRKlSohIsI4BNVU2Bow9qB6+PAhNmzYAAAYMmQIli5diq+++goDBw7En3/+ia1bt2Lv3r3m/SYkJODOnTvmn+/du4eLFy/Czc0NXl5eVseXlS+//BINGzZEUFAQevXqhdOnT2Pp0qVYvnx5uu3Xr18PvV6Pxo0bw97eHj/++CNUKhUqVqyIkiVLZvmZzO7QuVGjRqF///5o0KABGjVqhIULFyIxMdGizpq/vz/Kly+PmTNnAgA6deqE+fPnw9fX1zx0btKkSejUqZM54WTt8T1+/Lj5c1EQZbtqlKurq7myf/ny5XH16lUAQExMDJKSkvI2OiLKlCAIsFMYu0LbKYz1WZo1a4Y1368xdzl+uduxIAi4EpmEhX89gSBTABBefFm0AmDsyeTtPwnO3gU3W05ERERFlyAIKN0kZ4mJvBr27+zsjGPHjqF9+/aoVq0aJk6ciHnz5plnHlu7di2eP3+OevXqoV+/fggMDIS7u3uuXxcwJha6du2K9u3bo02bNqhTp06GN9oAzLVeZs6cCR8fH7Rr1w579+5NU1Q6PQqFAuPHj0edOnXQvHlzSKXSDKdPP3r0KB4/fowaNWqgbNmy5q9Tp04BMM785u/vjy+//BKvv/46OnfujL/++itXiQhrjvO8efNw4MABeHp6ZtjbIzAwEKNGjcKXX36J2rVrY//+/fj111/h7e2d49h8fX3h6+uL8+fP46effoKvr2+WM4kNHjwYW7ZssRgq9ttvv8FgMKBt27aoVq0aPv744zTDs6y1YsUKpKSkoHv37ha/o9Q91B4/fmxR46py5crYu3cvDhw4gDfeeAPz5s3DmjVrzAXrAWO9ZtP7BYwJF19fX0yePNnc5ptvvsm0mLw16tWrh61bt2LLli2oVasWJk+ejGnTpqVbCBwwFoFfvXo1mjZtijp16uDgwYPYvXu3uQZTXn8me/Xqhblz52Ly5MmoW7cuLl68iP3791sUCA8LC8Pjx4/NP0+cOBFffvklJk6ciBo1amDQoEFo27YtVq1aZW5jzfF9+PAhTp06lWbygIJEEK3so3X16lXUqlULffv2RYMGDTBq1CgEBQVhyZIl+OCDD3DgwAHUq1evwBcDj4uLQ4kSJRAbG5tpVX6iwuLR02dY/r89GPpBR5Qr9V+Bxbi4OOzctRMbNm6w+APi5eUF/37+6NqlK1QyAdEXjyDy9B6LQptKNw+4+3VESd8WkNo55Ov7ISIiouwrDNe4ycnJuHfvHipXrpytgsQ6dQKuzBkMg1YDWHPr8mLYf+0xawp1j+xvvvkGu3btynI4DxVOoiiicePG+OKLL9CnTx9bh5On+vfvD0EQsH79eluHUiSNHTsWz58/x/fff5+vr5udc7jVQ+fq1KmDhg0bonPnzujRowcAYMKECZDL5Th16hS6deuGiRMn5i5yIsozzs7O6O/fH/79/HHmzBn4D/DHhvUb0KRJE4une+5+HVG6SQfE37uC0ODJ8B44DU6Va7PwNxERERUIMpUjXuszFnc2BBk7XWeWbOKwfyokBEHA999/jytXrtg6lDwliiKOHDmCEydO2DqUIsvd3R2jRo2ydRiZsnro3NGjR1GzZk1zN8z+/fvj5MmTGDduHH799VfMmzcv3TGwRGRbgiCYn2w6Ozunm0ASBAGyFz2XZHYOTDIRERFRgVLC2xdV/SdBIleCw/5zZsiQIeb6PC9/DRkyJN/ieO+99zKMY8aMGfkWR0FQt25d9OvXz9Zh5ClBEPDvv//C09PT1qEUWV9++aXFEL2CyOoeTc2aNUOzZs2wZMkSbN26FevXr8fbb7+NqlWrYtCgQejfv3+mU/kRERERERHlVAlvX9QesyaDYf9lityw/2+++QbffPNNnu1v2rRpGD16dLrr8nO45Zo1a6BWq9NdZ5rVi4gKt2zPOufg4ICAgAAEBATgzp07WLduHZYtW4ZJkyahXbt2+PXXX19FnERFSkR0EoJ/v4WBbV+Hh5u9rcMhIiIiKhRkKkfzsH+9Oh56jRpSpQpSlRN7ZGfB3d09z4qU50b58uVtHQIRvWLZnnUutapVq+Lrr7/GxIkT4eTkZDHtIRFlLOJ5EmZtuYiI55ypkYiIiIoXK+ciypQgCJDZO0PpWgYy+/RLAxARUd7Jzrk72z2aTI4dO4bg4GBs374dEokEPXv2xKBBg3K6OyIiIiIiKsLkcjkAICkpCSqVysbREBFRdqSkpAAApFJplm2zlWh69OgR1q9fj/Xr1+POnTt48803sXjxYvTs2RMODkVjLDRRUVS6dGmMGD4CpUuXtnUoREREVExJpVK4uLggMjISAGBvb8+eSEREhYDBYEBUVBTs7e0hk2WdRrI60fTee+/h4MGDKFWqFPz9/TFw4EC8/vrruQqWiHLPyV6FFr5vwMk+4yeD7u7uCBwRmI9REREREaVlmjzIlGwiIqLCQSKRwMvLy6oHBFYnmuRyOX755Rd07NjRqq5SRJQ/nOzt0apeXVuHQURERJQlQRBQtmxZuLu7Q6vV2jocIiKykkKhgERiXZlvqxNNnE2OiIiIiIjyglQq5cNrIqIiKlezzhEREREREREREZkw0UREAAC5kyvKtugFuZOrrUMhIiIiIiKiQipbs84RUdEld3JDuVZ9bB0GERERERERFWLs0URERERERERERHmCiSYiIiIiIiIiIsoTTDQREREREREREVGeYKKJqCBLiQTCFhq/ExERERERERVwTDQRFWQpkcCDRUw0ERERERERUaHARBMREREREREREeUJJpqI8pg2PhqPDm2GNj7a1qEQERERERER5SsmmojymDb+OR4f/hna+Oe2DoWIiIiIiIgoXzHRRJTPRFFEbGIKACA2MQWiKNo4IiIiIiIiIqK8IbN1AETFRUyCBj8dvoNVe27gXkQ8AKDTpN9R2cMJn3b0Qd8WVeHiqLRxlEREREREREQ5xx5NRPngYMhD+AzaivFrz+H+k3iLdfefxGP82nPwGbQVB0Me2ihCIiIiIiIiotxjoonoFTsY8hA9gg5ArdFBFIGXR8qZlqk1OvQIOsBkExERERERERVaTDQRvUIxCRr0m/0nRFGEIYtSTAbRWL+p3+w/EZOgyZ8AiYiIiIiIiPJQgUg0LVu2DJUqVYKdnR0aN26Mc+fOWbXdli1bIAgCOnfu/GoDJMqhnw7fQZJGl2WSycQgAkkaHTYfvvtqAyMiIiIiIiJ6BWyeaPr5558xatQoTJkyBSEhIXjjjTfQtm1bREZGZrrd/fv3MXr0aDRr1iyfIiXKHlEUsWrPDSAHk8qt3HOds9ERERERERFRoWPzRNP8+fPx8ccfIyAgADVq1MDKlSthb2+P4ODgDLfR6/X48MMPMXXqVLz22mv5GC1R5kRRhE6dCACIfhaDexHx2c4ziSJwLyIe0fEcPkdERERERESFi8yWL56SkoLz589j/Pjx5mUSiQStW7fG6dOnM9xu2rRpcHd3x6BBg3D8+PFMX0Oj0UCj+e+GPS4uLveBE71Ep07AswuHEXVmLzTREQCA65vmAGiX430mqLUo6ZBHARIRERERERHlA5smmp4+fQq9Xo8yZcpYLC9Tpgxu3ryZ7jYnTpzA2rVrcfHiRateY+bMmZg6dWpuQyXKUGzoBfyzeTYMKZY9kJSCPlf7dVTJc7U9ERERERERUX6z+dC57IiPj0e/fv2wevVqlCpVyqptxo8fj9jYWPNXeHj4K46SipPY0Au4syEIBq0GxmJM/w2Uc5TqUE6RACGbg+cEAajs4QQ3J2XeBktERERERET0itm0R1OpUqUglUrx5MkTi+VPnjyBh4dHmvZ3797F/fv30alTJ/Myg8EAAJDJZLh16xaqVKlisY1SqYRSyRt2yns6dQL+2TwbgGgsrPQSQQC6lLyH5Y9rZXvfQzrWgCAIeRAlERERERERUf6xaY8mhUKB+vXr49ChQ+ZlBoMBhw4dgp+fX5r21atXx5UrV3Dx4kXz1/vvv48WLVrg4sWL8PT0zM/wqZh7duGwcbhcJrPDtXMNg1Kit7pXk0QA7JUy9GlRJevGRERERERERAWMTXs0AcCoUaPQv39/NGjQAI0aNcLChQuRmJiIgIAAAIC/vz/Kly+PmTNnws7ODrVqWfYOcXFxAYA0y4leJVEUEXVmL5BFAslRqsNUr3MYf7+JcTtk3EtJIgCCIODHcS3h4sheeLkVEZ2E4N9vYWDb1+HhZm/rcIiIiIiIiIoFmyeaevXqhaioKEyePBkRERGoW7cu9u/fby4QHhYWBomkUJWSomJAnxRvnl0uK42cojCz0hlMCWsEjUEKwDLhZBohp1LK8OO4lmjlWz7P4y2OIp4nYdaWi2jfyJOJJiIiIiIionxi80QTAAwfPhzDhw9Pd92RI0cy3Xb9+vV5HxBRFvQp6my1b+QUhW3Vf8fvz72w41llPEpxNK+rVMYJQzrWQN+WVVHCQZHXoRIRERERERHlmwKRaCIqbKQKVba3cZTq0K3UP+ha8h/EfTAXnacfx+6gtmheu2z6hb9FEdDFGv+tizX+zALhREREREREVIAx0USUA1J7JyjdPKCJfoKs6jRZEmBXsgykbi4AgBIOirRJJl0cELkdeLwe0IQZl13/CFB6AWUHAO7dAJlz7t9EESaKImITUwAAsYkpEEWRs/gRERERERHlAxY/IsoBQRBQukmHHG3r7tcx445Jz48Cf/sB94MATbjlOk24cfnffsZ2lEZMggbLd19D3SHb0WnS7wCATpN+R90h27F89zXEJGhsHCEREREREVHRxkQTUQ6V9G0BiUJp/XA2QYBEoYRb3XfSX//8KHBjIGBQw9hL6uWeUi+WGdTGdkw2WTgY8hA+g7Zi/NpzuP8k3mLd/SfxGL/2HHwGbcXBkIc2ipCIiIiIiKjoY6KJKIdkKke81mcsACHrZJMgABBQpc9YyFSOadfr4oBbQ5F+gullL9rcGmrcjnAw5CF6BB2AWqODKBrLWaVmWqbW6NAj6ACTTURERERERK8IE01EuVDC2xdV/SdBIlcCEF58pWZcJpEr4e0/Cc7evunvKHJ7qp5M1njRsylqe05DLzJiEjToN/tPiKIIQxaHzyAa6zf1m/0nh9ERERERERG9Akw0EeVSCW9f1B6zBp4dBkHpVsZindKtDDw7DEKdr9ZmnGQSRWPh75x4tD5t951i5qfDd5Ck0WWZZDIxiECSRofNh+++2sCIiIiIiIiKIc46R5QHZCpHuPt1ROkmHRB/7wpCgyfDe+A0OFWunfVsZ7rn/80uly2icTtdDCB3zUnYhZ4oili150b2Jv57YeWe6xjS0Yez0REREREREeUh9mgiykOCIEBm5wAAkNk5ZJjE8HC1x7jedeHhag/ok3L3ovrE3G1fiEXHa3AvIj7beSZRBO5FxCM6nsPniIiIiIiI8hJ7NBHZgIebPb7u82IonTY5dzuTOuQ+oEIqQa3N9fYlne3yKBoiIiIiIiJijyYiW5O5AkovpC0knhXBuJ3M5RUEVTg4quQ23Z6IiIiIiIgsMdFEZGuCAJQdkLNtyw0wbl9MuTkpUdnDKduHQBCAyh5OcHNSvprAiIiIiIiIiikmmogKAvdugEQF63s1SYztS3d7lVEVeIIg4NOOPjnadkjHGiwETkRERERElMeYaCIqCGTOwOvLYUw0ZZX8eLG++grjdsVc3xZVYa+UQWJlzkgiAPZKGfq0qPJqAyMiIiIiIiqGmGiioi8lEghbaPxekLm+DfgEp+rZ9HLm5MUyiQqosQ5waZ7/MRZALo5KbBzbEoIgZJlskgjGXlA/jmsJF0cOmyMiIiIiIsprTDRR0ZcSCTxYVPATTYAx2dTgNFB5EqD0tFyn9DQub3CaSaaXtK5XHtsmvQuVUgZBSFu2yrRMpZThl8nvopVvedsESkREREREVMTJbB0AEb1E5gyUDQA8BgCxp4HrHwI1NgEl/Ip14e+stK5XHjfW9sTmw3excs913IuIN6+rVMYJQzrWQN+WVVHCQWHDKImIiIiIiIo2JpqICipB+K8Gk8yZSSYruDgq8VmnGhjS0QfR8RokqLVwVMnh5qRk4W8iIiIiIqJ8wEQTERU5giCgpLMdSjrb2ToUIiIiIiKiYoU1moiyITIyEouXLEZkZCGo90RERERERESUz5hoIsqGqKgoLFm6BFFRUbYOhYiIiIiIiKjAYaKJiIiIiIiIiIjyBBNNRERERERERESUJ5hoIiIiIiIiIiKiPMFEExGA+KQkHAq5iPikJFuHQkRERERERFRoMdFEBCA+SY3DFy4hPklt61CIiIiIiIiICi0mmoiIiIiIiIiIKE8w0URERERERERERHmCiSYiIiIiIiIiIsoTTDQREREREREREVGeYKKJiIiIiIiIiIjyBBNNRERERERERESUJ5hoIiIiIiIiIiKiPCGzdQBERERUsIiiiCSNBilaHRRyGeyVSgiCYOuwiIiIiKgQYKKJiIiIAABqTQouhN7Bmes3ER0fb17u5uSEJjWqw9e7KlRKRbb2KYoi9Enx0KeoIVWoILV3YtKKiIiIqAhjoomIiIgQ+uAhNh86ghSdLs266Ph47Dv7Fw6ev4A+rd6Bd4XyEEURz58/R1JSEuzt7eHq6mqRQNKpE/DswmFEndkLTXSEebnSzQOlm3RASd8WkKkc8+W9EREREVH+YaKJiIiomAt98BAb/jgEiGKm7bQ6Hdb8uheltGrs3/MrwsLCzOu8vLzQ76N+6NqlK8Qnd/HP5tkwpGjS7EMT/QQP9gXj0cFNeK3PWJTw9s3z90NEREREtsNEExERUTGm1qRg86EjgCgi8zQT8OjeXZza9Qt0Wm2a4W/h4eGYMXMG/vhxJUY1Lgvj6vT2aFxm0GpwZ0MQqvpPYrKJiIiIqAjhrHNERETF2IXQO0jR6bJMMj2+dxfHf9kCnVYLwFh7KTVRFKGSCRhW3x2iaMiyd5RxvYh/Ns+GTp2Q8zdARERERAUKE01ERETFlCiKOHP9ZpbtUpKTcWrXL2mSSy97u6ILFFIBEmuLfYsiDCkaRF88Yl17IiIiIirwmGgiIiIqppI0GovZ5TJy/+plc0+mzLT1dstRHJGn92SZxCIiIiKiwoGJJiIriaKI2LhYAEBsXCxvioio0EvRpp1h7mWiKOJ2yF9ZtnNSSOHhqLS+N9N/rwBNdAT06qwTXkRERERU8LEYOFEW4uLisGPnDmz8caN5hqX+A/pbzLDk7Oxs4yiJiLJPIc/6MkCbnIzEmOdZtrOT5e7ZlV6jhsye51IiIiKiwo49mogycfz4cTR7uxlmzJyB8PBwi3WmGZaavd0Mx48ft1GERET/EUURz+KS8e+TeDyLS86y56W9Ugk3J6dM2+h1Wfd6AoBkncHqONMjVapytT0RERERFQzs0USUgePHj2PwJ4MhimK6N2umZWq1GoM/GYw1369Bs2bN8jtMIioGRFGEPike+hQ1pAoVpPZOEFINUYtJ0OCnw3ewas8N3Iv4bwhaZQ8nfNrRB31bVIWLozLNfgVBQJMa1bHvbMZD46Qy6y4V4lP0iEjQwN1Bkc3hcwKUbmUgVWWe8CIiIiKiwoGJJqJ0xMXFYXjg8AyTTKmZ1g8PHI7jR49D5eSKsi16Qe7kmh+hElERplMn4NmFw4g6sxea6AjzcqWbB0o36YCSvi1w5EYs+s3+E0matD2P7j+Jx/i15xD0Ywg2jm2J1vXKp2nj610VB89fgFanQ3pnO7mdHRxcXK0aPvd7aDT61fXI1nsEAHe/jhaJMyIiIiIqvDh0jigdO3bugFqttrrgtyiKUKvV2LlrJ+RObijXqg/kTjmbfYmICABiQy/gypzBeLAvGJroJxbrNNFP8GBfMNZOHIvu0/6AWqODKAIvn7JMy9QaHXoEHcDBkIfGBdpoIPkBoI2GSiFHn1bvAIKA9FI9giCgWr2GVsV89N8YpOgNMFg7WYIgQKJQwq3uO9a1JyIiIqICj4kmopeIooiNP27M0bYbNm7gbHRElGuxoRdwZ0MQDFoNAPHFV2oiEvRSTPqnLkRRhCGL045BBJwVahz9fTr0598B/qoPhDR78f0deEv+gH8rP8gzGCZXqVYdyOTyLONO0how/1Q4RBFZJ5sEAYCAKn3GQqZyzHLfRERERFQ4MNFE9JLnz58jLCws2wkjURQRFhaGmJiYVxMYERULOnUC/tk8G0A6XZRS2f/cCxqDFGK6/ZAstap8B9c+W4CpzX+DoLGc2ACacOB+ELwfd8aYdmXRoUmjNAXCPUqXxufjJkAikWQ5xO1KZBLmnAqHIFMAEF58pWZcJpEr4e0/Cc7evlnGT0RERESFB2s0Eb0kKSkpV9snJibC1ZX1mYgoZ55dOAxDiqknU/pEEdj5rHImLf7TqvIdbOu+GQJESASks98XPxvUUN39GH4+wWhSowvUGg00Wh2UchlUSiUEQUCNil4YHjgcarX6RRz/7cuUgFKpVAj8dhHq1vdF9MUjiDy956X6UmXg7tcRJX1bQGrnYMU7ICIiIqLChIkmopfY29vnansHB944EVHOiKKIqDN7kVmSCQDi9Ao8Ssl6uFkJZTI2dt4GASKkWfZhfvGat4ZCaHAa9nbOsLezbNGsWTMcP3ocO3ftxIaNGxAWFmZe5+npCf9+/ujapSucXvSIcvfriNJNOkCvjodeo4ZUqYJU5cTC30RERERFGBNNRC9xdXWFl5cXwsPDszV8ThAEeHp6wsXF5dUFR0RFmj4p3qL3T0bUBqlV++tb6xLs5doXPZmsIQIGNRC1HSgbkG4LZ2dn9PfvD/9+/oiJiUFiYiIcHBzg4uKSbgJJEATI7J0hs3e2NggiIiIiKsRYo4mKNlEEdLHGf+tiM613YiIIAvp91C9HL+ffz59P6okox/QpaqvaqSR6K1qJ+LT+uZwF8mh9ludLQRDg6uqKChUqwNXVlec+IiIiIgLARBMVVbo44NE6IOQd4PpHxmXXPzL+/GidcX0munbpCpVKZfWNk0QigUqlQpfOXXIXNxEVa1KFyqp2ztIUlFMkQMhkiJ2zMhmvuT7PRm8mExHQhAG6mOxuSERERETERBMVQc+PAn/7AfeDjLMppfZidiX87WdslwFnZ2csXbwUgiBkmWwyrV+6ZCmcnTk0hIiyRxRFREdH48GDB4hN1kLh5oG0M7VZEgSgS8l7mbaxl+lyF5g+MXfbExEREVGxxEQTFS3PjwI3BhprjEBE+rMrvahBcmNgpsmmZs2aYc33a8w9m15OOJmWqVQqrFm9Bs3eapbX74aICipRBBJvAf9MM37PRj03k7i4OKz/YT1at2mNxn6N0aJVCzR5swm2hdyHaMV8cu1cw6CU6DPs1ZSky2UZRiknNiAiIiKi7GOiiYoOXRxwayjSTzC97EWbW0MzHUZnmmFpwtcT4OnpabHO09MTE76egBPHTjDJRFRcpB6We6kdELHO+N3KYbkmx48fR7O3m2HGzBkID7fsefnrpfvQ6AwwZJG8cpTqMNXrHASI6Sab4jR2+Oe5KwwGa9+ciQAovQCZS3Y3JCIiIiJioomKkMjtqXoyWSPV7EqZMM2wdPCPg9iwfgMAYMP6DTj4x0H09+9vnsabiIq4HA7LjU9KwqGQi4hPSgJgTDIN/mQw1Go1RFFMM7tlYooe80+FQRSRZbKpkfNTzKx8DiqFFIJgHFL3HwGrQhplNQovfeUGvLwzIiIiIiKrMNFERYMoAo/X52xbK2ZXAoxD5Uw1mJydnTnDElFxksNhuaIoIjImBocvXEJkTAxiY2MxPHB4ugmm1C4/ScTsE/8iRS++SDa9fL4RAAiQyJX4cNgQ3FzXG7MGNUalMpaJ75NPmkIPO4hWZ5skgEQFlO5mZXsiIiIiIku5LOBAVEDonhtnScq2F7Mr6ePzPCQiKiKyPSwXUF//Ahec1uDMzfuIjjeeX9b9dgAPrl5CklptVXL78pNEDN1zC80ruaJPwypQav8rzq10KwN3v44o6dsCUjtjLaXPOtXAkI4+iI7XIEGthaNKDjcnJYQYL2PyK1V86XuRjKq+ApBxYgMiIiIiyhkmmqho0CflbnuDOm/iIKKiJ5vDckMTXsPmB72QIl5G6p5Ioiji4qkT2SocnqQ14Pc70biuccDuH4Px9O8DKN2wDexKe6bbq1IQBJR0tkNJZ7v/Frq+DfgEG5Nl5nNd6hhe7EeiMiaZXJpbHR8RERER0cuYaKKiQWqfu+0lqryJg4iKlmwOyw1NqIIN4R+++MkyEaRNTkZizPMchCAiLCwMGoUzvDoMzvb2AIzJpganjTXpHq237AGq9DTWZCrdjT2ZiIiIiCjXmGiiokHmapwlSRMO64uBA8bZlTwBKQt6E1E6sjEsV623w+YHvQAAYjolEPU6Xa5CSUxMhKura853IHMGygYAHgOA2NPA9Q+BGpuAEn4s/E1EREREeYbFwKloEASg7ICcbcvZlYgoI9kYlnsh9g2kiPJ0k0wAIJXl7tmOg4NDrrY3E4T/ei7JnHn+IyIiIqI8xUQTFR3u3V4MgePsSkSUR6wcliuKwJnoxpm2kdvZwcEl+z2SBEGAl5cXXFxcsr0tEREREVF+Y6KJig6ZM/D6cpim/c7cf7MriVInqFM0AAB1iibTKceJqJgxDcvN4pySpLdHtNYt03aCIKBavYY5CsO/n3+6xb+JiIiIiAoaJpqoaDHNrmTu2fTyjdmLZRIV1FXX4NSDUliwbSfW/XYAgHH68QXbduLU1etQa1LyOXgiKnCsHJabYlBYtbtKtepAJpdb/fISiQQqlQpdOnexehurKNyBCiON34mIiIiI8hATTVT0mGZXqjzJWOg7NaUnUHkSQsvuwpzfHmHf2b8QHR9v0SQ6Ph77zv6FOVu2IfTBw3wMnIgKJCuG5Sok1iWmFXZ2eLNzd6t6J5naLF2yFM7OeTwbnMId8PqciaZsEkURN8KeY+zqM7gR9pw9YImIiIjSwUQTFU2m2ZXqHTHOqgQYv9c7glB9G2w4dBraLGaA0up02PDHISabiIo7K4bl2kuT4CaPBmDIcndlK1dBs+69M+zZJAgCBEGASqXCmtVr0OytZjmPnfJETIIGy3dfQ90h29F4xC6s2HMDjUfsQt0h27F89zXEJGhsHSIRERFRgcFEExVtL82upE7RYvOhI4AoIqvn0CIAiCI2HzrCYXRExV0Ww3IFQUATt3NplmekbOUq6PTZSPi2agN3Dw+LdZ6enpjw9QScOHaCSaYC4GDIQ/gM2orxa8/h/hPLHrD3n8Rj/Npz8Bm0FQdD+FCCiIiICGCiiYqZC6F3kKLTZZlkMhEBpOh0uHjn7qsMi4gKgyyG5frWaQOFTGb1vJdKOzvUavwmDvx+EPv27EN///7Yt2cfDv5xEP39+8PJySnP3wJlz8GQh+gRdABqjQ6iaJxdMDXTMrVGhx5BB5hsIiIiIkIBSTQtW7YMlSpVgp2dHRo3boxz585l2Hb16tVo1qwZXF1d4erqitatW2fanshEFEWcuX4zR9uevnaDtTiIyHJYbsMQoN7xF9+PQOUVgD6tWgCCYN28l4KAPq3egb2dEt7e3pg4YSK8vb05u1wBEZOgQb/Zf0IURRiyOP0bROPfmH6z/+QwOiIiIir2bJ5o+vnnnzFq1ChMmTIFISEheOONN9C2bVtERkam2/7IkSPo06cPDh8+jNOnT8PT0xNt2rTBw4d8ikiZS9ampCn8ba3o+HioNbx5IKIXBAGQuwJ2FYzfXySHvCuUh3+bVpDLZJluLpfJ4N+mFbwrlM+PaCkHfjp8B0kaXZZJJhODCCRpdNh8mD1giYiIqHizeaJp/vz5+PjjjxEQEIAaNWpg5cqVsLe3R3BwcLrtN23ahKFDh6Ju3bqoXr061qxZA4PBgEOHDuVz5FTYaHX6XG2v0WZePJyICDAmm8b07oEOTRrB7aXhb25OTujQpBG+6tODSaYCTBRFrNpzA1aPs05l5Z7r7AFLRERExVrmj1xfsZSUFJw/fx7jx483L5NIJGjdujVOnz5t1T6SkpKg1Wrh5uaW7nqNRgNNqp4ocXFxuQuaCi25TJqr7ZVym/53IaJCRKVUwK+mD5rUqA61RgONVgelXAaVUsmhcYVAdLwG9yKy3wNWFIF7EfGIjtegpLPdK4iMiIiIqOCzaY+mp0+fQq/Xo0yZMhbLy5Qpg4iICKv2MXbsWJQrVw6tW7dOd/3MmTNRokQJ85enp2e67ajos5Mr0vQusJabkxNUSmUeR2QFhTtQYaTxOxEVOoIgwN7ODq5OjrC3s2OSqZBIUGttuj0RERFRYWbzoXO5MWvWLGzZsgU7d+6EnV36Tw7Hjx+P2NhY81d4eHg+R0kFhSAIaFKjeo629avpY5sbRIU74PU5E01ERPnIUSW36fZEREREhZlNE02lSpWCVCrFkydPLJY/efIEHh4emW47d+5czJo1C3/88Qfq1KmTYTulUglnZ2eLLyq+fL2rZmv6cQGAQiZD3apVXmVYRERUgLg5KVHZwwnZfb4gCEBlDye4OdmgBywRERFRAWHTRJNCoUD9+vUtCnmbCnv7+flluN13332HoKAg7N+/Hw0aNMiPUKmIUCkV6NPqnWxPP65SKl59cEREVCAIgoBPO/rkaNshHWtwiCQREREVazYfOjdq1CisXr0aP/zwA27cuIHPPvsMiYmJCAgIAAD4+/tbFAufPXs2Jk2ahODgYFSqVAkRERGIiIhAQkKCrd4CFTKcfpxyQxRFJCYn43l8AhKTkzm7FFER1bdFVdgrZZBYmTOSCIC9UoY+LdgDloiIiIo3m0+j1atXL0RFRWHy5MmIiIhA3bp1sX//fnOB8LCwMEgk/+XDVqxYgZSUFHTv3t1iP1OmTME333yTn6FTIWaafvzinbs4fe0GouP/m13IzckJfjV94OtdBXYK9mQiI7UmBRdC7+DM9ZtpPi9NalSHr3dVc883URTx/PlzJCUlwd7eHq6urun2cBBFEfqkeOhT1JAqVJDaO7EnBFEB4eKoxMaxLdEj6AAkEGHIJKcsEYy9oH4c1xIujhw2R0RERMWbIBazx/FxcXEoUaIEYmNjWa+puEi4ClzuBNTZDTjWSrNaFEXce/wYwb8dwMD33kXlsmUzvNm/du0aOnftjF07dqFmzZqvOnIqIEIfPMTmQ0eQotNl2EYhk6FT4/q4dPYMNv64EWFhYeZ1Xl5e6PdRP3Tt0hXOzs7QqRPw7MJhRJ3ZC030fzNsKt08ULpJB5T0bQGZyvGVviciss7BkIfoN/tPJGmM//9TXzWZ/lTYK2X4cVxLtPJlD1iyHV7jEhFRQWHzHk1EtiYIAuwUxifQdgole5SQhdAHD7Hhj0OWd5fpCAu9hb5zpkOfTjIqPDwcM2bOwIKFC7B88mjYX9kLQ4omTTtN9BM82BeMRwc34bU+Y1HC2zfP3gcR5UzreuVxY21PbD58Fyv3XMe9iP96NFYq44QhHWugb8uqKOHAHrCvSkR0EoJ/v4WBbV+Hh5t9nu47PikJ527eRqPq1eBkn7f7JiIiKq5sXqOJiKigUmtSsPnQEUAUkVma6fG9uzj2yxbotFqIopimbpNpmbezBPK/foE+JRmA+OLLoiUAEQatBnc2BCE29EKevh8iyhkXRyU+61QDF1d2w+6gtgCA3UFtcXFlN3zWqQaTTK9YxPMkzNpyERHPk/J0v6IoIjImBocvXEJkTEyGNfdEUcTt27fx7fRvcfv2bdbmIyIiygJ7NBERZeBC6J1Mh8sBQEpyMk7t+iXLGw97uQRf+FWAICDLGQ8hioAA/LN5NmqPWcNhdEQFhCAI5qRSCQcFe8AWUunV3Fv324E0Nffi4uKwY+cOi+HQP2z4Ic1waCIiIrLERBMRUTpEUcSZ6zezbHf/6mXotNos271d0QUKqQQSa29MRRGGFA2iLx6Bu19H67YhIqJMZVZzLzo+HvvO/oWD5y+gmrM9Zk77Bmq1Ok271MOhly5eimbNmnFyByIiolSYaCIiSkeSRmMxu1x6RFHE7ZC/rNpfW2+3HMUReXoPSjfpwBsWIqJcyk7NvR9/2QIA6fZWNS1Tq9UIHPYJln81BE6RNzi5AxER0Qus0URERZ4oingWl4x/n8TjWVyyVfU1UrSZD5kDAG1yMhJjnmfZzkkhhYej0vreTGYiNNER0KszT3gREVHmrK25l5KcjJMvhkNn9beitrs9lrb3hvzGn9BEP7FYZ5rc4cqcway3R0RExQ57NBFRoZbZcIWYBA1+OnwHq/bcsJgpqrKHEz7t6IO+LarCxVGZ7n4V8qxPj+nNMJceO1nucvp6jRoye9YBISoIPFztMa53XXi4coaywsSamnuA9cOh65RxwNi3Khrr7gkC0p/cAebJHar6T+JMokREVGww0UREhZJOnYBnFw4j6szedIcrXJT4YMCC00jSpL2xuP8kHuPXnkPQjyHYOLYlWtcrb1whioDuOaBPgr1EBTcnp0yHz0ll1p1Ck3WG7L25l19HqcrV9kSUdzzc7PF1HyYM8osoiohNTAEAxCamQBTFbA8ltrbmnrXDoe3lEox60xOCgKx7qnJyByIiKoaYaCKiQic29AL+2TwbhhRNmnWa6CfY8fNujL8fBQhCuqU4TMvUGh16BB3AzolN8E7Z08Dj9YDGOLOQAKCJczvsi2+MjOaJk9vZwcHFNcvhc/EpekQkaODuoMjm8DkBSrcykKqcsrENEVHhl16P1E6TfreqR+rLrKm5BwAparVVw6E5uQMREVHmWKOJiAqV2NALuLMhCAatBsahCZaZpAS9FFPCGkIEYMiiFJNBBFpUDEXD+A8g3g8CNOEW630djkAhaCEg/R5JgiCgWr2GVsX9e2i0Ve1e5u7XkYXAiahYORjyED6DtmL82nO4/8QyQWTqkeozaCsOhjy0an/W1NwDAJ02xap2uZncwZoagURERIUdE01EVGjo1An4Z/NsAGKGswbtf+4FjUEKMYNeSKm1qnwHW7tvhp0sBUI6SSuVNBl9KvwMABkmmyrVqgOZXJ7lax39NwYpegMM1t5kCAIkCiXc6r5jXXsioiLgYMhD9Ag6ALVGBzGdU71pmalHqjXJJmtq7gGATK7Iso29TMLJHYiIiLLARBMRFRrPLhw2DpfLIFkjisDOZ5UznVHIpIQyGRs7b4MAEdJMzoTejnfh77kJckGHtMVeAYWdHd7s3B2CIGTa8yhJa8CC0w+MN0lZBScIAARU6TOW9TyIqNiISdCg3+w/IYqiVT1SRVFEv9l/IiYh7TDq1OyVSrg5ZT0EWaFSwcHFNfM2eTC5AxERUVHHRBMRFQqiKCLqzF5klqZJ0MvwKMURGdVUSq1vrUuwl2szTTKZeDvexRjv+ehQZj/c7C1f383JCYP79MGKFSuhUqnSTTiZloXGGaBt2B1Shd2LGF+O07hMIlfC238SnDlDEREVIz8dvoMkjS7LJJOJQQSSNDpsPnw303aCIKBJjepZ7s+a4dApnNyBiIgoSywGTkQFliiKeP78OZKSkqAU9Bazy6VHI0qt3TM+rX8uW7GopMnwczuHJh6Poa65HxqdHkq5DCql0phYqumD40ePY+eundiwcQPCwsLM23p6esK/nz+6dukKJycn6Np1QfTFI4g8veelGfPKwN2vI0r6toDUziFb8RERFWaiKGLVnhtWdPlMa+We6xjS0SfTXqW+3lVx8PwFaHW6TF+iUq06uHL8MHRabbrrk3QGTu5ARESUBSaaiChviSKgew7okwCpPSBzfTEUzHpxcXHYsXMHNv640ZywKW0vx5IO1TLdTinordq/m0qN11yznlkoLRFCShjsZcmwV6UdXuHs7Iz+/v3h388fMTExSExMhIODA1xcXCxugGQqR7j7dUTpJh2gV8dDr1FDqlRBqnJi4W8iKpai4zXm2eWyQxSBexHxiI7XoKSzXYbtVEoF+rR6Bxv+OARBFDNMNins7NC0c3cc+2XLi/2nbfl7aDT61fXIdqyc3IGIiIoLDp0joryhiwMerQNC3gH+qg+ENHvx/R3jcl2cuakoikhMTsbz+AQkJidbXMgfP34czd5uhhkzZyA8/L9Z4JKtGK7gKNWhnCLhRWHvTNrJrZtZKEP6xExXC4IAV1dXVKhQAa6urhneWAiCAJm9M5SuZSCzd+YNCBEVWwnq9HsQ5eX23hXKw79NK8hlmT9n9fJ+HdNmzs5wOPSxsFik6EVO7kBERJQB9mgiotx7fhS4NRQwpFPkVBMO3A8CwuZCXXkJLkR54Mz1m4iO/+/JtZuTE5rUqI6kyAgMG/YZRFFM8xQ5PkWf5XAFQQC6lLyH5Y9rZRpugjbrmYUyJeWwNiKivOSoynr2zrzY3rtCeYzp3QMX79zF6Ws30vwt8qvpA1/vKrBTKNC+Vat0h0OX9CiPiIpvodKjM8hsFlQAnNyBiIiKJSaaqOhTuAMVRhq/U957fhS4MRDGwhrpXWwbl4XGlcPmvXeRIoanaREdH49dR49j94pF6SaZTKwZrtDONQxrn/hAY5BCzKAoeLRahX+eu6JSieeQZKtfpwAoPQGZS3Y2IiKiLLg5KVHZwwn3n8RnmrdJT2UPJ7g5KdOuSIkEIn4CPPpaXAOolAr41fRBkxrVce/xYwT/dgAD33sXlcuWtei9lHo49JkzZ+A/wB8b1m9AkyZNIAgCYkMv4J/Ns42zoQKw/Bto3I9ErkSVPmM5uQMRERUrHDpHRZ/CHfD6nImmV0EXZ+zJlGGSySg0oQo2hPeFVsw4t33/6mXotNoMk0wAcPTfGKToDZkOV3CU6jDV6xwEiJkMoROw6nwjayanS6vcgGzXnCIioswJgoBPO/rkaNshHWukP/Q4JRJ4sMj4PYPXtFMYE1R2CmWmw5yrVKmCEcNHoEqVKuZ2Jbx9UXvMGnh2GASlWxmLbZRuZeDZYRDqfLWWSSYiIip2mGgiopyL3P5iuFzGiR+13g6bH/QCAIgZnHJEUcTtkL+yfLkkrQHzT4VDFJFpsqmRUxRmVj4LpUQPAWnzQoIAbL72BtRaRYa9ntKSABIVULqble2JiCg7+raoCnulDJJs5PLtFFL0aVHl1QX1gru7OwJHBMLd3fKhlWlyh5pfrID3wGkAAO+B01DzixVw9+vIGUSJiKhYYqKJiHJGFIHH67NsdiH2DaSI8gyTTACQolYjMca6WeAuP0nE7BP/mns2pU04GethNHGLw/mpdTFrcGNUKmM5nXSlMk4Y/9HbwOvLIbxon7kX66uvAGTOVsVJRETZ4+KoxMaxLSEIQpbJJtPqbwc0hItjOsPmrORkr0IL3zfgZK/K8T6AF5M7vEgqyewcOLkDEREVa6zRREQ5o3sOaMIybSKKwJnoxlnvSpu9WeAuP0nE0D230byiC9p5u8Ej1U2G0q0M3P06oqRvC0jtHPBZHWBIRx9Ex2uQoNbCUSWHm5NpiEQNwC74pULmaWtsQKIyJplcmmcrTiIiyp7W9cpj26R30W/2n0jS6ABY1toWBOPPSrkEyVoDXvcsAVEUc5zYcbK3R6t6dfMgciIiIjJhoomIckaflGWTZL0dorVuWbaTybM/C1yS1oD9d6Kx/040Th/+E04qBaRKFaQqpzQ3HIIgoKSzHUo626XdkevbQIPTQNR24NF6y+SZ0tNYk6l0N/ZkIiLKJ63rlceNtT2x+fBdrNxzHfci/psZzvXFg4XoeGMB7k6TfkdlDyd82tEHfVtUzVXvJiIiIsobHDpHlA2lS5fGiOEjULp0aVuHYntS+yybZFb8OzWFSgUHF9dshyAIAry8vFCybAUoXctAZu+cs6faMmegbABQ7whQY5NxWY1Nxp/LBjDJRESUz1wclfisUw1cXNkNZ5d0RofGnlAppHieoMHzBI1F2/tP4jF+7Tn4DNqKgyEPbRQxIHdyRdkWvSB3yv7fMyIioqKEiSaibMioGGixJHMFlF7IrL6RXNBZtStBEFCtXsMcheHfzz/vamEIAmBfFagw0vidNTaIiGxKEAQ8fJqE/X89gEarhyhaDqUDYF6m1ujQI+iAzZJNcic3lGvVB3KnrHvyEhERFWVMNBFRzggCUHZApk3spMlwk0cDMGS5u0q16kAml1v98hKJBCqVCl06d7F6G6so3AGvz43fiYgo34iiCPWTMITtXQP1kzCIooiYBA36zf4ToijCkPFkowAAg2jcR7/ZfyLmpV5PRERElH9Yo4mIcs69GxA290Uh7bR3AIIANHE7i31P2mW5K4WdHd7s3B3Hf9kCMc1Mci/v19jTaOmSpXB25rA2IqLCTKdOwLMLhxF1Zi800REAgKjTe6B088BeWUskaXRpejFlxCACSRodNh++i89avMKgiYiIKEPs0USEvJveuNiROQOvL4dx+Fz6w8x8S1yCQtBCsKJXU9nKVdC8e2/I5HIIgpBuUW9BEKBSqbBm9Ro0e6tZHrwJIiKyldjQC7gyZzAe7AuGJvqJxbrkZ0+w7nhk2rFyVli553qWDy2IiIjo1WCiiQj/TW/sZJ91gWt6ievbgE8wIFEhvYSTSqpBnwpbgTRr0hIAlH2tKn76ZQcmfD0Bnp6eFus9PT0x4esJOHHsBJNMRESFXGzoBdzZEASDVgNjr1jLxFCcXo5HKQ4Qs/zrYUkUgXsR8YhNSsm7YImIiMhqHDpHRLnn+jbQ4DQQtR14tB7QhP23TukJ78p94f/6W9h85BxSdBkXCJfLZOjT6h14VygP3+rV4d/PHzExMUhMTISDgwNcXFzyrvA3ERHZjE6dgH82zwaQTnXvF9QGaa5eQ63RwSVXeyAiIqKcYKKJiPKGzBkoGwB4DAB0MYA+EZA6ADIXQBDgDWBM74q4eOcuTl+7gej4ePOmbk5O8KvpA1/vKrBTKMzLBUGAq6srXF05VTQRUVHy7MJhGFJMPZnSp5Loc/EKIuxlauM/dbHGZBYfVBAREeULJpqIKG8JAiB3NX69RKVUwK+mD5rUqA61RgONVgelXAaVUsmeSkRExYQoiog6sxeZJZkAwFmagnKKBDzOxvC5Espk9K19CcMa/o0S958ZF17/CFB6GWdKde9mfDBCRERErwxrNBFRvhMEAfZ2dnB1coS9nR2TTERExYg+Kd48u1xmBAHoUvKe1fttVfkObgxdgJktf0cFp2jLlZpw4H4Q8Lcf8PxodkMmIiKibGCiiYiIiIjyjT5FbXXbdq5hUEr0ELLo/dSq8h1s674ZKpkWEgGQCC+3f1Fs3KAGbgxksomIiOgVYqKJiIiIiPKNVKGyuq2jVIepXucgQMww2VRCmYyNnbdBgAhplle2LxJOt4YCujir4yAiIiLrMdFERERERPlGau8EpZsHYGXdpUZOUZhZ6Yy5Z9PLo6371r4Ee7nWiiSTyYueTVHbsxM2ERERWYmJJiIiIiLKN4IgoHSTDtnappFTFLZV/wMTWzuiUhmnVGtEDGv4t5Upq5c8Wm+cjY6IiIjyFBNNRERERJS+lEggbKHxex4q6dsCEoUSabonZUQQ4KyS4ovB7XFxZTfsDmoLANgz5U14OT+zejf/EQFNGKCLye6GRERElAUmmoiIiIgofSmRwINFeZ5okqkc8VqfsQCErJNNggBAQJU+YyFTOUIQBJRwUAAAnO0MuQtEn5i77YmIiCgNJpqIiIiI6JWLjIzE4iWLERlpTFqV8PZFVf9JkMiVMNZrejnhZFwmkSvh7T8Jzt6+5jUervYY17suPEq55C4oqUPuticiIqI0mGgiIiIiolcuKioKS5YuQVRUlHlZCW9f1B6zBp4dBkHpVsaivdKtDDw7DEKdr9ZaJJkAwMPNHl/38YVH6bKA0gvWFhb/j2DcTuaSszdDREREGZLZOgAiIiIiKr5kKke4+3VE6SYdEH/vCkKDJ8N74DQ4Va4NwZphdWUHAPeDsv/C5QZYXyOKiIiIrMYeTURERERkc4IgQGZnHMoms3PIOslk4t4NkKhgfa8mibF96W45ipOIiIgyx0QTERERERVeMmfg9eVIv87Ty16sr77CuB0RERHlOSaaiIiIiChX4pOScCjkIuKTkmwTgOvbgE9wqp5N6RcWh0QF1FgHuDTP/xiJiIiKCSaaiIiIiChX4pPUOHzhEuKT1LYLwvVtoMFpoPIkQOlpuU7paVze4DSTTERERK8Yi4ETERER0SsliiJi42IBALFxsRBF0foaTNkhcwbKBgAeA4DY08D1D4Eam4ASfiz8TURElE+YaCIiIiKiVyIuLg47du7Axh83IiwsDADQf0B/eHl5od9H/dC1S1c4O7+CWkmC8F8NJpkzk0xERET5iEPniIiIiCjPHT9+HM3eboYZM2cgPDzcYl14eDhmzJyBZm83w/Hjx20UIREREb0KTDQRERERUZ46fvw4Bn8yGGq1GqIoQhRFi/WmZWq1GoM/GcxkExERURHCRBMRERER5Zm4uDgMDxyeboLpZaY2wwOHIy4uLp8iJCIioleJiSYiIiIiSksUAZ2xgDd0scafrbBj5w5zTybrXsbYs2nnrp05jZSIiIgKECaaiIiIiOg/ujjg0Tog5B3g+kfGZdc/Mv78aJ1xfQZEUcTGHzfm6GU3bNxgdXKKiIiICi4mmoiIiIjI6PlR4G8/4H4QoLEs4A1NuHH5337GdumIi49DWFhYthNGoigiLCwM8fHxOY2ciIiICggmmoiIiIjImDy6MRAwqAGIL75Se7HMoDa2e5FsEkUR6hQNACAmLneJIrU6OVfbExERke3JbB0AEREREdmYLg64NRTpJ5heZlyvvv4FLjitwZmb9xH9oifSzhOncxWGSmWXq+2JiIjI9phoIiIiIiruIren6smUtdCE17D5QS+kiJcBCOblcjs7OLi4IjHmebZeXhAEeHp6wsnJKVvbERERUcHDoXNERERExZkoAo/XW908NKEKNoR/CK0oQ+okE2BMGFWr1zBHYfj384fC2Q1lW/SC3Mk1R/sgIiIi22OiiYiIiKg40z0HNGGwpjeTWm+HzQ96AQDEDC4jK9WqA5lcbvXLSyQSqFQqdOncBXInN5Rr1QdyJzertyciIqKChYkmIiIiouJMn2R10wuxbyBFlGeYZAIAhZ0d3uzcHYIgZNjGxNRm6ZKlcHZ2tjoOIiIiKriYaCIiIiIqzqT2VjUTReBMdGOr2patXAXNuvfOsGeTIAgQBAEqlQprVq9Bs7eaWR0uERERFWwsBk5ERERUnMlcAaUXoAlHZsPnkvT2iNZaP6StbOUq6PTZSNy/dhm3z/9lUSDc09MT/v380bVLVxYAJyIiKmKYaCIiIiIqzgQBKDsAuB+UabMUgyLbu1bY2aFa/UbwrtcQb7/mhWGffYoN6zegSZMmVg2tIyIiosKHQ+eIiIiIijv3boBEhZdnkUtNIUnJ8e4FQUBJVxcAgLOzM5NMRERERRgTTURERETFncwZeH05jImm9JNA9tIkuMmjARiyvXs3Jyco5dnvEZUrCnegwkjjdyIiIso3TDQREREREeD6NuATnKpnk2XCSRAENHE7l2a5Nfxq+uR/LyaFO+D1ORNNRERE+YyJJiIiIiIycn0baHAaqDwJUHparlN6wrdOGyhkMqtTTQIAhUyGulWr5HWkREREVEAx0URERERE/5E5A2UDgHpHgBqbjMtqbALqHYHKKwB9WrUABCHLZJMAAIKAPq3egUqZz8PmiIiIyGaYaCIiIiKitATBmHQCjN9fDH3zrlAe/m1aQS7LfPJiuUwG/zat4F2h/KuOlIiIiAqQzK8QiIiIiIhe4l2hPMb07oGLd+7i9LUbiI6PN69zc3KCX00f+HpXgZ2CPZmIiIiKmwLRo2nZsmWoVKkS7Ozs0LhxY5w7dy7T9tu2bUP16tVhZ2eH2rVrY9++ffkUKREREREBgEqpgF9NH3zRowsGvvcuAGDge+/iix5d4FfTh0kmIiKiYsrmiaaff/4Zo0aNwpQpUxASEoI33ngDbdu2RWRkZLrtT506hT59+mDQoEG4cOECOnfujM6dO+Pq1av5HDkRERERCYIAO4USAGCnUOb/7HJERERUoNg80TR//nx8/PHHCAgIQI0aNbBy5UrY29sjODg43faLFi1Cu3btMGbMGPj4+CAoKAj16tXD0qVL8zlyIiIiIiIiIiJKzaaJppSUFJw/fx6tW7c2L5NIJGjdujVOnz6d7janT5+2aA8Abdu2zbA9EREREeWQwh2oMNL4nYiIiMgKNi0G/vTpU+j1epQpU8ZieZkyZXDz5s10t4mIiEi3fURERLrtNRoNNBqN+ee4uLhcRk1ERERUTCjcAa/PbR0FERERFSI2Hzr3qs2cORMlSpQwf3l6eto6JCIiIqIixclehRa+b8DJXpVhm9KlS2PE8BEoXbp0PkZGRERE+c2miaZSpUpBKpXiyZMnFsufPHkCDw+PdLfx8PDIVvvx48cjNjbW/BUeHp43wRMRERERAMDJ3h6t6tWFk719hm3c3d0ROCIQ7u4chkdERFSU2TTRpFAoUL9+fRw6dMi8zGAw4NChQ/Dz80t3Gz8/P4v2AHDgwIEM2yuVSjg7O1t8ERERERERERFR3rNpjSYAGDVqFPr3748GDRqgUaNGWLhwIRITExEQEAAA8Pf3R/ny5TFz5kwAwMiRI/H2229j3rx56NChA7Zs2YK///4b33//vS3fBhERERERERFRsWfzRFOvXr0QFRWFyZMnIyIiAnXr1sX+/fvNBb/DwsIgkfzX8erNN9/ETz/9hIkTJ+Lrr7+Gt7c3du3ahVq1atnqLRAREREREREREQBBFEXR1kHkp7i4OJQoUQKxsbEcRkdERERERQKvcYmIqKAo8rPOERERERERERFR/mCiiYiIiIiIiIiI8gQTTURERERERERElCeYaCIiIiIiIiIiojzBRBMREREREREREeUJJpqIiIiIiIiIiChPMNFERERERERERER5gokmIiIiIiIiIiLKE0w0ERERERERERFRnmCiiYiIiIiIiIiI8gQTTURERERERERElCeYaCIiIiIiIiIiojzBRBMREREREREREeUJma0DyG+iKAIA4uLibBwJEREREVHeMF3bmq51iYiIbKXYJZri4+MBAJ6enjaOhIiIiIgob8XHx6NEiRK2DoOIiIoxQSxmjz0MBgMePXoEJycnCIJg63BsIi4uDp6enggPD4ezs7OtwykWeMzzH495/uMxz3885vmPxzz/8ZhbRxRFxMfHo1y5cpBIWB2DiIhsp9j1aJJIJKhQoYKtwygQnJ2decGWz3jM8x+Pef7jMc9/POb5j8c8//GYZ409mYiIqCDg4w4iIiIiIiIiIsoTTDQREREREREREVGeYKKpGFIqlZgyZQqUSqWtQyk2eMzzH495/uMxz3885vmPxzz/8ZgTEREVLsWuGDgREREREREREb0a7NFERERERERERER5gokmIiIiIiIiIiLKE0w0ERERERERERFRnmCiiYiIiIiIiIiI8gQTTZQjrCFPRESUt/i31TYMBoP533q93oaREBERFQ1MNFG23b9/H4sXL8bEiRPx8OFDW4dTLJgugnkTQoXZyZMnLW7oqGDh+cW2DAYDBEEAADx69MjG0RQvEonxcnjcuHH46quv+H+BiIgol5hoomy5cuUK3n33XVy5cgXx8fEoXbq0rUMqFkwXweHh4TaOhChnLl68iGbNmiEoKIjJpgLAdCP97NkzxMTEQK1Wm5MclP9EUTSf57/66isMHDgQcXFxNo6q6EudUNq/fz/+97//oUePHvy/QERElEtMNJHVbt++jZYtW6JHjx5YtWoVFi1aBIVCwSd/+WTPnj1488038eDBA1uHUmzws5136tati5UrV2LGjBmYMWMGk002JIoiBEHA7t270b59e7z99tuoVasW1qxZg8ePH9s6vGLH9PsAgBMnTuDEiROYNm0anJ2dbRxZ0Wc67nv37sWOHTvQpUsXNGnShMPniIiIcomJJrKKVqvFvHnz0K5dO0ycOBFSqdS8jk/+8odKpYKzs7N5SAVv1F8dU4JJrVanu5yst3r1apw6dQoGgwGffPIJli1bhilTpjDZZEOCIOD3339H79690atXL+zevRvt2rXDsGHDcOPGDVuHV+yY/ob+/PPPWLFiBapWrYpGjRpBp9PZOLLiISIiApMnT8bGjRvNvYalUinPT0RERLnARBNZRS6X4/Tp06hSpQrs7e3TrDddkCUnJ+d3aEVSehe4rVq1QsWKFTFmzBgA/w2no7wnCAJ+++039OrVC926dcPKlSuRmJgIQRCYbMoGURQxdepUDBw4ECEhITAYDBg8eDBWrVrFZJON6PV66HQ6bNiwAUOHDsWoUaMglUpx4MABDBgwAC1btrR1iMWSKIrYvXs39uzZgytXrsBgMEAmk/H/xytgOoebvnt4eCA4OBjNmjXD6dOnsW3bNgDGv7E83xMREeUM71QpSzqdDhEREXjw4AGqVq1qXpaaKemxcOFCPHv2LN9jLGpMxzMpKcli+aRJk5CQkICDBw8CYA+bV+XUqVP44IMPULVqVURHR+OHH37A8OHDER8fz2STlUzDge7duweVSoUBAwbg/PnzTDbZiOkzm5ycDJlMhn///Rdt2rRBYmIiGjVqhBYtWmDVqlUAgB9//BG3bt2yZbhF3svnEEEQsH79egwePBhPnz5FUFAQEhISmOzIY6kLrsfExECj0SA5ORlvvPEGZs+eDS8vLwQHB2P37t0AjL8Xnp+IiIiyj4kmylBUVBQAQCaTwd3dHXXq1MH333+PyMhIyGSyNBe/ly9fxq+//ornz5/bItwiZ9WqVfD29sa0adPMN321a9eGXC7Hzp07AXDY4qsQGhqKU6dOYdasWViwYAEOHjyIvn374tatWxg2bJg52cSbj8wJggCdTge5XI5z585BEAQEBAQw2WQjgiBgy5YtaNWqFQDA29sbc+bMQY0aNdC5c2csWbIEgDG5vX37duzevZu/k1ckdbLj7t27ePToEcLCwiCTyTBr1ix06tQJe/bswYoVK5CUlMTzTR5JXXB95syZ6NKlC9566y107doVN2/ehK+vL+bNmweNRoMVK1Zgz549ANh7mIiIKCf415PSFR8fj7p16+KTTz4BYLzQat26NS5cuIDly5fj2bNnaZIc27dvh7OzM2eiy6HUNxLJycno1q0b+vXrh7Nnz6J+/foYO3Ysbt++jTlz5mD79u04e/asDaMtmkJDQzF48GAsXrwYrq6uAIy1Oj799FP07dsXoaGhCAwMRFxcHG8+rCCTyaDVaiGXyxESEpJhsunbb7/FhAkTeDP9CpgeCISHh2P58uX48MMPAQA9evTA48eP4ezsjCVLlkChUAAApk+fjsuXL6Nr1678jL8CqZMdkyZNQteuXdGwYUO0adMGCxcuhFwux6JFi1C/fn388ssvWL58ublnE+WO6Zpl0qRJmDdvHnr16oVOnTpBr9ejcePGOHLkCHx9fTF79mxotVpMmzYNJ0+etHHUREREhZRIlA6dTicGBweLjo6OYmBgoHl5p06dRIVCIY4YMUIMDQ0VRVEUr1+/LgYGBopubm7i5cuXbRVyoabX683//u6778QJEyaI9+7dE0VRFBMSEsSNGzeKHTt2FCtWrCg2bNhQLF++vLhw4UJRFI2/K8obcXFx4ujRo8Vy5cqJ3bt3Fw0Gg3ldSkqKuHz5crF69erikCFDLNaRpYyOTUpKilizZk2xZs2a4rlz58yf+8WLF4slS5YUo6Ki8jPMYuP8+fPi4MGDxS5duogxMTGiKIqiWq0Wv/32W7F27dpikyZNxOHDh4tdu3YV3dzcxJCQEBtHXPRNnz5ddHNzE/fs2SNu3bpVDAoKEqVSqfj111+Lomj8v/LZZ5+JlSpVEjdt2mTjaAu31Oej8PBwsU6dOuKWLVvMyxISEsQBAwaIJUqUEB8+fCiKoiiePXtWHDFihMXfZiIiIrKeIIoc/E/p0+v12Lp1KwICAvDxxx+bh1Z89NFH+PPPPxEbGwsPDw84OTlBr9dj48aNqFu3rm2DLuTGjh2L9evXY+bMmWjXrh3KlStnXhcdHY1Hjx4hKCgIZ8+ehSiKuHTpElxcXGwXcCEnpppW3CQhIQFz5szB//73P7Rr1w5BQUGQy+UAjLMvrl+/Hu+++y4qVapkg4gLPtMxPXr0KI4fP4779+9j8ODBqFatGtzc3KDVauHr6wsAWL9+PerVqweJRIKYmBh+ll8BrVaLMWPG4JdffoGDg4NF7SW1Wo3Dhw9j69atiImJgbe3NwYPHozXX3/dhhEXTanPNWq1Gu+//z7at2+PL774wtxm06ZN6NevH3788Uf07dsXWq0WixYtwhdffGEx0ytZz2AwmHuDxcbGQqvVolKlSti7dy/efvtt8/qoqCi0bdsW3bt3x7hx4yx6kKXeBxEREVmHiSYyM10I6/V680WtXq/Hzz//jEGDBmHQoEFYunQpAODQoUO4desWIiMj0bBhQ9SrVw9ly5a1ZfiF3m+//YZPPvkEO3bsQMOGDc3LX77INRgMOH/+PD7//HP07dsXw4YNSzdhQpkzHbOzZ8/izJkz0Ov1qFevHt555x0kJiZi5syZOHDgAFq0aIFvv/0WMpnM1iEXGjt37sTAgQPRvHlzaLVanDt3DmPHjkWPHj1QqVIlaLVaNGzYEFFRUdi9ezfq1atn65CLnNTnhKioKCxYsACrVq3CwIED8d133/F8kY9S/y6uXbuGmjVronz58hg+fDjGjx8P4L+h0/369YNUKsX3338POzs78z5S/10m66Q+7l999RUePHiA9evXo2XLlvDx8cHSpUuhVCohiiL0ej3eeecdvPnmm/juu+9sHDkREVHhx0c0BAAICwvD2LFjERMTA6lUCr1eD8BYn6ZXr14IDg7G6tWrMXHiRABAq1atMHToUHzzzTfo0KEDk0x54MmTJ/Dw8ED16tXNx198Uc8j9Sx/EonEnNj766+/ALAoeE4IgoDt27ejTZs22LJlCzZu3IiWLVti4sSJUKlUGD9+PFq3bo0TJ07g888/TzPTIqXv7NmzGDFiBObPn4///e9/2LNnD+Li4jB//nysX78e4eHh5gLhFStWZC+mPGZ6dvT8+XMkJycjOjoapUuXxujRozFw4EAcPXoU06ZNM7fXarVptqW8kzrZMW7cOPTv3x8JCQno3r079u7di+vXrwMwntclEgmcnJwQGxtrkWQCwCRTNqU+7keOHMGhQ4cQGBgIuVyOjh074vr161i0aBEAWMwkaqrNR0RERLnDR/QEwNgDYffu3UhOTsa3334LZ2dn8xNUqVSKLl26ICoqCt999x06duyIJk2a2DrkIufhw4cIDw+Hk5MTAECn00Emk8FgMODEiRPmJJQoipBKpXB3d8fdu3eh0WigUCiYbMqm27dvIzAwEPPmzcPAgQOh0+nMvfekUimmTp2KsWPHIjExEdeuXUN0dDTc3d1tHXaBZjAYEBYWho8++ggBAQG4d+8eWrRogc8++wwlS5bE1KlTIZfL0atXL1StWhWnTp2ydchFiunm+tdff8V3332HuLg4yGQyjB49Gn379sWECRMgiiL27dsHqVSKiRMnmoeFAkxYvwqmY3r27FmcP38eS5cuhaOjI1q3bo2QkBDz0Ljq1asjMTERd+7cgY+Pj42jLtxSJ5l27tyJXbt2oXHjxubrlsDAQDx69AhbtmzBr7/+iqZNm+LEiROIiYnBmDFjbBk6ERFRkcEeTQQAGDZsGAICAvDXX39h/PjxiIuLs+jZZGdnh/bt20MURTx+/NjG0RZuGc2s1blzZzg4OGDUqFEQRdE8VCs+Ph4zZszA6dOnARhvXC5evIizZ89i9uzZUCqVvEHMwuLFi3Hjxg2LZXFxcXB0dESrVq0gCAIUCgX69euH77//Ht9++y1Onz4NZ2dnTJ8+HT/99BOTTBkw9QTQ6XSQSCRo0qQJ/P39kZycjM8++wytW7fGggULMHnyZJQvXx6zZ8/Gjh07oNPp2IMmjwmCgP3796NHjx7o1KkTPv74Y7zzzjv46KOPMHXqVLi4uGDcuHFo3rw5Nm7cyCFCr1Dq8/xPP/2E7777DiqVyjxMtFOnThgwYABu3ryJ1q1b491330Xz5s0RERGBBQsWAGAPs5wwGAzmv4d3797FihUrsGPHDty8edPcxt7eHrNnz8a4ceNQuXJlhIaGwtfXF5cuXYJMJjNf9xAREVHOsUcTmXvOjBo1CgaDAf/73/8wfvx4zJw5E87Ozub1rq6uqFSpEhwcHGwdcqGVut7S+fPnodVq4ebmhmrVquG1117DRx99hN9++w0DBw7E119/jbCwMCxYsABPnz5Fv379zPupW7cu/vjjD5QsWdJWb6VQEEURSUlJWL58Od577z2LdVqtFqGhoYiOjkblypXNn/POnTtj5syZuHXrFvz8/ODg4MDPfAZMPQcOHDiAkydPYuDAgfDy8gJgHI77+PFjDB8+HBKJBBEREXjnnXfg6emJrl27subVK2AwGLBhwwYMGDAAY8eONS+vVasWBg8ejJo1a6J79+4YM2YM7Ozs0LNnTxtGW3SZhjwDwM2bNxESEoJTp05BLpcjMjISFSpUAAAMGjQIdevWxcWLF3H58mV4enri888/h0wmM5+PyHqpj/vQoUMBAEuXLsX06dNx+PBhLF682Hw+UqlU6NmzJ3r27Gnxd5nHnYiIKG+wR1MxFRsbi5iYGAAwP8EzDbF4//33ERISgtGjRyMxMdF80TV//nw8ffoUtWrVsmHkhVfqi+CJEyeiW7du8Pf3R506dbBgwQJIJBKMHj0aAQEBCAkJQZ06dTBixAhoNBqcPXvW/HsyPSlnksk6Dg4OuHbtGry9vXHmzBlcvXoVoijCz88PHTt2xFdffYWbN2+aP+d2dnawt7fnLENWEAQBO3bsQLdu3ZCQkICkpCTzuujoaERFReHx48f4559/sGrVKty5cwcTJkxA1apVbRh10ZWSkoL79+/D2dkZgLGAtF6vx8CBA/Hpp59i8eLFiI+Ph7u7O6ZOncqZE1+B1D1qAgMD8dFHH2HixIkYN24cpFIpZs6cifDwcHP7+vXrY9CgQVi0aBFGjx5t8feYrJd6uNyDBw9w9uxZ9OzZE9WqVcOCBQvg5+eHbdu2Ye3atRa9MAFYnOt53ImIiPIGZ50rhu7fv48333wTLVu2RJ06dfDVV1+leaK3cOFC/PLLL9BoNGjVqhUiIiJw+PBh7N27F3Xr1rXtGyjkvv32WyxfvhybNm1CixYtMGzYMKxduxajR4/GhAkToFKpAADnzp2Du7s7vLy8zAXBeRGcM6ZhWhUrVkSZMmWwadMm1KhRA7t378aSJUug0Wgwffp0ODo6Ytu2bVizZg3Onj3LG/EsXL9+HW3btsWUKVMwePDgNOsDAwMRHBwMDw8PxMfH47fffuMMc3nIdHMdFRWF0qVLAwC+/PJL7NmzB3/++SfKly9vrrU3bdo0/PHHHzhx4oSNoy4enj9/jqFDh2Lw4MFo1aoVAGD27Nn4+eef0bJlS3z++eeoUKECZwzNA1qt1lxrbObMmfj7779hb2+P1atXm4eWR0VFYdiwYXj8+DEGDBiAgQMH8rgTERG9QnxkXwyFhIQgNjYW77//PoKDg9GlSxd89dVXiI6ONj9J/fzzzzF16lQ0aNAA165dQ8mSJfHnn38yyZQDqWt13L59G6dOncKKFSvQokUL7Nq1C5s3b0b37t0xY8YMzJgxw1wDq1GjRqhUqRIkEgkMBgOTTDmQ+sm1XC7HhQsXEBsbi8GDByM0NBSdOnXC559/jlKlSqF58+bo06cPtm3bhv379zPJZIWIiAiULFkSHTp0MNc1Sf15X7x4MXbu3Illy5bh3LlzTDLlIVOCYs+ePRg8eDA2bNgAAPjggw9Qvnx5jB49Go8ePTLPVhYVFYUSJUogKSmJtX9eAVMPYQBYtmwZatasifDwcHh7e5uXjx07Fj179jQP4/r333+Z7MilLVu2YPXq1dDpdNDr9VAqldi3bx8uXboEiUQCQRCg1WpRunRpLFu2DBUqVMCcOXOwZ88eW4dORERUtIlULDVp0kScP3++mJycLC5btkzs2rWrWKlSJXHixIni4cOHLdrqdDrbBFkEGAwG879v3boliqIo/vDDD6JarRZPnDghli9fXly8eLEoiqI4aNAg0d7eXvz888/FmJgYm8RblJiO/eHDh8WgoCDxzp07oiiKYmRkpFihQgXRz89PvH37trn9pUuXxNu3b4tPnjyxSbyF0Q8//CAqlUoxISFBFEXLc8Vff/0lhoeH2yq0YmHXrl2iUqkU58+fL169etW8fN26deI777wjVqxYURw4cKDYuXNn0dHRUbx06ZINoy261qxZI44YMUKMj48XRVEUT548KdavX190dnY2n3c0Go25/axZs8Ty5cuLS5cutUm8RcWqVatEQRDEAwcOmJclJiaKq1evFmUymTh58mTzcq1WK4qiKD558kScNGkSr2uIiIheMQ6dK2ZMwyg2btyI//3vf9iwYQPs7e0BAJUrV4YoioiMjET//v1Rq1YtDBs2zMYRF16phyMGBgZi7dq1iIyMhMFggJOTE0aOHIlnz55h7dq1UCqV+Oqrr3D69GkYDAacOHGCT7pzQXzR22P79u0ICAjAmDFj8P7776NOnToQBAGRkZGoV68evLy8sHr1atSoUYPHOwf+/fdftGvXDu+//z6+/vprlChRwnyOCQgIQPXq1TFmzBjWu3oFIiIi0LlzZ/To0QNffvllmvXnzp3Dnj17cOnSJVSoUAHDhg1DjRo1bBBp0bZ69Wp8+umn+N///odOnToBMJ77z58/j759+8Ld3R1Hjx6FTCazGOK1ceNG9O3b19zjjLJn1apVGD58OLZt24bOnTtbrNNqtfj+++8RGBiIb7/9FuPHjzcvNx1/4L/rISIiIsp7HItTzJguqho3boyvvvoKe/fuRY8ePRAQEIDk5GTs2bMHMTExmDRpEs6ePYsuXbqgXLlyNo66cDLdXIeGhiIhIQG//fYbHBwcIIoidDodbt26hbJly5ovfG/fvo25c+eicePGAMDaHdmU+iZCEAScPXsWn376KebPn29RP+jp06dwd3dHSEgIGjVqhN69e2Pbtm2oXr26rUIv8Eyfxb///hvXr19HXFwcGjdujIYNG6JHjx74448/kJKSggkTJuDZs2fYuHEj9u7di6+++opJpjzyco02jUaDhw8fwsfHx7ws9TmjUaNGaNSoEW+mX6FVq1Zh2LBh2LFjhznJBBgTTQ0bNsRPP/2EXr16oXXr1jh06BDkcjlSUlKgUCjMs4jy95N969evx7Bhw/Drr7+iffv25uUTJ05Enz59ULNmTXz88ccAgM8//xwSiQRjx461SDIB4HEnIiJ6hZhoKoZEUUS1atUwbtw4rF+/HuvXr8f58+fx22+/wdfXFwDwxhtvQCKRwM3NzcbRFm6bN2/G5MmT4erqiho1aph7OclkMnTs2BGBgYGIjo7G/fv3odfrUb9+fQBMMmXXl19+ibp166Jfv37mY3f27FnztO6JiYk4ePAgNmzYgLt372LYsGH4+OOPcebMGbRu3Rp2dna2fgsFmql32CeffIJmzZohLCwMwcHB6NatG6ZMmQKJRII9e/agTJky8PHxgVqtxu+//26RBKGcu3//Pnbu3IkGDRqgWbNmAIDExEQIgmBRh8yUiPrrr79w7do1DBgwgDfTr8gPP/yAYcOGYffu3XjvvffMy/39/dGtWzd88MEHaNiwIX7++Wf07t0b7777Lg4cOACFQmGxH/5+suevv/7CwIEDMXz4cIskU/fu3XH27FkMHz4cAKBQKPDxxx9DIpFg2LBhKFeunDm5R0RERK8eHzUXQ6YERuPGjXHlyhXcuXMHJ0+eNCeZRFFEqVKlmGTKAVMhZNN3tVoNDw8PhIaGQqfTQSKRQKvVAgCGDx+OFStWwM3NDS1btsTFixfNU1szyZQ9SqUStWvXBvDfsS9dujTCwsIQFBSErl27Yu3atRAEAe3atcOnn36KS5cuwcPDA5cvX2bh7yxcuXIFgYGBmDFjBnbt2oW1a9fixo0bSEhIgFQqxeTJk/Hnn39i165dWLduHU6cOGE+n1DuXLlyBe+++y7Onz9vnigAAGrUqAEfHx/zRA6peztt27YNBw4cQEJCgi1CLtJEUcT9+/cxcOBAtG/fHo0aNTKv69mzJ44dO2ZR9L5hw4bYsmULTp8+jZEjR9oi5CKlYcOG6NSpE06ePIlt27YBAHr16oXbt2/jxIkT8PDwMP8NUCgU+Oyzz7B161b06dPHlmETEREVO6zRVESZnm6nrhOUnqFDh+LYsWO4evUqAPakySvnz59H/fr1YTAYsHPnTkyZMgWurq745ZdfUKZMGYveB6l/Ry8Pj6HMvfx53b9/Px4+fIj+/fvj4cOHWLx4MQ4cOIA333wT/fr1Q9OmTREaGooPP/wQP/74I6pVq8bPfCoZnS+2b9+OuXPn4vTp07h37x5atGiBtm3bYtWqVQCAq1evolatWvkdbpF348YNNG3aFJ988glGjhyJsmXLWqz/999/0alTJ6jVagQFBUEURZw5cwbr1q3DyZMnzclXynuLFi3CwoUL0b9/f4wcORJDhgzB9evXsXv3blSqVCnNeeXmzZvw9vZmD6ZcSD3MsFu3brh79y6USqW5x6qHh4fFcV+7di26du0KV1dXAPz7SkRElJ/4F7cIunv3LoKDgxEXF4f27dtbdOs3Md1QDh48GOfOncOWLVvQu3dv3nDngRMnTqB58+ZYtGgRRowYga5du0Kn02HZsmXw9/fHhg0bUKZMGXNNodQ39rwIzp6XP6+//fYblixZAolEgoCAAMybNw8xMTFwcXExt/nhhx+QlJRkXsbPvJHpnBAeHo4//vgDBoMB1atXR7NmzSCXy1GmTBmEh4ejefPmaN++PZYvXw4AOH78OP744w+ULFkyTSKEci45ORnffvstPvzwQ8yaNcu8XK1WIzo6Gk+ePEG9evVw9OhRDBo0CEFBQdBoNKhQoQKOHz/OJNMrYvp/MnLkSAiCgDlz5mDz5s2QSCQ4cuQIypQpY5GwnTp1Kj744APUrVsXAGsy5YZUKjUfv+3bt+PDDz/E1q1bMXfuXJQuXRrAf+fzd999F4mJiQgICDBvz7+vRERE+Yd/dYuYK1euoH379nj//fdRrVo1tGrVKt12potgHx8fJCcnY+fOnejRowcvgPNAzZo1MXnyZIwaNcpcH6Jnz54QRRErVqzAgAEDEBwczJvyPGB6eh0REQEPDw8sWrQICoUCn376KQwGA/r06WNOKB05cgRbt27Fli1b8Oeff8Ld3d22wRcgphvjy5cv4/3330eZMmVw9+5duLi4YP78+ahTpw727duH3377DUOGDMGiRYvM227duhX37983z15JeUMmk+Hu3buoWbOmedn+/fuxb98+bNiwAQDQokULbNu2DTt27MCDBw+gVCqhVCrh7Oxsq7CLPIlEYv7/EhgYCDs7O4wePRr+/v7mIVsSiQSiKKJt27Z49OgRJk6caN6ef2NzJ3WyadOmTUhJScHatWtRsmRJ9O7dGzKZDO3bt0dYWBiuXr1q/l3wgQIREVH+YqKpCLl79y7atWuHfv36WTwBz+giy2AwQKVSYd26dXB0dOQFcA6kd2xdXV3NM92MGDECgiBg6NCh6NWrFwRBwNSpU/Hdd99hwYIFNoq6aDAd+z179mDRokX48MMPMWDAAMyZMweiKGLo0KEQBAG9e/eGWq3GoUOH8PjxYxw7dozDvFJJnWTy8/NDYGAgJk2ahFOnTqF///5YuXIl9u3bhxUrVuCzzz5DhQoVEBYWBq1Wi1WrVmHTpk04fvw4SpQoYeu3UmSIooiEhAS4ubkhPDwcZ86cwdGjRxEcHIz69etj2rRpqFatGj788EN89dVXmD9/PipUqGDrsIu01L2UUiebPvnkE6SkpGDWrFlwdnbGiBEjULZsWXTo0AHh4eG4fPkypFJplsPYKa3Q0FB4e3unWZ462bRt2zZ069YNc+bMgUQiwQ8//ID79+/j6tWrkMvlHC5HRERkKyIVCQaDQZw8ebL4/vvvi8+ePbN1OMXO3LlzxS1btlgse/78uTh16lRREARxzZo1oiiKol6vFw8cOCDqdDpbhFnk7Nq1S1QqleLChQvFkJAQi3VffvmlqFAoxODgYFEURTEmJkaMiYmxRZgFXlhYmFiqVCmxR48eFssbNmwoent7izExMWJCQoK4du1a0c7OTqxYsaLo4+Mj1qhRI81xp7yzadMm0dvbW/Ty8hJdXV3F1atXi3fv3jWv79Wrl9ilSxcbRlj0HT161PxvvV5vsS71z4sWLRIrVKggTpw4UWzevLlYrVo1MSUlRRRFUdRqtfkTbBFy69YtURAEcc6cORm2Sf13tEePHqIgCGKdOnV43ImIiAoAPuYpIgRBwNGjR+Hl5ZXubHGmp6mJiYlQKpV8wpdLYqqeTAkJCbh48SImTZoEOzs7fPDBBwAAFxcXfPbZZzh27Bg+/vhjxMfH4/PPP0fr1q0BsFZHbkVFRWHWrFmYOnWqxWxOKSkpUCgUmDt3LgRBwKBBgyCXy/HRRx/ZMNqCTa/Xo3LlytBoNDh58iSaNm2KmTNn4u+//0aDBg3g7++PkiVLomPHjti7dy/UajUqVqyI0qVLo0yZMrYOv8gxnV/69u2L+vXrQ6vVomzZsihZsqS5jV6vR0pKCqpXr27DSIu2Z8+eoUuXLqhduzaOHDli0ZMJSDuMzvS9Tp067FGTS+XLl8f06dMxYcIEyOXydGfsS92zaevWrZg+fTrGjh0LmUzG405ERGRj/CtcBIiiiMTERCQnJ5tv+kw32yamC+P58+ejefPmePvtt20Sa1GQ+kbjzp07qFSpEubMmQNXV1f4+/tj/fr16NKlCwCgdOnS8PHxQUxMDLZv326+WBYEgUmmXEpMTERYWFiaoscKhcJ8oz5nzhzI5XLUr1/fRlEWDpUqVcKmTZsQGBiI7777Du7u7vjf//6HrVu3olGjRjh//jyuXr2KIUOGwMHBAfXq1cP27dttHXaRJQiC+TP8+uuvp1mfkpKCadOm4ezZs5g9e7YNIiweSpYsiZ07d6J///5o164d9u/fn2myafjw4ahcuTLatm3LZEcOHTt2DM2bN4eDgwMCAwOhUCjwxRdfAECGySbTcZ4wYQIAzi5HRERUELBgQCFnuhlxdHRE7dq1ERwcjCdPnkChUJgLk5r8888/OHPmDIv25kLqG4zJkyfj888/x6+//goPDw988cUX6NevHwICAvDrr78CMM4c9fTpU0yaNAnHjx9nQdI8IIoiAOPvwsHBAc+fP0+z7tSpUwgODgYAzJgxAz4+PvkfaCHj7e2NRYsWQa1W48cff8RXX32F7t27w8vLC126dMGkSZNw48YNzJkzx6IGHL0aGZ0rduzYgcDAQKxZswZ79uxJt4YN5Z3mzZvjxx9/xNWrV9GuXTsA/yWXTFL/3KFDByaZcsjUg8z0IMzBwQFDhgzBnDlz8MUXX1hMQpDay8eZx52IiMj2mGgqpPR6PQBjrw6T3r17Qy6XY8CAAXj06FGawqMbNmxAXFwcKlasmK+xFiWmYzpp0iQsX74cQ4cORdOmTQEAlStXxpgxYxAQEIDOnTujZcuWaNiwIW7evImOHTsCyLgwO2XOlEBK7bXXXkPlypUxe/Zs/PPPPwD+uznfvXs3du/ejfj4+HyNs7CrVq0aVqxYgebNm+PPP//EiRMnzOu0Wi1KliyJ7t27M7mRR+Lj4y3O4Vk5d+4c1qxZg9jYWBw+fBi+vr6vMDoyadq0KX7++ecsk02pMdmRfaYeZGFhYWjbti0A65NNREREVLAIYnp3cFSghYaGYuXKlTh37hySk5PRoEED9O7dG2+//TZmz56N+fPno2LFiliyZIl5hqgff/wRP/30E44ePYo6derY+i0UateuXUOvXr0wb94888Vwamq1Gvv27cPBgwdRqlQpTJkyBTKZjDWZcsiUnDt48CC2bt2K8PBwNGjQAJ9//jkA4O233zbP7Ofi4oKTJ09iw4YNOHnyZJphdWSd0NBQBAYGQhRFTJo0yZxMpbxz/fp1fPjhhxgxYgT69u0LOzs7q7Z78OABnJ2d4ezs/IojpJedPHkSvXr1Qq1atbB//34A4Gxyr4DpONesWRO///47AONDtZUrV2Ls2LGYP38+AgMDbRwlERERZYaJpkLm8uXLaNmyJd577z04OTlBpVJh7dq1cHBwwKhRo/Dll19ixYoVWL58Oa5duwYnJyd4enrC0dER33//PZNMeeDChQt47733sHv3bjRs2NBiXUpKCrRaLRwcHCwSSxxGkTu7du2Cv78/PvzwQ9SqVQtff/01GjVqhJ9++gmOjo748MMP8e+//yI2NhYVK1bE/Pnz8cYbb9g67EItNDQUo0aNwtOnT7FgwQI0adLE1iEVGeHh4ejQoQMePXoEvV6PJUuWoHv37pkmm9gbsmA4efIkevfujTp16mDv3r22DqfIyijZtGrVKowePRpbtmxBz549bRwlERERZYSJpkLkwYMHaN68Ofr06YPp06dbLB84cCAuX76Mb7/9FoMHD0Z0dDROnTqFmJgYVK9eHZUqVUKpUqVsGH3hlN7T6mPHjqFjx474/fff4efnZ1F4/fDhwwgPD0fv3r0tirFTzj169AgdOnRAQEAAAgMDodfr4eHhgX79+mHu3Lnm38/z58+RkpICBwcHODo62jjqouHmzZuYNGkS5s2bBy8vL1uHUyTo9XqsW7cOu3fvxsqVK/Htt98iODgYq1evzjLZRK9GdnslnTp1Cs2bN8fIkSMxb968VxhZ8ZZesikhIQG7d+9Gjx49+PCGiIioAGOiqRDZtm0bVq5cia1bt8LFxQVSqRRarRZyuRzh4eH44IMPYDAYcOTIEbi4uNg63EIv9c3H0qVLkZCQgHHjxgEAOnfujJCQEPz111/mmf7UajW6dOmCWrVqYe7cuTaLuyhI3XsjMjIS7733Ho4dO4aoqCg0bdoUHTp0wPfffw8AOH78OJo2bcrhK6/IyzNYUu5dvHgR4eHh6NSpEwBg6NChWLduHVavXo1u3bpBpVJZtGdvplcn9Xn+3LlzEEURBoMBfn5+mW535coV1KhRg8OhXzFTD7LatWtj3759FuvYU5iIiKjg4p1ZIXL+/Hncu3cPbm5u5otbuVwOg8EAT09PLF68GJcvX8apU6dsHGnRYLr5GDNmDGbPng2NRoOwsDAAwDfffIPKlSvDx8cHCxYswMyZM/HBBx/g4cOHnJErDwiCgK1bt2L16tWQyWR4+vQpduzYgXfffRcdO3bE8uXLAQC3bt3CzJkzcfbsWRtHXHQxyZQ3QkJCMG3aNABA3bp1zUkmAFi+fDkGDhyIjz/+GNu3b0dycjIAYOvWrXj8+DGTTK+IKIrm8/zXX3+Njz76CIMHD0aHDh3wySef4N9//81w29q1a0MqlZon5iDrvTwjbmZMhdj/+OMPjBo1ymIdk0xEREQFF/9KFyKmuj+JiYlwdHQ0P4k1XShXqlQJJUqUQHR0tI0jLTq2bt2KjRs3pqnHVLduXWzduhUzZ87Epk2boFKpULVqVezdu5dTW+dQ6l4bV69exSeffIKpU6fCzc0NXbt2xSeffIKWLVti1apV5m02bNiAyMhIzqRIBdrly5fRsGFDfPHFFxbLTb1npFIpli1bBgD4+OOPYTAYcOzYMezfvx+nT5+2RcjFgul8M3/+fKxevRp79uxB48aNERQUhClTpuDjjz/O8tzCHk3Zk5MeZG+++SYuXLiAGjVq5FeYRERElEu8Ey5EOnTogClTpmD+/PmYPHkyJBIJ9Ho9JBIJBEFAcnIyKlWqhEqVKtk61CLj5s2beOutt9CwYUNzcW9TEqlMmTJYuHAhoqOjUaJECRb+zoHUNx2pk0zbtm3Dp59+ipEjRwIAevbsidu3b+Phw4fYuHEjlEolTpw4gR9++AHHjh1DuXLlbPYeiDJz6dIl+Pn5Ydy4cRa19QDjZ97UKyZ1smnAgAFwdHTE4cOH4enpaYuwi5WLFy9iypQpaNy4MX755RfMnz8fy5YtQ8OGDTl0NA+93IPsl19+gVKpxMOHD9G9e3dMmDAhw8SeaQZRzt5KRERUOHDoXAH17NkzXL9+HVeuXDEv8/LyQkBAAKZPn26uASSVSs036GvXroVer0e1atVsEnNhZ+rOn7pb/7Nnz3D//n1zrwNRFCGTyaDRaMwzDqUeymhaT1kzJZkePnyIn3/+GT/99BN2796NmTNnYtmyZYiJiTG39fPzw+jRo9G0aVMEBgZi5syZuH37No4fP87Z5ajAunPnDpo0aYIvv/wS06dPh6kk4saNG3H8+HFzu9RDsOzt7eHq6oqzZ8+ifv36Nom7uBBFEWq1GmfOnEGZMmVw6tQpBAQEYObMmfjss8+g1WoxYcIEHD582NahFgkv9yDbuHEjrly5gi+++AJr1qxBZGRklvtgkomIiKhw4B1xAXT16lUMHDgQUVFREEURbdq0wffff49SpUphxIgRiI2NxdixY3H+/Hm0b98egiDg9OnT2LhxI44dOwZ3d3dbv4VCZ8uWLfjjjz8wbtw4lC9fHg4ODgCMT1F37dqFffv2oXXr1uYZoZKSkjBz5kyo1Wp0797dvB/WUrGOKcl0+fJldOnSBXZ2dggNDUWdOnVQvnx5NGrUCL/99hsuXryIunXrAgBatGiBFi1a4JtvvoGzszN0Op3590RU0BgMBgQHB8PJyQklS5YEYDw/fPvtt1i8eLE5UW0ilUqxbds2zJs3D+fOnYOPj48twi7SXp5dThAEqFQqfPTRR5g7dy4uXbqEFStWICAgAAAQHx+Pixcvoly5cmjRooWtwi5y2IOMiIio6OOscwXMpUuX0LRpUwwZMgQdO3bEL7/8gtWrV2PBggUYOnQoAGMB5L1792LhwoVQq9UoVaoUqlevjqCgINSqVcvG76DwiYuLQ7169RAXFwcPDw80atQIb731FgYMGAAA6NixI27duoWJEyeiadOm0Gq1GD16NJ49e4aTJ0/yCWs2pU4y+fn5Yfjw4Rg5ciT+/vtvLF++HPHx8ejcuTN+/fVXuLm5ISgoCHXq1LGoZ0NUGDx69Ajfffcdzpw5gwEDBiAuLg5z587FDz/8gPfeey9N+8ePH8NgMKB8+fI2iLZoS51kunfvHpKTk83JvBMnTmDEiBFwcnJCcHAwqlatiidPnmDgwIGIiYnBsWPHeN7JA6IoIjk5GW+88QamT5+O8uXLo23btpgzZw6GDBkCrVaLr7/+Gu3bt2dij4iIqJBjoqkAuXPnDmrXro3Ro0cjKCgIgPGCuHr16hgxYoR5uJxJXFwcIiMj4erqCnt7+zRTYpN19Ho9Jk2ahIoVK6Jhw4b4888/MX36dLz77rto0aIFPvnkE/Tp0wcPHjzAmTNn8MYbb8DOzg7Hjh2DXC5nzYgcCA8PR7169dCiRQts3brVvHzlypUYP348Ll26hJCQECxduhSOjo4ICgoy1+ggKkwiIiIwffp0HDhwAHfv3sXvv/+Oli1b8rxhI+PGjcOWLVsQHR2NKlWqwN/fH8OGDcPu3bvx3Xff4cGDByhbtqy5ntCpU6d4ns+hl3uQmUybNg179+5N04MsOjoavXr1Qvv27dMUziciIqLChUPnCoj0hlkAxiFdWq0WoaGhWLhwIdzc3NCzZ0/IZDI4OzvD2dnZhlEXDVKpFM2aNUOvXr1w4sQJjB49GsOHD8eMGTMwbNgwbN26Fe3bt0f37t3h7u4OlUqFhg0bQiKRsPB3Dun1elSuXBkajQYnTpzAW2+9BQCoUqUKBEFAYmIiOnfuDI1Gg+DgYIwcORJLlixBzZo1bRw5UfZ4eHhg4sSJkEgkOHLkCC5cuICWLVtaFAGnVyd1suPHH3/Exo0bsXjxYnh5eWH16tXYvHkzHj9+jFmzZqFGjRoICQlBeHg4XnvtNXTr1s1iAgiyXmY9yFq2bImdO3eiUaNGaNasGQCYe5AlJSUhMDDQZnETERFR3mCPpgIk9TCL/v37Iz4+HrNmzcKwYcNQt25dbNq0CeHh4Xjy5Am8vb0xatQodOjQwdZhFxnDhg0DAPPMTzVr1kS1atVQqVIl3Lp1C/v378fGjRvx4YcfAsj4aS1ZJzQ0FIGBgTAYDFi4cCE8PT3x2muvISAgALNnzza327BhA7Zv345ly5ahQoUKNoyYKOdMPZv++usvdOnSBWPHjgXA80h+2bVrF+7duwepVGqRyJgxYwY2b96MoKAgdO7cOc12TAbmDnuQERERFU9MNBUwGQ2zAGB+qrp06VKEhIRg9OjRqFGjho0jLjrWrl2LdevWYffu3WjVqhXs7e2xb98+ODs74+HDhzh+/Di6d+/OJ9t5KDQ0FCNHjkRSUhIuX76M/v37Y8GCBQAArVYLuVwOwFiU18nJyZahEuWa6fx+4cIFtGrVClOnTrV1SEWWKYEniiKePn2KihUrIjk5GSNHjjSfY0xatGiBEiVKYNeuXbYJtgh5uQfZ2LFjLXqQXbx4Ee+88w5mzZqFW7dusQcZERFREcVEUwH05MkTzJgxA0eOHIG/vz++/PJLALCYjYUXYq9Go0aN8Pfff6N58+bYsWMH3Nzc0rThsc9boaGhGDJkCO7evYsNGzagefPmAGCeCp4z+VFREhERgfHjx+PBgwfYsmWLxVBpynt//fUXGjZsiGvXrqFXr16Qy+XYuXMnKlWqZG7zzTff4MyZM9i9e7c5uU25wx5kRERExdv/27v/mKrqP47jr8NVmCJXIvkxCPwBaMLSETbLfhBFgwu0zIYhmtrNLQr6obNNh8zUlqVthc7hr+IyjMglcyhF0BoyMRzmqAWuBk6ZzTUl0RAEgvv94ztP8i0Lvl28os/Hxh+cz+Gc97l/wYv3+3MImm5S1xuzIOQYHk6nU4ZhaM+ePXr33XflcDgUGxtrHsfwam5u1iuvvCKn06nc3Fw9+OCD7i4JGDa//PKLJCkwMNDNldza6urqNGfOHB0+fFhz5sxRU1OTEhMTNW3aNOXl5WnSpEkyDEOPP/64pkyZoo8//tjdJY9YdJABAIBrsTHETSooKEg5OTm67777dODAAa1du1aSCJmGydUwKT4+Xm1tbaqqqhpwHMMrIiJCW7Zs0ejRo7Vy5UrV1dW5uyRg2AQGBhIyDYPOzs4B3wcHB+uRRx5RQ0ODJCkqKkoVFRX66aef9Nhjj8lms2nJkiXq7u5WQUGBpD86KTE0V8fljh07Jn9/f9XX1ysqKkrV1dU6derUgHPj4uJ05coV9fb2uqFSAABwIxA03cSuhk2RkZE6cuSI2tra3F3SLS8kJESrV6/We++9p6amJneXc1uJjIzU5s2bdddddyk4ONjd5QAYQRwOhzZv3qzu7m7zWFhYmO6//3699dZbZggVHR2tiooKBQYGqrm5WStWrNC3334rT09P9fb28s+Ff6Gurk6zZ8/WkSNHFB0drb179+r8+fNatmyZGhsbdfnyZXV2durLL7/UnXfeyZgiAAC3MEbnRgDGLG6slpYWrV+/XgUFBbwNyg2u3YsMAP7Jzp07lZmZqfr6eoWEhGjs2LGyWq2SpPb2diUkJCgjI0PLly83327W1NSkhIQEzZw5U5988onGjx9PyDREnZ2dGjt2rPl9a2urFi9erPnz5+vll1+WJDU2Nspms6m7u1vTpk1TYGCgWlpaVFdXJ09PT8bTAQC4RfFX9AjAmMWNFR4eLofDIQ8PD/X19bm7nNsOIROAwSoqKlJWVpYOHDig8+fPKzw8XC+88ILKysrU19cnX19fzZ49W5WVlTIMQx4eHurv71dUVJSqqqp04sQJJScn68KFC+5+lBGFDjIAAPB3CJqAv3D1l1/efgMANyeHw6ElS5YoPj5eKSkpSkxMVF5enkJCQpSWlqZnn31Wu3fv1quvvqra2lqVlJRI+mM/oejoaJWVlam9vV0dHR3ufJQRZefOnbLb7UpNTdWFCxd06dIlc23VqlUKDg7W9u3b5XQ6zVDv6me/fv16Xbx4UU6nk9E5AABuYYzOAQCAEWXXrl3KzMyU3W7X559/rrlz52rbtm3men19vUpLS7V3716NGzdOP//8s2w2mzkSfe1YNOO6g1dUVCS73a79+/dr1KhRmjdvnpKTk/Xcc88pJSVFFotFWVlZamlpUUVFhaQ/3kjX2NiolJQUBQcH6+DBg/Lz83Pz0wAAgOFC0AQAAEaMDz74QCtWrFB5eblsNpt27NihNWvWKD09XVu3bjXP6+/vV29vrzZt2qS6ujp9/fXXOnr0qGbMmOHG6kcuh8Mhu92uhIQEVVZWSpJ2796tH374Qfn5+XryySeVlJSkhx9+WLNmzdKuXbuUnp4+4Brff/+90tPTVVFRobCwMHc8BgAAuAEImgAAwIhx6NAhnT171gwxLl68qE8//VQ5OTnKyMhQXl6epIGdSu3t7bLb7fLz81N+fr5GjRrF/kBDQAcZAAAYCoImAAAw4lz7xrJLly6ppKTkT2FTb2+vuRfQhg0bVFNTo6qqKrfVPBLRQQYAAIZqlLsLAAAAGKprO5KsVqvZ4bRmzRp5eHjo/fff1+jRo81AqqurS2fOnNFvv/2mcePG0dE0SDExMSouLpbNZpMkpaenyzAM5eTkyMPDwwz1fv/9d3l5eSk3N9fsINuyZQsdZAAA3IYImgAAwIh3NWwyDEMvvviiJk2apNdee02GYej06dM6efKkiouL5ePj4+5SR5S4uDhJf3SQjR8/3gz1cnJyJEl5eXny9PQ0O8h8fX0VExOjmpoa3i4HAMBtiKAJAADcEqxWq9LS0hQQEKDU1FTz+MSJE/Xhhx/K29vbjdWNbHSQAQCAwSJoAgAAtwxfX1899dRTkv47zmWxWGQYBiGTi9FBBgAArofNwAEAAPB/aW9v16FDh5SamiqLxWIev3z5MuEeAAC3KYImAAAA/GvXdpABAIDbF0ETAAAAAAAAXMLD3QUAAAAAAADg1kDQBAAAAAAAAJcgaAIAAAAAAIBLEDQBAAAAAADAJQiaAAAAAAAA4BIETQAAAAAAAHAJgiYAAAAAAAC4BEETAAAAAAAAXIKgCQDgNoZhaP/+/e4uAwAAAICLEDQBwG1u6dKlMgxDmZmZf1rLysqSYRhaunTpoK5VXV0twzDU3t4+qPPPnj0rm802hGoBAAAA3MwImgAACg0NVUlJibq6usxjV65cUXFxscLCwlx+v56eHklSUFCQvLy8XH59AAAAAO5B0AQA0L333qvQ0FCVlpaax0pLSxUWFqaYmBjzWH9/vzZu3KjJkydrzJgxmjlzpj777DNJ0qlTpxQfHy9JuuOOOwZ0Qj366KPKzs7W66+/rgkTJigxMVHSn0fnzpw5owULFsjPz0/e3t6aNWuWjh49Kkn67rvvFB8fLx8fH1mtVsXGxurYsWPD+bEAAAAAGKJR7i4AAHBzsNvtKigo0MKFCyVJH330kZ5//nlVV1eb52zcuFF79uzR9u3bFRkZqZqaGi1atEj+/v566KGHtG/fPj3zzDP68ccfZbVaNWbMGPNnCwsL9dJLL6m2tvYv79/R0aG4uDiFhISorKxMQUFBOn78uPr7+yVJCxcuVExMjPLz82WxWNTQ0KDRo0cP3wcCAAAAYMgImgAAkqRFixZp9erVOn36tCSptrZWJSUlZtDU3d2tt99+W1999ZUeeOABSdKUKVN0+PBh7dixQ3FxcfLz85MkBQQEyNfXd8D1IyMjtWnTpuvev7i4WOfOnVN9fb15nYiICHO9tbVVb7zxhu6++27zegAAAABuLgRNAABJkr+/v1JSUuRwOOR0OpWSkqIJEyaY683Nzers7NQTTzwx4Od6enoGjNddT2xs7N+uNzQ0KCYmxgyZ/teKFSu0bNkyFRUVKSEhQWlpaQoPDx/EkwEAAAC4UQiaAAAmu92u7OxsSdK2bdsGrHV0dEiSysvLFRISMmBtMBt6e3t7/+36tWN2f+XNN99URkaGysvL9cUXX2jt2rUqKSnR008//Y/3BgAAAHBjsBk4AMCUlJSknp4e9fb2mht2XxUVFSUvLy+1trYqIiJiwFdoaKgkydPTU5LU19c35HvPmDFDDQ0N+vXXX697ztSpU7V8+XJVVlZq3rx5KigoGPJ9AAAAAAwfgiYAgMlisejEiRNqamqSxWIZsObj46OVK1dq+fLlKiwsVEtLi44fP66tW7eqsLBQkjRx4kQZhqGDBw/q3LlzZhfUYCxYsEBBQUGaO3euamtrdfLkSe3bt0/ffPONurq6lJ2drerqap0+fVq1tbWqr6/X9OnTXfr8AAAAAP4dgiYAwABWq1VWq/Uv1zZs2KDc3Fxt3LhR06dPV1JSksrLyzV58mRJUkhIiNatW6dVq1YpMDDQHMMbDE9PT1VWViogIEDJycm655579M4778hischisaitrU2LFy/W1KlTNX/+fNlsNq1bt84lzwwAAADANQyn0+l0dxEAAAAAAAAY+ehoAgAAAAAAgEsQNAEAAAAAAMAlCJoAAAAAAADgEgRNAAAAAAAAcAmCJgAAAAAAALgEQRMAAAAAAABcgqAJAAAAAAAALkHQBAAAAAAAAJcgaAIAAAAAAIBLEDQBAAAAAADAJQiaAAAAAAAA4BIETQAAAAAAAHCJ/wAZRq4HDdl1+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define colors\n",
    "colors = ['#0d4e9e', '#ffc520', '#7b9ca0', '#242624', '#cc7b4f']\n",
    "\n",
    "# Plot results\n",
    "plot_parameter_results(results_batch_size, eps_batch_size, noise_batch_size, 'batch_size', colors, results_no_dp_stats)\n",
    "plot_parameter_results(results_sample_size, eps_sample_size, noise_sample_size, 'sample_size_ratio', colors, results_no_dp_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
